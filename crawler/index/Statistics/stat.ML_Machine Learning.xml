<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3Dall%3Astat.ML%26id_list%3D%26start%3D0%26max_results%3D500" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=all:stat.ML&amp;id_list=&amp;start=0&amp;max_results=500</title>
  <id>http://arxiv.org/api/Uk2hPIG2R+bGaV862AmgQqF/1MI</id>
  <updated>2017-10-08T00:00:00-04:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">11828</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">500</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/0905.2138v1</id>
    <updated>2009-05-13T16:04:02Z</updated>
    <published>2009-05-13T16:04:02Z</published>
    <title>A more robust boosting algorithm</title>
    <summary>  We present a new boosting algorithm, motivated by the large margins theory
for boosting. We give experimental evidence that the new algorithm is
significantly more robust against label noise than existing boosting algorithm.
</summary>
    <author>
      <name>Yoav Freund</name>
    </author>
    <link href="http://arxiv.org/abs/0905.2138v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0905.2138v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.5088v1</id>
    <updated>2013-01-22T07:10:34Z</updated>
    <published>2013-01-22T07:10:34Z</published>
    <title>Piecewise Linear Multilayer Perceptrons and Dropout</title>
    <summary>  We propose a new type of hidden layer for a multilayer perceptron, and
demonstrate that it obtains the best reported performance for an MLP on the
MNIST dataset.
</summary>
    <author>
      <name>Ian J. Goodfellow</name>
    </author>
    <link href="http://arxiv.org/abs/1301.5088v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.5088v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.5738v1</id>
    <updated>2013-10-21T22:02:17Z</updated>
    <published>2013-10-21T22:02:17Z</published>
    <title>A Kernel for Hierarchical Parameter Spaces</title>
    <summary>  We define a family of kernels for mixed continuous/discrete hierarchical
parameter spaces and show that they are positive definite.
</summary>
    <author>
      <name>Frank Hutter</name>
    </author>
    <author>
      <name>Michael A. Osborne</name>
    </author>
    <link href="http://arxiv.org/abs/1310.5738v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.5738v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.07826v1</id>
    <updated>2017-08-24T20:19:20Z</updated>
    <published>2017-08-24T20:19:20Z</published>
    <title>Logistic Regression as Soft Perceptron Learning</title>
    <summary>  We comment on the fact that gradient ascent for logistic regression has a
connection with the perceptron learning algorithm. Logistic learning is the
"soft" variant of perceptron learning.
</summary>
    <author>
      <name>Raul Rojas</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1708.07826v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.07826v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62M45, 68Q32" scheme="http://arxiv.org/schemas/atom"/>
    <category term="K.3.2; I.5.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0805.1390v1</id>
    <updated>2008-05-09T17:52:42Z</updated>
    <published>2008-05-09T17:52:42Z</published>
    <title>Random projection trees for vector quantization</title>
    <summary>  A simple and computationally efficient scheme for tree-structured vector
quantization is presented. Unlike previous methods, its quantization error
depends only on the intrinsic dimension of the data distribution, rather than
the apparent dimension of the space in which the data happen to lie.
</summary>
    <author>
      <name>Sanjoy Dasgupta</name>
    </author>
    <author>
      <name>Yoav Freund</name>
    </author>
    <link href="http://arxiv.org/abs/0805.1390v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0805.1390v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0902.3453v1</id>
    <updated>2009-02-19T20:50:53Z</updated>
    <published>2009-02-19T20:50:53Z</published>
    <title>Escaping the curse of dimensionality with a tree-based regressor</title>
    <summary>  We present the first tree-based regressor whose convergence rate depends only
on the intrinsic dimension of the data, namely its Assouad dimension. The
regressor uses the RPtree partitioning procedure, a simple randomized variant
of k-d trees.
</summary>
    <author>
      <name>Samory Kpotufe</name>
    </author>
    <link href="http://arxiv.org/abs/0902.3453v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0902.3453v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0908.2579v2</id>
    <updated>2009-10-29T19:40:49Z</updated>
    <published>2009-08-18T14:35:03Z</published>
    <title>Convex Multiview Fisher Discriminant Analysis</title>
    <summary>  Section 1.3 was incorrect, and 2.1 will be removed from further submissions.
A rewritten version will be posted in the future.
</summary>
    <author>
      <name>Tom Diethe</name>
    </author>
    <author>
      <name>John Shawe-Taylor</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper has been withdrawn</arxiv:comment>
    <link href="http://arxiv.org/abs/0908.2579v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0908.2579v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1203.5647v1</id>
    <updated>2012-03-26T12:43:19Z</updated>
    <published>2012-03-26T12:43:19Z</published>
    <title>Polynomial expansion of the binary classification function</title>
    <summary>  This paper describes a novel method to approximate the polynomial
coefficients of regression functions, with particular interest on
multi-dimensional classification. The derivation is simple, and offers a fast,
robust classification technique that is resistant to over-fitting.
</summary>
    <author>
      <name>Péter Kövesárki</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 6 figures. Submitted to JMLR, pending decision</arxiv:comment>
    <link href="http://arxiv.org/abs/1203.5647v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1203.5647v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62J02" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1208.0806v1</id>
    <updated>2012-08-03T18:01:52Z</updated>
    <published>2012-08-03T18:01:52Z</published>
    <title>Cross-conformal predictors</title>
    <summary>  This note introduces the method of cross-conformal prediction, which is a
hybrid of the methods of inductive conformal prediction and cross-validation,
and studies its validity and predictive efficiency empirically.
</summary>
    <author>
      <name>Vladimir Vovk</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 2 figures, 1 table</arxiv:comment>
    <link href="http://arxiv.org/abs/1208.0806v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1208.0806v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62G15" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.6170v1</id>
    <updated>2012-10-23T09:05:45Z</updated>
    <published>2012-10-23T09:05:45Z</published>
    <title>Further properties of Gaussian Reproducing Kernel Hilbert Spaces</title>
    <summary>  We generalize the orthonormal basis for the Gaussian RKHS described in
\cite{MinhGaussian2010} to an infinite, continuously parametrized, family of
orthonormal bases, along with some implications. The proofs are direct
generalizations of those in \cite{MinhGaussian2010}.
</summary>
    <author>
      <name>Minh Ha Quang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1210.6170v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.6170v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.FA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T05, 68P30" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.2686v1</id>
    <updated>2012-12-12T01:59:27Z</updated>
    <published>2012-12-12T01:59:27Z</published>
    <title>Joint Training of Deep Boltzmann Machines</title>
    <summary>  We introduce a new method for training deep Boltzmann machines jointly. Prior
methods require an initial learning pass that trains the deep Boltzmann machine
greedily, one layer at a time, or do not perform well on classifi- cation
tasks.
</summary>
    <author>
      <name>Ian Goodfellow</name>
    </author>
    <author>
      <name>Aaron Courville</name>
    </author>
    <author>
      <name>Yoshua Bengio</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1212.2686v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.2686v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.3900v2</id>
    <updated>2012-12-21T19:55:53Z</updated>
    <published>2012-12-17T06:49:14Z</published>
    <title>A Tutorial on Probabilistic Latent Semantic Analysis</title>
    <summary>  In this tutorial, I will discuss the details about how Probabilistic Latent
Semantic Analysis (PLSA) is formalized and how different learning algorithms
are proposed to learn the model.
</summary>
    <author>
      <name>Liangjie Hong</name>
    </author>
    <link href="http://arxiv.org/abs/1212.3900v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.3900v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.1674v1</id>
    <updated>2013-07-05T17:39:40Z</updated>
    <published>2013-07-05T17:39:40Z</published>
    <title>Stochastic Optimization of PCA with Capped MSG</title>
    <summary>  We study PCA as a stochastic optimization problem and propose a novel
stochastic approximation algorithm which we refer to as "Matrix Stochastic
Gradient" (MSG), as well as a practical variant, Capped MSG. We study the
method both theoretically and empirically.
</summary>
    <author>
      <name>Raman Arora</name>
    </author>
    <author>
      <name>Andrew Cotter</name>
    </author>
    <author>
      <name>Nathan Srebro</name>
    </author>
    <link href="http://arxiv.org/abs/1307.1674v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.1674v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.03465v1</id>
    <updated>2015-02-11T21:49:26Z</updated>
    <published>2015-02-11T21:49:26Z</published>
    <title>Variable and Fixed Interval Exponential Smoothing</title>
    <summary>  Exponential smoothers are a simple and memory efficient way to compute
running averages of time series. Here we define and describe practical
properties of exponential smoothers for signals observed at constant and
variable intervals.
</summary>
    <author>
      <name>Javier R. Movellan</name>
    </author>
    <link href="http://arxiv.org/abs/1502.03465v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.03465v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.07104v1</id>
    <updated>2015-02-25T10:08:34Z</updated>
    <published>2015-02-25T10:08:34Z</published>
    <title>A Note on the Kullback-Leibler Divergence for the von Mises-Fisher
  distribution</title>
    <summary>  We present a derivation of the Kullback Leibler (KL)-Divergence (also known
as Relative Entropy) for the von Mises Fisher (VMF) Distribution in
$d$-dimensions.
</summary>
    <author>
      <name>Tom Diethe</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1502.07104v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.07104v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.08536v2</id>
    <updated>2016-01-13T23:01:42Z</updated>
    <published>2015-06-29T08:11:52Z</published>
    <title>A simple yet efficient algorithm for multiple kernel learning under
  elastic-net constraints</title>
    <summary>  This report presents an algorithm for the solution of multiple kernel
learning (MKL) problems with elastic-net constraints on the kernel weights.
</summary>
    <author>
      <name>Luca Citi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, no figures, updated version of technical report</arxiv:comment>
    <link href="http://arxiv.org/abs/1506.08536v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.08536v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.08402v1</id>
    <updated>2016-04-28T13:11:54Z</updated>
    <published>2016-04-28T13:11:54Z</published>
    <title>Two Differentially Private Rating Collection Mechanisms for Recommender
  Systems</title>
    <summary>  We design two mechanisms for the recommender system to collect user ratings.
One is modified Laplace mechanism, and the other is randomized response
mechanism. We prove that they are both differentially private and preserve the
data utility.
</summary>
    <author>
      <name>Wenjie Zheng</name>
    </author>
    <link href="http://arxiv.org/abs/1604.08402v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.08402v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.02450v2</id>
    <updated>2016-08-28T15:23:47Z</updated>
    <published>2016-07-08T16:55:31Z</published>
    <title>Proceedings of the 2016 ICML Workshop on #Data4Good: Machine Learning in
  Social Good Applications</title>
    <summary>  This is the Proceedings of the ICML Workshop on #Data4Good: Machine Learning
in Social Good Applications, which was held on June 24, 2016 in New York.
</summary>
    <author>
      <name>Kush R. Varshney</name>
    </author>
    <link href="http://arxiv.org/abs/1607.02450v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.02450v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1611.09139v1</id>
    <updated>2016-11-28T14:34:15Z</updated>
    <published>2016-11-28T14:34:15Z</published>
    <title>Proceedings of NIPS 2016 Workshop on Interpretable Machine Learning for
  Complex Systems</title>
    <summary>  This is the Proceedings of NIPS 2016 Workshop on Interpretable Machine
Learning for Complex Systems, held in Barcelona, Spain on December 9, 2016
</summary>
    <author>
      <name>Andrew Gordon Wilson</name>
    </author>
    <author>
      <name>Been Kim</name>
    </author>
    <author>
      <name>William Herlands</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">31 papers</arxiv:comment>
    <link href="http://arxiv.org/abs/1611.09139v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1611.09139v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.01807v1</id>
    <updated>2017-06-06T15:03:15Z</updated>
    <published>2017-06-06T15:03:15Z</published>
    <title>GAN and VAE from an Optimal Transport Point of View</title>
    <summary>  This short article revisits some of the ideas introduced in arXiv:1701.07875
and arXiv:1705.07642 in a simple setup. This sheds some lights on the
connexions between Variational Autoencoders (VAE), Generative Adversarial
Networks (GAN) and Minimum Kantorovitch Estimators (MKE).
</summary>
    <author>
      <name>Aude Genevay</name>
    </author>
    <author>
      <name>Gabriel Peyré</name>
    </author>
    <author>
      <name>Marco Cuturi</name>
    </author>
    <link href="http://arxiv.org/abs/1706.01807v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.01807v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.08137v2</id>
    <updated>2017-07-09T18:21:33Z</updated>
    <published>2017-06-25T16:37:38Z</published>
    <title>A Contemporary Overview of Probabilistic Latent Variable Models</title>
    <summary>  In this paper we provide a conceptual overview of latent variable models
within a probabilistic modeling framework, an overview that emphasizes the
compositional nature and the interconnectedness of the seemingly disparate
models commonly encountered in statistical practice.
</summary>
    <author>
      <name>Rick Farouni</name>
    </author>
    <link href="http://arxiv.org/abs/1706.08137v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.08137v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.OT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62H99" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.06109v1</id>
    <updated>2017-09-18T18:12:10Z</updated>
    <published>2017-09-18T18:12:10Z</published>
    <title>A Note on Tight Lower Bound for MNL-Bandit Assortment Selection Models</title>
    <summary>  In this note we prove a tight lower bound for the MNL-bandit assortment
selection model that matches the upper bound given in (Agrawal et al., 2016)
for all parameters, up to logarithmic factors.
</summary>
    <author>
      <name>Xi Chen</name>
    </author>
    <author>
      <name>Yining Wang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1709.06109v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.06109v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.03863v1</id>
    <updated>2017-03-10T22:47:31Z</updated>
    <published>2017-03-10T22:47:31Z</published>
    <title>Tuning Over-Relaxed ADMM</title>
    <summary>  The framework of Integral Quadratic Constraints (IQC) reduces the computation
of upper bounds on the convergence rate of several optimization algorithms to a
semi-definite program (SDP). In the case of over-relaxed Alternating Direction
Method of Multipliers (ADMM), an explicit and closed form solution to this SDP
was derived in our recent work [1]. The purpose of this paper is twofold.
First, we summarize these results. Second, we explore one of its consequences
which allows us to obtain general and simple formulas for optimal parameter
selection. These results are valid for arbitrary strongly convex objective
functions.
</summary>
    <author>
      <name>Guilherme França</name>
    </author>
    <author>
      <name>José Bento</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">presented at NIPS 2016, Optimizing the Optimizers. Admin note: some
  overlap with arXiv:1512.02063 [stat.ML] by the same authors</arxiv:comment>
    <link href="http://arxiv.org/abs/1703.03863v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.03863v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0710.3183v1</id>
    <updated>2007-10-16T21:16:29Z</updated>
    <published>2007-10-16T21:16:29Z</published>
    <title>Probabilistic coherence and proper scoring rules</title>
    <summary>  We provide self-contained proof of a theorem relating probabilistic coherence
of forecasts to their non-domination by rival forecasts with respect to any
proper scoring rule. The theorem appears to be new but is closely related to
results achieved by other investigators.
</summary>
    <author>
      <name>Joel Predd</name>
    </author>
    <author>
      <name>Robert Seiringer</name>
    </author>
    <author>
      <name>Elliott H. Lieb</name>
    </author>
    <author>
      <name>Daniel Osherson</name>
    </author>
    <author>
      <name>Vincent Poor</name>
    </author>
    <author>
      <name>Sanjeev Kulkarni</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TIT.2009.2027573</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TIT.2009.2027573" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">LaTeX2, 15 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE T. Inform. Theory 55, 4786 (2009)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0710.3183v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0710.3183v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0804.1026v1</id>
    <updated>2008-04-07T13:46:27Z</updated>
    <published>2008-04-07T13:46:27Z</published>
    <title>Testing for Homogeneity with Kernel Fisher Discriminant Analysis</title>
    <summary>  We propose to investigate test statistics for testing homogeneity in
reproducing kernel Hilbert spaces. Asymptotic null distributions under null
hypothesis are derived, and consistency against fixed and local alternatives is
assessed. Finally, experimental evidence of the performance of the proposed
approach on both artificial data and a speaker verification task is provided.
</summary>
    <author>
      <name>Zaid Harchaoui</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LTCI</arxiv:affiliation>
    </author>
    <author>
      <name>Francis Bach</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rocquencourt</arxiv:affiliation>
    </author>
    <author>
      <name>Eric Moulines</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LTCI</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/0804.1026v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0804.1026v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0810.5117v1</id>
    <updated>2008-10-28T19:42:15Z</updated>
    <published>2008-10-28T19:42:15Z</published>
    <title>A non-negative expansion for small Jensen-Shannon Divergences</title>
    <summary>  In this report, we derive a non-negative series expansion for the
Jensen-Shannon divergence (JSD) between two probability distributions. This
series expansion is shown to be useful for numerical calculations of the JSD,
when the probability distributions are nearly equal, and for which,
consequently, small numerical errors dominate evaluation.
</summary>
    <author>
      <name>Anil Raj</name>
    </author>
    <author>
      <name>Chris H. Wiggins</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 page technical report, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0810.5117v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0810.5117v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0812.1615v1</id>
    <updated>2008-12-09T04:33:38Z</updated>
    <published>2008-12-09T04:33:38Z</published>
    <title>Missing Data using Decision Forest and Computational Intelligence</title>
    <summary>  Autoencoder neural network is implemented to estimate the missing data.
Genetic algorithm is implemented for network optimization and estimating the
missing data. Missing data is treated as Missing At Random mechanism by
implementing maximum likelihood algorithm. The network performance is
determined by calculating the mean square error of the network prediction. The
network is further optimized by implementing Decision Forest. The impact of
missing data is then investigated and decision forrests are found to improve
the results.
</summary>
    <author>
      <name>D. Moon</name>
    </author>
    <author>
      <name>T. Marwala</name>
    </author>
    <link href="http://arxiv.org/abs/0812.1615v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0812.1615v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0901.2735v1</id>
    <updated>2009-01-18T20:54:05Z</updated>
    <published>2009-01-18T20:54:05Z</published>
    <title>State Space Realization Theorems For Data Mining</title>
    <summary>  In this paper, we consider formal series associated with events, profiles
derived from events, and statistical models that make predictions about events.
We prove theorems about realizations for these formal series using the language
and tools of Hopf algebras.
</summary>
    <author>
      <name>Robert L Grossman</name>
    </author>
    <author>
      <name>Richard G Larson</name>
    </author>
    <link href="http://arxiv.org/abs/0901.2735v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0901.2735v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.RA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62A01; 16W30" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0902.4389v1</id>
    <updated>2009-02-25T15:14:31Z</updated>
    <published>2009-02-25T15:14:31Z</published>
    <title>Dimension reduction in representation of the data</title>
    <summary>  Suppose the data consist of a set $S$ of points $x_j$, $1\leq j \leq J$,
distributed in a bounded domain $D\subset R^N$, where $N$ is a large number. An
algorithm is given for finding the sets $L_k$ of dimension $k\ll N$,
$k=1,2,...K$, in a neighborhood of which maximal amount of points $x_j\in S$
lie. The algorithm is different from PCA (principal component analysis)
</summary>
    <author>
      <name>A. G. Ramm</name>
    </author>
    <link href="http://arxiv.org/abs/0902.4389v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0902.4389v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62H35" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0905.1540v1</id>
    <updated>2009-05-11T04:37:02Z</updated>
    <published>2009-05-11T04:37:02Z</published>
    <title>Supplementary material for Markov equivalence for ancestral graphs</title>
    <summary>  We prove that the criterion for Markov equivalence provided by Zhao et al.
(2005) may involve a set of features of a graph that is exponential in the
number of vertices.
</summary>
    <author>
      <name>R. A. Ali</name>
    </author>
    <author>
      <name>T. Richardson</name>
    </author>
    <author>
      <name>P. Spirtes</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2 pages, 1 figure, supplement to paper to appear in the Annals of
  Statistics</arxiv:comment>
    <link href="http://arxiv.org/abs/0905.1540v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0905.1540v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0907.0781v1</id>
    <updated>2009-07-04T18:24:06Z</updated>
    <published>2009-07-04T18:24:06Z</published>
    <title>Bayesian Agglomerative Clustering with Coalescents</title>
    <summary>  We introduce a new Bayesian model for hierarchical clustering based on a
prior over trees called Kingman's coalescent. We develop novel greedy and
sequential Monte Carlo inferences which operate in a bottom-up agglomerative
fashion. We show experimentally the superiority of our algorithms over others,
and demonstrate our approach in document clustering and phylolinguistics.
</summary>
    <author>
      <name>Yee Whye Teh</name>
    </author>
    <author>
      <name>Hal Daumé III</name>
    </author>
    <author>
      <name>Daniel Roy</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">NIPS 2008</arxiv:comment>
    <link href="http://arxiv.org/abs/0907.0781v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0907.0781v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0908.3321v1</id>
    <updated>2009-08-23T17:45:07Z</updated>
    <published>2009-08-23T17:45:07Z</published>
    <title>Relative Expected Improvement in Kriging Based Optimization</title>
    <summary>  We propose an extension of the concept of Expected Improvement criterion
commonly used in Kriging based optimization. We extend it for more complex
Kriging models, e.g. models using derivatives. The target field of application
are CFD problems, where objective function are extremely expensive to evaluate,
but the theory can be also used in other fields.
</summary>
    <author>
      <name>Łukasz Łaniewski-Wołłk</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">EUROGEN2009 Kwakow conference</arxiv:comment>
    <link href="http://arxiv.org/abs/0908.3321v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0908.3321v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0909.1418v1</id>
    <updated>2009-09-08T08:03:09Z</updated>
    <published>2009-09-08T08:03:09Z</published>
    <title>On Ranking Senators By Their Votes</title>
    <summary>  The problem of ranking a set of objects given some measure of similarity is
one of the most basic in machine learning. Recently Agarwal proposed a method
based on techniques in semi-supervised learning utilizing the graph Laplacian.
In this work we consider a novel application of this technique to ranking
binary choice data and apply it specifically to ranking US Senators by their
ideology.
</summary>
    <author>
      <name>Mugizi Rwebangira</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/0909.1418v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0909.1418v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1001.2615v1</id>
    <updated>2010-01-15T05:53:23Z</updated>
    <published>2010-01-15T05:53:23Z</published>
    <title>Sparsity-accuracy trade-off in MKL</title>
    <summary>  We empirically investigate the best trade-off between sparse and
uniformly-weighted multiple kernel learning (MKL) using the elastic-net
regularization on real and simulated datasets. We find that the best trade-off
parameter depends not only on the sparsity of the true kernel-weight spectrum
but also on the linear dependence among kernels and the number of samples.
</summary>
    <author>
      <name>Ryota Tomioka</name>
    </author>
    <author>
      <name>Taiji Suzuki</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1001.2615v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1001.2615v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1004.0089v2</id>
    <updated>2010-04-02T03:24:12Z</updated>
    <published>2010-04-01T09:16:53Z</published>
    <title>On the Schoenberg Transformations in Data Analysis: Theory and
  Illustrations</title>
    <summary>  The class of Schoenberg transformations, embedding Euclidean distances into
higher dimensional Euclidean spaces, is presented, and derived from theorems on
positive definite and conditionally negative definite matrices. Original
results on the arc lengths, angles and curvature of the transformations are
proposed, and visualized on artificial data sets by classical multidimensional
scaling. A simple distance-based discriminant algorithm illustrates the theory,
intimately connected to the Gaussian kernels of Machine Learning.
</summary>
    <author>
      <name>François Bavaud</name>
    </author>
    <link href="http://arxiv.org/abs/1004.0089v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1004.0089v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1004.0314v2</id>
    <updated>2013-03-07T16:36:59Z</updated>
    <published>2010-04-02T10:41:38Z</published>
    <title>Visualization of Manifold-Valued Elements by Multidimensional Scaling</title>
    <summary>  The present contribution suggests the use of a multidimensional scaling (MDS)
algorithm as a visualization tool for manifold-valued elements. A visualization
tool of this kind is useful in signal processing and machine learning whenever
learning/adaptation algorithms insist on high-dimensional parameter manifolds.
</summary>
    <author>
      <name>Simone Fiori</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The paper has been published in 2011, hence I think it is time to
  withdraw its draft version from the arXiv</arxiv:comment>
    <link href="http://arxiv.org/abs/1004.0314v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1004.0314v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1008.5211v1</id>
    <updated>2010-08-31T03:49:26Z</updated>
    <published>2010-08-31T03:49:26Z</published>
    <title>Union Support Recovery in Multi-task Learning</title>
    <summary>  We sharply characterize the performance of different penalization schemes for
the problem of selecting the relevant variables in the multi-task setting.
Previous work focuses on the regression problem where conditions on the design
matrix complicate the analysis. A clearer and simpler picture emerges by
studying the Normal means model. This model, often used in the field of
statistics, is a simplified model that provides a laboratory for studying
complex procedures.
</summary>
    <author>
      <name>Mladen Kolar</name>
    </author>
    <author>
      <name>John Lafferty</name>
    </author>
    <author>
      <name>Larry Wasserman</name>
    </author>
    <link href="http://arxiv.org/abs/1008.5211v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1008.5211v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1010.4236v1</id>
    <updated>2010-10-20T16:03:40Z</updated>
    <published>2010-10-20T16:03:40Z</published>
    <title>Maximum Likelihood Joint Tracking and Association in a Strong Clutter
  without Combinatorial Complexity</title>
    <summary>  We have developed an efficient algorithm for the maximum likelihood joint
tracking and association problem in a strong clutter for GMTI data. By using an
iterative procedure of the dynamic logic process "from vague-to-crisp," the new
tracker overcomes combinatorial complexity of tracking in highly-cluttered
scenarios and results in a significant improvement in signal-to-clutter ratio.
</summary>
    <author>
      <name>Leonid I. Perlovsky</name>
    </author>
    <author>
      <name>Ross W. Deming</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1010.4236v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1010.4236v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1012.3584v1</id>
    <updated>2010-12-16T12:47:34Z</updated>
    <published>2010-12-16T12:47:34Z</published>
    <title>Fast Convergent Algorithms for Expectation Propagation Approximate
  Bayesian Inference</title>
    <summary>  We propose a novel algorithm to solve the expectation propagation relaxation
of Bayesian inference for continuous-variable graphical models. In contrast to
most previous algorithms, our method is provably convergent. By marrying
convergent EP ideas from (Opper&amp;Winther 05) with covariance decoupling
techniques (Wipf&amp;Nagarajan 08, Nickisch&amp;Seeger 09), it runs at least an order
of magnitude faster than the most commonly used EP solver.
</summary>
    <author>
      <name>Matthias W. Seeger</name>
    </author>
    <author>
      <name>Hannes Nickisch</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 3 figures, submitted for conference publication</arxiv:comment>
    <link href="http://arxiv.org/abs/1012.3584v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1012.3584v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.0942v2</id>
    <updated>2011-06-03T19:08:19Z</updated>
    <published>2011-03-04T16:38:55Z</published>
    <title>Generalization error bounds for stationary autoregressive models</title>
    <summary>  We derive generalization error bounds for stationary univariate
autoregressive (AR) models. We show that imposing stationarity is enough to
control the Gaussian complexity without further regularization. This lets us
use structural risk minimization for model selection. We demonstrate our
methods by predicting interest rate movements.
</summary>
    <author>
      <name>Daniel J. McDonald</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Carnegie Mellon University</arxiv:affiliation>
    </author>
    <author>
      <name>Cosma Rohilla Shalizi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Carnegie Mellon University</arxiv:affiliation>
    </author>
    <author>
      <name>Mark Schervish</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Carnegie Mellon University</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 3 figures. CMU Statistics Technical Report</arxiv:comment>
    <link href="http://arxiv.org/abs/1103.0942v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.0942v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.2670v1</id>
    <updated>2011-03-14T14:03:30Z</updated>
    <published>2011-03-14T14:03:30Z</published>
    <title>Constrained Mixture Models for Asset Returns Modelling</title>
    <summary>  The estimation of asset return distributions is crucial for determining
optimal trading strategies. In this paper we describe the constrained mixture
model, based on a mixture of Gamma and Gaussian distributions, to provide an
accurate description of price trends as being clearly positive, negative or
ranging while accounting for heavy tails and high kurtosis. The model is
estimated in the Expectation Maximisation framework and model order estimation
also respects the model's constraints.
</summary>
    <author>
      <name>Iead Rezek</name>
    </author>
    <link href="http://arxiv.org/abs/1103.2670v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.2670v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.TR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1106.2474v1</id>
    <updated>2011-06-13T15:34:38Z</updated>
    <published>2011-06-13T15:34:38Z</published>
    <title>Source Separation and Clustering of Phase-Locked Subspaces: Derivations
  and Proofs</title>
    <summary>  Due to space limitations, our submission "Source Separation and Clustering of
Phase-Locked Subspaces", accepted for publication on the IEEE Transactions on
Neural Networks in 2011, presented some results without proof. Those proofs are
provided in this paper.
</summary>
    <author>
      <name>Miguel Almeida</name>
    </author>
    <author>
      <name>Jan-Hendrik Schleimer</name>
    </author>
    <author>
      <name>José Bioucas-Dias</name>
    </author>
    <author>
      <name>Ricardo Vigário</name>
    </author>
    <link href="http://arxiv.org/abs/1106.2474v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1106.2474v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.5357v1</id>
    <updated>2012-04-24T12:49:47Z</updated>
    <published>2012-04-24T12:49:47Z</published>
    <title>Learning AMP Chain Graphs under Faithfulness</title>
    <summary>  This paper deals with chain graphs under the alternative
Andersson-Madigan-Perlman (AMP) interpretation. In particular, we present a
constraint based algorithm for learning an AMP chain graph a given probability
distribution is faithful to. We also show that the extension of Meek's
conjecture to AMP chain graphs does not hold, which compromises the development
of efficient and correct score+search learning algorithms under assumptions
weaker than faithfulness.
</summary>
    <author>
      <name>Jose M. Peña</name>
    </author>
    <link href="http://arxiv.org/abs/1204.5357v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.5357v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.6509v1</id>
    <updated>2012-04-29T19:31:15Z</updated>
    <published>2012-04-29T19:31:15Z</published>
    <title>Dissimilarity Clustering by Hierarchical Multi-Level Refinement</title>
    <summary>  We introduce in this paper a new way of optimizing the natural extension of
the quantization error using in k-means clustering to dissimilarity data. The
proposed method is based on hierarchical clustering analysis combined with
multi-level heuristic refinement. The method is computationally efficient and
achieves better quantization errors than the
</summary>
    <author>
      <name>Brieuc Conan-Guez</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LITA</arxiv:affiliation>
    </author>
    <author>
      <name>Fabrice Rossi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">SAMM</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20-th European Symposium on Artificial Neural Networks, Computational
  Intelligence and Machine Learning (ESANN 2012), Bruges : Belgium (2012)</arxiv:comment>
    <link href="http://arxiv.org/abs/1204.6509v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.6509v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.6361v1</id>
    <updated>2012-06-27T18:37:50Z</updated>
    <published>2012-06-27T18:37:50Z</published>
    <title>Learning Markov Network Structure using Brownian Distance Covariance</title>
    <summary>  In this paper, we present a simple non-parametric method for learning the
structure of undirected graphs from data that drawn from an underlying unknown
distribution. We propose to use Brownian distance covariance to estimate the
conditional independences between the random variables and encodes pairwise
Markov graph. This framework can be applied in high-dimensional setting, where
the number of parameters much be larger than the sample size.
</summary>
    <author>
      <name>Ehsan Khoshgnauz</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.6361v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.6361v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.0016v2</id>
    <updated>2013-03-19T23:28:49Z</updated>
    <published>2012-08-31T20:58:15Z</published>
    <title>On the convergence of maximum variance unfolding</title>
    <summary>  Maximum Variance Unfolding is one of the main methods for (nonlinear)
dimensionality reduction. We study its large sample limit, providing specific
rates of convergence under standard assumptions. We find that it is consistent
when the underlying submanifold is isometric to a convex subset, and we provide
some simple examples where it fails to be consistent.
</summary>
    <author>
      <name>Ery Arias-Castro</name>
    </author>
    <author>
      <name>Bruno Pelletier</name>
    </author>
    <link href="http://arxiv.org/abs/1209.0016v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.0016v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.1996v1</id>
    <updated>2012-09-10T13:57:37Z</updated>
    <published>2012-09-10T13:57:37Z</published>
    <title>A Bayesian Boosting Model</title>
    <summary>  We offer a novel view of AdaBoost in a statistical setting. We propose a
Bayesian model for binary classification in which label noise is modeled
hierarchically. Using variational inference to optimize a dynamic evidence
lower bound, we derive a new boosting-like algorithm called VIBoost. We show
its close connections to AdaBoost and give experimental results from four
datasets.
</summary>
    <author>
      <name>Alexander Lorbert</name>
    </author>
    <author>
      <name>David M. Blei</name>
    </author>
    <author>
      <name>Robert E. Schapire</name>
    </author>
    <author>
      <name>Peter J. Ramadge</name>
    </author>
    <link href="http://arxiv.org/abs/1209.1996v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.1996v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.2717v1</id>
    <updated>2012-11-12T18:08:34Z</updated>
    <published>2012-11-12T18:08:34Z</published>
    <title>Proximal Stochastic Dual Coordinate Ascent</title>
    <summary>  We introduce a proximal version of dual coordinate ascent method. We
demonstrate how the derived algorithmic framework can be used for numerous
regularized loss minimization problems, including $\ell_1$ regularization and
structured output SVM. The convergence rates we obtain match, and sometimes
improve, state-of-the-art results.
</summary>
    <author>
      <name>Shai Shalev-Shwartz</name>
    </author>
    <author>
      <name>Tong Zhang</name>
    </author>
    <link href="http://arxiv.org/abs/1211.2717v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.2717v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.4507v2</id>
    <updated>2012-12-20T18:49:18Z</updated>
    <published>2012-12-18T21:06:10Z</published>
    <title>Variational Optimization</title>
    <summary>  We discuss a general technique that can be used to form a differentiable
bound on the optima of non-differentiable or discrete objective functions. We
form a unified description of these methods and consider under which
circumstances the bound is concave. In particular we consider two concrete
applications of the method, namely sparse learning and support vector
classification.
</summary>
    <author>
      <name>Joe Staines</name>
    </author>
    <author>
      <name>David Barber</name>
    </author>
    <link href="http://arxiv.org/abs/1212.4507v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.4507v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65K10" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.1299v1</id>
    <updated>2013-01-07T18:48:02Z</updated>
    <published>2013-01-07T18:48:02Z</published>
    <title>Automated Variational Inference in Probabilistic Programming</title>
    <summary>  We present a new algorithm for approximate inference in probabilistic
programs, based on a stochastic gradient for variational programs. This method
is efficient without restrictions on the probabilistic program; it is
particularly practical for distributions which are not analytically tractable,
including highly structured distributions that arise in probabilistic programs.
We show how to automatically derive mean-field probabilistic programs and
optimize them, and demonstrate that our perspective improves inference
efficiency over other algorithms.
</summary>
    <author>
      <name>David Wingate</name>
    </author>
    <author>
      <name>Theophane Weber</name>
    </author>
    <link href="http://arxiv.org/abs/1301.1299v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.1299v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.2015v1</id>
    <updated>2013-01-10T02:02:01Z</updated>
    <published>2013-01-10T02:02:01Z</published>
    <title>Heteroscedastic Relevance Vector Machine</title>
    <summary>  In this work we propose a heteroscedastic generalization to RVM, a fast
Bayesian framework for regression, based on some recent similar works. We use
variational approximation and expectation propagation to tackle the problem.
The work is still under progress and we are examining the results and comparing
with the previous works.
</summary>
    <author>
      <name>Daniel Khashabi</name>
    </author>
    <author>
      <name>Mojtaba Ziyadi</name>
    </author>
    <author>
      <name>Feng Liang</name>
    </author>
    <link href="http://arxiv.org/abs/1301.2015v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.2015v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.6944v1</id>
    <updated>2013-01-29T15:09:56Z</updated>
    <published>2013-01-29T15:09:56Z</published>
    <title>On the Consistency of the Bootstrap Approach for Support Vector Machines
  and Related Kernel Based Methods</title>
    <summary>  It is shown that bootstrap approximations of support vector machines (SVMs)
based on a general convex and smooth loss function and on a general kernel are
consistent. This result is useful to approximate the unknown finite sample
distribution of SVMs by the bootstrap approach.
</summary>
    <author>
      <name>Andreas Christmann</name>
    </author>
    <author>
      <name>Robert Hable</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1301.6944v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.6944v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62G08, 62G09, 62G20, 62G86" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1302.4853v2</id>
    <updated>2013-05-08T18:59:28Z</updated>
    <published>2013-02-20T09:48:49Z</published>
    <title>Consistency of Online Random Forests</title>
    <summary>  As a testament to their success, the theory of random forests has long been
outpaced by their application in practice. In this paper, we take a step
towards narrowing this gap by providing a consistency result for online random
forests.
</summary>
    <author>
      <name>Misha Denil</name>
    </author>
    <author>
      <name>David Matheson</name>
    </author>
    <author>
      <name>Nando de Freitas</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in Proceedings of the 30th International Conference on
  Machine Learning, 2013</arxiv:comment>
    <link href="http://arxiv.org/abs/1302.4853v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1302.4853v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1303.0632v2</id>
    <updated>2013-08-10T01:46:02Z</updated>
    <published>2013-03-04T07:59:11Z</published>
    <title>Supplement to "Reversible MCMC on Markov equivalence classes of sparse
  directed acyclic graphs"</title>
    <summary>  This supplementary material includes three parts: some preliminary results,
four examples, an experiment, three new algorithms, and all proofs of the
results in the paper "Reversible MCMC on Markov equivalence classes of sparse
directed acyclic graphs".
</summary>
    <author>
      <name>Yangbo He</name>
    </author>
    <author>
      <name>Jinzhu Jia</name>
    </author>
    <author>
      <name>Bin Yu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 papges</arxiv:comment>
    <link href="http://arxiv.org/abs/1303.0632v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1303.0632v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1303.5976v1</id>
    <updated>2013-03-24T18:32:38Z</updated>
    <published>2013-03-24T18:32:38Z</published>
    <title>On Learnability, Complexity and Stability</title>
    <summary>  We consider the fundamental question of learnability of a hypotheses class in
the supervised learning setting and in the general learning setting introduced
by Vladimir Vapnik. We survey classic results characterizing learnability in
term of suitable notions of complexity, as well as more recent results that
establish the connection between learnability and stability of a learning
algorithm.
</summary>
    <author>
      <name>Silvia Villa</name>
    </author>
    <author>
      <name>Lorenzo Rosasco</name>
    </author>
    <author>
      <name>Tomaso Poggio</name>
    </author>
    <link href="http://arxiv.org/abs/1303.5976v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1303.5976v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1306.3530v2</id>
    <updated>2013-06-18T11:50:23Z</updated>
    <published>2013-06-14T23:41:58Z</published>
    <title>Generalized Beta Divergence</title>
    <summary>  This paper generalizes beta divergence beyond its classical form associated
with power variance functions of Tweedie models. Generalized form is
represented by a compact definite integral as a function of variance function
of the exponential dispersion model. This compact integral form simplifies
derivations of many properties such as scaling, translation and expectation of
the beta divergence. Further, we show that beta divergence and (half of) the
statistical deviance are equivalent measures.
</summary>
    <author>
      <name>Y. Kenan Yilmaz</name>
    </author>
    <link href="http://arxiv.org/abs/1306.3530v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1306.3530v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1306.5860v1</id>
    <updated>2013-06-25T07:02:20Z</updated>
    <published>2013-06-25T07:02:20Z</published>
    <title>Supersparse Linear Integer Models for Predictive Scoring Systems</title>
    <summary>  We introduce Supersparse Linear Integer Models (SLIM) as a tool to create
scoring systems for binary classification. We derive theoretical bounds on the
true risk of SLIM scoring systems, and present experimental results to show
that SLIM scoring systems are accurate, sparse, and interpretable
classification models.
</summary>
    <author>
      <name>Berk Ustun</name>
    </author>
    <author>
      <name>Stefano Traca</name>
    </author>
    <author>
      <name>Cynthia Rudin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Short version</arxiv:comment>
    <link href="http://arxiv.org/abs/1306.5860v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1306.5860v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1308.1196v1</id>
    <updated>2013-08-06T07:24:36Z</updated>
    <published>2013-08-06T07:24:36Z</published>
    <title>The Group Lasso for Design of Experiments</title>
    <summary>  We introduce an application of the group lasso to design of exper- iments. We
show that the problem of constructing an optimal design matrix can be
transformed into a problem of the group lasso. We also give a numerical example
that we can obtain several orthogonal arrays as the solutions of the group
lasso problems.
</summary>
    <author>
      <name>Kentaro Tanaka</name>
    </author>
    <author>
      <name>Masami Miyakawa</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 5 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1308.1196v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1308.1196v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62K05" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1309.2505v1</id>
    <updated>2013-09-10T13:38:16Z</updated>
    <published>2013-09-10T13:38:16Z</published>
    <title>Compressed Sensing for Block-Sparse Smooth Signals</title>
    <summary>  We present reconstruction algorithms for smooth signals with block sparsity
from their compressed measurements. We tackle the issue of varying group size
via group-sparse least absolute shrinkage selection operator (LASSO) as well as
via latent group LASSO regularizations. We achieve smoothness in the signal via
fusion. We develop low-complexity solvers for our proposed formulations through
the alternating direction method of multipliers.
</summary>
    <author>
      <name>Shahzad Gishkori</name>
    </author>
    <author>
      <name>Geert Leus</name>
    </author>
    <link href="http://arxiv.org/abs/1309.2505v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1309.2505v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.3697v1</id>
    <updated>2013-10-14T14:36:22Z</updated>
    <published>2013-10-14T14:36:22Z</published>
    <title>Variance Adjusted Actor Critic Algorithms</title>
    <summary>  We present an actor-critic framework for MDPs where the objective is the
variance-adjusted expected return. Our critic uses linear function
approximation, and we extend the concept of compatible features to the
variance-adjusted setting. We present an episodic actor-critic algorithm and
show that it converges almost surely to a locally optimal point of the
objective function.
</summary>
    <author>
      <name>Aviv Tamar</name>
    </author>
    <author>
      <name>Shie Mannor</name>
    </author>
    <link href="http://arxiv.org/abs/1310.3697v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.3697v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1312.1244v1</id>
    <updated>2013-12-04T17:03:30Z</updated>
    <published>2013-12-04T17:03:30Z</published>
    <title>Chebushev Greedy Algorithm in convex optimization</title>
    <summary>  Chebyshev Greedy Algorithm is a generalization of the well known Orthogonal
Matching Pursuit defined in a Hilbert space to the case of Banach spaces. We
apply this algorithm for constructing sparse approximate solutions (with
respect to a given dictionary) to convex optimization problems. Rate of
convergence results in a style of the Lebesgue-type inequalities are proved.
</summary>
    <author>
      <name>Vladimir Temlyakov</name>
    </author>
    <link href="http://arxiv.org/abs/1312.1244v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1312.1244v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1401.6276v1</id>
    <updated>2014-01-24T07:50:28Z</updated>
    <published>2014-01-24T07:50:28Z</published>
    <title>The EM algorithm and the Laplace Approximation</title>
    <summary>  The Laplace approximation calls for the computation of second derivatives at
the likelihood maximum. When the maximum is found by the EM-algorithm, there is
a convenient way to compute these derivatives. The likelihood gradient can be
obtained from the EM-auxiliary, while the Hessian can be obtained from this
gradient with the Pearlmutter trick.
</summary>
    <author>
      <name>Niko Brümmer</name>
    </author>
    <link href="http://arxiv.org/abs/1401.6276v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1401.6276v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.5903v1</id>
    <updated>2014-04-23T17:25:02Z</updated>
    <published>2014-04-23T17:25:02Z</published>
    <title>Most Correlated Arms Identification</title>
    <summary>  We study the problem of finding the most mutually correlated arms among many
arms. We show that adaptive arms sampling strategies can have significant
advantages over the non-adaptive uniform sampling strategy. Our proposed
algorithms rely on a novel correlation estimator. The use of this accurate
estimator allows us to get improved results for a wide range of problem
instances.
</summary>
    <author>
      <name>Che-Yu Liu</name>
    </author>
    <author>
      <name>Sébastien Bubeck</name>
    </author>
    <link href="http://arxiv.org/abs/1404.5903v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.5903v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.1580v1</id>
    <updated>2014-05-07T12:02:40Z</updated>
    <published>2014-05-07T12:02:40Z</published>
    <title>PAC-Bayes Mini-tutorial: A Continuous Union Bound</title>
    <summary>  When I first encountered PAC-Bayesian concentration inequalities they seemed
to me to be rather disconnected from good old-fashioned results like
Hoeffding's and Bernstein's inequalities. But, at least for one flavour of the
PAC-Bayesian bounds, there is actually a very close relation, and the main
innovation is a continuous version of the union bound, along with some
ingenious applications. Here's the gist of what's going on, presented from a
machine learning perspective.
</summary>
    <author>
      <name>Tim van Erven</name>
    </author>
    <link href="http://arxiv.org/abs/1405.1580v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.1580v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1406.0118v1</id>
    <updated>2014-05-31T23:00:36Z</updated>
    <published>2014-05-31T23:00:36Z</published>
    <title>Improved graph Laplacian via geometric self-consistency</title>
    <summary>  We address the problem of setting the kernel bandwidth used by Manifold
Learning algorithms to construct the graph Laplacian. Exploiting the connection
between manifold geometry, represented by the Riemannian metric, and the
Laplace-Beltrami operator, we set the bandwidth by optimizing the Laplacian's
ability to preserve the geometry of the data. Experiments show that this
principled approach is effective and robust.
</summary>
    <author>
      <name>Dominique Perrault-Joncas</name>
    </author>
    <author>
      <name>Marina Meila</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1406.0118v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1406.0118v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1406.3070v1</id>
    <updated>2014-06-11T21:35:41Z</updated>
    <published>2014-06-11T21:35:41Z</published>
    <title>Distributed Parameter Estimation in Probabilistic Graphical Models</title>
    <summary>  This paper presents foundational theoretical results on distributed parameter
estimation for undirected probabilistic graphical models. It introduces a
general condition on composite likelihood decompositions of these models which
guarantees the global consistency of distributed estimators, provided the local
estimators are consistent.
</summary>
    <author>
      <name>Yariv Dror Mizrahi</name>
    </author>
    <author>
      <name>Misha Denil</name>
    </author>
    <author>
      <name>Nando de Freitas</name>
    </author>
    <link href="http://arxiv.org/abs/1406.3070v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1406.3070v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1408.3332v1</id>
    <updated>2014-08-14T16:29:36Z</updated>
    <published>2014-08-14T16:29:36Z</published>
    <title>Exact and empirical estimation of misclassification probability</title>
    <summary>  We discuss the problem of risk estimation in the classification problem, with
specific focus on finding distributions that maximize the confidence intervals
of risk estimation. We derived simple analytic approximations for the maximum
bias of empirical risk for histogram classifier. We carry out a detailed study
on using these analytic estimates for empirical estimation of risk.
</summary>
    <author>
      <name>Victor Nedelko</name>
    </author>
    <link href="http://arxiv.org/abs/1408.3332v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1408.3332v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1411.2005v1</id>
    <updated>2014-11-07T19:01:19Z</updated>
    <published>2014-11-07T19:01:19Z</published>
    <title>Scalable Variational Gaussian Process Classification</title>
    <summary>  Gaussian process classification is a popular method with a number of
appealing properties. We show how to scale the model within a variational
inducing point framework, outperforming the state of the art on benchmark
datasets. Importantly, the variational formulation can be exploited to allow
classification in problems with millions of data points, as we demonstrate in
experiments.
</summary>
    <author>
      <name>James Hensman</name>
    </author>
    <author>
      <name>Alex Matthews</name>
    </author>
    <author>
      <name>Zoubin Ghahramani</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 9 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1411.2005v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1411.2005v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1411.3409v1</id>
    <updated>2014-11-13T00:51:19Z</updated>
    <published>2014-11-13T00:51:19Z</published>
    <title>A Randomized Algorithm for CCA</title>
    <summary>  We present RandomizedCCA, a randomized algorithm for computing canonical
analysis, suitable for large datasets stored either out of core or on a
distributed file system. Accurate results can be obtained in as few as two data
passes, which is relevant for distributed processing frameworks in which
iteration is expensive (e.g., Hadoop). The strategy also provides an excellent
initializer for standard iterative solutions.
</summary>
    <author>
      <name>Paul Mineiro</name>
    </author>
    <author>
      <name>Nikos Karampatziakis</name>
    </author>
    <link href="http://arxiv.org/abs/1411.3409v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1411.3409v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1411.3436v2</id>
    <updated>2017-04-08T06:06:38Z</updated>
    <published>2014-11-13T03:34:32Z</published>
    <title>SelfieBoost: A Boosting Algorithm for Deep Learning</title>
    <summary>  We describe and analyze a new boosting algorithm for deep learning called
SelfieBoost. Unlike other boosting algorithms, like AdaBoost, which construct
ensembles of classifiers, SelfieBoost boosts the accuracy of a single network.
We prove a $\log(1/\epsilon)$ convergence rate for SelfieBoost under some "SGD
success" assumption which seems to hold in practice.
</summary>
    <author>
      <name>Shai Shalev-Shwartz</name>
    </author>
    <link href="http://arxiv.org/abs/1411.3436v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1411.3436v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.3297v1</id>
    <updated>2014-12-10T13:22:38Z</updated>
    <published>2014-12-10T13:22:38Z</published>
    <title>Convergence and rate of convergence of some greedy algorithms in convex
  optimization</title>
    <summary>  The paper gives a systematic study of the approximate versions of three
greedy-type algorithms that are widely used in convex optimization. By
approximate version we mean the one where some of evaluations are made with an
error. Importance of such versions of greedy-type algorithms in convex
optimization and in approximation theory was emphasized in previous literature.
</summary>
    <author>
      <name>Vladimir Temlyakov</name>
    </author>
    <link href="http://arxiv.org/abs/1412.3297v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.3297v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1501.00052v1</id>
    <updated>2014-12-31T00:23:35Z</updated>
    <published>2014-12-31T00:23:35Z</published>
    <title>Detailed Derivations of Small-Variance Asymptotics for some Hierarchical
  Bayesian Nonparametric Models</title>
    <summary>  In this note we provide detailed derivations of two versions of
small-variance asymptotics for hierarchical Dirichlet process (HDP) mixture
models and the HDP hidden Markov model (HDP-HMM, a.k.a. the infinite HMM). We
include derivations for the probabilities of certain CRP and CRF partitions,
which are of more general interest.
</summary>
    <author>
      <name>Jonathan H. Huggins</name>
    </author>
    <author>
      <name>Ardavan Saeedi</name>
    </author>
    <author>
      <name>Matthew J. Johnson</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1501.00052v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1501.00052v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.00052v1</id>
    <updated>2015-03-31T21:48:56Z</updated>
    <published>2015-03-31T21:48:56Z</published>
    <title>Improved Error Bounds Based on Worst Likely Assignments</title>
    <summary>  Error bounds based on worst likely assignments use permutation tests to
validate classifiers. Worst likely assignments can produce effective bounds
even for data sets with 100 or fewer training examples. This paper introduces a
statistic for use in the permutation tests of worst likely assignments that
improves error bounds, especially for accurate classifiers, which are typically
the classifiers of interest.
</summary>
    <author>
      <name>Eric Bax</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">IJCNN 2015</arxiv:comment>
    <link href="http://arxiv.org/abs/1504.00052v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.00052v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.02191v1</id>
    <updated>2015-04-09T04:54:29Z</updated>
    <published>2015-04-09T04:54:29Z</published>
    <title>`local' vs. `global' parameters -- breaking the gaussian complexity
  barrier</title>
    <summary>  We show that if $F$ is a convex class of functions that is $L$-subgaussian,
the error rate of learning problems generated by independent noise is
equivalent to a fixed point determined by `local' covering estimates of the
class, rather than by the gaussian averages. To that end, we establish new
sharp upper and lower estimates on the error rate for such problems.
</summary>
    <author>
      <name>Shahar Mendelson</name>
    </author>
    <link href="http://arxiv.org/abs/1504.02191v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.02191v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.06614v1</id>
    <updated>2015-05-25T13:02:32Z</updated>
    <published>2015-05-25T13:02:32Z</published>
    <title>Electre Tri-Machine Learning Approach to the Record Linkage Problem</title>
    <summary>  In this short paper, the Electre Tri-Machine Learning Method, generally used
to solve ordinal classification problems, is proposed for solving the Record
Linkage problem. Preliminary experimental results show that, using the Electre
Tri method, high accuracy can be achieved and more than 99% of the matches and
nonmatches were correctly identified by the procedure.
</summary>
    <author>
      <name>Renato De Leone</name>
    </author>
    <author>
      <name>Valentina Minnetti</name>
    </author>
    <link href="http://arxiv.org/abs/1505.06614v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.06614v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.07008v1</id>
    <updated>2015-05-26T15:26:43Z</updated>
    <published>2015-05-26T15:26:43Z</published>
    <title>An Overview of the Asymptotic Performance of the Family of the FastICA
  Algorithms</title>
    <summary>  This contribution summarizes the results on the asymptotic performance of
several variants of the FastICA algorithm. A number of new closed-form
expressions are presented.
</summary>
    <author>
      <name>Tianwen Wei</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in the 12th International Conference on Latent Variable
  Analysis and Source Separation (LVA/ICA 2015), Liberec, Czech Republic</arxiv:comment>
    <link href="http://arxiv.org/abs/1505.07008v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.07008v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.00543v1</id>
    <updated>2015-07-02T12:28:41Z</updated>
    <published>2015-07-02T12:28:41Z</published>
    <title>Classical vs. Bayesian methods for linear system identification: point
  estimators and confidence sets</title>
    <summary>  This paper compares classical parametric methods with recently developed
Bayesian methods for system identification. A Full Bayes solution is considered
together with one of the standard approximations based on the Empirical Bayes
paradigm. Results regarding point estimators for the impulse response as well
as for confidence regions are reported.
</summary>
    <author>
      <name>D. Romeres</name>
    </author>
    <author>
      <name>G. Prando</name>
    </author>
    <author>
      <name>G. Pillonetto</name>
    </author>
    <author>
      <name>A. Chiuso</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">number of pages = 8, number of figures = 4</arxiv:comment>
    <link href="http://arxiv.org/abs/1507.00543v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.00543v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.01059v2</id>
    <updated>2015-10-10T08:09:07Z</updated>
    <published>2015-07-04T02:03:02Z</published>
    <title>Remarks on kernel Bayes' rule</title>
    <summary>  Kernel Bayes' rule has been proposed as a nonparametric kernel-based method
to realize Bayesian inference in reproducing kernel Hilbert spaces. However, we
demonstrate both theoretically and experimentally that the prediction result by
kernel Bayes' rule is in some cases unnatural. We consider that this phenomenon
is in part due to the fact that the assumptions in kernel Bayes' rule do not
hold in general.
</summary>
    <author>
      <name>Hisashi Johno</name>
    </author>
    <author>
      <name>Kazunori Nakamoto</name>
    </author>
    <author>
      <name>Tatsuhiko Saigo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">22 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1507.01059v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.01059v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.05781v1</id>
    <updated>2015-07-21T10:51:49Z</updated>
    <published>2015-07-21T10:51:49Z</published>
    <title>Gradient Importance Sampling</title>
    <summary>  Adaptive Monte Carlo schemes developed over the last years usually seek to
ensure ergodicity of the sampling process in line with MCMC tradition. This
poses constraints on what is possible in terms of adaptation. In the general
case ergodicity can only be guaranteed if adaptation is diminished at a certain
rate. Importance Sampling approaches offer a way to circumvent this limitation
and design sampling algorithms that keep adapting. Here I present a gradient
informed variant of SMC (and its special case Population Monte Carlo) for
static problems.
</summary>
    <author>
      <name>Ingmar Schuster</name>
    </author>
    <link href="http://arxiv.org/abs/1507.05781v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.05781v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.07495v1</id>
    <updated>2015-07-27T17:37:27Z</updated>
    <published>2015-07-27T17:37:27Z</published>
    <title>Estimating an Activity Driven Hidden Markov Model</title>
    <summary>  We define a Hidden Markov Model (HMM) in which each hidden state has
time-dependent $\textit{activity levels}$ that drive transitions and emissions,
and show how to estimate its parameters. Our construction is motivated by the
problem of inferring human mobility on sub-daily time scales from, for example,
mobile phone records.
</summary>
    <author>
      <name>David A. Meyer</name>
    </author>
    <author>
      <name>Asif Shakeel</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1507.07495v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.07495v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1509.06449v1</id>
    <updated>2015-09-22T02:51:30Z</updated>
    <published>2015-09-22T02:51:30Z</published>
    <title>Efficient Neighborhood Selection for Gaussian Graphical Models</title>
    <summary>  This paper addresses the problem of neighborhood selection for Gaussian
graphical models. We present two heuristic algorithms: a forward-backward
greedy algorithm for general Gaussian graphical models based on mutual
information test, and a threshold-based algorithm for walk summable Gaussian
graphical models. Both algorithms are shown to be structurally consistent, and
efficient. Numerical results show that both algorithms work very well.
</summary>
    <author>
      <name>Yingxiang Yang</name>
    </author>
    <author>
      <name>Jalal Etesami</name>
    </author>
    <author>
      <name>Negar Kiyavash</name>
    </author>
    <link href="http://arxiv.org/abs/1509.06449v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1509.06449v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.00633v1</id>
    <updated>2015-10-02T16:15:30Z</updated>
    <published>2015-10-02T16:15:30Z</published>
    <title>Distributed Multitask Learning</title>
    <summary>  We consider the problem of distributed multi-task learning, where each
machine learns a separate, but related, task. Specifically, each machine learns
a linear predictor in high-dimensional space,where all tasks share the same
small support. We present a communication-efficient estimator based on the
debiased lasso and show that it is comparable with the optimal centralized
method.
</summary>
    <author>
      <name>Jialei Wang</name>
    </author>
    <author>
      <name>Mladen Kolar</name>
    </author>
    <author>
      <name>Nathan Srebro</name>
    </author>
    <link href="http://arxiv.org/abs/1510.00633v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.00633v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.01799v2</id>
    <updated>2015-10-09T23:59:02Z</updated>
    <published>2015-10-07T01:42:23Z</published>
    <title>Efficient Per-Example Gradient Computations</title>
    <summary>  This technical report describes an efficient technique for computing the norm
of the gradient of the loss function for a neural network with respect to its
parameters. This gradient norm can be computed efficiently for every example.
</summary>
    <author>
      <name>Ian Goodfellow</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This revision fixed some typos. Many thanks to Hugo Larochelle for
  reporting them!</arxiv:comment>
    <link href="http://arxiv.org/abs/1510.01799v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.01799v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.08110v1</id>
    <updated>2015-10-27T22:05:30Z</updated>
    <published>2015-10-27T22:05:30Z</published>
    <title>Spectral Convergence Rate of Graph Laplacian</title>
    <summary>  Laplacian Eigenvectors of the graph constructed from a data set are used in
many spectral manifold learning algorithms such as diffusion maps and spectral
clustering. Given a graph constructed from a random sample of a $d$-dimensional
compact submanifold $M$ in $\mathbb{R}^D$, we establish the spectral
convergence rate of the graph Laplacian. It implies the consistency of the
spectral clustering algorithm via a standard perturbation argument. A simple
numerical study indicates the necessity of a denoising step before applying
spectral algorithms.
</summary>
    <author>
      <name>Xu Wang</name>
    </author>
    <link href="http://arxiv.org/abs/1510.08110v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.08110v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.02176v1</id>
    <updated>2015-11-06T18:01:38Z</updated>
    <published>2015-11-06T18:01:38Z</published>
    <title>Optimal Non-Asymptotic Lower Bound on the Minimax Regret of Learning
  with Expert Advice</title>
    <summary>  We prove non-asymptotic lower bounds on the expectation of the maximum of $d$
independent Gaussian variables and the expectation of the maximum of $d$
independent symmetric random walks. Both lower bounds recover the optimal
leading constant in the limit. A simple application of the lower bound for
random walks is an (asymptotically optimal) non-asymptotic lower bound on the
minimax regret of online learning with expert advice.
</summary>
    <author>
      <name>Francesco Orabona</name>
    </author>
    <author>
      <name>David Pal</name>
    </author>
    <link href="http://arxiv.org/abs/1511.02176v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.02176v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.07318v1</id>
    <updated>2015-11-20T20:43:43Z</updated>
    <published>2015-11-20T20:43:43Z</published>
    <title>Bayesian SPLDA</title>
    <summary>  In this document we are going to derive the equations needed to implement a
Variational Bayes estimation of the parameters of the simplified probabilistic
linear discriminant analysis (SPLDA) model. This can be used to adapt SPLDA
from one database to another with few development data or to implement the
fully Bayesian recipe. Our approach is similar to Bishop's VB PPCA.
</summary>
    <author>
      <name>Jesús Villalba</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Technical Report, ViVoLab, I3A, University of Zaragoza, Spain</arxiv:comment>
    <link href="http://arxiv.org/abs/1511.07318v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.07318v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.07422v1</id>
    <updated>2015-11-20T21:38:25Z</updated>
    <published>2015-11-20T21:38:25Z</published>
    <title>Variational Bayes Factor Analysis for i-Vector Extraction</title>
    <summary>  In this document we are going to derive the equations needed to implement a
Variational Bayes i-vector extractor. This can be used to extract longer
i-vectors reducing the risk of overfittig or to adapt an i-vector extractor
from a database to another with scarce development data. This work is based on
Patrick Kenny's joint factor analysis and Christopher Bishop's variational
principal components.
</summary>
    <author>
      <name>Jesús Villalba</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Technical Report, ViVoLab, I3A, University of Zaragoza, Spain. arXiv
  admin note: text overlap with arXiv:1511.07318</arxiv:comment>
    <link href="http://arxiv.org/abs/1511.07422v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.07422v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1512.05698v1</id>
    <updated>2015-12-17T17:57:21Z</updated>
    <published>2015-12-17T17:57:21Z</published>
    <title>Oracle inequalities for ranking and U-processes with Lasso penalty</title>
    <summary>  We investigate properties of estimators obtained by minimization of
U-processes with the Lasso penalty in high-dimensional settings. Our attention
is focused on the ranking problem that is popular in machine learning. It is
related to guessing the ordering between objects on the basis of their observed
predictors. We prove the oracle inequality for the excess risk of the
considered estimator as well as the bound for the l1 distance between the
estimator and the oracle.
</summary>
    <author>
      <name>Wojciech Rejchel</name>
    </author>
    <link href="http://arxiv.org/abs/1512.05698v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1512.05698v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1512.07548v1</id>
    <updated>2015-12-23T17:12:06Z</updated>
    <published>2015-12-23T17:12:06Z</published>
    <title>k-Means Clustering Is Matrix Factorization</title>
    <summary>  We show that the objective function of conventional k-means clustering can be
expressed as the Frobenius norm of the difference of a data matrix and a low
rank approximation of that data matrix. In short, we show that k-means
clustering is a matrix factorization problem. These notes are meant as a
reference and intended to provide a guided tour towards a result that is often
mentioned but seldom made explicit in the literature.
</summary>
    <author>
      <name>Christian Bauckhage</name>
    </author>
    <link href="http://arxiv.org/abs/1512.07548v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1512.07548v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.04920v1</id>
    <updated>2016-01-19T13:40:47Z</updated>
    <published>2016-01-19T13:40:47Z</published>
    <title>Understanding Deep Convolutional Networks</title>
    <summary>  Deep convolutional networks provide state of the art classifications and
regressions results over many high-dimensional problems. We review their
architecture, which scatters data with a cascade of linear filter weights and
non-linearities. A mathematical framework is introduced to analyze their
properties. Computations of invariants involve multiscale contractions, the
linearization of hierarchical symmetries, and sparse separations. Applications
are discussed.
</summary>
    <author>
      <name>Stéphane Mallat</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1098/rsta.2015.0203</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1098/rsta.2015.0203" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages, 4 Figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1601.04920v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.04920v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1602.04915v2</id>
    <updated>2016-03-04T08:04:58Z</updated>
    <published>2016-02-16T05:43:31Z</published>
    <title>Gradient Descent Converges to Minimizers</title>
    <summary>  We show that gradient descent converges to a local minimizer, almost surely
with random initialization. This is proved by applying the Stable Manifold
Theorem from dynamical systems theory.
</summary>
    <author>
      <name>Jason D. Lee</name>
    </author>
    <author>
      <name>Max Simchowitz</name>
    </author>
    <author>
      <name>Michael I. Jordan</name>
    </author>
    <author>
      <name>Benjamin Recht</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to COLT 2016</arxiv:comment>
    <link href="http://arxiv.org/abs/1602.04915v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1602.04915v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.02443v2</id>
    <updated>2016-03-09T10:54:36Z</updated>
    <published>2016-03-08T09:46:30Z</published>
    <title>Note on the equivalence of hierarchical variational models and auxiliary
  deep generative models</title>
    <summary>  This note compares two recently published machine learning methods for
constructing flexible, but tractable families of variational hidden-variable
posteriors. The first method, called "hierarchical variational models" enriches
the inference model with an extra variable, while the other, called "auxiliary
deep generative models", enriches the generative model instead. We conclude
that the two methods are mathematically equivalent.
</summary>
    <author>
      <name>Niko Brümmer</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1603.02443v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.02443v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.04882v1</id>
    <updated>2016-03-15T20:46:46Z</updated>
    <published>2016-03-15T20:46:46Z</published>
    <title>Bias Correction for Regularized Regression and its Application in
  Learning with Streaming Data</title>
    <summary>  We propose an approach to reduce the bias of ridge regression and
regularization kernel network. When applied to a single data set the new
algorithms have comparable learning performance with the original ones. When
applied to incremental learning with block wise streaming data the new
algorithms are more efficient due to bias reduction. Both theoretical
characterizations and simulation studies are used to verify the effectiveness
of these new algorithms.
</summary>
    <author>
      <name>Qiang Wu</name>
    </author>
    <link href="http://arxiv.org/abs/1603.04882v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.04882v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.07285v1</id>
    <updated>2016-03-23T17:52:21Z</updated>
    <published>2016-03-23T17:52:21Z</published>
    <title>A guide to convolution arithmetic for deep learning</title>
    <summary>  We introduce a guide to help deep learning practitioners understand and
manipulate convolutional neural network architectures. The guide clarifies the
relationship between various properties (input shape, kernel shape, zero
padding, strides and output shape) of convolutional, pooling and transposed
convolutional layers, as well as the relationship between convolutional and
transposed convolutional layers. Relationships are derived for various cases,
and are illustrated in order to make them intuitive.
</summary>
    <author>
      <name>Vincent Dumoulin</name>
    </author>
    <author>
      <name>Francesco Visin</name>
    </author>
    <link href="http://arxiv.org/abs/1603.07285v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.07285v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.07850v1</id>
    <updated>2016-03-25T08:53:29Z</updated>
    <published>2016-03-25T08:53:29Z</published>
    <title>Markov substitute processes : a new model for linguistics and beyond</title>
    <summary>  We introduce Markov substitute processes, a new model at the crossroad of
statistics and formal grammars, and prove its main property : Markov substitute
processes with a given support form an exponential family.
</summary>
    <author>
      <name>Olivier Catoni</name>
    </author>
    <author>
      <name>Thomas Mainguy</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">22 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1603.07850v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.07850v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62M09, 60J10, 91F20, 68T50" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.03040v1</id>
    <updated>2016-05-10T14:55:46Z</updated>
    <published>2016-05-10T14:55:46Z</published>
    <title>A note on the statistical view of matrix completion</title>
    <summary>  A very simple interpretation of matrix completion problem is introduced based
on statistical models. Combined with the well-known results from missing data
analysis, such interpretation indicates that matrix completion is still a valid
and principled estimation procedure even without the missing completely at
random (MCAR) assumption, which almost all of the current theoretical studies
of matrix completion assume.
</summary>
    <author>
      <name>Tianxi Li</name>
    </author>
    <link href="http://arxiv.org/abs/1605.03040v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.03040v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.01487v1</id>
    <updated>2016-06-05T09:59:32Z</updated>
    <published>2016-06-05T09:59:32Z</published>
    <title>Bounds for Vector-Valued Function Estimation</title>
    <summary>  We present a framework to derive risk bounds for vector-valued learning with
a broad class of feature maps and loss functions. Multi-task learning and
one-vs-all multi-category learning are treated as examples. We discuss in
detail vector-valued functions with one hidden layer, and demonstrate that the
conditions under which shared representations are beneficial for multi- task
learning are equally applicable to multi-category learning.
</summary>
    <author>
      <name>Andreas Maurer</name>
    </author>
    <author>
      <name>Massimiliano Pontil</name>
    </author>
    <link href="http://arxiv.org/abs/1606.01487v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.01487v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.08455v1</id>
    <updated>2016-06-27T20:01:08Z</updated>
    <published>2016-06-27T20:01:08Z</published>
    <title>Anomaly detection in video with Bayesian nonparametrics</title>
    <summary>  A novel dynamic Bayesian nonparametric topic model for anomaly detection in
video is proposed in this paper. Batch and online Gibbs samplers are developed
for inference. The paper introduces a new abnormality measure for decision
making. The proposed method is evaluated on both synthetic and real data. The
comparison with a non-dynamic model shows the superiority of the proposed
dynamic one in terms of the classification performance for anomaly detection.
</summary>
    <author>
      <name>Olga Isupova</name>
    </author>
    <author>
      <name>Danil Kuzin</name>
    </author>
    <author>
      <name>Lyudmila Mihaylova</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1606.08455v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.08455v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.02531v2</id>
    <updated>2016-07-27T19:00:49Z</updated>
    <published>2016-07-08T21:07:54Z</published>
    <title>Proceedings of the 2016 ICML Workshop on Human Interpretability in
  Machine Learning (WHI 2016)</title>
    <summary>  This is the Proceedings of the 2016 ICML Workshop on Human Interpretability
in Machine Learning (WHI 2016), which was held in New York, NY, June 23, 2016.
  Invited speakers were Susan Athey, Rich Caruana, Jacob Feldman, Percy Liang,
and Hanna Wallach.
</summary>
    <author>
      <name>Been Kim</name>
    </author>
    <author>
      <name>Dmitry M. Malioutov</name>
    </author>
    <author>
      <name>Kush R. Varshney</name>
    </author>
    <link href="http://arxiv.org/abs/1607.02531v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.02531v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.05047v1</id>
    <updated>2016-07-18T12:43:40Z</updated>
    <published>2016-07-18T12:43:40Z</published>
    <title>A Batch, Off-Policy, Actor-Critic Algorithm for Optimizing the Average
  Reward</title>
    <summary>  We develop an off-policy actor-critic algorithm for learning an optimal
policy from a training set composed of data from multiple individuals. This
algorithm is developed with a view towards its use in mobile health.
</summary>
    <author>
      <name>S. A. Murphy</name>
    </author>
    <author>
      <name>Y. Deng</name>
    </author>
    <author>
      <name>E. B. Laber</name>
    </author>
    <author>
      <name>H. R. Maei</name>
    </author>
    <author>
      <name>R. S. Sutton</name>
    </author>
    <author>
      <name>K. Witkiewitz</name>
    </author>
    <link href="http://arxiv.org/abs/1607.05047v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.05047v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.07819v2</id>
    <updated>2016-08-08T14:41:26Z</updated>
    <published>2016-07-26T17:52:00Z</published>
    <title>Uniform Approximation by Neural Networks Activated by First and Second
  Order Ridge Splines</title>
    <summary>  We establish sup-norm error bounds for functions that are approximated by
linear combinations of first and second order ridge splines and show that these
bounds are near-optimal.
</summary>
    <author>
      <name>Jason M. Klusowski</name>
    </author>
    <author>
      <name>Andrew R. Barron</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to IEEE Transactions on Information Theory</arxiv:comment>
    <link href="http://arxiv.org/abs/1607.07819v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.07819v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62M45, 41A15" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.03769v1</id>
    <updated>2016-09-13T11:18:03Z</updated>
    <published>2016-09-13T11:18:03Z</published>
    <title>Analysis of Kelner and Levin graph sparsification algorithm for a
  streaming setting</title>
    <summary>  We derive a new proof to show that the incremental resparsification algorithm
proposed by Kelner and Levin (2013) produces a spectral sparsifier in high
probability. We rigorously take into account the dependencies across subsequent
resparsifications using martingale inequalities, fixing a flaw in the original
analysis.
</summary>
    <author>
      <name>Daniele Calandriello</name>
    </author>
    <author>
      <name>Alessandro Lazaric</name>
    </author>
    <author>
      <name>Michal Valko</name>
    </author>
    <link href="http://arxiv.org/abs/1609.03769v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.03769v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.05907v1</id>
    <updated>2016-12-18T12:41:08Z</updated>
    <published>2016-12-18T12:41:08Z</published>
    <title>Optimal tuning for divide-and-conquer kernel ridge regression with
  massive data</title>
    <summary>  We propose a first data-driven tuning procedure for divide-and-conquer kernel
ridge regression (Zhang et al., 2015). While the proposed criterion is
computationally scalable for massive data sets, it is also shown to be
asymptotically optimal under mild conditions. The effectiveness of our method
is illustrated by extensive simulations and an application to Million Song
Dataset.
</summary>
    <author>
      <name>Ganggang Xu</name>
    </author>
    <author>
      <name>Zuofeng Shang</name>
    </author>
    <author>
      <name>Guang Cheng</name>
    </author>
    <link href="http://arxiv.org/abs/1612.05907v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.05907v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.07993v1</id>
    <updated>2016-12-23T15:02:54Z</updated>
    <published>2016-12-23T15:02:54Z</published>
    <title>RSSL: Semi-supervised Learning in R</title>
    <summary>  In this paper, we introduce a package for semi-supervised learning research
in the R programming language called RSSL. We cover the purpose of the package,
the methods it includes and comment on their use and implementation. We then
show, using several code examples, how the package can be used to replicate
well-known results from the semi-supervised learning literature.
</summary>
    <author>
      <name>Jesse H. Krijthe</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented at RRPR 2016: 1st Workshop on Reproducible Research in
  Pattern Recognition</arxiv:comment>
    <link href="http://arxiv.org/abs/1612.07993v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.07993v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.08650v1</id>
    <updated>2016-12-27T14:57:22Z</updated>
    <published>2016-12-27T14:57:22Z</published>
    <title>Reproducible Pattern Recognition Research: The Case of Optimistic SSL</title>
    <summary>  In this paper, we discuss the approaches we took and trade-offs involved in
making a paper on a conceptual topic in pattern recognition research fully
reproducible. We discuss our definition of reproducibility, the tools used, how
the analysis was set up, show some examples of alternative analyses the code
enables and discuss our views on reproducibility.
</summary>
    <author>
      <name>Jesse H. Krijthe</name>
    </author>
    <author>
      <name>Marco Loog</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented at RRPR 2016: 1st Workshop on Reproducible Research in
  Pattern Recognition</arxiv:comment>
    <link href="http://arxiv.org/abs/1612.08650v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.08650v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.08875v1</id>
    <updated>2016-12-28T13:17:07Z</updated>
    <published>2016-12-28T13:17:07Z</published>
    <title>The Pessimistic Limits of Margin-based Losses in Semi-supervised
  Learning</title>
    <summary>  We show that for linear classifiers defined by convex margin-based surrogate
losses that are monotonically decreasing, it is impossible to construct any
semi-supervised approach that is able to guarantee an improvement over the
supervised classifier measured by this surrogate loss. For non-monotonically
decreasing loss functions, we demonstrate safe improvements are possible.
</summary>
    <author>
      <name>Jesse H. Krijthe</name>
    </author>
    <author>
      <name>Marco Loog</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 1 figure, 1 table</arxiv:comment>
    <link href="http://arxiv.org/abs/1612.08875v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.08875v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.04968v1</id>
    <updated>2017-01-18T06:49:03Z</updated>
    <published>2017-01-18T06:49:03Z</published>
    <title>Multilayer Perceptron Algebra</title>
    <summary>  Artificial Neural Networks(ANN) has been phenomenally successful on various
pattern recognition tasks. However, the design of neural networks rely heavily
on the experience and intuitions of individual developers. In this article, the
author introduces a mathematical structure called MLP algebra on the set of all
Multilayer Perceptron Neural Networks(MLP), which can serve as a guiding
principle to build MLPs accommodating to the particular data sets, and to build
complex MLPs from simpler ones.
</summary>
    <author>
      <name>Zhao Peng</name>
    </author>
    <link href="http://arxiv.org/abs/1701.04968v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.04968v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.07875v2</id>
    <updated>2017-03-09T23:12:26Z</updated>
    <published>2017-01-26T21:10:29Z</published>
    <title>Wasserstein GAN</title>
    <summary>  We introduce a new algorithm named WGAN, an alternative to traditional GAN
training. In this new model, we show that we can improve the stability of
learning, get rid of problems like mode collapse, and provide meaningful
learning curves useful for debugging and hyperparameter searches. Furthermore,
we show that the corresponding optimization problem is sound, and provide
extensive theoretical work highlighting the deep connections to other distances
between distributions.
</summary>
    <author>
      <name>Martin Arjovsky</name>
    </author>
    <author>
      <name>Soumith Chintala</name>
    </author>
    <author>
      <name>Léon Bottou</name>
    </author>
    <link href="http://arxiv.org/abs/1701.07875v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.07875v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1702.02982v1</id>
    <updated>2017-02-09T21:01:52Z</updated>
    <published>2017-02-09T21:01:52Z</published>
    <title>Fixing an error in Caponnetto and de Vito (2007)</title>
    <summary>  The seminal paper of Caponnetto and de Vito (2007) provides minimax-optimal
rates for kernel ridge regression in a very general setting. Its proof,
however, contains an error in its bound on the effective dimensionality. In
this note, we explain the mistake, provide a correct bound, and show that the
main theorem remains true.
</summary>
    <author>
      <name>Dougal J. Sutherland</name>
    </author>
    <link href="http://arxiv.org/abs/1702.02982v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1702.02982v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.01499v2</id>
    <updated>2017-03-15T14:55:52Z</updated>
    <published>2017-03-04T17:37:32Z</published>
    <title>A Machine-Learning Framework for Design for Manufacturability</title>
    <summary>  this is a duplicate submission(original is arXiv:1612.02141). Hence want to
withdraw it
</summary>
    <author>
      <name>Aditya Balu</name>
    </author>
    <author>
      <name>Sambit Ghadai</name>
    </author>
    <author>
      <name>Gavin Young</name>
    </author>
    <author>
      <name>Soumik Sarkar</name>
    </author>
    <author>
      <name>Adarsh Krishnamurthy</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">this is a duplicate submission. Hence want to withdraw it</arxiv:comment>
    <link href="http://arxiv.org/abs/1703.01499v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.01499v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.06749v2</id>
    <updated>2017-04-22T13:03:20Z</updated>
    <published>2017-03-20T14:02:11Z</published>
    <title>Efficient variational Bayesian neural network ensembles for outlier
  detection</title>
    <summary>  In this work we perform outlier detection using ensembles of neural networks
obtained by variational approximation of the posterior in a Bayesian neural
network setting. The variational parameters are obtained by sampling from the
true posterior by gradient descent. We show our outlier detection results are
comparable to those obtained using other efficient ensembling methods.
</summary>
    <author>
      <name>Nick Pawlowski</name>
    </author>
    <author>
      <name>Miguel Jaques</name>
    </author>
    <author>
      <name>Ben Glocker</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented at Workshop track - ICLR 2017</arxiv:comment>
    <link href="http://arxiv.org/abs/1703.06749v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.06749v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1704.02916v2</id>
    <updated>2017-08-15T01:56:16Z</updated>
    <published>2017-04-10T15:45:41Z</published>
    <title>Reinterpreting Importance-Weighted Autoencoders</title>
    <summary>  The standard interpretation of importance-weighted autoencoders is that they
maximize a tighter lower bound on the marginal likelihood than the standard
evidence lower bound. We give an alternate interpretation of this procedure:
that it optimizes the standard variational lower bound, but using a more
complex distribution. We formally derive this result, present a tighter lower
bound, and visualize the implicit importance-weighted distribution.
</summary>
    <author>
      <name>Chris Cremer</name>
    </author>
    <author>
      <name>Quaid Morris</name>
    </author>
    <author>
      <name>David Duvenaud</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICLR 2017 Workshop</arxiv:comment>
    <link href="http://arxiv.org/abs/1704.02916v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1704.02916v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1704.08727v1</id>
    <updated>2017-04-27T19:36:41Z</updated>
    <published>2017-04-27T19:36:41Z</published>
    <title>Structured Sparse Modelling with Hierarchical GP</title>
    <summary>  In this paper a new Bayesian model for sparse linear regression with a
spatio-temporal structure is proposed. It incorporates the structural
assumptions based on a hierarchical Gaussian process prior for spike and slab
coefficients. We design an inference algorithm based on Expectation Propagation
and evaluate the model over the real data.
</summary>
    <author>
      <name>Danil Kuzin</name>
    </author>
    <author>
      <name>Olga Isupova</name>
    </author>
    <author>
      <name>Lyudmila Mihaylova</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">SPARS 2017</arxiv:comment>
    <link href="http://arxiv.org/abs/1704.08727v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1704.08727v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.05278v2</id>
    <updated>2017-06-22T13:01:25Z</updated>
    <published>2017-05-15T14:59:26Z</published>
    <title>Unimodal probability distributions for deep ordinal classification</title>
    <summary>  Probability distributions produced by the cross-entropy loss for ordinal
classification problems can possess undesired properties. We propose a
straightforward technique to constrain discrete ordinal probability
distributions to be unimodal via the use of the Poisson and binomial
probability distributions. We evaluate this approach in the context of deep
learning on two large ordinal image datasets, obtaining promising results.
</summary>
    <author>
      <name>Christopher Beckham</name>
    </author>
    <author>
      <name>Christopher Pal</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted for publication for ICML2017. This is the camera-ready
  version</arxiv:comment>
    <link href="http://arxiv.org/abs/1705.05278v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.05278v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.09280v1</id>
    <updated>2017-05-25T17:55:24Z</updated>
    <published>2017-05-25T17:55:24Z</published>
    <title>Implicit Regularization in Matrix Factorization</title>
    <summary>  We study implicit regularization when optimizing an underdetermined quadratic
objective over a matrix $X$ with gradient descent on a factorization of $X$. We
conjecture and provide empirical and theoretical evidence that with small
enough step sizes and initialization close enough to the origin, gradient
descent on a full dimensional factorization converges to the minimum nuclear
norm solution.
</summary>
    <author>
      <name>Suriya Gunasekar</name>
    </author>
    <author>
      <name>Blake Woodworth</name>
    </author>
    <author>
      <name>Srinadh Bhojanapalli</name>
    </author>
    <author>
      <name>Behnam Neyshabur</name>
    </author>
    <author>
      <name>Nathan Srebro</name>
    </author>
    <link href="http://arxiv.org/abs/1705.09280v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.09280v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.02492v1</id>
    <updated>2017-06-08T09:34:31Z</updated>
    <published>2017-06-08T09:34:31Z</published>
    <title>Consistency Results for Stationary Autoregressive Processes with
  Constrained Coefficients</title>
    <summary>  We consider stationary autoregressive processes with coefficients restricted
to an ellipsoid, which includes autoregressive processes with absolutely
summable coefficients. We provide consistency results under different norms for
the estimation of such processes using constrained and penalized estimators. As
an application we show some weak form of universal consistency. Simulations
show that directly including the constraint in the estimation can lead to more
robust results.
</summary>
    <author>
      <name>Alessio Sancetta</name>
    </author>
    <link href="http://arxiv.org/abs/1706.02492v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.02492v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.04572v1</id>
    <updated>2017-06-14T16:24:18Z</updated>
    <published>2017-06-14T16:24:18Z</published>
    <title>Deep Learning Methods for Efficient Large Scale Video Labeling</title>
    <summary>  We present a solution to "Google Cloud and YouTube-8M Video Understanding
Challenge" that ranked 5th place. The proposed model is an ensemble of three
model families, two frame level and one video level. The training was performed
on augmented dataset, with cross validation.
</summary>
    <author>
      <name>Miha Skalic</name>
    </author>
    <author>
      <name>Marcin Pekalski</name>
    </author>
    <author>
      <name>Xingguo E. Pan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 5 tables, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1706.04572v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.04572v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.07101v1</id>
    <updated>2017-06-21T19:51:43Z</updated>
    <published>2017-06-21T19:51:43Z</published>
    <title>The energy landscape of a simple neural network</title>
    <summary>  We explore the energy landscape of a simple neural network. In particular, we
expand upon previous work demonstrating that the empirical complexity of fitted
neural networks is vastly less than a naive parameter count would suggest and
that this implicit regularization is actually beneficial for generalization
from fitted models.
</summary>
    <author>
      <name>Anthony Collins Gamst</name>
    </author>
    <author>
      <name>Alden Walker</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages, 15 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1706.07101v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.07101v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.08519v1</id>
    <updated>2017-06-26T17:41:20Z</updated>
    <published>2017-06-26T17:41:20Z</published>
    <title>On conditional parity as a notion of non-discrimination in machine
  learning</title>
    <summary>  We identify conditional parity as a general notion of non-discrimination in
machine learning. In fact, several recently proposed notions of
non-discrimination, including a few counterfactual notions, are instances of
conditional parity. We show that conditional parity is amenable to statistical
analysis by studying randomization as a general mechanism for achieving
conditional parity and a kernel-based test of conditional parity.
</summary>
    <author>
      <name>Ya'acov Ritov</name>
    </author>
    <author>
      <name>Yuekai Sun</name>
    </author>
    <author>
      <name>Ruofei Zhao</name>
    </author>
    <link href="http://arxiv.org/abs/1706.08519v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.08519v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.00797v1</id>
    <updated>2017-07-04T02:05:52Z</updated>
    <published>2017-07-04T02:05:52Z</published>
    <title>Learning Deep Energy Models: Contrastive Divergence vs. Amortized MLE</title>
    <summary>  We propose a number of new algorithms for learning deep energy models and
demonstrate their properties. We show that our SteinCD performs well in term of
test likelihood, while SteinGAN performs well in terms of generating realistic
looking images. Our results suggest promising directions for learning better
models by combining GAN-style methods with traditional energy-based learning.
</summary>
    <author>
      <name>Qiang Liu</name>
    </author>
    <author>
      <name>Dilin Wang</name>
    </author>
    <link href="http://arxiv.org/abs/1707.00797v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.00797v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.03383v1</id>
    <updated>2017-07-11T17:44:20Z</updated>
    <published>2017-07-11T17:44:20Z</published>
    <title>A step towards procedural terrain generation with GANs</title>
    <summary>  Procedural terrain generation for video games has been traditionally been
done with smartly designed but handcrafted algorithms that generate heightmaps.
We propose a first step toward the learning and synthesis of these using recent
advances in deep generative modelling with openly available satellite imagery
from NASA.
</summary>
    <author>
      <name>Christopher Beckham</name>
    </author>
    <author>
      <name>Christopher Pal</name>
    </author>
    <link href="http://arxiv.org/abs/1707.03383v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.03383v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.05532v1</id>
    <updated>2017-07-18T09:16:50Z</updated>
    <published>2017-07-18T09:16:50Z</published>
    <title>Bayesian Nonlinear Support Vector Machines for Big Data</title>
    <summary>  We propose a fast inference method for Bayesian nonlinear support vector
machines that leverages stochastic variational inference and inducing points.
Our experiments show that the proposed method is faster than competing Bayesian
approaches and scales easily to millions of data points. It provides additional
features over frequentist competitors such as accurate predictive uncertainty
estimates and automatic hyperparameter search.
</summary>
    <author>
      <name>Florian Wenzel</name>
    </author>
    <author>
      <name>Theo Galy-Fajou</name>
    </author>
    <author>
      <name>Matthaeus Deutsch</name>
    </author>
    <author>
      <name>Marius Kloft</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">accepted as conference paper at ECML-PKDD 2017</arxiv:comment>
    <link href="http://arxiv.org/abs/1707.05532v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.05532v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.06261v1</id>
    <updated>2017-07-19T18:56:04Z</updated>
    <published>2017-07-19T18:56:04Z</published>
    <title>Rates of Uniform Consistency for k-NN Regression</title>
    <summary>  We derive high-probability finite-sample uniform rates of consistency for
$k$-NN regression that are optimal up to logarithmic factors under mild
assumptions. We moreover show that $k$-NN regression adapts to an unknown lower
intrinsic dimension automatically. We then apply the $k$-NN regression rates to
establish new results about estimating the level sets and global maxima of a
function from noisy observations.
</summary>
    <author>
      <name>Heinrich Jiang</name>
    </author>
    <link href="http://arxiv.org/abs/1707.06261v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.06261v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.02666v1</id>
    <updated>2017-08-08T22:21:11Z</updated>
    <published>2017-08-08T22:21:11Z</published>
    <title>Proceedings of the 2017 ICML Workshop on Human Interpretability in
  Machine Learning (WHI 2017)</title>
    <summary>  This is the Proceedings of the 2017 ICML Workshop on Human Interpretability
in Machine Learning (WHI 2017), which was held in Sydney, Australia, August 10,
2017. Invited speakers were Tony Jebara, Pang Wei Koh, and David Sontag.
</summary>
    <author>
      <name>Been Kim</name>
    </author>
    <author>
      <name>Dmitry M. Malioutov</name>
    </author>
    <author>
      <name>Kush R. Varshney</name>
    </author>
    <author>
      <name>Adrian Weller</name>
    </author>
    <link href="http://arxiv.org/abs/1708.02666v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.02666v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.09708v1</id>
    <updated>2017-08-31T13:51:03Z</updated>
    <published>2017-08-31T13:51:03Z</published>
    <title>Sketching the order of events</title>
    <summary>  We introduce features for massive data streams. These stream features can be
thought of as "ordered moments" and generalize stream sketches from "moments of
order one" to "ordered moments of arbitrary order". In analogy to classic
moments, they have theoretical guarantees such as universality that are
important for learning algorithms.
</summary>
    <author>
      <name>Terry Lyons</name>
    </author>
    <author>
      <name>Harald Oberhauser</name>
    </author>
    <link href="http://arxiv.org/abs/1708.09708v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.09708v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.01860v1</id>
    <updated>2017-09-06T15:41:11Z</updated>
    <published>2017-09-06T15:41:11Z</published>
    <title>The low-rank hurdle model</title>
    <summary>  A composite loss framework is proposed for low-rank modeling of data
consisting of interesting and common values, such as excess zeros or missing
values. The methodology is motivated by the generalized low-rank framework and
the hurdle method which is commonly used to analyze zero-inflated counts. The
model is demonstrated on a manufacturing data set and applied to the problem of
missing value imputation.
</summary>
    <author>
      <name>Christopher Dienes</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 2 figures, 2 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1709.01860v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.01860v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.01972v2</id>
    <updated>2017-09-14T17:35:59Z</updated>
    <published>2017-09-06T19:35:02Z</published>
    <title>A Quasi-isometric Embedding Algorithm</title>
    <summary>  The Whitney embedding theorem gives an upper bound on the smallest embedding
dimension of a manifold. If a data set lies on a manifold, a random projection
into this reduced dimension will retain the manifold structure. Here we present
an algorithm to find a projection that distorts the data as little as possible.
</summary>
    <author>
      <name>David W. Dreisigmeyer</name>
    </author>
    <link href="http://arxiv.org/abs/1709.01972v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.01972v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.10222v1</id>
    <updated>2017-09-29T02:51:52Z</updated>
    <published>2017-09-29T02:51:52Z</published>
    <title>Comparison of PCA with ICA from data distribution perspective</title>
    <summary>  We performed an empirical comparison of ICA and PCA algorithms by applying
them on two simulated noisy time series with varying distribution parameters
and level of noise. In general, ICA shows better results than PCA because it
takes into account higher moments of data distribution. On the other hand, PCA
remains quite sensitive to the level of correlations among signals.
</summary>
    <author>
      <name>Miron Ivanov</name>
    </author>
    <link href="http://arxiv.org/abs/1709.10222v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.10222v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1710.00085v1</id>
    <updated>2017-09-29T20:43:24Z</updated>
    <published>2017-09-29T20:43:24Z</published>
    <title>Language-depedent I-Vectors for LRE15</title>
    <summary>  A standard recipe for spoken language recognition is to apply a Gaussian
back-end to i-vectors. This ignores the uncertainty in the i-vector extraction,
which could be important especially for short utterances. A recent paper by
Cumani, Plchot and Fer proposes a solution to propagate that uncertainty into
the backend. We propose an alternative method of propagating the uncertainty.
</summary>
    <author>
      <name>Niko Brümmer</name>
    </author>
    <author>
      <name>Albert Swart</name>
    </author>
    <link href="http://arxiv.org/abs/1710.00085v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1710.00085v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.02441v1</id>
    <updated>2017-05-06T04:15:06Z</updated>
    <published>2017-05-06T04:15:06Z</published>
    <title>Comments on `High-dimensional simultaneous inference with the bootstrap'</title>
    <summary>  We provide comments on the article "High-dimensional simultaneous inference
with the bootstrap" by Ruben Dezeure, Peter Buhlmann and Cun-Hui Zhang.
</summary>
    <author>
      <name>Jelena Bradic</name>
    </author>
    <author>
      <name>Yinchu Zhu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1705.02441v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.02441v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0705.2363v1</id>
    <updated>2007-05-16T14:23:17Z</updated>
    <published>2007-05-16T14:23:17Z</published>
    <title>Lasso type classifiers with a reject option</title>
    <summary>  We consider the problem of binary classification where one can, for a
particular cost, choose not to classify an observation. We present a simple
proof for the oracle inequality for the excess risk of structural risk
minimizers using a lasso type penalty.
</summary>
    <author>
      <name>Marten Wegkamp</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1214/07-EJS058</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1214/07-EJS058" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published at http://dx.doi.org/10.1214/07-EJS058 in the Electronic
  Journal of Statistics (http://www.i-journals.org/ejs/) by the Institute of
  Mathematical Statistics (http://www.imstat.org)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Electronic Journal of Statistics 2007, Vol. 1, 155-168</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0705.2363v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0705.2363v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62C05 (Primary) 62G05, 62G08 (Secondary)" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0707.0303v1</id>
    <updated>2007-07-02T20:16:49Z</updated>
    <published>2007-07-02T20:16:49Z</published>
    <title>Learning from dependent observations</title>
    <summary>  In most papers establishing consistency for learning algorithms it is assumed
that the observations used for training are realizations of an i.i.d. process.
In this paper we go far beyond this classical framework by showing that support
vector machines (SVMs) essentially only require that the data-generating
process satisfies a certain law of large numbers. We then consider the
learnability of SVMs for $\a$-mixing (not necessarily stationary) processes for
both classification and regression, where for the latter we explicitly allow
unbounded noise.
</summary>
    <author>
      <name>Ingo Steinwart</name>
    </author>
    <author>
      <name>Don Hush</name>
    </author>
    <author>
      <name>Clint Scovel</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">submitted to Journal of Multivariate Analysis</arxiv:comment>
    <link href="http://arxiv.org/abs/0707.0303v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0707.0303v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0707.3536v1</id>
    <updated>2007-07-24T12:45:39Z</updated>
    <published>2007-07-24T12:45:39Z</published>
    <title>Degenerating families of dendrograms</title>
    <summary>  Dendrograms used in data analysis are ultrametric spaces, hence objects of
nonarchimedean geometry. It is known that there exist $p$-adic representation
of dendrograms. Completed by a point at infinity, they can be viewed as
subtrees of the Bruhat-Tits tree associated to the $p$-adic projective line.
The implications are that certain moduli spaces known in algebraic geometry are
$p$-adic parameter spaces of (families of) dendrograms, and stochastic
classification can also be handled within this framework. At the end, we
calculate the topology of the hidden part of a dendrogram.
</summary>
    <author>
      <name>Patrick Erik Bradley</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s00357-008-9009-5</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s00357-008-9009-5" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 8 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">J. Classif. 25, 27-42 (2008)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0707.3536v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0707.3536v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0708.2377v1</id>
    <updated>2007-08-17T14:41:58Z</updated>
    <published>2007-08-17T14:41:58Z</published>
    <title>Online Learning in Discrete Hidden Markov Models</title>
    <summary>  We present and analyse three online algorithms for learning in discrete
Hidden Markov Models (HMMs) and compare them with the Baldi-Chauvin Algorithm.
Using the Kullback-Leibler divergence as a measure of generalisation error we
draw learning curves in simplified situations. The performance for learning
drifting concepts of one of the presented algorithms is analysed and compared
with the Baldi-Chauvin algorithm in the same situations. A brief discussion
about learning and symmetry breaking based on our results is also presented.
</summary>
    <author>
      <name>Roberto C. Alamino</name>
    </author>
    <author>
      <name>Nestor Caticha</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1063/1.2423274</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1063/1.2423274" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0708.2377v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0708.2377v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0711.2434v1</id>
    <updated>2007-11-15T15:09:41Z</updated>
    <published>2007-11-15T15:09:41Z</published>
    <title>Variable importance in binary regression trees and forests</title>
    <summary>  We characterize and study variable importance (VIMP) and pairwise variable
associations in binary regression trees. A key component involves the node mean
squared error for a quantity we refer to as a maximal subtree. The theory
naturally extends from single trees to ensembles of trees and applies to
methods like random forests. This is useful because while importance values
from random forests are used to screen variables, for example they are used to
filter high throughput genomic data in Bioinformatics, very little theory
exists about their properties.
</summary>
    <author>
      <name>Hemant Ishwaran</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1214/07-EJS039</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1214/07-EJS039" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published in at http://dx.doi.org/10.1214/07-EJS039 the Electronic
  Journal of Statistics (http://www.i-journals.org/ejs/) by the Institute of
  Mathematical Statistics (http://www.imstat.org)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Electronic Journal of Statistics 2007, Vol. 1, 519-537</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0711.2434v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0711.2434v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0712.1698v3</id>
    <updated>2009-01-09T15:13:19Z</updated>
    <published>2007-12-11T12:40:41Z</published>
    <title>PAC-Bayesian Bounds for Randomized Empirical Risk Minimizers</title>
    <summary>  The aim of this paper is to generalize the PAC-Bayesian theorems proved by
Catoni in the classification setting to more general problems of statistical
inference. We show how to control the deviations of the risk of randomized
estimators. A particular attention is paid to randomized estimators drawn in a
small neighborhood of classical estimators, whose study leads to control the
risk of the latter. These results allow to bound the risk of very general
estimation procedures, as well as to perform model selection.
</summary>
    <author>
      <name>Pierre Alquier</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PMA, Crest</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.3103/S1066530708040017</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.3103/S1066530708040017" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Mathematical Methods of Statistics 17, 4 (2008) 279-304</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0712.1698v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0712.1698v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0801.1440v1</id>
    <updated>2008-01-09T14:29:17Z</updated>
    <published>2008-01-09T14:29:17Z</published>
    <title>Parameterizations and fitting of bi-directed graph models to categorical
  data</title>
    <summary>  We discuss two parameterizations of models for marginal independencies for
discrete distributions which are representable by bi-directed graph models,
under the global Markov property. Such models are useful data analytic tools
especially if used in combination with other graphical models. The first
parameterization, in the saturated case, is also known as the multivariate
logistic transformation, the second is a variant that allows, in some (but not
all) cases, variation independent parameters. An algorithm for maximum
likelihood fitting is proposed, based on an extension of the Aitchison and
Silvey method.
</summary>
    <author>
      <name>Monia Lupparelli</name>
    </author>
    <author>
      <name>Giovanni M. Marchetti</name>
    </author>
    <author>
      <name>Wicher P. Bergsma</name>
    </author>
    <link href="http://arxiv.org/abs/0801.1440v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0801.1440v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0802.2758v4</id>
    <updated>2008-04-29T00:56:14Z</updated>
    <published>2008-02-20T20:54:29Z</published>
    <title>Time Varying Undirected Graphs</title>
    <summary>  Undirected graphs are often used to describe high dimensional distributions.
Under sparsity conditions, the graph can be estimated using $\ell_1$
penalization methods. However, current methods assume that the data are
independent and identically distributed. If the distribution, and hence the
graph, evolves over time then the data are not longer identically distributed.
In this paper, we show how to estimate the sequence of graphs for
non-identically distributed data, where the distribution evolves over time.
</summary>
    <author>
      <name>Shuheng Zhou</name>
    </author>
    <author>
      <name>John Lafferty</name>
    </author>
    <author>
      <name>Larry Wasserman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 3 figures, to appear in COLT 2008</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">The 21st Annual Conference on Learning Theory (COLT 2008),
  Helsinki, Finland</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0802.2758v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0802.2758v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0802.3150v1</id>
    <updated>2008-02-21T16:08:09Z</updated>
    <published>2008-02-21T16:08:09Z</published>
    <title>Self Organizing Map algorithm and distortion measure</title>
    <summary>  We study the statistical meaning of the minimization of distortion measure
and the relation between the equilibrium points of the SOM algorithm and the
minima of distortion measure. If we assume that the observations and the map
lie in an compact Euclidean space, we prove the strong consistency of the map
which almost minimizes the empirical distortion. Moreover, after calculating
the derivatives of the theoretical distortion measure, we show that the points
minimizing this measure and the equilibria of the Kohonen map do not match in
general. We illustrate, with a simple example, how this occurs.
</summary>
    <author>
      <name>Joseph Rynkiewicz</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CES, Samos</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Neural Networks 19, 6-7 (2006) 671-678</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0802.3150v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0802.3150v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0804.1325v1</id>
    <updated>2008-04-08T16:58:11Z</updated>
    <published>2008-04-08T16:58:11Z</published>
    <title>On the underestimation of model uncertainty by Bayesian K-nearest
  neighbors</title>
    <summary>  When using the K-nearest neighbors method, one often ignores uncertainty in
the choice of K. To account for such uncertainty, Holmes and Adams (2002)
proposed a Bayesian framework for K-nearest neighbors (KNN). Their Bayesian KNN
(BKNN) approach uses a pseudo-likelihood function, and standard Markov chain
Monte Carlo (MCMC) techniques to draw posterior samples. Holmes and Adams
(2002) focused on the performance of BKNN in terms of misclassification error
but did not assess its ability to quantify uncertainty. We present some
evidence to show that BKNN still significantly underestimates model
uncertainty.
</summary>
    <author>
      <name>Wanhua Su</name>
    </author>
    <author>
      <name>Hugh Chipman</name>
    </author>
    <author>
      <name>Mu Zhu</name>
    </author>
    <link href="http://arxiv.org/abs/0804.1325v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0804.1325v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0806.2646v1</id>
    <updated>2008-06-16T19:54:49Z</updated>
    <published>2008-06-16T19:54:49Z</published>
    <title>Manifold Learning: The Price of Normalization</title>
    <summary>  We analyze the performance of a class of manifold-learning algorithms that
find their output by minimizing a quadratic form under some normalization
constraints. This class consists of Locally Linear Embedding (LLE), Laplacian
Eigenmap, Local Tangent Space Alignment (LTSA), Hessian Eigenmaps (HLLE), and
Diffusion maps. We present and prove conditions on the manifold that are
necessary for the success of the algorithms. Both the finite sample case and
the limit case are analyzed. We show that there are simple manifolds in which
the necessary conditions are violated, and hence the algorithms cannot recover
the underlying manifolds. Finally, we present numerical results that
demonstrate our claims.
</summary>
    <author>
      <name>Y. Goldberg</name>
    </author>
    <author>
      <name>A. Zakai</name>
    </author>
    <author>
      <name>D. Kushnir</name>
    </author>
    <author>
      <name>Y. Ritov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to JMLR</arxiv:comment>
    <link href="http://arxiv.org/abs/0806.2646v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0806.2646v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0806.2669v1</id>
    <updated>2008-06-16T20:41:57Z</updated>
    <published>2008-06-16T20:41:57Z</published>
    <title>Local Procrustes for Manifold Embedding: A Measure of Embedding Quality
  and Embedding Algorithms</title>
    <summary>  We present the Procrustes measure, a novel measure based on Procrustes
rotation that enables quantitative comparison of the output of manifold-based
embedding algorithms (such as LLE (Roweis and Saul, 2000) and Isomap (Tenenbaum
et al, 2000)). The measure also serves as a natural tool when choosing
dimension-reduction parameters. We also present two novel dimension-reduction
techniques that attempt to minimize the suggested measure, and compare the
results of these techniques to the results of existing algorithms. Finally, we
suggest a simple iterative method that can be used to improve the output of
existing algorithms.
</summary>
    <author>
      <name>Y. Goldberg</name>
    </author>
    <author>
      <name>Y. Ritov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to Journal of Machine Learning</arxiv:comment>
    <link href="http://arxiv.org/abs/0806.2669v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0806.2669v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0808.2241v1</id>
    <updated>2008-08-16T08:16:11Z</updated>
    <published>2008-08-16T08:16:11Z</published>
    <title>Persistent Clustering and a Theorem of J. Kleinberg</title>
    <summary>  We construct a framework for studying clustering algorithms, which includes
two key ideas: persistence and functoriality. The first encodes the idea that
the output of a clustering scheme should carry a multiresolution structure, the
second the idea that one should be able to compare the results of clustering
algorithms as one varies the data set, for example by adding points or by
applying functions to it. We show that within this framework, one can prove a
theorem analogous to one of J. Kleinberg, in which one obtains an existence and
uniqueness theorem instead of a non-existence result. We explore further
properties of this unique scheme, stability and convergence are established.
</summary>
    <author>
      <name>Gunnar Carlsson</name>
    </author>
    <author>
      <name>Facundo Memoli</name>
    </author>
    <link href="http://arxiv.org/abs/0808.2241v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0808.2241v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0808.2337v1</id>
    <updated>2008-08-18T19:07:06Z</updated>
    <published>2008-08-18T19:07:06Z</published>
    <title>Decomposable Principal Component Analysis</title>
    <summary>  We consider principal component analysis (PCA) in decomposable Gaussian
graphical models. We exploit the prior information in these models in order to
distribute its computation. For this purpose, we reformulate the problem in the
sparse inverse covariance (concentration) domain and solve the global
eigenvalue problem using a sequence of local eigenvalue problems in each of the
cliques of the decomposable graph. We demonstrate the application of our
methodology in the context of decentralized anomaly detection in the Abilene
backbone network. Based on the topology of the network, we propose an
approximate statistical graphical model and distribute the computation of PCA.
</summary>
    <author>
      <name>Ami Wiesel</name>
    </author>
    <author>
      <name>Alfred O. Hero III</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TSP.2009.2025806</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TSP.2009.2025806" rel="related"/>
    <link href="http://arxiv.org/abs/0808.2337v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0808.2337v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0810.4553v1</id>
    <updated>2008-10-24T21:05:16Z</updated>
    <published>2008-10-24T21:05:16Z</published>
    <title>Online Coordinate Boosting</title>
    <summary>  We present a new online boosting algorithm for adapting the weights of a
boosted classifier, which yields a closer approximation to Freund and
Schapire's AdaBoost algorithm than previous online boosting algorithms. We also
contribute a new way of deriving the online algorithm that ties together
previous online boosting work. We assume that the weak hypotheses were selected
beforehand, and only their weights are updated during online boosting. The
update rule is derived by minimizing AdaBoost's loss when viewed in an
incremental form. The equations show that optimization is computationally
expensive. However, a fast online approximation is possible. We compare
approximation error to batch AdaBoost on synthetic datasets and generalization
error on face datasets and the MNIST dataset.
</summary>
    <author>
      <name>Raphael Pelossof</name>
    </author>
    <author>
      <name>Michael Jones</name>
    </author>
    <author>
      <name>Ilia Vovsha</name>
    </author>
    <author>
      <name>Cynthia Rudin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0810.4553v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0810.4553v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0810.4752v1</id>
    <updated>2008-10-27T08:25:20Z</updated>
    <published>2008-10-27T08:25:20Z</published>
    <title>Statistical Learning Theory: Models, Concepts, and Results</title>
    <summary>  Statistical learning theory provides the theoretical basis for many of
today's machine learning algorithms. In this article we attempt to give a
gentle, non-technical overview over the key ideas and insights of statistical
learning theory. We target at a broad audience, not necessarily machine
learning researchers. This paper can serve as a starting point for people who
want to get an overview on the field before diving into technical details.
</summary>
    <author>
      <name>Ulrike von Luxburg</name>
    </author>
    <author>
      <name>Bernhard Schoelkopf</name>
    </author>
    <link href="http://arxiv.org/abs/0810.4752v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0810.4752v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0811.3499v1</id>
    <updated>2008-11-21T10:17:00Z</updated>
    <published>2008-11-21T10:17:00Z</published>
    <title>Kernel Regression by Mode Calculation of the Conditional Probability
  Distribution</title>
    <summary>  The most direct way to express arbitrary dependencies in datasets is to
estimate the joint distribution and to apply afterwards the argmax-function to
obtain the mode of the corresponding conditional distribution. This method is
in practice difficult, because it requires a global optimization of a
complicated function, the joint distribution by fixed input variables. This
article proposes a method for finding global maxima if the joint distribution
is modeled by a kernel density estimation. Some experiments show advantages and
shortcomings of the resulting regression method in comparison to the standard
Nadaraya-Watson regression technique, which approximates the optimum by the
expectation value.
</summary>
    <author>
      <name>Steffen Kuehn</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0811.3499v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0811.3499v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0812.1949v1</id>
    <updated>2008-12-10T16:22:26Z</updated>
    <published>2008-12-10T16:22:26Z</published>
    <title>Prediction with Restricted Resources and Finite Automata</title>
    <summary>  We obtain an index of the complexity of a random sequence by allowing the
role of the measure in classical probability theory to be played by a function
we call the generating mechanism. Typically, this generating mechanism will be
a finite automata. We generate a set of biased sequences by applying a finite
state automata with a specified number, $m$, of states to the set of all binary
sequences. Thus we can index the complexity of our random sequence by the
number of states of the automata. We detail optimal algorithms to predict
sequences generated in this way.
</summary>
    <author>
      <name>Finn Macleod</name>
    </author>
    <author>
      <name>James Gleeson</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/0812.1949v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0812.1949v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0901.2962v2</id>
    <updated>2009-03-17T13:33:45Z</updated>
    <published>2009-01-20T02:26:44Z</published>
    <title>The Benefit of Group Sparsity</title>
    <summary>  This paper develops a theory for group Lasso using a concept called strong
group sparsity. Our result shows that group Lasso is superior to standard Lasso
for strongly group-sparse signals. This provides a convincing theoretical
justification for using group sparse regularization when the underlying group
structure is consistent with the data. Moreover, the theory predicts some
limitations of the group Lasso formulation that are confirmed by simulation
studies.
</summary>
    <author>
      <name>Junzhou Huang</name>
    </author>
    <author>
      <name>Tong Zhang</name>
    </author>
    <link href="http://arxiv.org/abs/0901.2962v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0901.2962v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0903.0649v1</id>
    <updated>2009-03-03T22:55:18Z</updated>
    <published>2009-03-03T22:55:18Z</published>
    <title>The Nonparanormal: Semiparametric Estimation of High Dimensional
  Undirected Graphs</title>
    <summary>  Recent methods for estimating sparse undirected graphs for real-valued data
in high dimensional problems rely heavily on the assumption of normality. We
show how to use a semiparametric Gaussian copula--or "nonparanormal"--for high
dimensional inference. Just as additive models extend linear models by
replacing linear functions with a set of one-dimensional smooth functions, the
nonparanormal extends the normal by transforming the variables by smooth
functions. We derive a method for estimating the nonparanormal, study the
method's theoretical properties, and show that it works well in many examples.
</summary>
    <author>
      <name>Han Liu</name>
    </author>
    <author>
      <name>John Lafferty</name>
    </author>
    <author>
      <name>Larry Wasserman</name>
    </author>
    <link href="http://arxiv.org/abs/0903.0649v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0903.0649v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0904.0584v1</id>
    <updated>2009-04-03T14:32:47Z</updated>
    <published>2009-04-03T14:32:47Z</published>
    <title>Dual Augmented Lagrangian Method for Efficient Sparse Reconstruction</title>
    <summary>  We propose an efficient algorithm for sparse signal reconstruction problems.
The proposed algorithm is an augmented Lagrangian method based on the dual
sparse reconstruction problem. It is efficient when the number of unknown
variables is much larger than the number of observations because of the dual
formulation. Moreover, the primal variable is explicitly updated and the
sparsity in the solution is exploited. Numerical comparison with the
state-of-the-art algorithms shows that the proposed algorithm is favorable when
the design matrix is poorly conditioned or dense and very large.
</summary>
    <author>
      <name>Ryota Tomioka</name>
    </author>
    <author>
      <name>Masashi Sugiyama</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/LSP.2009.2030111</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/LSP.2009.2030111" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 3 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE Signal Processing Letters, volume 16, issue 12, pages 1067 -
  1070, 2009</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0904.0584v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0904.0584v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0906.2034v1</id>
    <updated>2009-06-11T18:33:19Z</updated>
    <published>2009-06-11T18:33:19Z</published>
    <title>Regularization methods for learning incomplete matrices</title>
    <summary>  We use convex relaxation techniques to provide a sequence of solutions to the
matrix completion problem. Using the nuclear norm as a regularizer, we provide
simple and very efficient algorithms for minimizing the reconstruction error
subject to a bound on the nuclear norm. Our algorithm iteratively replaces the
missing elements with those obtained from a thresholded SVD. With warm starts
this allows us to efficiently compute an entire regularization path of
solutions.
</summary>
    <author>
      <name>Rahul Mazumder</name>
    </author>
    <author>
      <name>Trevor Hastie</name>
    </author>
    <author>
      <name>Rob Tibshirani</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/0906.2034v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0906.2034v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0907.5494v1</id>
    <updated>2009-07-31T09:19:49Z</updated>
    <published>2009-07-31T09:19:49Z</published>
    <title>How the initialization affects the stability of the k-means algorithm</title>
    <summary>  We investigate the role of the initialization for the stability of the
k-means clustering algorithm. As opposed to other papers, we consider the
actual k-means algorithm and do not ignore its property of getting stuck in
local optima. We are interested in the actual clustering, not only in the costs
of the solution. We analyze when different initializations lead to the same
local optimum, and when they lead to different local optima. This enables us to
prove that it is reasonable to select the number of clusters based on stability
scores.
</summary>
    <author>
      <name>Sebastien Bubeck</name>
    </author>
    <author>
      <name>Marina Meila</name>
    </author>
    <author>
      <name>Ulrike von Luxburg</name>
    </author>
    <link href="http://arxiv.org/abs/0907.5494v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0907.5494v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0908.1258v1</id>
    <updated>2009-08-09T22:35:14Z</updated>
    <published>2009-08-09T22:35:14Z</published>
    <title>Discrete Temporal Models of Social Networks</title>
    <summary>  We propose a family of statistical models for social network evolution over
time, which represents an extension of Exponential Random Graph Models (ERGMs).
Many of the methods for ERGMs are readily adapted for these models, including
maximum likelihood estimation algorithms. We discuss models of this type and
their properties, and give examples, as well as a demonstration of their use
for hypothesis testing and classification. We believe our temporal ERG models
represent a useful new framework for modeling time-evolving social networks,
and rewiring networks from other domains such as gene regulation circuitry, and
communication networks.
</summary>
    <author>
      <name>Steve Hanneke</name>
    </author>
    <author>
      <name>Wenjie Fu</name>
    </author>
    <author>
      <name>Eric Xing</name>
    </author>
    <link href="http://arxiv.org/abs/0908.1258v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0908.1258v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0908.3817v2</id>
    <updated>2010-07-10T22:11:40Z</updated>
    <published>2009-08-26T13:36:18Z</published>
    <title>Learning Bayesian Networks with the bnlearn R Package</title>
    <summary>  bnlearn is an R package which includes several algorithms for learning the
structure of Bayesian networks with either discrete or continuous variables.
Both constraint-based and score-based algorithms are implemented, and can use
the functionality provided by the snow package to improve their performance via
parallel computing. Several network scores and conditional independence
algorithms are available for both the learning algorithms and independent use.
Advanced plotting options are provided by the Rgraphviz package.
</summary>
    <author>
      <name>Marco Scutari</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">22 pages, 4 pictures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Statistical Software (2010), 35(3), 1-22</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0908.3817v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0908.3817v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0909.1234v4</id>
    <updated>2010-09-22T08:36:10Z</updated>
    <published>2009-09-07T12:20:10Z</published>
    <title>High-dimensional Graphical Model Search with gRapHD R Package</title>
    <summary>  This paper presents the R package gRapHD for efficient selection of
high-dimensional undirected graphical models. The package provides tools for
selecting trees, forests and decomposable models minimizing information
criteria such as AIC or BIC, and for displaying the independence graphs of the
models. It has also some useful tools for analysing graphical structures. It
supports the use of discrete, continuous, or both types of variables
simultaneously.
</summary>
    <author>
      <name>Gabriel C. G. de Abreu</name>
    </author>
    <author>
      <name>Rodrigo Labouriau</name>
    </author>
    <author>
      <name>David Edwards</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages with 8 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Statistical Software, Vol. 37, Issue 1, Nov. 2010</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0909.1234v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0909.1234v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0909.1440v1</id>
    <updated>2009-09-08T13:42:35Z</updated>
    <published>2009-09-08T13:42:35Z</published>
    <title>Structured Sparse Principal Component Analysis</title>
    <summary>  We present an extension of sparse PCA, or sparse dictionary learning, where
the sparsity patterns of all dictionary elements are structured and constrained
to belong to a prespecified set of shapes. This \emph{structured sparse PCA} is
based on a structured regularization recently introduced by [1]. While
classical sparse priors only deal with \textit{cardinality}, the regularization
we use encodes higher-order information about the data. We propose an efficient
and simple optimization procedure to solve this problem. Experiments with two
practical tasks, face recognition and the study of the dynamics of a protein
complex, demonstrate the benefits of the proposed structured approach over
unstructured approaches.
</summary>
    <author>
      <name>Rodolphe Jenatton</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rocquencourt</arxiv:affiliation>
    </author>
    <author>
      <name>Guillaume Obozinski</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rocquencourt</arxiv:affiliation>
    </author>
    <author>
      <name>Francis Bach</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rocquencourt</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/0909.1440v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0909.1440v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0909.2332v1</id>
    <updated>2009-09-12T13:31:41Z</updated>
    <published>2009-09-12T13:31:41Z</published>
    <title>A Nonconformity Approach to Model Selection for SVMs</title>
    <summary>  We investigate the issue of model selection and the use of the nonconformity
(strangeness) measure in batch learning. Using the nonconformity measure we
propose a new training algorithm that helps avoid the need for Cross-Validation
or Leave-One-Out model selection strategies. We provide a new generalisation
error bound using the notion of nonconformity to upper bound the loss of each
test example and show that our proposed approach is comparable to standard
model selection methods, but with theoretical guarantees of success and faster
convergence. We demonstrate our novel model selection technique using the
Support Vector Machine.
</summary>
    <author>
      <name>David R. Hardoon</name>
    </author>
    <author>
      <name>Zakria Hussain</name>
    </author>
    <author>
      <name>John Shawe-Taylor</name>
    </author>
    <link href="http://arxiv.org/abs/0909.2332v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0909.2332v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0909.4386v1</id>
    <updated>2009-09-24T08:54:15Z</updated>
    <published>2009-09-24T08:54:15Z</published>
    <title>Telling cause from effect based on high-dimensional observations</title>
    <summary>  We describe a method for inferring linear causal relations among
multi-dimensional variables. The idea is to use an asymmetry between the
distributions of cause and effect that occurs if both the covariance matrix of
the cause and the structure matrix mapping cause to the effect are
independently chosen. The method works for both stochastic and deterministic
causal relations, provided that the dimensionality is sufficiently high (in
some experiments, 5 was enough). It is applicable to Gaussian as well as
non-Gaussian data.
</summary>
    <author>
      <name>Dominik Janzing</name>
    </author>
    <author>
      <name>Patrik O. Hoyer</name>
    </author>
    <author>
      <name>Bernhard Schoelkopf</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0909.4386v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0909.4386v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0910.0115v1</id>
    <updated>2009-10-01T09:12:38Z</updated>
    <published>2009-10-01T09:12:38Z</published>
    <title>Expectation Propagation on the Maximum of Correlated Normal Variables</title>
    <summary>  Many inference problems involving questions of optimality ask for the maximum
or the minimum of a finite set of unknown quantities. This technical report
derives the first two posterior moments of the maximum of two correlated
Gaussian variables and the first two posterior moments of the two generating
variables (corresponding to Gaussian approximations minimizing relative
entropy). It is shown how this can be used to build a heuristic approximation
to the maximum relationship over a finite set of Gaussian variables, allowing
approximate inference by Expectation Propagation on such quantities.
</summary>
    <author>
      <name>Philipp Hennig</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0910.0115v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0910.0115v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0910.0483v1</id>
    <updated>2009-10-05T19:43:40Z</updated>
    <published>2009-10-05T19:43:40Z</published>
    <title>Statistical Decision Making for Authentication and Intrusion Detection</title>
    <summary>  User authentication and intrusion detection differ from standard
classification problems in that while we have data generated from legitimate
users, impostor or intrusion data is scarce or non-existent. We review existing
techniques for dealing with this problem and propose a novel alternative based
on a principled statistical decision-making view point. We examine the
technique on a toy problem and validate it on complex real-world data from an
RFID based access control system. The results indicate that it can
significantly outperform the classical world model approach. The method could
be more generally useful in other decision-making scenarios where there is a
lack of adversary data.
</summary>
    <author>
      <name>Christos Dimitrakakis</name>
    </author>
    <author>
      <name>Aikaterini Mitrokotsa</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 2 figures, to be presented at ICMLA 2009</arxiv:comment>
    <link href="http://arxiv.org/abs/0910.0483v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0910.0483v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0910.4636v3</id>
    <updated>2011-05-10T09:30:25Z</updated>
    <published>2009-10-24T10:11:01Z</published>
    <title>On approximation of smoothing probabilities for hidden Markov models</title>
    <summary>  We consider the smoothing probabilities of hidden Markov model (HMM). We show
that under fairly general conditions for HMM, the exponential forgetting still
holds, and the smoothing probabilities can be well approximated with the ones
of double sided HMM. This makes it possible to use ergodic theorems. As an
applications we consider the pointwise maximum a posteriori segmentation, and
show that the corresponding risks converge.
</summary>
    <author>
      <name>J. Lember</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">submitted to Statistics and Probability Letters</arxiv:comment>
    <link href="http://arxiv.org/abs/0910.4636v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0910.4636v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0910.5761v1</id>
    <updated>2009-10-30T01:10:44Z</updated>
    <published>2009-10-30T01:10:44Z</published>
    <title>Which graphical models are difficult to learn?</title>
    <summary>  We consider the problem of learning the structure of Ising models (pairwise
binary Markov random fields) from i.i.d. samples. While several methods have
been proposed to accomplish this task, their relative merits and limitations
remain somewhat obscure. By analyzing a number of concrete examples, we show
that low-complexity algorithms systematically fail when the Markov random field
develops long-range correlations. More precisely, this phenomenon appears to be
related to the Ising model phase transition (although it does not coincide with
it).
</summary>
    <author>
      <name>Jose Bento</name>
    </author>
    <author>
      <name>Andrea Montanari</name>
    </author>
    <link href="http://arxiv.org/abs/0910.5761v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0910.5761v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0912.0874v2</id>
    <updated>2011-11-03T14:37:26Z</updated>
    <published>2009-12-04T15:07:30Z</published>
    <title>Qualitative Robustness of Support Vector Machines</title>
    <summary>  Support vector machines have attracted much attention in theoretical and in
applied statistics. Main topics of recent interest are consistency, learning
rates and robustness. In this article, it is shown that support vector machines
are qualitatively robust. Since support vector machines can be represented by a
functional on the set of all probability measures, qualitative robustness is
proven by showing that this functional is continuous with respect to the
topology generated by weak convergence of probability measures. Combined with
the existence and uniqueness of support vector machines, our results show that
support vector machines are the solutions of a well-posed mathematical problem
in Hadamard's sense.
</summary>
    <author>
      <name>Robert Hable</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Bayreuth</arxiv:affiliation>
    </author>
    <author>
      <name>Andreas Christmann</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Bayreuth</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/0912.0874v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0912.0874v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62G08, 62G35" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0912.3604v2</id>
    <updated>2010-10-03T18:23:08Z</updated>
    <published>2009-12-18T08:06:06Z</published>
    <title>A Geometric Proof of Calibration</title>
    <summary>  We provide yet another proof of the existence of calibrated forecasters; it
has two merits. First, it is valid for an arbitrary finite number of outcomes.
Second, it is short and simple and it follows from a direct application of
Blackwell's approachability theorem to carefully chosen vector-valued payoff
function and convex target set. Our proof captures the essence of existing
proofs based on approachability (e.g., the proof by Foster, 1999 in case of
binary outcomes) and highlights the intrinsic connection between
approachability and calibration.
</summary>
    <author>
      <name>Shie Mannor</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">EE-Technion</arxiv:affiliation>
    </author>
    <author>
      <name>Gilles Stoltz</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">DMA, GREGH</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/0912.3604v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0912.3604v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1001.4019v1</id>
    <updated>2010-01-22T15:20:11Z</updated>
    <published>2010-01-22T15:20:11Z</published>
    <title>Classifying Network Data with Deep Kernel Machines</title>
    <summary>  Inspired by a growing interest in analyzing network data, we study the
problem of node classification on graphs, focusing on approaches based on
kernel machines. Conventionally, kernel machines are linear classifiers in the
implicit feature space. We argue that linear classification in the feature
space of kernels commonly used for graphs is often not enough to produce good
results. When this is the case, one naturally considers nonlinear classifiers
in the feature space. We show that repeating this process produces something we
call "deep kernel machines." We provide some examples where deep kernel
machines can make a big difference in classification performance, and point out
some connections to various recent literature on deep architectures in
artificial intelligence and machine learning.
</summary>
    <author>
      <name>Xiao Tang</name>
    </author>
    <author>
      <name>Mu Zhu</name>
    </author>
    <link href="http://arxiv.org/abs/1001.4019v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1001.4019v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1002.0832v1</id>
    <updated>2010-02-03T20:42:49Z</updated>
    <published>2010-02-03T20:42:49Z</published>
    <title>K-Dimensional Coding Schemes in Hilbert Spaces</title>
    <summary>  This paper presents a general coding method where data in a Hilbert space are
represented by finite dimensional coding vectors. The method is based on
empirical risk minimization within a certain class of linear operators, which
map the set of coding vectors to the Hilbert space. Two results bounding the
expected reconstruction error of the method are derived, which highlight the
role played by the codebook and the class of linear operators. The results are
specialized to some cases of practical importance, including K-means
clustering, nonnegative matrix factorization and other sparse coding methods.
</summary>
    <author>
      <name>Andreas Maurer Massimiliano Pontil</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE Transactions on Information Theory, 56(11): 5839-5846, 2010</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1002.0832v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1002.0832v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1002.3744v1</id>
    <updated>2010-02-19T13:48:57Z</updated>
    <published>2010-02-19T13:48:57Z</published>
    <title>Plugin procedure in segmentation and application to hyperspectral image
  segmentation</title>
    <summary>  In this article we give our contribution to the problem of segmentation with
plug-in procedures. We give general sufficient conditions under which plug in
procedure are efficient. We also give an algorithm that satisfy these
conditions. We give an application of the used algorithm to hyperspectral
images segmentation. Hyperspectral images are images that have both spatial and
spectral coherence with thousands of spectral bands on each pixel. In the
proposed procedure we combine a reduction dimension technique and a spatial
regularisation technique. This regularisation is based on the mixlet
modelisation of Kolaczyck and Al.
</summary>
    <author>
      <name>R. Girard</name>
    </author>
    <link href="http://arxiv.org/abs/1002.3744v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1002.3744v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1003.0060v1</id>
    <updated>2010-02-27T04:38:43Z</updated>
    <published>2010-02-27T04:38:43Z</published>
    <title>Comment on "Fastest learning in small-world neural networks"</title>
    <summary>  This comment reexamines Simard et al.'s work in [D. Simard, L. Nadeau, H.
Kroger, Phys. Lett. A 336 (2005) 8-15]. We found that Simard et al. calculated
mistakenly the local connectivity lengths Dlocal of networks. The right results
of Dlocal are presented and the supervised learning performance of feedforward
neural networks (FNNs) with different rewirings are re-investigated in this
comment. This comment discredits Simard et al's work by two conclusions: 1)
Rewiring connections of FNNs cannot generate networks with small-world
connectivity; 2) For different training sets, there do not exist networks with
a certain number of rewirings generating reduced learning errors than networks
with other numbers of rewiring.
</summary>
    <author>
      <name>Z. X. Guo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1003.0060v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1003.0060v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1003.0783v1</id>
    <updated>2010-03-03T11:36:56Z</updated>
    <published>2010-03-03T11:36:56Z</published>
    <title>Supervised Topic Models</title>
    <summary>  We introduce supervised latent Dirichlet allocation (sLDA), a statistical
model of labelled documents. The model accommodates a variety of response
types. We derive an approximate maximum-likelihood procedure for parameter
estimation, which relies on variational methods to handle intractable posterior
expectations. Prediction problems motivate this research: we use the fitted
model to predict response values for new documents. We test sLDA on two
real-world problems: movie ratings predicted from reviews, and the political
tone of amendments in the U.S. Senate based on the amendment text. We
illustrate the benefits of sLDA versus modern regularized regression, as well
as versus an unsupervised LDA analysis followed by a separate regression.
</summary>
    <author>
      <name>David M. Blei</name>
    </author>
    <author>
      <name>Jon D. McAuliffe</name>
    </author>
    <link href="http://arxiv.org/abs/1003.0783v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1003.0783v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1003.2245v1</id>
    <updated>2010-03-11T03:05:59Z</updated>
    <published>2010-03-11T03:05:59Z</published>
    <title>Optimal Allocation Strategies for the Dark Pool Problem</title>
    <summary>  We study the problem of allocating stocks to dark pools. We propose and
analyze an optimal approach for allocations, if continuous-valued allocations
are allowed. We also propose a modification for the case when only
integer-valued allocations are possible. We extend the previous work on this
problem to adversarial scenarios, while also improving on their results in the
iid setup. The resulting algorithms are efficient, and perform well in
simulations under stochastic and adversarial inputs.
</summary>
    <author>
      <name>Alekh Agarwal</name>
    </author>
    <author>
      <name>Peter Bartlett</name>
    </author>
    <author>
      <name>Max Dama</name>
    </author>
    <link href="http://arxiv.org/abs/1003.2245v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1003.2245v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1004.0456v1</id>
    <updated>2010-04-03T16:28:47Z</updated>
    <published>2010-04-03T16:28:47Z</published>
    <title>Exploratory Analysis of Functional Data via Clustering and Optimal
  Segmentation</title>
    <summary>  We propose in this paper an exploratory analysis algorithm for functional
data. The method partitions a set of functions into $K$ clusters and represents
each cluster by a simple prototype (e.g., piecewise constant). The total number
of segments in the prototypes, $P$, is chosen by the user and optimally
distributed among the clusters via two dynamic programming algorithms. The
practical relevance of the method is shown on two real world datasets.
</summary>
    <author>
      <name>Georges Hébrail</name>
    </author>
    <author>
      <name>Bernard Hugueney</name>
    </author>
    <author>
      <name>Yves Lechevallier</name>
    </author>
    <author>
      <name>Fabrice Rossi</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.neucom.2009.11.022</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.neucom.2009.11.022" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Neurocomputing, Volume 73, Issues 7-9, March 2010, Pages 1125-1141</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1004.0456v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1004.0456v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1004.2304v1</id>
    <updated>2010-04-14T01:50:42Z</updated>
    <published>2010-04-14T01:50:42Z</published>
    <title>Spatio-Temporal Graphical Model Selection</title>
    <summary>  We consider the problem of estimating the topology of spatial interactions in
a discrete state, discrete time spatio-temporal graphical model where the
interactions affect the temporal evolution of each agent in a network. Among
other models, the susceptible, infected, recovered ($SIR$) model for
interaction events fall into this framework. We pose the problem as a structure
learning problem and solve it using an $\ell_1$-penalized likelihood convex
program. We evaluate the solution on a simulated spread of infectious over a
complex network. Our topology estimates outperform those of a standard spatial
Markov random field graphical model selection using $\ell_1$-regularized
logistic regression.
</summary>
    <author>
      <name>Patrick L. Harrington Jr.</name>
    </author>
    <author>
      <name>Alfred O. Hero III</name>
    </author>
    <link href="http://arxiv.org/abs/1004.2304v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1004.2304v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1004.3101v1</id>
    <updated>2010-04-19T06:17:19Z</updated>
    <published>2010-04-19T06:17:19Z</published>
    <title>Strong Consistency of Prototype Based Clustering in Probabilistic Space</title>
    <summary>  In this paper we formulate in general terms an approach to prove strong
consistency of the Empirical Risk Minimisation inductive principle applied to
the prototype or distance based clustering. This approach was motivated by the
Divisive Information-Theoretic Feature Clustering model in probabilistic space
with Kullback-Leibler divergence which may be regarded as a special case within
the Clustering Minimisation framework. Also, we propose clustering
regularization restricting creation of additional clusters which are not
significant or are not essentially different comparing with existing clusters.
</summary>
    <author>
      <name>Vladimir Nikulin</name>
    </author>
    <author>
      <name>Geoffrey J. McLachlan</name>
    </author>
    <link href="http://arxiv.org/abs/1004.3101v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1004.3101v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1005.0437v1</id>
    <updated>2010-05-04T06:05:51Z</updated>
    <published>2010-05-04T06:05:51Z</published>
    <title>A Unifying View of Multiple Kernel Learning</title>
    <summary>  Recent research on multiple kernel learning has lead to a number of
approaches for combining kernels in regularized risk minimization. The proposed
approaches include different formulations of objectives and varying
regularization strategies. In this paper we present a unifying general
optimization criterion for multiple kernel learning and show how existing
formulations are subsumed as special cases. We also derive the criterion's dual
representation, which is suitable for general smooth optimization algorithms.
Finally, we evaluate multiple kernel learning in this framework analytically
using a Rademacher complexity bound on the generalization error and empirically
in a set of experiments.
</summary>
    <author>
      <name>Marius Kloft</name>
    </author>
    <author>
      <name>Ulrich Rückert</name>
    </author>
    <author>
      <name>Peter L. Bartlett</name>
    </author>
    <link href="http://arxiv.org/abs/1005.0437v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1005.0437v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1005.0928v2</id>
    <updated>2011-01-31T14:03:39Z</updated>
    <published>2010-05-06T08:38:24Z</published>
    <title>Training linear ranking SVMs in linearithmic time using red-black trees</title>
    <summary>  We introduce an efficient method for training the linear ranking support
vector machine. The method combines cutting plane optimization with red-black
tree based approach to subgradient calculations, and has O(m*s+m*log(m)) time
complexity, where m is the number of training examples, and s the average
number of non-zero features per example. Best previously known training
algorithms achieve the same efficiency only for restricted special cases,
whereas the proposed approach allows any real valued utility scores in the
training data. Experiments demonstrate the superior scalability of the proposed
approach, when compared to the fastest existing RankSVM implementations.
</summary>
    <author>
      <name>Antti Airola</name>
    </author>
    <author>
      <name>Tapio Pahikkala</name>
    </author>
    <author>
      <name>Tapio Salakoski</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.patrec.2011.03.014</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.patrec.2011.03.014" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1005.0928v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1005.0928v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1005.1036v3</id>
    <updated>2011-06-28T09:14:14Z</updated>
    <published>2010-05-06T16:33:40Z</published>
    <title>Introduction to Graphical Modelling</title>
    <summary>  The aim of this chapter is twofold. In the first part we will provide a brief
overview of the mathematical and statistical foundations of graphical models,
along with their fundamental properties, estimation and basic inference
procedures. In particular we will develop Markov networks (also known as Markov
random fields) and Bayesian networks, which comprise most past and current
literature on graphical models. In the second part we will review some
applications of graphical models in systems biology.
</summary>
    <author>
      <name>Marco Scutari</name>
    </author>
    <author>
      <name>Korbinian Strimmer</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Handbook of Statistical Systems Biology (D. Balding, M. Stumpf, M.
  Girolami, eds.), Wiley. 21 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1005.1036v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1005.1036v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1005.2263v2</id>
    <updated>2011-05-30T11:22:44Z</updated>
    <published>2010-05-13T07:02:54Z</published>
    <title>Context models on sequences of covers</title>
    <summary>  We present a class of models that, via a simple construction, enables exact,
incremental, non-parametric, polynomial-time, Bayesian inference of conditional
measures. The approach relies upon creating a sequence of covers on the
conditioning variable and maintaining a different model for each set within a
cover. Inference remains tractable by specifying the probabilistic model in
terms of a random walk within the sequence of covers. We demonstrate the
approach on problems of conditional density estimation, which, to our knowledge
is the first closed-form, non-parametric Bayesian approach to this problem.
</summary>
    <author>
      <name>Christos Dimitrakakis</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1005.2263v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1005.2263v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1007.0549v3</id>
    <updated>2011-09-28T18:14:13Z</updated>
    <published>2010-07-04T13:11:40Z</published>
    <title>Minimax Manifold Estimation</title>
    <summary>  We find the minimax rate of convergence in Hausdorff distance for estimating
a manifold M of dimension d embedded in R^D given a noisy sample from the
manifold. We assume that the manifold satisfies a smoothness condition and that
the noise distribution has compact support. We show that the optimal rate of
convergence is n^{-2/(2+d)}. Thus, the minimax rate depends only on the
dimension of the manifold, not on the dimension of the space in which M is
embedded.
</summary>
    <author>
      <name>Christopher Genovese</name>
    </author>
    <author>
      <name>Marco Perone-Pacifico</name>
    </author>
    <author>
      <name>Isabella Verdinelli</name>
    </author>
    <author>
      <name>Larry Wasserman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">journal submission, revision with some errors corrected</arxiv:comment>
    <link href="http://arxiv.org/abs/1007.0549v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1007.0549v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1007.0832v1</id>
    <updated>2010-07-06T08:36:21Z</updated>
    <published>2010-07-06T08:36:21Z</published>
    <title>Euclidean Distances, soft and spectral Clustering on Weighted Graphs</title>
    <summary>  We define a class of Euclidean distances on weighted graphs, enabling to
perform thermodynamic soft graph clustering. The class can be constructed form
the "raw coordinates" encountered in spectral clustering, and can be extended
by means of higher-dimensional embeddings (Schoenberg transformations).
Geographical flow data, properly conditioned, illustrate the procedure as well
as visualization aspects.
</summary>
    <author>
      <name>François Bavaud</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-642-15880-3</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-642-15880-3" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">accepted for presentation (and further publication) at the ECML PKDD
  2010 conference</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ECML PKDD 2010, J.L. Balc\'azar et al. (Eds.): ECML PKDD 2010,
  Part I, LNAI 6321, pp. 103-118</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1007.0832v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1007.0832v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1007.1075v1</id>
    <updated>2010-07-07T08:31:17Z</updated>
    <published>2010-07-07T08:31:17Z</published>
    <title>Clustering Stability: An Overview</title>
    <summary>  A popular method for selecting the number of clusters is based on stability
arguments: one chooses the number of clusters such that the corresponding
clustering results are "most stable". In recent years, a series of papers has
analyzed the behavior of this method from a theoretical point of view. However,
the results are very technical and difficult to interpret for non-experts. In
this paper we give a high-level overview about the existing literature on
clustering stability. In addition to presenting the results in a slightly
informal but accessible way, we relate them to each other and discuss their
different implications.
</summary>
    <author>
      <name>Ulrike von Luxburg</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1561/2200000008</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1561/2200000008" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Foundations and Trends in Machine Learning, Vol. 2, No. 3, p.
  235-274, 2010</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1007.1075v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1007.1075v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1007.3098v3</id>
    <updated>2012-05-09T23:07:29Z</updated>
    <published>2010-07-19T09:30:19Z</published>
    <title>Reduced Rank Vector Generalized Linear Models for Feature Extraction</title>
    <summary>  Supervised linear feature extraction can be achieved by fitting a reduced
rank multivariate model. This paper studies rank penalized and rank constrained
vector generalized linear models. From the perspective of thresholding rules,
we build a framework for fitting singular value penalized models and use it for
feature extraction. Through solving the rank constraint form of the problem, we
propose progressive feature space reduction for fast computation in high
dimensions with little performance loss. A novel projective cross-validation is
proposed for parameter tuning in such nonconvex setups. Real data applications
are given to show the power of the methodology in supervised dimension
reduction and feature extraction.
</summary>
    <author>
      <name>Yiyuan She</name>
    </author>
    <link href="http://arxiv.org/abs/1007.3098v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1007.3098v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1008.2277v1</id>
    <updated>2010-08-13T10:03:48Z</updated>
    <published>2010-08-13T10:03:48Z</published>
    <title>Faithfulness in Chain Graphs: The Gaussian Case</title>
    <summary>  This paper deals with chain graphs under the classic
Lauritzen-Wermuth-Frydenberg interpretation. We prove that the regular Gaussian
distributions that factorize with respect to a chain graph $G$ with $d$
parameters have positive Lebesgue measure with respect to $\mathbb{R}^d$,
whereas those that factorize with respect to $G$ but are not faithful to it
have zero Lebesgue measure with respect to $\mathbb{R}^d$. This means that, in
the measure-theoretic sense described, almost all the regular Gaussian
distributions that factorize with respect to $G$ are faithful to it.
</summary>
    <author>
      <name>Jose M. Peña</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 14th International Conference on Artificial
  Intelligence and Statistics (AISTATS 2011), 588-599</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1008.2277v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1008.2277v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62H05, 60E05, 68T30" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1008.2908v1</id>
    <updated>2010-08-17T14:47:31Z</updated>
    <published>2010-08-17T14:47:31Z</published>
    <title>A unifying view for performance measures in multi-class prediction</title>
    <summary>  In the last few years, many different performance measures have been
introduced to overcome the weakness of the most natural metric, the Accuracy.
Among them, Matthews Correlation Coefficient has recently gained popularity
among researchers not only in machine learning but also in several application
fields such as bioinformatics. Nonetheless, further novel functions are being
proposed in literature. We show that Confusion Entropy, a recently introduced
classifier performance measure for multi-class problems, has a strong
(monotone) relation with the multi-class generalization of a classical metric,
the Matthews Correlation Coefficient. Computational evidence in support of the
claim is provided, together with an outline of the theoretical explanation.
</summary>
    <author>
      <name>Giuseppe Jurman</name>
    </author>
    <author>
      <name>Cesare Furlanello</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1371/journal.pone.0041882</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1371/journal.pone.0041882" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">PLoS ONE 7(8): e41882 (2012)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1008.2908v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1008.2908v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1008.3951v3</id>
    <updated>2010-09-03T08:16:47Z</updated>
    <published>2010-08-24T02:47:00Z</published>
    <title>A Simple CW-SSIM Kernel-based Nearest Neighbor Method for Handwritten
  Digit Classification</title>
    <summary>  We propose a simple kernel based nearest neighbor approach for handwritten
digit classification. The "distance" here is actually a kernel defining the
similarity between two images. We carefully study the effects of different
number of neighbors and weight schemes and report the results. With only a few
nearest neighbors (or most similar images) to vote, the test set error rate on
MNIST database could reach about 1.5%-2.0%, which is very close to many
advanced models.
</summary>
    <author>
      <name>Jiheng Wang</name>
    </author>
    <author>
      <name>Guangzhe Fan</name>
    </author>
    <author>
      <name>Zhou Wang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 11 figures, 1 table and 3 equations</arxiv:comment>
    <link href="http://arxiv.org/abs/1008.3951v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1008.3951v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1008.5386v1</id>
    <updated>2010-08-31T18:51:43Z</updated>
    <published>2010-08-31T18:51:43Z</published>
    <title>Mixed Cumulative Distribution Networks</title>
    <summary>  Directed acyclic graphs (DAGs) are a popular framework to express
multivariate probability distributions. Acyclic directed mixed graphs (ADMGs)
are generalizations of DAGs that can succinctly capture much richer sets of
conditional independencies, and are especially useful in modeling the effects
of latent variables implicitly. Unfortunately there are currently no good
parameterizations of general ADMGs. In this paper, we apply recent work on
cumulative distribution networks and copulas to propose one one general
construction for ADMG models. We consider a simple parameter estimation
approach, and report some encouraging experimental results.
</summary>
    <author>
      <name>Ricardo Silva</name>
    </author>
    <author>
      <name>Charles Blundell</name>
    </author>
    <author>
      <name>Yee Whye Teh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1008.5386v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1008.5386v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1009.0571v3</id>
    <updated>2011-11-20T07:11:57Z</updated>
    <published>2010-09-03T02:49:20Z</published>
    <title>Information-theoretic lower bounds on the oracle complexity of
  stochastic convex optimization</title>
    <summary>  Relative to the large literature on upper bounds on complexity of convex
optimization, lesser attention has been paid to the fundamental hardness of
these problems. Given the extensive use of convex optimization in machine
learning and statistics, gaining an understanding of these complexity-theoretic
issues is important. In this paper, we study the complexity of stochastic
convex optimization in an oracle model of computation. We improve upon known
results and obtain tight minimax complexity estimates for various function
classes.
</summary>
    <author>
      <name>Alekh Agarwal</name>
    </author>
    <author>
      <name>Peter L. Bartlett</name>
    </author>
    <author>
      <name>Pradeep Ravikumar</name>
    </author>
    <author>
      <name>Martin J. Wainwright</name>
    </author>
    <link href="http://arxiv.org/abs/1009.0571v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1009.0571v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1009.1318v1</id>
    <updated>2010-09-07T14:57:15Z</updated>
    <published>2010-09-07T14:57:15Z</published>
    <title>Optimizing an Organized Modularity Measure for Topographic Graph
  Clustering: a Deterministic Annealing Approach</title>
    <summary>  This paper proposes an organized generalization of Newman and Girvan's
modularity measure for graph clustering. Optimized via a deterministic
annealing scheme, this measure produces topologically ordered graph clusterings
that lead to faithful and readable graph representations based on clustering
induced graphs. Topographic graph clustering provides an alternative to more
classical solutions in which a standard graph clustering method is applied to
build a simpler graph that is then represented with a graph layout algorithm. A
comparative study on four real world graphs ranging from 34 to 1 133 vertices
shows the interest of the proposed approach with respect to classical solutions
and to self-organizing maps for graphs.
</summary>
    <author>
      <name>Fabrice Rossi</name>
    </author>
    <author>
      <name>Nathalie Villa-Vialaneix</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.neucom.2009.11.023</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.neucom.2009.11.023" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Neurocomputing, 73(7--9):1142--1163, March 2010</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1009.1318v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1009.1318v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1010.2770v1</id>
    <updated>2010-10-13T20:48:30Z</updated>
    <published>2010-10-13T20:48:30Z</published>
    <title>Online Multiple Kernel Learning for Structured Prediction</title>
    <summary>  Despite the recent progress towards efficient multiple kernel learning (MKL),
the structured output case remains an open research front. Current approaches
involve repeatedly solving a batch learning problem, which makes them
inadequate for large scale scenarios. We propose a new family of online
proximal algorithms for MKL (as well as for group-lasso and variants thereof),
which overcomes that drawback. We show regret, convergence, and generalization
bounds for the proposed method. Experiments on handwriting recognition and
dependency parsing testify for the successfulness of the approach.
</summary>
    <author>
      <name>Andre F. T. Martins</name>
    </author>
    <author>
      <name>Mario A. T. Figueiredo</name>
    </author>
    <author>
      <name>Pedro M. Q. Aguiar</name>
    </author>
    <author>
      <name>Noah A. Smith</name>
    </author>
    <author>
      <name>Eric P. Xing</name>
    </author>
    <link href="http://arxiv.org/abs/1010.2770v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1010.2770v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1010.4945v1</id>
    <updated>2010-10-24T09:11:40Z</updated>
    <published>2010-10-24T09:11:40Z</published>
    <title>f-divergence estimation and two-sample homogeneity test under
  semiparametric density-ratio models</title>
    <summary>  A density ratio is defined by the ratio of two probability densities. We
study the inference problem of density ratios and apply a semi-parametric
density-ratio estimator to the two-sample homogeneity test. In the proposed
test procedure, the f-divergence between two probability densities is estimated
using a density-ratio estimator. The f-divergence estimator is then exploited
for the two-sample homogeneity test. We derive the optimal estimator of
f-divergence in the sense of the asymptotic variance, and then investigate the
relation between the proposed test procedure and the existing score test based
on empirical likelihood estimator. Through numerical studies, we illustrate the
adequacy of the asymptotic theory for finite-sample inference.
</summary>
    <author>
      <name>Takafumi Kanamori</name>
    </author>
    <author>
      <name>Taiji Suzuki</name>
    </author>
    <author>
      <name>Masashi Sugiyama</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">28 pages, 3 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1010.4945v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1010.4945v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1011.5142v1</id>
    <updated>2010-11-23T16:12:33Z</updated>
    <published>2010-11-23T16:12:33Z</published>
    <title>Estimating Subagging by cross-validation</title>
    <summary>  In this article, we derive concentration inequalities for the
cross-validation estimate of the generalization error for subagged estimators,
both for classification and regressor. General loss functions and class of
predictors with both finite and infinite VC-dimension are considered. We
slightly generalize the formalism introduced by \cite{DUD03} to cover a large
variety of cross-validation procedures including leave-one-out
cross-validation, $k$-fold cross-validation, hold-out cross-validation (or
split sample), and the leave-$\upsilon$-out cross-validation.
  \bigskip
  \noindent An interesting consequence is that the probability upper bound is
bounded by the minimum of a Hoeffding-type bound and a Vapnik-type bounds, and
thus is smaller than 1 even for small learning set. Finally, we give a simple
rule on how to subbag the predictor. \bigskip
</summary>
    <author>
      <name>Matthieu CORNEC</name>
    </author>
    <link href="http://arxiv.org/abs/1011.5142v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1011.5142v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1101.4439v2</id>
    <updated>2011-01-27T14:45:29Z</updated>
    <published>2011-01-24T03:39:57Z</published>
    <title>Reproducing Kernel Banach Spaces with the l1 Norm II: Error Analysis for
  Regularized Least Square Regression</title>
    <summary>  A typical approach in estimating the learning rate of a regularized learning
scheme is to bound the approximation error by the sum of the sampling error,
the hypothesis error and the regularization error. Using a reproducing kernel
space that satisfies the linear representer theorem brings the advantage of
discarding the hypothesis error from the sum automatically. Following this
direction, we illustrate how reproducing kernel Banach spaces with the l1 norm
can be applied to improve the learning rate estimate of l1-regularization in
machine learning.
</summary>
    <author>
      <name>Guohui Song</name>
    </author>
    <author>
      <name>Haizhang Zhang</name>
    </author>
    <link href="http://arxiv.org/abs/1101.4439v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1101.4439v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.FA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1101.5435v1</id>
    <updated>2011-01-28T03:32:01Z</updated>
    <published>2011-01-28T03:32:01Z</published>
    <title>An Analysis of the Convergence of Graph Laplacians</title>
    <summary>  Existing approaches to analyzing the asymptotics of graph Laplacians
typically assume a well-behaved kernel function with smoothness assumptions. We
remove the smoothness assumption and generalize the analysis of graph
Laplacians to include previously unstudied graphs including kNN graphs. We also
introduce a kernel-free framework to analyze graph constructions with shrinking
neighborhoods in general and apply it to analyze locally linear embedding
(LLE). We also describe how for a given limiting Laplacian operator desirable
properties such as a convergent spectrum and sparseness can be achieved
choosing the appropriate graph construction.
</summary>
    <author>
      <name>Daniel Ting</name>
    </author>
    <author>
      <name>Ling Huang</name>
    </author>
    <author>
      <name>Michael Jordan</name>
    </author>
    <link href="http://arxiv.org/abs/1101.5435v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1101.5435v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1102.5750v1</id>
    <updated>2011-02-28T19:31:41Z</updated>
    <published>2011-02-28T19:31:41Z</published>
    <title>Neyman-Pearson classification, convexity and stochastic constraints</title>
    <summary>  Motivated by problems of anomaly detection, this paper implements the
Neyman-Pearson paradigm to deal with asymmetric errors in binary classification
with a convex loss. Given a finite collection of classifiers, we combine them
and obtain a new classifier that satisfies simultaneously the two following
properties with high probability: (i) its probability of type I error is below
a pre-specified level and (ii), it has probability of type II error close to
the minimum possible. The proposed classifier is obtained by solving an
optimization problem with an empirical objective and an empirical constraint.
New techniques to handle such problems are developed and have consequences on
chance constrained programming.
</summary>
    <author>
      <name>Philippe Rigollet</name>
    </author>
    <author>
      <name>Xin Tong</name>
    </author>
    <link href="http://arxiv.org/abs/1102.5750v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1102.5750v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.0431v2</id>
    <updated>2011-07-13T13:24:28Z</updated>
    <published>2011-03-02T13:59:51Z</published>
    <title>Fast Convergence Rate of Multiple Kernel Learning with Elastic-net
  Regularization</title>
    <summary>  We investigate the learning rate of multiple kernel leaning (MKL) with
elastic-net regularization, which consists of an $\ell_1$-regularizer for
inducing the sparsity and an $\ell_2$-regularizer for controlling the
smoothness. We focus on a sparse setting where the total number of kernels is
large but the number of non-zero components of the ground truth is relatively
small, and prove that elastic-net MKL achieves the minimax learning rate on the
$\ell_2$-mixed-norm ball. Our bound is sharper than the convergence rates ever
shown, and has a property that the smoother the truth is, the faster the
convergence rate is.
</summary>
    <author>
      <name>Taiji Suzuki</name>
    </author>
    <author>
      <name>Ryota Tomioka</name>
    </author>
    <author>
      <name>Masashi Sugiyama</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages, 0 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1103.0431v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.0431v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.0790v1</id>
    <updated>2011-03-03T21:29:00Z</updated>
    <published>2011-03-03T21:29:00Z</published>
    <title>The Local Rademacher Complexity of Lp-Norm Multiple Kernel Learning</title>
    <summary>  We derive an upper bound on the local Rademacher complexity of $\ell_p$-norm
multiple kernel learning, which yields a tighter excess risk bound than global
approaches. Previous local approaches aimed at analyzed the case $p=1$ only
while our analysis covers all cases $1\leq p\leq\infty$, assuming the different
feature mappings corresponding to the different kernels to be uncorrelated. We
also show a lower bound that shows that the bound is tight, and derive
consequences regarding excess loss, namely fast convergence rates of the order
$O(n^{-\frac{\alpha}{1+\alpha}})$, where $\alpha$ is the minimum eigenvalue
decay rate of the individual kernels.
</summary>
    <author>
      <name>Marius Kloft</name>
    </author>
    <author>
      <name>Gilles Blanchard</name>
    </author>
    <link href="http://arxiv.org/abs/1103.0790v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.0790v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.0897v3</id>
    <updated>2012-06-07T17:54:06Z</updated>
    <published>2011-03-04T13:32:28Z</published>
    <title>Multiple Kernel Learning: A Unifying Probabilistic Viewpoint</title>
    <summary>  We present a probabilistic viewpoint to multiple kernel learning unifying
well-known regularised risk approaches and recent advances in approximate
Bayesian inference relaxations. The framework proposes a general objective
function suitable for regression, robust regression and classification that is
lower bound of the marginal likelihood and contains many regularised risk
approaches as special cases. Furthermore, we derive an efficient and provably
convergent optimisation algorithm.
</summary>
    <author>
      <name>Hannes Nickisch</name>
    </author>
    <author>
      <name>Matthias Seeger</name>
    </author>
    <link href="http://arxiv.org/abs/1103.0897v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.0897v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.0941v1</id>
    <updated>2011-03-04T16:29:04Z</updated>
    <published>2011-03-04T16:29:04Z</published>
    <title>Estimating $β$-mixing coefficients</title>
    <summary>  The literature on statistical learning for time series assumes the asymptotic
independence or ``mixing' of the data-generating process. These mixing
assumptions are never tested, nor are there methods for estimating mixing rates
from data. We give an estimator for the $\beta$-mixing rate based on a single
stationary sample path and show it is $L_1$-risk consistent.
</summary>
    <author>
      <name>Daniel J. McDonald</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Carnegie Mellon University</arxiv:affiliation>
    </author>
    <author>
      <name>Cosma Rohilla Shalizi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Carnegie Mellon University</arxiv:affiliation>
    </author>
    <author>
      <name>Mark Schervish</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Carnegie Mellon University</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, accepted by AIStats. CMU Statistics Technical Report</arxiv:comment>
    <link href="http://arxiv.org/abs/1103.0941v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.0941v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.4998v1</id>
    <updated>2011-03-25T15:35:16Z</updated>
    <published>2011-03-25T15:35:16Z</published>
    <title>Sufficient Component Analysis for Supervised Dimension Reduction</title>
    <summary>  The purpose of sufficient dimension reduction (SDR) is to find the
low-dimensional subspace of input features that is sufficient for predicting
output values. In this paper, we propose a novel distribution-free SDR method
called sufficient component analysis (SCA), which is computationally more
efficient than existing methods. In our method, a solution is computed by
iteratively performing dependence estimation and maximization: Dependence
estimation is analytically carried out by recently-proposed least-squares
mutual information (LSMI), and dependence maximization is also analytically
carried out by utilizing the Epanechnikov kernel. Through large-scale
experiments on real-world image classification and audio tagging problems, the
proposed method is shown to compare favorably with existing dimension reduction
approaches.
</summary>
    <author>
      <name>Makoto Yamada</name>
    </author>
    <author>
      <name>Gang Niu</name>
    </author>
    <author>
      <name>Jun Takagi</name>
    </author>
    <author>
      <name>Masashi Sugiyama</name>
    </author>
    <link href="http://arxiv.org/abs/1103.4998v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.4998v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.5202v2</id>
    <updated>2011-07-13T13:22:29Z</updated>
    <published>2011-03-27T11:49:44Z</published>
    <title>Fast Learning Rate of lp-MKL and its Minimax Optimality</title>
    <summary>  In this paper, we give a new sharp generalization bound of lp-MKL which is a
generalized framework of multiple kernel learning (MKL) and imposes
lp-mixed-norm regularization instead of l1-mixed-norm regularization. We
utilize localization techniques to obtain the sharp learning rate. The bound is
characterized by the decay rate of the eigenvalues of the associated kernels. A
larger decay rate gives a faster convergence rate. Furthermore, we give the
minimax learning rate on the ball characterized by lp-mixed-norm in the product
space. Then we show that our derived learning rate of lp-MKL achieves the
minimax optimal rate on the lp-mixed-norm ball.
</summary>
    <author>
      <name>Taiji Suzuki</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, submitted to COLT2011</arxiv:comment>
    <link href="http://arxiv.org/abs/1103.5202v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.5202v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1104.1992v1</id>
    <updated>2011-04-11T16:45:47Z</updated>
    <published>2011-04-11T16:45:47Z</published>
    <title>Unified Treatment of Hidden Markov Switching Models</title>
    <summary>  Many real-world problems encountered in several disciplines deal with the
modeling of time-series containing different underlying dynamical regimes, for
which probabilistic approaches are very often employed. In this paper we
describe several such approaches in the common framework of graphical models.
We give a unified overview of models previously introduced in the literature,
which is simpler and more comprehensive than previous descriptions and enables
us to highlight commonalities and differences among models that were not
observed in the past. In addition, we present several new models and inference
routines, which are naturally derived within this unified viewpoint.
</summary>
    <author>
      <name>Silvia Chiappa</name>
    </author>
    <link href="http://arxiv.org/abs/1104.1992v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1104.1992v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1104.5341v2</id>
    <updated>2011-11-30T07:47:30Z</updated>
    <published>2011-04-28T10:02:17Z</published>
    <title>Joint estimation of linear non-Gaussian acyclic models</title>
    <summary>  A linear non-Gaussian structural equation model called LiNGAM is an
identifiable model for exploratory causal analysis. Previous methods estimate a
causal ordering of variables and their connection strengths based on a single
dataset. However, in many application domains, data are obtained under
different conditions, that is, multiple datasets are obtained rather than a
single dataset. In this paper, we present a new method to jointly estimate
multiple LiNGAMs under the assumption that the models share a causal ordering
but may have different connection strengths and differently distributed
variables. In simulations, the new method estimates the models more accurately
than estimating them separately.
</summary>
    <author>
      <name>Shohei Shimizu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">A revised version was accepted in Neurocomputing</arxiv:comment>
    <link href="http://arxiv.org/abs/1104.5341v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1104.5341v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1105.0875v2</id>
    <updated>2013-05-31T16:52:11Z</updated>
    <published>2011-05-04T17:25:52Z</published>
    <title>A Risk Comparison of Ordinary Least Squares vs Ridge Regression</title>
    <summary>  We compare the risk of ridge regression to a simple variant of ordinary least
squares, in which one simply projects the data onto a finite dimensional
subspace (as specified by a Principal Component Analysis) and then performs an
ordinary (un-regularized) least squares regression in this subspace. This note
shows that the risk of this ordinary least squares method is within a constant
factor (namely 4) of the risk of ridge regression.
</summary>
    <author>
      <name>Paramveer S. Dhillon</name>
    </author>
    <author>
      <name>Dean P. Foster</name>
    </author>
    <author>
      <name>Sham M. Kakade</name>
    </author>
    <author>
      <name>Lyle H. Ungar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appearing in JMLR 14, June 2013</arxiv:comment>
    <link href="http://arxiv.org/abs/1105.0875v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1105.0875v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1105.2952v3</id>
    <updated>2012-01-30T06:31:45Z</updated>
    <published>2011-05-15T16:05:11Z</published>
    <title>Bounds on the Bayes Error Given Moments</title>
    <summary>  We show how to compute lower bounds for the supremum Bayes error if the
class-conditional distributions must satisfy moment constraints, where the
supremum is with respect to the unknown class-conditional distributions. Our
approach makes use of Curto and Fialkow's solutions for the truncated moment
problem. The lower bound shows that the popular Gaussian assumption is not
robust in this regard. We also construct an upper bound for the supremum Bayes
error by constraining the decision boundary to be linear.
</summary>
    <author>
      <name>Bela A. Frigyik</name>
    </author>
    <author>
      <name>Maya R. Gupta</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 2 figures, to appear in IEEE Transactions on Information
  Theory</arxiv:comment>
    <link href="http://arxiv.org/abs/1105.2952v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1105.2952v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1106.0565v2</id>
    <updated>2011-12-05T16:43:49Z</updated>
    <published>2011-06-03T04:49:53Z</published>
    <title>Multi-stage Convex Relaxation for Feature Selection</title>
    <summary>  A number of recent work studied the effectiveness of feature selection using
Lasso. It is known that under the restricted isometry properties (RIP), Lasso
does not generally lead to the exact recovery of the set of nonzero
coefficients, due to the looseness of convex relaxation. This paper considers
the feature selection property of nonconvex regularization, where the solution
is given by a multi-stage convex relaxation scheme. Under appropriate
conditions, we show that the local solution obtained by this procedure recovers
the set of nonzero coefficients without suffering from the bias of Lasso
relaxation, which complements parameter estimation results of this procedure.
</summary>
    <author>
      <name>Tong Zhang</name>
    </author>
    <link href="http://arxiv.org/abs/1106.0565v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1106.0565v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1106.0730v2</id>
    <updated>2017-05-22T22:40:23Z</updated>
    <published>2011-06-03T19:09:31Z</published>
    <title>Rademacher complexity of stationary sequences</title>
    <summary>  We show how to control the generalization error of time series models wherein
past values of the outcome are used to predict future values. The results are
based on a generalization of standard i.i.d. concentration inequalities to
dependent data without the mixing assumptions common in the time series
setting. Our proof and the result are simpler than previous analyses with
dependent data or stochastic adversaries which use sequential Rademacher
complexities rather than the expected Rademacher complexity for i.i.d.
processes. We also derive empirical Rademacher results without mixing
assumptions resulting in fully calculable upper bounds.
</summary>
    <author>
      <name>Daniel J. McDonald</name>
    </author>
    <author>
      <name>Cosma Rohilla Shalizi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1106.0730v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1106.0730v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1106.1674v1</id>
    <updated>2011-06-08T21:26:42Z</updated>
    <published>2011-06-08T21:26:42Z</published>
    <title>Moment based estimation of stochastic Kronecker graph parameters</title>
    <summary>  Stochastic Kronecker graphs supply a parsimonious model for large sparse real
world graphs. They can specify the distribution of a large random graph using
only three or four parameters. Those parameters have however proved difficult
to choose in specific applications. This article looks at method of moments
estimators that are computationally much simpler than maximum likelihood. The
estimators are fast and in our examples, they typically yield Kronecker
parameters with expected feature counts closer to a given graph than we get
from KronFit. The improvement was especially prominent for the number of
triangles in the graph.
</summary>
    <author>
      <name>David F. Gleich</name>
    </author>
    <author>
      <name>Art B. Owen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">22 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1106.1674v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1106.1674v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="63P99, 91D30" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1106.2494v2</id>
    <updated>2011-06-16T11:06:04Z</updated>
    <published>2011-06-13T17:23:50Z</published>
    <title>Pitman-Yor Diffusion Trees</title>
    <summary>  We introduce the Pitman Yor Diffusion Tree (PYDT) for hierarchical
clustering, a generalization of the Dirichlet Diffusion Tree (Neal, 2001) which
removes the restriction to binary branching structure. The generative process
is described and shown to result in an exchangeable distribution over data
points. We prove some theoretical properties of the model and then present two
inference methods: a collapsed MCMC sampler which allows us to model
uncertainty over tree structures, and a computationally efficient greedy
Bayesian EM search algorithm. Both algorithms use message passing on the tree
structure. The utility of the model and algorithms is demonstrated on synthetic
and real world data, both continuous and binary.
</summary>
    <author>
      <name>David A. Knowles</name>
    </author>
    <author>
      <name>Zoubin Ghahramani</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, to be presented at UAI 2011</arxiv:comment>
    <link href="http://arxiv.org/abs/1106.2494v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1106.2494v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62G07, 62H30" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.3.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1106.2697v2</id>
    <updated>2011-08-04T04:04:45Z</updated>
    <published>2011-06-14T12:51:54Z</published>
    <title>A Tutorial on Bayesian Nonparametric Models</title>
    <summary>  A key problem in statistical modeling is model selection, how to choose a
model at an appropriate level of complexity. This problem appears in many
settings, most prominently in choosing the number ofclusters in mixture models
or the number of factors in factor analysis. In this tutorial we describe
Bayesian nonparametric methods, a class of methods that side-steps this issue
by allowing the data to determine the complexity of the model. This tutorial is
a high-level introduction to Bayesian nonparametric methods and contains
several examples of their application.
</summary>
    <author>
      <name>Samuel J. Gershman</name>
    </author>
    <author>
      <name>David M. Blei</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">28 pages, 8 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1106.2697v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1106.2697v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1106.3834v1</id>
    <updated>2011-06-20T08:04:08Z</updated>
    <published>2011-06-20T08:04:08Z</published>
    <title>Dimensionally Constrained Symbolic Regression</title>
    <summary>  We describe dimensionally constrained symbolic regression which has been
developed for mass measurement in certain classes of events in high-energy
physics (HEP). With symbolic regression, we can derive equations that are well
known in HEP. However, in problems with large number of variables, we find that
by constraining the terms allowed in the symbolic regression, convergence
behavior is improved. Dimensionally constrained symbolic regression (DCSR)
finds solutions with much better fitness than is normally possible with
symbolic regression. In some cases, novel solutions are found.
</summary>
    <author>
      <name>Suyong Choi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Korea University</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/1106.3834v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1106.3834v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1106.4198v1</id>
    <updated>2011-06-21T13:34:06Z</updated>
    <published>2011-06-21T13:34:06Z</published>
    <title>Online algorithms for Nonnegative Matrix Factorization with the
  Itakura-Saito divergence</title>
    <summary>  Nonnegative matrix factorization (NMF) is now a common tool for audio source
separation. When learning NMF on large audio databases, one major drawback is
that the complexity in time is O(FKN) when updating the dictionary (where (F;N)
is the dimension of the input power spectrograms, and K the number of basis
spectra), thus forbidding its application on signals longer than an hour. We
provide an online algorithm with a complexity of O(FK) in time and memory for
updates in the dictionary. We show on audio simulations that the online
approach is faster for short audio signals and allows to analyze audio signals
of several hours.
</summary>
    <author>
      <name>Augustin Lefèvre</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Paris - Rocquencourt</arxiv:affiliation>
    </author>
    <author>
      <name>Francis Bach</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIENS</arxiv:affiliation>
    </author>
    <author>
      <name>Cédric Févotte</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LTCI</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/1106.4198v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1106.4198v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1106.5175v1</id>
    <updated>2011-06-25T21:38:55Z</updated>
    <published>2011-06-25T21:38:55Z</published>
    <title>Sparse Inverse Covariance Estimation via an Adaptive Gradient-Based
  Method</title>
    <summary>  We study the problem of estimating from data, a sparse approximation to the
inverse covariance matrix. Estimating a sparsity constrained inverse covariance
matrix is a key component in Gaussian graphical model learning, but one that is
numerically very challenging. We address this challenge by developing a new
adaptive gradient-based method that carefully combines gradient information
with an adaptive step-scaling strategy, which results in a scalable, highly
competitive method. Our algorithm, like its predecessors, maximizes an
$\ell_1$-norm penalized log-likelihood and has the same per iteration
arithmetic complexity as the best methods in its class. Our experiments reveal
that our approach outperforms state-of-the-art competitors, often significantly
so, for large problems.
</summary>
    <author>
      <name>Suvrit Sra</name>
    </author>
    <author>
      <name>Dongmin Kim</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1106.5175v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1106.5175v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1107.0521v3</id>
    <updated>2012-01-25T11:38:01Z</updated>
    <published>2011-07-04T04:09:03Z</published>
    <title>On a Rapid Simulation of the Dirichlet Process</title>
    <summary>  We describe a simple and efficient procedure for approximating the L\'evy
measure of a $\text{Gamma}(\alpha,1)$ random variable. We use this
approximation to derive a finite sum-representation that converges almost
surely to Ferguson's representation of the Dirichlet process based on arrivals
of a homogeneous Poisson process. We compare the efficiency of our
approximation to several other well known approximations of the Dirichlet
process and demonstrate a substantial improvement.
</summary>
    <author>
      <name>Mahmoud Zarepour</name>
    </author>
    <author>
      <name>Luai Al Labadi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Copy right regulations. The paper has been accepted</arxiv:comment>
    <link href="http://arxiv.org/abs/1107.0521v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1107.0521v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1107.2347v1</id>
    <updated>2011-07-12T16:56:14Z</updated>
    <published>2011-07-12T16:56:14Z</published>
    <title>BSVM: A Banded Suport Vector Machine</title>
    <summary>  We describe a novel binary classification technique called Banded SVM
(B-SVM). In the standard C-SVM formulation of Cortes et al. (1995), the
decision rule is encouraged to lie in the interval [1, \infty]. The new B-SVM
objective function contains a penalty term that encourages the decision rule to
lie in a user specified range [\rho_1, \rho_2]. In addition to the standard set
of support vectors (SVs) near the class boundaries, B-SVM results in a second
set of SVs in the interior of each class.
</summary>
    <author>
      <name>Gautam V. Pendse</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1107.2347v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1107.2347v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1107.4340v1</id>
    <updated>2011-07-21T18:44:51Z</updated>
    <published>2011-07-21T18:44:51Z</published>
    <title>Spectral approximations in machine learning</title>
    <summary>  In many areas of machine learning, it becomes necessary to find the
eigenvector decompositions of large matrices. We discuss two methods for
reducing the computational burden of spectral decompositions: the more
venerable Nystom extension and a newly introduced algorithm based on random
projections. Previous work has centered on the ability to reconstruct the
original matrix. We argue that a more interesting and relevant comparison is
their relative performance in clustering and classification tasks using the
approximate eigenvectors as features. We demonstrate that performance is task
specific and depends on the rank of the approximation.
</summary>
    <author>
      <name>Darren Homrighausen</name>
    </author>
    <author>
      <name>Daniel J. McDonald</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1107.4340v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1107.4340v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1107.4390v4</id>
    <updated>2012-08-24T22:35:38Z</updated>
    <published>2011-07-21T22:10:22Z</published>
    <title>Multi-Task Averaging</title>
    <summary>  We present a multi-task learning approach to jointly estimate the means of
multiple independent data sets. The proposed multi-task averaging (MTA)
algorithm results in a convex combination of the single-task maximum likelihood
estimates. We derive the optimal minimum risk estimator and the minimax
estimator, and show that these estimators can be efficiently estimated.
Simulations and real data experiments demonstrate that MTA estimators often
outperform both single-task and James-Stein estimators.
</summary>
    <author>
      <name>Sergey Feldman</name>
    </author>
    <author>
      <name>Bela A. Frigyik</name>
    </author>
    <author>
      <name>Maya R. Gupta</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">totally redone paper</arxiv:comment>
    <link href="http://arxiv.org/abs/1107.4390v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1107.4390v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1108.1766v1</id>
    <updated>2011-08-08T18:04:02Z</updated>
    <published>2011-08-08T18:04:02Z</published>
    <title>Activized Learning: Transforming Passive to Active with Improved Label
  Complexity</title>
    <summary>  We study the theoretical advantages of active learning over passive learning.
Specifically, we prove that, in noise-free classifier learning for VC classes,
any passive learning algorithm can be transformed into an active learning
algorithm with asymptotically strictly superior label complexity for all
nontrivial target functions and distributions. We further provide a general
characterization of the magnitudes of these improvements in terms of a novel
generalization of the disagreement coefficient. We also extend these results to
active learning in the presence of label noise, and find that even under broad
classes of noise distributions, we can typically guarantee strict improvements
over the known results for passive learning.
</summary>
    <author>
      <name>Steve Hanneke</name>
    </author>
    <link href="http://arxiv.org/abs/1108.1766v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1108.1766v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1108.2989v1</id>
    <updated>2011-08-15T13:26:26Z</updated>
    <published>2011-08-15T13:26:26Z</published>
    <title>A theory of multiclass boosting</title>
    <summary>  Boosting combines weak classifiers to form highly accurate predictors.
Although the case of binary classification is well understood, in the
multiclass setting, the "correct" requirements on the weak classifier, or the
notion of the most efficient boosting algorithms are missing. In this paper, we
create a broad and general framework, within which we make precise and identify
the optimal requirements on the weak-classifier, as well as design the most
effective, in a certain sense, boosting algorithms that assume such
requirements.
</summary>
    <author>
      <name>Indraneel Mukherjee</name>
    </author>
    <author>
      <name>Robert E. Schapire</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">A preliminary version appeared in NIPS 2010</arxiv:comment>
    <link href="http://arxiv.org/abs/1108.2989v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1108.2989v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1108.5397v1</id>
    <updated>2011-08-26T21:21:51Z</updated>
    <published>2011-08-26T21:21:51Z</published>
    <title>Prediction of peptide bonding affinity: kernel methods for nonlinear
  modeling</title>
    <summary>  This paper presents regression models obtained from a process of blind
prediction of peptide binding affinity from provided descriptors for several
distinct datasets as part of the 2006 Comparative Evaluation of Prediction
Algorithms (COEPRA) contest. This paper finds that kernel partial least
squares, a nonlinear partial least squares (PLS) algorithm, outperforms PLS,
and that the incorporation of transferable atom equivalent features improves
predictive capability.
</summary>
    <author>
      <name>Charles Bergeron</name>
    </author>
    <author>
      <name>Theresa Hepburn</name>
    </author>
    <author>
      <name>C. Matthew Sundling</name>
    </author>
    <author>
      <name>Michael Krein</name>
    </author>
    <author>
      <name>Bill Katt</name>
    </author>
    <author>
      <name>Nagamani Sukumar</name>
    </author>
    <author>
      <name>Curt M. Breneman</name>
    </author>
    <author>
      <name>Kristin P. Bennett</name>
    </author>
    <link href="http://arxiv.org/abs/1108.5397v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1108.5397v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1109.0455v1</id>
    <updated>2011-09-02T14:27:25Z</updated>
    <published>2011-09-02T14:27:25Z</published>
    <title>Gradient-based kernel dimension reduction for supervised learning</title>
    <summary>  This paper proposes a novel kernel approach to linear dimension reduction for
supervised learning. The purpose of the dimension reduction is to find
directions in the input space to explain the output as effectively as possible.
The proposed method uses an estimator for the gradient of regression function,
based on the covariance operators on reproducing kernel Hilbert spaces. In
comparison with other existing methods, the proposed one has wide applicability
without strong assumptions on the distributions or the type of variables, and
uses computationally simple eigendecomposition. Experimental results show that
the proposed method successfully finds the effective directions with efficient
computation.
</summary>
    <author>
      <name>Kenji Fukumizu</name>
    </author>
    <author>
      <name>Chenlei Leng</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1109.0455v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1109.0455v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1110.0413v1</id>
    <updated>2011-10-03T16:49:45Z</updated>
    <published>2011-10-03T16:49:45Z</published>
    <title>Group Lasso with Overlaps: the Latent Group Lasso approach</title>
    <summary>  We study a norm for structured sparsity which leads to sparse linear
predictors whose supports are unions of prede ned overlapping groups of
variables. We call the obtained formulation latent group Lasso, since it is
based on applying the usual group Lasso penalty on a set of latent variables. A
detailed analysis of the norm and its properties is presented and we
characterize conditions under which the set of groups associated with latent
variables are correctly identi ed. We motivate and discuss the delicate choice
of weights associated to each group, and illustrate this approach on simulated
data and on the problem of breast cancer prognosis from gene expression data.
</summary>
    <author>
      <name>Guillaume Obozinski</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIENS, INRIA Paris - Rocquencourt</arxiv:affiliation>
    </author>
    <author>
      <name>Laurent Jacob</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CBIO</arxiv:affiliation>
    </author>
    <author>
      <name>Jean-Philippe Vert</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CBIO</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/1110.0413v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1110.0413v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1110.1769v1</id>
    <updated>2011-10-08T21:24:36Z</updated>
    <published>2011-10-08T21:24:36Z</published>
    <title>On the trade-off between complexity and correlation decay in structural
  learning algorithms</title>
    <summary>  We consider the problem of learning the structure of Ising models (pairwise
binary Markov random fields) from i.i.d. samples. While several methods have
been proposed to accomplish this task, their relative merits and limitations
remain somewhat obscure. By analyzing a number of concrete examples, we show
that low-complexity algorithms often fail when the Markov random field develops
long-range correlations. More precisely, this phenomenon appears to be related
to the Ising model phase transition (although it does not coincide with it).
</summary>
    <author>
      <name>José Bento</name>
    </author>
    <author>
      <name>Andrea Montanari</name>
    </author>
    <link href="http://arxiv.org/abs/1110.1769v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1110.1769v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1110.5238v1</id>
    <updated>2011-10-24T14:01:26Z</updated>
    <published>2011-10-24T14:01:26Z</published>
    <title>Multiple Gaussian Process Models</title>
    <summary>  We consider a Gaussian process formulation of the multiple kernel learning
problem. The goal is to select the convex combination of kernel matrices that
best explains the data and by doing so improve the generalisation on unseen
data. Sparsity in the kernel weights is obtained by adopting a hierarchical
Bayesian approach: Gaussian process priors are imposed over the latent
functions and generalised inverse Gaussians on their associated weights. This
construction is equivalent to imposing a product of heavy-tailed process priors
over function space. A variational inference algorithm is derived for
regression and binary classification.
</summary>
    <author>
      <name>Cedric Archambeau</name>
    </author>
    <author>
      <name>Francis Bach</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">NIPS 2010 Workshop: New Directions in Multiple Kernel Learning;
  Videolectures: http://videolectures.net/nipsworkshops2010_archambeau_mgp/</arxiv:comment>
    <link href="http://arxiv.org/abs/1110.5238v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1110.5238v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.1830v1</id>
    <updated>2011-11-08T08:51:17Z</updated>
    <published>2011-11-08T08:51:17Z</published>
    <title>Estimation of scale functions to model heteroscedasticity by support
  vector machines</title>
    <summary>  A main goal of regression is to derive statistical conclusions on the
conditional distribution of the output variable Y given the input values x. Two
of the most important characteristics of a single distribution are location and
scale. Support vector machines (SVMs) are well established to estimate location
functions like the conditional median or the conditional mean. We investigate
the estimation of scale functions by SVMs when the conditional median is
unknown, too. Estimation of scale functions is important e.g. to estimate the
volatility in finance. We consider the median absolute deviation (MAD) and the
interquantile range (IQR) as measures of scale. Our main result shows the
consistency of MAD-type SVMs.
</summary>
    <author>
      <name>Robert Hable</name>
    </author>
    <author>
      <name>Andreas Christmann</name>
    </author>
    <link href="http://arxiv.org/abs/1111.1830v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.1830v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.3404v1</id>
    <updated>2011-11-15T01:44:12Z</updated>
    <published>2011-11-15T01:44:12Z</published>
    <title>Estimated VC dimension for risk bounds</title>
    <summary>  Vapnik-Chervonenkis (VC) dimension is a fundamental measure of the
generalization capacity of learning algorithms. However, apart from a few
special cases, it is hard or impossible to calculate analytically. Vapnik et
al. [10] proposed a technique for estimating the VC dimension empirically.
While their approach behaves well in simulations, it could not be used to bound
the generalization risk of classifiers, because there were no bounds for the
estimation error of the VC dimension itself. We rectify this omission,
providing high probability concentration results for the proposed estimator and
deriving corresponding generalization bounds.
</summary>
    <author>
      <name>Daniel J. McDonald</name>
    </author>
    <author>
      <name>Cosma Rohilla Shalizi</name>
    </author>
    <author>
      <name>Mark Schervish</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1111.3404v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.3404v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.5648v1</id>
    <updated>2011-11-23T23:25:57Z</updated>
    <published>2011-11-23T23:25:57Z</published>
    <title>Falsification and future performance</title>
    <summary>  We information-theoretically reformulate two measures of capacity from
statistical learning theory: empirical VC-entropy and empirical Rademacher
complexity. We show these capacity measures count the number of hypotheses
about a dataset that a learning algorithm falsifies when it finds the
classifier in its repertoire minimizing empirical risk. It then follows from
that the future performance of predictors on unseen data is controlled in part
by how many hypotheses the learner falsifies. As a corollary we show that
empirical VC-entropy quantifies the message length of the true hypothesis in
the optimal code of a particular probability distribution, the so-called actual
repertoire.
</summary>
    <author>
      <name>David Balduzzi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1111.5648v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.5648v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.6160v1</id>
    <updated>2011-11-26T13:43:40Z</updated>
    <published>2011-11-26T13:43:40Z</published>
    <title>Optimal exponential bounds on the accuracy of classification</title>
    <summary>  We consider a standard binary classification problem. The performance of any
binary classifier based on the training data is characterized by the excess
risk. We study Bahadur's type exponential bounds on the minimax accuracy
confidence function based on the excess risk. We study how this quantity
depends on the complexity of the class of distributions characterized by
exponents of entropies of the class of regression functions or of the class of
Bayes classifiers corresponding to the distributions from the class. We also
study its dependence on margin parameters of the classification problem.
</summary>
    <author>
      <name>N. I. Pentacaput</name>
    </author>
    <link href="http://arxiv.org/abs/1111.6160v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.6160v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62G08, 62G07, 62H05, 68T10" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.6285v2</id>
    <updated>2011-12-11T23:58:45Z</updated>
    <published>2011-11-27T18:39:14Z</published>
    <title>Ward's Hierarchical Clustering Method: Clustering Criterion and
  Agglomerative Algorithm</title>
    <summary>  The Ward error sum of squares hierarchical clustering method has been very
widely used since its first description by Ward in a 1963 publication. It has
also been generalized in various ways. However there are different
interpretations in the literature and there are different implementations of
the Ward agglomerative algorithm in commonly used software systems, including
differing expressions of the agglomerative criterion. Our survey work and case
studies will be useful for all those involved in developing software for data
analysis using Ward's hierarchical clustering method.
</summary>
    <author>
      <name>Fionn Murtagh</name>
    </author>
    <author>
      <name>Pierre Legendre</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s00357-014-9161-z</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s00357-014-9161-z" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages, 21 citations, 4 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Classification, 31 (3), 274-295, 2014</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1111.6285v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.6285v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62H30, 91C20" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.3; H.3.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1112.1217v1</id>
    <updated>2011-12-06T10:17:31Z</updated>
    <published>2011-12-06T10:17:31Z</published>
    <title>Entropy Search for Information-Efficient Global Optimization</title>
    <summary>  Contemporary global optimization algorithms are based on local measures of
utility, rather than a probability measure over location and value of the
optimum. They thus attempt to collect low function values, not to learn about
the optimum. The reason for the absence of probabilistic global optimizers is
that the corresponding inference problem is intractable in several ways. This
paper develops desiderata for probabilistic optimization algorithms, then
presents a concrete algorithm which addresses each of the computational
intractabilities with a sequence of approximations and explicitly adresses the
decision problem of maximizing information gain from each evaluation.
</summary>
    <author>
      <name>Philipp Hennig</name>
    </author>
    <author>
      <name>Christian J. Schuler</name>
    </author>
    <link href="http://arxiv.org/abs/1112.1217v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1112.1217v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1112.2288v1</id>
    <updated>2011-12-10T16:49:43Z</updated>
    <published>2011-12-10T16:49:43Z</published>
    <title>Asynchronous Stochastic Approximation with Differential Inclusions</title>
    <summary>  The asymptotic pseudo-trajectory approach to stochastic approximation of
Benaim, Hofbauer and Sorin is extended for asynchronous stochastic
approximations with a set-valued mean field. The asynchronicity of the process
is incorporated into the mean field to produce convergence results which remain
similar to those of an equivalent synchronous process. In addition, this allows
many of the restrictive assumptions previously associated with asynchronous
stochastic approximation to be removed. The framework is extended for a coupled
asynchronous stochastic approximation process with set-valued mean fields.
Two-timescales arguments are used here in a similar manner to the original work
in this area by Borkar. The applicability of this approach is demonstrated
through learning in a Markov decision process.
</summary>
    <author>
      <name>Steven Perkins</name>
    </author>
    <author>
      <name>David S. Leslie</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">41 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1112.2288v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1112.2288v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1112.2289v1</id>
    <updated>2011-12-10T17:04:01Z</updated>
    <published>2011-12-10T17:04:01Z</published>
    <title>Convergent Expectation Propagation in Linear Models with Spike-and-slab
  Priors</title>
    <summary>  Exact inference in the linear regression model with spike and slab priors is
often intractable. Expectation propagation (EP) can be used for approximate
inference. However, the regular sequential form of EP (R-EP) may fail to
converge in this model when the size of the training set is very small. As an
alternative, we propose a provably convergent EP algorithm (PC-EP). PC-EP is
proved to minimize an energy function which, under some constraints, is bounded
from below and whose stationary points coincide with the solution of R-EP.
Experiments with synthetic data indicate that when R-EP does not converge, the
approximation generated by PC-EP is often better. By contrast, when R-EP
converges, both methods perform similarly.
</summary>
    <author>
      <name>José Miguel Hernández-Lobato</name>
    </author>
    <author>
      <name>Daniel Hernández-Lobato</name>
    </author>
    <link href="http://arxiv.org/abs/1112.2289v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1112.2289v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1112.2679v1</id>
    <updated>2011-12-12T20:11:41Z</updated>
    <published>2011-12-12T20:11:41Z</published>
    <title>Truncated Power Method for Sparse Eigenvalue Problems</title>
    <summary>  This paper considers the sparse eigenvalue problem, which is to extract
dominant (largest) sparse eigenvectors with at most $k$ non-zero components. We
propose a simple yet effective solution called truncated power method that can
approximately solve the underlying nonconvex optimization problem. A strong
sparse recovery result is proved for the truncated power method, and this
theory is our key motivation for developing the new algorithm. The proposed
method is tested on applications such as sparse principal component analysis
and the densest $k$-subgraph problem. Extensive experiments on several
synthetic and real-world large scale datasets demonstrate the competitive
empirical performance of our method.
</summary>
    <author>
      <name>Xiao-Tong Yuan</name>
    </author>
    <author>
      <name>Tong Zhang</name>
    </author>
    <link href="http://arxiv.org/abs/1112.2679v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1112.2679v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1112.2738v1</id>
    <updated>2011-12-12T22:33:55Z</updated>
    <published>2011-12-12T22:33:55Z</published>
    <title>Robust Learning via Cause-Effect Models</title>
    <summary>  We consider the problem of function estimation in the case where the data
distribution may shift between training and test time, and additional
information about it may be available at test time. This relates to popular
scenarios such as covariate shift, concept drift, transfer learning and
semi-supervised learning. This working paper discusses how these tasks could be
tackled depending on the kind of changes of the distributions. It argues that
knowledge of an underlying causal direction can facilitate several of these
tasks.
</summary>
    <author>
      <name>Bernhard Schölkopf</name>
    </author>
    <author>
      <name>Dominik Janzing</name>
    </author>
    <author>
      <name>Jonas Peters</name>
    </author>
    <author>
      <name>Kun Zhang</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">A version of this paper has been published as "On Causal and
  Anticausal Learning" in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1112.2738v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1112.2738v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1112.5215v1</id>
    <updated>2011-12-22T01:16:20Z</updated>
    <published>2011-12-22T01:16:20Z</published>
    <title>Bilateral Random Projections</title>
    <summary>  Low-rank structure have been profoundly studied in data mining and machine
learning. In this paper, we show a dense matrix $X$'s low-rank approximation
can be rapidly built from its left and right random projections $Y_1=XA_1$ and
$Y_2=X^TA_2$, or bilateral random projection (BRP). We then show power scheme
can further improve the precision. The deterministic, average and deviation
bounds of the proposed method and its power scheme modification are proved
theoretically. The effectiveness and the efficiency of BRP based low-rank
approximation is empirically verified on both artificial and real datasets.
</summary>
    <author>
      <name>Tianyi Zhou</name>
    </author>
    <author>
      <name>Dacheng Tao</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages, 3 figures, technical report</arxiv:comment>
    <link href="http://arxiv.org/abs/1112.5215v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1112.5215v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1201.4002v1</id>
    <updated>2012-01-19T10:06:29Z</updated>
    <published>2012-01-19T10:06:29Z</published>
    <title>Adaptive Policies for Sequential Sampling under Incomplete Information
  and a Cost Constraint</title>
    <summary>  We consider the problem of sequential sampling from a finite number of
independent statistical populations to maximize the expected infinite horizon
average outcome per period, under a constraint that the expected average
sampling cost does not exceed an upper bound. The outcome distributions are not
known. We construct a class of consistent adaptive policies, under which the
average outcome converges with probability 1 to the true value under complete
information for all distributions with finite means. We also compare the rate
of convergence for various policies in this class using simulation.
</summary>
    <author>
      <name>Apostolos Burnetas</name>
    </author>
    <author>
      <name>Odysseas Kanavetas</name>
    </author>
    <link href="http://arxiv.org/abs/1201.4002v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1201.4002v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.3774v1</id>
    <updated>2012-02-14T16:41:17Z</updated>
    <published>2012-02-14T16:41:17Z</published>
    <title>Risk Bounds for Infinitely Divisible Distribution</title>
    <summary>  In this paper, we study the risk bounds for samples independently drawn from
an infinitely divisible (ID) distribution. In particular, based on a martingale
method, we develop two deviation inequalities for a sequence of random
variables of an ID distribution with zero Gaussian component. By applying the
deviation inequalities, we obtain the risk bounds based on the covering number
for the ID distribution. Finally, we analyze the asymptotic convergence of the
risk bound derived from one of the two deviation inequalities and show that the
convergence rate of the bound is faster than the result for the generic i.i.d.
empirical process (Mendelson, 2003).
</summary>
    <author>
      <name>Chao Zhang</name>
    </author>
    <author>
      <name>Dacheng Tao</name>
    </author>
    <link href="http://arxiv.org/abs/1202.3774v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.3774v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.5130v2</id>
    <updated>2013-01-12T20:43:14Z</updated>
    <published>2012-02-23T09:33:17Z</published>
    <title>Support Vector Regression for Right Censored Data</title>
    <summary>  We develop a unified approach for classification and regression support
vector machines for data subject to right censoring. We provide finite sample
bounds on the generalization error of the algorithm, prove risk consistency for
a wide class of probability measures, and study the associated learning rates.
We apply the general methodology to estimation of the (truncated) mean, median,
quantiles, and for classification problems. We present a simulation study that
demonstrates the performance of the proposed approach.
</summary>
    <author>
      <name>Yair Goldberg</name>
    </author>
    <author>
      <name>Michael R. Kosorok</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In this version, we strengthened the theoretical results and
  corrected a few mistakes</arxiv:comment>
    <link href="http://arxiv.org/abs/1202.5130v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.5130v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1203.0038v1</id>
    <updated>2012-02-29T22:40:56Z</updated>
    <published>2012-02-29T22:40:56Z</published>
    <title>Inference in Hidden Markov Models with Explicit State Duration
  Distributions</title>
    <summary>  In this letter we borrow from the inference techniques developed for
unbounded state-cardinality (nonparametric) variants of the HMM and use them to
develop a tuning-parameter free, black-box inference procedure for
Explicit-state-duration hidden Markov models (EDHMM). EDHMMs are HMMs that have
latent states consisting of both discrete state-indicator and discrete
state-duration random variables. In contrast to the implicit geometric state
duration distribution possessed by the standard HMM, EDHMMs allow the direct
parameterisation and estimation of per-state duration distributions. As most
duration distributions are defined over the positive integers, truncation or
other approximations are usually required to perform EDHMM inference.
</summary>
    <author>
      <name>Michael Dewar</name>
    </author>
    <author>
      <name>Chris Wiggins</name>
    </author>
    <author>
      <name>Frank Wood</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/LSP.2012.2184795</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/LSP.2012.2184795" rel="related"/>
    <link href="http://arxiv.org/abs/1203.0038v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1203.0038v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1203.0453v2</id>
    <updated>2013-01-16T06:44:58Z</updated>
    <published>2012-03-02T13:12:03Z</published>
    <title>Change-Point Detection in Time-Series Data by Relative Density-Ratio
  Estimation</title>
    <summary>  The objective of change-point detection is to discover abrupt property
changes lying behind time-series data. In this paper, we present a novel
statistical change-point detection algorithm based on non-parametric divergence
estimation between time-series samples from two retrospective segments. Our
method uses the relative Pearson divergence as a divergence measure, and it is
accurately and efficiently estimated by a method of direct density-ratio
estimation. Through experiments on artificial and real-world datasets including
human-activity sensing, speech, and Twitter messages, we demonstrate the
usefulness of the proposed method.
</summary>
    <author>
      <name>Song Liu</name>
    </author>
    <author>
      <name>Makoto Yamada</name>
    </author>
    <author>
      <name>Nigel Collier</name>
    </author>
    <author>
      <name>Masashi Sugiyama</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.neunet.2013.01.012</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.neunet.2013.01.012" rel="related"/>
    <link href="http://arxiv.org/abs/1203.0453v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1203.0453v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1203.2570v1</id>
    <updated>2012-03-12T18:00:49Z</updated>
    <published>2012-03-12T18:00:49Z</published>
    <title>Differential Privacy for Functions and Functional Data</title>
    <summary>  Differential privacy is a framework for privately releasing summaries of a
database. Previous work has focused mainly on methods for which the output is a
finite dimensional vector, or an element of some discrete set. We develop
methods for releasing functions while preserving differential privacy.
Specifically, we show that adding an appropriate Gaussian process to the
function of interest yields differential privacy. When the functions lie in the
same RKHS as the Gaussian process, then the correct noise level is established
by measuring the "sensitivity" of the function in the RKHS norm. As examples we
consider kernel density estimation, kernel support vector machines, and
functions in reproducing kernel Hilbert spaces.
</summary>
    <author>
      <name>Rob Hall</name>
    </author>
    <author>
      <name>Alessandro Rinaldo</name>
    </author>
    <author>
      <name>Larry Wasserman</name>
    </author>
    <link href="http://arxiv.org/abs/1203.2570v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1203.2570v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1203.3783v1</id>
    <updated>2012-03-16T19:01:10Z</updated>
    <published>2012-03-16T19:01:10Z</published>
    <title>Learning Feature Hierarchies with Centered Deep Boltzmann Machines</title>
    <summary>  Deep Boltzmann machines are in principle powerful models for extracting the
hierarchical structure of data. Unfortunately, attempts to train layers jointly
(without greedy layer-wise pretraining) have been largely unsuccessful. We
propose a modification of the learning algorithm that initially recenters the
output of the activation functions to zero. This modification leads to a better
conditioned Hessian and thus makes learning easier. We test the algorithm on
real data and demonstrate that our suggestion, the centered deep Boltzmann
machine, learns a hierarchy of increasingly abstract representations and a
better generative model of data.
</summary>
    <author>
      <name>Grégoire Montavon</name>
    </author>
    <author>
      <name>Klaus-Robert Müller</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-642-35289-8_33</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-642-35289-8_33" rel="related"/>
    <link href="http://arxiv.org/abs/1203.3783v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1203.3783v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1203.6345v2</id>
    <updated>2012-10-29T05:21:41Z</updated>
    <published>2012-03-28T19:24:35Z</published>
    <title>Empirical Normalization for Quadratic Discriminant Analysis and
  Classifying Cancer Subtypes</title>
    <summary>  We introduce a new discriminant analysis method (Empirical Discriminant
Analysis or EDA) for binary classification in machine learning. Given a dataset
of feature vectors, this method defines an empirical feature map transforming
the training and test data into new data with components having Gaussian
empirical distributions. This map is an empirical version of the Gaussian
copula used in probability and mathematical finance. The purpose is to form a
feature mapped dataset as close as possible to Gaussian, after which standard
quadratic discriminants can be used for classification. We discuss this method
in general, and apply it to some datasets in computational biology.
</summary>
    <author>
      <name>Mark A. Kon</name>
    </author>
    <author>
      <name>Nikolay Nikolaev</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/ICMLA.2011.160</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/ICMLA.2011.160" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2011 10th International Conference on Machine Learning and
  Applications and Workshops</arxiv:comment>
    <link href="http://arxiv.org/abs/1203.6345v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1203.6345v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.1437v1</id>
    <updated>2012-04-06T08:55:38Z</updated>
    <published>2012-04-06T08:55:38Z</published>
    <title>Fast projections onto mixed-norm balls with applications</title>
    <summary>  Joint sparsity offers powerful structural cues for feature selection,
especially for variables that are expected to demonstrate a "grouped" behavior.
Such behavior is commonly modeled via group-lasso, multitask lasso, and related
methods where feature selection is effected via mixed-norms. Several mixed-norm
based sparse models have received substantial attention, and for some cases
efficient algorithms are also available. Surprisingly, several constrained
sparse models seem to be lacking scalable algorithms. We address this
deficiency by presenting batch and online (stochastic-gradient) optimization
methods, both of which rely on efficient projections onto mixed-norm balls. We
illustrate our methods by applying them to the multitask lasso. We conclude by
mentioning some open problems.
</summary>
    <author>
      <name>Suvrit Sra</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Preprint of paper under review</arxiv:comment>
    <link href="http://arxiv.org/abs/1204.1437v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.1437v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.1795v1</id>
    <updated>2012-04-09T05:29:07Z</updated>
    <published>2012-04-09T05:29:07Z</published>
    <title>Estimation of causal orders in a linear non-Gaussian acyclic model: a
  method robust against latent confounders</title>
    <summary>  We consider to learn a causal ordering of variables in a linear non-Gaussian
acyclic model called LiNGAM. Several existing methods have been shown to
consistently estimate a causal ordering assuming that all the model assumptions
are correct. But, the estimation results could be distorted if some assumptions
actually are violated. In this paper, we propose a new algorithm for learning
causal orders that is robust against one typical violation of the model
assumptions: latent confounders. We demonstrate the effectiveness of our method
using artificial data.
</summary>
    <author>
      <name>Tatsuya Tashiro</name>
    </author>
    <author>
      <name>Shohei Shimizu</name>
    </author>
    <author>
      <name>Aapo Hyvarinen</name>
    </author>
    <author>
      <name>Takashi Washio</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1204.1795v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.1795v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.5043v2</id>
    <updated>2012-06-12T08:59:52Z</updated>
    <published>2012-04-23T12:35:56Z</published>
    <title>Sparse Prediction with the $k$-Support Norm</title>
    <summary>  We derive a novel norm that corresponds to the tightest convex relaxation of
sparsity combined with an $\ell_2$ penalty. We show that this new {\em
$k$-support norm} provides a tighter relaxation than the elastic net and is
thus a good replacement for the Lasso or the elastic net in sparse prediction
problems. Through the study of the $k$-support norm, we also bound the
looseness of the elastic net, thus shedding new light on it and providing
justification for its use.
</summary>
    <author>
      <name>Andreas Argyriou</name>
    </author>
    <author>
      <name>Rina Foygel</name>
    </author>
    <author>
      <name>Nathan Srebro</name>
    </author>
    <link href="http://arxiv.org/abs/1204.5043v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.5043v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.1240v1</id>
    <updated>2012-05-06T19:54:33Z</updated>
    <published>2012-05-06T19:54:33Z</published>
    <title>Convex Relaxation for Combinatorial Penalties</title>
    <summary>  In this paper, we propose an unifying view of several recently proposed
structured sparsity-inducing norms. We consider the situation of a model
simultaneously (a) penalized by a set- function de ned on the support of the
unknown parameter vector which represents prior knowledge on supports, and (b)
regularized in Lp-norm. We show that the natural combinatorial optimization
problems obtained may be relaxed into convex optimization problems and
introduce a notion, the lower combinatorial envelope of a set-function, that
characterizes the tightness of our relaxations. We moreover establish links
with norms based on latent representations including the latent group Lasso and
block-coding, and with norms obtained from submodular functions.
</summary>
    <author>
      <name>Guillaume Obozinski</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Paris - Rocquencourt, LIENS</arxiv:affiliation>
    </author>
    <author>
      <name>Francis Bach</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Paris - Rocquencourt, LIENS</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">35 page</arxiv:comment>
    <link href="http://arxiv.org/abs/1205.1240v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.1240v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.1406v2</id>
    <updated>2012-05-09T11:22:58Z</updated>
    <published>2012-05-07T14:24:24Z</published>
    <title>Graph Prediction in a Low-Rank and Autoregressive Setting</title>
    <summary>  We study the problem of prediction for evolving graph data. We formulate the
problem as the minimization of a convex objective encouraging sparsity and
low-rank of the solution, that reflect natural graph properties. The convex
formulation allows to obtain oracle inequalities and efficient solvers. We
provide empirical results for our algorithm and comparison with competing
methods, and point out two open questions related to compressed sensing and
algebra of low-rank and sparse matrices.
</summary>
    <author>
      <name>Emile Richard</name>
    </author>
    <author>
      <name>Pierre-Andre Savalle</name>
    </author>
    <author>
      <name>Nicolas Vayatis</name>
    </author>
    <link href="http://arxiv.org/abs/1205.1406v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.1406v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.1782v2</id>
    <updated>2012-05-21T16:30:22Z</updated>
    <published>2012-05-08T19:22:43Z</published>
    <title>Approximate Dynamic Programming By Minimizing Distributionally Robust
  Bounds</title>
    <summary>  Approximate dynamic programming is a popular method for solving large Markov
decision processes. This paper describes a new class of approximate dynamic
programming (ADP) methods- distributionally robust ADP-that address the curse
of dimensionality by minimizing a pessimistic bound on the policy loss. This
approach turns ADP into an optimization problem, for which we derive new
mathematical program formulations and analyze its properties. DRADP improves on
the theoretical guarantees of existing ADP methods-it guarantees convergence
and L1 norm based error bounds. The empirical evaluation of DRADP shows that
the theoretical guarantees translate well into good performance on benchmark
problems.
</summary>
    <author>
      <name>Marek Petrik</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings of International Conference on Machine Learning, 2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1205.1782v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.1782v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.2172v2</id>
    <updated>2012-10-05T06:22:14Z</updated>
    <published>2012-05-10T07:02:20Z</published>
    <title>Modularity-Based Clustering for Network-Constrained Trajectories</title>
    <summary>  We present a novel clustering approach for moving object trajectories that
are constrained by an underlying road network. The approach builds a similarity
graph based on these trajectories then uses modularity-optimization hiearchical
graph clustering to regroup trajectories with similar profiles. Our
experimental study shows the superiority of the proposed approach over classic
hierarchical clustering and gives a brief insight to visualization of the
clustering results.
</summary>
    <author>
      <name>Mohamed Khalil El Mahrsi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LTCI</arxiv:affiliation>
    </author>
    <author>
      <name>Fabrice Rossi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">SAMM</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20-th European Symposium on Artificial Neural Networks, Computational
  Intelligence and Machine Learning (ESANN 2012), Bruges : Belgium (2012)</arxiv:comment>
    <link href="http://arxiv.org/abs/1205.2172v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.2172v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.2604v1</id>
    <updated>2012-05-09T18:43:56Z</updated>
    <published>2012-05-09T18:43:56Z</published>
    <title>The Infinite Latent Events Model</title>
    <summary>  We present the Infinite Latent Events Model, a nonparametric hierarchical
Bayesian distribution over infinite dimensional Dynamic Bayesian Networks with
binary state representations and noisy-OR-like transitions. The distribution
can be used to learn structure in discrete timeseries data by simultaneously
inferring a set of latent events, which events fired at each timestep, and how
those events are causally linked. We illustrate the model on a sound
factorization task, a network topology identification task, and a video game
task.
</summary>
    <author>
      <name>David Wingate</name>
    </author>
    <author>
      <name>Noah Goodman</name>
    </author>
    <author>
      <name>Daniel Roy</name>
    </author>
    <author>
      <name>Joshua Tenenbaum</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty
  in Artificial Intelligence (UAI2009)</arxiv:comment>
    <link href="http://arxiv.org/abs/1205.2604v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.2604v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.4217v2</id>
    <updated>2012-07-19T13:59:13Z</updated>
    <published>2012-05-18T19:00:51Z</published>
    <title>Thompson Sampling: An Asymptotically Optimal Finite Time Analysis</title>
    <summary>  The question of the optimality of Thompson Sampling for solving the
stochastic multi-armed bandit problem had been open since 1933. In this paper
we answer it positively for the case of Bernoulli rewards by providing the
first finite-time analysis that matches the asymptotic rate given in the Lai
and Robbins lower bound for the cumulative regret. The proof is accompanied by
a numerical comparison with other optimal policies, experiments that have been
lacking in the literature until now for the Bernoulli case.
</summary>
    <author>
      <name>Emilie Kaufmann</name>
    </author>
    <author>
      <name>Nathaniel Korda</name>
    </author>
    <author>
      <name>Rémi Munos</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 2 figures, submitted to ALT (Algorithmic Learning Theory)</arxiv:comment>
    <link href="http://arxiv.org/abs/1205.4217v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.4217v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.4476v3</id>
    <updated>2013-02-22T17:03:20Z</updated>
    <published>2012-05-21T01:46:04Z</published>
    <title>Soft Rule Ensembles for Statistical Learning</title>
    <summary>  In this article supervised learning problems are solved using soft rule
ensembles. We first review the importance sampling learning ensembles (ISLE)
approach that is useful for generating hard rules. The soft rules are then
obtained with logistic regression from the corresponding hard rules. In order
to deal with the perfect separation problem related to the logistic regression,
Firth's bias corrected likelihood is used. Various examples and simulation
results show that soft rule ensembles can improve predictive performance over
hard rule ensembles.
</summary>
    <author>
      <name>Deniz Akdemir</name>
    </author>
    <author>
      <name>Nicolas Heslot</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: text overlap with arXiv:1112.3699</arxiv:comment>
    <link href="http://arxiv.org/abs/1205.4476v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.4476v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.1106v2</id>
    <updated>2013-02-18T16:09:50Z</updated>
    <published>2012-06-06T02:06:57Z</published>
    <title>No More Pesky Learning Rates</title>
    <summary>  The performance of stochastic gradient descent (SGD) depends critically on
how learning rates are tuned and decreased over time. We propose a method to
automatically adjust multiple learning rates so as to minimize the expected
error at any one time. The method relies on local gradient variations across
samples. In our approach, learning rates can increase as well as decrease,
making it suitable for non-stationary problems. Using a number of convex and
non-convex learning tasks, we show that the resulting algorithm matches the
performance of SGD or other adaptive approaches with their best settings
obtained through systematic search, and effectively removes the need for
learning rate tuning.
</summary>
    <author>
      <name>Tom Schaul</name>
    </author>
    <author>
      <name>Sixin Zhang</name>
    </author>
    <author>
      <name>Yann LeCun</name>
    </author>
    <link href="http://arxiv.org/abs/1206.1106v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.1106v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.1386v3</id>
    <updated>2016-04-28T16:10:32Z</updated>
    <published>2012-06-07T02:07:48Z</published>
    <title>Robust subspace recovery by Tyler's M-estimator</title>
    <summary>  This paper considers the problem of robust subspace recovery: given a set of
$N$ points in $\mathbb{R}^D$, if many lie in a $d$-dimensional subspace, then
can we recover the underlying subspace? We show that Tyler's M-estimator can be
used to recover the underlying subspace, if the percentage of the inliers is
larger than $d/D$ and the data points lie in general position. Empirically,
Tyler's M-estimator compares favorably with other convex subspace recovery
algorithms in both simulations and experiments on real data sets.
</summary>
    <author>
      <name>Teng Zhang</name>
    </author>
    <link href="http://arxiv.org/abs/1206.1386v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.1386v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.3137v1</id>
    <updated>2012-06-14T15:21:24Z</updated>
    <published>2012-06-14T15:21:24Z</published>
    <title>Identifiability and Unmixing of Latent Parse Trees</title>
    <summary>  This paper explores unsupervised learning of parsing models along two
directions. First, which models are identifiable from infinite data? We use a
general technique for numerically checking identifiability based on the rank of
a Jacobian matrix, and apply it to several standard constituency and dependency
parsing models. Second, for identifiable models, how do we estimate the
parameters efficiently? EM suffers from local optima, while recent work using
spectral methods cannot be directly applied since the topology of the parse
tree varies across sentences. We develop a strategy, unmixing, which deals with
this additional complexity for restricted classes of parsing models.
</summary>
    <author>
      <name>Daniel Hsu</name>
    </author>
    <author>
      <name>Sham M. Kakade</name>
    </author>
    <author>
      <name>Percy Liang</name>
    </author>
    <link href="http://arxiv.org/abs/1206.3137v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.3137v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.1977v1</id>
    <updated>2012-07-09T08:05:44Z</updated>
    <published>2012-07-09T08:05:44Z</published>
    <title>Estimating a Causal Order among Groups of Variables in Linear Models</title>
    <summary>  The machine learning community has recently devoted much attention to the
problem of inferring causal relationships from statistical data. Most of this
work has focused on uncovering connections among scalar random variables. We
generalize existing methods to apply to collections of multi-dimensional random
vectors, focusing on techniques applicable to linear models. The performance of
the resulting algorithms is evaluated and compared in simulations, which show
that our methods can, in many cases, provide useful information on causal
relationships even for relatively small sample sizes.
</summary>
    <author>
      <name>Doris Entner</name>
    </author>
    <author>
      <name>Patrik O. Hoyer</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear at the International Conference on Artificial Neural
  Networks 2012 (proceedings to be published in LNCS, Springer); To be
  presented at the UAI Workshop on Causal Structure Learning 2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1207.1977v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.1977v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.3961v3</id>
    <updated>2012-11-15T00:44:30Z</updated>
    <published>2012-07-17T11:54:31Z</published>
    <title>Ensemble Clustering with Logic Rules</title>
    <summary>  In this article, the logic rule ensembles approach to supervised learning is
applied to the unsupervised or semi-supervised clustering. Logic rules which
were obtained by combining simple conjunctive rules are used to partition the
input space and an ensemble of these rules is used to define a similarity
matrix. Similarity partitioning is used to partition the data in an
hierarchical manner. We have used internal and external measures of cluster
validity to evaluate the quality of clusterings or to identify the number of
clusters.
</summary>
    <author>
      <name>Deniz Akdemir</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Replacing two articles with one</arxiv:comment>
    <link href="http://arxiv.org/abs/1207.3961v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.3961v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.6745v1</id>
    <updated>2012-07-29T04:29:03Z</updated>
    <published>2012-07-29T04:29:03Z</published>
    <title>Universally Consistent Latent Position Estimation and Vertex
  Classification for Random Dot Product Graphs</title>
    <summary>  In this work we show that, using the eigen-decomposition of the adjacency
matrix, we can consistently estimate latent positions for random dot product
graphs provided the latent positions are i.i.d. from some distribution. If
class labels are observed for a number of vertices tending to infinity, then we
show that the remaining vertices can be classified with error converging to
Bayes optimal using the $k$-nearest-neighbors classification rule. We evaluate
the proposed methods on simulated data and a graph derived from Wikipedia.
</summary>
    <author>
      <name>Daniel L. Sussman</name>
    </author>
    <author>
      <name>Minh Tang</name>
    </author>
    <author>
      <name>Carey E. Priebe</name>
    </author>
    <link href="http://arxiv.org/abs/1207.6745v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.6745v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1208.0129v1</id>
    <updated>2012-08-01T07:57:53Z</updated>
    <published>2012-08-01T07:57:53Z</published>
    <title>Oracle inequalities for computationally adaptive model selection</title>
    <summary>  We analyze general model selection procedures using penalized empirical loss
minimization under computational constraints. While classical model selection
approaches do not consider computational aspects of performing model selection,
we argue that any practical model selection procedure must not only trade off
estimation and approximation error, but also the computational effort required
to compute empirical minimizers for different function classes. We provide a
framework for analyzing such problems, and we give algorithms for model
selection under a computational budget. These algorithms satisfy oracle
inequalities that show that the risk of the selected model is not much worse
than if we had devoted all of our omputational budget to the optimal function
class.
</summary>
    <author>
      <name>Alekh Agarwal</name>
    </author>
    <author>
      <name>Peter L. Bartlett</name>
    </author>
    <author>
      <name>John C. Duchi</name>
    </author>
    <link href="http://arxiv.org/abs/1208.0129v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1208.0129v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1208.0628v1</id>
    <updated>2012-08-02T23:15:26Z</updated>
    <published>2012-08-02T23:15:26Z</published>
    <title>Ancestral Inference from Functional Data: Statistical Methods and
  Numerical Examples</title>
    <summary>  Many biological characteristics of evolutionary interest are not scalar
variables but continuous functions. Here we use phylogenetic Gaussian process
regression to model the evolution of simulated function-valued traits. Given
function-valued data only from the tips of an evolutionary tree and utilising
independent principal component analysis (IPCA) as a method for dimension
reduction, we construct distributional estimates of ancestral function-valued
traits, and estimate parameters describing their evolutionary dynamics.
</summary>
    <author>
      <name>Pantelis Z. Hadjipantelis</name>
    </author>
    <author>
      <name>Nick S. Jones</name>
    </author>
    <author>
      <name>John Moriarty</name>
    </author>
    <author>
      <name>David Springate</name>
    </author>
    <author>
      <name>Christopher G. Knight</name>
    </author>
    <link href="http://arxiv.org/abs/1208.0628v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1208.0628v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.PE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1208.2417v1</id>
    <updated>2012-08-12T10:12:48Z</updated>
    <published>2012-08-12T10:12:48Z</published>
    <title>How to sample if you must: on optimal functional sampling</title>
    <summary>  We examine a fundamental problem that models various active sampling setups,
such as network tomography. We analyze sampling of a multivariate normal
distribution with an unknown expectation that needs to be estimated: in our
setup it is possible to sample the distribution from a given set of linear
functionals, and the difficulty addressed is how to optimally select the
combinations to achieve low estimation error. Although this problem is in the
heart of the field of optimal design, no efficient solutions for the case with
many functionals exist. We present some bounds and an efficient sub-optimal
solution for this problem for more structured sets such as binary functionals
that are induced by graph walks.
</summary>
    <author>
      <name>Assaf Hallak</name>
    </author>
    <author>
      <name>Shie Mannor</name>
    </author>
    <link href="http://arxiv.org/abs/1208.2417v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1208.2417v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.1119v2</id>
    <updated>2013-02-15T16:30:49Z</updated>
    <published>2012-09-05T21:06:32Z</published>
    <title>Augment-and-Conquer Negative Binomial Processes</title>
    <summary>  By developing data augmentation methods unique to the negative binomial (NB)
distribution, we unite seemingly disjoint count and mixture models under the NB
process framework. We develop fundamental properties of the models and derive
efficient Gibbs sampling inference. We show that the gamma-NB process can be
reduced to the hierarchical Dirichlet process with normalization, highlighting
its unique theoretical, structural and computational advantages. A variety of
NB processes with distinct sharing mechanisms are constructed and applied to
topic modeling, with connections to existing algorithms, showing the importance
of inferring both the NB dispersion and probability parameters.
</summary>
    <author>
      <name>Mingyuan Zhou</name>
    </author>
    <author>
      <name>Lawrence Carin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Neural Information Processing Systems, NIPS 2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1209.1119v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.1119v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.1360v2</id>
    <updated>2012-09-14T14:14:53Z</updated>
    <published>2012-09-06T18:22:25Z</published>
    <title>Multiclass Learning with Simplex Coding</title>
    <summary>  In this paper we discuss a novel framework for multiclass learning, defined
by a suitable coding/decoding strategy, namely the simplex coding, that allows
to generalize to multiple classes a relaxation approach commonly used in binary
classification. In this framework, a relaxation error analysis can be developed
avoiding constraints on the considered hypotheses class. Moreover, we show that
in this setting it is possible to derive the first provably consistent
regularized method with training/tuning complexity which is independent to the
number of classes. Tools from convex analysis are introduced that can be used
beyond the scope of this paper.
</summary>
    <author>
      <name>Youssef Mroueh</name>
    </author>
    <author>
      <name>Tomaso Poggio</name>
    </author>
    <author>
      <name>Lorenzo Rosasco</name>
    </author>
    <author>
      <name>Jean-Jacques Slotine</name>
    </author>
    <link href="http://arxiv.org/abs/1209.1360v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.1360v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.1727v1</id>
    <updated>2012-09-08T15:22:07Z</updated>
    <published>2012-09-08T15:22:07Z</published>
    <title>Bandits with heavy tail</title>
    <summary>  The stochastic multi-armed bandit problem is well understood when the reward
distributions are sub-Gaussian. In this paper we examine the bandit problem
under the weaker assumption that the distributions have moments of order
1+\epsilon, for some $\epsilon \in (0,1]$. Surprisingly, moments of order 2
(i.e., finite variance) are sufficient to obtain regret bounds of the same
order as under sub-Gaussian reward distributions. In order to achieve such
regret, we define sampling strategies based on refined estimators of the mean
such as the truncated empirical mean, Catoni's M-estimator, and the
median-of-means estimator. We also derive matching lower bounds that also show
that the best achievable regret deteriorates when \epsilon &lt;1.
</summary>
    <author>
      <name>Sébastien Bubeck</name>
    </author>
    <author>
      <name>Nicolò Cesa-Bianchi</name>
    </author>
    <author>
      <name>Gábor Lugosi</name>
    </author>
    <link href="http://arxiv.org/abs/1209.1727v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.1727v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.1873v2</id>
    <updated>2013-01-30T15:30:25Z</updated>
    <published>2012-09-10T03:25:29Z</published>
    <title>Stochastic Dual Coordinate Ascent Methods for Regularized Loss
  Minimization</title>
    <summary>  Stochastic Gradient Descent (SGD) has become popular for solving large scale
supervised machine learning optimization problems such as SVM, due to their
strong theoretical guarantees. While the closely related Dual Coordinate Ascent
(DCA) method has been implemented in various software packages, it has so far
lacked good convergence analysis. This paper presents a new analysis of
Stochastic Dual Coordinate Ascent (SDCA) showing that this class of methods
enjoy strong theoretical guarantees that are comparable or better than SGD.
This analysis justifies the effectiveness of SDCA for practical applications.
</summary>
    <author>
      <name>Shai Shalev-Shwartz</name>
    </author>
    <author>
      <name>Tong Zhang</name>
    </author>
    <link href="http://arxiv.org/abs/1209.1873v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.1873v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.3230v1</id>
    <updated>2012-09-14T15:27:45Z</updated>
    <published>2012-09-14T15:27:45Z</published>
    <title>Link Prediction in Graphs with Autoregressive Features</title>
    <summary>  In the paper, we consider the problem of link prediction in time-evolving
graphs. We assume that certain graph features, such as the node degree, follow
a vector autoregressive (VAR) model and we propose to use this information to
improve the accuracy of prediction. Our strategy involves a joint optimization
procedure over the space of adjacency matrices and VAR matrices which takes
into account both sparsity and low rank properties of the matrices. Oracle
inequalities are derived and illustrate the trade-offs in the choice of
smoothing parameters when modeling the joint effect of sparsity and low rank
property. The estimate is computed efficiently using proximal methods through a
generalized forward-backward agorithm.
</summary>
    <author>
      <name>Emile Richard</name>
    </author>
    <author>
      <name>Stephane Gaiffas</name>
    </author>
    <author>
      <name>Nicolas Vayatis</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">NIPS 2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1209.3230v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.3230v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.3761v1</id>
    <updated>2012-09-17T19:52:38Z</updated>
    <published>2012-09-17T19:52:38Z</published>
    <title>Generalized Canonical Correlation Analysis for Disparate Data Fusion</title>
    <summary>  Manifold matching works to identify embeddings of multiple disparate data
spaces into the same low-dimensional space, where joint inference can be
pursued. It is an enabling methodology for fusion and inference from multiple
and massive disparate data sources. In this paper we focus on a method called
Canonical Correlation Analysis (CCA) and its generalization Generalized
Canonical Correlation Analysis (GCCA), which belong to the more general Reduced
Rank Regression (RRR) framework. We present an efficiency investigation of CCA
and GCCA under different training conditions for a particular text document
classification task.
</summary>
    <author>
      <name>Ming Sun</name>
    </author>
    <author>
      <name>Carey E. Priebe</name>
    </author>
    <author>
      <name>Minh Tang</name>
    </author>
    <link href="http://arxiv.org/abs/1209.3761v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.3761v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.4280v1</id>
    <updated>2012-09-19T15:20:47Z</updated>
    <published>2012-09-19T15:20:47Z</published>
    <title>Alpha/Beta Divergences and Tweedie Models</title>
    <summary>  We describe the underlying probabilistic interpretation of alpha and beta
divergences. We first show that beta divergences are inherently tied to Tweedie
distributions, a particular type of exponential family, known as exponential
dispersion models. Starting from the variance function of a Tweedie model, we
outline how to get alpha and beta divergences as special cases of Csisz\'ar's
$f$ and Bregman divergences. This result directly generalizes the well-known
relationship between the Gaussian distribution and least squares estimation to
Tweedie models and beta divergence minimization.
</summary>
    <author>
      <name>Y. Kenan Yilmaz</name>
    </author>
    <author>
      <name>A. Taylan Cemgil</name>
    </author>
    <link href="http://arxiv.org/abs/1209.4280v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.4280v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.4887v1</id>
    <updated>2012-09-21T19:15:16Z</updated>
    <published>2012-09-21T19:15:16Z</published>
    <title>A Note on the SPICE Method</title>
    <summary>  In this article, we analyze the SPICE method developed in [1], and establish
its connections with other standard sparse estimation methods such as the Lasso
and the LAD-Lasso. This result positions SPICE as a computationally efficient
technique for the calculation of Lasso-type estimators. Conversely, this
connection is very useful for establishing the asymptotic properties of SPICE
under several problem scenarios and for suggesting suitable modifications in
cases where the naive version of SPICE would not work.
</summary>
    <author>
      <name>Cristian R. Rojas</name>
    </author>
    <author>
      <name>Dimitrios Katselis</name>
    </author>
    <author>
      <name>Håkan Hjalmarsson</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TSP.2013.2272291</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TSP.2013.2272291" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 1 figure. Submitted to the IEEE Transactions on Signal
  Processing</arxiv:comment>
    <link href="http://arxiv.org/abs/1209.4887v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.4887v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.6004v1</id>
    <updated>2012-09-26T17:00:21Z</updated>
    <published>2012-09-26T17:00:21Z</published>
    <title>The Issue-Adjusted Ideal Point Model</title>
    <summary>  We develop a model of issue-specific voting behavior. This model can be used
to explore lawmakers' personal voting patterns of voting by issue area,
providing an exploratory window into how the language of the law is correlated
with political support. We derive approximate posterior inference algorithms
based on variational methods. Across 12 years of legislative data, we
demonstrate both improvement in heldout prediction performance and the model's
utility in interpreting an inherently multi-dimensional space.
</summary>
    <author>
      <name>Sean M. Gerrish</name>
    </author>
    <author>
      <name>David M. Blei</name>
    </author>
    <link href="http://arxiv.org/abs/1209.6004v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.6004v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.1190v1</id>
    <updated>2012-10-03T18:37:47Z</updated>
    <published>2012-10-03T18:37:47Z</published>
    <title>Fast Conical Hull Algorithms for Near-separable Non-negative Matrix
  Factorization</title>
    <summary>  The separability assumption (Donoho &amp; Stodden, 2003; Arora et al., 2012)
turns non-negative matrix factorization (NMF) into a tractable problem.
Recently, a new class of provably-correct NMF algorithms have emerged under
this assumption. In this paper, we reformulate the separable NMF problem as
that of finding the extreme rays of the conical hull of a finite set of
vectors. From this geometric perspective, we derive new separable NMF
algorithms that are highly scalable and empirically noise robust, and have
several other favorable properties in relation to existing methods. A parallel
implementation of our algorithm demonstrates high scalability on shared- and
distributed-memory machines.
</summary>
    <author>
      <name>Abhishek Kumar</name>
    </author>
    <author>
      <name>Vikas Sindhwani</name>
    </author>
    <author>
      <name>Prabhanjan Kambadur</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1210.1190v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.1190v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.1928v3</id>
    <updated>2013-09-05T03:42:50Z</updated>
    <published>2012-10-06T08:11:01Z</published>
    <title>Information fusion in multi-task Gaussian processes</title>
    <summary>  This paper evaluates heterogeneous information fusion using multi-task
Gaussian processes in the context of geological resource modeling.
Specifically, it empirically demonstrates that information integration across
heterogeneous information sources leads to superior estimates of all the
quantities being modeled, compared to modeling them individually. Multi-task
Gaussian processes provide a powerful approach for simultaneous modeling of
multiple quantities of interest while taking correlations between these
quantities into consideration. Experiments are performed on large scale real
sensor data.
</summary>
    <author>
      <name>Shrihari Vasudevan</name>
    </author>
    <author>
      <name>Arman Melkumyan</name>
    </author>
    <author>
      <name>Steven Scheding</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">53 pages, 33 figures; improved presentation</arxiv:comment>
    <link href="http://arxiv.org/abs/1210.1928v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.1928v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.1960v1</id>
    <updated>2012-10-06T14:16:33Z</updated>
    <published>2012-10-06T14:16:33Z</published>
    <title>Feature Selection via L1-Penalized Squared-Loss Mutual Information</title>
    <summary>  Feature selection is a technique to screen out less important features. Many
existing supervised feature selection algorithms use redundancy and relevancy
as the main criteria to select features. However, feature interaction,
potentially a key characteristic in real-world problems, has not received much
attention. As an attempt to take feature interaction into account, we propose
L1-LSMI, an L1-regularization based algorithm that maximizes a squared-loss
variant of mutual information between selected features and outputs. Numerical
results show that L1-LSMI performs well in handling redundancy, detecting
non-linear dependency, and considering feature interaction.
</summary>
    <author>
      <name>Wittawat Jitkrittum</name>
    </author>
    <author>
      <name>Hirotaka Hachiya</name>
    </author>
    <author>
      <name>Masashi Sugiyama</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1587/transinf.E96.D.1513</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1587/transinf.E96.D.1513" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">25 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1210.1960v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.1960v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.2085v2</id>
    <updated>2013-10-10T17:53:36Z</updated>
    <published>2012-10-07T18:27:03Z</published>
    <title>Privacy Aware Learning</title>
    <summary>  We study statistical risk minimization problems under a privacy model in
which the data is kept confidential even from the learner. In this local
privacy framework, we establish sharp upper and lower bounds on the convergence
rates of statistical estimation procedures. As a consequence, we exhibit a
precise tradeoff between the amount of privacy the data preserves and the
utility, as measured by convergence rate, of any statistical estimator or
learning procedure.
</summary>
    <author>
      <name>John C. Duchi</name>
    </author>
    <author>
      <name>Michael I. Jordan</name>
    </author>
    <author>
      <name>Martin J. Wainwright</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">60 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1210.2085v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.2085v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.4347v1</id>
    <updated>2012-10-16T10:26:29Z</updated>
    <published>2012-10-16T10:26:29Z</published>
    <title>Hilbert Space Embedding for Dirichlet Process Mixtures</title>
    <summary>  This paper proposes a Hilbert space embedding for Dirichlet Process mixture
models via a stick-breaking construction of Sethuraman. Although Bayesian
nonparametrics offers a powerful approach to construct a prior that avoids the
need to specify the model size/complexity explicitly, an exact inference is
often intractable. On the other hand, frequentist approaches such as kernel
machines, which suffer from the model selection/comparison problems, often
benefit from efficient learning algorithms. This paper discusses the
possibility to combine the best of both worlds by using the Dirichlet Process
mixture model as a case study.
</summary>
    <author>
      <name>Krikamol Muandet</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">NIPS 2012 Workshop in confluence between kernel methods and graphical
  models</arxiv:comment>
    <link href="http://arxiv.org/abs/1210.4347v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.4347v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.5196v1</id>
    <updated>2012-10-18T17:30:43Z</updated>
    <published>2012-10-18T17:30:43Z</published>
    <title>Matrix reconstruction with the local max norm</title>
    <summary>  We introduce a new family of matrix norms, the "local max" norms,
generalizing existing methods such as the max norm, the trace norm (nuclear
norm), and the weighted or smoothed weighted trace norms, which have been
extensively used in the literature as regularizers for matrix reconstruction
problems. We show that this new family can be used to interpolate between the
(weighted or unweighted) trace norm and the more conservative max norm. We test
this interpolation on simulated data and on the large-scale Netflix and
MovieLens ratings data, and find improved accuracy relative to the existing
matrix norms. We also provide theoretical results showing learning guarantees
for some of the new norms.
</summary>
    <author>
      <name>Rina Foygel</name>
    </author>
    <author>
      <name>Nathan Srebro</name>
    </author>
    <author>
      <name>Ruslan Salakhutdinov</name>
    </author>
    <link href="http://arxiv.org/abs/1210.5196v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.5196v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.5345v1</id>
    <updated>2012-10-19T09:03:24Z</updated>
    <published>2012-10-19T09:03:24Z</published>
    <title>Adaptive Stratified Sampling for Monte-Carlo integration of
  Differentiable functions</title>
    <summary>  We consider the problem of adaptive stratified sampling for Monte Carlo
integration of a differentiable function given a finite number of evaluations
to the function. We construct a sampling scheme that samples more often in
regions where the function oscillates more, while allocating the samples such
that they are well spread on the domain (this notion shares similitude with low
discrepancy). We prove that the estimate returned by the algorithm is almost
similarly accurate as the estimate that an optimal oracle strategy (that would
know the variations of the function everywhere) would return, and provide a
finite-sample analysis.
</summary>
    <author>
      <name>Alexandra Carpentier</name>
    </author>
    <author>
      <name>Rémi Munos</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">23 pages, 3 figures, to appear in NIPS 2012 conference proceedings</arxiv:comment>
    <link href="http://arxiv.org/abs/1210.5345v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.5345v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.5474v1</id>
    <updated>2012-10-19T17:16:48Z</updated>
    <published>2012-10-19T17:16:48Z</published>
    <title>Disentangling Factors of Variation via Generative Entangling</title>
    <summary>  Here we propose a novel model family with the objective of learning to
disentangle the factors of variation in data. Our approach is based on the
spike-and-slab restricted Boltzmann machine which we generalize to include
higher-order interactions among multiple latent variables. Seen from a
generative perspective, the multiplicative interactions emulates the entangling
of factors of variation. Inference in the model can be seen as disentangling
these generative factors. Unlike previous attempts at disentangling latent
factors, the proposed model is trained using no supervised information
regarding the latent factors. We apply our model to the task of facial
expression classification.
</summary>
    <author>
      <name>Guillaume Desjardins</name>
    </author>
    <author>
      <name>Aaron Courville</name>
    </author>
    <author>
      <name>Yoshua Bengio</name>
    </author>
    <link href="http://arxiv.org/abs/1210.5474v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.5474v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.5631v2</id>
    <updated>2013-01-04T22:52:39Z</updated>
    <published>2012-10-20T14:39:39Z</published>
    <title>Content-boosted Matrix Factorization Techniques for Recommender Systems</title>
    <summary>  Many businesses are using recommender systems for marketing outreach.
Recommendation algorithms can be either based on content or driven by
collaborative filtering. We study different ways to incorporate content
information directly into the matrix factorization approach of collaborative
filtering. These content-boosted matrix factorization algorithms not only
improve recommendation accuracy, but also provide useful insights about the
contents, as well as make recommendations more easily interpretable.
</summary>
    <author>
      <name>Jennifer Nguyen</name>
    </author>
    <author>
      <name>Mu Zhu</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1002/sam.11184</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1002/sam.11184" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Statistical Analysis and Data Mining, Vol. 6, pp. 286 - 301,
  August 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1210.5631v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.5631v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.5873v1</id>
    <updated>2012-10-22T11:17:31Z</updated>
    <published>2012-10-22T11:17:31Z</published>
    <title>Initialization of Self-Organizing Maps: Principal Components Versus
  Random Initialization. A Case Study</title>
    <summary>  The performance of the Self-Organizing Map (SOM) algorithm is dependent on
the initial weights of the map. The different initialization methods can
broadly be classified into random and data analysis based initialization
approach. In this paper, the performance of random initialization (RI) approach
is compared to that of principal component initialization (PCI) in which the
initial map weights are chosen from the space of the principal component.
Performance is evaluated by the fraction of variance unexplained (FVU).
Datasets were classified into quasi-linear and non-linear and it was observed
that RI performed better for non-linear datasets; however the performance of
PCI approach remains inconclusive for quasi-linear datasets.
</summary>
    <author>
      <name>A. A. Akinduko</name>
    </author>
    <author>
      <name>E. M. Mirkes</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1210.5873v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.5873v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.8353v1</id>
    <updated>2012-10-31T14:55:50Z</updated>
    <published>2012-10-31T14:55:50Z</published>
    <title>Temporal Autoencoding Restricted Boltzmann Machine</title>
    <summary>  Much work has been done refining and characterizing the receptive fields
learned by deep learning algorithms. A lot of this work has focused on the
development of Gabor-like filters learned when enforcing sparsity constraints
on a natural image dataset. Little work however has investigated how these
filters might expand to the temporal domain, namely through training on natural
movies. Here we investigate exactly this problem in established temporal deep
learning algorithms as well as a new learning paradigm suggested here, the
Temporal Autoencoding Restricted Boltzmann Machine (TARBM).
</summary>
    <author>
      <name>Chris Häusler</name>
    </author>
    <author>
      <name>Alex Susemihl</name>
    </author>
    <link href="http://arxiv.org/abs/1210.8353v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.8353v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.0757v1</id>
    <updated>2012-11-05T04:15:25Z</updated>
    <published>2012-11-05T04:15:25Z</published>
    <title>Efficient Point-to-Subspace Query in $\ell^1$: Theory and Applications
  in Computer Vision</title>
    <summary>  Motivated by vision tasks such as robust face and object recognition, we
consider the following general problem: given a collection of low-dimensional
linear subspaces in a high-dimensional ambient (image) space and a query point
(image), efficiently determine the nearest subspace to the query in $\ell^1$
distance. We show in theory that Cauchy random embedding of the objects into
significantly-lower-dimensional spaces helps preserve the identity of the
nearest subspace with constant probability. This offers the possibility of
efficiently selecting several candidates for accurate search. We sketch
preliminary experiments on robust face and digit recognition to corroborate our
theory.
</summary>
    <author>
      <name>Ju Sun</name>
    </author>
    <author>
      <name>Yuqian Zhang</name>
    </author>
    <author>
      <name>John Wright</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in NIPS workshop on big learning, 2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1211.0757v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.0757v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.0889v3</id>
    <updated>2013-05-04T06:22:23Z</updated>
    <published>2012-11-02T07:42:54Z</published>
    <title>APPLE: Approximate Path for Penalized Likelihood Estimators</title>
    <summary>  In high-dimensional data analysis, penalized likelihood estimators are shown
to provide superior results in both variable selection and parameter
estimation. A new algorithm, APPLE, is proposed for calculating the Approximate
Path for Penalized Likelihood Estimators. Both the convex penalty (such as
LASSO) and the nonconvex penalty (such as SCAD and MCP) cases are considered.
The APPLE efficiently computes the solution path for the penalized likelihood
estimator using a hybrid of the modified predictor-corrector method and the
coordinate-descent algorithm. APPLE is compared with several well-known
packages via simulation and analysis of two gene expression data sets.
</summary>
    <author>
      <name>Yi Yu</name>
    </author>
    <author>
      <name>Yang Feng</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">24 pages, 9 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1211.0889v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.0889v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.3010v1</id>
    <updated>2012-11-13T14:54:47Z</updated>
    <published>2012-11-13T14:54:47Z</published>
    <title>Time-series Scenario Forecasting</title>
    <summary>  Many applications require the ability to judge uncertainty of time-series
forecasts. Uncertainty is often specified as point-wise error bars around a
mean or median forecast. Due to temporal dependencies, such a method obscures
some information. We would ideally have a way to query the posterior
probability of the entire time-series given the predictive variables, or at a
minimum, be able to draw samples from this distribution. We use a Bayesian
dictionary learning algorithm to statistically generate an ensemble of
forecasts. We show that the algorithm performs as well as a physics-based
ensemble method for temperature forecasts for Houston. We conclude that the
method shows promise for scenario forecasting where physics-based methods are
absent.
</summary>
    <author>
      <name>Sriharsha Veeramachaneni</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1211.3010v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.3010v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.4142v1</id>
    <updated>2012-11-17T18:28:30Z</updated>
    <published>2012-11-17T18:28:30Z</published>
    <title>Data Clustering via Principal Direction Gap Partitioning</title>
    <summary>  We explore the geometrical interpretation of the PCA based clustering
algorithm Principal Direction Divisive Partitioning (PDDP). We give several
examples where this algorithm breaks down, and suggest a new method, gap
partitioning, which takes into account natural gaps in the data between
clusters. Geometric features of the PCA space are derived and illustrated and
experimental results are given which show our method is comparable on the
datasets used in the original paper on PDDP.
</summary>
    <author>
      <name>Ralph Abbey</name>
    </author>
    <author>
      <name>Jeremy Diepenbrock</name>
    </author>
    <author>
      <name>Amy Langville</name>
    </author>
    <author>
      <name>Carl Meyer</name>
    </author>
    <author>
      <name>Shaina Race</name>
    </author>
    <author>
      <name>Dexin Zhou</name>
    </author>
    <link href="http://arxiv.org/abs/1211.4142v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.4142v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.4321v1</id>
    <updated>2012-11-19T07:40:51Z</updated>
    <published>2012-11-19T07:40:51Z</published>
    <title>Bayesian nonparametric models for ranked data</title>
    <summary>  We develop a Bayesian nonparametric extension of the popular Plackett-Luce
choice model that can handle an infinite number of choice items. Our framework
is based on the theory of random atomic measures, with the prior specified by a
gamma process. We derive a posterior characterization and a simple and
effective Gibbs sampler for posterior simulation. We develop a time-varying
extension of our model, and apply it to the New York Times lists of weekly
bestselling books.
</summary>
    <author>
      <name>Francois Caron</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Bordeaux - Sud-Ouest, IMB</arxiv:affiliation>
    </author>
    <author>
      <name>Yee Whye Teh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">NIPS - Neural Information Processing Systems (2012)</arxiv:comment>
    <link href="http://arxiv.org/abs/1211.4321v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.4321v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.4753v1</id>
    <updated>2012-11-20T14:22:07Z</updated>
    <published>2012-11-20T14:22:07Z</published>
    <title>A unifying representation for a class of dependent random measures</title>
    <summary>  We present a general construction for dependent random measures based on
thinning Poisson processes on an augmented space. The framework is not
restricted to dependent versions of a specific nonparametric model, but can be
applied to all models that can be represented using completely random measures.
Several existing dependent random measures can be seen as specific cases of
this framework. Interesting properties of the resulting measures are derived
and the efficacy of the framework is demonstrated by constructing a
covariate-dependent latent feature model and topic model that obtain superior
predictive performance.
</summary>
    <author>
      <name>Nicholas J. Foti</name>
    </author>
    <author>
      <name>Joseph D. Futoma</name>
    </author>
    <author>
      <name>Daniel N. Rockmore</name>
    </author>
    <author>
      <name>Sinead Williamson</name>
    </author>
    <link href="http://arxiv.org/abs/1211.4753v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.4753v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.4798v1</id>
    <updated>2012-11-20T16:29:13Z</updated>
    <published>2012-11-20T16:29:13Z</published>
    <title>A survey of non-exchangeable priors for Bayesian nonparametric models</title>
    <summary>  Dependent nonparametric processes extend distributions over measures, such as
the Dirichlet process and the beta process, to give distributions over
collections of measures, typically indexed by values in some covariate space.
Such models are appropriate priors when exchangeability assumptions do not
hold, and instead we want our model to vary fluidly with some set of
covariates. Since the concept of dependent nonparametric processes was
formalized by MacEachern [1], there have been a number of models proposed and
used in the statistics and machine learning literatures. Many of these models
exhibit underlying similarities, an understanding of which, we hope, will help
in selecting an appropriate prior, developing new models, and leveraging
inference techniques.
</summary>
    <author>
      <name>Nicholas J. Foti</name>
    </author>
    <author>
      <name>Sinead Williamson</name>
    </author>
    <link href="http://arxiv.org/abs/1211.4798v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.4798v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.7120v1</id>
    <updated>2012-11-29T23:39:00Z</updated>
    <published>2012-11-29T23:39:00Z</published>
    <title>Exact and Efficient Parallel Inference for Nonparametric Mixture Models</title>
    <summary>  Nonparametric mixture models based on the Dirichlet process are an elegant
alternative to finite models when the number of underlying components is
unknown, but inference in such models can be slow. Existing attempts to
parallelize inference in such models have relied on introducing approximations,
which can lead to inaccuracies in the posterior estimate. In this paper, we
describe auxiliary variable representations for the Dirichlet process and the
hierarchical Dirichlet process that allow us to sample from the true posterior
in a distributed manner. We show that our approach allows scalable inference
without the deterioration in estimate quality that accompanies existing
methods.
</summary>
    <author>
      <name>Sinead A. Williamson</name>
    </author>
    <author>
      <name>Avinava Dubey</name>
    </author>
    <author>
      <name>Eric P. Xing</name>
    </author>
    <link href="http://arxiv.org/abs/1211.7120v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.7120v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.7369v1</id>
    <updated>2012-11-30T20:50:40Z</updated>
    <published>2012-11-30T20:50:40Z</published>
    <title>Approximate Rank-Detecting Factorization of Low-Rank Tensors</title>
    <summary>  We present an algorithm, AROFAC2, which detects the (CP-)rank of a degree 3
tensor and calculates its factorization into rank-one components. We provide
generative conditions for the algorithm to work and demonstrate on both
synthetic and real world data that AROFAC2 is a potentially outperforming
alternative to the gold standard PARAFAC over which it has the advantages that
it can intrinsically detect the true rank, avoids spurious components, and is
stable with respect to outliers and non-Gaussian noise.
</summary>
    <author>
      <name>Franz J. Király</name>
    </author>
    <author>
      <name>Andreas Ziehe</name>
    </author>
    <link href="http://arxiv.org/abs/1211.7369v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.7369v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.1263v1</id>
    <updated>2012-12-06T09:17:39Z</updated>
    <published>2012-12-06T09:17:39Z</published>
    <title>On the probabilistic continuous complexity conjecture</title>
    <summary>  In this paper we prove the probabilistic continuous complexity conjecture. In
continuous complexity theory, this states that the complexity of solving a
continuous problem with probability approaching 1 converges (in this limit) to
the complexity of solving the same problem in its worst case. We prove the
conjecture holds if and only if space of problem elements is uniformly convex.
The non-uniformly convex case has a striking counterexample in the problem of
identifying a Brownian path in Wiener space, where it is shown that
probabilistic complexity converges to only half of the worst case complexity in
this limit.
</summary>
    <author>
      <name>Mark A. Kon</name>
    </author>
    <link href="http://arxiv.org/abs/1212.1263v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.1263v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.1496v2</id>
    <updated>2013-01-14T17:55:24Z</updated>
    <published>2012-12-06T23:06:32Z</published>
    <title>Excess risk bounds for multitask learning with trace norm regularization</title>
    <summary>  Trace norm regularization is a popular method of multitask learning. We give
excess risk bounds with explicit dependence on the number of tasks, the number
of examples per task and properties of the data distribution. The bounds are
independent of the dimension of the input space, which may be infinite as in
the case of reproducing kernel Hilbert spaces. A byproduct of the proof are
bounds on the expected norm of sums of random positive semidefinite matrices
with subexponential moments.
</summary>
    <author>
      <name>Andreas Maurer</name>
    </author>
    <author>
      <name>Massimiliano Pontil</name>
    </author>
    <link href="http://arxiv.org/abs/1212.1496v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.1496v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.2767v1</id>
    <updated>2012-12-12T10:55:27Z</updated>
    <published>2012-12-12T10:55:27Z</published>
    <title>Bayesian one-mode projection for dynamic bipartite graphs</title>
    <summary>  We propose a Bayesian methodology for one-mode projecting a bipartite network
that is being observed across a series of discrete time steps. The resulting
one mode network captures the uncertainty over the presence/absence of each
link and provides a probability distribution over its possible weight values.
Additionally, the incorporation of prior knowledge over previous states makes
the resulting network less sensitive to noise and missing observations that
usually take place during the data collection process. The methodology consists
of computationally inexpensive update rules and is scalable to large problems,
via an appropriate distributed implementation.
</summary>
    <author>
      <name>Ioannis Psorakis</name>
    </author>
    <author>
      <name>Iead Rezek</name>
    </author>
    <author>
      <name>Zach Frankel</name>
    </author>
    <author>
      <name>Stephen J. Roberts</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1212.2767v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.2767v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.4562v1</id>
    <updated>2012-12-19T03:06:13Z</updated>
    <published>2012-12-19T03:06:13Z</published>
    <title>A complexity analysis of statistical learning algorithms</title>
    <summary>  We apply information-based complexity analysis to support vector machine
(SVM) algorithms, with the goal of a comprehensive continuous algorithmic
analysis of such algorithms. This involves complexity measures in which some
higher order operations (e.g., certain optimizations) are considered primitive
for the purposes of measuring complexity. We consider classes of information
operators and algorithms made up of scaled families, and investigate the
utility of scaling the complexities to minimize error. We look at the division
of statistical learning into information and algorithmic components, at the
complexities of each, and at applications to support vector machine (SVM) and
more general machine learning algorithms. We give applications to SVM
algorithms graded into linear and higher order components, and give an example
in biomedical informatics.
</summary>
    <author>
      <name>Mark A. Kon</name>
    </author>
    <link href="http://arxiv.org/abs/1212.4562v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.4562v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.0142v1</id>
    <updated>2013-01-01T22:52:22Z</updated>
    <published>2013-01-01T22:52:22Z</published>
    <title>Semi-Supervised Domain Adaptation with Non-Parametric Copulas</title>
    <summary>  A new framework based on the theory of copulas is proposed to address semi-
supervised domain adaptation problems. The presented method factorizes any
multivariate density into a product of marginal distributions and bivariate
cop- ula functions. Therefore, changes in each of these factors can be detected
and corrected to adapt a density model accross different learning domains.
Impor- tantly, we introduce a novel vine copula model, which allows for this
factorization in a non-parametric manner. Experimental results on regression
problems with real-world data illustrate the efficacy of the proposed approach
when compared to state-of-the-art techniques.
</summary>
    <author>
      <name>David Lopez-Paz</name>
    </author>
    <author>
      <name>José Miguel Hernández-Lobato</name>
    </author>
    <author>
      <name>Bernhard Schölkopf</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, Appearing on Advances in Neural Information Processing
  Systems 25</arxiv:comment>
    <link href="http://arxiv.org/abs/1301.0142v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.0142v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.1919v1</id>
    <updated>2013-01-09T16:48:07Z</updated>
    <published>2013-01-09T16:48:07Z</published>
    <title>Nonparametric Reduced Rank Regression</title>
    <summary>  We propose an approach to multivariate nonparametric regression that
generalizes reduced rank regression for linear models. An additive model is
estimated for each dimension of a $q$-dimensional response, with a shared
$p$-dimensional predictor variable. To control the complexity of the model, we
employ a functional form of the Ky-Fan or nuclear norm, resulting in a set of
function estimates that have low rank. Backfitting algorithms are derived and
justified using a nonparametric form of the nuclear norm subdifferential.
Oracle inequalities on excess risk are derived that exhibit the scaling
behavior of the procedure in the high dimensional setting. The methods are
illustrated on gene expression data.
</summary>
    <author>
      <name>Rina Foygel</name>
    </author>
    <author>
      <name>Michael Horrell</name>
    </author>
    <author>
      <name>Mathias Drton</name>
    </author>
    <author>
      <name>John Lafferty</name>
    </author>
    <link href="http://arxiv.org/abs/1301.1919v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.1919v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.2007v1</id>
    <updated>2013-01-09T23:48:15Z</updated>
    <published>2013-01-09T23:48:15Z</published>
    <title>Spectral Clustering Based on Local PCA</title>
    <summary>  We propose a spectral clustering method based on local principal components
analysis (PCA). After performing local PCA in selected neighborhoods, the
algorithm builds a nearest neighbor graph weighted according to a discrepancy
between the principal subspaces in the neighborhoods, and then applies spectral
clustering. As opposed to standard spectral methods based solely on pairwise
distances between points, our algorithm is able to resolve intersections. We
establish theoretical guarantees for simpler variants within a prototypical
mathematical framework for multi-manifold clustering, and evaluate our
algorithm on various simulated data sets.
</summary>
    <author>
      <name>Ery Arias-Castro</name>
    </author>
    <author>
      <name>Gilad Lerman</name>
    </author>
    <author>
      <name>Teng Zhang</name>
    </author>
    <link href="http://arxiv.org/abs/1301.2007v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.2007v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.2115v1</id>
    <updated>2013-01-10T13:29:17Z</updated>
    <published>2013-01-10T13:29:17Z</published>
    <title>Domain Generalization via Invariant Feature Representation</title>
    <summary>  This paper investigates domain generalization: How to take knowledge acquired
from an arbitrary number of related domains and apply it to previously unseen
domains? We propose Domain-Invariant Component Analysis (DICA), a kernel-based
optimization algorithm that learns an invariant transformation by minimizing
the dissimilarity across domains, whilst preserving the functional relationship
between input and output variables. A learning-theoretic analysis shows that
reducing dissimilarity improves the expected generalization ability of
classifiers on new domains, motivating the proposed algorithm. Experimental
results on synthetic and real-world datasets demonstrate that DICA successfully
learns invariant features and improves classifier performance in practice.
</summary>
    <author>
      <name>Krikamol Muandet</name>
    </author>
    <author>
      <name>David Balduzzi</name>
    </author>
    <author>
      <name>Bernhard Schölkopf</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The 30th International Conference on Machine Learning (ICML 2013)</arxiv:comment>
    <link href="http://arxiv.org/abs/1301.2115v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.2115v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.2656v1</id>
    <updated>2013-01-12T07:46:56Z</updated>
    <published>2013-01-12T07:46:56Z</published>
    <title>Multiple functional regression with both discrete and continuous
  covariates</title>
    <summary>  In this paper we present a nonparametric method for extending functional
regression methodology to the situation where more than one functional
covariate is used to predict a functional response. Borrowing the idea from
Kadri et al. (2010a), the method, which support mixed discrete and continuous
explanatory variables, is based on estimating a function-valued function in
reproducing kernel Hilbert spaces by virtue of positive operator-valued
kernels.
</summary>
    <author>
      <name>Hachem Kadri</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Lille - Nord Europe</arxiv:affiliation>
    </author>
    <author>
      <name>Philippe Preux</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Lille - Nord Europe, LIFL</arxiv:affiliation>
    </author>
    <author>
      <name>Emmanuel Duflos</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Lille - Nord Europe, LAGIS</arxiv:affiliation>
    </author>
    <author>
      <name>Stéphane Canu</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LITIS</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">2nd International Workshop on Functional and Operatorial
  Statistics (IWFOS), Santander : Spain (2011)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1301.2656v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.2656v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.3570v1</id>
    <updated>2013-01-16T03:24:43Z</updated>
    <published>2013-01-16T03:24:43Z</published>
    <title>A Nested HDP for Hierarchical Topic Models</title>
    <summary>  We develop a nested hierarchical Dirichlet process (nHDP) for hierarchical
topic modeling. The nHDP is a generalization of the nested Chinese restaurant
process (nCRP) that allows each word to follow its own path to a topic node
according to a document-specific distribution on a shared tree. This alleviates
the rigid, single-path formulation of the nCRP, allowing a document to more
easily express thematic borrowings as a random effect. We demonstrate our
algorithm on 1.8 million documents from The New York Times.
</summary>
    <author>
      <name>John Paisley</name>
    </author>
    <author>
      <name>Chong Wang</name>
    </author>
    <author>
      <name>David Blei</name>
    </author>
    <author>
      <name>Michael I. Jordan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to the workshop track of the International Conference on
  Learning Representations 2013. It is a short version of a longer paper</arxiv:comment>
    <link href="http://arxiv.org/abs/1301.3570v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.3570v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.4944v1</id>
    <updated>2013-01-21T18:17:05Z</updated>
    <published>2013-01-21T18:17:05Z</published>
    <title>Evaluation of a Supervised Learning Approach for Stock Market Operations</title>
    <summary>  Data mining methods have been widely applied in financial markets, with the
purpose of providing suitable tools for prices forecasting and automatic
trading. Particularly, learning methods aim to identify patterns in time series
and, based on such patterns, to recommend buy/sell operations. The objective of
this work is to evaluate the performance of Random Forests, a supervised
learning method based on ensembles of decision trees, for decision support in
stock markets. Preliminary results indicate good rates of successful operations
and good rates of return per operation, providing a strong motivation for
further research in this topic.
</summary>
    <author>
      <name>Marcelo S. Lauretto</name>
    </author>
    <author>
      <name>Barbara B. C. Silva</name>
    </author>
    <author>
      <name>Pablo M. Andrade</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1301.4944v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.4944v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.7189v2</id>
    <updated>2013-07-02T20:30:47Z</updated>
    <published>2013-01-30T10:40:07Z</published>
    <title>Approximate Counting of Graphical Models Via MCMC Revisited</title>
    <summary>  In Pe\~na (2007), MCMC sampling is applied to approximately calculate the
ratio of essential graphs (EGs) to directed acyclic graphs (DAGs) for up to 20
nodes. In the present paper, we extend that work from 20 to 31 nodes. We also
extend that work by computing the approximate ratio of connected EGs to
connected DAGs, of connected EGs to EGs, and of connected DAGs to DAGs.
Furthermore, we prove that the latter ratio is asymptotically 1. We also
discuss the implications of these results for learning DAGs from data.
</summary>
    <author>
      <name>Jose M. Peña</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings of the 15th Conference of the Spanish Association for
  Artificial Intelligence (CAEPIA 2013). Lecture Notes in Artificial
  Intelligence</arxiv:comment>
    <link href="http://arxiv.org/abs/1301.7189v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.7189v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1302.2672v1</id>
    <updated>2013-02-12T00:14:44Z</updated>
    <published>2013-02-12T00:14:44Z</published>
    <title>Competing With Strategies</title>
    <summary>  We study the problem of online learning with a notion of regret defined with
respect to a set of strategies. We develop tools for analyzing the minimax
rates and for deriving regret-minimization algorithms in this scenario. While
the standard methods for minimizing the usual notion of regret fail, through
our analysis we demonstrate existence of regret-minimization methods that
compete with such sets of strategies as: autoregressive algorithms, strategies
based on statistical models, regularized least squares, and follow the
regularized leader strategies. In several cases we also derive efficient
learning algorithms.
</summary>
    <author>
      <name>Wei Han</name>
    </author>
    <author>
      <name>Alexander Rakhlin</name>
    </author>
    <author>
      <name>Karthik Sridharan</name>
    </author>
    <link href="http://arxiv.org/abs/1302.2672v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1302.2672v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1302.3700v1</id>
    <updated>2013-02-15T08:16:14Z</updated>
    <published>2013-02-15T08:16:14Z</published>
    <title>Density Ratio Hidden Markov Models</title>
    <summary>  Hidden Markov models and their variants are the predominant sequential
classification method in such domains as speech recognition, bioinformatics and
natural language processing. Being generative rather than discriminative
models, however, their classification performance is a drawback. In this paper
we apply ideas from the field of density ratio estimation to bypass the
difficult step of learning likelihood functions in HMMs. By reformulating
inference and model fitting in terms of density ratios and applying a fast
kernel-based estimation method, we show that it is possible to obtain a
striking increase in discriminative performance while retaining the
probabilistic qualities of the HMM. We demonstrate experimentally that this
formulation makes more efficient use of training data than alternative
approaches.
</summary>
    <author>
      <name>John A. Quinn</name>
    </author>
    <author>
      <name>Masashi Sugiyama</name>
    </author>
    <link href="http://arxiv.org/abs/1302.3700v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1302.3700v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1302.4773v1</id>
    <updated>2013-02-19T22:59:44Z</updated>
    <published>2013-02-19T22:59:44Z</published>
    <title>Optimal Discriminant Functions Based On Sampled Distribution Distance
  for Modulation Classification</title>
    <summary>  In this letter, we derive the optimal discriminant functions for modulation
classification based on the sampled distribution distance. The proposed method
classifies various candidate constellations using a low complexity approach
based on the distribution distance at specific testpoints along the cumulative
distribution function. This method, based on the Bayesian decision criteria,
asymptotically provides the minimum classification error possible given a set
of testpoints. Testpoint locations are also optimized to improve classification
performance. The method provides significant gains over existing approaches
that also use the distribution of the signal features.
</summary>
    <author>
      <name>Paulo Urriza</name>
    </author>
    <author>
      <name>Eric Rebeiz</name>
    </author>
    <author>
      <name>Danijela Cabric</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/LCOMM.2013.082113.131131</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/LCOMM.2013.082113.131131" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 3 figures, submitted to IEEE Communications Letters</arxiv:comment>
    <link href="http://arxiv.org/abs/1302.4773v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1302.4773v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1302.6452v1</id>
    <updated>2013-02-26T15:16:32Z</updated>
    <published>2013-02-26T15:16:32Z</published>
    <title>A Conformal Prediction Approach to Explore Functional Data</title>
    <summary>  This paper applies conformal prediction techniques to compute simultaneous
prediction bands and clustering trees for functional data. These tools can be
used to detect outliers and clusters. Both our prediction bands and clustering
trees provide prediction sets for the underlying stochastic process with a
guaranteed finite sample behavior, under no distributional assumptions. The
prediction sets are also informative in that they correspond to the high
density region of the underlying process. While ordinary conformal prediction
has high computational cost for functional data, we use the inductive conformal
predictor, together with several novel choices of conformity scores, to
simplify the computation. Our methods are illustrated on some real data
examples.
</summary>
    <author>
      <name>Jing Lei</name>
    </author>
    <author>
      <name>Alessandro Rinaldo</name>
    </author>
    <author>
      <name>Larry Wasserman</name>
    </author>
    <link href="http://arxiv.org/abs/1302.6452v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1302.6452v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1303.2517v1</id>
    <updated>2013-03-11T13:34:51Z</updated>
    <published>2013-03-11T13:34:51Z</published>
    <title>Refinement revisited with connections to Bayes error, conditional
  entropy and calibrated classifiers</title>
    <summary>  The concept of refinement from probability elicitation is considered for
proper scoring rules. Taking directions from the axioms of probability,
refinement is further clarified using a Hilbert space interpretation and
reformulated into the underlying data distribution setting where connections to
maximal marginal diversity and conditional entropy are considered and used to
derive measures that provide arbitrarily tight bounds on the Bayes error.
Refinement is also reformulated into the classifier output setting and its
connections to calibrated classifiers and proper margin losses are established.
</summary>
    <author>
      <name>Hamed Masnadi-Shirazi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">25 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1303.2517v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1303.2517v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1303.6811v1</id>
    <updated>2013-03-27T12:45:48Z</updated>
    <published>2013-03-27T12:45:48Z</published>
    <title>Sparse approximation and recovery by greedy algorithms in Banach spaces</title>
    <summary>  We study sparse approximation by greedy algorithms. We prove the
Lebesgue-type inequalities for the Weak Chebyshev Greedy Algorithm (WCGA), a
generalization of the Weak Orthogonal Matching Pursuit to the case of a Banach
space. The main novelty of these results is a Banach space setting instead of a
Hilbert space setting. The results are proved for redundant dictionaries
satisfying certain conditions. Then we apply these general results to the case
of bases. In particular, we prove that the WCGA provides almost optimal sparse
approximation for the trigonometric system in $L_p$, $2\le p&lt;\infty$.
</summary>
    <author>
      <name>Vladimir Temlyakov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: substantial text overlap with arXiv:1303.3595</arxiv:comment>
    <link href="http://arxiv.org/abs/1303.6811v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1303.6811v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.FA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="41A65" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.0596v1</id>
    <updated>2013-04-02T11:49:11Z</updated>
    <published>2013-04-02T11:49:11Z</published>
    <title>A Semiparametric Bayesian Extreme Value Model Using a Dirichlet Process
  Mixture of Gamma Densities</title>
    <summary>  In this paper we propose a model with a Dirichlet process mixture of gamma
densities in the bulk part below threshold and a generalized Pareto density in
the tail for extreme value estimation. The proposed model is simple and
flexible allowing us posterior density estimation and posterior inference for
high quantiles. The model works well even for small sample sizes and in the
absence of prior information. We evaluate the performance of the proposed model
through a simulation study. Finally, the proposed model is applied to a real
environmental data.
</summary>
    <author>
      <name>Jairo Fuquene</name>
    </author>
    <link href="http://arxiv.org/abs/1304.0596v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.0596v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.3568v1</id>
    <updated>2013-04-12T08:47:38Z</updated>
    <published>2013-04-12T08:47:38Z</published>
    <title>Distributed dictionary learning over a sensor network</title>
    <summary>  We consider the problem of distributed dictionary learning, where a set of
nodes is required to collectively learn a common dictionary from noisy
measurements. This approach may be useful in several contexts including sensor
networks. Diffusion cooperation schemes have been proposed to solve the
distributed linear regression problem. In this work we focus on a
diffusion-based adaptive dictionary learning strategy: each node records
observations and cooperates with its neighbors by sharing its local dictionary.
The resulting algorithm corresponds to a distributed block coordinate descent
(alternate optimization). Beyond dictionary learning, this strategy could be
adapted to many matrix factorization problems and generalized to various
settings. This article presents our approach and illustrates its efficiency on
some numerical examples.
</summary>
    <author>
      <name>Pierre Chainais</name>
    </author>
    <author>
      <name>Cédric Richard</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1304.3568v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.3568v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.5245v2</id>
    <updated>2015-12-24T22:09:57Z</updated>
    <published>2013-04-18T20:25:15Z</published>
    <title>Feature Elimination in Kernel Machines in moderately high dimensions</title>
    <summary>  We develop an approach for feature elimination in statistical learning with
kernel machines, based on recursive elimination of features.We present
theoretical properties of this method and show that it is uniformly consistent
in finding the correct feature space under certain generalized assumptions.We
present four case studies to show that the assumptions are met in most
practical situations and present simulation results to demonstrate performance
of the proposed approach.
</summary>
    <author>
      <name>Sayan Dasgupta</name>
    </author>
    <author>
      <name>Yair Goldberg</name>
    </author>
    <author>
      <name>Michael Kosorok</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">50 pages, 5 figures, submitted to Annals of Statistics</arxiv:comment>
    <link href="http://arxiv.org/abs/1304.5245v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.5245v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T05, 62G08," scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.7230v2</id>
    <updated>2013-04-29T21:16:46Z</updated>
    <published>2013-04-26T16:56:30Z</published>
    <title>Learning Densities Conditional on Many Interacting Features</title>
    <summary>  Learning a distribution conditional on a set of discrete-valued features is a
commonly encountered task. This becomes more challenging with a
high-dimensional feature set when there is the possibility of interaction
between the features. In addition, many frequently applied techniques consider
only prediction of the mean, but the complete conditional density is needed to
answer more complex questions. We demonstrate a novel nonparametric Bayes
method based upon a tensor factorization of feature-dependent weights for
Gaussian kernels. The method makes use of multistage feature selection for
dimension reduction. The resulting conditional density morphs flexibly with the
selected features.
</summary>
    <author>
      <name>David C. Kessler</name>
    </author>
    <author>
      <name>Jack Taylor</name>
    </author>
    <author>
      <name>David B. Dunson</name>
    </author>
    <link href="http://arxiv.org/abs/1304.7230v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.7230v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.7717v2</id>
    <updated>2013-06-03T09:24:00Z</updated>
    <published>2013-04-29T17:27:50Z</published>
    <title>The Randomized Dependence Coefficient</title>
    <summary>  We introduce the Randomized Dependence Coefficient (RDC), a measure of
non-linear dependence between random variables of arbitrary dimension based on
the Hirschfeld-Gebelein-R\'enyi Maximum Correlation Coefficient. RDC is defined
in terms of correlation of random non-linear copula projections; it is
invariant with respect to marginal distribution transformations, has low
computational cost and is easy to implement: just five lines of R code,
included at the end of the paper.
</summary>
    <author>
      <name>David Lopez-Paz</name>
    </author>
    <author>
      <name>Philipp Hennig</name>
    </author>
    <author>
      <name>Bernhard Schölkopf</name>
    </author>
    <link href="http://arxiv.org/abs/1304.7717v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.7717v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.7981v5</id>
    <updated>2014-06-26T21:41:48Z</updated>
    <published>2013-04-30T13:06:35Z</published>
    <title>Generalized Canonical Correlation Analysis for Classification</title>
    <summary>  For multiple multivariate data sets, we derive conditions under which
Generalized Canonical Correlation Analysis (GCCA) improves classification
performance of the projected datasets, compared to standard Canonical
Correlation Analysis (CCA) using only two data sets. We illustrate our
theoretical results with simulations and a real data experiment.
</summary>
    <author>
      <name>Cencheng Shen</name>
    </author>
    <author>
      <name>Ming Sun</name>
    </author>
    <author>
      <name>Minh Tang</name>
    </author>
    <author>
      <name>Carey E. Priebe</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.jmva.2014.05.011</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.jmva.2014.05.011" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">28 pages, 3 figures, 7 tables</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Multivariate Analysis 130 (2014) 310-322</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1304.7981v5" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.7981v5" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1305.0855v1</id>
    <updated>2013-05-03T23:01:50Z</updated>
    <published>2013-05-03T23:01:50Z</published>
    <title>Inference in Kingman's Coalescent with Particle Markov Chain Monte Carlo
  Method</title>
    <summary>  We propose a new algorithm to do posterior sampling of Kingman's coalescent,
based upon the Particle Markov Chain Monte Carlo methodology. Specifically, the
algorithm is an instantiation of the Particle Gibbs Sampling method, which
alternately samples coalescent times conditioned on coalescent tree structures,
and tree structures conditioned on coalescent times via the conditional
Sequential Monte Carlo procedure. We implement our algorithm as a C++ package,
and demonstrate its utility via a parameter estimation task in population
genetics on both single- and multiple-locus data. The experiment results show
that the proposed algorithm performs comparable to or better than several
well-developed methods.
</summary>
    <author>
      <name>Yifei Chen</name>
    </author>
    <author>
      <name>Xiaohui Xie</name>
    </author>
    <link href="http://arxiv.org/abs/1305.0855v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1305.0855v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.PE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1305.1809v2</id>
    <updated>2014-05-02T09:44:45Z</updated>
    <published>2013-05-08T13:11:52Z</published>
    <title>Cover Tree Bayesian Reinforcement Learning</title>
    <summary>  This paper proposes an online tree-based Bayesian approach for reinforcement
learning. For inference, we employ a generalised context tree model. This
defines a distribution on multivariate Gaussian piecewise-linear models, which
can be updated in closed form. The tree structure itself is constructed using
the cover tree method, which remains efficient in high dimensional spaces. We
combine the model with Thompson sampling and approximate dynamic programming to
obtain effective exploration policies in unknown environments. The flexibility
and computational simplicity of the model render it suitable for many
reinforcement learning problems in continuous state spaces. We demonstrate this
in an experimental comparison with least squares policy iteration.
</summary>
    <author>
      <name>Nikolaos Tziortziotis</name>
    </author>
    <author>
      <name>Christos Dimitrakakis</name>
    </author>
    <author>
      <name>Konstantinos Blekas</name>
    </author>
    <link href="http://arxiv.org/abs/1305.1809v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1305.1809v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1305.1998v1</id>
    <updated>2013-05-09T03:15:19Z</updated>
    <published>2013-05-09T03:15:19Z</published>
    <title>Inferring Team Strengths Using a Discrete Markov Random Field</title>
    <summary>  We propose an original model for inferring team strengths using a Markov
Random Field, which can be used to generate historical estimates of the
offensive and defensive strengths of a team over time. This model was designed
to be applied to sports such as soccer or hockey, in which contest outcomes
take value in a limited discrete space. We perform inference using a
combination of Expectation Maximization and Loopy Belief Propagation. The
challenges of working with a non-convex optimization problem and a
high-dimensional parameter space are discussed. The performance of the model is
demonstrated on professional soccer data from the English Premier League.
</summary>
    <author>
      <name>John Zech</name>
    </author>
    <author>
      <name>Frank Wood</name>
    </author>
    <link href="http://arxiv.org/abs/1305.1998v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1305.1998v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1305.2581v1</id>
    <updated>2013-05-12T12:46:25Z</updated>
    <published>2013-05-12T12:46:25Z</published>
    <title>Accelerated Mini-Batch Stochastic Dual Coordinate Ascent</title>
    <summary>  Stochastic dual coordinate ascent (SDCA) is an effective technique for
solving regularized loss minimization problems in machine learning. This paper
considers an extension of SDCA under the mini-batch setting that is often used
in practice. Our main contribution is to introduce an accelerated mini-batch
version of SDCA and prove a fast convergence rate for this method. We discuss
an implementation of our method over a parallel computing system, and compare
the results to both the vanilla stochastic dual coordinate ascent and to the
accelerated deterministic gradient descent method of
\cite{nesterov2007gradient}.
</summary>
    <author>
      <name>Shai Shalev-Shwartz</name>
    </author>
    <author>
      <name>Tong Zhang</name>
    </author>
    <link href="http://arxiv.org/abs/1305.2581v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1305.2581v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1305.3120v1</id>
    <updated>2013-05-14T11:49:34Z</updated>
    <published>2013-05-14T11:49:34Z</published>
    <title>Optimization with First-Order Surrogate Functions</title>
    <summary>  In this paper, we study optimization methods consisting of iteratively
minimizing surrogates of an objective function. By proposing several
algorithmic variants and simple convergence analyses, we make two main
contributions. First, we provide a unified viewpoint for several first-order
optimization techniques such as accelerated proximal gradient, block coordinate
descent, or Frank-Wolfe algorithms. Second, we introduce a new incremental
scheme that experimentally matches or outperforms state-of-the-art solvers for
large-scale optimization problems typically arising in machine learning.
</summary>
    <author>
      <name>Julien Mairal</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Grenoble Rhône-Alpes / LJK Laboratoire Jean Kuntzmann</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">to appear in the proceedings of ICML 2013; the arxiv paper contains
  the 9 pages main text followed by 26 pages of supplemental material.
  International Conference on Machine Learning (ICML 2013) (2013)</arxiv:comment>
    <link href="http://arxiv.org/abs/1305.3120v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1305.3120v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1305.4153v1</id>
    <updated>2013-05-17T18:44:50Z</updated>
    <published>2013-05-17T18:44:50Z</published>
    <title>Factored expectation propagation for input-output FHMM models in systems
  biology</title>
    <summary>  We consider the problem of joint modelling of metabolic signals and gene
expression in systems biology applications. We propose an approach based on
input-output factorial hidden Markov models and propose a structured
variational inference approach to infer the structure and states of the model.
We start from the classical free form structured variational mean field
approach and use a expectation propagation to approximate the expectations
needed in the variational loop. We show that this corresponds to a factored
expectation constrained approximate inference. We validate our model through
extensive simulations and demonstrate its applicability on a real world
bacterial data set.
</summary>
    <author>
      <name>Botond Cseke</name>
    </author>
    <author>
      <name>Guido Sanguinetti</name>
    </author>
    <link href="http://arxiv.org/abs/1305.4153v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1305.4153v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1306.0407v2</id>
    <updated>2013-06-15T02:01:22Z</updated>
    <published>2013-06-03T13:54:34Z</published>
    <title>Constructive Setting of the Density Ratio Estimation Problem and its
  Rigorous Solution</title>
    <summary>  We introduce a general constructive setting of the density ratio estimation
problem as a solution of a (multidimensional) integral equation. In this
equation, not only its right hand side is known approximately, but also the
integral operator is defined approximately. We show that this ill-posed problem
has a rigorous solution and obtain the solution in a closed form. The key
element of this solution is the novel V-matrix, which captures the geometry of
the observed samples. We compare our method with three well-known previously
proposed ones. Our experimental results demonstrate the good potential of the
new approach.
</summary>
    <author>
      <name>Vladimir Vapnik</name>
    </author>
    <author>
      <name>Igor Braga</name>
    </author>
    <author>
      <name>Rauf Izmailov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Added funding information</arxiv:comment>
    <link href="http://arxiv.org/abs/1306.0407v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1306.0407v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1306.1185v1</id>
    <updated>2013-06-05T17:42:57Z</updated>
    <published>2013-06-05T17:42:57Z</published>
    <title>Multiclass Total Variation Clustering</title>
    <summary>  Ideas from the image processing literature have recently motivated a new set
of clustering algorithms that rely on the concept of total variation. While
these algorithms perform well for bi-partitioning tasks, their recursive
extensions yield unimpressive results for multiclass clustering tasks. This
paper presents a general framework for multiclass total variation clustering
that does not rely on recursion. The results greatly outperform previous total
variation algorithms and compare well with state-of-the-art NMF approaches.
</summary>
    <author>
      <name>Xavier Bresson</name>
    </author>
    <author>
      <name>Thomas Laurent</name>
    </author>
    <author>
      <name>David Uminsky</name>
    </author>
    <author>
      <name>James H. von Brecht</name>
    </author>
    <link href="http://arxiv.org/abs/1306.1185v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1306.1185v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1306.2084v1</id>
    <updated>2013-06-10T01:45:49Z</updated>
    <published>2013-06-10T01:45:49Z</published>
    <title>Logistic Tensor Factorization for Multi-Relational Data</title>
    <summary>  Tensor factorizations have become increasingly popular approaches for various
learning tasks on structured data. In this work, we extend the RESCAL tensor
factorization, which has shown state-of-the-art results for multi-relational
learning, to account for the binary nature of adjacency tensors. We study the
improvements that can be gained via this approach on various benchmark datasets
and show that the logistic extension can improve the prediction results
significantly.
</summary>
    <author>
      <name>Maximilian Nickel</name>
    </author>
    <author>
      <name>Volker Tresp</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at ICML 2013 Workshop "Structured Learning: Inferring Graphs
  from Structured and Unstructured Inputs" (SLG 2013)</arxiv:comment>
    <link href="http://arxiv.org/abs/1306.2084v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1306.2084v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1306.3862v1</id>
    <updated>2013-06-17T13:57:05Z</updated>
    <published>2013-06-17T13:57:05Z</published>
    <title>Bayesian methods for low-rank matrix estimation: short survey and
  theoretical study</title>
    <summary>  The problem of low-rank matrix estimation recently received a lot of
attention due to challenging applications. A lot of work has been done on
rank-penalized methods and convex relaxation, both on the theoretical and
applied sides. However, only a few papers considered Bayesian estimation. In
this paper, we review the different type of priors considered on matrices to
favour low-rank. We also prove that the obtained Bayesian estimators, under
suitable assumptions, enjoys the same optimality properties as the ones based
on penalization.
</summary>
    <author>
      <name>Pierre Alquier</name>
    </author>
    <link href="http://arxiv.org/abs/1306.3862v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1306.3862v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.0578v1</id>
    <updated>2013-07-02T02:54:09Z</updated>
    <published>2013-07-02T02:54:09Z</published>
    <title>A non-parametric conditional factor regression model for
  high-dimensional input and response</title>
    <summary>  In this paper, we propose a non-parametric conditional factor regression
(NCFR)model for domains with high-dimensional input and response. NCFR enhances
linear regression in two ways: a) introducing low-dimensional latent factors
leading to dimensionality reduction and b) integrating an Indian Buffet Process
as a prior for the latent factors to derive unlimited sparse dimensions.
Experimental results comparing NCRF to several alternatives give evidence to
remarkable prediction performance.
</summary>
    <author>
      <name>Ava Bargi</name>
    </author>
    <author>
      <name>Richard Yi Da Xu</name>
    </author>
    <author>
      <name>Massimo Piccardi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 3 figures, NIPS submission</arxiv:comment>
    <link href="http://arxiv.org/abs/1307.0578v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.0578v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.0846v1</id>
    <updated>2013-07-02T20:51:40Z</updated>
    <published>2013-07-02T20:51:40Z</published>
    <title>Semi-supervised Ranking Pursuit</title>
    <summary>  We propose a novel sparse preference learning/ranking algorithm. Our
algorithm approximates the true utility function by a weighted sum of basis
functions using the squared loss on pairs of data points, and is a
generalization of the kernel matching pursuit method. It can operate both in a
supervised and a semi-supervised setting and allows efficient search for
multiple, near-optimal solutions. Furthermore, we describe the extension of the
algorithm suitable for combined ranking and regression tasks. In our
experiments we demonstrate that the proposed algorithm outperforms several
state-of-the-art learning methods when taking into account unlabeled data and
performs comparably in a supervised learning scenario, while providing sparser
solutions.
</summary>
    <author>
      <name>Evgeni Tsivtsivadze</name>
    </author>
    <author>
      <name>Tom Heskes</name>
    </author>
    <link href="http://arxiv.org/abs/1307.0846v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.0846v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.6143v2</id>
    <updated>2013-07-24T13:26:08Z</updated>
    <published>2013-07-23T16:33:00Z</published>
    <title>Generative, Fully Bayesian, Gaussian, Openset Pattern Classifier</title>
    <summary>  This report works out the details of a closed-form, fully Bayesian,
multiclass, openset, generative pattern classifier using multivariate Gaussian
likelihoods, with conjugate priors. The generative model has a common
within-class covariance, which is proportional to the between-class covariance
in the conjugate prior. The scalar proportionality constant is the only plugin
parameter. All other model parameters are intergated out in closed form. An
expression is given for the model evidence, which can be used to make plugin
estimates for the proportionality constant. Pattern recognition is done via the
predictive likeihoods of classes for which training data is available, as well
as a predicitve likelihood for any as yet unseen class.
</summary>
    <author>
      <name>Niko Brummer</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Research Report, BOSARIS 2012 Speaker Recognition Workshop</arxiv:comment>
    <link href="http://arxiv.org/abs/1307.6143v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.6143v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.7981v1</id>
    <updated>2013-07-30T13:59:13Z</updated>
    <published>2013-07-30T13:59:13Z</published>
    <title>Likelihood-ratio calibration using prior-weighted proper scoring rules</title>
    <summary>  Prior-weighted logistic regression has become a standard tool for calibration
in speaker recognition. Logistic regression is the optimization of the expected
value of the logarithmic scoring rule. We generalize this via a parametric
family of proper scoring rules. Our theoretical analysis shows how different
members of this family induce different relative weightings over a spectrum of
applications of which the decision thresholds range from low to high. Special
attention is given to the interaction between prior weighting and proper
scoring rule parameters. Experiments on NIST SRE'12 suggest that for
applications with low false-alarm rate requirements, scoring rules tailored to
emphasize higher score thresholds may give better accuracy than logistic
regression.
</summary>
    <author>
      <name>Niko Brümmer</name>
    </author>
    <author>
      <name>George Doddington</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted, Interspeech 2013</arxiv:comment>
    <link href="http://arxiv.org/abs/1307.7981v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.7981v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1308.2867v2</id>
    <updated>2014-04-14T15:20:52Z</updated>
    <published>2013-08-13T13:55:12Z</published>
    <title>Composite Self-Concordant Minimization</title>
    <summary>  We propose a variable metric framework for minimizing the sum of a
self-concordant function and a possibly non-smooth convex function, endowed
with an easily computable proximal operator. We theoretically establish the
convergence of our framework without relying on the usual Lipschitz gradient
assumption on the smooth part. An important highlight of our work is a new set
of analytic step-size selection and correction procedures based on the
structure of the problem. We describe concrete algorithmic instances of our
framework for several interesting applications and demonstrate them numerically
on both synthetic and real data.
</summary>
    <author>
      <name>Quoc Tran-Dinh</name>
    </author>
    <author>
      <name>Anastasios Kyrillidis</name>
    </author>
    <author>
      <name>Volkan Cevher</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">46 pages, 9 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1308.2867v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1308.2867v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1308.3314v1</id>
    <updated>2013-08-15T06:15:21Z</updated>
    <published>2013-08-15T06:15:21Z</published>
    <title>The algorithm of noisy k-means</title>
    <summary>  In this note, we introduce a new algorithm to deal with finite dimensional
clustering with errors in variables. The design of this algorithm is based on
recent theoretical advances (see Loustau (2013a,b)) in statistical learning
with errors in variables. As the previous mentioned papers, the algorithm mixes
different tools from the inverse problem literature and the machine learning
community. Coarsely, it is based on a two-step procedure: (1) a deconvolution
step to deal with noisy inputs and (2) Newton's iterations as the popular
k-means.
</summary>
    <author>
      <name>Camille Brunet</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LAREMA</arxiv:affiliation>
    </author>
    <author>
      <name>Sébastien Loustau</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LAREMA</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/1308.3314v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1308.3314v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1308.4214v1</id>
    <updated>2013-08-20T02:50:43Z</updated>
    <published>2013-08-20T02:50:43Z</published>
    <title>Pylearn2: a machine learning research library</title>
    <summary>  Pylearn2 is a machine learning research library. This does not just mean that
it is a collection of machine learning algorithms that share a common API; it
means that it has been designed for flexibility and extensibility in order to
facilitate research projects that involve new or unusual use cases. In this
paper we give a brief history of the library, an overview of its basic
philosophy, a summary of the library's architecture, and a description of how
the Pylearn2 community functions socially.
</summary>
    <author>
      <name>Ian J. Goodfellow</name>
    </author>
    <author>
      <name>David Warde-Farley</name>
    </author>
    <author>
      <name>Pascal Lamblin</name>
    </author>
    <author>
      <name>Vincent Dumoulin</name>
    </author>
    <author>
      <name>Mehdi Mirza</name>
    </author>
    <author>
      <name>Razvan Pascanu</name>
    </author>
    <author>
      <name>James Bergstra</name>
    </author>
    <author>
      <name>Frédéric Bastien</name>
    </author>
    <author>
      <name>Yoshua Bengio</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1308.4214v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1308.4214v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1308.6342v4</id>
    <updated>2014-02-05T17:59:18Z</updated>
    <published>2013-08-29T01:55:37Z</published>
    <title>Linear and Parallel Learning of Markov Random Fields</title>
    <summary>  We introduce a new embarrassingly parallel parameter learning algorithm for
Markov random fields with untied parameters which is efficient for a large
class of practical models. Our algorithm parallelizes naturally over cliques
and, for graphs of bounded degree, its complexity is linear in the number of
cliques. Unlike its competitors, our algorithm is fully parallel and for
log-linear models it is also data efficient, requiring only the local
sufficient statistics of the data to estimate parameters.
</summary>
    <author>
      <name>Yariv Dror Mizrahi</name>
    </author>
    <author>
      <name>Misha Denil</name>
    </author>
    <author>
      <name>Nando de Freitas</name>
    </author>
    <link href="http://arxiv.org/abs/1308.6342v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1308.6342v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1309.0337v1</id>
    <updated>2013-09-02T09:34:50Z</updated>
    <published>2013-09-02T09:34:50Z</published>
    <title>Scalable Probabilistic Entity-Topic Modeling</title>
    <summary>  We present an LDA approach to entity disambiguation. Each topic is associated
with a Wikipedia article and topics generate either content words or entity
mentions. Training such models is challenging because of the topic and
vocabulary size, both in the millions. We tackle these problems using a novel
distributed inference and representation framework based on a parallel Gibbs
sampler guided by the Wikipedia link graph, and pipelines of MapReduce allowing
fast and memory-frugal processing of large datasets. We report state-of-the-art
performance on a public dataset.
</summary>
    <author>
      <name>Neil Houlsby</name>
    </author>
    <author>
      <name>Massimiliano Ciaramita</name>
    </author>
    <link href="http://arxiv.org/abs/1309.0337v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1309.0337v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1309.1193v2</id>
    <updated>2013-10-09T17:59:10Z</updated>
    <published>2013-09-04T21:46:55Z</published>
    <title>Confidence-constrained joint sparsity recovery under the Poisson noise
  model</title>
    <summary>  Our work is focused on the joint sparsity recovery problem where the common
sparsity pattern is corrupted by Poisson noise. We formulate the
confidence-constrained optimization problem in both least squares (LS) and
maximum likelihood (ML) frameworks and study the conditions for perfect
reconstruction of the original row sparsity and row sparsity pattern. However,
the confidence-constrained optimization problem is non-convex. Using convex
relaxation, an alternative convex reformulation of the problem is proposed. We
evaluate the performance of the proposed approach using simulation results on
synthetic data and show the effectiveness of proposed row sparsity and row
sparsity pattern recovery framework.
</summary>
    <author>
      <name>E. Chunikhina</name>
    </author>
    <author>
      <name>R. Raich</name>
    </author>
    <author>
      <name>T. Nguyen</name>
    </author>
    <link href="http://arxiv.org/abs/1309.1193v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1309.1193v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1309.1233v2</id>
    <updated>2015-01-22T06:44:45Z</updated>
    <published>2013-09-05T04:42:00Z</published>
    <title>Noisy Sparse Subspace Clustering</title>
    <summary>  This paper considers the problem of subspace clustering under noise.
Specifically, we study the behavior of Sparse Subspace Clustering (SSC) when
either adversarial or random noise is added to the unlabelled input data
points, which are assumed to be in a union of low-dimensional subspaces. We
show that a modified version of SSC is \emph{provably effective} in correctly
identifying the underlying subspaces, even with noisy data. This extends
theoretical guarantee of this algorithm to more practical settings and provides
justification to the success of SSC in a class of real applications.
</summary>
    <author>
      <name>Yu-Xiang Wang</name>
    </author>
    <author>
      <name>Huan Xu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Manuscript currently under review at journal of machine learning
  research. Previously conference version appeared at ICML'12, and was uploaded
  to ArXiv by the conference committee</arxiv:comment>
    <link href="http://arxiv.org/abs/1309.1233v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1309.1233v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1309.1952v2</id>
    <updated>2014-07-07T05:10:23Z</updated>
    <published>2013-09-08T12:55:39Z</published>
    <title>A Clustering Approach to Learn Sparsely-Used Overcomplete Dictionaries</title>
    <summary>  We consider the problem of learning overcomplete dictionaries in the context
of sparse coding, where each sample selects a sparse subset of dictionary
elements. Our main result is a strategy to approximately recover the unknown
dictionary using an efficient algorithm. Our algorithm is a clustering-style
procedure, where each cluster is used to estimate a dictionary element. The
resulting solution can often be further cleaned up to obtain a high accuracy
estimate, and we provide one simple scenario where $\ell_1$-regularized
regression can be used for such a second stage.
</summary>
    <author>
      <name>Alekh Agarwal</name>
    </author>
    <author>
      <name>Animashree Anandkumar</name>
    </author>
    <author>
      <name>Praneeth Netrapalli</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Part of this work appears in COLT 2014</arxiv:comment>
    <link href="http://arxiv.org/abs/1309.1952v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1309.1952v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1309.2375v2</id>
    <updated>2013-10-08T06:06:09Z</updated>
    <published>2013-09-10T05:39:25Z</published>
    <title>Accelerated Proximal Stochastic Dual Coordinate Ascent for Regularized
  Loss Minimization</title>
    <summary>  We introduce a proximal version of the stochastic dual coordinate ascent
method and show how to accelerate the method using an inner-outer iteration
procedure. We analyze the runtime of the framework and obtain rates that
improve state-of-the-art results for various key machine learning optimization
problems including SVM, logistic regression, ridge regression, Lasso, and
multiclass SVM. Experiments validate our theoretical findings.
</summary>
    <author>
      <name>Shai Shalev-Shwartz</name>
    </author>
    <author>
      <name>Tong Zhang</name>
    </author>
    <link href="http://arxiv.org/abs/1309.2375v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1309.2375v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1309.3699v1</id>
    <updated>2013-09-14T21:06:22Z</updated>
    <published>2013-09-14T21:06:22Z</published>
    <title>Local Support Vector Machines:Formulation and Analysis</title>
    <summary>  We provide a formulation for Local Support Vector Machines (LSVMs) that
generalizes previous formulations, and brings out the explicit connections to
local polynomial learning used in nonparametric estimation literature. We
investigate the simplest type of LSVMs called Local Linear Support Vector
Machines (LLSVMs). For the first time we establish conditions under which
LLSVMs make Bayes consistent predictions at each test point $x_0$. We also
establish rates at which the local risk of LLSVMs converges to the minimum
value of expected local risk at each point $x_0$. Using stability arguments we
establish generalization error bounds for LLSVMs.
</summary>
    <author>
      <name>Ravi Ganti</name>
    </author>
    <author>
      <name>Alexander Gray</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1309.3699v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1309.3699v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1309.4844v1</id>
    <updated>2013-09-19T03:09:33Z</updated>
    <published>2013-09-19T03:09:33Z</published>
    <title>Network Anomaly Detection: A Survey and Comparative Analysis of
  Stochastic and Deterministic Methods</title>
    <summary>  We present five methods to the problem of network anomaly detection. These
methods cover most of the common techniques in the anomaly detection field,
including Statistical Hypothesis Tests (SHT), Support Vector Machines (SVM) and
clustering analysis. We evaluate all methods in a simulated network that
consists of nominal data, three flow-level anomalies and one packet-level
attack. Through analyzing the results, we point out the advantages and
disadvantages of each method and conclude that combining the results of the
individual methods can yield improved anomaly detection results.
</summary>
    <author>
      <name>Jing Wang</name>
    </author>
    <author>
      <name>Daniel Rossell</name>
    </author>
    <author>
      <name>Christos G. Cassandras</name>
    </author>
    <author>
      <name>Ioannis Ch. Paschalidis</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages. 1 more figure than final CDC 2013 version</arxiv:comment>
    <link href="http://arxiv.org/abs/1309.4844v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1309.4844v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1309.6013v1</id>
    <updated>2013-09-24T00:31:41Z</updated>
    <published>2013-09-24T00:31:41Z</published>
    <title>A Max-Norm Constrained Minimization Approach to 1-Bit Matrix Completion</title>
    <summary>  We consider in this paper the problem of noisy 1-bit matrix completion under
a general non-uniform sampling distribution using the max-norm as a convex
relaxation for the rank. A max-norm constrained maximum likelihood estimate is
introduced and studied. The rate of convergence for the estimate is obtained.
Information-theoretical methods are used to establish a minimax lower bound
under the general sampling model. The minimax upper and lower bounds together
yield the optimal rate of convergence for the Frobenius norm loss.
Computational algorithms and numerical performance are also discussed.
</summary>
    <author>
      <name>T. Tony Cai</name>
    </author>
    <author>
      <name>Wen-Xin Zhou</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">33 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1309.6013v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1309.6013v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1309.7804v1</id>
    <updated>2013-09-30T11:51:23Z</updated>
    <published>2013-09-30T11:51:23Z</published>
    <title>On statistics, computation and scalability</title>
    <summary>  How should statistical procedures be designed so as to be scalable
computationally to the massive datasets that are increasingly the norm? When
coupled with the requirement that an answer to an inferential question be
delivered within a certain time budget, this question has significant
repercussions for the field of statistics. With the goal of identifying
"time-data tradeoffs," we investigate some of the statistical consequences of
computational perspectives on scability, in particular divide-and-conquer
methodology and hierarchies of convex relaxations.
</summary>
    <author>
      <name>Michael I. Jordan</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.3150/12-BEJSP17</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.3150/12-BEJSP17" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published in at http://dx.doi.org/10.3150/12-BEJSP17 the Bernoulli
  (http://isi.cbs.nl/bernoulli/) by the International Statistical
  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Bernoulli 2013, Vol. 19, No. 4, 1378-1390</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1309.7804v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1309.7804v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1309.7821v2</id>
    <updated>2016-02-06T19:16:06Z</updated>
    <published>2013-09-30T12:34:09Z</published>
    <title>MPBART - Multinomial Probit Bayesian Additive Regression Trees</title>
    <summary>  This article proposes Multinomial Probit Bayesian Additive Regression Trees
(MPBART) as a multinomial probit extension of BART - Bayesian Additive
Regression Trees (Chipman et al (2010)). MPBART is flexible to allow inclusion
of predictors that describe the observed units as well as the available choice
alternatives. Through two simulation studies and four real data examples, we
show that MPBART exhibits very good predictive performance in comparison to
other discrete choice and multiclass classification methods. To implement
MPBART, we have developed an R package mpbart available freely from CRAN
repositories.
</summary>
    <author>
      <name>Bereket P. Kindo</name>
    </author>
    <author>
      <name>Hao Wang</name>
    </author>
    <author>
      <name>Edsel A. Peña</name>
    </author>
    <link href="http://arxiv.org/abs/1309.7821v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1309.7821v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.0532v4</id>
    <updated>2015-01-15T21:43:45Z</updated>
    <published>2013-10-02T00:33:34Z</published>
    <title>Perfect Clustering for Stochastic Blockmodel Graphs via Adjacency
  Spectral Embedding</title>
    <summary>  Vertex clustering in a stochastic blockmodel graph has wide applicability and
has been the subject of extensive research. In thispaper, we provide a short
proof that the adjacency spectral embedding can be used to obtain perfect
clustering for the stochastic blockmodel and the degree-corrected stochastic
blockmodel. We also show an analogous result for the more general random dot
product graph model.
</summary>
    <author>
      <name>Vince Lyzinski</name>
    </author>
    <author>
      <name>Daniel Sussman</name>
    </author>
    <author>
      <name>Minh Tang</name>
    </author>
    <author>
      <name>Avanti Athreya</name>
    </author>
    <author>
      <name>Carey Priebe</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">22 pages, including references; 2 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Electronic Journal of Statistics, 8 (2014) 2905--2922</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1310.0532v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.0532v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.1022v1</id>
    <updated>2013-10-03T16:16:35Z</updated>
    <published>2013-10-03T16:16:35Z</published>
    <title>Multivariate regression and fit function uncertainty</title>
    <summary>  This article describes a multivariate polynomial regression method where the
uncertainty of the input parameters are approximated with Gaussian
distributions, derived from the central limit theorem for large weighted sums,
directly from the training sample. The estimated uncertainties can be
propagated into the optimal fit function, as an alternative to the statistical
bootstrap method. This uncertainty can be propagated further into a loss
function like quantity, with which it is possible to calculate the expected
loss function, and allows to select the optimal polynomial degree with
statistical significance. Combined with simple phase space splitting methods,
it is possible to model most features of the training data even with low degree
polynomials or constants.
</summary>
    <author>
      <name>Peter Kovesarki</name>
    </author>
    <author>
      <name>Ian C. Brock</name>
    </author>
    <link href="http://arxiv.org/abs/1310.1022v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.1022v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62J02" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.1404v1</id>
    <updated>2013-10-04T20:19:56Z</updated>
    <published>2013-10-04T20:19:56Z</published>
    <title>Sequential Monte Carlo Bandits</title>
    <summary>  In this paper we propose a flexible and efficient framework for handling
multi-armed bandits, combining sequential Monte Carlo algorithms with
hierarchical Bayesian modeling techniques. The framework naturally encompasses
restless bandits, contextual bandits, and other bandit variants under a single
inferential model. Despite the model's generality, we propose efficient Monte
Carlo algorithms to make inference scalable, based on recent developments in
sequential Monte Carlo methods. Through two simulation studies, the framework
is shown to outperform other empirical methods, while also naturally scaling to
more complex problems for which existing approaches can not cope. Additionally,
we successfully apply our framework to online video-based advertising
recommendation, and show its increased efficacy as compared to current state of
the art bandit algorithms.
</summary>
    <author>
      <name>Michael Cherkassky</name>
    </author>
    <author>
      <name>Luke Bornn</name>
    </author>
    <link href="http://arxiv.org/abs/1310.1404v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.1404v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.1415v1</id>
    <updated>2013-10-04T22:33:35Z</updated>
    <published>2013-10-04T22:33:35Z</published>
    <title>Narrowing the Gap: Random Forests In Theory and In Practice</title>
    <summary>  Despite widespread interest and practical use, the theoretical properties of
random forests are still not well understood. In this paper we contribute to
this understanding in two ways. We present a new theoretically tractable
variant of random regression forests and prove that our algorithm is
consistent. We also provide an empirical evaluation, comparing our algorithm
and other theoretically tractable random forest models to the random forest
algorithm used in practice. Our experiments provide insight into the relative
importance of different simplifications that theoreticians have made to obtain
tractable models for analysis.
</summary>
    <author>
      <name>Misha Denil</name>
    </author>
    <author>
      <name>David Matheson</name>
    </author>
    <author>
      <name>Nando de Freitas</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Under review by the International Conference on Machine Learning
  (ICML) 2014</arxiv:comment>
    <link href="http://arxiv.org/abs/1310.1415v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.1415v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.1562v4</id>
    <updated>2016-11-08T04:18:06Z</updated>
    <published>2013-10-06T09:36:55Z</published>
    <title>Dependence Measure for non-additive model</title>
    <summary>  We proposed a new statistical dependency measure called Copula Dependency
Coefficient(CDC) for two sets of variables based on copula. It is robust to
outliers, easy to implement, powerful and appropriate to high-dimensional
variables. These properties are important in many applications. Experimental
results show that CDC can detect the dependence between variables in both
additive and non-additive models.
</summary>
    <author>
      <name>Hangjin Jiang</name>
    </author>
    <author>
      <name>Yiming Ding</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper has been withdrawn by the author due to change of the main
  content</arxiv:comment>
    <link href="http://arxiv.org/abs/1310.1562v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.1562v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.2627v2</id>
    <updated>2015-11-07T05:11:48Z</updated>
    <published>2013-10-09T20:39:08Z</published>
    <title>A Sparse and Adaptive Prior for Time-Dependent Model Parameters</title>
    <summary>  We consider the scenario where the parameters of a probabilistic model are
expected to vary over time. We construct a novel prior distribution that
promotes sparsity and adapts the strength of correlation between parameters at
successive timesteps, based on the data. We derive approximate variational
inference procedures for learning and prediction with this prior. We test the
approach on two tasks: forecasting financial quantities from relevant text, and
modeling language contingent on time-varying financial measurements.
</summary>
    <author>
      <name>Dani Yogatama</name>
    </author>
    <author>
      <name>Bryan R. Routledge</name>
    </author>
    <author>
      <name>Noah A. Smith</name>
    </author>
    <link href="http://arxiv.org/abs/1310.2627v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.2627v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.3101v1</id>
    <updated>2013-10-11T12:14:00Z</updated>
    <published>2013-10-11T12:14:00Z</published>
    <title>Deep Multiple Kernel Learning</title>
    <summary>  Deep learning methods have predominantly been applied to large artificial
neural networks. Despite their state-of-the-art performance, these large
networks typically do not generalize well to datasets with limited sample
sizes. In this paper, we take a different approach by learning multiple layers
of kernels. We combine kernels at each layer and then optimize over an estimate
of the support vector machine leave-one-out error rather than the dual
objective function. Our experiments on a variety of datasets show that each
layer successively increases performance with only a few base kernels.
</summary>
    <author>
      <name>Eric Strobl</name>
    </author>
    <author>
      <name>Shyam Visweswaran</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/ICMLA.2013.84</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/ICMLA.2013.84" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 1 figure, 1 table, conference paper</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE 12th International Conference on Machine Learning and
  Applications (ICMLA 2013)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1310.3101v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.3101v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.3892v3</id>
    <updated>2014-05-05T13:10:03Z</updated>
    <published>2013-10-15T01:27:14Z</published>
    <title>Ridge Fusion in Statistical Learning</title>
    <summary>  We propose a penalized likelihood method to jointly estimate multiple
precision matrices for use in quadratic discriminant analysis and model based
clustering. A ridge penalty and a ridge fusion penalty are used to introduce
shrinkage and promote similarity between precision matrix estimates. Block-wise
coordinate descent is used for optimization, and validation likelihood is used
for tuning parameter selection. Our method is applied in quadratic discriminant
analysis and semi-supervised model based clustering.
</summary>
    <author>
      <name>Bradley S. Price</name>
    </author>
    <author>
      <name>Charles J. Geyer</name>
    </author>
    <author>
      <name>Adam J. Rothman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">24 pages and 9 tables, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1310.3892v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.3892v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.4794v2</id>
    <updated>2014-03-13T02:49:09Z</updated>
    <published>2013-10-17T18:43:40Z</published>
    <title>The Gaussian Radon Transform and Machine Learning</title>
    <summary>  There has been growing recent interest in probabilistic interpretations of
kernel-based methods as well as learning in Banach spaces. The absence of a
useful Lebesgue measure on an infinite-dimensional reproducing kernel Hilbert
space is a serious obstacle for such stochastic models. We propose an
estimation model for the ridge regression problem within the framework of
abstract Wiener spaces and show how the support vector machine solution to such
problems can be interpreted in terms of the Gaussian Radon transform.
</summary>
    <author>
      <name>Irina Holmes</name>
    </author>
    <author>
      <name>Ambar Sengupta</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">28 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1310.4794v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.4794v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.FA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.5347v1</id>
    <updated>2013-10-20T16:58:57Z</updated>
    <published>2013-10-20T16:58:57Z</published>
    <title>Bayesian Extensions of Kernel Least Mean Squares</title>
    <summary>  The kernel least mean squares (KLMS) algorithm is a computationally efficient
nonlinear adaptive filtering method that "kernelizes" the celebrated (linear)
least mean squares algorithm. We demonstrate that the least mean squares
algorithm is closely related to the Kalman filtering, and thus, the KLMS can be
interpreted as an approximate Bayesian filtering method. This allows us to
systematically develop extensions of the KLMS by modifying the underlying
state-space and observation models. The resulting extensions introduce many
desirable properties such as "forgetting", and the ability to learn from
discrete data, while retaining the computational simplicity and time complexity
of the original algorithm.
</summary>
    <author>
      <name>Il Memming Park</name>
    </author>
    <author>
      <name>Sohan Seth</name>
    </author>
    <author>
      <name>Steven Van Vaerenbergh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 4 fiures</arxiv:comment>
    <link href="http://arxiv.org/abs/1310.5347v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.5347v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.5438v3</id>
    <updated>2017-08-08T21:34:00Z</updated>
    <published>2013-10-21T07:10:51Z</published>
    <title>Variational Bayesian inference for linear and logistic regression</title>
    <summary>  The article describe the model, derivation, and implementation of variational
Bayesian inference for linear and logistic regression, both with and without
automatic relevance determination. It has the dual function of acting as a
tutorial for the derivation of variational Bayesian inference for simple
models, as well as documenting, and providing brief examples for the MATLAB
functions that implement this inference. These functions are freely available
online.
</summary>
    <author>
      <name>Jan Drugowitsch</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">28 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1310.5438v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.5438v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.5543v2</id>
    <updated>2013-10-24T03:45:51Z</updated>
    <published>2013-10-21T13:51:16Z</published>
    <title>Universalities of Reproducing Kernels Revisited</title>
    <summary>  Kernel methods have been widely applied to machine learning and other
questions of approximating an unknown function from its finite sample data. To
ensure arbitrary accuracy of such approximation, various denseness conditions
are imposed on the selected kernel. This note contributes to the study of
universal, characteristic, and $C_0$-universal kernels. We first give simple
and direct description of the difference and relation among these three kinds
of universalities of kernels. We then focus on translation-invariant and
weighted polynomial kernels. A simple and shorter proof of the known
characterization of characteristic translation-invariant kernels will be
presented. The main purpose of the note is to give a delicate discussion on the
universalities of weighted polynomial kernels.
</summary>
    <author>
      <name>Benxun Wang</name>
    </author>
    <author>
      <name>Haizhang Zhang</name>
    </author>
    <link href="http://arxiv.org/abs/1310.5543v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.5543v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.5666v1</id>
    <updated>2013-10-21T18:29:12Z</updated>
    <published>2013-10-21T18:29:12Z</published>
    <title>Distributed parameter estimation of discrete hierarchical models via
  marginal likelihoods</title>
    <summary>  We consider discrete graphical models Markov with respect to a graph $G$ and
propose two distributed marginal methods to estimate the maximum likelihood
estimate of the canonical parameter of the model. Both methods are based on a
relaxation of the marginal likelihood obtained by considering the density of
the variables represented by a vertex $v$ of $G$ and a neighborhood. The two
methods differ by the size of the neighborhood of $v$. We show that the
estimates are consistent and that those obtained with the larger neighborhood
have smaller asymptotic variance than the ones obtained through the smaller
neighborhood.
</summary>
    <author>
      <name>Helene Massam</name>
    </author>
    <author>
      <name>Nanwei Wang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1310.5666v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.5666v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62H17 (Primary), 62M40" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.6740v1</id>
    <updated>2013-10-24T14:15:39Z</updated>
    <published>2013-10-24T14:15:39Z</published>
    <title>Active Learning of Linear Embeddings for Gaussian Processes</title>
    <summary>  We propose an active learning method for discovering low-dimensional
structure in high-dimensional Gaussian process (GP) tasks. Such problems are
increasingly frequent and important, but have hitherto presented severe
practical difficulties. We further introduce a novel technique for
approximately marginalizing GP hyperparameters, yielding marginal predictions
robust to hyperparameter mis-specification. Our method offers an efficient
means of performing GP regression, quadrature, or Bayesian optimization in
high-dimensional spaces.
</summary>
    <author>
      <name>Roman Garnett</name>
    </author>
    <author>
      <name>Michael A. Osborne</name>
    </author>
    <author>
      <name>Philipp Hennig</name>
    </author>
    <link href="http://arxiv.org/abs/1310.6740v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.6740v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T05" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.6; I.5.2; G.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.7855v1</id>
    <updated>2013-10-29T16:05:44Z</updated>
    <published>2013-10-29T16:05:44Z</published>
    <title>A comparison of bandwidth selectors for mean shift clustering</title>
    <summary>  We explore the performance of several automatic bandwidth selectors,
originally designed for density gradient estimation, as data-based procedures
for nonparametric, modal clustering. The key tool to obtain a clustering from
density gradient estimators is the mean shift algorithm, which allows to obtain
a partition not only of the data sample, but also of the whole space. The
results of our simulation study suggest that most of the methods considered
here, like cross validation and plug in bandwidth selectors, are useful for
cluster analysis via the mean shift algorithm.
</summary>
    <author>
      <name>José E. Chacón</name>
    </author>
    <author>
      <name>Pablo Monfort</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1310.7855v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.7855v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.8612v1</id>
    <updated>2013-10-31T17:40:20Z</updated>
    <published>2013-10-31T17:40:20Z</published>
    <title>Nonlinear unmixing of hyperspectral images using a semiparametric model
  and spatial regularization</title>
    <summary>  Incorporating spatial information into hyperspectral unmixing procedures has
been shown to have positive effects, due to the inherent spatial-spectral
duality in hyperspectral scenes. Current research works that consider spatial
information are mainly focused on the linear mixing model. In this paper, we
investigate a variational approach to incorporating spatial correlation into a
nonlinear unmixing procedure. A nonlinear algorithm operating in reproducing
kernel Hilbert spaces, associated with an $\ell_1$ local variation norm as the
spatial regularizer, is derived. Experimental results, with both synthetic and
real data, illustrate the effectiveness of the proposed scheme.
</summary>
    <author>
      <name>Jie Chen</name>
    </author>
    <author>
      <name>Cédric Richard</name>
    </author>
    <author>
      <name>Alfred O. Hero III</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 1 figure, submitted to ICASSP 2014</arxiv:comment>
    <link href="http://arxiv.org/abs/1310.8612v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.8612v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1311.0072v1</id>
    <updated>2013-11-01T02:17:06Z</updated>
    <published>2013-11-01T02:17:06Z</published>
    <title>Bayesian inference as iterated random functions with applications to
  sequential inference in graphical models</title>
    <summary>  We propose a general formalism of iterated random functions with semigroup
property, under which exact and approximate Bayesian posterior updates can be
viewed as specific instances. A convergence theory for iterated random
functions is presented. As an application of the general theory we analyze
convergence behaviors of exact and approximate message-passing algorithms that
arise in a sequential change point detection problem formulated via a latent
variable directed graphical model. The sequential inference algorithm and its
supporting theory are illustrated by simulated examples.
</summary>
    <author>
      <name>Arash A. Amini</name>
    </author>
    <author>
      <name>XuanLong Nguyen</name>
    </author>
    <link href="http://arxiv.org/abs/1311.0072v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1311.0072v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1311.0360v1</id>
    <updated>2013-11-02T09:09:35Z</updated>
    <published>2013-11-02T09:09:35Z</published>
    <title>Multivariate Generalized Gaussian Process Models</title>
    <summary>  We propose a family of multivariate Gaussian process models for correlated
outputs, based on assuming that the likelihood function takes the generic form
of the multivariate exponential family distribution (EFD). We denote this model
as a multivariate generalized Gaussian process model, and derive Taylor and
Laplace algorithms for approximate inference on the generic model. By
instantiating the EFD with specific parameter functions, we obtain two novel GP
models (and corresponding inference algorithms) for correlated outputs: 1) a
Von-Mises GP for angle regression; and 2) a Dirichlet GP for regressing on the
multinomial simplex.
</summary>
    <author>
      <name>Antoni B. Chan</name>
    </author>
    <link href="http://arxiv.org/abs/1311.0360v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1311.0360v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1311.0468v1</id>
    <updated>2013-11-03T14:18:56Z</updated>
    <published>2013-11-03T14:18:56Z</published>
    <title>Thompson Sampling for Online Learning with Linear Experts</title>
    <summary>  In this note, we present a version of the Thompson sampling algorithm for the
problem of online linear generalization with full information (i.e., the
experts setting), studied by Kalai and Vempala, 2005. The algorithm uses a
Gaussian prior and time-varying Gaussian likelihoods, and we show that it
essentially reduces to Kalai and Vempala's Follow-the-Perturbed-Leader
strategy, with exponentially distributed noise replaced by Gaussian noise. This
implies sqrt(T) regret bounds for Thompson sampling (with time-varying
likelihood) for online learning with full information.
</summary>
    <author>
      <name>Aditya Gopalan</name>
    </author>
    <link href="http://arxiv.org/abs/1311.0468v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1311.0468v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1311.0622v1</id>
    <updated>2013-11-04T09:31:51Z</updated>
    <published>2013-11-04T09:31:51Z</published>
    <title>Stochastic Dual Coordinate Ascent with Alternating Direction Multiplier
  Method</title>
    <summary>  We propose a new stochastic dual coordinate ascent technique that can be
applied to a wide range of regularized learning problems. Our method is based
on Alternating Direction Multiplier Method (ADMM) to deal with complex
regularization functions such as structured regularizations. Although the
original ADMM is a batch method, the proposed method offers a stochastic update
rule where each iteration requires only one or few sample observations.
Moreover, our method can naturally afford mini-batch update and it gives speed
up of convergence. We show that, under mild assumptions, our method converges
exponentially. The numerical experiments show that our method actually performs
efficiently.
</summary>
    <author>
      <name>Taiji Suzuki</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">26pages, 12 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1311.0622v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1311.0622v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1311.0707v3</id>
    <updated>2014-02-14T15:15:43Z</updated>
    <published>2013-11-04T14:13:27Z</published>
    <title>Generative Modelling for Unsupervised Score Calibration</title>
    <summary>  Score calibration enables automatic speaker recognizers to make
cost-effective accept / reject decisions. Traditional calibration requires
supervised data, which is an expensive resource. We propose a 2-component GMM
for unsupervised calibration and demonstrate good performance relative to a
supervised baseline on NIST SRE'10 and SRE'12. A Bayesian analysis demonstrates
that the uncertainty associated with the unsupervised calibration parameter
estimates is surprisingly small.
</summary>
    <author>
      <name>Niko Brümmer</name>
    </author>
    <author>
      <name>Daniel Garcia-Romero</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted for ICASSP 2014</arxiv:comment>
    <link href="http://arxiv.org/abs/1311.0707v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1311.0707v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1311.1033v2</id>
    <updated>2013-11-21T10:51:26Z</updated>
    <published>2013-11-05T12:39:04Z</published>
    <title>Nonparametric Bayesian models of hierarchical structure in complex
  networks</title>
    <summary>  Analyzing and understanding the structure of complex relational data is
important in many applications including analysis of the connectivity in the
human brain. Such networks can have prominent patterns on different scales,
calling for a hierarchically structured model. We propose two non-parametric
Bayesian hierarchical network models based on Gibbs fragmentation tree priors,
and demonstrate their ability to capture nested patterns in simulated networks.
On real networks we demonstrate detection of hierarchical structure and show
predictive performance on par with the state of the art. We envision that our
methods can be employed in exploratory analysis of large scale complex networks
for example to model human brain connectivity.
</summary>
    <author>
      <name>Mikkel N. Schmidt</name>
    </author>
    <author>
      <name>Tue Herlau</name>
    </author>
    <author>
      <name>Morten Mørup</name>
    </author>
    <link href="http://arxiv.org/abs/1311.1033v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1311.1033v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1311.3257v2</id>
    <updated>2014-03-08T16:49:40Z</updated>
    <published>2013-11-13T19:12:55Z</published>
    <title>Compressive Nonparametric Graphical Model Selection For Time Series</title>
    <summary>  We propose a method for inferring the conditional indepen- dence graph (CIG)
of a high-dimensional discrete-time Gaus- sian vector random process from
finite-length observations. Our approach does not rely on a parametric model
(such as, e.g., an autoregressive model) for the vector random process; rather,
it only assumes certain spectral smoothness proper- ties. The proposed
inference scheme is compressive in that it works for sample sizes that are
(much) smaller than the number of scalar process components. We provide
analytical conditions for our method to correctly identify the CIG with high
probability.
</summary>
    <author>
      <name>Alexander Jung</name>
    </author>
    <author>
      <name>Reinhard Heckel</name>
    </author>
    <author>
      <name>Helmut Bölcskei</name>
    </author>
    <author>
      <name>Franz Hlawatsch</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">to appear in Proc. IEEE ICASSP 2014</arxiv:comment>
    <link href="http://arxiv.org/abs/1311.3257v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1311.3257v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1311.3709v1</id>
    <updated>2013-11-15T01:33:48Z</updated>
    <published>2013-11-15T01:33:48Z</published>
    <title>On Estimating Many Means, Selection Bias, and the Bootstrap</title>
    <summary>  With recent advances in high throughput technology, researchers often find
themselves running a large number of hypothesis tests (thousands+) and esti-
mating a large number of effect-sizes. Generally there is particular interest
in those effects estimated to be most extreme. Unfortunately naive estimates of
these effect-sizes (even after potentially accounting for multiplicity in a
testing procedure) can be severely biased. In this manuscript we explore this
bias from a frequentist perspective: we give a formal definition, and show that
an oracle estimator using this bias dominates the naive maximum likelihood
estimate. We give a resampling estimator to approximate this oracle, and show
that it works well on simulated data. We also connect this to ideas in
empirical Bayes.
</summary>
    <author>
      <name>Noah Simon</name>
    </author>
    <author>
      <name>Richard Simon</name>
    </author>
    <link href="http://arxiv.org/abs/1311.3709v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1311.3709v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1311.4025v3</id>
    <updated>2014-02-27T22:36:08Z</updated>
    <published>2013-11-16T06:53:44Z</published>
    <title>Signal Recovery from Pooling Representations</title>
    <summary>  In this work we compute lower Lipschitz bounds of $\ell_p$ pooling operators
for $p=1, 2, \infty$ as well as $\ell_p$ pooling operators preceded by
half-rectification layers. These give sufficient conditions for the design of
invertible neural network layers. Numerical experiments on MNIST and image
patches confirm that pooling layers can be inverted with phase recovery
algorithms. Moreover, the regularity of the inverse pooling, controlled by the
lower Lipschitz constant, is empirically verified with a nearest neighbor
regression.
</summary>
    <author>
      <name>Joan Bruna</name>
    </author>
    <author>
      <name>Arthur Szlam</name>
    </author>
    <author>
      <name>Yann LeCun</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1311.4025v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1311.4025v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1311.4472v2</id>
    <updated>2013-12-06T22:02:14Z</updated>
    <published>2013-11-18T17:56:28Z</published>
    <title>A Component Lasso</title>
    <summary>  We propose a new sparse regression method called the component lasso, based
on a simple idea. The method uses the connected-components structure of the
sample covariance matrix to split the problem into smaller ones. It then solves
the subproblems separately, obtaining a coefficient vector for each one. Then,
it uses non-negative least squares to recombine the different vectors into a
single solution. This step is useful in selecting and reweighting components
that are correlated with the response. Simulated and real data examples show
that the component lasso can outperform standard regression methods such as the
lasso and elastic net, achieving a lower mean squared error as well as better
support recovery.
</summary>
    <author>
      <name>Nadine Hussami</name>
    </author>
    <author>
      <name>Robert Tibshirani</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1311.4472v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1311.4472v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62J07" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1311.4825v3</id>
    <updated>2015-06-08T13:27:19Z</updated>
    <published>2013-11-19T18:29:19Z</published>
    <title>Gaussian Process Optimization with Mutual Information</title>
    <summary>  In this paper, we analyze a generic algorithm scheme for sequential global
optimization using Gaussian processes. The upper bounds we derive on the
cumulative regret for this generic algorithm improve by an exponential factor
the previously known bounds for algorithms like GP-UCB. We also introduce the
novel Gaussian Process Mutual Information algorithm (GP-MI), which
significantly improves further these upper bounds for the cumulative regret. We
confirm the efficiency of this algorithm on synthetic and real tasks against
the natural competitor, GP-UCB, and also the Expected Improvement heuristic.
</summary>
    <author>
      <name>Emile Contal</name>
    </author>
    <author>
      <name>Vianney Perchet</name>
    </author>
    <author>
      <name>Nicolas Vayatis</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of The 31st International Conference on Machine Learning
  (ICML 2014)</arxiv:comment>
    <link href="http://arxiv.org/abs/1311.4825v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1311.4825v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1312.2171v3</id>
    <updated>2014-11-24T19:21:22Z</updated>
    <published>2013-12-08T03:40:47Z</published>
    <title>bartMachine: Machine Learning with Bayesian Additive Regression Trees</title>
    <summary>  We present a new package in R implementing Bayesian additive regression trees
(BART). The package introduces many new features for data analysis using BART
such as variable selection, interaction detection, model diagnostic plots,
incorporation of missing data and the ability to save trees for future
prediction. It is significantly faster than the current R implementation,
parallelized, and capable of handling both large sample sizes and
high-dimensional data.
</summary>
    <author>
      <name>Adam Kapelner</name>
    </author>
    <author>
      <name>Justin Bleich</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">39 pages, 13 figures, 4 tables, 2 appendices</arxiv:comment>
    <link href="http://arxiv.org/abs/1312.2171v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1312.2171v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1312.4717v1</id>
    <updated>2013-12-17T11:01:29Z</updated>
    <published>2013-12-17T11:01:29Z</published>
    <title>The Matrix Ridge Approximation: Algorithms and Applications</title>
    <summary>  We are concerned with an approximation problem for a symmetric positive
semidefinite matrix due to motivation from a class of nonlinear machine
learning methods. We discuss an approximation approach that we call {matrix
ridge approximation}. In particular, we define the matrix ridge approximation
as an incomplete matrix factorization plus a ridge term. Moreover, we present
probabilistic interpretations using a normal latent variable model and a
Wishart model for this approximation approach. The idea behind the latent
variable model in turn leads us to an efficient EM iterative method for
handling the matrix ridge approximation problem. Finally, we illustrate the
applications of the approximation approach in multivariate data analysis.
Empirical studies in spectral clustering and Gaussian process regression show
that the matrix ridge approximation with the EM iteration is potentially
useful.
</summary>
    <author>
      <name>Zhihua Zhang</name>
    </author>
    <link href="http://arxiv.org/abs/1312.4717v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1312.4717v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1312.4719v1</id>
    <updated>2013-12-17T11:10:06Z</updated>
    <published>2013-12-17T11:10:06Z</published>
    <title>The Bernstein Function: A Unifying Framework of Nonconvex Penalization
  in Sparse Estimation</title>
    <summary>  In this paper we study nonconvex penalization using Bernstein functions.
Since the Bernstein function is concave and nonsmooth at the origin, it can
induce a class of nonconvex functions for high-dimensional sparse estimation
problems. We derive a threshold function based on the Bernstein penalty and
give its mathematical properties in sparsity modeling. We show that a
coordinate descent algorithm is especially appropriate for penalized regression
problems with the Bernstein penalty. Additionally, we prove that the Bernstein
function can be defined as the concave conjugate of a $\varphi$-divergence and
develop a conjugate maximization algorithm for finding the sparse solution.
Finally, we particularly exemplify a family of Bernstein nonconvex penalties
based on a generalized Gamma measure and conduct empirical analysis for this
family.
</summary>
    <author>
      <name>Zhihua Zhang</name>
    </author>
    <link href="http://arxiv.org/abs/1312.4719v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1312.4719v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1312.4852v1</id>
    <updated>2013-12-17T16:32:54Z</updated>
    <published>2013-12-17T16:32:54Z</published>
    <title>Identification of Gaussian Process State-Space Models with Particle
  Stochastic Approximation EM</title>
    <summary>  Gaussian process state-space models (GP-SSMs) are a very flexible family of
models of nonlinear dynamical systems. They comprise a Bayesian nonparametric
representation of the dynamics of the system and additional (hyper-)parameters
governing the properties of this nonparametric representation. The Bayesian
formalism enables systematic reasoning about the uncertainty in the system
dynamics. We present an approach to maximum likelihood identification of the
parameters in GP-SSMs, while retaining the full nonparametric description of
the dynamics. The method is based on a stochastic approximation version of the
EM algorithm that employs recent developments in particle Markov chain Monte
Carlo for efficient identification.
</summary>
    <author>
      <name>Roger Frigola</name>
    </author>
    <author>
      <name>Fredrik Lindsten</name>
    </author>
    <author>
      <name>Thomas B. Schön</name>
    </author>
    <author>
      <name>Carl E. Rasmussen</name>
    </author>
    <link href="http://arxiv.org/abs/1312.4852v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1312.4852v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1312.5179v1</id>
    <updated>2013-12-18T15:35:32Z</updated>
    <published>2013-12-18T15:35:32Z</published>
    <title>The Total Variation on Hypergraphs - Learning on Hypergraphs Revisited</title>
    <summary>  Hypergraphs allow one to encode higher-order relationships in data and are
thus a very flexible modeling tool. Current learning methods are either based
on approximations of the hypergraphs via graphs or on tensor methods which are
only applicable under special conditions. In this paper, we present a new
learning framework on hypergraphs which fully uses the hypergraph structure.
The key element is a family of regularization functionals based on the total
variation on hypergraphs.
</summary>
    <author>
      <name>Matthias Hein</name>
    </author>
    <author>
      <name>Simon Setzer</name>
    </author>
    <author>
      <name>Leonardo Jost</name>
    </author>
    <author>
      <name>Syama Sundar Rangapuram</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Long version of paper accepted at NIPS 2013</arxiv:comment>
    <link href="http://arxiv.org/abs/1312.5179v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1312.5179v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1312.5192v2</id>
    <updated>2014-03-24T10:10:42Z</updated>
    <published>2013-12-18T16:01:25Z</published>
    <title>Nonlinear Eigenproblems in Data Analysis - Balanced Graph Cuts and the
  RatioDCA-Prox</title>
    <summary>  It has been recently shown that a large class of balanced graph cuts allows
for an exact relaxation into a nonlinear eigenproblem. We review briefly some
of these results and propose a family of algorithms to compute nonlinear
eigenvectors which encompasses previous work as special cases. We provide a
detailed analysis of the properties and the convergence behavior of these
algorithms and then discuss their application in the area of balanced graph
cuts.
</summary>
    <author>
      <name>Leonardo Jost</name>
    </author>
    <author>
      <name>Simon Setzer</name>
    </author>
    <author>
      <name>Matthias Hein</name>
    </author>
    <link href="http://arxiv.org/abs/1312.5192v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1312.5192v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1312.5370v1</id>
    <updated>2013-12-18T23:16:52Z</updated>
    <published>2013-12-18T23:16:52Z</published>
    <title>Perturbed Gibbs Samplers for Synthetic Data Release</title>
    <summary>  We propose a categorical data synthesizer with a quantifiable disclosure
risk. Our algorithm, named Perturbed Gibbs Sampler, can handle high-dimensional
categorical data that are often intractable to represent as contingency tables.
The algorithm extends a multiple imputation strategy for fully synthetic data
by utilizing feature hashing and non-parametric distribution approximations.
California Patient Discharge data are used to demonstrate statistical
properties of the proposed synthesizing methodology. Marginal and conditional
distributions, as well as the coefficients of regression models built on the
synthesized data are compared to those obtained from the original data.
Intruder scenarios are simulated to evaluate disclosure risks of the
synthesized data from multiple angles. Limitations and extensions of the
proposed algorithm are also discussed.
</summary>
    <author>
      <name>Yubin Park</name>
    </author>
    <author>
      <name>Joydeep Ghosh</name>
    </author>
    <link href="http://arxiv.org/abs/1312.5370v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1312.5370v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1312.5386v1</id>
    <updated>2013-12-19T01:11:48Z</updated>
    <published>2013-12-19T01:11:48Z</published>
    <title>Detecting Parameter Symmetries in Probabilistic Models</title>
    <summary>  Probabilistic models often have parameters that can be translated, scaled,
permuted, or otherwise transformed without changing the model. These symmetries
can lead to strong correlation and multimodality in the posterior distribution
over the model's parameters, which can pose challenges both for performing
inference and interpreting the results. In this work, we address the automatic
detection of common problematic model symmetries. To do so, we introduce local
symmetries, which cover many common cases and are amenable to automatic
detection. We show how to derive algorithms to detect several broad classes of
local symmetries. Our algorithms are compatible with probabilistic programming
constructs such as arrays, for loops, and if statements, and they scale to
models with many variables.
</summary>
    <author>
      <name>Robert Nishihara</name>
    </author>
    <author>
      <name>Thomas Minka</name>
    </author>
    <author>
      <name>Daniel Tarlow</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">24 pages, 8 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1312.5386v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1312.5386v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1312.5889v1</id>
    <updated>2013-12-20T11:09:33Z</updated>
    <published>2013-12-20T11:09:33Z</published>
    <title>Non-parametric Bayesian modeling of complex networks</title>
    <summary>  Modeling structure in complex networks using Bayesian non-parametrics makes
it possible to specify flexible model structures and infer the adequate model
complexity from the observed data. This paper provides a gentle introduction to
non-parametric Bayesian modeling of complex networks: Using an infinite mixture
model as running example we go through the steps of deriving the model as an
infinite limit of a finite parametric model, inferring the model parameters by
Markov chain Monte Carlo, and checking the model's fit and predictive
performance. We explain how advanced non-parametric models for complex networks
can be derived and point out relevant literature.
</summary>
    <author>
      <name>Mikkel N. Schmidt</name>
    </author>
    <author>
      <name>Morten Mørup</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/MSP.2012.2235191</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/MSP.2012.2235191" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Signal Processing Magazine, IEEE (Volume:30, Issue:3, Year:2013)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1312.5889v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1312.5889v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1312.6205v2</id>
    <updated>2014-01-02T07:50:44Z</updated>
    <published>2013-12-21T04:53:56Z</published>
    <title>Relaxations for inference in restricted Boltzmann machines</title>
    <summary>  We propose a relaxation-based approximate inference algorithm that samples
near-MAP configurations of a binary pairwise Markov random field. We experiment
on MAP inference tasks in several restricted Boltzmann machines. We also use
our underlying sampler to estimate the log-partition function of restricted
Boltzmann machines and compare against other sampling-based methods.
</summary>
    <author>
      <name>Sida I. Wang</name>
    </author>
    <author>
      <name>Roy Frostig</name>
    </author>
    <author>
      <name>Percy Liang</name>
    </author>
    <author>
      <name>Christopher D. Manning</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICLR 2014 workshop track submission</arxiv:comment>
    <link href="http://arxiv.org/abs/1312.6205v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1312.6205v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1312.7011v1</id>
    <updated>2013-12-25T19:45:07Z</updated>
    <published>2013-12-25T19:45:07Z</published>
    <title>Classification automatique de données temporelles en classes
  ordonnées</title>
    <summary>  This paper proposes a method of segmenting temporal data into ordered
classes. It is based on mixture models and a discrete latent process, which
enables to successively activates the classes. The classification can be
performed by maximizing the likelihood via the EM algorithm or by
simultaneously optimizing the model parameters and the partition by the CEM
algorithm. These two algorithms can be seen as alternatives to Fisher's
algorithm, which improve its computing time.
</summary>
    <author>
      <name>Faicel Chamroukhi</name>
    </author>
    <author>
      <name>Allou Samé</name>
    </author>
    <author>
      <name>Gérard Govaert</name>
    </author>
    <author>
      <name>Patrice Aknin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">in French, 44\`emes Journ\'ees de Statistique, SFdS</arxiv:comment>
    <link href="http://arxiv.org/abs/1312.7011v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1312.7011v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1401.0334v1</id>
    <updated>2014-01-01T21:14:10Z</updated>
    <published>2014-01-01T21:14:10Z</published>
    <title>Convex optimization on Banach Spaces</title>
    <summary>  Greedy algorithms which use only function evaluations are applied to convex
optimization in a general Banach space $X$. Along with algorithms that use
exact evaluations, algorithms with approximate evaluations are treated. A
priori upper bounds for the convergence rate of the proposed algorithms are
given. These bounds depend on the smoothness of the objective function and the
sparsity or compressibility (with respect to a given dictionary) of a point in
$X$ where the minimum is attained.
</summary>
    <author>
      <name>R. A. DeVore</name>
    </author>
    <author>
      <name>V. N. Temlyakov</name>
    </author>
    <link href="http://arxiv.org/abs/1401.0334v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1401.0334v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1401.1489v1</id>
    <updated>2014-01-07T20:16:05Z</updated>
    <published>2014-01-07T20:16:05Z</published>
    <title>Key point selection and clustering of swimmer coordination through
  Sparse Fisher-EM</title>
    <summary>  To answer the existence of optimal swimmer learning/teaching strategies, this
work introduces a two-level clustering in order to analyze temporal dynamics of
motor learning in breaststroke swimming. Each level have been performed through
Sparse Fisher-EM, a unsupervised framework which can be applied efficiently on
large and correlated datasets. The induced sparsity selects key points of the
coordination phase without any prior knowledge.
</summary>
    <author>
      <name>John Komar</name>
    </author>
    <author>
      <name>Romain Hérault</name>
    </author>
    <author>
      <name>Ludovic Seifert</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented at ECML/PKDD 2013 Workshop on Machine Learning and Data
  Mining for Sports Analytics (MLSA2013)</arxiv:comment>
    <link href="http://arxiv.org/abs/1401.1489v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1401.1489v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1401.3813v1</id>
    <updated>2014-01-16T02:33:44Z</updated>
    <published>2014-01-16T02:33:44Z</published>
    <title>Seeded Graph Matching Via Joint Optimization of Fidelity and
  Commensurability</title>
    <summary>  We present a novel approximate graph matching algorithm that incorporates
seeded data into the graph matching paradigm. Our Joint Optimization of
Fidelity and Commensurability (JOFC) algorithm embeds two graphs into a common
Euclidean space where the matching inference task can be performed. Through
real and simulated data examples, we demonstrate the versatility of our
algorithm in matching graphs with various characteristics--weightedness,
directedness, loopiness, many-to-one and many-to-many matchings, and soft
seedings.
</summary>
    <author>
      <name>Vince Lyzinski</name>
    </author>
    <author>
      <name>Sancar Adali</name>
    </author>
    <author>
      <name>Joshua T. Vogelstein</name>
    </author>
    <author>
      <name>Youngser Park</name>
    </author>
    <author>
      <name>Carey E. Priebe</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1401.3813v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1401.3813v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1401.3940v1</id>
    <updated>2014-01-16T09:04:20Z</updated>
    <published>2014-01-16T09:04:20Z</published>
    <title>Nonparametric Latent Tree Graphical Models: Inference, Estimation, and
  Structure Learning</title>
    <summary>  Tree structured graphical models are powerful at expressing long range or
hierarchical dependency among many variables, and have been widely applied in
different areas of computer science and statistics. However, existing methods
for parameter estimation, inference, and structure learning mainly rely on the
Gaussian or discrete assumptions, which are restrictive under many
applications. In this paper, we propose new nonparametric methods based on
reproducing kernel Hilbert space embeddings of distributions that can recover
the latent tree structures, estimate the parameters, and perform inference for
high dimensional continuous and non-Gaussian variables. The usefulness of the
proposed methods are illustrated by thorough numerical results.
</summary>
    <author>
      <name>Le Song</name>
    </author>
    <author>
      <name>Han Liu</name>
    </author>
    <author>
      <name>Ankur Parikh</name>
    </author>
    <author>
      <name>Eric Xing</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">29 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1401.3940v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1401.3940v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1401.7145v1</id>
    <updated>2014-01-28T11:44:29Z</updated>
    <published>2014-01-28T11:44:29Z</published>
    <title>Tempering by Subsampling</title>
    <summary>  In this paper we demonstrate that tempering Markov chain Monte Carlo samplers
for Bayesian models by recursively subsampling observations without replacement
can improve the performance of baseline samplers in terms of effective sample
size per computation. We present two tempering by subsampling algorithms,
subsampled parallel tempering and subsampled tempered transitions. We provide
an asymptotic analysis of the computational cost of tempering by subsampling,
verify that tempering by subsampling costs less than traditional tempering, and
demonstrate both algorithms on Bayesian approaches to learning the mean of a
high dimensional multivariate Normal and estimating Gaussian process
hyperparameters.
</summary>
    <author>
      <name>Jan-Willem van de Meent</name>
    </author>
    <author>
      <name>Brooks Paige</name>
    </author>
    <author>
      <name>Frank Wood</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 3 figures, 2 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1401.7145v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1401.7145v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1401.8008v1</id>
    <updated>2014-01-30T21:49:16Z</updated>
    <published>2014-01-30T21:49:16Z</published>
    <title>Support vector comparison machines</title>
    <summary>  In ranking problems, the goal is to learn a ranking function from labeled
pairs of input points. In this paper, we consider the related comparison
problem, where the label indicates which element of the pair is better, or if
there is no significant difference. We cast the learning problem as a margin
maximization, and show that it can be solved by converting it to a standard
SVM. We use simulated nonlinear patterns and a real learning to rank sushi data
set to show that our proposed SVMcompare algorithm outperforms SVMrank when
there are equality pairs.
</summary>
    <author>
      <name>Toby Dylan Hocking</name>
    </author>
    <author>
      <name>Supaporn Spanurattana</name>
    </author>
    <author>
      <name>Masashi Sugiyama</name>
    </author>
    <link href="http://arxiv.org/abs/1401.8008v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1401.8008v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1401.8017v1</id>
    <updated>2014-01-30T22:40:35Z</updated>
    <published>2014-01-30T22:40:35Z</published>
    <title>Sparse Bayesian Unsupervised Learning</title>
    <summary>  This paper is about variable selection, clustering and estimation in an
unsupervised high-dimensional setting. Our approach is based on fitting
constrained Gaussian mixture models, where we learn the number of clusters $K$
and the set of relevant variables $S$ using a generalized Bayesian posterior
with a sparsity inducing prior. We prove a sparsity oracle inequality which
shows that this procedure selects the optimal parameters $K$ and $S$. This
procedure is implemented using a Metropolis-Hastings algorithm, based on a
clustering-oriented greedy proposal, which makes the convergence to the
posterior very fast.
</summary>
    <author>
      <name>Stephane Gaiffas</name>
    </author>
    <author>
      <name>Bertrand Michel</name>
    </author>
    <link href="http://arxiv.org/abs/1401.8017v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1401.8017v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62H30" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.3; H.3.3; I.5.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1402.0099v1</id>
    <updated>2014-02-01T16:38:59Z</updated>
    <published>2014-02-01T16:38:59Z</published>
    <title>Dual-to-kernel learning with ideals</title>
    <summary>  In this paper, we propose a theory which unifies kernel learning and symbolic
algebraic methods. We show that both worlds are inherently dual to each other,
and we use this duality to combine the structure-awareness of algebraic methods
with the efficiency and generality of kernels. The main idea lies in relating
polynomial rings to feature space, and ideals to manifolds, then exploiting
this generative-discriminative duality on kernel matrices. We illustrate this
by proposing two algorithms, IPCA and AVICA, for simultaneous manifold and
feature learning, and test their accuracy on synthetic and real world data.
</summary>
    <author>
      <name>Franz J. Király</name>
    </author>
    <author>
      <name>Martin Kreuzer</name>
    </author>
    <author>
      <name>Louis Theran</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1402.0099v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1402.0099v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.AC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.AG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1402.2148v1</id>
    <updated>2014-02-10T13:57:32Z</updated>
    <published>2014-02-10T13:57:32Z</published>
    <title>An Algorithmic Framework for Computing Validation Performance Bounds by
  Using Suboptimal Models</title>
    <summary>  Practical model building processes are often time-consuming because many
different models must be trained and validated. In this paper, we introduce a
novel algorithm that can be used for computing the lower and the upper bounds
of model validation errors without actually training the model itself. A key
idea behind our algorithm is using a side information available from a
suboptimal model. If a reasonably good suboptimal model is available, our
algorithm can compute lower and upper bounds of many useful quantities for
making inferences on the unknown target model. We demonstrate the advantage of
our algorithm in the context of model selection for regularized learning
problems.
</summary>
    <author>
      <name>Yoshiki Suzuki</name>
    </author>
    <author>
      <name>Kohei Ogawa</name>
    </author>
    <author>
      <name>Yuki Shinmura</name>
    </author>
    <author>
      <name>Ichiro Takeuchi</name>
    </author>
    <link href="http://arxiv.org/abs/1402.2148v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1402.2148v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1402.2499v1</id>
    <updated>2014-02-11T14:24:54Z</updated>
    <published>2014-02-11T14:24:54Z</published>
    <title>Justifying Information-Geometric Causal Inference</title>
    <summary>  Information Geometric Causal Inference (IGCI) is a new approach to
distinguish between cause and effect for two variables. It is based on an
independence assumption between input distribution and causal mechanism that
can be phrased in terms of orthogonality in information space. We describe two
intuitive reinterpretations of this approach that makes IGCI more accessible to
a broader audience.
  Moreover, we show that the described independence is related to the
hypothesis that unsupervised learning and semi-supervised learning only works
for predicting the cause from the effect and not vice versa.
</summary>
    <author>
      <name>Dominik Janzing</name>
    </author>
    <author>
      <name>Bastian Steudel</name>
    </author>
    <author>
      <name>Naji Shajarisales</name>
    </author>
    <author>
      <name>Bernhard Schölkopf</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3 Figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1402.2499v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1402.2499v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1402.4507v1</id>
    <updated>2014-02-18T21:53:33Z</updated>
    <published>2014-02-18T21:53:33Z</published>
    <title>High Dimensional Semiparametric Scale-Invariant Principal Component
  Analysis</title>
    <summary>  We propose a new high dimensional semiparametric principal component analysis
(PCA) method, named Copula Component Analysis (COCA). The semiparametric model
assumes that, after unspecified marginally monotone transformations, the
distributions are multivariate Gaussian. COCA improves upon PCA and sparse PCA
in three aspects: (i) It is robust to modeling assumptions; (ii) It is robust
to outliers and data contamination; (iii) It is scale-invariant and yields more
interpretable results. We prove that the COCA estimators obtain fast estimation
rates and are feature selection consistent when the dimension is nearly
exponentially large relative to the sample size. Careful experiments confirm
that COCA outperforms sparse PCA on both synthetic and real-world datasets.
</summary>
    <author>
      <name>Fang Han</name>
    </author>
    <author>
      <name>Han Liu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted in IEEE Transactions on Pattern Analysis and Machine
  Intelligence (TPMAI)</arxiv:comment>
    <link href="http://arxiv.org/abs/1402.4507v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1402.4507v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1402.4884v2</id>
    <updated>2014-02-21T22:37:10Z</updated>
    <published>2014-02-20T04:06:28Z</published>
    <title>Le Cam meets LeCun: Deficiency and Generic Feature Learning</title>
    <summary>  "Deep Learning" methods attempt to learn generic features in an unsupervised
fashion from a large unlabelled data set. These generic features should perform
as well as the best hand crafted features for any learning problem that makes
use of this data. We provide a definition of generic features, characterize
when it is possible to learn them and provide methods closely related to the
autoencoder and deep belief network of deep learning. In order to do so we use
the notion of deficiency and illustrate its value in studying certain general
learning problems.
</summary>
    <author>
      <name>Brendan van Rooyen</name>
    </author>
    <author>
      <name>Robert C. Williamson</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">25 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1402.4884v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1402.4884v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1402.6863v3</id>
    <updated>2014-08-14T09:11:18Z</updated>
    <published>2014-02-27T11:27:44Z</published>
    <title>Addendum on the scoring of Gaussian directed acyclic graphical models</title>
    <summary>  We provide a correction to the expression for scoring Gaussian directed
acyclic graphical models derived in Geiger and Heckerman [Ann. Statist. 30
(2002) 1414-1440] and discuss how to evaluate the score efficiently.
</summary>
    <author>
      <name>Jack Kuipers</name>
    </author>
    <author>
      <name>Giusi Moffa</name>
    </author>
    <author>
      <name>David Heckerman</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1214/14-AOS1217</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1214/14-AOS1217" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published in at http://dx.doi.org/10.1214/14-AOS1217 the Annals of
  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical
  Statistics (http://www.imstat.org)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Annals of Statistics 2014, Vol. 42, No. 4, 1689-1691</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1402.6863v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1402.6863v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1403.0745v1</id>
    <updated>2014-03-04T11:28:59Z</updated>
    <published>2014-03-04T11:28:59Z</published>
    <title>EnsembleSVM: A Library for Ensemble Learning Using Support Vector
  Machines</title>
    <summary>  EnsembleSVM is a free software package containing efficient routines to
perform ensemble learning with support vector machine (SVM) base models. It
currently offers ensemble methods based on binary SVM models. Our
implementation avoids duplicate storage and evaluation of support vectors which
are shared between constituent models. Experimental results show that using
ensemble approaches can drastically reduce training complexity while
maintaining high predictive accuracy. The EnsembleSVM software package is
freely available online at http://esat.kuleuven.be/stadius/ensemblesvm.
</summary>
    <author>
      <name>Marc Claesen</name>
    </author>
    <author>
      <name>Frank De Smet</name>
    </author>
    <author>
      <name>Johan Suykens</name>
    </author>
    <author>
      <name>Bart De Moor</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 1 table</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Machine Learning Research. 15 (2014) 141-145</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1403.0745v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1403.0745v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.3; I.2.6; I.5.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1403.5370v1</id>
    <updated>2014-03-21T05:23:17Z</updated>
    <published>2014-03-21T05:23:17Z</published>
    <title>Using n-grams models for visual semantic place recognition</title>
    <summary>  The aim of this paper is to present a new method for visual place
recognition. Our system combines global image characterization and visual
words, which allows to use efficient Bayesian filtering methods to integrate
several images. More precisely, we extend the classical HMM model with
techniques inspired by the field of Natural Language Processing. This paper
presents our system and the Bayesian filtering algorithm. The performance of
our system and the influence of the main parameters are evaluated on a standard
database. The discussion highlights the interest of using such models and
proposes improvements.
</summary>
    <author>
      <name>Mathieu Dubois</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIMSI</arxiv:affiliation>
    </author>
    <author>
      <name>Frenoux Emmanuelle</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIMSI</arxiv:affiliation>
    </author>
    <author>
      <name>Philippe Tarroux</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIMSI</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">VISAPP (2013)</arxiv:comment>
    <link href="http://arxiv.org/abs/1403.5370v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1403.5370v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1403.5877v1</id>
    <updated>2014-03-24T08:26:19Z</updated>
    <published>2014-03-24T08:26:19Z</published>
    <title>Non-uniform Feature Sampling for Decision Tree Ensembles</title>
    <summary>  We study the effectiveness of non-uniform randomized feature selection in
decision tree classification. We experimentally evaluate two feature selection
methodologies, based on information extracted from the provided dataset: $(i)$
\emph{leverage scores-based} and $(ii)$ \emph{norm-based} feature selection.
Experimental evaluation of the proposed feature selection techniques indicate
that such approaches might be more effective compared to naive uniform feature
selection and moreover having comparable performance to the random forest
algorithm [3]
</summary>
    <author>
      <name>Anastasios Kyrillidis</name>
    </author>
    <author>
      <name>Anastasios Zouzias</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 7 figures, 1 table</arxiv:comment>
    <link href="http://arxiv.org/abs/1403.5877v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1403.5877v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1403.7265v1</id>
    <updated>2014-03-28T01:28:52Z</updated>
    <published>2014-03-28T01:28:52Z</published>
    <title>Accelerating MCMC via Parallel Predictive Prefetching</title>
    <summary>  We present a general framework for accelerating a large class of widely used
Markov chain Monte Carlo (MCMC) algorithms. Our approach exploits fast,
iterative approximations to the target density to speculatively evaluate many
potential future steps of the chain in parallel. The approach can accelerate
computation of the target distribution of a Bayesian inference problem, without
compromising exactness, by exploiting subsets of data. It takes advantage of
whatever parallel resources are available, but produces results exactly
equivalent to standard serial execution. In the initial burn-in phase of chain
evaluation, it achieves speedup over serial evaluation that is close to linear
in the number of available cores.
</summary>
    <author>
      <name>Elaine Angelino</name>
    </author>
    <author>
      <name>Eddie Kohler</name>
    </author>
    <author>
      <name>Amos Waterland</name>
    </author>
    <author>
      <name>Margo Seltzer</name>
    </author>
    <author>
      <name>Ryan P. Adams</name>
    </author>
    <link href="http://arxiv.org/abs/1403.7265v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1403.7265v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.0751v2</id>
    <updated>2016-12-12T15:36:21Z</updated>
    <published>2014-04-03T02:58:37Z</published>
    <title>Subspace Learning from Extremely Compressed Measurements</title>
    <summary>  We consider learning the principal subspace of a large set of vectors from an
extremely small number of compressive measurements of each vector. Our
theoretical results show that even a constant number of measurements per column
suffices to approximate the principal subspace to arbitrary precision, provided
that the number of vectors is large. This result is achieved by a simple
algorithm that computes the eigenvectors of an estimate of the covariance
matrix. The main insight is to exploit an averaging effect that arises from
applying a different random projection to each vector. We provide a number of
simulations confirming our theoretical results.
</summary>
    <author>
      <name>Akshay Krishnamurthy</name>
    </author>
    <author>
      <name>Martin Azizyan</name>
    </author>
    <author>
      <name>Aarti Singh</name>
    </author>
    <link href="http://arxiv.org/abs/1404.0751v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.0751v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.1238v3</id>
    <updated>2014-11-12T09:51:00Z</updated>
    <published>2014-04-04T12:50:48Z</published>
    <title>Exact Estimation of Multiple Directed Acyclic Graphs</title>
    <summary>  This paper considers the problem of estimating the structure of multiple
related directed acyclic graph (DAG) models. Building on recent developments in
exact estimation of DAGs using integer linear programming (ILP), we present an
ILP approach for joint estimation over multiple DAGs, that does not require
that the vertices in each DAG share a common ordering. Furthermore, we allow
also for (potentially unknown) dependency structure between the DAGs. Results
are presented on both simulated data and fMRI data obtained from multiple
subjects.
</summary>
    <author>
      <name>Chris J. Oates</name>
    </author>
    <author>
      <name>Jim Q. Smith</name>
    </author>
    <author>
      <name>Sach Mukherjee</name>
    </author>
    <author>
      <name>James Cussens</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Revised version - 12/11/14</arxiv:comment>
    <link href="http://arxiv.org/abs/1404.1238v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.1238v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.2007v1</id>
    <updated>2014-04-08T04:44:59Z</updated>
    <published>2014-04-08T04:44:59Z</published>
    <title>A Permutation Approach for Selecting the Penalty Parameter in Penalized
  Model Selection</title>
    <summary>  We describe a simple, efficient, permutation based procedure for selecting
the penalty parameter in the LASSO. The procedure, which is intended for
applications where variable selection is the primary focus, can be applied in a
variety of structural settings, including generalized linear models. We briefly
discuss connections between permutation selection and existing theory for the
LASSO. In addition, we present a simulation study and an analysis of three real
data sets in which permutation selection is compared with cross-validation
(CV), the Bayesian information criterion (BIC), and a selection method based on
recently developed testing procedures for the LASSO.
</summary>
    <author>
      <name>Jeremy Sabourin</name>
    </author>
    <author>
      <name>William Valdar</name>
    </author>
    <author>
      <name>Andrew Nobel</name>
    </author>
    <link href="http://arxiv.org/abs/1404.2007v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.2007v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.3219v1</id>
    <updated>2014-04-11T20:22:40Z</updated>
    <published>2014-04-11T20:22:40Z</published>
    <title>Estimating nonlinear regression errors without doing regression</title>
    <summary>  A method for estimating nonlinear regression errors and their distributions
without performing regression is presented. Assuming continuity of the modeling
function the variance is given in terms of conditional probabilities extracted
from the data. For N data points the computational demand is N2. Comparing the
predicted residual errors with those derived from a linear model assumption
provides a signal for nonlinearity. The method is successfully illustrated with
data generated by the Ikeda and Lorenz maps augmented with noise. As a
by-product the embedding dimensions of these maps are also extracted.
</summary>
    <author>
      <name>Hong Pi</name>
    </author>
    <author>
      <name>Carsten Peterson</name>
    </author>
    <link href="http://arxiv.org/abs/1404.3219v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.3219v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.CD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.4095v3</id>
    <updated>2014-05-19T03:43:42Z</updated>
    <published>2014-04-15T22:06:35Z</published>
    <title>Multi-borders classification</title>
    <summary>  The number of possible methods of generalizing binary classification to
multi-class classification increases exponentially with the number of class
labels. Often, the best method of doing so will be highly problem dependent.
Here we present classification software in which the partitioning of
multi-class classification problems into binary classification problems is
specified using a recursive control language.
</summary>
    <author>
      <name>Peter Mills</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Corrected error in equations: second and third equations were not
  linearly independent. Corrected figure to match. "Hierarchical" scheme is a
  decision tree</arxiv:comment>
    <link href="http://arxiv.org/abs/1404.4095v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.4095v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.5443v1</id>
    <updated>2014-04-22T10:04:10Z</updated>
    <published>2014-04-22T10:04:10Z</published>
    <title>Approximate Inference for Nonstationary Heteroscedastic Gaussian process
  Regression</title>
    <summary>  This paper presents a novel approach for approximate integration over the
uncertainty of noise and signal variances in Gaussian process (GP) regression.
Our efficient and straightforward approach can also be applied to integration
over input dependent noise variance (heteroscedasticity) and input dependent
signal variance (nonstationarity) by setting independent GP priors for the
noise and signal variances. We use expectation propagation (EP) for inference
and compare results to Markov chain Monte Carlo in two simulated data sets and
three empirical examples. The results show that EP produces comparable results
with less computational burden.
</summary>
    <author>
      <name>Ville Tolvanen</name>
    </author>
    <author>
      <name>Pasi Jylänki</name>
    </author>
    <author>
      <name>Aki Vehtari</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/MLSP.2014.6958906</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/MLSP.2014.6958906" rel="related"/>
    <link href="http://arxiv.org/abs/1404.5443v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.5443v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.5793v2</id>
    <updated>2015-03-26T04:36:38Z</updated>
    <published>2014-04-23T12:02:59Z</published>
    <title>Bayesian Reconstruction of Missing Observations</title>
    <summary>  We focus on an interpolation method referred to Bayesian reconstruction in
this paper. Whereas in standard interpolation methods missing data are
interpolated deterministically, in Bayesian reconstruction, missing data are
interpolated probabilistically using a Bayesian treatment. In this paper, we
address the framework of Bayesian reconstruction and its application to the
traffic data reconstruction problem in the field of traffic engineering. In the
latter part of this paper, we describe the evaluation of the statistical
performance of our Bayesian traffic reconstruction model using a statistical
mechanical approach and clarify its statistical behavior.
</summary>
    <author>
      <name>Shun Kataoka</name>
    </author>
    <author>
      <name>Muneki Yasuda</name>
    </author>
    <author>
      <name>Kazuyuki Tanaka</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Interdisciplinary Information Sciences, Vol.21, No.1, pp.11-23,
  2015</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1404.5793v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.5793v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.6216v1</id>
    <updated>2014-04-24T18:35:37Z</updated>
    <published>2014-04-24T18:35:37Z</published>
    <title>CoRE Kernels</title>
    <summary>  The term "CoRE kernel" stands for correlation-resemblance kernel. In many
applications (e.g., vision), the data are often high-dimensional, sparse, and
non-binary. We propose two types of (nonlinear) CoRE kernels for non-binary
sparse data and demonstrate the effectiveness of the new kernels through a
classification experiment. CoRE kernels are simple with no tuning parameters.
However, training nonlinear kernel SVM can be (very) costly in time and memory
and may not be suitable for truly large-scale industrial applications (e.g.
search). In order to make the proposed CoRE kernels more practical, we develop
basic probabilistic hashing algorithms which transform nonlinear kernels into
linear kernels.
</summary>
    <author>
      <name>Ping Li</name>
    </author>
    <link href="http://arxiv.org/abs/1404.6216v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.6216v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.0042v2</id>
    <updated>2015-06-15T13:12:12Z</updated>
    <published>2014-04-30T21:48:34Z</published>
    <title>Learning with incremental iterative regularization</title>
    <summary>  Within a statistical learning setting, we propose and study an iterative
regularization algorithm for least squares defined by an incremental gradient
method. In particular, we show that, if all other parameters are fixed a
priori, the number of passes over the data (epochs) acts as a regularization
parameter, and prove strong universal consistency, i.e. almost sure convergence
of the risk, as well as sharp finite sample bounds for the iterates. Our
results are a step towards understanding the effect of multiple epochs in
stochastic gradient techniques in machine learning and rely on integrating
statistical and optimization results.
</summary>
    <author>
      <name>Lorenzo Rosasco</name>
    </author>
    <author>
      <name>Silvia Villa</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">30 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1405.0042v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.0042v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.0099v1</id>
    <updated>2014-05-01T05:27:51Z</updated>
    <published>2014-05-01T05:27:51Z</published>
    <title>Fast MLE Computation for the Dirichlet Multinomial</title>
    <summary>  Given a collection of categorical data, we want to find the parameters of a
Dirichlet distribution which maximizes the likelihood of that data. Newton's
method is typically used for this purpose but current implementations require
reading through the entire dataset on each iteration. In this paper, we propose
a modification which requires only a single pass through the dataset and
substantially decreases running time. Furthermore we analyze both theoretically
and empirically the performance of the proposed algorithm, and provide an open
source implementation.
</summary>
    <author>
      <name>Max Sklar</name>
    </author>
    <link href="http://arxiv.org/abs/1405.0099v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.0099v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.0558v2</id>
    <updated>2014-10-27T21:46:29Z</updated>
    <published>2014-05-03T07:35:29Z</published>
    <title>The Falling Factorial Basis and Its Statistical Applications</title>
    <summary>  We study a novel spline-like basis, which we name the "falling factorial
basis", bearing many similarities to the classic truncated power basis. The
advantage of the falling factorial basis is that it enables rapid, linear-time
computations in basis matrix multiplication and basis matrix inversion. The
falling factorial functions are not actually splines, but are close enough to
splines that they provably retain some of the favorable properties of the
latter functions. We examine their application in two problems: trend filtering
over arbitrary input points, and a higher-order variant of the two-sample
Kolmogorov-Smirnov test.
</summary>
    <author>
      <name>Yu-Xiang Wang</name>
    </author>
    <author>
      <name>Alex Smola</name>
    </author>
    <author>
      <name>Ryan J. Tibshirani</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Full version for the ICML paper with the same title</arxiv:comment>
    <link href="http://arxiv.org/abs/1405.0558v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.0558v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.0602v1</id>
    <updated>2014-05-03T15:52:00Z</updated>
    <published>2014-05-03T15:52:00Z</published>
    <title>Why (and When and How) Contrastive Divergence Works</title>
    <summary>  Contrastive divergence (CD) is a promising method of inference in high
dimensional distributions with intractable normalizing constants, however, the
theoretical foundations justifying its use are somewhat shaky. This document
proposes a framework for understanding CD inference, how/when it works, and
provides multiple justifications for the CD moment conditions, including
framing them as a variational approximation. Algorithms for performing
inference are discussed and are applied to social network data using an
exponential-family random graph models (ERGM). The framework also provides
guidance about how to construct MCMC kernels providing good CD inference, which
turn out to be quite different from those used typically to provide fast global
mixing.
</summary>
    <author>
      <name>Ian E Fellows</name>
    </author>
    <link href="http://arxiv.org/abs/1405.0602v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.0602v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.2377v1</id>
    <updated>2014-05-10T02:03:22Z</updated>
    <published>2014-05-10T02:03:22Z</published>
    <title>A Hybrid Monte Carlo Architecture for Parameter Optimization</title>
    <summary>  Much recent research has been conducted in the area of Bayesian learning,
particularly with regard to the optimization of hyper-parameters via Gaussian
process regression. The methodologies rely chiefly on the method of maximizing
the expected improvement of a score function with respect to adjustments in the
hyper-parameters. In this work, we present a novel algorithm that exploits
notions of confidence intervals and uncertainties to enable the discovery of
the best optimal within a targeted region of the parameter space. We
demonstrate the efficacy of our algorithm with respect to machine learning
problems and show cases where our algorithm is competitive with the method of
maximizing expected improvement.
</summary>
    <author>
      <name>James Brofos</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 2 figures, 2 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1405.2377v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.2377v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.2432v1</id>
    <updated>2014-05-10T13:34:22Z</updated>
    <published>2014-05-10T13:34:22Z</published>
    <title>Functional Bandits</title>
    <summary>  We introduce the functional bandit problem, where the objective is to find an
arm that optimises a known functional of the unknown arm-reward distributions.
These problems arise in many settings such as maximum entropy methods in
natural language processing, and risk-averse decision-making, but current
best-arm identification techniques fail in these domains. We propose a new
approach, that combines functional estimation and arm elimination, to tackle
this problem. This method achieves provably efficient performance guarantees.
In addition, we illustrate this method on a number of important functionals in
risk management and information theory, and refine our generic theoretical
results in those cases.
</summary>
    <author>
      <name>Long Tran-Thanh</name>
    </author>
    <author>
      <name>Jia Yuan Yu</name>
    </author>
    <link href="http://arxiv.org/abs/1405.2432v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.2432v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.3080v1</id>
    <updated>2014-05-13T09:45:49Z</updated>
    <published>2014-05-13T09:45:49Z</published>
    <title>Accelerating Minibatch Stochastic Gradient Descent using Stratified
  Sampling</title>
    <summary>  Stochastic Gradient Descent (SGD) is a popular optimization method which has
been applied to many important machine learning tasks such as Support Vector
Machines and Deep Neural Networks. In order to parallelize SGD, minibatch
training is often employed. The standard approach is to uniformly sample a
minibatch at each step, which often leads to high variance. In this paper we
propose a stratified sampling strategy, which divides the whole dataset into
clusters with low within-cluster variance; we then take examples from these
clusters using a stratified sampling technique. It is shown that the
convergence rate can be significantly improved by the algorithm. Encouraging
experimental results confirm the effectiveness of the proposed method.
</summary>
    <author>
      <name>Peilin Zhao</name>
    </author>
    <author>
      <name>Tong Zhang</name>
    </author>
    <link href="http://arxiv.org/abs/1405.3080v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.3080v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.3379v1</id>
    <updated>2014-05-14T06:50:08Z</updated>
    <published>2014-05-14T06:50:08Z</published>
    <title>Learning rates for the risk of kernel based quantile regression
  estimators in additive models</title>
    <summary>  Additive models play an important role in semiparametric statistics. This
paper gives learning rates for regularized kernel based methods for additive
models. These learning rates compare favourably in particular in high
dimensions to recent results on optimal learning rates for purely nonparametric
regularized kernel based quantile regression using the Gaussian radial basis
function kernel, provided the assumption of an additive model is valid.
Additionally, a concrete example is presented to show that a Gaussian function
depending only on one variable lies in a reproducing kernel Hilbert space
generated by an additive Gaussian kernel, but does not belong to the
reproducing kernel Hilbert space generated by the multivariate Gaussian kernel
of the same variance.
</summary>
    <author>
      <name>Andreas Christmann</name>
    </author>
    <author>
      <name>Ding-Xuan Zhou</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">35 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1405.3379v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.3379v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.3738v1</id>
    <updated>2014-05-15T04:32:29Z</updated>
    <published>2014-05-15T04:32:29Z</published>
    <title>Effective Bayesian Modeling of Groups of Related Count Time Series</title>
    <summary>  Time series of counts arise in a variety of forecasting applications, for
which traditional models are generally inappropriate. This paper introduces a
hierarchical Bayesian formulation applicable to count time series that can
easily account for explanatory variables and share statistical strength across
groups of related time series. We derive an efficient approximate inference
technique, and illustrate its performance on a number of datasets from supply
chain planning.
</summary>
    <author>
      <name>Nicolas Chapados</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 7 figures. Appears in Proceedings of the 31st International
  Conference on Machine Learning, Beijing, China, 2014. JMLR: W&amp;CP volume 32</arxiv:comment>
    <link href="http://arxiv.org/abs/1405.3738v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.3738v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.3952v1</id>
    <updated>2014-05-15T19:14:44Z</updated>
    <published>2014-05-15T19:14:44Z</published>
    <title>Fast Ridge Regression with Randomized Principal Component Analysis and
  Gradient Descent</title>
    <summary>  We propose a new two stage algorithm LING for large scale regression
problems. LING has the same risk as the well known Ridge Regression under the
fixed design setting and can be computed much faster. Our experiments have
shown that LING performs well in terms of both prediction accuracy and
computational efficiency compared with other large scale regression algorithms
like Gradient Descent, Stochastic Gradient Descent and Principal Component
Regression on both simulated and real datasets.
</summary>
    <author>
      <name>Yichao Lu</name>
    </author>
    <author>
      <name>Dean P. Foster</name>
    </author>
    <link href="http://arxiv.org/abs/1405.3952v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.3952v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1406.0013v1</id>
    <updated>2014-05-30T20:45:50Z</updated>
    <published>2014-05-30T20:45:50Z</published>
    <title>Estimating Vector Fields on Manifolds and the Embedding of Directed
  Graphs</title>
    <summary>  This paper considers the problem of embedding directed graphs in Euclidean
space while retaining directional information. We model a directed graph as a
finite set of observations from a diffusion on a manifold endowed with a vector
field. This is the first generative model of its kind for directed graphs. We
introduce a graph embedding algorithm that estimates all three features of this
model: the low-dimensional embedding of the manifold, the data density and the
vector field. In the process, we also obtain new theoretical results on the
limits of "Laplacian type" matrices derived from directed graphs. The
application of our method to both artificially constructed and real data
highlights its strengths.
</summary>
    <author>
      <name>Dominique Perrault-Joncas</name>
    </author>
    <author>
      <name>Marina Meila</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1406.0013v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1406.0013v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1406.1853v2</id>
    <updated>2014-10-31T23:36:00Z</updated>
    <published>2014-06-07T03:02:09Z</published>
    <title>Model-based Reinforcement Learning and the Eluder Dimension</title>
    <summary>  We consider the problem of learning to optimize an unknown Markov decision
process (MDP). We show that, if the MDP can be parameterized within some known
function class, we can obtain regret bounds that scale with the dimensionality,
rather than cardinality, of the system. We characterize this dependence
explicitly as $\tilde{O}(\sqrt{d_K d_E T})$ where $T$ is time elapsed, $d_K$ is
the Kolmogorov dimension and $d_E$ is the \emph{eluder dimension}. These
represent the first unified regret bounds for model-based reinforcement
learning and provide state of the art guarantees in several important settings.
Moreover, we present a simple and computationally efficient algorithm
\emph{posterior sampling for reinforcement learning} (PSRL) that satisfies
these bounds.
</summary>
    <author>
      <name>Ian Osband</name>
    </author>
    <author>
      <name>Benjamin Van Roy</name>
    </author>
    <link href="http://arxiv.org/abs/1406.1853v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1406.1853v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1406.2602v1</id>
    <updated>2014-06-10T15:49:05Z</updated>
    <published>2014-06-10T15:49:05Z</published>
    <title>Graph Approximation and Clustering on a Budget</title>
    <summary>  We consider the problem of learning from a similarity matrix (such as
spectral clustering and lowd imensional embedding), when computing pairwise
similarities are costly, and only a limited number of entries can be observed.
We provide a theoretical analysis using standard notions of graph
approximation, significantly generalizing previous results (which focused on
spectral clustering with two clusters). We also propose a new algorithmic
approach based on adaptive sampling, which experimentally matches or improves
on previous methods, while being considerably more general and computationally
cheaper.
</summary>
    <author>
      <name>Ethan Fetaya</name>
    </author>
    <author>
      <name>Ohad Shamir</name>
    </author>
    <author>
      <name>Shimon Ullman</name>
    </author>
    <link href="http://arxiv.org/abs/1406.2602v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1406.2602v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1406.2864v1</id>
    <updated>2014-06-11T11:38:34Z</updated>
    <published>2014-06-11T11:38:34Z</published>
    <title>Algebraic-Combinatorial Methods for Low-Rank Matrix Completion with
  Application to Athletic Performance Prediction</title>
    <summary>  This paper presents novel algorithms which exploit the intrinsic algebraic
and combinatorial structure of the matrix completion task for estimating
missing en- tries in the general low rank setting. For positive data, we
achieve results out- performing the state of the art nuclear norm, both in
accuracy and computational efficiency, in simulations and in the task of
predicting athletic performance from partially observed data.
</summary>
    <author>
      <name>Duncan A. J. Blythe</name>
    </author>
    <author>
      <name>Louis Theran</name>
    </author>
    <author>
      <name>Franz Kiraly</name>
    </author>
    <link href="http://arxiv.org/abs/1406.2864v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1406.2864v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1406.6315v2</id>
    <updated>2014-09-09T13:53:25Z</updated>
    <published>2014-06-24T17:15:11Z</published>
    <title>Automatic Dimension Selection for a Non-negative Factorization Approach
  to Clustering Multiple Random Graphs</title>
    <summary>  We consider a problem of grouping multiple graphs into several clusters using
singular value thesholding and non-negative factorization. We derive a model
selection information criterion to estimate the number of clusters. We
demonstrate our approach using "Swimmer data set" as well as simulated data
set, and compare its performance with two standard clustering algorithms.
</summary>
    <author>
      <name>Nam H. Lee</name>
    </author>
    <author>
      <name>I-Jeng Wang</name>
    </author>
    <author>
      <name>Youngser Park</name>
    </author>
    <author>
      <name>Care E. Priebe</name>
    </author>
    <author>
      <name>Michael Rosen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper has been withdrawn by the author due to a newer version
  with overlapping contents</arxiv:comment>
    <link href="http://arxiv.org/abs/1406.6315v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1406.6315v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1407.1176v1</id>
    <updated>2014-07-04T10:17:43Z</updated>
    <published>2014-07-04T10:17:43Z</published>
    <title>Identifying Higher-order Combinations of Binary Features</title>
    <summary>  Finding statistically significant interactions between binary variables is
computationally and statistically challenging in high-dimensional settings, due
to the combinatorial explosion in the number of hypotheses. Terada et al.
recently showed how to elegantly address this multiple testing problem by
excluding non-testable hypotheses. Still, it remains unclear how their approach
scales to large datasets.
  We here proposed strategies to speed up the approach by Terada et al. and
evaluate them thoroughly in 11 real-world benchmark datasets. We observe that
one approach, incremental search with early stopping, is orders of magnitude
faster than the current state-of-the-art approach.
</summary>
    <author>
      <name>Felipe Llinares</name>
    </author>
    <author>
      <name>Mahito Sugiyama</name>
    </author>
    <author>
      <name>Karsten M. Borgwardt</name>
    </author>
    <link href="http://arxiv.org/abs/1407.1176v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1407.1176v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1407.2483v2</id>
    <updated>2014-07-12T17:23:57Z</updated>
    <published>2014-07-09T14:02:01Z</published>
    <title>Counting Markov Blanket Structures</title>
    <summary>  Learning Markov blanket (MB) structures has proven useful in performing
feature selection, learning Bayesian networks (BNs), and discovering causal
relationships. We present a formula for efficiently determining the number of
MB structures given a target variable and a set of other variables. As
expected, the number of MB structures grows exponentially. However, we show
quantitatively that there are many fewer MB structures that contain the target
variable than there are BN structures that contain it. In particular, the ratio
of BN structures to MB structures appears to increase exponentially in the
number of variables.
</summary>
    <author>
      <name>Shyam Visweswaran</name>
    </author>
    <author>
      <name>Gregory F. Cooper</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 2 figures, 1 table</arxiv:comment>
    <link href="http://arxiv.org/abs/1407.2483v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1407.2483v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1407.2812v1</id>
    <updated>2014-07-10T14:48:03Z</updated>
    <published>2014-07-10T14:48:03Z</published>
    <title>Rate-Optimal Detection of Very Short Signal Segments</title>
    <summary>  Motivated by a range of applications in engineering and genomics, we consider
in this paper detection of very short signal segments in three settings:
signals with known shape, arbitrary signals, and smooth signals. Optimal rates
of detection are established for the three cases and rate-optimal detectors are
constructed. The detectors are easily implementable and are based on scanning
with linear and quadratic statistics. Our analysis reveals both similarities
and differences in the strategy and fundamental difficulty of detection among
these three settings.
</summary>
    <author>
      <name>T. Tony Cai</name>
    </author>
    <author>
      <name>Ming Yuan</name>
    </author>
    <link href="http://arxiv.org/abs/1407.2812v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1407.2812v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1407.4508v2</id>
    <updated>2014-12-30T16:55:45Z</updated>
    <published>2014-07-16T21:51:07Z</published>
    <title>Large scale canonical correlation analysis with iterative least squares</title>
    <summary>  Canonical Correlation Analysis (CCA) is a widely used statistical tool with
both well established theory and favorable performance for a wide range of
machine learning problems. However, computing CCA for huge datasets can be very
slow since it involves implementing QR decomposition or singular value
decomposition of huge matrices. In this paper we introduce L-CCA, a iterative
algorithm which can compute CCA fast on huge sparse datasets. Theory on both
the asymptotic convergence and finite time accuracy of L-CCA are established.
The experiments also show that L-CCA outperform other fast CCA approximation
schemes on two real datasets.
</summary>
    <author>
      <name>Yichao Lu</name>
    </author>
    <author>
      <name>Dean P. Foster</name>
    </author>
    <link href="http://arxiv.org/abs/1407.4508v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1407.4508v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1407.4543v2</id>
    <updated>2016-10-19T06:13:35Z</updated>
    <published>2014-07-17T03:11:19Z</published>
    <title>Sparse Quadratic Discriminant Analysis and Community Bayes</title>
    <summary>  We develop a class of rules spanning the range between quadratic discriminant
analysis and naive Bayes, through a path of sparse graphical models. A group
lasso penalty is used to introduce shrinkage and encourage a similar pattern of
sparsity across precision matrices. It gives sparse estimates of interactions
and produces interpretable models. Inspired by the connected-components
structure of the estimated precision matrices, we propose the community Bayes
model, which partitions features into several conditional independent
communities and splits the classification problem into separate smaller ones.
The community Bayes idea is quite general and can be applied to non-Gaussian
data and likelihood-based classifiers.
</summary>
    <author>
      <name>Ya Le</name>
    </author>
    <author>
      <name>Trevor Hastie</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Revised version (adding more experiments)</arxiv:comment>
    <link href="http://arxiv.org/abs/1407.4543v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1407.4543v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1408.0337v1</id>
    <updated>2014-08-02T04:31:56Z</updated>
    <published>2014-08-02T04:31:56Z</published>
    <title>A Bayesian estimation approach to analyze non-Gaussian data-generating
  processes with latent classes</title>
    <summary>  A large amount of observational data has been accumulated in various fields
in recent times, and there is a growing need to estimate the generating
processes of these data. A linear non-Gaussian acyclic model (LiNGAM) based on
the non-Gaussianity of external influences has been proposed to estimate the
data-generating processes of variables. However, the results of the estimation
can be biased if there are latent classes. In this paper, we first review
LiNGAM, its extended model, as well as the estimation procedure for LiNGAM in a
Bayesian framework. We then propose a new Bayesian estimation procedure that
solves the problem.
</summary>
    <author>
      <name>Naoki Tanaka</name>
    </author>
    <author>
      <name>Shohei Shimizu</name>
    </author>
    <author>
      <name>Takashi Washio</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 1 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1408.0337v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1408.0337v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1408.1319v1</id>
    <updated>2014-08-06T15:27:20Z</updated>
    <published>2014-08-06T15:27:20Z</published>
    <title>When does Active Learning Work?</title>
    <summary>  Active Learning (AL) methods seek to improve classifier performance when
labels are expensive or scarce. We consider two central questions: Where does
AL work? How much does it help? To address these questions, a comprehensive
experimental simulation study of Active Learning is presented. We consider a
variety of tasks, classifiers and other AL factors, to present a broad
exploration of AL performance in various settings. A precise way to quantify
performance is needed in order to know when AL works. Thus we also present a
detailed methodology for tackling the complexities of assessing AL performance
in the context of this experimental study.
</summary>
    <author>
      <name>Lewis Evans</name>
    </author>
    <author>
      <name>Niall M. Adams</name>
    </author>
    <author>
      <name>Christoforos Anagnostopoulos</name>
    </author>
    <link href="http://arxiv.org/abs/1408.1319v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1408.1319v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1408.1336v2</id>
    <updated>2015-06-15T09:54:15Z</updated>
    <published>2014-08-06T15:50:30Z</published>
    <title>On the Generalization of the C-Bound to Structured Output Ensemble
  Methods</title>
    <summary>  This paper generalizes an important result from the PAC-Bayesian literature
for binary classification to the case of ensemble methods for structured
outputs. We prove a generic version of the \Cbound, an upper bound over the
risk of models expressed as a weighted majority vote that is based on the first
and second statistical moments of the vote's margin. This bound may
advantageously $(i)$ be applied on more complex outputs such as multiclass
labels and multilabel, and $(ii)$ allow to consider margin relaxations. These
results open the way to develop new ensemble methods for structured output
prediction with PAC-Bayesian guarantees.
</summary>
    <author>
      <name>François Laviolette</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LHC</arxiv:affiliation>
    </author>
    <author>
      <name>Emilie Morvant</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LHC</arxiv:affiliation>
    </author>
    <author>
      <name>Liva Ralaivola</name>
    </author>
    <author>
      <name>Jean-Francis Roy</name>
    </author>
    <link href="http://arxiv.org/abs/1408.1336v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1408.1336v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1408.5404v2</id>
    <updated>2016-09-27T10:15:33Z</updated>
    <published>2014-08-23T03:16:41Z</published>
    <title>A Wild Bootstrap for Degenerate Kernel Tests</title>
    <summary>  A wild bootstrap method for nonparametric hypothesis tests based on kernel
distribution embeddings is proposed. This bootstrap method is used to construct
provably consistent tests that apply to random processes, for which the naive
permutation-based bootstrap fails. It applies to a large group of kernel tests
based on V-statistics, which are degenerate under the null hypothesis, and
non-degenerate elsewhere. To illustrate this approach, we construct a
two-sample test, an instantaneous independence test and a multiple lag
independence test for time series. In experiments, the wild bootstrap gives
strong performance on synthetic examples, on audio data, and in performance
benchmarking for the Gibbs sampler.
</summary>
    <author>
      <name>Kacper Chwialkowski</name>
    </author>
    <author>
      <name>Dino Sejdinovic</name>
    </author>
    <author>
      <name>Arthur Gretton</name>
    </author>
    <link href="http://arxiv.org/abs/1408.5404v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1408.5404v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62G10" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1408.5544v2</id>
    <updated>2014-08-27T15:21:09Z</updated>
    <published>2014-08-24T02:53:57Z</published>
    <title>To lie or not to lie in a subspace</title>
    <summary>  Give deterministic necessary and sufficient conditions to guarantee that if a
subspace fits certain partially observed data from a union of subspaces, it is
because such data really lies in a subspace.
  Furthermore, Give deterministic necessary and sufficient conditions to
guarantee that if a subspace fits certain partially observed data, such
subspace is unique.
  Do this by characterizing when and only when a set of incomplete vectors
behaves as a single but complete one.
</summary>
    <author>
      <name>Daniel L. Pimentel-Alarcón</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">First author mistakenly listed advisors as co-authors in his research
  proposal. This is corrected in the current version. 59 pages, 19 figures.
  Subspace clustering, missing data, converse of matrix completion</arxiv:comment>
    <link href="http://arxiv.org/abs/1408.5544v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1408.5544v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1408.5810v2</id>
    <updated>2014-12-15T17:02:54Z</updated>
    <published>2014-08-25T15:44:05Z</published>
    <title>Kernel-based Information Criterion</title>
    <summary>  This paper introduces Kernel-based Information Criterion (KIC) for model
selection in regression analysis. The novel kernel-based complexity measure in
KIC efficiently computes the interdependency between parameters of the model
using a variable-wise variance and yields selection of better, more robust
regressors. Experimental results show superior performance on both simulated
and real data sets compared to Leave-One-Out Cross-Validation (LOOCV),
kernel-based Information Complexity (ICOMP), and maximum log of marginal
likelihood in Gaussian Process Regression (GPR).
</summary>
    <author>
      <name>Somayeh Danafar</name>
    </author>
    <author>
      <name>Kenji Fukumizu</name>
    </author>
    <author>
      <name>Faustino Gomez</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">We modified the reference 17, and the subcaptions of Figure 3</arxiv:comment>
    <link href="http://arxiv.org/abs/1408.5810v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1408.5810v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1409.0791v1</id>
    <updated>2014-09-02T16:52:53Z</updated>
    <published>2014-09-02T16:52:53Z</published>
    <title>Feature Selection in Conditional Random Fields for Map Matching of GPS
  Trajectories</title>
    <summary>  Map matching of the GPS trajectory serves the purpose of recovering the
original route on a road network from a sequence of noisy GPS observations. It
is a fundamental technique to many Location Based Services. However, map
matching of a low sampling rate on urban road network is still a challenging
task. In this paper, the characteristics of Conditional Random Fields with
regard to inducing many contextual features and feature selection are explored
for the map matching of the GPS trajectories at a low sampling rate.
Experiments on a taxi trajectory dataset show that our method may achieve
competitive results along with the success of reducing model complexity for
computation-limited applications.
</summary>
    <author>
      <name>Jian Yang</name>
    </author>
    <author>
      <name>Liqiu Meng</name>
    </author>
    <link href="http://arxiv.org/abs/1409.0791v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1409.0791v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1409.0797v1</id>
    <updated>2014-09-02T17:15:58Z</updated>
    <published>2014-09-02T17:15:58Z</published>
    <title>Feature Engineering for Map Matching of Low-Sampling-Rate GPS
  Trajectories in Road Network</title>
    <summary>  Map matching of GPS trajectories from a sequence of noisy observations serves
the purpose of recovering the original routes in a road network. In this work
in progress, we attempt to share our experience of feature construction in a
spatial database by reporting our ongoing experiment of feature extrac-tion in
Conditional Random Fields (CRFs) for map matching. Our preliminary results are
obtained from real-world taxi GPS trajectories.
</summary>
    <author>
      <name>Jian Yang</name>
    </author>
    <author>
      <name>Liqiu Meng</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ECML/PKDD14 workshop on Machine Learning for Urban Sensor
  Data(SenseML)</arxiv:comment>
    <link href="http://arxiv.org/abs/1409.0797v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1409.0797v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1409.2655v5</id>
    <updated>2015-09-10T06:57:59Z</updated>
    <published>2014-09-09T09:52:59Z</published>
    <title>Weighted Classification Cascades for Optimizing Discovery Significance
  in the HiggsML Challenge</title>
    <summary>  We introduce a minorization-maximization approach to optimizing common
measures of discovery significance in high energy physics. The approach
alternates between solving a weighted binary classification problem and
updating class weights in a simple, closed-form manner. Moreover, an argument
based on convex duality shows that an improvement in weighted classification
error on any round yields a commensurate improvement in discovery significance.
We complement our derivation with experimental results from the 2014 Higgs
boson machine learning challenge.
</summary>
    <author>
      <name>Lester Mackey</name>
    </author>
    <author>
      <name>Jordan Bryan</name>
    </author>
    <author>
      <name>Man Yue Mo</name>
    </author>
    <link href="http://arxiv.org/abs/1409.2655v5" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1409.2655v5" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1409.2824v2</id>
    <updated>2014-09-10T09:30:37Z</updated>
    <published>2014-09-09T17:42:55Z</published>
    <title>Scalable Bayesian Modelling of Paired Symbols</title>
    <summary>  We present a novel, scalable and Bayesian approach to modelling the
occurrence of pairs of symbols (i,j) drawn from a large vocabulary. Observed
pairs are assumed to be generated by a simple popularity based selection
process followed by censoring using a preference function. By basing inference
on the well-founded principle of variational bounding, and using new
site-independent bounds, we show how a scalable inference procedure can be
obtained for large data sets. State of the art results are presented on
real-world movie viewing data.
</summary>
    <author>
      <name>Ulrich Paquet</name>
    </author>
    <author>
      <name>Noam Koenigstein</name>
    </author>
    <author>
      <name>Ole Winther</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1409.2824v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1409.2824v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1409.4011v1</id>
    <updated>2014-09-14T04:01:37Z</updated>
    <published>2014-09-14T04:01:37Z</published>
    <title>Raiders of the Lost Architecture: Kernels for Bayesian Optimization in
  Conditional Parameter Spaces</title>
    <summary>  In practical Bayesian optimization, we must often search over structures with
differing numbers of parameters. For instance, we may wish to search over
neural network architectures with an unknown number of layers. To relate
performance data gathered for different architectures, we define a new kernel
for conditional parameter spaces that explicitly includes information about
which parameters are relevant in a given structure. We show that this kernel
improves model quality and Bayesian optimization results over several simpler
baseline kernels.
</summary>
    <author>
      <name>Kevin Swersky</name>
    </author>
    <author>
      <name>David Duvenaud</name>
    </author>
    <author>
      <name>Jasper Snoek</name>
    </author>
    <author>
      <name>Frank Hutter</name>
    </author>
    <author>
      <name>Michael A. Osborne</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 3 figures. Appeared in the NIPS 2013 workshop on Bayesian
  optimization</arxiv:comment>
    <link href="http://arxiv.org/abs/1409.4011v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1409.4011v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1409.4044v1</id>
    <updated>2014-09-14T10:25:23Z</updated>
    <published>2014-09-14T10:25:23Z</published>
    <title>A new approach in machine learning</title>
    <summary>  In this technical report we presented a novel approach to machine learning.
Once the new framework is presented, we will provide a simple and yet very
powerful learning algorithm which will be benchmark on various dataset.
  The framework we proposed is based on booleen circuits; more specifically the
classifier produced by our algorithm have that form. Using bits and boolean
gates instead of real numbers and multiplication enable the the learning
algorithm and classifier to use very efficient boolean vector operations. This
enable both the learning algorithm and classifier to be extremely efficient.
The accuracy of the classifier we obtain with our framework compares very
favorably those produced by conventional techniques, both in terms of
efficiency and accuracy.
</summary>
    <author>
      <name>Alain Tapp</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Preliminary report</arxiv:comment>
    <link href="http://arxiv.org/abs/1409.4044v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1409.4044v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1409.6179v1</id>
    <updated>2014-09-22T14:17:15Z</updated>
    <published>2014-09-22T14:17:15Z</published>
    <title>Expectation Propagation</title>
    <summary>  Variational inference is a powerful concept that underlies many iterative
approximation algorithms; expectation propagation, mean-field methods and
belief propagations were all central themes at the school that can be perceived
from this unifying framework. The lectures of Manfred Opper introduce the
archetypal example of Expectation Propagation, before establishing the
connection with the other approximation methods. Corrections by expansion about
the expectation propagation are then explained. Finally some advanced inference
topics and applications are explored in the final sections.
</summary>
    <author>
      <name>Jack Raymond</name>
    </author>
    <author>
      <name>Andre Manoel</name>
    </author>
    <author>
      <name>Manfred Opper</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Chapter of "Statistical Physics, Optimization, Inference, and
  Message-Passing Algorithms", Eds.: F. Krzakala, F. Ricci-Tersenghi, L.
  Zdeborova, R. Zecchina, E. W. Tramel, L. F. Cugliandolo (Oxford University
  Press, to appear)</arxiv:comment>
    <link href="http://arxiv.org/abs/1409.6179v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1409.6179v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1409.7193v2</id>
    <updated>2015-03-19T03:04:20Z</updated>
    <published>2014-09-25T09:28:54Z</published>
    <title>MIST: L0 Sparse Linear Regression with Momentum</title>
    <summary>  Significant attention has been given to minimizing a penalized least squares
criterion for estimating sparse solutions to large linear systems of equations.
The penalty is responsible for inducing sparsity and the natural choice is the
so-called $l_0$ norm. In this paper we develop a Momentumized Iterative
Shrinkage Thresholding (MIST) algorithm for minimizing the resulting non-convex
criterion and prove its convergence to a local minimizer. Simulations on large
data sets show superior performance of the proposed method to other methods.
</summary>
    <author>
      <name>Goran Marjanovic</name>
    </author>
    <author>
      <name>Magnus O. Ulfarsson</name>
    </author>
    <author>
      <name>Alfred O. Hero III</name>
    </author>
    <link href="http://arxiv.org/abs/1409.7193v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1409.7193v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1409.8630v1</id>
    <updated>2014-09-30T17:06:47Z</updated>
    <published>2014-09-30T17:06:47Z</published>
    <title>Unsupervised Bump Hunting Using Principal Components</title>
    <summary>  Principal Components Analysis is a widely used technique for dimension
reduction and characterization of variability in multivariate populations. Our
interest lies in studying when and why the rotation to principal components can
be used effectively within a response-predictor set relationship in the context
of mode hunting. Specifically focusing on the Patient Rule Induction Method
(PRIM), we first develop a fast version of this algorithm (fastPRIM) under
normality which facilitates the theoretical studies to follow. Using basic
geometrical arguments, we then demonstrate how the PC rotation of the predictor
space alone can in fact generate improved mode estimators. Simulation results
are used to illustrate our findings.
</summary>
    <author>
      <name>Daniel A Díaz-Pachón</name>
    </author>
    <author>
      <name>Jean-Eudes Dazard</name>
    </author>
    <author>
      <name>J. Sunil Rao</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">24 pages, 9 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1409.8630v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1409.8630v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65C60" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.0633v3</id>
    <updated>2015-05-24T17:31:55Z</updated>
    <published>2014-10-02T18:20:04Z</published>
    <title>Deterministic Conditions for Subspace Identifiability from Incomplete
  Sampling</title>
    <summary>  Consider a generic $r$-dimensional subspace of $\mathbb{R}^d$, $r&lt;d$, and
suppose that we are only given projections of this subspace onto small subsets
of the canonical coordinates. The paper establishes necessary and sufficient
deterministic conditions on the subsets for subspace identifiability.
</summary>
    <author>
      <name>Daniel L. Pimentel-Alarcón</name>
    </author>
    <author>
      <name>Robert D. Nowak</name>
    </author>
    <author>
      <name>Nigel Boston</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in Proc. of IEEE ISIT, 2015</arxiv:comment>
    <link href="http://arxiv.org/abs/1410.0633v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.0633v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.0870v3</id>
    <updated>2015-06-05T14:55:19Z</updated>
    <published>2014-10-03T14:51:09Z</published>
    <title>BayesPy: Variational Bayesian Inference in Python</title>
    <summary>  BayesPy is an open-source Python software package for performing variational
Bayesian inference. It is based on the variational message passing framework
and supports conjugate exponential family models. By removing the tedious task
of implementing the variational Bayesian update equations, the user can
construct models faster and in a less error-prone way. Simple syntax, flexible
model construction and efficient inference make BayesPy suitable for both
average and expert Bayesian users. It also supports some advanced methods such
as stochastic and collapsed variational inference.
</summary>
    <author>
      <name>Jaakko Luttinen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to Journal of Machine Learning Research - Machine Learning
  Open Source Software</arxiv:comment>
    <link href="http://arxiv.org/abs/1410.0870v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.0870v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.4062v1</id>
    <updated>2014-10-15T13:50:34Z</updated>
    <published>2014-10-15T13:50:34Z</published>
    <title>Complexity Issues and Randomization Strategies in Frank-Wolfe Algorithms
  for Machine Learning</title>
    <summary>  Frank-Wolfe algorithms for convex minimization have recently gained
considerable attention from the Optimization and Machine Learning communities,
as their properties make them a suitable choice in a variety of applications.
However, as each iteration requires to optimize a linear model, a clever
implementation is crucial to make such algorithms viable on large-scale
datasets. For this purpose, approximation strategies based on a random sampling
have been proposed by several researchers. In this work, we perform an
experimental study on the effectiveness of these techniques, analyze possible
alternatives and provide some guidelines based on our results.
</summary>
    <author>
      <name>Emanuele Frandi</name>
    </author>
    <author>
      <name>Ricardo Nanculef</name>
    </author>
    <author>
      <name>Johan Suykens</name>
    </author>
    <link href="http://arxiv.org/abs/1410.4062v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.4062v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.5522v1</id>
    <updated>2014-10-21T02:34:07Z</updated>
    <published>2014-10-21T02:34:07Z</published>
    <title>Variational Reformulation of Bayesian Inverse Problems</title>
    <summary>  The classical approach to inverse problems is based on the optimization of a
misfit function. Despite its computational appeal, such an approach suffers
from many shortcomings, e.g., non-uniqueness of solutions, modeling prior
knowledge, etc. The Bayesian formalism to inverse problems avoids most of the
difficulties encountered by the optimization approach, albeit at an increased
computational cost. In this work, we use information theoretic arguments to
cast the Bayesian inference problem in terms of an optimization problem. The
resulting scheme combines the theoretical soundness of fully Bayesian inference
with the computational efficiency of a simple optimization.
</summary>
    <author>
      <name>Panagiotis Tsilifis</name>
    </author>
    <author>
      <name>Ilias Bilionis</name>
    </author>
    <author>
      <name>Ioannis Katsounaros</name>
    </author>
    <author>
      <name>Nicholas Zabaras</name>
    </author>
    <link href="http://arxiv.org/abs/1410.5522v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.5522v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.6714v2</id>
    <updated>2014-11-17T16:41:28Z</updated>
    <published>2014-10-24T15:50:32Z</published>
    <title>Stochastic Blockmodeling for Online Advertising</title>
    <summary>  Online advertising is an important and huge industry. Having knowledge of the
website attributes can contribute greatly to business strategies for
ad-targeting, content display, inventory purchase or revenue prediction.
Classical inferences on users and sites impose challenge, because the data is
voluminous, sparse, high-dimensional and noisy. In this paper, we introduce a
stochastic blockmodeling for the website relations induced by the event of
online user visitation. We propose two clustering algorithms to discover the
instrinsic structures of websites, and compare the performance with a
goodness-of-fit method and a deterministic graph partitioning method. We
demonstrate the effectiveness of our algorithms on both simulation and AOL
website dataset.
</summary>
    <author>
      <name>Li Chen</name>
    </author>
    <author>
      <name>Matthew Patton</name>
    </author>
    <link href="http://arxiv.org/abs/1410.6714v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.6714v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.6959v2</id>
    <updated>2015-02-11T02:19:56Z</updated>
    <published>2014-10-25T20:52:51Z</published>
    <title>An Aggregation Method for Sparse Logistic Regression</title>
    <summary>  $L_1$ regularized logistic regression has now become a workhorse of data
mining and bioinformatics: it is widely used for many classification problems,
particularly ones with many features. However, $L_1$ regularization typically
selects too many features and that so-called false positives are unavoidable.
In this paper, we demonstrate and analyze an aggregation method for sparse
logistic regression in high dimensions. This approach linearly combines the
estimators from a suitable set of logistic models with different underlying
sparsity patterns and can balance the predictive ability and model
interpretability. Numerical performance of our proposed aggregation method is
then investigated using simulation studies. We also analyze a published
genome-wide case-control dataset to further evaluate the usefulness of the
aggregation method in multilocus association mapping.
</summary>
    <author>
      <name>Zhe Liu</name>
    </author>
    <link href="http://arxiv.org/abs/1410.6959v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.6959v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.7279v1</id>
    <updated>2014-10-27T15:41:23Z</updated>
    <published>2014-10-27T15:41:23Z</published>
    <title>Topology Adaptive Graph Estimation in High Dimensions</title>
    <summary>  We introduce Graphical TREX (GTREX), a novel method for graph estimation in
high-dimensional Gaussian graphical models. By conducting neighborhood
selection with TREX, GTREX avoids tuning parameters and is adaptive to the
graph topology. We compare GTREX with standard methods on a new simulation
set-up that is designed to assess accurately the strengths and shortcomings of
different methods. These simulations show that a neighborhood selection scheme
based on Lasso and an optimal (in practice unknown) tuning parameter
outperforms other standard methods over a large spectrum of scenarios.
Moreover, we show that GTREX can rival this scheme and, therefore, can provide
competitive graph estimation without the need for tuning parameter calibration.
</summary>
    <author>
      <name>Johannes Lederer</name>
    </author>
    <author>
      <name>Christian Müller</name>
    </author>
    <link href="http://arxiv.org/abs/1410.7279v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.7279v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.8372v1</id>
    <updated>2014-10-30T13:37:39Z</updated>
    <published>2014-10-30T13:37:39Z</published>
    <title>On Estimating $L_2^2$ Divergence</title>
    <summary>  We give a comprehensive theoretical characterization of a nonparametric
estimator for the $L_2^2$ divergence between two continuous distributions. We
first bound the rate of convergence of our estimator, showing that it is
$\sqrt{n}$-consistent provided the densities are sufficiently smooth. In this
smooth regime, we then show that our estimator is asymptotically normal,
construct asymptotic confidence intervals, and establish a Berry-Ess\'{e}en
style inequality characterizing the rate of convergence to normality. We also
show that this estimator is minimax optimal.
</summary>
    <author>
      <name>Akshay Krishnamurthy</name>
    </author>
    <author>
      <name>Kirthevasan Kandasamy</name>
    </author>
    <author>
      <name>Barnabas Poczos</name>
    </author>
    <author>
      <name>Larry Wasserman</name>
    </author>
    <link href="http://arxiv.org/abs/1410.8372v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.8372v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1411.0707v1</id>
    <updated>2014-11-03T21:34:24Z</updated>
    <published>2014-11-03T21:34:24Z</published>
    <title>A Nonparametric Adaptive Nonlinear Statistical Filter</title>
    <summary>  We use statistical learning methods to construct an adaptive state estimator
for nonlinear stochastic systems. Optimal state estimation, in the form of a
Kalman filter, requires knowledge of the system's process and measurement
uncertainty. We propose that these uncertainties can be estimated from
(conditioned on) past observed data, and without making any assumptions of the
system's prior distribution. The system's prior distribution at each time step
is constructed from an ensemble of least-squares estimates on sub-sampled sets
of the data via jackknife sampling. As new data is acquired, the state
estimates, process uncertainty, and measurement uncertainty are updated
accordingly, as described in this manuscript.
</summary>
    <author>
      <name>Michael Busch</name>
    </author>
    <author>
      <name>Jeff Moehlis</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at the 2014 IEEE Conference on Decision and Control</arxiv:comment>
    <link href="http://arxiv.org/abs/1411.0707v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1411.0707v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1411.1469v1</id>
    <updated>2014-11-06T01:34:26Z</updated>
    <published>2014-11-06T01:34:26Z</published>
    <title>A Generic Sample Splitting Approach for Refined Community Recovery in
  Stochastic Block Models</title>
    <summary>  We propose and analyze a generic method for community recovery in stochastic
block models and degree corrected block models. This approach can exactly
recover the hidden communities with high probability when the expected node
degrees are of order $\log n$ or higher. Starting from a roughly correct
community partition given by some conventional community recovery algorithm,
this method refines the partition in a cross clustering step. Our results
simplify and extend some of the previous work on exact community recovery,
discovering the key role played by sample splitting. The proposed method is
simple and can be implemented with many practical community recovery
algorithms.
</summary>
    <author>
      <name>Jing Lei</name>
    </author>
    <author>
      <name>Lingxue Zhu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1411.1469v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1411.1469v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1411.1557v1</id>
    <updated>2014-11-06T10:41:32Z</updated>
    <published>2014-11-06T10:41:32Z</published>
    <title>Proof Supplement - Learning Sparse Causal Models is not NP-hard
  (UAI2013)</title>
    <summary>  This article contains detailed proofs and additional examples related to the
UAI-2013 submission `Learning Sparse Causal Models is not NP-hard'. It
describes the FCI+ algorithm: a method for sound and complete causal model
discovery in the presence of latent confounders and/or selection bias, that has
worst case polynomial complexity of order $N^{2(k+1)}$ in the number of
independence tests, for sparse graphs over $N$ nodes, bounded by node degree
$k$. The algorithm is an adaptation of the well-known FCI algorithm by (Spirtes
et al., 2000) that is also sound and complete, but has worst case complexity
exponential in $N$.
</summary>
    <author>
      <name>Tom Claassen</name>
    </author>
    <author>
      <name>Joris M. Mooij</name>
    </author>
    <author>
      <name>Tom Heskes</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, supplement to `Learning Sparse Causal Models is not
  NP-hard' (UAI2013)</arxiv:comment>
    <link href="http://arxiv.org/abs/1411.1557v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1411.1557v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1411.2581v1</id>
    <updated>2014-11-10T20:57:30Z</updated>
    <published>2014-11-10T20:57:30Z</published>
    <title>Deep Exponential Families</title>
    <summary>  We describe \textit{deep exponential families} (DEFs), a class of latent
variable models that are inspired by the hidden structures used in deep neural
networks. DEFs capture a hierarchy of dependencies between latent variables,
and are easily generalized to many settings through exponential families. We
perform inference using recent "black box" variational inference techniques. We
then evaluate various DEFs on text and combine multiple DEFs into a model for
pairwise recommendation data. In an extensive study, we show that going beyond
one layer improves predictions for DEFs. We demonstrate that DEFs find
interesting exploratory structure in large data sets, and give better
predictive performance than state-of-the-art models.
</summary>
    <author>
      <name>Rajesh Ranganath</name>
    </author>
    <author>
      <name>Linpeng Tang</name>
    </author>
    <author>
      <name>Laurent Charlin</name>
    </author>
    <author>
      <name>David M. Blei</name>
    </author>
    <link href="http://arxiv.org/abs/1411.2581v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1411.2581v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1411.4342v3</id>
    <updated>2015-06-19T23:29:07Z</updated>
    <published>2014-11-17T02:04:57Z</published>
    <title>Influence Functions for Machine Learning: Nonparametric Estimators for
  Entropies, Divergences and Mutual Informations</title>
    <summary>  We propose and analyze estimators for statistical functionals of one or more
distributions under nonparametric assumptions. Our estimators are based on the
theory of influence functions, which appear in the semiparametric statistics
literature. We show that estimators based either on data-splitting or a
leave-one-out technique enjoy fast rates of convergence and other favorable
theoretical properties. We apply this framework to derive estimators for
several popular information theoretic quantities, and via empirical evaluation,
show the advantage of this approach over existing estimators.
</summary>
    <author>
      <name>Kirthevasan Kandasamy</name>
    </author>
    <author>
      <name>Akshay Krishnamurthy</name>
    </author>
    <author>
      <name>Barnabas Poczos</name>
    </author>
    <author>
      <name>Larry Wasserman</name>
    </author>
    <author>
      <name>James M. Robins</name>
    </author>
    <link href="http://arxiv.org/abs/1411.4342v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1411.4342v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1411.5010v2</id>
    <updated>2017-05-26T18:43:59Z</updated>
    <published>2014-11-18T20:52:52Z</published>
    <title>Nonnegative Tensor Factorization for Directional Blind Audio Source
  Separation</title>
    <summary>  We augment the nonnegative matrix factorization method for audio source
separation with cues about directionality of sound propagation. This improves
separation quality greatly and removes the need for training data, with only a
twofold increase in run time. This is the first method which can exploit
directional information from microphone arrays much smaller than the wavelength
of sound, working both in simulation and in practice on millimeter-scale
microphone arrays.
</summary>
    <author>
      <name>Noah D. Stein</name>
    </author>
    <link href="http://arxiv.org/abs/1411.5010v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1411.5010v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1411.6520v1</id>
    <updated>2014-11-24T16:40:33Z</updated>
    <published>2014-11-24T16:40:33Z</published>
    <title>Distributed Coordinate Descent for L1-regularized Logistic Regression</title>
    <summary>  Solving logistic regression with L1-regularization in distributed settings is
an important problem. This problem arises when training dataset is very large
and cannot fit the memory of a single machine. We present d-GLMNET, a new
algorithm solving logistic regression with L1-regularization in the distributed
settings. We empirically show that it is superior over distributed online
learning via truncated gradient.
</summary>
    <author>
      <name>Ilya Trofimov</name>
    </author>
    <author>
      <name>Alexander Genkin</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-319-26123-2_24</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-319-26123-2_24" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Analysis of Images, Social Networks and Texts. Fourth
  International Conference, AIST 2015, Yekaterinburg, Russia, April 9-11, 2015,
  Revised Selected Papers. Communications in Computer and Information Science,
  Vol. 542, 243-254, Springer</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1411.6520v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1411.6520v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1411.7200v1</id>
    <updated>2014-11-26T12:14:22Z</updated>
    <published>2014-11-26T12:14:22Z</published>
    <title>Localized Complexities for Transductive Learning</title>
    <summary>  We show two novel concentration inequalities for suprema of empirical
processes when sampling without replacement, which both take the variance of
the functions into account. While these inequalities may potentially have broad
applications in learning theory in general, we exemplify their significance by
studying the transductive setting of learning theory. For which we provide the
first excess risk bounds based on the localized complexity of the hypothesis
class, which can yield fast rates of convergence also in the transductive
learning setting. We give a preliminary analysis of the localized complexities
for the prominent case of kernel classes.
</summary>
    <author>
      <name>Ilya Tolstikhin</name>
    </author>
    <author>
      <name>Gilles Blanchard</name>
    </author>
    <author>
      <name>Marius Kloft</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appeared in Conference on Learning Theory 2014</arxiv:comment>
    <link href="http://arxiv.org/abs/1411.7200v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1411.7200v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1411.7432v1</id>
    <updated>2014-11-27T00:27:05Z</updated>
    <published>2014-11-27T00:27:05Z</published>
    <title>Metrics for Probabilistic Geometries</title>
    <summary>  We investigate the geometrical structure of probabilistic generative
dimensionality reduction models using the tools of Riemannian geometry. We
explicitly define a distribution over the natural metric given by the models.
We provide the necessary algorithms to compute expected metric tensors where
the distribution over mappings is given by a Gaussian process. We treat the
corresponding latent variable model as a Riemannian manifold and we use the
expectation of the metric under the Gaussian process prior to define
interpolating paths and measure distance between latent points. We show how
distances that respect the expected metric lead to more appropriate generation
of new data.
</summary>
    <author>
      <name>Alessandra Tosi</name>
    </author>
    <author>
      <name>Søren Hauberg</name>
    </author>
    <author>
      <name>Alfredo Vellido</name>
    </author>
    <author>
      <name>Neil D. Lawrence</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">UAI 2014</arxiv:comment>
    <link href="http://arxiv.org/abs/1411.7432v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1411.7432v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1411.7610v3</id>
    <updated>2015-03-05T21:55:38Z</updated>
    <published>2014-11-27T14:22:36Z</published>
    <title>Learning Stochastic Recurrent Networks</title>
    <summary>  Leveraging advances in variational inference, we propose to enhance recurrent
neural networks with latent variables, resulting in Stochastic Recurrent
Networks (STORNs). The model i) can be trained with stochastic gradient
methods, ii) allows structured and multi-modal conditionals at each time step,
iii) features a reliable estimator of the marginal likelihood and iv) is a
generalisation of deterministic recurrent neural networks. We evaluate the
method on four polyphonic musical data sets and motion capture data.
</summary>
    <author>
      <name>Justin Bayer</name>
    </author>
    <author>
      <name>Christian Osendorfer</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to conference track of ICLR 2015</arxiv:comment>
    <link href="http://arxiv.org/abs/1411.7610v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1411.7610v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1411.7817v1</id>
    <updated>2014-11-28T11:20:48Z</updated>
    <published>2014-11-28T11:20:48Z</published>
    <title>Learning with Algebraic Invariances, and the Invariant Kernel Trick</title>
    <summary>  When solving data analysis problems it is important to integrate prior
knowledge and/or structural invariances. This paper contributes by a novel
framework for incorporating algebraic invariance structure into kernels. In
particular, we show that algebraic properties such as sign symmetries in data,
phase independence, scaling etc. can be included easily by essentially
performing the kernel trick twice. We demonstrate the usefulness of our theory
in simulations on selected applications such as sign-invariant spectral
clustering and underdetermined ICA.
</summary>
    <author>
      <name>Franz J. Király</name>
    </author>
    <author>
      <name>Andreas Ziehe</name>
    </author>
    <author>
      <name>Klaus-Robert Müller</name>
    </author>
    <link href="http://arxiv.org/abs/1411.7817v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1411.7817v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1411.7924v1</id>
    <updated>2014-11-28T16:06:52Z</updated>
    <published>2014-11-28T16:06:52Z</published>
    <title>Predicting clicks in online display advertising with latent features and
  side-information</title>
    <summary>  We review a method for click-through rate prediction based on the work of
Menon et al. [11], which combines collaborative filtering and matrix
factorization with a side-information model and fuses the outputs to proper
probabilities in [0,1]. In addition we provide details, both for the modeling
as well as the experimental part, that are not found elsewhere. We rigorously
test the performance on several test data sets from consecutive days in a
click-through rate prediction setup, in a manner which reflects a real-world
pipeline. Our results confirm that performance can be increased using latent
features, albeit the differences in the measures are small but significant.
</summary>
    <author>
      <name>Bjarne Ørum Fruergaard</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Technical Report</arxiv:comment>
    <link href="http://arxiv.org/abs/1411.7924v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1411.7924v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.1370v1</id>
    <updated>2014-12-03T15:39:55Z</updated>
    <published>2014-12-03T15:39:55Z</published>
    <title>Nested Variational Compression in Deep Gaussian Processes</title>
    <summary>  Deep Gaussian processes provide a flexible approach to probabilistic
modelling of data using either supervised or unsupervised learning. For
tractable inference approximations to the marginal likelihood of the model must
be made. The original approach to approximate inference in these models used
variational compression to allow for approximate variational marginalization of
the hidden variables leading to a lower bound on the marginal likelihood of the
model [Damianou and Lawrence, 2013]. In this paper we extend this idea with a
nested variational compression. The resulting lower bound on the likelihood can
be easily parallelized or adapted for stochastic variational inference.
</summary>
    <author>
      <name>James Hensman</name>
    </author>
    <author>
      <name>Neil D. Lawrence</name>
    </author>
    <link href="http://arxiv.org/abs/1412.1370v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.1370v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.1927v1</id>
    <updated>2014-12-05T09:18:31Z</updated>
    <published>2014-12-05T09:18:31Z</published>
    <title>Quantile universal threshold: model selection at the detection edge for
  high-dimensional linear regression</title>
    <summary>  To estimate a sparse linear model from data with Gaussian noise, consilience
from lasso and compressed sensing literatures is that thresholding estimators
like lasso and the Dantzig selector have the ability in some situations to
identify with high probability part of the significant covariates
asymptotically, and are numerically tractable thanks to convexity.
  Yet, the selection of a threshold parameter $\lambda$ remains crucial in
practice. To that aim we propose Quantile Universal Thresholding, a selection
of $\lambda$ at the detection edge. We show with extensive simulations and real
data that an excellent compromise between high true positive rate and low false
discovery rate is achieved, leading also to good predictive risk.
</summary>
    <author>
      <name>Jairo Diaz-Rodriguez</name>
    </author>
    <author>
      <name>Sylvain Sardy</name>
    </author>
    <link href="http://arxiv.org/abs/1412.1927v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.1927v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.2669v2</id>
    <updated>2015-06-02T18:39:18Z</updated>
    <published>2014-12-05T18:19:31Z</published>
    <title>Two step recovery of jointly sparse and low-rank matrices: theoretical
  guarantees</title>
    <summary>  We introduce a two step algorithm with theoretical guarantees to recover a
jointly sparse and low-rank matrix from undersampled measurements of its
columns. The algorithm first estimates the row subspace of the matrix using a
set of common measurements of the columns. In the second step, the subspace
aware recovery of the matrix is solved using a simple least square algorithm.
The results are verified in the context of recovering CINE data from
undersampled measurements; we obtain good recovery when the sampling conditions
are satisfied.
</summary>
    <author>
      <name>Sampurna Biswas</name>
    </author>
    <author>
      <name>Sunrita Poddar</name>
    </author>
    <author>
      <name>Soura Dasgupta</name>
    </author>
    <author>
      <name>Raghuraman Mudumbai</name>
    </author>
    <author>
      <name>Mathews Jacob</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 4 figures, ISBI 2015 conference submission</arxiv:comment>
    <link href="http://arxiv.org/abs/1412.2669v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.2669v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.3078v1</id>
    <updated>2014-12-09T20:03:06Z</updated>
    <published>2014-12-09T20:03:06Z</published>
    <title>Hierarchical Mixture-of-Experts Model for Large-Scale Gaussian Process
  Regression</title>
    <summary>  We propose a practical and scalable Gaussian process model for large-scale
nonlinear probabilistic regression. Our mixture-of-experts model is
conceptually simple and hierarchically recombines computations for an overall
approximation of a full Gaussian process. Closed-form and distributed
computations allow for efficient and massive parallelisation while keeping the
memory consumption small. Given sufficient computing resources, our model can
handle arbitrarily large data sets, without explicit sparse approximations. We
provide strong experimental evidence that our model can be applied to large
data sets of sizes far beyond millions. Hence, our model has the potential to
lay the foundation for general large-scale Gaussian process research.
</summary>
    <author>
      <name>Jun Wei Ng</name>
    </author>
    <author>
      <name>Marc Peter Deisenroth</name>
    </author>
    <link href="http://arxiv.org/abs/1412.3078v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.3078v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.5158v1</id>
    <updated>2014-12-16T20:36:26Z</updated>
    <published>2014-12-16T20:36:26Z</published>
    <title>Testing and Confidence Intervals for High Dimensional Proportional
  Hazards Model</title>
    <summary>  This paper proposes a decorrelation-based approach to test hypotheses and
construct confidence intervals for the low dimensional component of high
dimensional proportional hazards models. Motivated by the geometric projection
principle, we propose new decorrelated score, Wald and partial likelihood ratio
statistics. Without assuming model selection consistency, we prove the
asymptotic normality of these test statistics, establish their semiparametric
optimality. We also develop new procedures for constructing pointwise
confidence intervals for the baseline hazard function and baseline survival
function. Thorough numerical results are provided to back up our theory.
</summary>
    <author>
      <name>Ethan X. Fang</name>
    </author>
    <author>
      <name>Yang Ning</name>
    </author>
    <author>
      <name>Han Liu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">42 pages, 4 figures, 5 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1412.5158v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.5158v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.6785v2</id>
    <updated>2015-03-11T16:18:47Z</updated>
    <published>2014-12-21T13:40:29Z</published>
    <title>Principal Sensitivity Analysis</title>
    <summary>  We present a novel algorithm (Principal Sensitivity Analysis; PSA) to analyze
the knowledge of the classifier obtained from supervised machine learning
techniques. In particular, we define principal sensitivity map (PSM) as the
direction on the input space to which the trained classifier is most sensitive,
and use analogously defined k-th PSM to define a basis for the input space. We
train neural networks with artificial data and real data, and apply the
algorithm to the obtained supervised classifiers. We then visualize the PSMs to
demonstrate the PSA's ability to decompose the knowledge acquired by the
trained classifiers.
</summary>
    <author>
      <name>Sotetsu Koyamada</name>
    </author>
    <author>
      <name>Masanori Koyama</name>
    </author>
    <author>
      <name>Ken Nakae</name>
    </author>
    <author>
      <name>Shin Ishii</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-319-18038-0_48</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-319-18038-0_48" rel="related"/>
    <link href="http://arxiv.org/abs/1412.6785v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.6785v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.7983v2</id>
    <updated>2015-01-09T23:54:38Z</updated>
    <published>2014-12-26T20:01:21Z</published>
    <title>Exploring Sparsity in Multi-class Linear Discriminant Analysis</title>
    <summary>  Recent studies in the literature have paid much attention to the sparsity in
linear classification tasks. One motivation of imposing sparsity assumption on
the linear discriminant direction is to rule out the noninformative features,
making hardly contribution to the classification problem. Most of those work
were focused on the scenarios of binary classification. In the presence of
multi-class data, preceding researches recommended individually pairwise sparse
linear discriminant analysis(LDA). However, further sparsity should be
explored. In this paper, an estimator of grouped LASSO type is proposed to take
advantage of sparsity for multi-class data. It enjoys appealing non-asymptotic
properties which allows insignificant correlations among features. This
estimator exhibits superior capability on both simulated and real data.
</summary>
    <author>
      <name>Dong Xia</name>
    </author>
    <link href="http://arxiv.org/abs/1412.7983v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.7983v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.5.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1501.00375v1</id>
    <updated>2015-01-02T10:00:07Z</updated>
    <published>2015-01-02T10:00:07Z</published>
    <title>Passing Expectation Propagation Messages with Kernel Methods</title>
    <summary>  We propose to learn a kernel-based message operator which takes as input all
expectation propagation (EP) incoming messages to a factor node and produces an
outgoing message. In ordinary EP, computing an outgoing message involves
estimating a multivariate integral which may not have an analytic expression.
Learning such an operator allows one to bypass the expensive computation of the
integral during inference by directly mapping all incoming messages into an
outgoing message. The operator can be learned from training data (examples of
input and output messages) which allows automated inference to be made on any
kind of factor that can be sampled.
</summary>
    <author>
      <name>Wittawat Jitkrittum</name>
    </author>
    <author>
      <name>Arthur Gretton</name>
    </author>
    <author>
      <name>Nicolas Heess</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to Advances in Variational Inference, NIPS 2014 Workshop</arxiv:comment>
    <link href="http://arxiv.org/abs/1501.00375v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1501.00375v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1501.02102v2</id>
    <updated>2016-03-25T04:42:28Z</updated>
    <published>2015-01-09T10:53:02Z</published>
    <title>Equitability of Dependence Measure</title>
    <summary>  A measure of dependence is said to be equitable if it gives similar scores to
equally noisy relationship of different types. In practice, we do not know what
kind of functional relationship is underlying two given observations, Hence the
equitability of dependence measure is critical in analysis and by scoring
relationships according to an equitable measure one hopes to find important
patterns of any type of further examination. In this paper, we introduce our
definition of equitability of a dependence measure, which is naturally from
this initial description, and Further more power-equitable(weak-equitable) is
introduced which is of the most practical meaning in evaluating the equitablity
of a dependence measure.
</summary>
    <author>
      <name>Hangjin Jiang</name>
    </author>
    <author>
      <name>Kan Liu</name>
    </author>
    <author>
      <name>Yiming Ding</name>
    </author>
    <link href="http://arxiv.org/abs/1501.02102v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1501.02102v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1501.03001v1</id>
    <updated>2015-01-13T13:47:03Z</updated>
    <published>2015-01-13T13:47:03Z</published>
    <title>On Generalizing the C-Bound to the Multiclass and Multi-label Settings</title>
    <summary>  The C-bound, introduced in Lacasse et al., gives a tight upper bound on the
risk of a binary majority vote classifier. In this work, we present a first
step towards extending this work to more complex outputs, by providing
generalizations of the C-bound to the multiclass and multi-label settings.
</summary>
    <author>
      <name>Francois Laviolette</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LHC</arxiv:affiliation>
    </author>
    <author>
      <name>Emilie Morvant</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LHC</arxiv:affiliation>
    </author>
    <author>
      <name>Liva Ralaivola</name>
    </author>
    <author>
      <name>Jean-Francis Roy</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">NIPS 2014 Workshop on Representation and Learning Methods for Complex
  Outputs, Dec 2014, Montr{\'e}al, Canada</arxiv:comment>
    <link href="http://arxiv.org/abs/1501.03001v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1501.03001v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1501.03002v1</id>
    <updated>2015-01-13T13:50:58Z</updated>
    <published>2015-01-13T13:50:58Z</published>
    <title>An Improvement to the Domain Adaptation Bound in a PAC-Bayesian context</title>
    <summary>  This paper provides a theoretical analysis of domain adaptation based on the
PAC-Bayesian theory. We propose an improvement of the previous domain
adaptation bound obtained by Germain et al. in two ways. We first give another
generalization bound tighter and easier to interpret. Moreover, we provide a
new analysis of the constant term appearing in the bound that can be of high
interest for developing new algorithmic solutions.
</summary>
    <author>
      <name>Pascal Germain</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LHC</arxiv:affiliation>
    </author>
    <author>
      <name>Amaury Habrard</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LHC</arxiv:affiliation>
    </author>
    <author>
      <name>Francois Laviolette</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LHC</arxiv:affiliation>
    </author>
    <author>
      <name>Emilie Morvant</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LHC</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">NIPS 2014 Workshop on Transfer and Multi-task learning: Theory Meets
  Practice, Dec 2014, Montr{\'e}al, Canada</arxiv:comment>
    <link href="http://arxiv.org/abs/1501.03002v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1501.03002v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1501.03861v1</id>
    <updated>2015-01-16T01:59:34Z</updated>
    <published>2015-01-16T01:59:34Z</published>
    <title>Bayesian Nonparametrics in Topic Modeling: A Brief Tutorial</title>
    <summary>  Using nonparametric methods has been increasingly explored in Bayesian
hierarchical modeling as a way to increase model flexibility. Although the
field shows a lot of promise, inference in many models, including Hierachical
Dirichlet Processes (HDP), remain prohibitively slow. One promising path
forward is to exploit the submodularity inherent in Indian Buffet Process (IBP)
to derive near-optimal solutions in polynomial time. In this work, I will
present a brief tutorial on Bayesian nonparametric methods, especially as they
are applied to topic modeling. I will show a comparison between different
non-parametric models and the current state-of-the-art parametric model, Latent
Dirichlet Allocation (LDA).
</summary>
    <author>
      <name>Alexander Spangher</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, unpublished</arxiv:comment>
    <link href="http://arxiv.org/abs/1501.03861v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1501.03861v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1501.04467v1</id>
    <updated>2015-01-19T12:13:44Z</updated>
    <published>2015-01-19T12:13:44Z</published>
    <title>Implementable confidence sets in high dimensional regression</title>
    <summary>  We consider the setting of linear regression in high dimension. We focus on
the problem of constructing adaptive and honest confidence sets for the sparse
parameter \theta, i.e. we want to construct a confidence set for theta that
contains theta with high probability, and that is as small as possible. The l_2
diameter of a such confidence set should depend on the sparsity S of \theta -
the larger S, the wider the confidence set. However, in practice, S is unknown.
This paper focuses on constructing a confidence set for \theta which contains
\theta with high probability, whose diameter is adaptive to the unknown
sparsity S, and which is implementable in practice.
</summary>
    <author>
      <name>Alexandra Carpentier</name>
    </author>
    <link href="http://arxiv.org/abs/1501.04467v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1501.04467v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1501.05740v1</id>
    <updated>2015-01-23T08:52:35Z</updated>
    <published>2015-01-23T08:52:35Z</published>
    <title>Bayesian Learning for Low-Rank matrix reconstruction</title>
    <summary>  We develop latent variable models for Bayesian learning based low-rank matrix
completion and reconstruction from linear measurements. For under-determined
systems, the developed methods are shown to reconstruct low-rank matrices when
neither the rank nor the noise power is known a-priori. We derive relations
between the latent variable models and several low-rank promoting penalty
functions. The relations justify the use of Kronecker structured covariance
matrices in a Gaussian based prior. In the methods, we use evidence
approximation and expectation-maximization to learn the model parameters. The
performance of the methods is evaluated through extensive numerical
simulations.
</summary>
    <author>
      <name>Martin Sundin</name>
    </author>
    <author>
      <name>Cristian R. Rojas</name>
    </author>
    <author>
      <name>Magnus Jansson</name>
    </author>
    <author>
      <name>Saikat Chatterjee</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to IEEE Transactions on Signal Processing</arxiv:comment>
    <link href="http://arxiv.org/abs/1501.05740v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1501.05740v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1501.06060v1</id>
    <updated>2015-01-24T16:41:55Z</updated>
    <published>2015-01-24T16:41:55Z</published>
    <title>Consistency Analysis of Nearest Subspace Classifier</title>
    <summary>  The Nearest subspace classifier (NSS) finds an estimation of the underlying
subspace within each class and assigns data points to the class that
corresponds to its nearest subspace. This paper mainly studies how well NSS can
be generalized to new samples. It is proved that NSS is strongly consistent
under certain assumptions. For completeness, NSS is evaluated through
experiments on various simulated and real data sets, in comparison with some
other linear model based classifiers. It is also shown that NSS can obtain
effective classification results and is very efficient, especially for large
scale data sets.
</summary>
    <author>
      <name>Yi Wang</name>
    </author>
    <link href="http://arxiv.org/abs/1501.06060v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1501.06060v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1501.06066v1</id>
    <updated>2015-01-24T17:34:36Z</updated>
    <published>2015-01-24T17:34:36Z</published>
    <title>Sparse Distance Weighted Discrimination</title>
    <summary>  Distance weighted discrimination (DWD) was originally proposed to handle the
data piling issue in the support vector machine. In this paper, we consider the
sparse penalized DWD for high-dimensional classification. The state-of-the-art
algorithm for solving the standard DWD is based on second-order cone
programming, however such an algorithm does not work well for the sparse
penalized DWD with high-dimensional data. In order to overcome the challenging
computation difficulty, we develop a very efficient algorithm to compute the
solution path of the sparse DWD at a given fine grid of regularization
parameters. We implement the algorithm in a publicly available R package sdwd.
We conduct extensive numerical experiments to demonstrate the computational
efficiency and classification performance of our method.
</summary>
    <author>
      <name>Boxiang Wang</name>
    </author>
    <author>
      <name>Hui Zou</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1501.06066v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1501.06066v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1501.06794v1</id>
    <updated>2015-01-27T15:36:22Z</updated>
    <published>2015-01-27T15:36:22Z</published>
    <title>Computing Functions of Random Variables via Reproducing Kernel Hilbert
  Space Representations</title>
    <summary>  We describe a method to perform functional operations on probability
distributions of random variables. The method uses reproducing kernel Hilbert
space representations of probability distributions, and it is applicable to all
operations which can be applied to points drawn from the respective
distributions. We refer to our approach as {\em kernel probabilistic
programming}. We illustrate it on synthetic data, and show how it can be used
for nonparametric structural equation models, with an application to causal
inference.
</summary>
    <author>
      <name>Bernhard Schölkopf</name>
    </author>
    <author>
      <name>Krikamol Muandet</name>
    </author>
    <author>
      <name>Kenji Fukumizu</name>
    </author>
    <author>
      <name>Jonas Peters</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Statistics and Computing 25:755-766 (2015)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1501.06794v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1501.06794v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.3; I.2.6; D.3.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1501.06929v1</id>
    <updated>2015-01-27T21:23:22Z</updated>
    <published>2015-01-27T21:23:22Z</published>
    <title>A Probabilistic Least-Mean-Squares Filter</title>
    <summary>  We introduce a probabilistic approach to the LMS filter. By means of an
efficient approximation, this approach provides an adaptable step-size LMS
algorithm together with a measure of uncertainty about the estimation. In
addition, the proposed approximation preserves the linear complexity of the
standard LMS. Numerical results show the improved performance of the algorithm
with respect to standard LMS and state-of-the-art algorithms with similar
complexity. The goal of this work, therefore, is to open the door to bring some
more Bayesian machine learning techniques to adaptive filtering.
</summary>
    <author>
      <name>Jesus Fernandez-Bes</name>
    </author>
    <author>
      <name>Víctor Elvira</name>
    </author>
    <author>
      <name>Steven Van Vaerenbergh</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/ICASSP.2015.7178361</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/ICASSP.2015.7178361" rel="related"/>
    <link href="http://arxiv.org/abs/1501.06929v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1501.06929v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.01943v1</id>
    <updated>2015-02-06T16:40:06Z</updated>
    <published>2015-02-06T16:40:06Z</published>
    <title>Active Function Cross-Entropy Clustering</title>
    <summary>  Gaussian Mixture Models (GMM) have found many applications in density
estimation and data clustering. However, the model does not adapt well to
curved and strongly nonlinear data. Recently there appeared an improvement
called AcaGMM (Active curve axis Gaussian Mixture Model), which fits Gaussians
along curves using an EM-like (Expectation Maximization) approach.
  Using the ideas standing behind AcaGMM, we build an alternative active
function model of clustering, which has some advantages over AcaGMM. In
particular it is naturally defined in arbitrary dimensions and enables an easy
adaptation to clustering of complicated datasets along the predefined family of
functions. Moreover, it does not need external methods to determine the number
of clusters as it automatically reduces the number of groups on-line.
</summary>
    <author>
      <name>P. Spurek</name>
    </author>
    <author>
      <name>J. Tabor</name>
    </author>
    <author>
      <name>P. Markowicz</name>
    </author>
    <link href="http://arxiv.org/abs/1502.01943v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.01943v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.03255v1</id>
    <updated>2015-02-11T10:42:40Z</updated>
    <published>2015-02-11T10:42:40Z</published>
    <title>Off-policy evaluation for MDPs with unknown structure</title>
    <summary>  Off-policy learning in dynamic decision problems is essential for providing
strong evidence that a new policy is better than the one in use. But how can we
prove superiority without testing the new policy? To answer this question, we
introduce the G-SCOPE algorithm that evaluates a new policy based on data
generated by the existing policy. Our algorithm is both computationally and
sample efficient because it greedily learns to exploit factored structure in
the dynamics of the environment. We present a finite sample analysis of our
approach and show through experiments that the algorithm scales well on
high-dimensional problems with few samples.
</summary>
    <author>
      <name>Assaf Hallak</name>
    </author>
    <author>
      <name>François Schnitzler</name>
    </author>
    <author>
      <name>Timothy Mann</name>
    </author>
    <author>
      <name>Shie Mannor</name>
    </author>
    <link href="http://arxiv.org/abs/1502.03255v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.03255v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.03466v1</id>
    <updated>2015-02-11T21:56:13Z</updated>
    <published>2015-02-11T21:56:13Z</published>
    <title>Dependent Matérn Processes for Multivariate Time Series</title>
    <summary>  For the challenging task of modeling multivariate time series, we propose a
new class of models that use dependent Mat\'ern processes to capture the
underlying structure of data, explain their interdependencies, and predict
their unknown values. Although similar models have been proposed in the
econometric, statistics, and machine learning literature, our approach has
several advantages that distinguish it from existing methods: 1) it is flexible
to provide high prediction accuracy, yet its complexity is controlled to avoid
overfitting; 2) its interpretability separates it from black-box methods; 3)
finally, its computational efficiency makes it scalable for high-dimensional
time series. In this paper, we use several simulated and real data sets to
illustrate these advantages. We will also briefly discuss some extensions of
our model.
</summary>
    <author>
      <name>Alexander Vandenberg-Rodes</name>
    </author>
    <author>
      <name>Babak Shahbaba</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1502.03466v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.03466v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.03491v1</id>
    <updated>2015-02-11T23:44:02Z</updated>
    <published>2015-02-11T23:44:02Z</published>
    <title>How to show a probabilistic model is better</title>
    <summary>  We present a simple theoretical framework, and corresponding practical
procedures, for comparing probabilistic models on real data in a traditional
machine learning setting. This framework is based on the theory of proper
scoring rules, but requires only basic algebra and probability theory to
understand and verify. The theoretical concepts presented are well-studied,
primarily in the statistics literature. The goal of this paper is to advocate
their wider adoption for performance evaluation in empirical machine learning.
</summary>
    <author>
      <name>Mithun Chakraborty</name>
    </author>
    <author>
      <name>Sanmay Das</name>
    </author>
    <author>
      <name>Allen Lavoie</name>
    </author>
    <link href="http://arxiv.org/abs/1502.03491v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.03491v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.03492v3</id>
    <updated>2015-04-02T17:40:44Z</updated>
    <published>2015-02-11T23:52:36Z</published>
    <title>Gradient-based Hyperparameter Optimization through Reversible Learning</title>
    <summary>  Tuning hyperparameters of learning algorithms is hard because gradients are
usually unavailable. We compute exact gradients of cross-validation performance
with respect to all hyperparameters by chaining derivatives backwards through
the entire training procedure. These gradients allow us to optimize thousands
of hyperparameters, including step-size and momentum schedules, weight
initialization distributions, richly parameterized regularization schemes, and
neural network architectures. We compute hyperparameter gradients by exactly
reversing the dynamics of stochastic gradient descent with momentum.
</summary>
    <author>
      <name>Dougal Maclaurin</name>
    </author>
    <author>
      <name>David Duvenaud</name>
    </author>
    <author>
      <name>Ryan P. Adams</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 figures. Submitted to ICML</arxiv:comment>
    <link href="http://arxiv.org/abs/1502.03492v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.03492v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.04502v1</id>
    <updated>2015-02-16T11:50:42Z</updated>
    <published>2015-02-16T11:50:42Z</published>
    <title>Clustering by Descending to the Nearest Neighbor in the Delaunay Graph
  Space</title>
    <summary>  In our previous works, we proposed a physically-inspired rule to organize the
data points into an in-tree (IT) structure, in which some undesired edges are
allowed to occur. By removing those undesired or redundant edges, this IT
structure is divided into several separate parts, each representing one
cluster. In this work, we seek to prevent the undesired edges from arising at
the source. Before using the physically-inspired rule, data points are at first
organized into a proximity graph which restricts each point to select the
optimal directed neighbor just among its neighbors. Consequently, separated
in-trees or clusters automatically arise, without redundant edges requiring to
be removed.
</summary>
    <author>
      <name>Teng Qiu</name>
    </author>
    <author>
      <name>Yongjie Li</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1502.04502v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.04502v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.05313v2</id>
    <updated>2015-03-27T15:02:25Z</updated>
    <published>2015-02-18T17:45:44Z</published>
    <title>Variational Optimization of Annealing Schedules</title>
    <summary>  Annealed importance sampling (AIS) is a common algorithm to estimate
partition functions of useful stochastic models. One important problem for
obtaining accurate AIS estimates is the selection of an annealing schedule.
Conventionally, an annealing schedule is often determined heuristically or is
simply set as a linearly increasing sequence. In this paper, we propose an
algorithm for the optimal schedule by deriving a functional that dominates the
AIS estimation error and by numerically minimizing this functional. We
experimentally demonstrate that the proposed algorithm mostly outperforms
conventional scheduling schemes with large quantization numbers.
</summary>
    <author>
      <name>Taichi Kiwaki</name>
    </author>
    <link href="http://arxiv.org/abs/1502.05313v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.05313v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.00214v2</id>
    <updated>2016-08-23T20:56:46Z</updated>
    <published>2015-03-01T04:24:42Z</published>
    <title>Matrix Completion with Noisy Entries and Outliers</title>
    <summary>  This paper considers the problem of matrix completion when the observed
entries are noisy and contain outliers. It begins with introducing a new
optimization criterion for which the recovered matrix is defined as its
solution. This criterion uses the celebrated Huber function from the robust
statistics literature to downweigh the effects of outliers. A practical
algorithm is developed to solve the optimization involved. This algorithm is
fast, straightforward to implement, and monotonic convergent. Furthermore, the
proposed methodology is theoretically shown to be stable in a well defined
sense. Its promising empirical performance is demonstrated via a sequence of
simulation experiments, including image inpainting.
</summary>
    <author>
      <name>Raymond K. W. Wong</name>
    </author>
    <author>
      <name>Thomas C. M. Lee</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">32 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1503.00214v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.00214v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.01494v1</id>
    <updated>2015-03-04T22:53:41Z</updated>
    <published>2015-03-04T22:53:41Z</published>
    <title>Local Expectation Gradients for Doubly Stochastic Variational Inference</title>
    <summary>  We introduce local expectation gradients which is a general purpose
stochastic variational inference algorithm for constructing stochastic
gradients through sampling from the variational distribution. This algorithm
divides the problem of estimating the stochastic gradients over multiple
variational parameters into smaller sub-tasks so that each sub-task exploits
intelligently the information coming from the most relevant part of the
variational distribution. This is achieved by performing an exact expectation
over the single random variable that mostly correlates with the variational
parameter of interest resulting in a Rao-Blackwellized estimate that has low
variance and can work efficiently for both continuous and discrete random
variables. Furthermore, the proposed algorithm has interesting similarities
with Gibbs sampling but at the same time, unlike Gibbs sampling, it can be
trivially parallelized.
</summary>
    <author>
      <name>Michalis K. Titsias</name>
    </author>
    <link href="http://arxiv.org/abs/1503.01494v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.01494v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.02533v2</id>
    <updated>2015-08-24T21:47:10Z</updated>
    <published>2015-03-09T15:49:21Z</published>
    <title>A Smoothed Dual Approach for Variational Wasserstein Problems</title>
    <summary>  Variational problems that involve Wasserstein distances have been recently
proposed to summarize and learn from probability measures. Despite being
conceptually simple, such problems are computationally challenging because they
involve minimizing over quantities (Wasserstein distances) that are themselves
hard to compute. We show that the dual formulation of Wasserstein variational
problems introduced recently by Carlier et al. (2014) can be regularized using
an entropic smoothing, which leads to smooth, differentiable, convex
optimization problems that are simpler to implement and numerically more
stable. We illustrate the versatility of this approach by applying it to the
computation of Wasserstein barycenters and gradient flows of spacial
regularization functionals.
</summary>
    <author>
      <name>Marco Cuturi</name>
    </author>
    <author>
      <name>Gabriel Peyré</name>
    </author>
    <link href="http://arxiv.org/abs/1503.02533v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.02533v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.02698v2</id>
    <updated>2016-07-03T00:55:28Z</updated>
    <published>2015-03-09T21:10:48Z</published>
    <title>Graphical Exponential Screening</title>
    <summary>  In high dimensions we propose and analyze an aggregation estimator of the
precision matrix for Gaussian graphical models. This estimator, called
graphical Exponential Screening (gES), linearly combines a suitable set of
individual estimators with different underlying graphs, and balances the
estimation error and sparsity. We study the risk of this aggregation estimator
and show that it is comparable to that of the best estimator based on a single
graph, chosen by an oracle. Numerical performance of our method is investigated
using both simulated and real datasets, in comparison with some state-of-art
estimation procedures.
</summary>
    <author>
      <name>Zhe Liu</name>
    </author>
    <link href="http://arxiv.org/abs/1503.02698v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.02698v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.03132v1</id>
    <updated>2015-03-11T00:21:51Z</updated>
    <published>2015-03-11T00:21:51Z</published>
    <title>L_1-regularized Boltzmann machine learning using majorizer minimization</title>
    <summary>  We propose an inference method to estimate sparse interactions and biases
according to Boltzmann machine learning. The basis of this method is $L_1$
regularization, which is often used in compressed sensing, a technique for
reconstructing sparse input signals from undersampled outputs. $L_1$
regularization impedes the simple application of the gradient method, which
optimizes the cost function that leads to accurate estimations, owing to the
cost function's lack of smoothness. In this study, we utilize the majorizer
minimization method, which is a well-known technique implemented in
optimization problems, to avoid the non-smoothness of the cost function. By
using the majorizer minimization method, we elucidate essentially relevant
biases and interactions from given data with seemingly strongly-correlated
components.
</summary>
    <author>
      <name>Masayuki Ohzeki</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.7566/JPSJ.84.054801</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.7566/JPSJ.84.054801" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1503.03132v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.03132v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.04337v3</id>
    <updated>2015-08-11T17:16:01Z</updated>
    <published>2015-03-14T19:43:30Z</published>
    <title>Communication-efficient sparse regression: a one-shot approach</title>
    <summary>  We devise a one-shot approach to distributed sparse regression in the
high-dimensional setting. The key idea is to average "debiased" or
"desparsified" lasso estimators. We show the approach converges at the same
rate as the lasso as long as the dataset is not split across too many machines.
We also extend the approach to generalized linear models.
</summary>
    <author>
      <name>Jason D. Lee</name>
    </author>
    <author>
      <name>Yuekai Sun</name>
    </author>
    <author>
      <name>Qiang Liu</name>
    </author>
    <author>
      <name>Jonathan E. Taylor</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">29 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1503.04337v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.04337v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.06134v2</id>
    <updated>2015-12-01T01:23:45Z</updated>
    <published>2015-03-20T16:08:56Z</published>
    <title>A Bennett Inequality for the Missing Mass</title>
    <summary>  Novel concentration inequalities are obtained for the missing mass, i.e. the
total probability mass of the outcomes not observed in the sample. We derive
distribution-free deviation bounds with sublinear exponents in deviation size
for missing mass and improve the results of Berend and Kontorovich (2013) and
Yari Saeed Khanloo and Haffari (2015) for small deviations which is the most
important case in learning theory.
</summary>
    <author>
      <name>Bahman Yari Saeed Khanloo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">It is not possible to derive a Bennett inequality using this approach</arxiv:comment>
    <link href="http://arxiv.org/abs/1503.06134v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.06134v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.08985v2</id>
    <updated>2015-04-01T08:39:47Z</updated>
    <published>2015-03-31T09:49:30Z</published>
    <title>Iterative Regularization for Learning with Convex Loss Functions</title>
    <summary>  We consider the problem of supervised learning with convex loss functions and
propose a new form of iterative regularization based on the subgradient method.
Unlike other regularization approaches, in iterative regularization no
constraint or penalization is considered, and generalization is achieved by
(early) stopping an empirical iteration. We consider a nonparametric setting,
in the framework of reproducing kernel Hilbert spaces, and prove finite sample
bounds on the excess risk under general regularity conditions. Our study
provides a new class of efficient regularized learning algorithms and gives
insights on the interplay between statistics and optimization in machine
learning.
</summary>
    <author>
      <name>Junhong Lin</name>
    </author>
    <author>
      <name>Lorenzo Rosasco</name>
    </author>
    <author>
      <name>Ding-Xuan Zhou</name>
    </author>
    <link href="http://arxiv.org/abs/1503.08985v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.08985v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.00064v1</id>
    <updated>2015-03-31T23:27:03Z</updated>
    <published>2015-03-31T23:27:03Z</published>
    <title>Crowdsourcing Feature Discovery via Adaptively Chosen Comparisons</title>
    <summary>  We introduce an unsupervised approach to efficiently discover the underlying
features in a data set via crowdsourcing. Our queries ask crowd members to
articulate a feature common to two out of three displayed examples. In addition
we also ask the crowd to provide binary labels to the remaining examples based
on the discovered features. The triples are chosen adaptively based on the
labels of the previously discovered features on the data set. In two natural
models of features, hierarchical and independent, we show that a simple
adaptive algorithm, using "two-out-of-three" similarity queries, recovers all
features with less labor than any nonadaptive algorithm. Experimental results
validate the theoretical findings.
</summary>
    <author>
      <name>James Y. Zou</name>
    </author>
    <author>
      <name>Kamalika Chaudhuri</name>
    </author>
    <author>
      <name>Adam Tauman Kalai</name>
    </author>
    <link href="http://arxiv.org/abs/1504.00064v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.00064v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.00083v1</id>
    <updated>2015-04-01T02:31:55Z</updated>
    <published>2015-04-01T02:31:55Z</published>
    <title>A Theory of Feature Learning</title>
    <summary>  Feature Learning aims to extract relevant information contained in data sets
in an automated fashion. It is driving force behind the current deep learning
trend, a set of methods that have had widespread empirical success. What is
lacking is a theoretical understanding of different feature learning schemes.
This work provides a theoretical framework for feature learning and then
characterizes when features can be learnt in an unsupervised fashion. We also
provide means to judge the quality of features via rate-distortion theory and
its generalizations.
</summary>
    <author>
      <name>Brendan van Rooyen</name>
    </author>
    <author>
      <name>Robert C. Williamson</name>
    </author>
    <link href="http://arxiv.org/abs/1504.00083v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.00083v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.04054v1</id>
    <updated>2015-04-15T21:31:58Z</updated>
    <published>2015-04-15T21:31:58Z</published>
    <title>A Generative Model for Deep Convolutional Learning</title>
    <summary>  A generative model is developed for deep (multi-layered) convolutional
dictionary learning. A novel probabilistic pooling operation is integrated into
the deep model, yielding efficient bottom-up (pretraining) and top-down
(refinement) probabilistic learning. Experimental results demonstrate powerful
capabilities of the model to learn multi-layer features from images, and
excellent classification results are obtained on the MNIST and Caltech 101
datasets.
</summary>
    <author>
      <name>Yunchen Pu</name>
    </author>
    <author>
      <name>Xin Yuan</name>
    </author>
    <author>
      <name>Lawrence Carin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3 pages, 1 figure, ICLR workshop</arxiv:comment>
    <link href="http://arxiv.org/abs/1504.04054v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.04054v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.05392v1</id>
    <updated>2015-04-21T11:48:14Z</updated>
    <published>2015-04-21T11:48:14Z</published>
    <title>Nonparametric Testing for Heterogeneous Correlation</title>
    <summary>  In the presence of weak overall correlation, it may be useful to investigate
if the correlation is significantly and substantially more pronounced over a
subpopulation. Two different testing procedures are compared. Both are based on
the rankings of the values of two variables from a data set with a large number
n of observations. The first maintains its level against Gaussian copulas; the
second adapts to general alternatives in the sense that that the number of
parameters used in the test grows with n. An analysis of wine quality
illustrates how the methods detect heterogeneity of association between
chemical properties of the wine, which are attributable to a mix of different
cultivars.
</summary>
    <author>
      <name>Stephen Bamattre</name>
    </author>
    <author>
      <name>Rex Hu</name>
    </author>
    <author>
      <name>Joseph S. Verducci</name>
    </author>
    <link href="http://arxiv.org/abs/1504.05392v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.05392v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.07829v2</id>
    <updated>2016-05-06T11:59:23Z</updated>
    <published>2015-04-29T12:21:49Z</published>
    <title>Market forecasting using Hidden Markov Models</title>
    <summary>  Working on the daily closing prices and logreturns, in this paper we deal
with the use of Hidden Markov Models (HMMs) to forecast the price of the
EUR/USD Futures. The aim of our work is to understand how the HMMs describe
different financial time series depending on their structure. Subsequently, we
analyse the forecasting methods exposed in the previous literature, putting on
evidence their pros and cons.
</summary>
    <author>
      <name>Sara Rebagliati</name>
    </author>
    <author>
      <name>Emanuela Sasso</name>
    </author>
    <author>
      <name>Samuele Soraggi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper has been withdrawn by the author due to many errors and
  not very precise results</arxiv:comment>
    <link href="http://arxiv.org/abs/1504.07829v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.07829v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B84" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.03036v1</id>
    <updated>2015-05-12T14:49:08Z</updated>
    <published>2015-05-12T14:49:08Z</published>
    <title>Removing systematic errors for exoplanet search via latent causes</title>
    <summary>  We describe a method for removing the effect of confounders in order to
reconstruct a latent quantity of interest. The method, referred to as
half-sibling regression, is inspired by recent work in causal inference using
additive noise models. We provide a theoretical justification and illustrate
the potential of the method in a challenging astronomy application.
</summary>
    <author>
      <name>Bernhard Schölkopf</name>
    </author>
    <author>
      <name>David W. Hogg</name>
    </author>
    <author>
      <name>Dun Wang</name>
    </author>
    <author>
      <name>Daniel Foreman-Mackey</name>
    </author>
    <author>
      <name>Dominik Janzing</name>
    </author>
    <author>
      <name>Carl-Johann Simon-Gabriel</name>
    </author>
    <author>
      <name>Jonas Peters</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Extended version of a paper appearing in the Proceedings of the 32nd
  International Conference on Machine Learning, Lille, France, 2015</arxiv:comment>
    <link href="http://arxiv.org/abs/1505.03036v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.03036v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.EP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.IM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.3; I.2.6; J.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.03481v1</id>
    <updated>2015-05-09T23:13:54Z</updated>
    <published>2015-05-09T23:13:54Z</published>
    <title>Relations Between Adjacency and Modularity Graph Partitioning</title>
    <summary>  In this paper the exact linear relation between the leading eigenvector of
the unnormalized modularity matrix and the eigenvectors of the adjacency matrix
is developed. Based on this analysis a method to approximate the leading
eigenvector of the modularity matrix is given, and the relative error of the
approximation is derived. A complete proof of the equivalence between
normalized modularity clustering and normalized adjacency clustering is also
given. A new metric is defined to describe the agreement of two clustering
methods, and some applications and experiments are given to illustrate and
corroborate the points that are made in the theoretical development.
</summary>
    <author>
      <name>Hansi Jiang</name>
    </author>
    <author>
      <name>Carl Meyer</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1505.03481v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.03481v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="05C50, 15A18, 62H30, 90C59" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
