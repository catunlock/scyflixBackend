<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3Dall%3Aq-fin.RM%26id_list%3D%26start%3D0%26max_results%3D500" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=all:q-fin.RM&amp;id_list=&amp;start=0&amp;max_results=500</title>
  <id>http://arxiv.org/api/vsG6Gvdg44OLvuaX7W6SzWWN/So</id>
  <updated>2017-10-08T00:00:00-04:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">1027</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">500</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/1103.5965v1</id>
    <updated>2011-03-30T15:48:24Z</updated>
    <published>2011-03-30T15:48:24Z</published>
    <title>Scaling conditional tail probability and quantile estimators</title>
    <summary>  We present a novel procedure for scaling relatively high frequency tail
probability and quantile estimates for the conditional distribution of returns.
</summary>
    <author>
      <name>John Cotter</name>
    </author>
    <link href="http://arxiv.org/abs/1103.5965v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.5965v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1110.1578v1</id>
    <updated>2011-10-07T16:27:00Z</updated>
    <published>2011-10-07T16:27:00Z</published>
    <title>Menger 1934 revisited</title>
    <summary>  Karl Menger's 1934 paper on the St. Petersburg paradox contains mathematical
errors that invalidate his conclusion that unbounded utility functions,
specifically Bernoulli's logarithmic utility, fail to resolve modified versions
of the St. Petersburg paradox.
</summary>
    <author>
      <name>Ole Peters</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1110.1578v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1110.1578v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.0646v1</id>
    <updated>2012-09-04T13:56:46Z</updated>
    <published>2012-09-04T13:56:46Z</published>
    <title>Scenarios and their Aggregation in the Regulatory Risk Measurement
  Environment</title>
    <summary>  We define scenarios, propose different methods of aggregating them, discuss
their properties and benchmark them against quadrant requirements.
</summary>
    <author>
      <name>Andreas Haier</name>
    </author>
    <author>
      <name>Thorsten Pfeiffer</name>
    </author>
    <link href="http://arxiv.org/abs/1209.0646v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.0646v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1402.5534v1</id>
    <updated>2014-02-22T17:35:56Z</updated>
    <published>2014-02-22T17:35:56Z</published>
    <title>Estimation Error of Expected Shortfall</title>
    <summary>  The problem of estimation error of Expected Shortfall is analyzed, with a
view of its introduction as a global regulatory risk measure.
</summary>
    <author>
      <name>Imre Kondor</name>
    </author>
    <link href="http://arxiv.org/abs/1402.5534v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1402.5534v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.05227v1</id>
    <updated>2016-12-15T20:32:31Z</updated>
    <published>2016-12-15T20:32:31Z</published>
    <title>European banking supervision, the role of stress test. Some brief
  considerations</title>
    <summary>  A quick review of European financial stability institutions and the role of
stress tests in the current juridical system.
</summary>
    <author>
      <name>Simone Manduchi</name>
    </author>
    <link href="http://arxiv.org/abs/1612.05227v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.05227v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.3814v1</id>
    <updated>2012-10-14T17:09:30Z</updated>
    <published>2012-10-14T17:09:30Z</published>
    <title>Russian interbank networks: main characteristics and stability with
  respect to contagion</title>
    <summary>  Systemic risks characterizing the Russian overnight interbank market from the
network point of view are analyzed.
</summary>
    <author>
      <name>A. V. Leonidov</name>
    </author>
    <author>
      <name>E. L. Rumyantsev</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in the Proceedings the International Conference
  "Instabilities and Control of Excitable Networks: from macro- to nano-
  systems"</arxiv:comment>
    <link href="http://arxiv.org/abs/1210.3814v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.3814v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.0225v1</id>
    <updated>2012-10-21T16:13:20Z</updated>
    <published>2012-10-21T16:13:20Z</published>
    <title>The role of the Model Validation function to manage and mitigate model
  risk</title>
    <summary>  This paper describes the current taxonomy of model risk, ways for its
mitigation and management and the importance of the model validation function
in collaboration with other departments to design and implement them.
</summary>
    <author>
      <name>Alberto Elices</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 1 figure, accepted for publication in Bloomberg Risk
  Newsletter</arxiv:comment>
    <link href="http://arxiv.org/abs/1211.0225v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.0225v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1311.3764v1</id>
    <updated>2013-11-15T08:26:52Z</updated>
    <published>2013-11-15T08:26:52Z</published>
    <title>Modeling systemic risks in financial markets</title>
    <summary>  We survey systemic risks to financial markets and present a high-level
description of an algorithm that measures systemic risk in terms of coupled
networks.
</summary>
    <author>
      <name>Abhijnan Rej</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, discussion paper</arxiv:comment>
    <link href="http://arxiv.org/abs/1311.3764v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1311.3764v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.04485v1</id>
    <updated>2015-05-18T01:27:25Z</updated>
    <published>2015-05-18T01:27:25Z</published>
    <title>Remarks on equality of two distributions under some partial orders</title>
    <summary>  In this note we establish some appropriate conditions for stochastic equality
of two random variables/vectors which are ordered with respect to convex
ordering or with respect to supermodular ordering. Multivariate extensions of
this result are also considered.
</summary>
    <author>
      <name>Chuancun Yin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1505.04485v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.04485v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.08283v1</id>
    <updated>2016-08-29T23:23:42Z</updated>
    <published>2016-08-29T23:23:42Z</published>
    <title>Risk measures and Margining control</title>
    <summary>  This document constitutes the final report of the contractual activity
between Directa SIM and Dipartimento di Automatica e Informatica, Politecnico
di Torino, on the research topic titled "quantificazione del rischio di un
portafoglio di strumenti finanziari per trading online su device fissi e
mobili."
</summary>
    <author>
      <name>Giuseppe Carlo Calafiore</name>
    </author>
    <author>
      <name>Leonardo Massai</name>
    </author>
    <link href="http://arxiv.org/abs/1608.08283v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.08283v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0708.0089v1</id>
    <updated>2007-08-01T08:31:24Z</updated>
    <published>2007-08-01T08:31:24Z</published>
    <title>Discussion of "2004 IMS Medallion Lecture: Local Rademacher complexities
  and oracle inequalities in risk minimization" by V. Koltchinskii</title>
    <summary>  Discussion of "2004 IMS Medallion Lecture: Local Rademacher complexities and
oracle inequalities in risk minimization" by V. Koltchinskii [arXiv:0708.0083]
</summary>
    <author>
      <name>Peter L. Bartlett</name>
    </author>
    <author>
      <name>Shahar Mendelson</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1214/009053606000001028</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1214/009053606000001028" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published at http://dx.doi.org/10.1214/009053606000001028 in the
  Annals of Statistics (http://www.imstat.org/aos/) by the Institute of
  Mathematical Statistics (http://www.imstat.org)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Annals of Statistics 2006, Vol. 34, No. 6, 2657-2663</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0708.0089v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0708.0089v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0708.0098v1</id>
    <updated>2007-08-01T09:05:09Z</updated>
    <published>2007-08-01T09:05:09Z</published>
    <title>Discussion of ``2004 IMS Medallion Lecture: Local Rademacher
  complexities and oracle inequalities in risk minimization'' by V.
  Koltchinskii</title>
    <summary>  Discussion of ``2004 IMS Medallion Lecture: Local Rademacher complexities and
oracle inequalities in risk minimization'' by V. Koltchinskii [arXiv:0708.0083]
</summary>
    <author>
      <name>Stéphan Clémençon</name>
    </author>
    <author>
      <name>Gábor Lugosi</name>
    </author>
    <author>
      <name>Nicolas Vayatis</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1214/009053606000001046</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1214/009053606000001046" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published at http://dx.doi.org/10.1214/009053606000001046 in the
  Annals of Statistics (http://www.imstat.org/aos/) by the Institute of
  Mathematical Statistics (http://www.imstat.org)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Annals of Statistics 2006, Vol. 34, No. 6, 2672-2676</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0708.0098v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0708.0098v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0708.0121v1</id>
    <updated>2007-08-01T10:51:14Z</updated>
    <published>2007-08-01T10:51:14Z</published>
    <title>Discussion of ``2004 IMS Medallion Lecture: Local Rademacher
  complexities and oracle inequalities in risk minimization'' by V.
  Koltchinskii</title>
    <summary>  Discussion of ``2004 IMS Medallion Lecture: Local Rademacher complexities and
oracle inequalities in risk minimization'' by V. Koltchinskii [arXiv:0708.0083]
</summary>
    <author>
      <name>Xiaotong Shen</name>
    </author>
    <author>
      <name>Lifeng Wang</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1214/009053606000001055</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1214/009053606000001055" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published at http://dx.doi.org/10.1214/009053606000001055 in the
  Annals of Statistics (http://www.imstat.org/aos/) by the Institute of
  Mathematical Statistics (http://www.imstat.org)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Annals of Statistics 2006, Vol. 34, No. 6, 2677-2680</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0708.0121v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0708.0121v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0708.0124v1</id>
    <updated>2007-08-01T11:09:36Z</updated>
    <published>2007-08-01T11:09:36Z</published>
    <title>Discussion of ``2004 IMS Medallion Lecture: Local Rademacher
  complexities and oracle inequalities in risk minimization'' by V.
  Koltchinskii</title>
    <summary>  Discussion of ``2004 IMS Medallion Lecture: Local Rademacher complexities and
oracle inequalities in risk minimization'' by V. Koltchinskii [arXiv:0708.0083]
</summary>
    <author>
      <name>A. B. Tsybakov</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1214/009053606000001064</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1214/009053606000001064" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published at http://dx.doi.org/10.1214/009053606000001064 in the
  Annals of Statistics (http://www.imstat.org/aos/) by the Institute of
  Mathematical Statistics (http://www.imstat.org)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Annals of Statistics 2006, Vol. 34, No. 6, 2681-2687</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0708.0124v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0708.0124v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0708.0132v1</id>
    <updated>2007-08-01T11:28:07Z</updated>
    <published>2007-08-01T11:28:07Z</published>
    <title>Discussion of ``2004 IMS Medallion Lecture: Local Rademacher
  complexities and oracle inequalities in risk minimization'' by V.
  Koltchinskii</title>
    <summary>  Discussion of ``2004 IMS Medallion Lecture: Local Rademacher complexities and
oracle inequalities in risk minimization'' by V. Koltchinskii [arXiv:0708.0083]
</summary>
    <author>
      <name>Sara van de Geer</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1214/009053606000001073</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1214/009053606000001073" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published at http://dx.doi.org/10.1214/009053606000001073 in the
  Annals of Statistics (http://www.imstat.org/aos/) by the Institute of
  Mathematical Statistics (http://www.imstat.org)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Annals of Statistics 2006, Vol. 34, No. 6, 2688-2696</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0708.0132v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0708.0132v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0709.0232v1</id>
    <updated>2007-09-03T13:51:11Z</updated>
    <published>2007-09-03T13:51:11Z</published>
    <title>Valuations and dynamic convex risk measures</title>
    <summary>  This paper approaches the definition and properties of dynamic convex risk
measures through the notion of a family of concave valuation operators
satisfying certain simple and credible axioms. Exploring these in the simplest
context of a finite time set and finite sample space, we find natural
risk-transfer and time-consistency properties for a firm seeking to spread its
risk across a group of subsidiaries.
</summary>
    <author>
      <name>A. Jobert</name>
    </author>
    <author>
      <name>L. C. G. Rogers</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">26 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/0709.0232v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0709.0232v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B02" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0806.2358v1</id>
    <updated>2008-06-14T04:11:35Z</updated>
    <published>2008-06-14T04:11:35Z</published>
    <title>Minimizing the Probability of Ruin when Consumption is Ratcheted</title>
    <summary>  We assume that an agent's rate of consumption is {\it ratcheted}; that is, it
forms a non-decreasing process. Given the rate of consumption, we act as
financial advisers and find the optimal investment strategy for the agent who
wishes to minimize his probability of ruin.
</summary>
    <author>
      <name>Erhan Bayraktar</name>
    </author>
    <author>
      <name>Virginia R. Young</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Key Words: Self-annuitization, optimal investment, stochastic optimal
  control, probability of ruin, ratcheting of consumption</arxiv:comment>
    <link href="http://arxiv.org/abs/0806.2358v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0806.2358v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0905.0781v2</id>
    <updated>2009-09-27T14:47:52Z</updated>
    <published>2009-05-06T09:00:10Z</published>
    <title>Variance-covariance based risk allocation in credit portfolios:
  analytical approximation</title>
    <summary>  High precision analytical approximation is proposed for variance-covariance
based risk allocation in a portfolio of risky assets. A general case of a
single-period multi-factor Merton-type model with stochastic recovery is
considered. The accuracy of the approximation as well as its speed are compared
to and shown to be superior to those of Monte Carlo simulation.
</summary>
    <author>
      <name>Mikhail Voropaev</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0905.0781v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0905.0781v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.CP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0910.5398v1</id>
    <updated>2009-10-28T14:55:02Z</updated>
    <published>2009-10-28T14:55:02Z</published>
    <title>Inf-convolution of G-expectations</title>
    <summary>  In this paper we will discuss the optimal risk transfer problems when risk
measures are generated by G-expectations, and we present the relationship
between inf-convolution of G-expectations and the inf-convolution of drivers G.
</summary>
    <author>
      <name>Xuepeng Bai</name>
    </author>
    <author>
      <name>Rainer Buckdahn</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s11425-010-4031-6</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s11425-010-4031-6" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">23 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Science China Mathematics, 2010 Vol. 53 No. 8: 1957-1970</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0910.5398v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0910.5398v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="60H10, 60H05, 60H30" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1001.3644v2</id>
    <updated>2010-01-21T11:55:23Z</updated>
    <published>2010-01-20T17:09:07Z</published>
    <title>Dual Representation of Quasiconvex Conditional Maps</title>
    <summary>  We provide a dual representation of quasiconvex maps between two lattices of
random variables in terms of conditional expectations. This generalizes the
dual representation of quasiconvex real valued functions and the dual
representation of conditional convex maps.
</summary>
    <author>
      <name>Marco Frittelli</name>
    </author>
    <author>
      <name>Marco Maggis</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Date changed Added one remark on assumption (c), page 6</arxiv:comment>
    <link href="http://arxiv.org/abs/1001.3644v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1001.3644v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1002.3560v1</id>
    <updated>2010-02-18T16:18:12Z</updated>
    <published>2010-02-18T16:18:12Z</published>
    <title>Spin Glass Model of Operational Risk</title>
    <summary>  We analyze operational risk in terms of a spin glass model. Several regimes
are investigated, as a functions of the parameters that characterize the
dynamics. The system is found to be robust against variations of these
parameters. We unveil the presence of limit cycles and scrutinize the features
of the asymptotic state.
</summary>
    <author>
      <name>M. Bardoscia</name>
    </author>
    <author>
      <name>P. Facchi</name>
    </author>
    <author>
      <name>S. Pascazio</name>
    </author>
    <author>
      <name>A. Trullo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 Pages, 15 Figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1002.3560v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1002.3560v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.CP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1002.3794v1</id>
    <updated>2010-02-19T17:46:02Z</updated>
    <published>2010-02-19T17:46:02Z</published>
    <title>Dynamic risk measures</title>
    <summary>  This paper gives an overview of the theory of dynamic convex risk measures
for random variables in discrete time setting. We summarize robust
representation results of conditional convex risk measures, and we characterize
various time consistency properties of dynamic risk measures in terms of
acceptance sets, penalty functions, and by supermartingale properties of risk
processes and penalty functions.
</summary>
    <author>
      <name>Beatrice Acciaio</name>
    </author>
    <author>
      <name>Irina Penner</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">30 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1002.3794v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1002.3794v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="60G35; 91B30; 91B16" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1005.4456v1</id>
    <updated>2010-05-24T23:42:19Z</updated>
    <published>2010-05-24T23:42:19Z</published>
    <title>Some Remarks on T-copulas</title>
    <summary>  We examine three methods of constructing correlated Student-$t$ random
variables. Our motivation arises from simulations that utilise heavy-tailed
distributions for the purposes of stress testing and economic capital
calculations for financial institutions. We make several observations regarding
the suitability of the three methods for this purpose.
</summary>
    <author>
      <name>Volf Frishling</name>
    </author>
    <author>
      <name>David G Maher</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 7 figures. Submitted to QMF2010</arxiv:comment>
    <link href="http://arxiv.org/abs/1005.4456v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1005.4456v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62G32, 60E99" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1007.0610v1</id>
    <updated>2010-07-05T03:21:44Z</updated>
    <published>2010-07-05T03:21:44Z</published>
    <title>What risk measures are time consistent for all filtrations?</title>
    <summary>  We study coherent risk measures which are time-consistent for multiple
filtrations. We show that a coherent risk measure is time-consistent for every
filtration if and only if it is one of four main types. Furthermore, if the
risk measure is strictly monotone it is linear, and if the reference
probability space is not atomic then it is either linear or an essential
supremum.
</summary>
    <author>
      <name>Samuel N. Cohen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1007.0610v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1007.0610v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1010.5810v3</id>
    <updated>2016-01-07T20:58:05Z</updated>
    <published>2010-10-27T21:17:18Z</published>
    <title>Quantile hedging for basket derivatives</title>
    <summary>  The problem of quantile hedging for basket derivatives in the Black-Scholes
model with correlation is considered. Explicit formulas for the probability
maximizing function and the cost reduction function are derived. Applicability
of the results for the widely traded derivatives as digital, quantos,
outperformance and spread options is shown.
</summary>
    <author>
      <name>Michał Barski</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">30 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Applicationes Mathematicae, 2012, 39,1, 103-127</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1010.5810v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1010.5810v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B30, 91B24, 91B70" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.5655v1</id>
    <updated>2011-03-29T14:31:04Z</updated>
    <published>2011-03-29T14:31:04Z</published>
    <title>Implied correlation from VaR</title>
    <summary>  Value at risk (VaR) is a risk measure that has been widely implemented by
financial institutions. This paper measures the correlation among asset price
changes implied from VaR calculation. Empirical results using US and UK equity
indexes show that implied correlation is not constant but tends to be higher
for events in the left tails (crashes) than in the right tails (booms).
</summary>
    <author>
      <name>John Cotter</name>
    </author>
    <author>
      <name>François Longin</name>
    </author>
    <link href="http://arxiv.org/abs/1103.5655v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.5655v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.5656v1</id>
    <updated>2011-03-29T14:32:39Z</updated>
    <published>2011-03-29T14:32:39Z</published>
    <title>Modelling catastrophic risk in international equity markets: An extreme
  value approach</title>
    <summary>  This letter uses the Block Maxima Extreme Value approach to quantify
catastrophic risk in international equity markets. Risk measures are generated
from a set threshold of the distribution of returns that avoids the pitfall of
using absolute returns for markets exhibiting diverging levels of risk. From an
application to leading markets, the letter finds that the Nikkei is more prone
to catastrophic risk than the FTSE and Dow Jones Indexes.
</summary>
    <author>
      <name>john cotter</name>
    </author>
    <link href="http://arxiv.org/abs/1103.5656v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.5656v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1107.2164v1</id>
    <updated>2011-07-11T23:15:43Z</updated>
    <published>2011-07-11T23:15:43Z</published>
    <title>KISS approach to credit portfolio modeling</title>
    <summary>  A simple, yet reasonably accurate, analytical technique is proposed for
multi-factor structural credit portfolio models. The accuracy of the technique
is demonstrated by benchmarking against Monte Carlo simulations. The approach
presented here may be of high interest to practitioners looking for
transparent, intuitive, easy to implement and high performance credit portfolio
model.
</summary>
    <author>
      <name>Mikhail Voropaev</name>
    </author>
    <link href="http://arxiv.org/abs/1107.2164v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1107.2164v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.4421v1</id>
    <updated>2011-11-18T16:46:09Z</updated>
    <published>2011-11-18T16:46:09Z</published>
    <title>Historical risk measures on stock market indices and energy markets</title>
    <summary>  In this paper we look at the efficacy of different risk measures on energy
markets and across several different stock market indices. We use both the
Value at Risk and the Tail Conditional Expectation on each of these data sets.
We also consider several different durations and levels for historical risk
measures. Through our results we make some recommendations for a robust risk
management strategy that involves historical risk measures.
</summary>
    <author>
      <name>Wayne Tarrant</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1111.4421v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.4421v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1201.1788v2</id>
    <updated>2012-09-05T12:48:31Z</updated>
    <published>2012-01-09T14:51:08Z</published>
    <title>Complete duality for quasiconvex dynamic risk measures on modules of the
  $L^{p}$-type</title>
    <summary>  In the conditional setting we provide a complete duality between quasiconvex
risk measures defined on $L^{0}$ modules of the $L^{p}$ type and the
appropriate class of dual functions. This is based on a general result which
extends the usual Penot-Volle representation for quasiconvex real valued maps.
</summary>
    <author>
      <name>Marco Frittelli</name>
    </author>
    <author>
      <name>Marco Maggis</name>
    </author>
    <link href="http://arxiv.org/abs/1201.1788v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1201.1788v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.1966v1</id>
    <updated>2012-10-06T15:02:39Z</updated>
    <published>2012-10-06T15:02:39Z</published>
    <title>How We Tend To Overestimate Powerlaw Tail Exponents</title>
    <summary>  In the presence of a layer of metaprobabilities (from uncertainty concerning
the parameters), the asymptotic tail exponent corresponds to the lowest
possible tail exponent regardless of its probability. The problem explains
"Black Swan" effects, i.e., why measurements tend to chronically underestimate
tail contributions, rather than merely deliver imprecise but unbiased
estimates.
</summary>
    <author>
      <name>Nassim N. Taleb</name>
    </author>
    <link href="http://arxiv.org/abs/1210.1966v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.1966v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.2043v1</id>
    <updated>2012-10-07T11:35:11Z</updated>
    <published>2012-10-07T11:35:11Z</published>
    <title>Smooth Nonparametric Bernstein Vine Copulas</title>
    <summary>  We propose to use nonparametric Bernstein copulas as bivariate pair-copulas
in high-dimensional vine models. The resulting smooth and nonparametric vine
copulas completely obviate the error-prone need for choosing the pair-copulas
from parametric copula families. By means of a simulation study and an
empirical analysis of financial market data, we show that our proposed smooth
nonparametric vine copula model is superior to competing parametric vine models
calibrated via Akaike's Information Criterion.
</summary>
    <author>
      <name>Gregor Weiß</name>
    </author>
    <author>
      <name>Marcus Scheffer</name>
    </author>
    <link href="http://arxiv.org/abs/1210.2043v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.2043v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62P20" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.4126v1</id>
    <updated>2012-12-17T20:31:20Z</updated>
    <published>2012-12-17T20:31:20Z</published>
    <title>Risk Measures in a Regime Switching Model Capturing Stylized Facts</title>
    <summary>  We pick up the regime switching model for asset returns introduced by Rogers
and Zhang. The calibration involves various markets including implied
volatility in order to gain additional predictive power. We focus on the
calculation of risk measures by Fourier methods that have successfully been
applied to option pricing and analyze the accuracy of the results.
</summary>
    <author>
      <name>Rainer Haidinger</name>
    </author>
    <author>
      <name>Richard Warnung</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages, 11 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1212.4126v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.4126v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1306.5705v1</id>
    <updated>2013-06-24T18:40:35Z</updated>
    <published>2013-06-24T18:40:35Z</published>
    <title>Computational Dynamic Market Risk Measures in Discrete Time Setting</title>
    <summary>  Different approaches to defining dynamic market risk measures are available
in the literature. Most are focused or derived from probability theory,
economic behavior or dynamic programming. Here, we propose an approach to
define and implement dynamic market risk measures based on recursion and state
economy representation. The proposed approach is to be implementable and to
inherit properties from static market risk measures.
</summary>
    <author>
      <name>Babacar Seck</name>
    </author>
    <author>
      <name>Robert J. Elliott</name>
    </author>
    <author>
      <name>Jean-Pierre Gueyie</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1306.5705v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1306.5705v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91G99" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1308.5064v2</id>
    <updated>2014-05-07T17:10:08Z</updated>
    <published>2013-08-23T07:35:24Z</published>
    <title>Analytical models of operational risk and new results on the correlation
  problem</title>
    <summary>  We propose a portfolio approach for operational risk quantification based on
a class of analytical models from which we derive new results on the
correlation problem. In particular, we show that uniform correlation is a
robust assumption for measuring capital charges in these models.
</summary>
    <author>
      <name>Vivien Brunel</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 3 figures, 1 table</arxiv:comment>
    <link href="http://arxiv.org/abs/1308.5064v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1308.5064v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1312.5271v1</id>
    <updated>2013-12-18T19:21:24Z</updated>
    <published>2013-12-18T19:21:24Z</published>
    <title>Systematic and multifactor risk models revisited</title>
    <summary>  Systematic and multifactor risk models are revisited via methods which were
already successfully developed in signal processing and in automatic control.
The results, which bypass the usual criticisms on those risk modeling, are
illustrated by several successful computer experiments.
</summary>
    <author>
      <name>Michel Fliess</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIX, AL.I.E.N.</arxiv:affiliation>
    </author>
    <author>
      <name>Cédric Join</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">AL.I.E.N., CRAN, INRIA Lille - Nord Europe</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">First Paris Financial Management Conference, Paris : France (2013)</arxiv:comment>
    <link href="http://arxiv.org/abs/1312.5271v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1312.5271v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.CP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1312.7346v1</id>
    <updated>2013-12-27T13:00:45Z</updated>
    <published>2013-12-27T13:00:45Z</published>
    <title>Bankruptcy Risk Induced by Career Concerns of Regulators</title>
    <summary>  We introduce a model in which a regulator employs mechanism design to embed
her human capital beta signal(s) in a firm's capital structure, in order to
enhance the value of her post career change indexed executive stock option
contract with the firm. We prove that the agency cost of this revolving door
behavior increases the firm's financial leverage, bankruptcy risk, and affects
estimation of firm value at risk (VaR).
</summary>
    <author>
      <name>Godfrey Charles-Cadogan</name>
    </author>
    <author>
      <name>John A. Cole</name>
    </author>
    <link href="http://arxiv.org/abs/1312.7346v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1312.7346v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1401.3121v1</id>
    <updated>2014-01-14T10:05:28Z</updated>
    <published>2014-01-14T10:05:28Z</published>
    <title>Law-invariant risk measures: extension properties and qualitative
  robustness</title>
    <summary>  We characterize when a convex risk measure associated to a law-invariant
acceptance set in $L^\infty$ can be extended to $L^p$, $1\leq p&lt;\infty$,
preserving finiteness and continuity. This problem is strongly connected to the
statistical robustness of the corresponding risk measures. Special attention is
paid to concrete examples including risk measures based on expected utility,
max-correlation risk measures, and distortion risk measures.
</summary>
    <author>
      <name>Pablo Koch-Medina</name>
    </author>
    <author>
      <name>Cosimo Munari</name>
    </author>
    <link href="http://arxiv.org/abs/1401.3121v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1401.3121v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B30, 91G80" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1408.6673v2</id>
    <updated>2015-04-13T06:16:11Z</updated>
    <published>2014-08-28T10:30:49Z</published>
    <title>Hedging Conditional Value at Risk with Options</title>
    <summary>  We present a method of hedging Conditional Value at Risk of a position in
stock using put options. The result leads to a linear programming problem that
can be solved to optimise risk hedging.
</summary>
    <author>
      <name>Maciej J. Capiński</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.ejor.2014.11.011</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.ejor.2014.11.011" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 0 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">European Journal of Operational Research 242 (2015) 688-691</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1408.6673v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1408.6673v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.06217v1</id>
    <updated>2015-02-22T12:23:08Z</updated>
    <published>2015-02-22T12:23:08Z</published>
    <title>Contour map of estimation error for Expected Shortfall</title>
    <summary>  The contour map of estimation error of Expected Shortfall (ES) is
constructed. It allows one to quantitatively determine the sample size (the
length of the time series) required by the optimization under ES of large
institutional portfolios for a given size of the portfolio, at a given
confidence level and a given estimation error.
</summary>
    <author>
      <name>Imre Kondor</name>
    </author>
    <author>
      <name>Fabio Caccioli</name>
    </author>
    <author>
      <name>Gábor Papp</name>
    </author>
    <author>
      <name>Matteo Marsili</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1502.06217v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.06217v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.05655v2</id>
    <updated>2016-03-10T09:24:14Z</updated>
    <published>2015-03-19T06:20:57Z</published>
    <title>Option Pricing Beyond Black-Scholes Based on Double-Fractional Diffusion</title>
    <summary>  We show how the prices of options can be determined with the help of
double-fractional differential equation in such a way that their inclusion in a
portfolio of stocks provides a more reliable hedge against dramatic price drops
that the use of options whose prices were fixed by the Black-Scholes formula.
</summary>
    <author>
      <name>Hagen Kleinert</name>
    </author>
    <author>
      <name>Jan Korbel</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.physa.2015.12.125</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.physa.2015.12.125" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 5 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Physica A 449, 2016, 200-214</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1503.05655v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.05655v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.00937v2</id>
    <updated>2016-11-29T18:39:12Z</updated>
    <published>2015-06-02T16:08:07Z</published>
    <title>Financial Contagion and Asset Liquidation Strategies</title>
    <summary>  This paper provides a framework for modeling the financial system with
multiple illiquid assets during a crisis. This work generalizes the paper by
Amini, Filipovic and Minca (2016) by allowing for differing liquidation
strategies. The main result is a proof of sufficient conditions for the
existence of an equilibrium liquidation strategy with corresponding unique
clearing payments and liquidation prices. An algorithm for computing the
maximal clearing payments and prices is provided.
</summary>
    <author>
      <name>Zachary Feinstein</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1506.00937v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.00937v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.03171v1</id>
    <updated>2016-01-13T08:42:23Z</updated>
    <published>2016-01-13T08:42:23Z</published>
    <title>On a law of large numbers for insurance risks</title>
    <summary>  This note presents a kind of the strong law of large numbers for an insurance
risk caused by a single catastrophic event rather than by an accumulation of
independent and identically distributed risks. We derive this result by a large
diversification effect resulting from optimal allocation of the risk to many
reinsurers or investors.
</summary>
    <author>
      <name>Yumiharu Nakano</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1601.03171v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.03171v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.02774v1</id>
    <updated>2016-09-09T12:58:03Z</updated>
    <published>2016-09-09T12:58:03Z</published>
    <title>Value at risk and the diversification dogma</title>
    <summary>  The so-called risk diversification principle is analyzed, showing that its
convenience depends on individual characteristics of the risks involved and the
dependence relationship among them.
  -----
  Se analiza el principio de diversificaci\'on de riesgos y se demuestra que no
siempre resulta mejor que no diversificar, pues esto depende de
caracter\'isticas individuales de los riesgos involucrados, as\'i como de la
relaci\'on de dependencia entre los mismos.
</summary>
    <author>
      <name>Arturo Erdely</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 1 figure, in English and Spanish</arxiv:comment>
    <link href="http://arxiv.org/abs/1609.02774v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.02774v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91G10" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.02985v1</id>
    <updated>2016-12-09T11:46:33Z</updated>
    <published>2016-12-09T11:46:33Z</published>
    <title>Risk averse fractional trading using the current drawdown</title>
    <summary>  In this paper the fractional trading ansatz of money management is
reconsidered with special attention to chance and risk parts in the goal
function of the related optimization problem. By changing the goal function
with due regards to other risk measures like current drawdowns, the optimal
fraction solutions reflect the needs of risk averse investors better than the
original optimal f solution of Ralph Vince.
  Keywords: fractional trading, optimal f, current drawdown, terminal wealth
relative, risk aversion
</summary>
    <author>
      <name>Stanislaus Maier-Paape</name>
    </author>
    <link href="http://arxiv.org/abs/1612.02985v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.02985v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.03347v1</id>
    <updated>2016-12-10T21:58:09Z</updated>
    <published>2016-12-10T21:58:09Z</published>
    <title>Dual Moments and Risk Attitudes</title>
    <summary>  In the economics of risk, the primal moments of mean and variance play a
central role to define the local index of absolute risk aversion. In this note,
we show that in canonical non-EU models dual moments have to be used instead
of, or on par with, their primal counterparts to obtain an equivalent index of
absolute risk aversion.
</summary>
    <author>
      <name>Louis R. Eeckhoudt</name>
    </author>
    <author>
      <name>Roger J. A. Laeven</name>
    </author>
    <link href="http://arxiv.org/abs/1612.03347v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.03347v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.04549v1</id>
    <updated>2017-03-05T18:12:50Z</updated>
    <published>2017-03-05T18:12:50Z</published>
    <title>Systemic Risk, Maximum Entropy and Interbank Contagion</title>
    <summary>  We discuss the systemic risk implied by the interbank exposures reconstructed
with the maximum entropy method. The maximum entropy method severely
underestimates the risk of interbank contagion by assuming a fully connected
network, while in reality the structure of the interbank network is sparsely
connected. Here, we formulate an algorithm for sparse network reconstruction,
and we show numerically that it provides a more reliable estimation of the
systemic risk.
</summary>
    <author>
      <name>M. Andrecut</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1142/S0129183116501485</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1142/S0129183116501485" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 3 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Int. J. Mod. Phys. C 27, 1650148 (2016)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1703.04549v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.04549v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.05047v2</id>
    <updated>2017-03-16T16:46:08Z</updated>
    <published>2017-03-15T09:40:50Z</published>
    <title>Data driven partition-of-unity copulas with applications to risk
  management</title>
    <summary>  We present a constructive and self-contained approach to data driven general
partition-of-unity copulas that were recently introduced in the literature. In
particular, we consider Bernstein-, negative binomial and Poisson copulas and
present a solution to the problem of fitting such copulas to highly asymmetric
data.
</summary>
    <author>
      <name>Dietmar Pfeifer</name>
    </author>
    <author>
      <name>Andreas Mändle</name>
    </author>
    <author>
      <name>Olena Ragulina</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, several figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1703.05047v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.05047v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62H05, 62H12, 62H17, 62H20" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1704.01503v1</id>
    <updated>2017-04-05T16:10:23Z</updated>
    <published>2017-04-05T16:10:23Z</published>
    <title>Multivariate Geometric Expectiles</title>
    <summary>  A generalization of expectiles for d-dimensional multivariate distribution
functions is introduced. The resulting geometric expectiles are unique
solutions to a convex risk minimization problem and are given by d-dimensional
vectors. They are well behaved under common data transformations and the
corresponding sample version is shown to be a consistent estimator. We
exemplify their usage as risk measures in a number of multivariate settings,
highlighting the influence of varying margins and dependence structures.
</summary>
    <author>
      <name>Klaus Herrmann</name>
    </author>
    <author>
      <name>Marius Hofert</name>
    </author>
    <author>
      <name>Melina Mailhot</name>
    </author>
    <link href="http://arxiv.org/abs/1704.01503v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1704.01503v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1704.07152v1</id>
    <updated>2017-04-24T11:35:18Z</updated>
    <published>2017-04-24T11:35:18Z</published>
    <title>Asymptotic multivariate expectiles</title>
    <summary>  In [16], a new family of vector-valued risk measures called multivariate
expectiles is introduced. In this paper, we focus on the asymptotic behavior of
these measures in a multivariate regular variations context. For models with
equivalent tails, we propose an estimator of these multivariate asymptotic
expectiles, in the Fr\'echet attraction domain case, with asymptotic
independence, or in the comonotonic case.
</summary>
    <author>
      <name>Véronique Maume-Deschamps</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">ICJ</arxiv:affiliation>
    </author>
    <author>
      <name>Didier Rullière</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">SAF</arxiv:affiliation>
    </author>
    <author>
      <name>Khalil Said</name>
    </author>
    <link href="http://arxiv.org/abs/1704.07152v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1704.07152v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.06285v1</id>
    <updated>2017-06-20T06:44:36Z</updated>
    <published>2017-06-20T06:44:36Z</published>
    <title>A class of dynamical contagion credit risk models and their applications</title>
    <summary>  In this paper, we establish a class of default risk models with possible
dynamical contagion between different obligors. Thereby, we derive explicitly
the pricing formulae by set-valued Markov chain approach. As an application, we
employ the default contagion model to price synthetic CDOs. The calculation
time is reduced dramatically comparing with related literatures, especially,
when the number of reference obligors is large.
</summary>
    <author>
      <name>Dianfa Chen</name>
    </author>
    <author>
      <name>Jun Deng</name>
    </author>
    <author>
      <name>Jianfen Feng</name>
    </author>
    <link href="http://arxiv.org/abs/1706.06285v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.06285v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.07322v1</id>
    <updated>2017-07-23T17:06:58Z</updated>
    <published>2017-07-23T17:06:58Z</published>
    <title>Extended Gini-type measures of risk and variability</title>
    <summary>  The main of this paper is to introduce a family of risk measures which
generalizes the Gini-type measures of risk and variability, by taking into
consideration the psychological behavior. Our risk measures family is coherent
and catches variability with respect to the decision-maker attitude towards
risk.
</summary>
    <author>
      <name>Mohammed Berkhouch</name>
    </author>
    <author>
      <name>Ghizlane Lakhnati</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This is a working paper consisting of 20 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1707.07322v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.07322v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.09343v1</id>
    <updated>2017-08-30T16:18:10Z</updated>
    <published>2017-08-30T16:18:10Z</published>
    <title>Value-at-Risk and Expected Shortfall for the major digital currencies</title>
    <summary>  Digital currencies and cryptocurrencies have hesitantly started to penetrate
the investors, and the next step will be the regulatory risk management
framework. We examine the Value-at-Risk and Expected Shortfall properties for
the major digital currencies, Bitcoin, Ethereum, Litecoin, and Ripple. The
methodology used is GARCH modelling followed by Filtered Historical Simulation.
We find that digital currencies are subject to a higher risk, therefore, to
higher sufficient buffer and risk capital to cover potential losses.
</summary>
    <author>
      <name>Stavros Stavroyiannis</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1708.09343v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.09343v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.07682v1</id>
    <updated>2017-09-22T10:34:13Z</updated>
    <published>2017-09-22T10:34:13Z</published>
    <title>New copulas based on general partitions-of-unity and their applications
  to risk management (part II)</title>
    <summary>  We present a constructive and self-contained approach to data driven infinite
partition-of-unity copulas that were recently introduced in the literature. In
particular, we consider negative binomial and Poisson copulas and present a
solution to the problem of fitting such copulas to highly asymmetric data in
arbitrary dimensions.
</summary>
    <author>
      <name>Dietmar Pfeifer</name>
    </author>
    <author>
      <name>Andreas Mändle</name>
    </author>
    <author>
      <name>Olena Ragulina</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1709.07682v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.07682v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62H05, 62H12, 62H17, 62H20" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.08411v1</id>
    <updated>2017-08-28T16:46:29Z</updated>
    <published>2017-08-28T16:46:29Z</published>
    <title>Default Contagion with Domino Effect , A First Passage Time Approach</title>
    <summary>  The present paper introduces a structural framework to model dependent
defaults, with a particular interest in their contagion.
</summary>
    <author>
      <name>Jiro Akahori</name>
    </author>
    <author>
      <name>Hai Ha Pham</name>
    </author>
    <link href="http://arxiv.org/abs/1708.08411v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.08411v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.MF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.MF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0704.0394v1</id>
    <updated>2007-04-03T13:42:37Z</updated>
    <published>2007-04-03T13:42:37Z</published>
    <title>Average optimality for risk-sensitive control with general state space</title>
    <summary>  This paper deals with discrete-time Markov control processes on a general
state space. A long-run risk-sensitive average cost criterion is used as a
performance measure. The one-step cost function is nonnegative and possibly
unbounded. Using the vanishing discount factor approach, the optimality
inequality and an optimal stationary strategy for the decision maker are
established.
</summary>
    <author>
      <name>Anna Jaśkiewicz</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1214/105051606000000790</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1214/105051606000000790" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published at http://dx.doi.org/10.1214/105051606000000790 in the
  Annals of Applied Probability (http://www.imstat.org/aap/) by the Institute
  of Mathematical Statistics (http://www.imstat.org)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Annals of Applied Probability 2007, Vol. 17, No. 2, 654-675</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0704.0394v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0704.0394v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="60J05, 90C39 (Primary) 60A10 (Secondary)" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0706.3331v1</id>
    <updated>2007-06-22T13:44:05Z</updated>
    <published>2007-06-22T13:44:05Z</published>
    <title>A Model for Counterparty Risk with Geometric Attenuation Effect and the
  Valuation of CDS</title>
    <summary>  In this paper, a geometric function is introduced to reflect the attenuation
speed of impact of one firm's default to its partner. If two firms are
competitions (copartners), the default intensity of one firm will decrease
(increase) abruptly when the other firm defaults. As time goes on, the impact
will decrease gradually until extinct. In this model, the joint distribution
and marginal distributions of default times are derived by employing the change
of measure, so can we value the fair swap premium of a CDS.
</summary>
    <author>
      <name>Yunfen Bai</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Mathematics, Shanghai Jiaotong University;</arxiv:affiliation>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Mathematics, Shijiazhuang College</arxiv:affiliation>
    </author>
    <author>
      <name>Xinhua Hu</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Mathematics, Shanghai Jiaotong University;</arxiv:affiliation>
    </author>
    <author>
      <name>Zhongxing Ye</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Mathematics, Shanghai Jiaotong University;</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/0706.3331v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0706.3331v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62P05" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0710.3892v2</id>
    <updated>2008-08-04T17:14:02Z</updated>
    <published>2007-10-20T23:32:43Z</published>
    <title>Maturity-independent risk measures</title>
    <summary>  The new notion of maturity-independent risk measures is introduced and
contrasted with the existing risk measurement concepts. It is shown, by means
of two examples, one set on a finite probability space and the other in a
diffusion framework, that, surprisingly, some of the widely utilized risk
measures cannot be used to build maturity-independent counterparts. We
construct a large class of maturity-independent risk measures and give
representative examples in both continuous- and discrete-time financial models.
</summary>
    <author>
      <name>Thaleia Zariphopoulou</name>
    </author>
    <author>
      <name>Gordan Zitkovic</name>
    </author>
    <link href="http://arxiv.org/abs/0710.3892v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0710.3892v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0712.3363v1</id>
    <updated>2007-12-20T10:39:06Z</updated>
    <published>2007-12-20T10:39:06Z</published>
    <title>Incorporating exchange rate risk into PDs and asset correlations</title>
    <summary>  Intuitively, the default risk of a single borrower is higher when her or his
assets and debt are denominated in different currencies. Additionally, the
default dependence of borrowers with assets and debt in different currencies
should be stronger than in the one-currency case. By combining well-known
models by Merton (1974), Garman and Kohlhagen (1983), and Vasicek (2002) we
develop simple representations of PDs and asset correlations that take into
account exchange rate risk. From these results, consistency conditions can be
derived that link the changes in PD and asset correlation and do not require
knowledge of hard-to-estimate parameters like asset value volatility.
</summary>
    <author>
      <name>Dirk Tasche</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/0712.3363v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0712.3363v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B28; 62P05" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0802.4141v2</id>
    <updated>2010-03-19T07:16:08Z</updated>
    <published>2008-02-28T08:27:49Z</published>
    <title>Good deal bounds induced by shortfall risk</title>
    <summary>  We shall provide in this paper good deal pricing bounds for contingent claims
induced by the shortfall risk with some loss function. Assumptions we impose on
loss functions and contingent claims are very mild. We prove that the upper and
lower bounds of good deal pricing bounds are expressed by convex risk measures
on Orlicz hearts. In addition, we obtain its representation with the minimal
penalty function. Moreover, we give a representation, for two simple cases, of
good deal bounds and calculate the optimal strategies when a claim is traded at
the upper or lower bounds of its good deal pricing bound.
</summary>
    <author>
      <name>Takuji Arai</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper has been withdrawn by the author.</arxiv:comment>
    <link href="http://arxiv.org/abs/0802.4141v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0802.4141v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B28; 46E30" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0803.2283v3</id>
    <updated>2008-04-03T17:13:27Z</updated>
    <published>2008-03-15T10:57:46Z</published>
    <title>Feasibility of Portfolio Optimization under Coherent Risk Measures</title>
    <summary>  It is shown that the axioms for coherent risk measures imply that whenever
there is an asset in a portfolio that dominates the others in a given sample
(which happens with finite probability even for large samples), then this
portfolio cannot be optimized under any coherent measure on that sample, and
the risk measure diverges to minus infinity. This instability was first
discovered on the special example of Expected Shortfall which is used here both
as an illustration and as a prompt for generalization.
</summary>
    <author>
      <name>Imre Kondor</name>
    </author>
    <author>
      <name>Istvan Varga-Haszonits</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0803.2283v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0803.2283v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0804.1642v2</id>
    <updated>2009-10-27T04:39:26Z</updated>
    <published>2008-04-10T08:03:00Z</published>
    <title>Calibration of transparency risks: a note</title>
    <summary>  The aim of this research is to give a simple framework to evaluate/quantize
the "transparency" of a firm. We assume that the process of the firm value is
only observable once in a while but is strongly correlated with the stock price
which is observable and tradable. This hybrid type structure make the
transparency "observable". The implication of the present study is that the
depth of the shock to the market caused by the precise accounting information
does reflect the degree of transparency. Furthermore, it can be quantized
resorting to the calibration method.
</summary>
    <author>
      <name>Jirô Akahori</name>
    </author>
    <author>
      <name>Yuuki Kanishi</name>
    </author>
    <author>
      <name>Yuichi Morimura</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11pages</arxiv:comment>
    <link href="http://arxiv.org/abs/0804.1642v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0804.1642v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0809.4372v1</id>
    <updated>2008-09-25T10:54:01Z</updated>
    <published>2008-09-25T10:54:01Z</published>
    <title>Ruin probabilities under general investments and heavy-tailed claims</title>
    <summary>  In this paper we study the asymptotic decay of finite time ruin probabilities
for an insurance company that faces heavy-tailed claims, uses predictable
investment strategies and makes investments in risky assets whose prices evolve
according to quite general semimartingales. We show that the ruin problem
corresponds to determining hitting probabilities for the solution to a randomly
perturbed stochastic integral equation. We derive a large deviation result for
the hitting probabilities that holds uniformly over a family of semimartingales
and show that this result gives the asymptotic decay of finite time ruin
probabilities under arbitrary investment strategies, including optimal
investment strategies.
</summary>
    <author>
      <name>Henrik Hult</name>
    </author>
    <author>
      <name>Filip Lindskog</name>
    </author>
    <link href="http://arxiv.org/abs/0809.4372v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0809.4372v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="60F10; 60H20" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0901.3318v1</id>
    <updated>2009-01-21T17:16:43Z</updated>
    <published>2009-01-21T17:16:43Z</published>
    <title>Partial Equilibria with Convex Capital Requirements: Existence,
  Uniqueness and Stability</title>
    <summary>  In an incomplete semimartingale model of a financial market, we consider
several risk-averse financial agents who negotiate the price of a bundle of
contingent claims. Assuming that the agents' risk preferences are modelled by
convex capital requirements, we define and analyze their demand functions and
propose a notion of a partial equilibrium price. In addition to sufficient
conditions for the existence and uniqueness, we also show that the equilibrium
prices are stable with respect to misspecifications of agents' risk
preferences.
</summary>
    <author>
      <name>Michail Anthropelos</name>
    </author>
    <author>
      <name>Gordan Zitkovic</name>
    </author>
    <link href="http://arxiv.org/abs/0901.3318v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0901.3318v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0904.1361v1</id>
    <updated>2009-04-08T15:14:42Z</updated>
    <published>2009-04-08T15:14:42Z</published>
    <title>The Quantification of Operational Risk using Internal Data, Relevant
  External Data and Expert Opinions</title>
    <summary>  To quantify an operational risk capital charge under Basel II, many banks
adopt a Loss Distribution Approach. Under this approach, quantification of the
frequency and severity distributions of operational risk involves the bank's
internal data, expert opinions and relevant external data. In this paper we
suggest a new approach, based on a Bayesian inference method, that allows for a
combination of these three sources of information to estimate the parameters of
the risk frequency and severity distributions.
</summary>
    <author>
      <name>Dominik D. Lambrigger</name>
    </author>
    <author>
      <name>Pavel V. Shevchenko</name>
    </author>
    <author>
      <name>Mario V. Wüthrich</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">The Journal of Operational Risk 2(3), pp.3-27, 2007.
  www.journalofoperationalrisk.com</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0904.1361v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0904.1361v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0904.1771v1</id>
    <updated>2009-04-11T02:15:23Z</updated>
    <published>2009-04-11T02:15:23Z</published>
    <title>Estimation of Operational Risk Capital Charge under Parameter
  Uncertainty</title>
    <summary>  Many banks adopt the Loss Distribution Approach to quantify the operational
risk capital charge under Basel II requirements. It is common practice to
estimate the capital charge using the 0.999 quantile of the annual loss
distribution, calculated using point estimators of the frequency and severity
distribution parameters. The uncertainty of the parameter estimates is
typically ignored. One of the unpleasant consequences for the banks accounting
for parameter uncertainty is an increase in the capital requirement. This paper
demonstrates how the parameter uncertainty can be taken into account using a
Bayesian framework that also allows for incorporation of expert opinions and
external data into the estimation procedure.
</summary>
    <author>
      <name>Pavel V. Shevchenko</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">The Journal of Operational Risk 3(1), pp. 51-63, 2008
  www.journalofoperationalrisk.com</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0904.1771v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0904.1771v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0904.1805v2</id>
    <updated>2009-07-29T12:20:44Z</updated>
    <published>2009-04-11T14:56:16Z</published>
    <title>Implementing Loss Distribution Approach for Operational Risk</title>
    <summary>  To quantify the operational risk capital charge under the current regulatory
framework for banking supervision, referred to as Basel II, many banks adopt
the Loss Distribution Approach. There are many modeling issues that should be
resolved to use the approach in practice. In this paper we review the
quantitative methods suggested in literature for implementation of the
approach. In particular, the use of the Bayesian inference method that allows
to take expert judgement and parameter uncertainty into account, modeling
dependence and inclusion of insurance are discussed.
</summary>
    <author>
      <name>Pavel V. Shevchenko</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1002/asmb.812</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1002/asmb.812" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Applied Stochastic Models in Business and Industry (2010), volume
  26 issue 3, pages: 277-307</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0904.1805v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0904.1805v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0904.4620v1</id>
    <updated>2009-04-29T14:22:30Z</updated>
    <published>2009-04-29T14:22:30Z</published>
    <title>Haar Wavelets-Based Approach for Quantifying Credit Portfolio Losses</title>
    <summary>  This paper proposes a new methodology to compute Value at Risk (VaR) for
quantifying losses in credit portfolios. We approximate the cumulative
distribution of the loss function by a finite combination of Haar wavelets
basis functions and calculate the coefficients of the approximation by
inverting its Laplace transform. In fact, we demonstrate that only a few
coefficients of the approximation are needed, so VaR can be reached quickly. To
test the methodology we consider the Vasicek one-factor portfolio credit loss
model as our model framework. The Haar wavelets method is fast, accurate and
robust to deal with small or concentrated portfolios, when the hypothesis of
the Basel II formulas are violated.
</summary>
    <author>
      <name>Josep J. Masdemont</name>
    </author>
    <author>
      <name>Luis Ortiz-Gracia</name>
    </author>
    <link href="http://arxiv.org/abs/0904.4620v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0904.4620v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0907.5600v1</id>
    <updated>2009-07-31T19:41:26Z</updated>
    <published>2009-07-31T19:41:26Z</published>
    <title>Macrostate Parameter, an Econophysics Approach for the Risk Analysis of
  the Stock Exchange Market Transactions</title>
    <summary>  In this paper we attempt to introduce an econophysics approach to evaluate
some aspects of the risks in financial markets. For this purpose, the
thermodynamical methods and statistical physics results about entropy and
equilibrium states in the physical systems are used. Some considerations on
economic value and financial information are made. Finally, on this basis, a
new index for the financial risk estimation of the stock-exchange market
transactions, named macrostate parameter, was introduced and discussed.
  Keywords: econophysics, stock-exchange markets, financial risk, informational
fascicle, entropy, macrostate parameter.
</summary>
    <author>
      <name>Anca Gheorghiu</name>
    </author>
    <author>
      <name>Ion Spanulescu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 6 figures, 25 references</arxiv:comment>
    <link href="http://arxiv.org/abs/0907.5600v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0907.5600v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0911.0223v3</id>
    <updated>2011-07-13T06:34:12Z</updated>
    <published>2009-11-02T01:26:06Z</published>
    <title>Analytical Framework for Credit Portfolios. Part I: Systematic Risk</title>
    <summary>  Analytical, free of time consuming Monte Carlo simulations, framework for
credit portfolio systematic risk metrics calculations is presented. Techniques
are described that allow calculation of portfolio-level systematic risk
measures (standard deviation, VaR and Expected Shortfall) as well as allocation
of risk down to individual transactions. The underlying model is the industry
standard multi-factor Merton-type model with arbitrary valuation function at
horizon (in contrast to the simplistic default-only case). High accuracy of the
proposed analytical technique is demonstrated by benchmarking against Monte
Carlo simulations.
</summary>
    <author>
      <name>Mikhail Voropaev</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Obsolete, see "Analytical Framework for Credit Portfolios" instead</arxiv:comment>
    <link href="http://arxiv.org/abs/0911.0223v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0911.0223v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.CP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0911.3472v1</id>
    <updated>2009-11-18T07:26:00Z</updated>
    <published>2009-11-18T07:26:00Z</published>
    <title>Les Générateurs de Scénarios Économiques : quelle utilisation en
  assurance?</title>
    <summary>  In this paper, we present the principal components of an economic scenario
generator (ESG), both for the theoretical design and for practical
implementation. The choice of these components should be linked to the ultimate
vocation of the economic scenario generator, which can be either a tool for
pricing financial products or a tool for projection and risk management. We
then develop a study on some performance measure indicators of the ESG as an
input for the decision-making process, namely the indicators of stability and
bias absence. Finally, a numerical application illustrates the main ideas of
the paper.
</summary>
    <author>
      <name>Alaeddine Faleh</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">SAF</arxiv:affiliation>
    </author>
    <author>
      <name>Frédéric Planchet</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">SAF</arxiv:affiliation>
    </author>
    <author>
      <name>Didier Rullière</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">SAF</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/0911.3472v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0911.3472v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0911.3802v2</id>
    <updated>2014-01-19T15:49:33Z</updated>
    <published>2009-11-19T14:25:23Z</published>
    <title>A Coupled Markov Chain Approach to Credit Risk Modeling</title>
    <summary>  We propose a Markov chain model for credit rating changes. We do not use any
distributional assumptions on the asset values of the rated companies but
directly model the rating transitions process. The parameters of the model are
estimated by a maximum likelihood approach using historical rating transitions
and heuristic global optimization techniques.
  We benchmark the model against a GLMM model in the context of bond portfolio
risk management. The proposed model yields stronger dependencies and higher
risks than the GLMM model. As a result, the risk optimal portfolios are more
conservative than the decisions resulting from the benchmark model.
</summary>
    <author>
      <name>David Wozabal</name>
    </author>
    <author>
      <name>Ronald Hochreiter</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.jedc.2011.09.011</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.jedc.2011.09.011" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Economic Dynamics and Control 36(3): 403-415. 2012</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0911.3802v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0911.3802v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0912.1396v2</id>
    <updated>2010-07-09T04:57:09Z</updated>
    <published>2009-12-08T03:20:25Z</published>
    <title>Time consistency and moving horizons for risk measures</title>
    <summary>  We consider portfolio selection when decisions based on a dynamic risk
measure are affected by the use of a moving horizon, and the possible
inconsistencies that this creates. By giving a formal treatment of time
consistency which is independent of Bellman's equations, we show that there is
a new sense in which these decisions can be seen as consistent.
</summary>
    <author>
      <name>Samuel N. Cohen</name>
    </author>
    <author>
      <name>Robert J. Elliott</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/0912.1396v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0912.1396v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0912.1841v1</id>
    <updated>2009-12-09T19:13:34Z</updated>
    <published>2009-12-09T19:13:34Z</published>
    <title>A duality approach to the worst case value at risk for a sum of
  dependent random variables with known covariances</title>
    <summary>  We propose an approach to the aggregation of risks which is based on
estimation of simple quantities (such as covariances) associated to a vector of
dependent random variables, and which avoids the use of parametric families of
copulae. Our main result demonstrates that the method leads to bounds on the
worst case Value at Risk for a sum of dependent random variables. Its proof
applies duality theory for infinite dimensional linear programs.
</summary>
    <author>
      <name>Brice Franke</name>
    </author>
    <author>
      <name>Michael Stolz</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/0912.1841v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0912.1841v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91G80, 60E05, 62P05, 90C05" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1001.1908v1</id>
    <updated>2010-01-12T15:40:33Z</updated>
    <published>2010-01-12T15:40:33Z</published>
    <title>Mesure des risques de marché et de souscription vie en situation
  d'information incomplète pour un portefeuille de prévoyance</title>
    <summary>  In the framework of Embedded Value new standards, namely the MCEV norms, the
latest principles published in June 2008 address the issue of market and
underwriting risks measurement by using stochastic models of projection and
valorization. Knowing that stochastic models particularly data-consuming, the
question which can arise is the treatment of insurance portfolios only
available in aggregate data or portfolios in situation of incomplete
information. The aim of this article is to propose a pragmatic modeling of
these risks tied up with death covers of individual protection products in
these situations.
</summary>
    <author>
      <name>Jean-Paul Félix</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">SAF</arxiv:affiliation>
    </author>
    <author>
      <name>Frédéric Planchet</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">SAF</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Bulletin Fran\c{c}ais d'Actuariat 9, 18 (2009) 79...105</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1001.1908v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1001.1908v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1002.3627v1</id>
    <updated>2010-02-19T14:44:22Z</updated>
    <published>2010-02-19T14:44:22Z</published>
    <title>Risk assessment for uncertain cash flows: Model ambiguity, discounting
  ambiguity, and the role of bubbles</title>
    <summary>  We study the risk assessment of uncertain cash flows in terms of dynamic
convex risk measures for processes as introduced in Cheridito, Delbaen, and
Kupper (2006). These risk measures take into account not only the amounts but
also the timing of a cash flow. We discuss their robust representation in terms
of suitably penalized probability measures on the optional sigma-field. This
yields an explicit analysis both of model and discounting ambiguity. We focus
on supermartingale criteria for different notions of time consistency. In
particular we show how bubbles may appear in the dynamic penalization, and how
they cause a breakdown of asymptotic safety of the risk assessment procedure.
</summary>
    <author>
      <name>Beatrice Acciaio</name>
    </author>
    <author>
      <name>Hans Foellmer</name>
    </author>
    <author>
      <name>Irina Penner</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">40 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1002.3627v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1002.3627v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="60G35; 91B30; 91B16" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1003.0709v1</id>
    <updated>2010-03-03T00:08:43Z</updated>
    <published>2010-03-03T00:08:43Z</published>
    <title>Tracking errors from discrete hedging in exponential Lévy models</title>
    <summary>  We analyze the errors arising from discrete readjustment of the hedging
portfolio when hedging options in exponential Levy models, and establish the
rate at which the expected squared error goes to zero when the readjustment
frequency increases. We compare the quadratic hedging strategy with the common
market practice of delta hedging, and show that for discontinuous option
pay-offs the latter strategy may suffer from very large discretization errors.
For options with discontinuous pay-offs, the convergence rate depends on the
underlying Levy process, and we give an explicit relation between the rate and
the Blumenthal-Getoor index of the process.
</summary>
    <author>
      <name>Mats Brodén</name>
    </author>
    <author>
      <name>Peter Tankov</name>
    </author>
    <link href="http://arxiv.org/abs/1003.0709v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1003.0709v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1004.4526v1</id>
    <updated>2010-04-26T13:51:40Z</updated>
    <published>2010-04-26T13:51:40Z</published>
    <title>Hedging Errors Induced by Discrete Trading Under an Adaptive Trading
  Strategy</title>
    <summary>  Discrete time hedging in a complete diffusion market is considered. The hedge
portfolio is rebalanced when the absolute difference between delta of the hedge
portfolio and the derivative contract reaches a threshold level. The rate of
convergence of the expected squared hedging error as the threshold level
approaches zero is analyzed. The results hinge to a great extent on a theorem
stating that the difference between the hedge ratios normalized by the
threshold level tends to a triangular distribution as the threshold level tends
to zero.
</summary>
    <author>
      <name>Mats Brodén</name>
    </author>
    <author>
      <name>Magnus Wiktorsson</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1004.4526v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1004.4526v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="60F25, 60F05, 91B28" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1005.1360v2</id>
    <updated>2010-05-31T10:26:22Z</updated>
    <published>2010-05-09T02:43:45Z</published>
    <title>Optimal dividend and investing control of a insurance company with
  higher solvency constraints</title>
    <summary>  This paper considers optimal control problem of a large insurance company
under a fixed insolvency probability. The company controls proportional
reinsurance rate, dividend pay-outs and investing process to maximize the
expected present value of the dividend pay-outs until the time of bankruptcy.
This paper aims at describing the optimal return function as well as the
optimal policy. As a by-product, the paper theoretically sets a risk-based
capital standard to ensure the capital requirement of can cover the total risk.
</summary>
    <author>
      <name>Zongxia Liang</name>
    </author>
    <author>
      <name>Jianping Huang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">31 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1005.1360v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1005.1360v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B30 (Primary), 91B28, 93E20, 60H10 (Secondary), 60H30, 60H05" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1005.2862v3</id>
    <updated>2011-12-19T11:46:58Z</updated>
    <published>2010-05-17T10:04:52Z</published>
    <title>Multivariate heavy-tailed models for Value-at-Risk estimation</title>
    <summary>  For purposes of Value-at-Risk estimation, we consider several multivariate
families of heavy-tailed distributions, which can be seen as multidimensional
versions of Paretian stable and Student's t distributions allowing different
marginals to have different tail thickness. After a discussion of relevant
estimation and simulation issues, we conduct a backtesting study on a set of
portfolios containing derivative instruments, using historical US stock price
data.
</summary>
    <author>
      <name>Carlo Marinelli</name>
    </author>
    <author>
      <name>Stefano d'Addona</name>
    </author>
    <author>
      <name>Svetlozar T. Rachev</name>
    </author>
    <link href="http://arxiv.org/abs/1005.2862v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1005.2862v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1006.0863v1</id>
    <updated>2010-06-04T11:11:24Z</updated>
    <published>2010-06-04T11:11:24Z</published>
    <title>A Loan Portfolio Model Subject to Random Liabilities and Systemic Jump
  Risk</title>
    <summary>  We extend the Vasi\v{c}ek loan portfolio model to a setting where liabilities
fluctuate randomly and asset values may be subject to systemic jump risk. We
derive the probability distribution of the percentage loss of a uniform
portfolio and analyze its properties. We find that the impact of liability risk
is ambiguous and depends on the correlation between the continuous aggregate
factor and the asset-liability ratio as well as on the default intensity. We
also find that systemic jump risk has a significant impact on the upper
percentiles of the loss distribution and, therefore, on both the VaR-measure as
well as on the expected shortfall.
</summary>
    <author>
      <name>Luis H. R. Alvarez</name>
    </author>
    <author>
      <name>Jani Sainio</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1006.0863v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1006.0863v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1006.2711v2</id>
    <updated>2011-08-09T20:10:32Z</updated>
    <published>2010-06-07T17:27:10Z</published>
    <title>Recovery Rates in investment-grade pools of credit assets: A large
  deviations analysis</title>
    <summary>  We consider the effect of recovery rates on a pool of credit assets. We allow
the recovery rate to depend on the defaults in a general way. Using the theory
of large deviations, we study the structure of losses in a pool consisting of a
continuum of types. We derive the corresponding rate function and show that it
has a natural interpretation as the favored way to rearrange recoveries and
losses among the different types. Numerical examples are also provided.
</summary>
    <author>
      <name>Konstantinos Spiliopoulos</name>
    </author>
    <author>
      <name>Richard B. Sowers</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.spa.2011.08.005</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.spa.2011.08.005" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">27 Pages, 3 Figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Stochastic Processes and their Applications, Volume 121, Issue 12,
  2011, pp. 2861- 2898</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1006.2711v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1006.2711v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="60F05, 60F10 and 91G40" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1007.5433v1</id>
    <updated>2010-07-30T12:55:23Z</updated>
    <published>2010-07-30T12:55:23Z</published>
    <title>Analytical Framework for Credit Portfolios</title>
    <summary>  Analytical, free of time consuming Monte Carlo simulations, framework for
credit portfolio systematic risk metrics calculations is presented. Techniques
are described that allow calculation of portfolio-level systematic risk
measures (standard deviation, VaR and Expected Shortfall) as well as allocation
of risk down to individual transactions. The underlying model is the industry
standard multi-factor Merton-type model with arbitrary valuation function at
horizon (in contrast to the simplistic default-only case). High accuracy of the
proposed analytical technique is demonstrated by benchmarking against Monte
Carlo simulations.
</summary>
    <author>
      <name>Mikhail Voropaev</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1007.5433v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1007.5433v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1009.2896v4</id>
    <updated>2012-06-05T13:26:49Z</updated>
    <published>2010-09-15T10:44:50Z</published>
    <title>On the nature of financial leverage</title>
    <summary>  The article presents a translation of some widespread financial terminology
into the language of decision theory. For instance, financial leverage can be
regarded as an object of choice or a decision. We show how the optics of
decision theory allows perceiving the recently introduced metrics of
see-through-leverage, which proved to be very useful in understanding the
phenomenology of the recent economic crisis. The importance for practical
decision making of specification of the statistical regularity of the random
phenomena at hand as well as of the rationality class of the decision maker is
discussed.
</summary>
    <author>
      <name>Yaroslav Ivanenko</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1009.2896v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1009.2896v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1010.4339v2</id>
    <updated>2011-05-19T22:03:54Z</updated>
    <published>2010-10-20T23:58:00Z</published>
    <title>Dynamic Coherent Acceptability Indices and their Applications to Finance</title>
    <summary>  In this paper we present a theoretical framework for studying coherent
acceptability indices in a dynamic setup. We study dynamic coherent
acceptability indices and dynamic coherent risk measures, and we establish a
duality between them. We derive a representation theorem for dynamic coherent
risk measures in terms of so called dynamically consistent sequence of sets of
probability measures. Based on these results, we give a specific construction
of dynamic coherent acceptability indices. We also provide examples of dynamic
coherent acceptability indices, both abstract and also some that generalize
selected classical financial measures of portfolio performance.
</summary>
    <author>
      <name>Tomasz R. Bielecki</name>
    </author>
    <author>
      <name>Igor Cialenco</name>
    </author>
    <author>
      <name>Zhao Zhang</name>
    </author>
    <link href="http://arxiv.org/abs/1010.4339v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1010.4339v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B30, 60G30, 91B06" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1010.5171v1</id>
    <updated>2010-10-25T15:50:50Z</updated>
    <published>2010-10-25T15:50:50Z</published>
    <title>Ordering of multivariate probability distributions with respect to
  extreme portfolio losses</title>
    <summary>  A new notion of stochastic ordering is introduced to compare multivariate
stochastic risk models with respect to extreme portfolio losses. In the
framework of multivariate regular variation comparison criteria are derived in
terms of ordering conditions on the spectral measures, which allows for
analytical or numerical verification in practical applications. Additional
comparison criteria in terms of further stochastic orderings are derived. The
application examples include worst case and best case scenarios, elliptically
contoured distributions, and multivariate regularly varying models with Gumbel,
Archimedean, and Galambos copulas.
</summary>
    <author>
      <name>Georg Mainik</name>
    </author>
    <author>
      <name>Ludger Rüschendorf</name>
    </author>
    <link href="http://arxiv.org/abs/1010.5171v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1010.5171v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1011.5986v1</id>
    <updated>2010-11-27T17:27:02Z</updated>
    <published>2010-11-27T17:27:02Z</published>
    <title>Set-valued risk measures for conical market models</title>
    <summary>  Set-valued risk measures on $L^p_d$ with $0 \leq p \leq \infty$ for conical
market models are defined, primal and dual representation results are given.
The collection of initial endowments which allow to super-hedge a multivariate
claim are shown to form the values of a set-valued sublinear (coherent) risk
measure. Scalar risk measures with multiple eligible assets also turn out to be
a special case within the set-valued framework.
</summary>
    <author>
      <name>Andreas H. Hamel</name>
    </author>
    <author>
      <name>Frank Heyde</name>
    </author>
    <author>
      <name>Birgit Rudloff</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Mathematics and Financial Economics 5 (1), 1 - 28, (2011)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1011.5986v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1011.5986v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B30, 46A20, 46N10, 26E25" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.5408v1</id>
    <updated>2011-03-28T16:32:15Z</updated>
    <published>2011-03-28T16:32:15Z</published>
    <title>Spectral Risk Measures with an Application to Futures Clearinghouse
  Variation Margin Requirements</title>
    <summary>  This paper applies an AR(1)-GARCH (1, 1) process to detail the conditional
distributions of the return distributions for the S&amp;P500, FT100, DAX, Hang
Seng, and Nikkei225 futures contracts. It then uses the conditional
distribution for these contracts to estimate spectral risk measures, which are
coherent risk measures that reflect a user's risk-aversion function. It
compares these to more familiar VaR and Expected Shortfall (ES) measures of
risk, and also compares the precision and discusses the relative usefulness of
each of these risk measures in setting variation margins that incorporate
time-varying market conditions. The goodness of fit of the model is confirmed
by a variety of backtests.
</summary>
    <author>
      <name>John Cotter</name>
    </author>
    <author>
      <name>Kevin Dowd</name>
    </author>
    <link href="http://arxiv.org/abs/1103.5408v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.5408v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.5409v1</id>
    <updated>2011-03-28T16:36:10Z</updated>
    <published>2011-03-28T16:36:10Z</published>
    <title>Exponential Spectral Risk Measures</title>
    <summary>  Spectral risk measures are attractive risk measures as they allow the user to
obtain risk measures that reflect their subjective risk-aversion. This paper
examines spectral risk measures based on an exponential utility function, and
finds that these risk measures have nice intuitive properties. It also
discusses how they can be estimated using numerical quadrature methods, and how
confidence intervals for them can be estimated using a parametric bootstrap.
Illustrative results suggest that estimated exponential spectral risk measures
obtained using such methods are quite precise in the presence of normally
distributed losses.
</summary>
    <author>
      <name>Kevin Dowd</name>
    </author>
    <author>
      <name>John Cotter</name>
    </author>
    <link href="http://arxiv.org/abs/1103.5409v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.5409v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.5416v1</id>
    <updated>2011-03-28T16:46:54Z</updated>
    <published>2011-03-28T16:46:54Z</published>
    <title>Minimum Capital Requirement Calculations for UK Futures</title>
    <summary>  Key to the imposition of appropriate minimum capital requirements on a daily
basis requires accurate volatility estimation. Here, measures are presented
based on discrete estimation of aggregated high frequency UK futures
realisations underpinned by a continuous time framework. Squared and absolute
returns are incorporated into the measurement process so as to rely on the
quadratic variation of a diffusion process and be robust in the presence of fat
tails. The realized volatility estimates incorporate the long memory property.
The dynamics of the volatility variable are adequately captured. Resulting
rescaled returns are applied to minimum capital requirement calculations.
</summary>
    <author>
      <name>John Cotter</name>
    </author>
    <link href="http://arxiv.org/abs/1103.5416v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.5416v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.TR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.5418v1</id>
    <updated>2011-03-28T16:53:24Z</updated>
    <published>2011-03-28T16:53:24Z</published>
    <title>Tail Behaviour of the Euro</title>
    <summary>  This paper empirically analyses risk in the Euro relative to other
currencies. Comparisons are made between a sub period encompassing the final
transitional stage to full monetary union with a sub period prior to this.
Stability in the face of speculative attack is examined using Extreme Value
Theory to obtain estimates of tail exchange rate changes. The findings are
encouraging. The Euro's common risk measures do not deviate substantially from
other currencies. Also, the Euro is stable in the face of speculative pressure.
For example, the findings consistently show the Euro being less risky than the
Yen, and having similar inherent risk to the Deutsche Mark, the currency that
it is essentially replacing.
</summary>
    <author>
      <name>John Cotter</name>
    </author>
    <link href="http://arxiv.org/abs/1103.5418v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.5418v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.5649v1</id>
    <updated>2011-03-29T14:21:27Z</updated>
    <published>2011-03-29T14:21:27Z</published>
    <title>Varying the VaR for Unconditional and Conditional Environments</title>
    <summary>  Accurate forecasting of risk is the key to successful risk management
techniques. Using the largest stock index futures from twelve European bourses,
this paper presents VaR measures based on their unconditional and conditional
distributions for single and multi-period settings. These measures underpinned
by extreme value theory are statistically robust explicitly allowing for
fat-tailed densities. Conditional tail estimates are obtained by adjusting the
unconditional extreme value procedure with GARCH filtered returns. The
conditional modelling results in iid returns allowing for the use of a simple
and efficient multi-period extreme value scaling law. The paper examines the
properties of these distinct conditional and unconditional trading models. The
paper finds that the biases inherent in unconditional single and multi-period
estimates assuming normality extend to the conditional setting.
</summary>
    <author>
      <name>John Cotter</name>
    </author>
    <link href="http://arxiv.org/abs/1103.5649v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.5649v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.5653v1</id>
    <updated>2011-03-29T14:28:19Z</updated>
    <published>2011-03-29T14:28:19Z</published>
    <title>Extreme Spectral Risk Measures: An Application to Futures Clearinghouse
  Margin Requirements</title>
    <summary>  This paper applies the Extreme-Value (EV) Generalised Pareto distribution to
the extreme tails of the return distributions for the S&amp;P500, FT100, DAX, Hang
Seng, and Nikkei225 futures contracts. It then uses tail estimators from these
contracts to estimate spectral risk measures, which are coherent risk measures
that reflect a user's risk-aversion function. It compares these to VaR and
Expected Shortfall (ES) risk measures, and compares the precision of their
estimators. It also discusses the usefulness of these risk measures in the
context of clearinghouses setting initial margin requirements, and compares
these to the SPAN measures typically used. Keywords: Spectral risk measures,
Expected Shortfall, Value at Risk, Extreme Value
</summary>
    <author>
      <name>John Cotter</name>
    </author>
    <author>
      <name>Kevin Dowd</name>
    </author>
    <link href="http://arxiv.org/abs/1103.5653v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.5653v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.5665v1</id>
    <updated>2011-03-29T14:45:40Z</updated>
    <published>2011-03-29T14:45:40Z</published>
    <title>Evaluating the Precision of Estimators of Quantile-Based Risk Measures</title>
    <summary>  This paper examines the precision of estimators of Quantile-Based Risk
Measures (Value at Risk, Expected Shortfall, Spectral Risk Measures). It first
addresses the question of how to estimate the precision of these estimators,
and proposes a Monte Carlo method that is free of some of the limitations of
existing approaches. It then investigates the distribution of risk estimators,
and presents simulation results suggesting that the common practice of relying
on asymptotic normality results might be unreliable with the sample sizes
commonly available to them. Finally, it investigates the relationship between
the precision of different risk estimators and the distribution of underlying
losses (or returns), and yields a number of useful conclusions.
</summary>
    <author>
      <name>Kevin Dowd</name>
    </author>
    <author>
      <name>John Cotter</name>
    </author>
    <link href="http://arxiv.org/abs/1103.5665v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.5665v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.5666v1</id>
    <updated>2011-03-29T14:47:36Z</updated>
    <published>2011-03-29T14:47:36Z</published>
    <title>Estimating financial risk measures for futures positions: a
  non-parametric approach</title>
    <summary>  This paper presents non-parametric estimates of spectral risk measures
applied to long and short positions in 5 prominent equity futures contracts. It
also compares these to estimates of two popular alternative measures, the
Value-at-Risk (VaR) and Expected Shortfall (ES). The spectral risk measures are
conditioned on the coefficient of absolute risk aversion, and the latter two
are conditioned on the confidence level. Our findings indicate that all risk
measures increase dramatically and their estimators deteriorate in precision
when their respective conditioning parameter increases. Results also suggest
that estimates of spectral risk measures and their precision levels are of
comparable orders of magnitude as those of more conventional risk measures.
Running head: financial risk measures for futures positions
</summary>
    <author>
      <name>john cotter</name>
    </author>
    <author>
      <name>kevin dowd</name>
    </author>
    <link href="http://arxiv.org/abs/1103.5666v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.5666v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.5668v1</id>
    <updated>2011-03-29T14:52:40Z</updated>
    <published>2011-03-29T14:52:40Z</published>
    <title>Spectral Risk Measures and the Choice of Risk Aversion Function</title>
    <summary>  Spectral risk measures are attractive risk measures as they allow the user to
obtain risk measures that reflect their risk-aversion functions. To date there
has been very little guidance on the choice of risk-aversion functions
underlying spectral risk measures. This paper addresses this issue by examining
two popular risk aversion functions, based on exponential and power utility
functions respectively. We find that the former yields spectral risk measures
with nice intuitive properties, but the latter yields spectral risk measures
that can have perverse properties. More work therefore needs to be done before
we can be sure that arbitrary but respectable utility functions will always
yield 'well-behaved' spectral risk measures.
</summary>
    <author>
      <name>kevin dowd</name>
    </author>
    <author>
      <name>john cotter</name>
    </author>
    <link href="http://arxiv.org/abs/1103.5668v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.5668v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.5674v1</id>
    <updated>2011-03-29T15:01:34Z</updated>
    <published>2011-03-29T15:01:34Z</published>
    <title>Spectral Risk Measures: Properties and Limitations</title>
    <summary>  Spectral risk measures (SRMs) are risk measures that take account of user
riskaversion, but to date there has been little guidance on the choice of
utility function underlying them. This paper addresses this issue by examining
alternative approaches based on exponential and power utility functions. A
number of problems are identified with both types of spectral risk measure. The
general lesson is that users of spectral risk measures must be careful to
select utility functions that fit the features of the particular problems they
are dealing with, and should be especially careful when using power SRMs.
</summary>
    <author>
      <name>Kevin Dowd</name>
    </author>
    <author>
      <name>John Cotter</name>
    </author>
    <author>
      <name>Ghulam Sorwar</name>
    </author>
    <link href="http://arxiv.org/abs/1103.5674v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.5674v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.5966v1</id>
    <updated>2011-03-30T15:50:28Z</updated>
    <published>2011-03-30T15:50:28Z</published>
    <title>Hedging: Scaling and the Investor Horizon</title>
    <summary>  This paper examines the volatility and covariance dynamics of cash and
futures contracts that underlie the Optimal Hedge Ratio (OHR) across different
hedging time horizons. We examine whether hedge ratios calculated over a short
term hedging horizon can be scaled and successfully applied to longer term
horizons. We also test the equivalence of scaled hedge ratios with those
calculated directly from lower frequency data and compare them in terms of
hedging effectiveness. Our findings show that the volatility and covariance
dynamics may differ considerably depending on the hedging horizon and this
gives rise to significant differences between short term and longer term
hedges. Despite this, scaling provides good hedging outcomes in terms of risk
reduction which are comparable to those based on direct estimation.
</summary>
    <author>
      <name>John Cotter</name>
    </author>
    <author>
      <name>Jim Hanly</name>
    </author>
    <link href="http://arxiv.org/abs/1103.5966v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.5966v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.5973v1</id>
    <updated>2011-03-30T16:00:40Z</updated>
    <published>2011-03-30T16:00:40Z</published>
    <title>A Utility Based Approach to Energy Hedging</title>
    <summary>  A key issue in the estimation of energy hedges is the hedgers' attitude
towards risk which is encapsulated in the form of the hedgers' utility
function. However, the literature typically uses only one form of utility
function such as the quadratic when estimating hedges. This paper addresses
this issue by estimating and applying energy market based risk aversion to
commonly applied utility functions including log, exponential and quadratic,
and we incorporate these in our hedging frameworks. We find significant
differences in the optimal hedge strategies based on the utility function
chosen.
</summary>
    <author>
      <name>John Cotter</name>
    </author>
    <author>
      <name>Jim Hanly</name>
    </author>
    <link href="http://arxiv.org/abs/1103.5973v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.5973v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.5978v1</id>
    <updated>2011-03-30T16:09:27Z</updated>
    <published>2011-03-30T16:09:27Z</published>
    <title>Financial Risks and the Pension Protection Fund: Can it Survive Them?</title>
    <summary>  This paper discusses the financial risks faced by the UK Pension Protection
Fund (PPF) and what, if anything, it can do about them. It draws lessons from
the regulatory regimes under which other financial institutions, such as banks
and insurance companies, operate and asks why pension funds are treated
differently. It also reviews the experience with other government-sponsored
insurance schemes, such as the US Pension Benefit Guaranty Corporation, upon
which the PPF is modelled. We conclude that the PPF will live under the
permanent risk of insolvency as a consequence of the moral hazard, adverse
selection, and, especially, systemic risks that it faces.
</summary>
    <author>
      <name>David Blake</name>
    </author>
    <author>
      <name>John Cotter</name>
    </author>
    <author>
      <name>Kevin Dowd</name>
    </author>
    <link href="http://arxiv.org/abs/1103.5978v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.5978v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1104.0508v1</id>
    <updated>2011-04-04T09:40:30Z</updated>
    <published>2011-04-04T09:40:30Z</published>
    <title>Concave Distortion Semigroups</title>
    <summary>  The problem behind this paper is the proper measurement of the degree of
quality/acceptability/distance to arbitrage of trades. We are narrowing the
class of coherent acceptability indices introduced by Cherny and Madan (2007)
by imposing an additional mathematical property. For this, we introduce the
notion of a concave distortion semigroup as a family $(\Psi_t)_{t\ge0}$ of
concave increasing functions $[0,1]\to[0,1]$ satisfying the semigroup property
$$ \Psi_s\circ\Psi_t=\Psi_{s+t},\quad s,t\ge0. $$ The goal of the paper is the
investigation of these semigroups with regard to the following aspects:
representation of distortion semigroups; properties of distortion semigroups
desirable from the economical or mathematical perspective; determining which
concave distortions belong to some distortion semigroup.
</summary>
    <author>
      <name>Alexander Cherny</name>
    </author>
    <author>
      <name>Damir Filipović</name>
    </author>
    <link href="http://arxiv.org/abs/1104.0508v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1104.0508v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1105.5717v1</id>
    <updated>2011-05-28T13:35:11Z</updated>
    <published>2011-05-28T13:35:11Z</published>
    <title>Is there a bubble in LinkedIn's stock price?</title>
    <summary>  Recent academic work has developed a method to determine, in real time, if a
given stock is exhibiting a price bubble. Currently there is speculation in the
financial press concerning the existence of a price bubble in the aftermath of
the recent IPO of LinkedIn. We analyze stock price tick data from the short
lifetime of this stock through May 24, 2011, and we find that LinkedIn has a
price bubble.
</summary>
    <author>
      <name>Robert Jarrow</name>
    </author>
    <author>
      <name>Younes Kchia</name>
    </author>
    <author>
      <name>Philip Protter</name>
    </author>
    <link href="http://arxiv.org/abs/1105.5717v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1105.5717v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1107.2562v2</id>
    <updated>2012-01-02T18:38:33Z</updated>
    <published>2011-07-13T14:43:23Z</published>
    <title>Quantum Financial Economics - Risk and Returns</title>
    <summary>  Financial volatility risk and its relation to a business cycle-related
intrinsic time is addressed through a multiple round evolutionary quantum game
equilibrium leading to turbulence and multifractal signatures in the financial
returns and in the risk dynamics. The model is simulated and the results are
compared with actual financial volatility data.
</summary>
    <author>
      <name>Carlos Pedro Gonçalves</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages; 5 figures; Based on talk given at the conference "As
  Ci\^encias Sociais: Abordagens de Investiga\c{c}\~ao" (Lisbon, 2011)</arxiv:comment>
    <link href="http://arxiv.org/abs/1107.2562v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1107.2562v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91A22, 91G80, 82C27, 82C10" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1109.0706v1</id>
    <updated>2011-09-04T12:06:13Z</updated>
    <published>2011-09-04T12:06:13Z</published>
    <title>Losing money with a high Sharpe ratio</title>
    <summary>  A simple example shows that losing all money is compatible with a very high
Sharpe ratio (as computed after losing all money). However, the only way that
the Sharpe ratio can be high while losing money is that there is a period in
which all or almost all money is lost. This note explores the best achievable
Sharpe and Sortino ratios for investors who lose money but whose one-period
returns are bounded below (or both below and above) by a known constant.
</summary>
    <author>
      <name>Vladimir Vovk</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1109.0706v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1109.0706v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91G10" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1110.4516v1</id>
    <updated>2011-10-20T13:00:33Z</updated>
    <published>2011-10-20T13:00:33Z</published>
    <title>Calculating Variable Annuity Liability 'Greeks' Using Monte Carlo
  Simulation</title>
    <summary>  Hedging methods to mitigate the exposure of variable annuity products to
market risks require the calculation of market risk sensitivities (or
"Greeks"). The complex, path-dependent nature of these products means these
sensitivities typically must be estimated by Monte Carlo simulation. Standard
market practice is to measure such sensitivities using a "bump and revalue"
method. As well as requiring multiple valuations, such approaches can be
unreliable for higher order Greeks, e.g., gamma. In this article we investigate
alternative estimators implemented within an advanced economic scenario
generator model, incorporating stochastic interest-rates and stochastic equity
volatility. The estimators can also be easily generalized to work with the
addition of equity jumps in this model.
</summary>
    <author>
      <name>Mark J. Cathcart</name>
    </author>
    <author>
      <name>Steven Morrison</name>
    </author>
    <author>
      <name>Alexander J. McNeil</name>
    </author>
    <link href="http://arxiv.org/abs/1110.4516v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1110.4516v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.CP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.4414v1</id>
    <updated>2011-11-18T16:29:31Z</updated>
    <published>2011-11-18T16:29:31Z</published>
    <title>On the Necessity of Five Risk Measures</title>
    <summary>  The banking systems that deal with risk management depend on underlying risk
measures. Following the Basel II accord, there are two separate methods by
which banks may determine their capital requirement. The Value at Risk measure
plays an important role in computing the capital for both approaches. In this
paper we analyze the errors produced by using this measure. We discuss other
measures, demonstrating their strengths and shortcomings. We give examples,
showing the need for the information from multiple risk measures in order to
determine a bank's loss distribution. We conclude by suggesting a regulatory
requirement of multiple risk measures being reported by banks, giving specific
recommendations.
</summary>
    <author>
      <name>Dominique Guégan</name>
    </author>
    <author>
      <name>Wayne Tarrant</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">23 pages, 9 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1111.4414v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.4414v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.4417v1</id>
    <updated>2011-11-18T16:38:22Z</updated>
    <published>2011-11-18T16:38:22Z</published>
    <title>Viewing Risk Measures as Information</title>
    <summary>  Regulation and risk management in banks depend on underlying risk measures.
In general this is the only purpose that is seen for risk measures. In this
paper we suggest that the reporting of risk measures can be used to determine
the loss distribution function for a financial entity. We demonstrate that a
lack of sufficient information can lead to ambiguous risk situations. We give
examples, showing the need for the reporting of multiple risk measures in order
to determine a bank's loss distribution. We conclude by suggesting a regulatory
requirement of multiple risk measures being reported by banks, giving specific
recommendations.
</summary>
    <author>
      <name>Dominique Gu/'egan</name>
    </author>
    <author>
      <name>Wayne Tarrant</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 9 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1111.4417v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.4417v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1112.2889v1</id>
    <updated>2011-12-13T13:48:23Z</updated>
    <published>2011-12-13T13:48:23Z</published>
    <title>Estimating financial risk using piecewise Gaussian processes</title>
    <summary>  We present a computational method for measuring financial risk by estimating
the Value at Risk and Expected Shortfall from financial series. We have made
two assumptions: First, that the predictive distributions of the values of an
asset are conditioned by information on the way in which the variable evolves
from similar conditions, and secondly, that the underlying random processes can
be described using piecewise Gaussian processes. The performance of the method
was evaluated by using it to estimate VaR and ES for a daily data series taken
from the S&amp;P500 index and applying a backtesting procedure recommended by the
Basel Committee on Banking Supervision. The results indicated a satisfactory
performance.
</summary>
    <author>
      <name>I. Garcia</name>
    </author>
    <author>
      <name>J. Jimenez</name>
    </author>
    <link href="http://arxiv.org/abs/1112.2889v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1112.2889v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1201.0967v2</id>
    <updated>2012-05-23T19:38:36Z</updated>
    <published>2012-01-04T19:11:11Z</published>
    <title>Real Output Costs of Financial Crises: A Loss Distribution Approach</title>
    <summary>  We study cross-country GDP losses due to financial crises in terms of
frequency (number of loss events per period) and severity (loss per
occurrence). We perform the Loss Distribution Approach (LDA) to estimate a
multi-country aggregate GDP loss probability density function and the
percentiles associated to extreme events due to financial crises.
  We find that output losses arising from financial crises are strongly
heterogeneous and that currency crises lead to smaller output losses than debt
and banking crises.
  Extreme global financial crises episodes, occurring with a one percent
probability every five years, lead to losses between 2.95% and 4.54% of world
GDP.
</summary>
    <author>
      <name>Daniel Kapp</name>
    </author>
    <author>
      <name>Marco Vega</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">31 pages, 10 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1201.0967v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1201.0967v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1201.1783v2</id>
    <updated>2012-09-19T08:50:46Z</updated>
    <published>2012-01-09T14:42:25Z</published>
    <title>A Goal Programming Model with Satisfaction Function for Risk Management
  and Optimal Portfolio Diversification</title>
    <summary>  We extend the classical risk minimization model with scalar risk measures to
the general case of set-valued risk measures. The problem we obtain is a
set-valued optimization model and we propose a goal programming-based approach
with satisfaction function to obtain a solution which represents the best
compromise between goals and the achievement levels. Numerical examples are
provided to illustrate how the method works in practical situations.
</summary>
    <author>
      <name>Davide La Torre</name>
    </author>
    <author>
      <name>Marco Maggis</name>
    </author>
    <link href="http://arxiv.org/abs/1201.1783v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1201.1783v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1201.2257v4</id>
    <updated>2012-09-06T11:01:35Z</updated>
    <published>2012-01-11T08:19:43Z</published>
    <title>Risk Measures on $\mathcal{P}(\mathbb{R})$ and Value At Risk with
  Probability/Loss function</title>
    <summary>  We propose a generalization of the classical notion of the $V@R_{\lambda}$
that takes into account not only the probability of the losses, but the balance
between such probability and the amount of the loss. This is obtained by
defining a new class of law invariant risk measures based on an appropriate
family of acceptance sets. The $V@R_{\lambda}$ and other known law invariant
risk measures turn out to be special cases of our proposal. We further prove
the dual representation of Risk Measures on $\mathcal{P}(% \mathbb{R}).$
</summary>
    <author>
      <name>Marco Frittelli</name>
    </author>
    <author>
      <name>Marco Maggis</name>
    </author>
    <author>
      <name>Ilaria Peri</name>
    </author>
    <link href="http://arxiv.org/abs/1201.2257v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1201.2257v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.5702v2</id>
    <updated>2013-01-11T15:11:25Z</updated>
    <published>2012-02-25T22:28:39Z</published>
    <title>Set-valued average value at risk and its computation</title>
    <summary>  New versions of the set-valued average value at risk for multivariate risks
are introduced by generalizing the well-known certainty equivalent
representation to the set-valued case. The first "regulator" version is
independent from any market model whereas the second version, called the market
extension, takes trading opportunities into account. Essential properties of
both versions are proven and an algorithmic approach is provided which admits
to compute the values of both version over finite probability spaces. Several
examples illustrate various features of the theoretical constructions.
</summary>
    <author>
      <name>Andreas H. Hamel</name>
    </author>
    <author>
      <name>Birgit Rudloff</name>
    </author>
    <author>
      <name>Mihaela Yankova</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Mathematics and Financial Economics 7 (2), 229-246, (2013)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1202.5702v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.5702v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.CP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B30, 46N10, 26E25, 46A20" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1203.3031v1</id>
    <updated>2012-03-14T09:35:50Z</updated>
    <published>2012-03-14T09:35:50Z</published>
    <title>Using Decision Tree Learner to Classify Solvency Position for Thai
  Non-life Insurance Companies</title>
    <summary>  This paper introduces a Decision Tree Learner as an early warning system for
classification of the non-life insurance companies according to their financial
solid as strong, moderate, weak, or insolvency. In this study, we ran several
experiments to show that the proposed model can achieve a good result using
standard 10 fold crossvalidation, split train and test data set, and separated
test set. The results show that the method is effective and can accurately
classify the solvency position.
</summary>
    <author>
      <name>Phaiboon Jhongpita</name>
    </author>
    <author>
      <name>Sukree Sinthupinyo</name>
    </author>
    <author>
      <name>Thitivadee Chaiyawat</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of the Computer, the Internet and Management
  Vol. 19. No.3 (September-December, 2011) pp 41 -46</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1203.3031v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1203.3031v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1203.6424v2</id>
    <updated>2012-04-20T04:00:36Z</updated>
    <published>2012-03-29T04:22:43Z</published>
    <title>Ordinal Classification Method for the Evaluation Of Thai Non-life
  Insurance Companies</title>
    <summary>  This paper proposes a use of an ordinal classifier to evaluate the financial
solidity of non-life insurance companies as strong, moderate, weak, and
insolvency. This study constructed an efficient classification model that can
be used by regulators to evaluate the financial solidity and to determine the
priority of further examination as an early warning system. The proposed model
is beneficial to policy-makers to create guidelines for the solvency
regulations and roles of the government in protecting the public against
insolvency.
</summary>
    <author>
      <name>Phaiboon Jhonpita</name>
    </author>
    <author>
      <name>Sukree Sinthupinyo</name>
    </author>
    <author>
      <name>Thitivadee Chaiyawat</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IJCSI Volume 9, Issue 1, January 2012
  http://www.ijcsi.org/articles/Ordinal-classification-method-for-the-evaluation-of-thai-nonlife-insurance-companies.php</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1203.6424v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1203.6424v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.5369v2</id>
    <updated>2012-05-25T09:37:01Z</updated>
    <published>2012-05-24T08:51:35Z</published>
    <title>Two Models of Stochastic Loss Given Default</title>
    <summary>  We propose two structural models for stochastic losses given default which
allow to model the credit losses of a portfolio of defaultable financial
instruments. The credit losses are integrated into a structural model of
default events accounting for correlations between the default events and the
associated losses. We show how the models can be calibrated and analyze the
impact of correlations between the occurrences of defaults and recoveries by
testing our models for a representative sample portfolio.
</summary>
    <author>
      <name>Simone Farinelli</name>
    </author>
    <author>
      <name>Mykhaylo Shkolnikov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Problems with figures in preceeding version has been solved</arxiv:comment>
    <link href="http://arxiv.org/abs/1205.5369v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.5369v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.6186v1</id>
    <updated>2012-07-26T07:28:22Z</updated>
    <published>2012-07-26T07:28:22Z</published>
    <title>A Dynamical Model for Operational Risk in Banks</title>
    <summary>  Operational risk is the risk relative to monetary losses caused by failures
of bank internal processes due to heterogeneous causes. A dynamical model
including both spontaneous generation of losses and generation via interactions
between different processes is presented; the efforts made by the bank to avoid
the occurrence of losses is also taken into account. Under certain hypotheses,
the model can be exactly solved and, in principle, the solution can be
exploited to estimate most of the model parameters from real data. The
forecasting power of the model is also investigated and proved to be
surprisingly remarkable.
</summary>
    <author>
      <name>Marco Bardoscia</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.3254/978-1-61499-071-0-399</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.3254/978-1-61499-071-0-399" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 2 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the International School of Physics "Enrico Fermi"
  176 (2012), pp. 399-403</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1207.6186v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.6186v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.6759v1</id>
    <updated>2012-07-29T09:21:20Z</updated>
    <published>2012-07-29T09:21:20Z</published>
    <title>Computing Quantiles in Regime-Switching Jump-Diffusions with Application
  to Optimal Risk Management: a Fourier Transform Approach</title>
    <summary>  In this paper we consider the problem of calculating the quantiles of a risky
position, the dynamic of which is described as a continuous time
regime-switching jump-diffusion, by using Fourier Transform methods.
Furthermore, we study a classical option-based portfolio strategy which
minimizes the Value-at-Risk of the hedged position and show the impact of jumps
and switching regimes on the optimal strategy in a numerical example. However,
the analysis of this hedging strategy, as well as the computational technique
for its implementation, is fairly general, i.e. it can be applied to any
dynamical model for which Fourier transform methods are viable.
</summary>
    <author>
      <name>Alessandro Ramponi</name>
    </author>
    <link href="http://arxiv.org/abs/1207.6759v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.6759v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.CP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91G60, 91B30, 91G20, 60J75" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1208.5303v1</id>
    <updated>2012-08-27T07:01:40Z</updated>
    <published>2012-08-27T07:01:40Z</published>
    <title>Hedging Swing contract on gas markets</title>
    <summary>  Swing options on the gas market are american style option where daily
quantities exercices are constrained and global quantities exerciced each year
constrained too. The option holder has to decide each day how much he consumes
of the quantities satisfying the constraints and tries to use a strategy in
order to maximize its expected profit. The pay off fonction is a spread between
the spot gas market and the value of an index composed of the past average of
some commodities spot or future prices. We study the valorization and the
effectiveness of the dynamic hedging of such a contract.
</summary>
    <author>
      <name>Xavier Warin</name>
    </author>
    <link href="http://arxiv.org/abs/1208.5303v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1208.5303v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.4173v1</id>
    <updated>2012-11-17T23:33:33Z</updated>
    <published>2012-11-17T23:33:33Z</published>
    <title>Closed form solutions of measures of systemic risk</title>
    <summary>  This paper derives -- considering a Gaussian setting -- closed form solutions
of the statistics that Adrian and Brunnermeier and Acharya et al. have
suggested as measures of systemic risk to be attached to individual banks. The
statistics equal the product of statistic specific Beta-coefficients with the
mean corrected Value at Risk. Hence, the measures of systemic risks are closely
related to well known concepts of financial economics. Another benefit of the
analysis is that it is revealed how the concepts are related to each other.
Also, it may be relatively easy to convince the regulators to consider a closed
form solution, especially so if the statistics involved are well known and can
easily be communicated to the financial community.
</summary>
    <author>
      <name>Manfred Jaeger-Ambrozewicz</name>
    </author>
    <link href="http://arxiv.org/abs/1211.4173v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.4173v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B30, 91G70, 62P20" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.0092v1</id>
    <updated>2012-12-01T10:55:05Z</updated>
    <published>2012-12-01T10:55:05Z</published>
    <title>Parameter estimation of a Levy copula of a discretely observed bivariate
  compound Poisson process with an application to operational risk modelling</title>
    <summary>  A method is developed to estimate the parameters of a Levy copula of a
discretely observed bivariate compound Poisson process without knowledge of
common shocks. The method is tested in a small sample simulation study. Also,
the method is applied to a real data set and a goodness of fit test is
developed. With the methodology of this work, the Levy copula becomes a
realistic tool of the advanced measurement approach of operational risk.
</summary>
    <author>
      <name>J. L. van Velsen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">25 pages including 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1212.0092v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.0092v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.6732v4</id>
    <updated>2013-12-13T10:42:11Z</updated>
    <published>2012-12-30T15:36:46Z</published>
    <title>A Fourier Approach to the Computation of CV@R and Optimized Certainty
  Equivalents</title>
    <summary>  We consider the class of risk measures associated with optimized certainty
equivalents. This class includes several popular examples, such as CV@R and
monotone mean-variance. Numerical schemes are developed for the computation of
these risk measures using Fourier transform methods. This leads, in particular,
to a very competitive method for the calculation of CV@R which is comparable in
computational time to the calculation of V@R. We also develop methods for the
efficient computation of risk contributions.
</summary>
    <author>
      <name>Samuel Drapeau</name>
    </author>
    <author>
      <name>Michael Kupper</name>
    </author>
    <author>
      <name>Antonis Papapantoleon</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Risk 16(6), 3-29, 2014</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1212.6732v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.6732v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.CP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91G60 91B30" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.0186v1</id>
    <updated>2013-01-02T08:35:33Z</updated>
    <published>2013-01-02T08:35:33Z</published>
    <title>On Infectious Model for Dependent Defaults</title>
    <summary>  In this paper, we propose a two-sector Markovian infectious model, which is
an extension of Greenwood's model. The central idea of this model is that the
causality of defaults of two sectors is in both direction, which enrich
dependence dynamics. The Bayesian Information Criterion is adopted to compare
the proposed model with the two-sector model in credit literature using the
real data. We find that the newly proposed model is statistically better than
the model in past literature. We also introduce two measures: CRES and CRVaR to
give risk evaluation of our model.
</summary>
    <author>
      <name>Jia-Wen Gu</name>
    </author>
    <author>
      <name>Wai-Ki Ching</name>
    </author>
    <author>
      <name>Tak-Kuen Siu</name>
    </author>
    <author>
      <name>Harry Zheng</name>
    </author>
    <link href="http://arxiv.org/abs/1301.0186v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.0186v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.CP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.1471v1</id>
    <updated>2013-01-08T10:17:52Z</updated>
    <published>2013-01-08T10:17:52Z</published>
    <title>The Foster-Hart Measure of Riskiness for General Gambles</title>
    <summary>  Foster and Hart proposed an operational measure of riskiness for discrete
random variables. We show that their defining equation has no solution for many
common continuous distributions including many uniform distributions, e.g. We
show how to extend consistently the definition of riskiness to continuous
random variables. For many continuous random variables, the risk measure is
equal to the worst--case risk measure, i.e. the maximal possible loss incurred
by that gamble. We also extend the Foster--Hart risk measure to dynamic
environments for general distributions and probability spaces, and we show that
the extended measure avoids bankruptcy in infinitely repeated gambles.
</summary>
    <author>
      <name>Frank Riedel</name>
    </author>
    <author>
      <name>Tobias Hellmann</name>
    </author>
    <link href="http://arxiv.org/abs/1301.1471v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.1471v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.4832v1</id>
    <updated>2013-01-21T12:02:30Z</updated>
    <published>2013-01-21T12:02:30Z</published>
    <title>Measuring Model Risk</title>
    <summary>  We propose to interpret distribution model risk as sensitivity of expected
loss to changes in the risk factor distribution, and to measure the
distribution model risk of a portfolio by the maximum expected loss over a set
of plausible distributions defined in terms of some divergence from an
estimated distribution. The divergence may be relative entropy, a Bregman
distance, or an $f$-divergence. We give formulas for the calculation of
distribution model risk and explicitly determine the worst case distribution
from the set of plausible distributions. We also give formulas for the
evaluation of divergence preferences describing ambiguity averse decision
makers.
</summary>
    <author>
      <name>Thomas Breuer</name>
    </author>
    <author>
      <name>Imre Csiszar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">30 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1301.4832v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.4832v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1302.4595v1</id>
    <updated>2013-02-19T12:58:26Z</updated>
    <published>2013-02-19T12:58:26Z</published>
    <title>Collateral-Enhanced Default Risk</title>
    <summary>  Changes in collateralization have been implicated in significant default (or
near-default) events during the financial crisis, most notably with AIG. We
have developed a framework for quantifying this effect based on moving between
Merton-type and Black-Cox-type structural default models. Our framework leads
to a single equation that emcompasses the range of possibilities, including
collateralization remargining frequency (i.e. discrete observations). We show
that increases in collateralization, by exposing entities to daily
mark-to-market volatility, enhance default probability. This quantifies the
well-known problem with collateral triggers. Furthermore our model can be used
to quantify the degree to which central counterparties, whilst removing credit
risk transmission, systematically increase default risk.
</summary>
    <author>
      <name>Chris Kenyon</name>
    </author>
    <author>
      <name>Andrew Green</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages; 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1302.4595v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1302.4595v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91G20, 91B30, 91B74, 91G40, 91G50, 91B55" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1303.1672v1</id>
    <updated>2013-03-07T13:00:59Z</updated>
    <published>2013-03-07T13:00:59Z</published>
    <title>A new approach for an unitary risk theory</title>
    <summary>  The work deals with the risk assessment theory. An unitary risk algorithm is
elaborated. The algorithm is based on parallel curves. The basic curve of risk
is a hyperbolic curve, obtained as a multiplication between the probability of
occurrence of certain event and its impact. Section 1 contains the problem
formulation. Section 2 contains some specific notations and the mathematical
background of risk algorithm. A numerical application based on risk algorithm
is the content of section 3. Section 4 contains several conclusions.
</summary>
    <author>
      <name>Nicolae Popoviciu</name>
    </author>
    <author>
      <name>Floarea Baicu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 2 figures, 1 table, 3 references</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. of the WSEAS Int. Conf. on Signal Processing, Computational
  Geometry and Artificial Vision, Athena, Grece, aug. 2007, pp. 218-222, ISSN
  1790-5117, ISBN 978-960-8457-97-3</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1303.1672v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1303.1672v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.1940v3</id>
    <updated>2014-10-14T22:35:11Z</updated>
    <published>2013-04-06T21:56:33Z</published>
    <title>Ruin Probabilities for Risk Processes with Non-Stationary Arrivals and
  Subexponential Claims</title>
    <summary>  In this paper, we obtain the finite-horizon and infinite-horizon ruin
probability asymptotics for risk processes with claims of subexponential tails
for non-stationary arrival processes that satisfy a large deviation principle.
As a result, the arrival process can be dependent, non-stationary and
non-renewal. We give three examples of non-stationary and non-renewal point
processes: Hawkes process, Cox process with shot noise intensity and
self-correcting point process. We also show some aggregate claims results for
these three examples.
</summary>
    <author>
      <name>Lingjiong Zhu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Insurance: Mathematics and Economics 2013, Volume 53, Issue 3,
  544-550</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1304.1940v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.1940v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B30, 60G55, 60F10" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.7882v1</id>
    <updated>2013-04-30T05:27:44Z</updated>
    <published>2013-04-30T05:27:44Z</published>
    <title>Mean-Variance Asset-Liability Management with State-Dependent Risk
  Aversion</title>
    <summary>  In this paper, we consider the asset-liability management under the
mean-variance criterion. The financial market consists of a risk-free bond and
a stock whose price process is modeled by a geometric Brownian motion. The
liability of the investor is uncontrollable and is modeled by another geometric
Brownian motion. We consider a specific state-dependent risk aversion which
depends on a power function of the liability. By solving a flow of FBSDEs with
bivariate state process, we obtain the equilibrium strategy among all the
open-loop controls for this time-inconsistent control problem. It shows that
the equilibrium strategy is a feedback control of the liability.
</summary>
    <author>
      <name>Qian Zhao</name>
    </author>
    <author>
      <name>Jiaqin Wei</name>
    </author>
    <author>
      <name>Rongming Wang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1304.7882v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.7882v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1305.2151v3</id>
    <updated>2015-01-29T08:37:37Z</updated>
    <published>2013-05-09T17:25:33Z</published>
    <title>A comparison of techniques for dynamic multivariate risk measures</title>
    <summary>  This paper contains an overview of results for dynamic multivariate risk
measures. We provide the main results of four different approaches. We will
prove under which assumptions results within these approaches coincide, and how
properties like primal and dual representation and time consistency in the
different approaches compare to each other.
</summary>
    <author>
      <name>Zachary Feinstein</name>
    </author>
    <author>
      <name>Birgit Rudloff</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">In: A. Hamel, F. Heyde, A. L{\"o}hne, B. Rudloff, C. Schrage
  (eds.): Set Optimization and Applications in Finance - The State of the Art,
  Springer PROMS series, Vol. 151, 3-41, (2015). ISBN: 978-3-662-48668-9</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1305.2151v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1305.2151v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B30, 46N10, 26E25" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1305.5238v1</id>
    <updated>2013-05-22T19:15:11Z</updated>
    <published>2013-05-22T19:15:11Z</published>
    <title>Risk Measure Estimation On Fiegarch Processes</title>
    <summary>  We consider the Fractionally Integrated Exponential Generalized
Autoregressive Conditional Heteroskedasticity process, denoted by
FIEGARCH(p,d,q), introduced by Bollerslev and Mikkelsen (1996). We present a
simulated study regarding the estimation of the risk measure $VaR_p$ on
FIEGARCH processes. We consider the distribution function of the portfolio
log-returns (univariate case) and the multivariate distribution function of the
risk-factor changes (multivariate case). We also compare the performance of the
risk measures $VaR_p$, $ES_p$ and MaxLoss for a portfolio composed by stocks of
four Brazilian companies.
</summary>
    <author>
      <name>Taiane S. Prass</name>
    </author>
    <author>
      <name>Sílvia R. C. Lopes</name>
    </author>
    <link href="http://arxiv.org/abs/1305.5238v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1305.5238v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1305.6762v1</id>
    <updated>2013-05-29T11:53:15Z</updated>
    <published>2013-05-29T11:53:15Z</published>
    <title>Hedging without sweat: a genetic programming approach</title>
    <summary>  Hedging in the presence of transaction costs leads to complex optimization
problems. These problems typically lack closed-form solutions, and their
implementation relies on numerical methods that provide hedging strategies for
specific parameter values. In this paper we use a genetic programming algorithm
to derive explicit formulas for near-optimal hedging strategies under nonlinear
transaction costs. The strategies are valid over a large range of parameter
values and require no information about the structure of the optimal hedging
strategy.
</summary>
    <author>
      <name>Terje Lensberg</name>
    </author>
    <author>
      <name>Klaus Reiner Schenk-Hoppé</name>
    </author>
    <link href="http://arxiv.org/abs/1305.6762v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1305.6762v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1306.3531v1</id>
    <updated>2013-06-14T23:57:54Z</updated>
    <published>2013-06-14T23:57:54Z</published>
    <title>The convergence of regional house prices in the USA in the context of
  the stress testing of financial institutions</title>
    <summary>  I studied the convergence of regional house prices to national prices in USA
by analyzing time-series of house price indices of 9 Census Divisions. I found
the evidence of the convergence in some parts of the country using asymmetric
unit root tests. The fact that the evidence of the convergence is not present
in large parts of the country raises an issue of execution and interpretation
of results of Federal Reserve Bank's annual stress testing of the US banking
system.
</summary>
    <author>
      <name>Argyn Kuketayev</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">38 pages, 7 tables, 30 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1306.3531v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1306.3531v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B84" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.0684v2</id>
    <updated>2013-07-10T12:41:06Z</updated>
    <published>2013-07-02T11:19:56Z</published>
    <title>Assessing Financial Model Risk</title>
    <summary>  Model risk has a huge impact on any risk measurement procedure and its
quantification is therefore a crucial step. In this paper, we introduce three
quantitative measures of model risk when choosing a particular reference model
within a given class: the absolute measure of model risk, the relative measure
of model risk and the local measure of model risk. Each of the measures has a
specific purpose and so allows for flexibility. We illustrate the various
notions by studying some relevant examples, so as to emphasize the
practicability and tractability of our approach.
</summary>
    <author>
      <name>Pauline Barrieu</name>
    </author>
    <author>
      <name>Giacomo Scandolo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">23 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1307.0684v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.0684v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91G99" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.6695v2</id>
    <updated>2013-07-29T00:58:55Z</updated>
    <published>2013-07-25T10:56:16Z</published>
    <title>Where Do Thin Tails Come From?</title>
    <summary>  The literature of heavy tails (typically) starts with a random walk and finds
mechanisms that lead to fat tails under aggregation. We follow the inverse
route and show how starting with fat tails we get to thin-tails when deriving
the probability distribution of the response to a random variable. We introduce
a general dose-response curve and argue that the left and right-boundedness or
saturation of the response in natural things leads to thin-tails, even when the
"underlying" random variable at the source of the exposure is fat-tailed.
</summary>
    <author>
      <name>Nassim Nicholas Taleb</name>
    </author>
    <link href="http://arxiv.org/abs/1307.6695v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.6695v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.8020v2</id>
    <updated>2013-07-31T10:35:34Z</updated>
    <published>2013-07-30T15:47:28Z</published>
    <title>Systematic and non-systematic mortality risk in pension portfolios</title>
    <summary>  We study the effects of non-systematic and systematic mortality risks on the
required initial capital in a pension plan, in the presence of financial risks.
We discover that for a pension plan with few members the impact of pooling on
the required capital per person is strong, but non-systematic risk diminishes
rapidly as the number of members increases. Systematic mortality risk, on the
other hand, is a significant source of risk is a pension portfolio.
</summary>
    <author>
      <name>Helena Aro</name>
    </author>
    <link href="http://arxiv.org/abs/1307.8020v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.8020v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.CP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.8261v1</id>
    <updated>2013-07-31T09:47:10Z</updated>
    <published>2013-07-31T09:47:10Z</published>
    <title>Liability-driven investment in longevity risk management</title>
    <summary>  This paper studies optimal investment from the point of view of an investor
with longevity-linked liabilities. The relevant optimization problems rarely
are analytically tractable, but we are able to show numerically that liability
driven investment can significantly outperform common strategies that do not
take the liabilities into account. In problems without liabilities the
advantage disappears, which suggests that the superiority of the proposed
strategies is indeed based on connections between liabilities and asset
returns.
</summary>
    <author>
      <name>Helena Aro</name>
    </author>
    <author>
      <name>Teemu Pennanen</name>
    </author>
    <link href="http://arxiv.org/abs/1307.8261v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.8261v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.CP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1309.5094v1</id>
    <updated>2013-09-19T20:15:30Z</updated>
    <published>2013-09-19T20:15:30Z</published>
    <title>Hedging under multiple risk constraints</title>
    <summary>  Motivated by the asset-liability management of a nuclear power plant
operator, we consider the problem of finding the least expensive portfolio,
which outperforms a given set of stochastic benchmarks. For a specified loss
function, the expected shortfall with respect to each of the benchmarks
weighted by this loss function must remain bounded by a given threshold. We
consider different alternative formulations of this problem in a complete
market setting, establish the relationship between these formulations, present
a general resolution methodology via dynamic programming in a non-Markovian
context and give explicit solutions in special cases.
</summary>
    <author>
      <name>Ying Jiao</name>
    </author>
    <author>
      <name>Olivier Klopfenstein</name>
    </author>
    <author>
      <name>Peter Tankov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">29 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1309.5094v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1309.5094v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.7128v1</id>
    <updated>2013-10-26T16:44:03Z</updated>
    <published>2013-10-26T16:44:03Z</published>
    <title>Restructuring the "one-way CSA" counterparty risk in a CDO</title>
    <summary>  We show how to restructure the counterparty risk faced by the originator of a
securitization or covered bond arising from an interest rate hedging swap
assisted by a "one-way" collateral agreement. This risk emerges when the swap
is negotiated between the special purpose vehicle and a third party that covers
itself through a back-to-back swap with the originator. We show that the
counterparty risk of the originator may be removed by adding a chain of
back-to-back credit derivatives between the three parties (originator,
counterparty and vehicle).
</summary>
    <author>
      <name>Lorenzo Giada</name>
    </author>
    <author>
      <name>Claudio Nordio</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1310.7128v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.7128v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B99" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1311.0354v1</id>
    <updated>2013-11-02T07:41:56Z</updated>
    <published>2013-11-02T07:41:56Z</published>
    <title>On the Capital Allocation Problem for a New Coherent Risk Measure in
  Collective Risk Theory</title>
    <summary>  In this paper we introduce a new coherent cumulative risk measure on
$\mathcal{R}_L^p$, the space of c\`adl\`ag processes having Laplace transform.
This new coherent risk measure turns out to be tractable enough within a class
of models where the aggregate claims is driven by a spectrally positive L\'evy
process. Moreover, we study the problem of capital allocation in an insurance
context and we show that the capital allocation problem for this risk measure
has a unique solution determined by the Euler allocation method. Some examples
are provided.
</summary>
    <author>
      <name>Assa Hirbod</name>
    </author>
    <author>
      <name>Morales Manuel</name>
    </author>
    <author>
      <name>Omidi Firouzi Hassan</name>
    </author>
    <link href="http://arxiv.org/abs/1311.0354v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1311.0354v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1312.6804v2</id>
    <updated>2014-04-24T05:13:30Z</updated>
    <published>2013-12-24T12:17:12Z</published>
    <title>A model of financial contagion with variable asset returns may be
  replaced with a simple threshold model of cascades</title>
    <summary>  I show the equivalence between a model of financial contagion and the
threshold model of global cascades proposed by Watts (2002). The model
financial network comprises banks that hold risky external assets as well as
interbank assets. It is shown that a simple threshold model can replicate the
size and the frequency of financial contagion without using information about
individual balance sheets. Keywords: financial network, cascades, financial
contagion, systemic risk.
</summary>
    <author>
      <name>Teruyoshi Kobayashi</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.econlet.2014.05.003</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.econlet.2014.05.003" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, including 2 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Economics Letters 124, 113-116, 2014</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1312.6804v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1312.6804v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1401.3589v2</id>
    <updated>2014-08-26T11:11:45Z</updated>
    <published>2014-01-15T13:57:05Z</published>
    <title>Risk aggregation and stochastic claims reserving in disability insurance</title>
    <summary>  We consider a large, homogeneous portfolio of life or disability annuity
policies. The policies are assumed to be independent conditional on an external
stochastic process representing the economic-demographic environment. Using a
conditional law of large numbers, we establish the connection between claims
reserving and risk aggregation for large portfolios. Further, we derive a
partial differential equation for moments of present values. Moreover, we show
how statistical multi-factor intensity models can be approximated by one-factor
models, which allows for solving the PDEs very efficiently. Finally, we give a
numerical example where moments of present values of disability annuities are
computed using finite difference methods and Monte Carlo simulations.
</summary>
    <author>
      <name>Boualem Djehiche</name>
    </author>
    <author>
      <name>Björn Löfdahl</name>
    </author>
    <link href="http://arxiv.org/abs/1401.3589v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1401.3589v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1402.3560v2</id>
    <updated>2014-03-07T05:47:06Z</updated>
    <published>2014-02-14T19:44:41Z</published>
    <title>Optimal Investment and Risk Control Problem for an Insurer: Expected
  Utility Maximization</title>
    <summary>  Motivated by the AIG bailout case in the financial crisis of 2007-2008, we
consider an insurer who wants to maximize the expected utility of the terminal
wealth by selecting optimal investment and risk control strategies. The
insurer's risk process is modelled by a jump-diffusion process and is
negatively correlated with the capital gains in the financial market. We obtain
explicit solution to optimal strategies for various utility functions.
</summary>
    <author>
      <name>Bin Zou</name>
    </author>
    <author>
      <name>Abel Cadenillas</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">27 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1402.3560v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1402.3560v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.0732v1</id>
    <updated>2014-05-04T18:55:09Z</updated>
    <published>2014-05-04T18:55:09Z</published>
    <title>Hedging of equity-linked with maximal success factor</title>
    <summary>  We consider an equity-linked contract whose payoff depends on the lifetime of
policy holder and the stock price. We assume the limited capital for hedging
and we provide with the best strategy for an insurance company in the meaning
of so called succes factor $\IE^\IP\left[{\mathbf 1}_{\{V_T \geq D)}+{\mathbf
1}_{\{V_T &lt; D\}}\frac{V_T}{D}\right ]$, where $V_T$ denotes the end value of
strategy and $D$ is the payoff of the contract. The work is a genaralisation of
the work of F\"{o}llmer and Schied \cite{FS2004} and Klusik and Palmowski
\cite{KluPal}, but it considers much more general "incompletness" of the
market, among others midterm nonmarket information signals and infitite
nonmarket scenarios.
</summary>
    <author>
      <name>Klusik Przemyslaw</name>
    </author>
    <link href="http://arxiv.org/abs/1405.0732v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.0732v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.1309v3</id>
    <updated>2015-08-21T18:15:32Z</updated>
    <published>2014-05-06T15:19:46Z</published>
    <title>Default Probability Estimation via Pair Copula Constructions</title>
    <summary>  In this paper we present a novel approach for firm default probability
estimation. The methodology is based on multivariate contingent claim analysis
and pair copula constructions. For each considered firm, balance sheet data are
used to assess the asset value, and to compute its default probability. The
asset pricing function is expressed via a pair copula construction, and it is
approximated via Monte Carlo simulations. The methodology is illustrated
through an application to the analysis of both operative and defaulted firms.
</summary>
    <author>
      <name>Luciana Dalla Valle</name>
    </author>
    <author>
      <name>Maria Elena De Giuli</name>
    </author>
    <author>
      <name>Claudia Tarantola</name>
    </author>
    <author>
      <name>Claudio Manelli</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">40 pages, 11 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1405.1309v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.1309v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.3769v2</id>
    <updated>2014-05-24T11:53:59Z</updated>
    <published>2014-05-15T08:49:57Z</published>
    <title>Distortion Risk Measures and Elicitability</title>
    <summary>  We discuss equivalent axiomatic characterizations of distortion risk
measures, and give a novel and concise proof of the characterization of
elicitable distortion risk measures. Elicitability has recently been discussed
as a desirable criterion for risk measures, motivated by statistical
considerations of forecasting. We reveal the mathematical conflict between the
requirements of elicitability and comonotonic additivity which intuitively
explains why only Value-at-Risk and the mean are elicitable distortion risk
measures in a general sense.
</summary>
    <author>
      <name>Ruodu Wang</name>
    </author>
    <author>
      <name>Johanna F. Ziegel</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The paper has been withdrawn by the authors because it is not
  properly written to be cited by the research community</arxiv:comment>
    <link href="http://arxiv.org/abs/1405.3769v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.3769v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.MF" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1406.2950v1</id>
    <updated>2014-06-11T16:09:15Z</updated>
    <published>2014-06-11T16:09:15Z</published>
    <title>On Optimal Reinsurance Policy with Distortion Risk Measures and Premiums</title>
    <summary>  In this paper, we consider the problem of optimal reinsurance design, when
the risk is measured by a distortion risk measure and the premium is given by a
distortion risk premium. First, we show how the optimal reinsurance design for
the ceding company, the reinsurance company and the social planner can be
formulated in the same way. Second, by introducing the marginal indemnification
functions, we characterize the optimal reinsurance contracts. We show that, for
an optimal policy, the associated marginal indemnification function only takes
the values zero and one. We will see how the roles of the market preferences
and premiums and that of the total risk are separated.
</summary>
    <author>
      <name>Hirbod Assa</name>
    </author>
    <link href="http://arxiv.org/abs/1406.2950v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1406.2950v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1406.6575v1</id>
    <updated>2014-06-25T14:05:51Z</updated>
    <published>2014-06-25T14:05:51Z</published>
    <title>Systemic risk through contagion in a core-periphery structured banking
  network</title>
    <summary>  We contribute to the understanding of how systemic risk arises in a network
of credit-interlinked agents. Motivated by empirical studies we formulate a
network model which, despite its simplicity, depicts the nature of interbank
markets better than a homogeneous model. The components of a vector
Ornstein-Uhlenbeck process living on the vertices of the network describe the
financial robustnesses of the agents. For this system, we prove a LLN for
growing network size leading to a propagation of chaos result. We state
properties, which arise from such a structure, and examine the effect of
inhomogeneity on several risk management issues and the possibility of
contagion.
</summary>
    <author>
      <name>Oliver Kley</name>
    </author>
    <author>
      <name>Claudia Klüppelberg</name>
    </author>
    <author>
      <name>Lukas Reichel</name>
    </author>
    <link href="http://arxiv.org/abs/1406.6575v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1406.6575v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="60K35, 60H30, 91B30" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1406.7775v1</id>
    <updated>2014-06-30T15:32:00Z</updated>
    <published>2014-06-30T15:32:00Z</published>
    <title>A two-stage model for dealing with temporal degradation of credit
  scoring</title>
    <summary>  This work is attached to the BRICS 2013 competition. We propose a two-stage
model for dealing with the temporal degradation of credit scoring models. This
methodology produced motivating results in a 1-year horizon. We anticipate that
it can be extended to other applications of risk assessment with great success.
Future extensions should cover predictions in larger time frames and consider
lagged periods. This methodology can be further improved if more information
about the economic cycles is integrated in the forecasting of default.
</summary>
    <author>
      <name>Maria Rocha Sousa</name>
    </author>
    <author>
      <name>João Gama</name>
    </author>
    <author>
      <name>Manuel J. Silva Gonçalves</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1406.7775v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1406.7775v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1407.1072v1</id>
    <updated>2014-07-03T21:54:17Z</updated>
    <published>2014-07-03T21:54:17Z</published>
    <title>On a Transform Method for the Efficient Computation of Conditional VaR
  (and VaR) with Application to Loss Models with Jumps and Stochastic
  Volatility</title>
    <summary>  In this paper we consider Fourier transform techniques to efficiently compute
the Value-at-Risk and the Conditional Value-at-Risk of an arbitrary loss random
variable, characterized by having a computable generalized characteristic
function. We exploit the property of these risk measures of being the solution
of an elementary optimization problem of convex type in one dimension for which
Fast and Fractional Fourier transform can be implemented. An application to
univariate loss models driven by L\'{e}vy or stochastic volatility risk factors
dynamic is finally reported.
</summary>
    <author>
      <name>Alessandro Ramponi</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s11009-015-9446-7</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s11009-015-9446-7" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">23 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1407.1072v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1407.1072v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91G60, 91B30, 60E10" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1408.3086v1</id>
    <updated>2014-08-03T15:19:19Z</updated>
    <published>2014-08-03T15:19:19Z</published>
    <title>Downturn LGD: A More Conservative Approach for Economic Decline Periods</title>
    <summary>  The purpose of this paper is to identify a relevant statistical correlation
between rate of default, RD, and loss given default, LGD, in a major Brazilian
financial institution Retail Home Equity exposure rated using the IRB approach,
so that we may find a causal relationship between the two risk parameters.
Therefore, according to Central Bank of Brazil requirements, a methodology is
applied to add conservatism to the estimation of the Loss Given Default
parameter at times of economic decline, reflected as increased rates of
default.
</summary>
    <author>
      <name>Mauro R. Oliveira</name>
    </author>
    <author>
      <name>Armando Chinelatto Neto</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Revista Tecnologia de Cr\'edito, Edi\c{c}\~ao 86, Editora Serasa
  Experian, 2014 pages 42-51</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1408.3086v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1408.3086v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1408.4618v3</id>
    <updated>2015-02-23T19:28:15Z</updated>
    <published>2014-08-20T11:55:04Z</published>
    <title>Diversification and Endogenous Financial Networks</title>
    <summary>  We test the hypothesis that interconnections across financial institutions
can be explained by a diversification motive. This idea stems from the
empirical evidence of the existence of long-term exposures that cannot be
explained by a liquidity motive (maturity or currency mismatch). We model
endogenous interconnections of heterogenous financial institutions facing
regulatory constraints using a maximization of their expected utility. Both
theoretical and simulation-based results are compared to a stylized genuine
financial network. The diversification motive appears to plausibly explain
interconnections among key players. Using our model, the impact of regulation
on interconnections between banks -currently discussed at the Basel Committee
on Banking Supervision- is analyzed.
</summary>
    <author>
      <name>Jean-Cyprien Héam</name>
    </author>
    <author>
      <name>Erwan Koch</name>
    </author>
    <link href="http://arxiv.org/abs/1408.4618v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1408.4618v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1409.2661v1</id>
    <updated>2014-09-09T10:19:25Z</updated>
    <published>2014-09-09T10:19:25Z</published>
    <title>The effect of the number of states on the validity of credit ratings</title>
    <summary>  We explicitly test if the reliability of credit ratings depends on the total
number of admissible states. We analyse open access credit rating data and show
that the effect of the number of states in the dynamical properties of ratings
change with time, thus giving supportive evidence that the ideal number of
admissible states changes with time. We use matrix estimation methods that
explicitly assume the hypothesis needed for the process to be a valid rating
process. By comparing with the likelihood maximization method of matrix
estimation, we quantify the "likelihood-loss" of assuming that the process is a
well grounded rating process.
</summary>
    <author>
      <name>P. Lencastre</name>
    </author>
    <author>
      <name>F. Raischel</name>
    </author>
    <author>
      <name>P. G. Lind</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1088/1742-6596/574/1/012151</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1088/1742-6596/574/1/012151" rel="related"/>
    <link href="http://arxiv.org/abs/1409.2661v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1409.2661v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1409.7933v1</id>
    <updated>2014-09-28T17:10:20Z</updated>
    <published>2014-09-28T17:10:20Z</published>
    <title>Parametric Risk Parity</title>
    <summary>  Any optimization algorithm based on the risk parity approach requires the
formulation of portfolio total risk in terms of marginal contributions. In this
paper we use the independence of the underlying factors in the market to derive
the centered moments required in the risk decomposition process when the
modified versions of Value at Risk and Expected Shortfall are considered.
  The choice of the Mixed Tempered Stable distribution seems adequate for
fitting skewed and heavy tailed distributions. The ensuing detailed description
of the optimization procedure is due to the existence of analytical higher
order moments. Better results are achieved in terms of out of sample
performance and greater diversification.
</summary>
    <author>
      <name>Lorenzo Mercuri</name>
    </author>
    <author>
      <name>Edit Rroji</name>
    </author>
    <link href="http://arxiv.org/abs/1409.7933v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1409.7933v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.OT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.4847v1</id>
    <updated>2014-09-30T08:06:53Z</updated>
    <published>2014-09-30T08:06:53Z</published>
    <title>Impact of shadow banks on financial contagion</title>
    <summary>  An asset network systemic risk (ANWSER) model is presented to investigate the
impact of how shadow banks are intermingled in a financial system on the
severity of financial contagion. Particularly, the focus of this study is the
impact of the following three representative topologies of an interbank loan
network between shadow banks and regulated banks. (1) Random mixing network:
shadow banks and regulated banks are intermingled randomly. (2)
Asset-correlated mixing network: banks having bigger assets are a regulated
bank and other banks are shadow banks. (3) Layered mixing network: banks in a
shadow bank layer are connected to banks in a regulated bank layer with some
interbank loans.
</summary>
    <author>
      <name>Yoshiharu Maeno</name>
    </author>
    <author>
      <name>Kenji Nishiguchi</name>
    </author>
    <author>
      <name>Satoshi Morinaga</name>
    </author>
    <author>
      <name>Hirokazu Matsushima</name>
    </author>
    <link href="http://arxiv.org/abs/1410.4847v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.4847v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.7845v1</id>
    <updated>2014-10-29T00:44:12Z</updated>
    <published>2014-10-29T00:44:12Z</published>
    <title>A new multivariate dependence measure based on comonotonicity</title>
    <summary>  In this paper we introduce a new multivariate dependence measure based on
comonotonicity by means of product moment which motivated by the recent papers
of Koch and Schepper (ASTIN Bulletin 41 (2011) 191-213) and Dhaene et al.
(Journal of Computational and Applied Mathematics 263 (2014) 78-87). Some
differences and relations between the new dependence measure and other
multivariate measures are an- alyzed. We also give several characteristics of
this measure and estimations based on the definitions and its property are
presented.
</summary>
    <author>
      <name>Ying Zhang</name>
    </author>
    <author>
      <name>Chuancun Yin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1410.7845v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.7845v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1411.0426v1</id>
    <updated>2014-11-03T11:12:51Z</updated>
    <published>2014-11-03T11:12:51Z</published>
    <title>Risk measures with the CxLS property</title>
    <summary>  In the present contribution we characterize law determined convex risk
measures that have convex level sets at the level of distributions. By relaxing
the assumptions in Weber (2006), we show that these risk measures can be
identified with a class of generalized shortfall risk measures. As a direct
consequence, we are able to extend the results in Ziegel (2014) and Bellini and
Bignozzi (2014) on convex elicitable risk measures and confirm that expectiles
are the only elicitable coherent risk measures. Further, we provide a simple
characterization of robustness for convex risk measures in terms of a weak
notion of mixture continuity.
</summary>
    <author>
      <name>Freddy Delbaen</name>
    </author>
    <author>
      <name>Fabio Bellini</name>
    </author>
    <author>
      <name>Valeria Bignozzi</name>
    </author>
    <author>
      <name>Johanna F. Ziegel</name>
    </author>
    <link href="http://arxiv.org/abs/1411.0426v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1411.0426v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1411.1348v1</id>
    <updated>2014-11-05T18:19:30Z</updated>
    <published>2014-11-05T18:19:30Z</published>
    <title>Modelling cross-border systemic risk in the European banking sector: a
  copula approach</title>
    <summary>  We propose a new methodology based on the Marshall-Olkin (MO) copula to model
cross-border systemic risk. The proposed framework estimates the impact of the
systematic and idiosyncratic components on systemic risk. Initially, we propose
a maximum-likelihood method to estimate the parameter of the MO copula. In
order to use the data on non-distressed banks for these estimates, we consider
times to bank failures as censored samples. Hence, we propose an estimation
procedure for the MO copula on censored data. The empirical evidence from
European banks shows that the proposed censored model avoid possible
underestimation of the contagion risk.
</summary>
    <author>
      <name>Raffaella Calabrese</name>
    </author>
    <author>
      <name>Silvia Osmetti</name>
    </author>
    <link href="http://arxiv.org/abs/1411.1348v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1411.1348v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1411.4441v4</id>
    <updated>2014-12-24T09:48:12Z</updated>
    <published>2014-11-17T11:44:12Z</published>
    <title>On the Coherent Risk Measure Representations in the Discrete Probability
  Spaces</title>
    <summary>  We give a complete characterization of both comonotone and not comonotone
coherent risk measures in the discrete finite probability space, where each
outcome is equally likely. To the best of our knowledge, this is the first work
that characterizes \textit{and} distinguishes comonotone and not comonotone
coherent risk measures via a simplified AVaR representation in this probability
space, which is crucial in applications and simulations.
</summary>
    <author>
      <name>Kerem Ugurlu</name>
    </author>
    <link href="http://arxiv.org/abs/1411.4441v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1411.4441v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.03986v1</id>
    <updated>2015-03-13T08:50:17Z</updated>
    <published>2015-03-13T08:50:17Z</published>
    <title>Measuring switching processes in financial markets with the
  Mean-Variance spin glass approach</title>
    <summary>  In this article we use the Mean-Variance Model in order to measure the
current market state. In our study we take the approach of detecting the
overall alignment of portfolios in the spin picture. The projection to the
ground-states enables us to use physical observables in order to describe the
current state of the explored market. The defined magnetization of portfolios
shows cursor effects, which we use to detect turmoils.
</summary>
    <author>
      <name>Jan Jurczyk</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1503.03986v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.03986v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.07152v3</id>
    <updated>2017-02-18T00:39:29Z</updated>
    <published>2015-04-27T16:34:59Z</published>
    <title>Dynamic Interaction Between Asset Prices and Bank Behavior: A Systemic
  Risk Perspective</title>
    <summary>  Systemic risk in banking systems remains a crucial issue that it has not been
completely understood. In our toy model, banks are exposed to two sources of
risks, namely, market risk from their investments in assets external to the
banking system and credit risk from their lending in the interbank market. By
and large, both risks increase during severe financial turmoil. Under this
scenario, the paper shows the conditions under which both the individual and
the systemic default tend to coincide.
</summary>
    <author>
      <name>Aki-Hiro Sato</name>
    </author>
    <author>
      <name>Paolo Tasca</name>
    </author>
    <author>
      <name>Takashi Isogai</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">26 pages, 35 figures, 21st Computing in Economics and Finance
  (CEF2015)</arxiv:comment>
    <link href="http://arxiv.org/abs/1504.07152v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.07152v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.CP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.07805v2</id>
    <updated>2015-05-11T15:36:01Z</updated>
    <published>2015-04-29T10:53:07Z</published>
    <title>Operational risk modeled analytically II: the consequences of
  classification invariance</title>
    <summary>  Most of the banks' operational risk internal models are based on loss pooling
in risk and business line categories. The parameters and outputs of operational
risk models are sensitive to the pooling of the data and the choice of the risk
classification. In a simple model, we establish the link between the number of
risk cells and the model parameters by requiring invariance of the bank's loss
distribution upon a change in classification. We provide details on the impact
of this requirement on the domain of attraction of the loss distribution, on
diversification effects and on cell risk correlations.
</summary>
    <author>
      <name>Vivien Brunel</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1504.07805v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.07805v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.00288v2</id>
    <updated>2015-11-10T17:20:57Z</updated>
    <published>2015-05-01T22:01:50Z</published>
    <title>New copulas based on general partitions-of-unity and their applications
  to risk management</title>
    <summary>  We construct new multivariate copulas on the basis of a generalized infinite
partition-of-unity approach. This approach allows - in contrast to finite
partition-of-unity copulas - for tail-dependence as well as for asymmetry. A
possibility of fitting such copulas to real data from quantitative risk
management is also pointed out.
</summary>
    <author>
      <name>Dietmar Pfeifer</name>
    </author>
    <author>
      <name>Hervé Awoumlac Tsatedem</name>
    </author>
    <author>
      <name>Andreas Mändle</name>
    </author>
    <author>
      <name>Côme Girschig</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1515/demo-2016-0006</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1515/demo-2016-0006" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">22 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">http://dx.doi.org/10.1515/demo-2016-0006</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1505.00288v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.00288v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="60E99, 62H05, 62H20, 62P05, 91G99" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.02281v2</id>
    <updated>2015-12-25T00:59:40Z</updated>
    <published>2015-05-09T14:50:27Z</published>
    <title>Improved Algorithms for Computing Worst Value-at-Risk: Numerical
  Challenges and the Adaptive Rearrangement Algorithm</title>
    <summary>  Numerical challenges inherent in algorithms for computing worst Value-at-Risk
in homogeneous portfolios are identified and solutions as well as words of
warning concerning their implementation are provided. Furthermore, both
conceptual and computational improvements to the Rearrangement Algorithm for
approximating worst Value-at-Risk for portfolios with arbitrary marginal loss
distributions are given. In particular, a novel Adaptive Rearrangement
Algorithm is introduced and investigated. These algorithms are implemented
using the R package qrmtools.
</summary>
    <author>
      <name>Marius Hofert</name>
    </author>
    <author>
      <name>Amir Memartoluie</name>
    </author>
    <author>
      <name>David Saunders</name>
    </author>
    <author>
      <name>Tony Wirjanto</name>
    </author>
    <link href="http://arxiv.org/abs/1505.02281v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.02281v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.04593v1</id>
    <updated>2015-05-18T11:08:56Z</updated>
    <published>2015-05-18T11:08:56Z</published>
    <title>The efficiency of Anderson-Darling test with limited sample size: an
  application to Backtesting Counterparty Credit Risk internal model</title>
    <summary>  This work presents a theoretical and empirical evaluation of Anderson-Darling
test when the sample size is limited. The test can be applied in order to
backtest the risk factors dynamics in the context of Counterparty Credit Risk
modelling. We show the limits of such test when backtesting the distributions
of an interest rate model over long time horizons and we propose a modified
version of the test that is able to detect more efficiently an underestimation
of the model's volatility. Finally we provide an empirical application.
</summary>
    <author>
      <name>M. Formenti</name>
    </author>
    <author>
      <name>L. Spadafora</name>
    </author>
    <author>
      <name>M. Terraneo</name>
    </author>
    <author>
      <name>F. Ramponi</name>
    </author>
    <link href="http://arxiv.org/abs/1505.04593v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.04593v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.05089v1</id>
    <updated>2015-05-17T22:03:23Z</updated>
    <published>2015-05-17T22:03:23Z</published>
    <title>CEI: a new indicator measuring City Commercial Credit Risk initiated in
  China</title>
    <summary>  Aiming at quantifying and evaluating the regional commercial environment
along with the level of economic development among cities in mainland China,
the concept of China City Commercial Environment Credit Index(CEI) was first
introduced and established in 2010. In this manuscript, a historical review and
detailed introduction of CEI is included, followed by statistical studies. In
particular, an independent statistical cross-check for the existing CEI-2012 is
performed and significant factors that play the most in influential roles are
discussed.
</summary>
    <author>
      <name>Ruonan Lin</name>
    </author>
    <author>
      <name>Yi Gu</name>
    </author>
    <link href="http://arxiv.org/abs/1505.05089v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.05089v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.04125v1</id>
    <updated>2015-06-12T19:42:30Z</updated>
    <published>2015-06-12T19:42:30Z</published>
    <title>A risk management approach to capital allocation</title>
    <summary>  The European insurance sector will soon be faced with the application of
Solvency 2 regulation norms. It will create a real change in risk management
practices. The ORSA approach of the second pillar makes the capital allocation
an important exercise for all insurers and specially for groups. Considering
multi-branches firms, capital allocation has to be based on a multivariate risk
modeling. Several allocation methods are present in the literature and insurers
practices. In this paper, we present a new risk allocation method, we study its
coherence using an axiomatic approach, and we try to define what the best
allocation choice for an insurance group is.
</summary>
    <author>
      <name>Véronique Maume-Deschamps</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">ICJ</arxiv:affiliation>
    </author>
    <author>
      <name>Didier Rullière</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">SAF</arxiv:affiliation>
    </author>
    <author>
      <name>Khalil Said</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">SAF</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/1506.04125v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.04125v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.00244v2</id>
    <updated>2015-07-12T10:24:23Z</updated>
    <published>2015-07-01T14:24:36Z</published>
    <title>Expected Shortfall is jointly elicitable with Value at Risk -
  Implications for backtesting</title>
    <summary>  In this note, we comment on the relevance of elicitability for backtesting
risk measure estimates. In particular, we propose the use of Diebold-Mariano
tests, and show how they can be implemented for Expected Shortfall (ES), based
on the recent result of Fissler and Ziegel (2015) that ES is jointly elicitable
with Value at Risk.
</summary>
    <author>
      <name>Tobias Fissler</name>
    </author>
    <author>
      <name>Johanna F. Ziegel</name>
    </author>
    <author>
      <name>Tilmann Gneiting</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Risk, January 2016, 58-61</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1507.00244v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.00244v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.04655v2</id>
    <updated>2017-07-13T16:17:20Z</updated>
    <published>2015-07-16T17:06:40Z</published>
    <title>Insurance makes wealth grow faster</title>
    <summary>  Voluntary insurance contracts constitute a puzzle because they increase the
expectation value of one party's wealth, whereas both parties must sign for
such contracts to exist. Classically, the puzzle is resolved by introducing
non-linear utility functions, which encode asymmetric risk preferences; or by
assuming the parties have asymmetric information. Here we show the puzzle goes
away if contracts are evaluated by their effect on the time-average growth rate
of wealth. Our solution assumes only knowledge of wealth dynamics. Time
averages and expectation values differ because wealth changes are non-ergodic.
Our reasoning is generalisable: business happens when both parties grow faster.
</summary>
    <author>
      <name>Ole Peters</name>
    </author>
    <author>
      <name>Alexander Adamou</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">27 pages, 3 figures, 3 tables, 1 glossary</arxiv:comment>
    <link href="http://arxiv.org/abs/1507.04655v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.04655v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1509.09133v2</id>
    <updated>2016-11-18T14:43:12Z</updated>
    <published>2015-09-30T11:41:59Z</published>
    <title>Dynamics of multivariate default system in random environment</title>
    <summary>  We consider a multivariate default system where random environmental
information is available. We study the dynamics of the system in a general
setting and adopt the point of view of change of probability measures. We also
make a link with the density approach in the credit risk modelling. In the
particular case where no environmental information is concerned, we pay a
special attention to the phenomenon of system weakened by failures as in the
classical reliability system.
</summary>
    <author>
      <name>Nicole El Karoui</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LPMA</arxiv:affiliation>
    </author>
    <author>
      <name>Monique Jeanblanc</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LaMME</arxiv:affiliation>
    </author>
    <author>
      <name>Ying Jiao</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">SAF</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/1509.09133v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1509.09133v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.MF" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.01675v1</id>
    <updated>2015-10-06T17:38:22Z</updated>
    <published>2015-10-06T17:38:22Z</published>
    <title>What's in a ball? Constructing and characterizing uncertainty sets</title>
    <summary>  In the presence of model risk, it is well-established to replace classical
expected values by worst-case expectations over all models within a fixed
radius from a given reference model. This is the "robustness" approach. We show
that previous methods for measuring this radius, e.g. relative entropy or
polynomial divergences, are inadequate for reference models which are
moderately heavy-tailed such as lognormal models. Worst cases are either
infinitely pessimistic, or they rule out the possibility of fat-tailed "power
law" models as plausible alternatives. We introduce a new family of divergence
measures which captures intermediate levels of pessimism.
</summary>
    <author>
      <name>Thomas Kruse</name>
    </author>
    <author>
      <name>Judith C. Schneider</name>
    </author>
    <author>
      <name>Nikolaus Schweizer</name>
    </author>
    <link href="http://arxiv.org/abs/1510.01675v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.01675v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.03920v1</id>
    <updated>2015-10-13T22:51:14Z</updated>
    <published>2015-10-13T22:51:14Z</published>
    <title>A State-Dependent Dual Risk Model</title>
    <summary>  In a dual risk model, the premiums are considered as the costs and the claims
are regarded as the profits. The surplus can be interpreted as the wealth of a
venture capital, whose profits depend on research and development. In most of
the existing literature of dual risk models, the profits follow the compound
Poisson model and the cost is constant. In this paper, we develop a
state-dependent dual risk model, in which the arrival rate of the profits and
the costs depend on the current state of the wealth process. Ruin probabilities
are obtained in closed-forms. Further properties and results will also be
discussed.
</summary>
    <author>
      <name>Lingjiong Zhu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1510.03920v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.03920v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.04924v1</id>
    <updated>2015-10-16T16:01:46Z</updated>
    <published>2015-10-16T16:01:46Z</published>
    <title>Optimal Investment in a Dual Risk Model</title>
    <summary>  Dual risk models are popular for modeling a venture capital or high tech
company, for which the running cost is deterministic and the profits arrive
stochastically over time. Most of the existing literature on dual risk models
concentrated on the optimal dividend strategies. In this paper, we propose to
study the optimal investment strategy on research and development for the dual
risk models to minimize the ruin probability of the underlying company. We will
also study the optimization problem when in addition the investment in a risky
asset is allowed.
</summary>
    <author>
      <name>Arash Fahim</name>
    </author>
    <author>
      <name>Lingjiong Zhu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">32 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1510.04924v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.04924v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.05561v3</id>
    <updated>2016-11-15T17:33:36Z</updated>
    <published>2015-10-19T16:14:06Z</published>
    <title>A Supermartingale Relation for Multivariate Risk Measures</title>
    <summary>  The equivalence between multiportfolio time consistency of a dynamic
multivariate risk measure and a supermartingale property is proven.
Furthermore, the dual variables under which this set-valued supermartingale is
a martingale are characterized as the worst-case dual variables in the dual
representation of the risk measure. Examples of multivariate risk measures
satisfying the supermartingale property are given. Crucial for obtaining the
results are dual representations of scalarizations of set-valued dynamic risk
measures, which are of independent interest in the fast growing literature on
multivariate risks.
</summary>
    <author>
      <name>Zachary Feinstein</name>
    </author>
    <author>
      <name>Birgit Rudloff</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">38 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1510.05561v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.05561v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B30, 26E25, 60G48" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.02934v1</id>
    <updated>2015-11-09T23:46:54Z</updated>
    <published>2015-11-09T23:46:54Z</published>
    <title>Capital allocation and risk appetite under Solvency II framework</title>
    <summary>  The aim of this paper is to introduce a method for computing the allocated
Solvency II Capital Requirement (SCR) of each Risk which the company is exposed
to, taking in account for the diversification effect among different risks. The
method suggested is based on the Euler principle. We show that it has very
suitable properties like coherence in the sense of Denault (2001) and RORAC
compatibility, and practical implications for the companies that use the
standard formula. Further, we show how this approach can be used to evaluate
the underwriting and reinsurance policies and to define a measure of the
Company's risk appetite, based on the capital at risk return.
</summary>
    <author>
      <name>Ivan Granito</name>
    </author>
    <author>
      <name>Paolo De Angelis</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.13140/RG.2.1.1136.8404</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.13140/RG.2.1.1136.8404" rel="related"/>
    <link href="http://arxiv.org/abs/1511.02934v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.02934v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.06320v2</id>
    <updated>2016-11-01T07:15:24Z</updated>
    <published>2015-11-19T19:33:53Z</published>
    <title>Intragroup transfers, intragroup diversification and their risk
  assessment</title>
    <summary>  When assessing group solvency, an important question is to what extent
intragroup transfers may be considered, as this determines to which extent
diversification can be achieved. We suggest a framework to describe the
families of admissible transfers that range from the free movement of capital
to excluding any transactions. The constraints on admissible transactions are
described as random closed sets. The paper focuses on the corresponding
solvency tests that amount to the existence of acceptable selections of the
random sets of admissible transactions.
</summary>
    <author>
      <name>Andreas Haier</name>
    </author>
    <author>
      <name>Ilya Molchanov</name>
    </author>
    <author>
      <name>Michael Schmutz</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages, 3 figures. Revised version</arxiv:comment>
    <link href="http://arxiv.org/abs/1511.06320v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.06320v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B30, 97M30, 60D05" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.06943v4</id>
    <updated>2017-10-02T18:24:43Z</updated>
    <published>2015-11-22T01:00:16Z</published>
    <title>A composition between risk and deviation measures</title>
    <summary>  The intuition on risk is based on two main concepts: loss and variability. In
this paper we present a composition of risk and deviation measures, which capt
these two concepts. Based on the proposed Limitedness axiom, we prove that this
composition is a coherent, convex or co-monotone risk measure, conform
properties of the two components. We also provide examples of known and new
risk measures constructed under this framework, in order to highlight the
importance of our approach, specially the role of the Limitedness axiom.
</summary>
    <author>
      <name>Marcelo Brutti Righi</name>
    </author>
    <link href="http://arxiv.org/abs/1511.06943v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.06943v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.03435v2</id>
    <updated>2016-02-09T22:39:20Z</updated>
    <published>2016-01-13T22:37:42Z</published>
    <title>Asymptotic Analysis for Optimal Dividends in a Dual Risk Model</title>
    <summary>  The dual risk model is a popular model in finance and insurance, which is
often used to model the wealth process of a venture capital or high tech
company. Optimal dividends have been extensively studied in the literature for
the dual risk model. It is well known that the value function of this optimal
control problem does not yield closed-form solutions except in some special
cases. In this paper, we study the asymptotics of the optimal dividends problem
when the parameters of the model go to either zero or infinity. Our results
provide insights to the optimal strategies and the optimal values when the
parameters are extreme.
</summary>
    <author>
      <name>Arash Fahim</name>
    </author>
    <author>
      <name>Lingjiong Zhu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">23 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1601.03435v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.03435v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.06979v1</id>
    <updated>2016-01-26T11:13:51Z</updated>
    <published>2016-01-26T11:13:51Z</published>
    <title>Robust Optimal Risk Sharing and Risk Premia in Expanding Pools</title>
    <summary>  We consider the problem of optimal risk sharing in a pool of cooperative
agents. We analyze the asymptotic behavior of the certainty equivalents and
risk premia associated with the Pareto optimal risk sharing contract as the
pool expands. We first study this problem under expected utility preferences
with an objectively or subjectively given probabilistic model. Next, we develop
a robust approach by explicitly taking uncertainty about the probabilistic
model (ambiguity) into account. The resulting robust certainty equivalents and
risk premia compound risk and ambiguity aversion. We provide explicit results
on their limits and rates of convergence, induced by Pareto optimal risk
sharing in expanding pools.
</summary>
    <author>
      <name>Thomas Knispel</name>
    </author>
    <author>
      <name>Roger J. A. Laeven</name>
    </author>
    <author>
      <name>Gregor Svindland</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.insmatheco.2016.05.012</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.insmatheco.2016.05.012" rel="related"/>
    <link href="http://arxiv.org/abs/1601.06979v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.06979v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1602.05749v1</id>
    <updated>2016-02-18T10:34:29Z</updated>
    <published>2016-02-18T10:34:29Z</published>
    <title>Value-at-Risk and backtesting with the APARCH model and the standardized
  Pearson type IV distribution</title>
    <summary>  We examine the efficiency of the Asymmetric Power ARCH (APARCH) model in the
case where the residuals follow the standardized Pearson type IV distribution.
The model is tested with a variety of loss functions and the efficiency is
examined via application of several statistical tests and risk measures. The
results indicate that the APARCH model with the standardized Pearson type IV
distribution is accurate, within the general financial risk modeling
perspective, providing the financial analyst with an additional skewed
distribution for incorporation in the risk management tools.
</summary>
    <author>
      <name>Stavros Stavroyiannis</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages, 3 figures, 5 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1602.05749v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1602.05749v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.03458v1</id>
    <updated>2016-03-09T00:40:55Z</updated>
    <published>2016-03-09T00:40:55Z</published>
    <title>Financial contagion in investment funds</title>
    <summary>  Many new models for measuring financial contagion have been presented
recently. While these models have not been specified for investment funds
directly, there are many similarities that could be explored to extend the
models. In this work we explore ideas developed about financial contagion to
create a network of investment funds using both cross-holding of quotas and a
bipartite network of funds and assets. Using data from the Brazilian asset
management market we analyze not only the contagion pattern but also the
structure of this network and how this model can be used to assess the
stability of the market.
</summary>
    <author>
      <name>Leonardo dos Santos Pinheiro</name>
    </author>
    <author>
      <name>Flavio Codeco Coelho</name>
    </author>
    <link href="http://arxiv.org/abs/1603.03458v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.03458v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.07042v1</id>
    <updated>2016-04-24T15:53:10Z</updated>
    <published>2016-04-24T15:53:10Z</published>
    <title>Entropy and credit risk in highly correlated markets</title>
    <summary>  We compare two models of corporate default by calculating the
Jeffreys-Kullback-Leibler divergence between their predicted default
probabilities when asset correlations are either high or low. Our main results
show that the divergence between the two models increases in highly correlated,
volatile, and large markets, but that it is closer to zero in small markets,
when asset correlations are low and firms are highly leveraged. These findings
suggest that during periods of financial instability the single-and
multi-factor models of corporate default will generate increasingly
inconsistent predictions.
</summary>
    <author>
      <name>Sylvia Gottschalk</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.physa.2017.02.083</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.physa.2017.02.083" rel="related"/>
    <link href="http://arxiv.org/abs/1604.07042v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.07042v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="60G15, 60G52, 60J65, 62B10, 62P05" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.04940v1</id>
    <updated>2016-03-05T22:33:01Z</updated>
    <published>2016-03-05T22:33:01Z</published>
    <title>Value-at-Risk: The Effect of Autoregression in a Quantile Process</title>
    <summary>  Value-at-Risk (VaR) is an institutional measure of risk favored by financial
regulators. VaR may be interpreted as a quantile of future portfolio values
conditional on the information available, where the most common quantile used
is 95%. Here we demonstrate Conditional Autoregressive Value at Risk, first
introduced by Engle, Manganelli (2001). CAViaR suggests that negative/positive
returns are not i.i.d., and that there is significant autocorrelation. The
model is tested using data from 1986- 1999 and 1999-2009 for GM, IBM, XOM, SPX,
and then validated via the dynamic quantile test. Results suggest that the
tails (upper/lower quantile) of a distribution of returns behave differently
than the core.
</summary>
    <author>
      <name>Khizar Qureshi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Columbia Economics Review, November 2015</arxiv:comment>
    <link href="http://arxiv.org/abs/1605.04940v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.04940v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.00448v1</id>
    <updated>2016-07-02T01:52:59Z</updated>
    <published>2016-07-02T01:52:59Z</published>
    <title>Estimation and prediction of credit risk based on rating transition
  systems</title>
    <summary>  Risk management is an important practice in the banking industry. In this
paper we develop a new methodology to estimate and predict the probability of
default (PD) based on the rating transition matrices, which relates the rating
transition matrices to the macroeconomic variables. Our method can overcome the
shortcomings of the framework of Belkin et al. (1998), and is especially useful
in predicting the PD and doing stress testing. Simulation is conducted at the
end, which shows that our method can provide more accurate estimate than that
obtained by the method of Belkin et al. (1998).
</summary>
    <author>
      <name>Jinghai Shao</name>
    </author>
    <author>
      <name>Siming Li</name>
    </author>
    <author>
      <name>Yong Li</name>
    </author>
    <link href="http://arxiv.org/abs/1607.00448v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.00448v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.04739v1</id>
    <updated>2016-07-16T13:22:22Z</updated>
    <published>2016-07-16T13:22:22Z</published>
    <title>Multiple risk factor dependence structures: Distributional properties</title>
    <summary>  We introduce a class of dependence structures, that we call the Multiple Risk
Factor (MRF) dependence structures. On the one hand, the new constructions
extend the popular CreditRisk+ approach, and as such they formally describe
default risk portfolios exposed to an arbitrary number of fatal risk factors
with conditionally exponential and dependent hitting (or occurrence) times. On
the other hand, the MRF structures can be seen as an encompassing family of
multivariate probability distributions with univariate margins distributed
Pareto of the 2nd kind, and in this role they can be used to model insurance
risk portfolios of dependent and heavy tailed risk components.
</summary>
    <author>
      <name>Jianxi Su</name>
    </author>
    <author>
      <name>Edward Furman</name>
    </author>
    <link href="http://arxiv.org/abs/1607.04739v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.04739v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.02068v2</id>
    <updated>2016-09-30T13:22:42Z</updated>
    <published>2016-08-06T05:07:35Z</published>
    <title>Arbitrage and utility maximization in market models with an insider</title>
    <summary>  We study arbitrage opportunities, market viability and utility maximization
in market models with an insider. Assuming that an economic agent possesses
from the beginning an additional information in the form of a random variable
G, which only becomes known to the ordinary agents at date T, we give criteria
for the No Unbounded Profits with Bounded Risk property to hold, characterize
optimal arbitrage strategies, and prove duality results for the utility
maximization problem faced by the insider. Examples of markets satisfying NUPBR
yet admitting arbitrage opportunities are provided for both atomic and
continuous random variables G.
</summary>
    <author>
      <name>Ngoc Huy Chau</name>
    </author>
    <author>
      <name>Wolfgang Runggaldier</name>
    </author>
    <author>
      <name>Peter Tankov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Replaced with revised version</arxiv:comment>
    <link href="http://arxiv.org/abs/1608.02068v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.02068v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.MF" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.00554v1</id>
    <updated>2016-09-02T11:39:36Z</updated>
    <published>2016-09-02T11:39:36Z</published>
    <title>On Jensen's inequality for generalized Choquet integral with an
  application to risk aversion</title>
    <summary>  In the paper we give necessary and sufficient conditions for the Jensen
inequality to hold for the generalized Choquet integral with respect to a pair
of capacities. Next, we apply obtained result to the theory of risk aversion by
providing the assumptions on utility function and capacities under which an
agent is risk averse. Moreover, we show that the Arrow-Pratt theorem can be
generalized to cover the case, where the expectation is replaced by the
generalized Choquet integral.
</summary>
    <author>
      <name>Wioletta Szeligowska</name>
    </author>
    <author>
      <name>Marek Kaluszka</name>
    </author>
    <link href="http://arxiv.org/abs/1609.00554v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.00554v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.00869v1</id>
    <updated>2016-09-03T22:10:45Z</updated>
    <published>2016-09-03T22:10:45Z</published>
    <title>Determining Optimal Stop-Loss Thresholds via Bayesian Analysis of
  Drawdown Distributions</title>
    <summary>  Stop-loss rules are often studied in the financial literature, but the
stop-loss levels are seldom constructed systematically. In many papers, and
indeed in practice as well, the level of the stops is too often set
arbitrarily. Guided by the overarching goal in finance to maximize expected
returns given available information, we propose a natural method by which to
systematically select the stop-loss threshold by analyzing the distribution of
maximum drawdowns. We present results for an hourly trading strategy with two
variations on the construction.
</summary>
    <author>
      <name>Antoine Emil Zambelli</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 8 figures, 2 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1609.00869v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.00869v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.TR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.07897v1</id>
    <updated>2016-09-26T09:25:07Z</updated>
    <published>2016-09-26T09:25:07Z</published>
    <title>Risk-Consistent Conditional Systemic Risk Measures</title>
    <summary>  We axiomatically introduce risk-consistent conditional systemic risk measures
defined on multidimensional risks. This class consists of those conditional
systemic risk measures which can be decomposed into a state-wise conditional
aggregation and a univariate conditional risk measure. Our studies extend known
results for unconditional risk measures on finite state spaces. We argue in
favor of a conditional framework on general probability spaces for assessing
systemic risk. Mathematically, the problem reduces to selecting a realization
of a random field with suitable properties. Moreover, our approach covers many
prominent examples of systemic risk measures from the literature and used in
practice.
</summary>
    <author>
      <name>Hannes Hoffmann</name>
    </author>
    <author>
      <name>Thilo Meyer-Brandis</name>
    </author>
    <author>
      <name>Gregor Svindland</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Stochastic Processes and their Applications, Vol. 126, No. 7, pp.
  2014-2037</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1609.07897v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.07897v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1611.06010v1</id>
    <updated>2016-11-18T08:55:03Z</updated>
    <published>2016-11-18T08:55:03Z</published>
    <title>Value-at-Risk Prediction in R with the GAS Package</title>
    <summary>  GAS models have been recently proposed in time-series econometrics as
valuable tools for signal extraction and prediction. This paper details how
financial risk managers can use GAS models for Value-at-Risk (VaR) prediction
using the novel GAS package for R. Details and code snippets for prediction,
comparison and backtesting with GAS models are presented. An empirical
application considering Dow Jones Index constituents investigates the VaR
forecasting performance of GAS models.
</summary>
    <author>
      <name>David Ardia</name>
    </author>
    <author>
      <name>Kris Boudt</name>
    </author>
    <author>
      <name>Leopoldo Catania</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages 1 fig 2 tab</arxiv:comment>
    <link href="http://arxiv.org/abs/1611.06010v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1611.06010v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.04126v1</id>
    <updated>2016-12-13T12:33:59Z</updated>
    <published>2016-12-13T12:33:59Z</published>
    <title>The hierarchical generalized linear model and the bootstrap estimator of
  the error of prediction of loss reserves in a non-life insurance company</title>
    <summary>  This paper presents the hierarchical generalized linear model (HGLM) for loss
reserving in a non-life insurance company. Because in this case the error of
prediction is expressed by a complex analytical formula, the error bootstrap
estimator is proposed instead. Moreover, the bootstrap procedure is used to
obtain full information about the error by applying quantiles of the absolute
prediction error. The full R code is available on the Github
https://github.com/woali/BootErrorLossReserveHGLM.
</summary>
    <author>
      <name>Alicja Wolny-Dominiak</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Loss Reserves; Hierarchical Generalized Linear Model; Error of
  prediction; MSE; Parametric Bootstrap</arxiv:comment>
    <link href="http://arxiv.org/abs/1612.04126v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.04126v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.07132v1</id>
    <updated>2016-12-21T14:23:14Z</updated>
    <published>2016-12-21T14:23:14Z</published>
    <title>Conditional loss probabilities for systems of economic agents sharing
  light-tailed claims with analysis of portfolio diversification benefits</title>
    <summary>  We analyze systems of agents sharing light-tailed risky claims issued by
different financial objects. Assuming exponentially distributed claims, we
obtain that both agents' and system's losses follow generalized exponential
mixture distributions. We show that this leads to qualitatively different
results on individual and system risks compared to heavy-tailed claims
previously studied in the literature. By deducing conditional loss
distributions we investigate the impact of stress situations on agents' and
system's losses. Moreover, we present a criterion for agents to decide whether
holding few objects or portfolio diversification minimizes their risks in
system crisis situations.
</summary>
    <author>
      <name>Claudia Klüppelberg</name>
    </author>
    <author>
      <name>Miriam Isabel Seifert</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">29 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1612.07132v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.07132v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="60G70, 62E20, 90B10, 91B30" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.07194v1</id>
    <updated>2016-12-21T15:39:42Z</updated>
    <published>2016-12-21T15:39:42Z</published>
    <title>Leverage and Uncertainty</title>
    <summary>  Risk and uncertainty will always be a matter of experience, luck, skills, and
modelling. Leverage is another concept, which is critical for the investor
decisions and results. Adaptive skills and quantitative probabilistic methods
need to be used in successful management of risk, uncertainty and leverage. The
author explores how uncertainty beyond risk determines consistent leverage in a
simple model of the world with fat tails due to significant, not fully
quantifiable and not too rare events. Among particular technical results, for
the single asset fractional Kelly criterion is derived in the presence of the
fat tails associated with subjective uncertainty. For the multi-asset
portfolio, Kelly criterion provides an insightful perspective on Risk Parity
strategies, which can be extended for the assets with fat tails.
</summary>
    <author>
      <name>Mihail Turlakov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1612.07194v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.07194v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.00540v1</id>
    <updated>2017-01-01T21:24:07Z</updated>
    <published>2017-01-01T21:24:07Z</published>
    <title>Net Stable Funding Ratio: Impact on Funding Value Adjustment</title>
    <summary>  In this paper we investigate the relationship between Funding Value
Adjustment (FVA) and Net Stable Funding Ratio (NSFR). FVA is defined in a
consistent way with NSFR such that the new framework of FVA monitors the costs
due to keeping NSFR at an acceptable level, as well.
  In addition, the problem of choosing the optimal funding strategy is
formulated as a shortest path problem where the proposed FVA framework is
applied in the optimization process. The solution provides us with the optimal
funding decisions that lead to the minimum funding cost of the transaction. We
also provide numerical experiments for FVA calculation and optimization
problem.
</summary>
    <author>
      <name>Medya Siadat</name>
    </author>
    <author>
      <name>Ola Hammarlid</name>
    </author>
    <link href="http://arxiv.org/abs/1701.00540v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.00540v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.MF" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1702.04287v2</id>
    <updated>2017-07-16T16:02:21Z</updated>
    <published>2017-02-14T16:54:47Z</published>
    <title>Contagion in financial systems: A Bayesian network approach</title>
    <summary>  We develop a structural default model for interconnected financial
institutions in a probabilistic framework. For all possible network structures
we characterize the joint default distribution of the system using Bayesian
network methodologies. Particular emphasis is given to the treatment and
consequences of cyclic financial linkages. We further demonstrate how Bayesian
network theory can be applied to detect contagion channels within the financial
network, to measure the systemic importance of selected entities on others, and
to compute conditional or unconditional probabilities of default for single or
multiple institutions.
</summary>
    <author>
      <name>Carsten Chong</name>
    </author>
    <author>
      <name>Claudia Klüppelberg</name>
    </author>
    <link href="http://arxiv.org/abs/1702.04287v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1702.04287v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B30, 62-09, 91G80" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1702.08901v1</id>
    <updated>2017-02-28T18:39:56Z</updated>
    <published>2017-02-28T18:39:56Z</published>
    <title>Solvency II, or How to Swipe the Downside Risk Under the Carpet</title>
    <summary>  Under Solvency II the computation of capital requirements is based on value
at risk (V@R). V@R is a quantile-based risk measure and neglects extreme risks
in the tail. V@R belongs to the family of distortion risk measures. A serious
deficiency of V@R is that firms can hide their total downside risk in corporate
groups. They can largely reduce their total capital requirements via
appropriate transfer agreements within a group structure consisting of
sufficiently many entities and thereby circumvent capital regulation. We prove
several versions of such a result for general distortion risk measures of
V@R-type, explicitly construct suitable allocations of the group portfolio, and
finally demonstrate how these findings can be extended beyond distortion risk
measures.
</summary>
    <author>
      <name>Stefan Weber</name>
    </author>
    <link href="http://arxiv.org/abs/1702.08901v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1702.08901v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B30" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.01137v2</id>
    <updated>2017-09-08T09:24:07Z</updated>
    <published>2017-03-03T12:55:15Z</published>
    <title>Model Spaces for Risk Measures</title>
    <summary>  We show how risk measures originally defined in a model free framework in
terms of acceptance sets and reference assets imply a meaningful underlying
probability structure. Hereafter we construct a maximal domain of definition of
the risk measure respecting the underlying ambiguity profile. We particularly
emphasise liquidity effects and discuss the correspondence between properties
of the risk measure and the structure of this domain as well as
subdifferentiability properties.
  Keywords: Model free risk assessment, extension of risk measures, continuity
properties of risk measures, subgradients.
</summary>
    <author>
      <name>Felix-Benedikt Liebrich</name>
    </author>
    <author>
      <name>Gregor Svindland</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Mistake in Proposition 3.1 and minor typos corrected, Example 5.1
  new, Proposition 4.2 improved</arxiv:comment>
    <link href="http://arxiv.org/abs/1703.01137v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.01137v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.FA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="46B42, 91B30, 91G80" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.01984v2</id>
    <updated>2017-03-21T10:17:49Z</updated>
    <published>2017-03-06T17:15:39Z</published>
    <title>Optimality of Excess-Loss Reinsurance under a Mean-Variance Criterion</title>
    <summary>  In this paper, we study an insurer's reinsurance-investment problem under a
mean-variance criterion. We show that excess-loss is the unique equilibrium
reinsurance strategy under a spectrally negative L\'{e}vy insurance model when
the reinsurance premium is computed according to the expected value premium
principle. Furthermore, we obtain the explicit equilibrium
reinsurance-investment strategy by solving the extended Hamilton-Jacobi-Bellman
equation.
</summary>
    <author>
      <name>Danping Li</name>
    </author>
    <author>
      <name>Dongchen Li</name>
    </author>
    <author>
      <name>Virginia R. Young</name>
    </author>
    <link href="http://arxiv.org/abs/1703.01984v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.01984v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.04537v1</id>
    <updated>2017-05-12T12:24:40Z</updated>
    <published>2017-05-12T12:24:40Z</published>
    <title>Murphy Diagrams: Forecast Evaluation of Expected Shortfall</title>
    <summary>  Motivated by the Basel 3 regulations, recent studies have considered joint
forecasts of Value-at-Risk and Expected Shortfall. A large family of scoring
functions can be used to evaluate forecast performance in this context.
However, little intuitive or empirical guidance is currently available, which
renders the choice of scoring function awkward in practice. We therefore
develop graphical checks (Murphy diagrams) of whether one forecast method
dominates another under a relevant class of scoring functions, and propose an
associated hypothesis test. We illustrate these tools with simulation examples
and an empirical analysis of S&amp;P 500 and DAX returns.
</summary>
    <author>
      <name>Johanna F. Ziegel</name>
    </author>
    <author>
      <name>Fabian Krüger</name>
    </author>
    <author>
      <name>Alexander Jordan</name>
    </author>
    <author>
      <name>Fernando Fasciati</name>
    </author>
    <link href="http://arxiv.org/abs/1705.04537v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.04537v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.00284v1</id>
    <updated>2017-06-01T13:03:36Z</updated>
    <published>2017-06-01T13:03:36Z</published>
    <title>Clearing algorithms and network centrality</title>
    <summary>  I show that the solution of a standard clearing model commonly used in
contagion analyses for financial systems can be expressed as a specific form of
a generalized Katz centrality measure under conditions that correspond to a
system-wide shock. This result provides a formal explanation for earlier
empirical results which showed that Katz-type centrality measures are closely
related to contagiousness. It also allows assessing the assumptions that one is
making when using such centrality measures as systemic risk indicators. I
conclude that these assumptions should be considered too strong and that, from
a theoretical perspective, clearing models should be given preference over
centrality measures in systemic risk analyses.
</summary>
    <author>
      <name>Christoph Siebenbrunner</name>
    </author>
    <link href="http://arxiv.org/abs/1706.00284v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.00284v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.03391v1</id>
    <updated>2017-07-12T08:11:41Z</updated>
    <published>2017-07-12T08:11:41Z</published>
    <title>The partial damage loss cover ratemaking of the automobile insurance
  using generalized linear models</title>
    <summary>  It is illustrated a methodology to compute the pure premium for the
automobile insurance (claim frequency and severity) using generalized linear
models. It is obtained the pure premium for the partial damage loss cover (PPD)
using a set of automobile insurance policies with an exposition of a year. It
is found that the most influential variables in the claim frequency are the car
production year, the insured's age, and the region's subscription policy and
the most influential variables in the claim severity are the car's value, type
and make and the insured's gender.
</summary>
    <author>
      <name>William Guevara-Alarcón</name>
    </author>
    <author>
      <name>Luz Mery González</name>
    </author>
    <author>
      <name>Armando Antonio Zarruk</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">in Spanish</arxiv:comment>
    <link href="http://arxiv.org/abs/1707.03391v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.03391v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.03516v1</id>
    <updated>2017-07-12T02:05:27Z</updated>
    <published>2017-07-12T02:05:27Z</published>
    <title>Portfolio Risk Assessment using Copula Models</title>
    <summary>  In the paper, we use and investigate copulas models to represent multivariate
dependence in financial time series. We propose the algorithm of risk measure
computation using copula models. Using the optimal mean-$CVaR$ portfolio we
compute portfolio's Profit and Loss series and corresponded risk measures
curves. Value-at-risk and Conditional-Value-at-risk curves were simulated by
three copula models: full Gaussian, Student's $t$ and regular vine copula.
These risk curves are lower than historical values of the risk measures curve.
All three models have superior prediction ability than a usual empirical
method. Further directions of research are described.
</summary>
    <author>
      <name>Mikhail Semenov</name>
    </author>
    <author>
      <name>Daulet Smagulov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1707.03516v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.03516v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.09829v1</id>
    <updated>2017-07-31T12:59:01Z</updated>
    <published>2017-07-31T12:59:01Z</published>
    <title>A risk measure that optimally balances capital determination errors</title>
    <summary>  In this paper, we propose a risk measurement approach that minimizes the
expectation of sum between costs from capital determination overestimation and
underestimation. We develop results that guarantee the existence of a solution,
indicate properties that our risk measure fulfills, and characterize the
resulting minimum cost as a deviation measure. We generalize this approach to a
robust framework, where the minimization is over a supremum of expectations,
based on a convex set of probability measures. We relate this robust approach
with the dual representation of coherent risk measures. In a numerical example,
we illustrate our approach for simulated and real financial data. Results
indicate our approach leads to more parsimonious capital requirement
determinations and reduces the mentioned costs.
</summary>
    <author>
      <name>Marcelo Brutti Righi</name>
    </author>
    <link href="http://arxiv.org/abs/1707.09829v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.09829v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.01489v1</id>
    <updated>2017-08-04T13:31:25Z</updated>
    <published>2017-08-04T13:31:25Z</published>
    <title>Spectral backtests of forecast distributions with application to risk
  management</title>
    <summary>  We study a class of backtests for forecast distributions in which the test
statistic is a spectral transformation that weights exceedance events by a
function of the modeled probability level. The choice of the kernel function
makes explicit the user's priorities for model performance. The class of
spectral backtests includes tests of unconditional coverage and tests of
conditional coverage. We show how the class embeds a wide variety of backtests
in the existing literature, and propose novel variants as well. We assess the
size and power of the backtests in realistic sample sizes, and in particular
demonstrate the tradeoff between power and specificity in validating quantile
forecasts.
</summary>
    <author>
      <name>Michael B. Gordy</name>
    </author>
    <author>
      <name>Hsiao Yen Lok</name>
    </author>
    <author>
      <name>Alexander J. McNeil</name>
    </author>
    <link href="http://arxiv.org/abs/1708.01489v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.01489v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.09810v1</id>
    <updated>2017-08-31T16:42:03Z</updated>
    <published>2017-08-31T16:42:03Z</published>
    <title>Extending Yagil exchange ratio determination model to the case of
  stochastic dividends</title>
    <summary>  This article extends, in a stochastic environment, the Yagil (1987) model
which establishes, in a deterministic dividend discount model, a range for the
exchange ratio in a stock-for-stock merger agreement. Here, we generalize
Yagil's work letting both pre- and post-merger dividends grow randomly over
time. If Yagil focuses only on changes in stock prices before and after the
merger, our stochastic environment allows to keep in account both shares'
expected values and variance, letting us to identify a more complex bargaining
region whose shape depends on mean and standard deviation of the dividends'
growth rate.
</summary>
    <author>
      <name>Alessandra Mainini</name>
    </author>
    <author>
      <name>Enrico Moretto</name>
    </author>
    <link href="http://arxiv.org/abs/1708.09810v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.09810v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91G50" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.01115v1</id>
    <updated>2017-09-04T18:53:01Z</updated>
    <published>2017-09-04T18:53:01Z</published>
    <title>Risk-Minimizing Hedging of Counterparty Risk</title>
    <summary>  We study dynamic hedging of counterparty risk for a portfolio of credit
derivatives. Our empirically driven credit model consists of interacting
default intensities which ramp up and then decay after the occurrence of credit
events. Using the Galtchouk-Kunita-Watanabe decomposition of the counterparty
risk price payment stream, we recover a closed-form representation for the risk
minimizing strategy in terms of classical solutions to nonlinear recursive
systems of Cauchy problems. We discuss applications of our framework to the
most prominent class of credit derivatives, including credit swap and risky
bond portfolios, as well as first-to-default claims.
</summary>
    <author>
      <name>Lijun Bo</name>
    </author>
    <author>
      <name>Agostino Capponi</name>
    </author>
    <author>
      <name>Claudia Ceci</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">32 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1709.01115v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.01115v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="60J25, 60J75, 60H30, 91B28" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.01337v1</id>
    <updated>2017-09-05T11:37:19Z</updated>
    <published>2017-09-05T11:37:19Z</published>
    <title>Backtesting Expected Shortfall: is it really that hard?</title>
    <summary>  In this short note we propose a new backtesting framework for Expected
Shortfall that could be used by the regulator. Instead of looking at the
estimated capital reserve and the realized cash-flow separately, one could bind
them into the secured position, for which the risk measurement process is much
easier. Using this simple concept combined with monotonicity of Expected
Shortfall with respect to its target confidence level, one can provide an
unconditional coverage backtesting framework for Expected Shortfall that is a
natural extension of the current Value-at-Risk regulatory traffic-light
approach.
</summary>
    <author>
      <name>Felix Moldenhauer</name>
    </author>
    <author>
      <name>Marcin Pitera</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This is a preliminary draft. Comments are appreciated</arxiv:comment>
    <link href="http://arxiv.org/abs/1709.01337v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.01337v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.CP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.MF" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0908.0840v1</id>
    <updated>2009-08-06T11:11:47Z</updated>
    <published>2009-08-06T11:11:47Z</published>
    <title>Robust mean-variance hedging in the single period model</title>
    <summary>  We give an explicit solution of robust mean-variance hedging problem in the
single period model for some type of contingent claims. The alternative
approach is also considered.
</summary>
    <author>
      <name>R. Tevzadze</name>
    </author>
    <author>
      <name>T. Uzunashvili</name>
    </author>
    <link href="http://arxiv.org/abs/0908.0840v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0908.0840v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="60H30,90C47" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1110.4648v1</id>
    <updated>2011-10-20T20:59:31Z</updated>
    <published>2011-10-20T20:59:31Z</published>
    <title>Anti-Robust and Tonsured Statistics</title>
    <summary>  This describes a statistical technique called "tonsuring" for exploratory
data analysis in finance. Instead of rejecting "outlier" data that conflicts
with the model, this strips out "inlier" data to get a clearer picture of how
the market changes for larger moves.
</summary>
    <author>
      <name>Martin Goldberg</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, 9 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1110.4648v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1110.4648v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.4311v1</id>
    <updated>2012-02-20T13:00:28Z</updated>
    <published>2012-02-20T13:00:28Z</published>
    <title>Comparative statistics of Garman-Klass, Parkinson, Roger-Satchell and
  bridge estimators</title>
    <summary>  Comparative statistical properties of Parkinson, Garman-Klass, Roger-Satchell
and bridge oscillation estimators are discussed. Point and interval
estimations, related with mentioned estimators are considered
</summary>
    <author>
      <name>Alexander Saichev</name>
    </author>
    <author>
      <name>Svetlana Lapinova</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, 12 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1202.4311v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.4311v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.5881v1</id>
    <updated>2013-07-22T20:50:12Z</updated>
    <published>2013-07-22T20:50:12Z</published>
    <title>A Remark on the Structure of Expectiles</title>
    <summary>  Expectiles were defined using a minimisation principle. They form a special
class of coherent risk measures. We will describe the scenario set and we will
show that there is a most severe commonotonic risk measure that is smaller than
the given expectile.
</summary>
    <author>
      <name>Freddy Delbaen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1307.5881v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.5881v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91GXX" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.00640v1</id>
    <updated>2015-04-01T07:06:03Z</updated>
    <published>2015-04-01T07:06:03Z</published>
    <title>Remark on the Paper "Entropic Value-at-Risk: A New Coherent Risk
  Measure" by Amir Ahmadi-Javid, J. Opt. Theory and Appl., 155
  (2001),1105--1123</title>
    <summary>  The paper mentioned in the title introduces the entropic value at risk. I
give some extra comments and using the general theory make a relation with some
commonotone risk measures.
</summary>
    <author>
      <name>Freddy Delbaen</name>
    </author>
    <link href="http://arxiv.org/abs/1504.00640v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.00640v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="90B50" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cond-mat/0307244v1</id>
    <updated>2003-07-10T13:07:37Z</updated>
    <published>2003-07-10T13:07:37Z</published>
    <title>Concave risk measures in international capital regulation</title>
    <summary>  We show that some specific market risk measures implied by current
international capital regulation (the Basel Accords and the Capital Adequacy
Directive of the European Union) violate the obvious requirement of convexity
in some regions in the space of portfolio weights.
</summary>
    <author>
      <name>Imre Kondor</name>
    </author>
    <author>
      <name>Andras Szepessy</name>
    </author>
    <author>
      <name>Tunde Ujvarosi</name>
    </author>
    <link href="http://arxiv.org/abs/cond-mat/0307244v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cond-mat/0307244v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/math/0402456v1</id>
    <updated>2004-02-27T16:25:19Z</updated>
    <published>2004-02-27T16:25:19Z</published>
    <title>VaR and ES for linear portfolios with mixture of elliptic distributed
  Risk Factors</title>
    <summary>  In this paper, we generalize the parametric Delta-VaR methods from portfolios
with elliptic distributed risk factors to portfolios with mixture of
elliptically distributed ones. We treat both the Expected Shortfall and the
Value-at-Risk of such portfolios. Special attention is given to the particular
case of the mixture of Student-t distributions.
</summary>
    <author>
      <name>Jules Sadefo Kamdem</name>
    </author>
    <link href="http://arxiv.org/abs/math/0402456v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/math/0402456v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/math/0506127v2</id>
    <updated>2005-07-12T05:11:26Z</updated>
    <published>2005-06-08T04:03:49Z</published>
    <title>A Note on the Ruin Problem with Risky Investments</title>
    <summary>  We reprove a result concerning certain ruin in the classical problem of the
probability of ruin with risky investments and several of it's generalisations.
We also provide the combined transition density of the risk and investment
processes in the diffusion case.
</summary>
    <author>
      <name>David Maher</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages; Corrected typos and labels</arxiv:comment>
    <link href="http://arxiv.org/abs/math/0506127v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/math/0506127v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62P05; 43A80" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/math/0603041v1</id>
    <updated>2006-03-02T12:15:33Z</updated>
    <published>2006-03-02T12:15:33Z</published>
    <title>On decomposing risk in a financial-intermediate market and reserving</title>
    <summary>  We consider the problem of decomposing monetary risk in the presence of a
fully traded market in {\it some} risks. We show that a mark-to-market approach
to pricing leads to such a decomposition if the risk measure is time-consistent
in the sense of Delbaen.
</summary>
    <author>
      <name>Saul Jacka</name>
    </author>
    <author>
      <name>Abdel Berkaoui</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/math/0603041v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/math/0603041v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B30; 91B28; 91B26; 90C46; 60H05" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0912.4621v1</id>
    <updated>2009-12-23T11:46:05Z</updated>
    <published>2009-12-23T11:46:05Z</published>
    <title>Dynamic Estimation of Credit Rating Transition Probabilities</title>
    <summary>  We present a continuous-time maximum likelihood estimation methodology for
credit rating transition probabilities, taking into account the presence of
censored data. We perform rolling estimates of the transition matrices with
exponential time weighting with varying horizons and discuss the underlying
dynamics of transition generator matrices in the long-term and short-term
estimation horizons.
</summary>
    <author>
      <name>Arthur M. Berd</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">28 pages, 23 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0912.4621v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0912.4621v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1002.3681v2</id>
    <updated>2010-02-20T10:53:05Z</updated>
    <published>2010-02-19T08:24:58Z</published>
    <title>Optimal investment with bounded VaR for power utility functions</title>
    <summary>  We consider the optimal investment problem for Black-Scholes type financial
market with bounded VaR measure on the whole investment interval $[0,T]$. The
explicit form for the optimal strategies is found.
</summary>
    <author>
      <name>Bénamar Chouaf</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LMRS</arxiv:affiliation>
    </author>
    <author>
      <name>Serguei Pergamenchtchikov</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LMRS</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/1002.3681v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1002.3681v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.PM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B28, 93E20" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1004.1053v1</id>
    <updated>2010-04-07T10:56:03Z</updated>
    <published>2010-04-07T10:56:03Z</published>
    <title>Managing Derivative Exposure</title>
    <summary>  We present an approach to derivative exposure management based on subjective
and implied probabilities. We suggest to maximize the valuation difference
subject to risk constraints and propose a class of risk measures derived from
the subjective distribution. We illustrate this process with specific examples
for the two and three dimensional case. In these cases the optimization can be
performed graphically.
</summary>
    <author>
      <name>Ulrich Kirchner</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1004.1053v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1004.1053v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.PM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1004.3577v1</id>
    <updated>2010-04-20T21:10:02Z</updated>
    <published>2010-04-20T21:10:02Z</published>
    <title>Fractional smoothness and applications in finance</title>
    <summary>  This overview article concerns the notion of fractional smoothness of random
variables of the form $g(X_T)$, where $X=(X_t)_{t\in [0,T]}$ is a certain
diffusion process. We review the connection to the real interpolation theory,
give examples and applications of this concept. The applications in stochastic
finance mainly concern the analysis of discrete time hedging errors. We close
the review by indicating some further developments.
</summary>
    <author>
      <name>Stefan Geiss</name>
    </author>
    <author>
      <name>Emmanuel Gobet</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Chapter of AMAMEF book. 20 pages.</arxiv:comment>
    <link href="http://arxiv.org/abs/1004.3577v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1004.3577v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1011.3246v1</id>
    <updated>2010-11-14T18:43:59Z</updated>
    <published>2010-11-14T18:43:59Z</published>
    <title>Reduced form models of bond portfolios</title>
    <summary>  We derive simple return models for several classes of bond portfolios. With
only one or two risk factors our models are able to explain most of the return
variations in portfolios of fixed rate government bonds, inflation linked
government bonds and investment grade corporate bonds. The underlying risk
factors have natural interpretations which make the models well suited for risk
management and portfolio design.
</summary>
    <author>
      <name>Matti Koivu</name>
    </author>
    <author>
      <name>Teemu Pennanen</name>
    </author>
    <link href="http://arxiv.org/abs/1011.3246v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1011.3246v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.5672v1</id>
    <updated>2011-03-29T14:59:44Z</updated>
    <published>2011-03-29T14:59:44Z</published>
    <title>How Unlucky is 25-Sigma?</title>
    <summary>  One of the more memorable moments of last summer's credit crunch came when
the CFO of Goldman Sachs, David Viniar, announced in August that Goldman's
flagship GEO hedge fund had lost 27% of its value since the start of the year.
As Mr. Viniar explained, "We were seeing things that were 25-standard deviation
moves, several days in a row."
</summary>
    <author>
      <name>Kevin Dowd</name>
    </author>
    <author>
      <name>John Cotter</name>
    </author>
    <author>
      <name>Chris Humphrey</name>
    </author>
    <author>
      <name>Margaret Woods</name>
    </author>
    <link href="http://arxiv.org/abs/1103.5672v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.5672v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1110.0561v1</id>
    <updated>2011-10-04T01:47:49Z</updated>
    <published>2011-10-04T01:47:49Z</published>
    <title>Modeling Multiple Risks: Hidden Domain of Attraction</title>
    <summary>  Hidden regular variation is a sub-model of multivariate regular variation and
facilitates accurate estimation of joint tail probabilities. We generalize the
model of hidden regular variation to what we call hidden domain of attraction.
We exhibit examples that illustrate the need for a more general model and
discuss detection and estimation techniques.
</summary>
    <author>
      <name>Abhimanyu Mitra</name>
    </author>
    <author>
      <name>Sidney I. Resnick</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1110.0561v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1110.0561v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1401.2524v1</id>
    <updated>2014-01-11T11:44:39Z</updated>
    <published>2014-01-11T11:44:39Z</published>
    <title>Four Points Beginner Risk Managers Should Learn from Jeff Holman's
  Mistakes in the Discussion of Antifragile</title>
    <summary>  Using Jeff Holman's comments in Quantitative Finance to illustrate 4 critical
errors students should learn to avoid: 1) Mistaking tails (4th moment) for
volatility (2nd moment), 2) Missing Jensen's Inequality, 3) Analyzing the
hedging wihout the underlying, 4) The necessity of a numeraire in finance.
</summary>
    <author>
      <name>Nassim Nicholas Taleb</name>
    </author>
    <link href="http://arxiv.org/abs/1401.2524v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1401.2524v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1403.5833v1</id>
    <updated>2014-03-24T02:07:38Z</updated>
    <published>2014-03-24T02:07:38Z</published>
    <title>Sophisticated gamblers ruin and survival chances</title>
    <summary>  This note explores the mathematical theory to solve modern gamblers ruin
problems. We establish a ruin framework and solve for the probability of
bankruptcy. We also show how this relates to the expected time to bankruptcy
and review the risk neutral probabilities associated an adjustment to
asymmetrical views.
</summary>
    <author>
      <name>Salil Mehta</name>
    </author>
    <link href="http://arxiv.org/abs/1403.5833v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1403.5833v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.05460v1</id>
    <updated>2015-08-22T03:09:05Z</updated>
    <published>2015-08-22T03:09:05Z</published>
    <title>Long run risk sensitive portfolio with general factors</title>
    <summary>  In the paper portfolio optimization over long run risk sensitive criterion is
considered. It is assumed that economic factors which stimulate asset prices
are ergodic but non necessarily uniformly ergodic. Solution to suitable Bellman
equation using local span contraction with weighted norms is shown. The form of
optimal strategy is presented and examples of market models satisfying imposed
assumptions are shown.
</summary>
    <author>
      <name>Marcin Pitera</name>
    </author>
    <author>
      <name>Łukasz Stettner</name>
    </author>
    <link href="http://arxiv.org/abs/1508.05460v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.05460v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.MF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="93E20, 91G10, 91G80" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.01133v1</id>
    <updated>2016-08-03T10:04:25Z</updated>
    <published>2016-08-03T10:04:25Z</published>
    <title>The boundary non-Crossing probabilities for Slepian process</title>
    <summary>  In this contribution we derive an explicit formula for the boundary
non-crossing probabilities for Slepian processes associated with the piecewise
linear boundary function. This formula is used to develop an approximation
formula to the boundary non-crossing probabilities for general continuous
boundaries. The formulas we developed are easy to implement in calculation the
boundary non-crossing probabilities.
</summary>
    <author>
      <name>Pingjin Deng</name>
    </author>
    <link href="http://arxiv.org/abs/1608.01133v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.01133v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.MF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1704.03110v1</id>
    <updated>2017-04-11T01:33:37Z</updated>
    <published>2017-04-11T01:33:37Z</published>
    <title>Bartlett's delta in the SABR model</title>
    <summary>  We refine the analysis of hedging strategies for options under the SABR model
carried out in [2]. In particular, we provide a theoretical justification of
the empirical observation made in [2] that the modified delta ("Bartlett's
delta") introduced there provides a more accurate and robust hedging strategy
than the conventional SABR delta hedge.
</summary>
    <author>
      <name>Patrick S. Hagan</name>
    </author>
    <author>
      <name>Andrew Lesniewski</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1704.03110v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1704.03110v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.CP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.CP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.01324v1</id>
    <updated>2017-08-03T22:35:34Z</updated>
    <published>2017-08-03T22:35:34Z</published>
    <title>Vector-Valued Multivariate Conditional Value-at-Risk</title>
    <summary>  In this study, we propose a new definition of multivariate conditional
value-at-risk (MCVaR) as a set of vectors for discrete probability spaces. We
explore the properties of the vector-valued MCVaR (VMCVaR) and show the
advantages of VMCVaR over the existing definitions given for continuous random
variables when adapted to the discrete case.
</summary>
    <author>
      <name>Merve Merakli</name>
    </author>
    <author>
      <name>Simge Kucukyavuz</name>
    </author>
    <link href="http://arxiv.org/abs/1708.01324v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.01324v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0704.1348v3</id>
    <updated>2009-03-04T06:59:51Z</updated>
    <published>2007-04-11T13:37:47Z</published>
    <title>Large portfolio losses: A dynamic contagion model</title>
    <summary>  Using particle system methodologies we study the propagation of financial
distress in a network of firms facing credit risk. We investigate the
phenomenon of a credit crisis and quantify the losses that a bank may suffer in
a large credit portfolio. Applying a large deviation principle we compute the
limiting distributions of the system and determine the time evolution of the
credit quality indicators of the firms, deriving moreover the dynamics of a
global financial health indicator. We finally describe a suitable version of
the "Central Limit Theorem" useful to study large portfolio losses. Simulation
results are provided as well as applications to portfolio loss distribution
analysis.
</summary>
    <author>
      <name>Paolo Dai Pra</name>
    </author>
    <author>
      <name>Wolfgang J. Runggaldier</name>
    </author>
    <author>
      <name>Elena Sartori</name>
    </author>
    <author>
      <name>Marco Tolotti</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1214/08-AAP544</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1214/08-AAP544" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published in at http://dx.doi.org/10.1214/08-AAP544 the Annals of
  Applied Probability (http://www.imstat.org/aap/) by the Institute of
  Mathematical Statistics (http://www.imstat.org)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Annals of Applied Probability 2009, Vol. 19, No. 1, 347-394</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0704.1348v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0704.1348v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="60K35, 91B70 (Primary)" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0707.3478v2</id>
    <updated>2007-07-27T13:30:40Z</updated>
    <published>2007-07-24T14:10:57Z</published>
    <title>Credit risk - A structural model with jumps and correlations</title>
    <summary>  We set up a structural model to study credit risk for a portfolio containing
several or many credit contracts. The model is based on a jump--diffusion
process for the risk factors, i.e. for the company assets. We also include
correlations between the companies. We discuss that models of this type have
much in common with other problems in statistical physics and in the theory of
complex systems. We study a simplified version of our model analytically.
Furthermore, we perform extensive numerical simulations for the full model. The
observables are the loss distribution of the credit portfolio, its moments and
other quantities derived thereof. We compile detailed information about the
parameter dependence of these observables. In the course of setting up and
analyzing our model, we also give a review of credit risk modeling for a
physics audience.
</summary>
    <author>
      <name>Rudi Schäfer</name>
    </author>
    <author>
      <name>Markus Sjölin</name>
    </author>
    <author>
      <name>Andreas Sundin</name>
    </author>
    <author>
      <name>Michal Wolanski</name>
    </author>
    <author>
      <name>Thomas Guhr</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.physa.2007.04.053</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.physa.2007.04.053" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">24 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Physica A 383, 533 (2007)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0707.3478v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0707.3478v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0710.4106v1</id>
    <updated>2007-10-22T17:03:37Z</updated>
    <published>2007-10-22T17:03:37Z</published>
    <title>Cash Sub-additive Risk Measures and Interest Rate Ambiguity</title>
    <summary>  A new class of risk measures called cash sub-additive risk measures is
introduced to assess the risk of future financial, nonfinancial and insurance
positions. The debated cash additive axiom is relaxed into the cash sub
additive axiom to preserve the original difference between the numeraire of the
current reserve amounts and future positions. Consequently, cash sub-additive
risk measures can model stochastic and/or ambiguous interest rates or
defaultable contingent claims. Practical examples are presented and in such
contexts cash additive risk measures cannot be used. Several representations of
the cash sub-additive risk measures are provided. The new risk measures are
characterized by penalty functions defined on a set of sub-linear probability
measures and can be represented using penalty functions associated with cash
additive risk measures defined on some extended spaces. The issue of the
optimal risk transfer is studied in the new framework using inf-convolution
techniques. Examples of dynamic cash sub-additive risk measures are provided
via BSDEs where the generator can locally depend on the level of the cash
sub-additive risk measure.
</summary>
    <author>
      <name>Nicole El Karoui</name>
    </author>
    <author>
      <name>Claudia Ravanelli</name>
    </author>
    <link href="http://arxiv.org/abs/0710.4106v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0710.4106v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0804.3209v1</id>
    <updated>2008-04-20T18:21:16Z</updated>
    <published>2008-04-20T18:21:16Z</published>
    <title>Convex Risk Measures: Lebesgue Property on one Period and Multi Period
  Risk Measures and Application in Capital Allocation Problem</title>
    <summary>  In this work we study the Lebesgue property for convex risk measures on the
space of bounded c\`adl\`ag random processes ($\mathcal{R}^\infty$). Lebesgue
property has been defined for one period convex risk measures in \cite{Jo} and
earlier had been studied in \cite{De} for coherent risk measures. We introduce
and study the Lebesgue property for convex risk measures in the multi period
framework. We give presentation of all convex risk measures with Lebesgue
property on bounded c\`adl\`ag processes. To do that we need to have a complete
description of compact sets of $\mathcal{A}^1$. The main mathematical
contribution of this paper is the characterization of the compact sets of
$\mathcal{A}^p$ (including $\mathcal{A}^1$). At the final part of this paper,
we will solve the Capital Allocation Problem when we work with coherent risk
measures.
</summary>
    <author>
      <name>Hirbod Assa</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/0804.3209v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0804.3209v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0805.3129v1</id>
    <updated>2008-05-20T17:48:54Z</updated>
    <published>2008-05-20T17:48:54Z</published>
    <title>Deterministic definition of the capital risk</title>
    <summary>  In this paper we propose a look at the capital risk problem inspired by
deterministic, known from classical mechanics, problem of juggling. We propose
capital equivalents to the Newton's laws of motion and on this basis we
determine the most secure form of credit repayment with regard to maximisation
of profit. Then we extend the Newton's laws to models in linear spaces of
arbitrary dimension with the help of matrix rates of return. The matrix rates
describe the evolution of multidimensional capital and they are sensitive to
both quantitative changes of individual elements and flows between them. This
allows us for simultaneous analysis of evolution of complex capital in both
continuous and discrete time models.
</summary>
    <author>
      <name>Anna Szczypinska</name>
    </author>
    <author>
      <name>Edward W. Piotrowski</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages,</arxiv:comment>
    <link href="http://arxiv.org/abs/0805.3129v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0805.3129v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0806.3399v1</id>
    <updated>2008-06-20T14:31:09Z</updated>
    <published>2008-06-20T14:31:09Z</published>
    <title>Heterogeneous credit portfolios and the dynamics of the aggregate losses</title>
    <summary>  We study the impact of contagion in a network of firms facing credit risk. We
describe an intensity based model where the homogeneity assumption is broken by
introducing a random environment that makes it possible to take into account
the idiosyncratic characteristics of the firms. We shall see that our model
goes behind the identification of groups of firms that can be considered
basically exchangeable. Despite this heterogeneity assumption our model has the
advantage of being totally tractable. The aim is to quantify the losses that a
bank may suffer in a large credit portfolio. Relying on a large deviation
principle on the trajectory space of the process, we state a suitable law of
large number and a central limit theorem useful to study large portfolio
losses. Simulation results are provided as well as applications to portfolio
loss distribution analysis.
</summary>
    <author>
      <name>Paolo Dai Pra</name>
    </author>
    <author>
      <name>Marco Tolotti</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">35 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0806.3399v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0806.3399v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="60K35; 91B70" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0806.4125v2</id>
    <updated>2008-12-18T06:49:51Z</updated>
    <published>2008-06-25T15:10:22Z</published>
    <title>Ruin models with investment income</title>
    <summary>  This survey treats the problem of ruin in a risk model when assets earn
investment income. In addition to a general presentation of the problem, topics
covered are a presentation of the relevant integro-differential equations,
exact and numerical solutions, asymptotic results, bounds on the ruin
probability and also the possibility of minimizing the ruin probability by
investment and possibly reinsurance control. The main emphasis is on continuous
time models, but discrete time models are also covered. A fairly extensive list
of references is provided, particularly of papers published after 1998. For
more references to papers published before that, the reader can consult [47].
</summary>
    <author>
      <name>Jostein Paulsen</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1214/08-PS134</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1214/08-PS134" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published in at http://dx.doi.org/10.1214/08-PS134 the Probability
  Surveys (http://www.i-journals.org/ps/) by the Institute of Mathematical
  Statistics (http://www.imstat.org)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Probability Surveys 2008, Vol. 5, No. 0, 416-434</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0806.4125v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0806.4125v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="60G99 (Primary) 60G40, 60G44, 60J25, 60J75 (Secondary)" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0807.4958v1</id>
    <updated>2008-07-30T22:46:31Z</updated>
    <published>2008-07-30T22:46:31Z</published>
    <title>Hazard processes and martingale hazard processes</title>
    <summary>  In this paper, we provide a solution to two problems which have been open in
default time modeling in credit risk. We first show that if $\tau$ is an
arbitrary random (default) time such that its Az\'ema's supermartingale
$Z_t^\tau=\P(\tau&gt;t|\F_t)$ is continuous, then $\tau$ avoids stopping times. We
then disprove a conjecture about the equality between the hazard process and
the martingale hazard process, which first appeared in \cite{jenbrutk1}, and we
show how it should be modified to become a theorem. The pseudo-stopping times,
introduced in \cite{AshkanYor}, appear as the most general class of random
times for which these two processes are equal. We also show that these two
processes always differ when $\tau$ is an honest time.
</summary>
    <author>
      <name>Delia Coculescu</name>
    </author>
    <author>
      <name>Ashkan Nikeghbali</name>
    </author>
    <link href="http://arxiv.org/abs/0807.4958v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0807.4958v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="60G07, 60G44, 60G99" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0811.0800v2</id>
    <updated>2008-11-16T15:40:51Z</updated>
    <published>2008-11-05T19:27:52Z</published>
    <title>The instability of downside risk measures</title>
    <summary>  We study the feasibility and noise sensitivity of portfolio optimization
under some downside risk measures (Value-at-Risk, Expected Shortfall, and
semivariance) when they are estimated by fitting a parametric distribution on a
finite sample of asset returns. We find that the existence of the optimum is a
probabilistic issue, depending on the particular random sample, in all three
cases. At a critical combination of the parameters of these problems we find an
algorithmic phase transition, separating the phase where the optimization is
feasible from the one where it is not. This transition is similar to the one
discovered earlier for Expected Shortfall based on historical time series. We
employ the replica method to compute the phase diagram, as well as to obtain
the critical exponent of the estimation error that diverges at the critical
point. The analytical results are corroborated by Monte Carlo simulations.
</summary>
    <author>
      <name>Istvan Varga-Haszonits</name>
    </author>
    <author>
      <name>Imre Kondor</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0811.0800v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0811.0800v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0902.2756v1</id>
    <updated>2009-02-16T18:37:59Z</updated>
    <published>2009-02-16T18:37:59Z</published>
    <title>Monitoring dates of maximal risk</title>
    <summary>  Monitoring means to observe a system for any changes which may occur over
time, using a monitor or measuring device of some sort. In this paper we
formulate a problem of monitoring dates of maximal risk of a financial
position. Thus, the systems we are going to observe arise from situations in
finance. The measuring device we are going to use is a time-consistent measure
of risk.
  In the first part of the paper we discuss the numerical representation of
conditional convex risk measures which are defined in a space Lp(F,R) and take
values in L1(G,R). This will allow us to consider time-consistent convex risk
measures in L1(R).
  In the second part of the paper we use a time-consistent convex risk measure
in order to define an abstract problem of monitoring stopping times of maximal
risk. The penalty function involved in the robust representation changes
qualitatively the time when maximal risk is for the first time identified. A
phenomenon which we discuss from the point of view of robust statistics.
</summary>
    <author>
      <name>Erick Trevino Aguilar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Working Paper</arxiv:comment>
    <link href="http://arxiv.org/abs/0902.2756v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0902.2756v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0904.0870v1</id>
    <updated>2009-04-06T09:20:23Z</updated>
    <published>2009-04-06T09:20:23Z</published>
    <title>Risk Measures in Quantitative Finance</title>
    <summary>  This paper was presented and written for two seminars: a national UK
University Risk Conference and a Risk Management industry workshop. The target
audience is therefore a cross section of Academics and industry professionals.
  The current ongoing global credit crunch has highlighted the importance of
risk measurement in Finance to companies and regulators alike. Despite risk
measurement's central importance to risk management, few papers exist reviewing
them or following their evolution from its foremost beginnings up to the
present day risk measures.
  This paper reviews the most important portfolio risk measures in Financial
Mathematics, from Bernoulli (1738) to Markowitz's Portfolio Theory, to the
presently preferred risk measures such as CVaR (conditional Value at Risk). We
provide a chronological review of the risk measures and survey less commonly
known risk measures e.g. Treynor ratio.
</summary>
    <author>
      <name>Sovan Mitra</name>
    </author>
    <link href="http://arxiv.org/abs/0904.0870v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0904.0870v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0904.1483v1</id>
    <updated>2009-04-09T09:23:37Z</updated>
    <published>2009-04-09T09:23:37Z</published>
    <title>Model uncertainty in claims reserving within Tweedie's compound Poisson
  models</title>
    <summary>  In this paper we examine the claims reserving problem using Tweedie's
compound Poisson model. We develop the maximum likelihood and Bayesian Markov
chain Monte Carlo simulation approaches to fit the model and then compare the
estimated models under different scenarios. The key point we demonstrate
relates to the comparison of reserving quantities with and without model
uncertainty incorporated into the prediction. We consider both the model
selection problem and the model averaging solutions for the predicted reserves.
As a part of this process we also consider the sub problem of variable
selection to obtain a parsimonious representation of the model being fitted.
</summary>
    <author>
      <name>Gareth W. Peters</name>
    </author>
    <author>
      <name>Pavel V. Shevchenko</name>
    </author>
    <author>
      <name>Mario V. Wüthrich</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ASTIN Bulletin 39(1), pp.1-33, 2009</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0904.1483v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0904.1483v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.CP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0904.1653v2</id>
    <updated>2010-02-01T10:14:31Z</updated>
    <published>2009-04-10T08:00:08Z</published>
    <title>An extension of Davis and Lo's contagion model</title>
    <summary>  The present paper provides a multi-period contagion model in the credit risk
field. Our model is an extension of Davis and Lo's infectious default model. We
consider an economy of n firms which may default directly or may be infected by
other defaulting firms (a domino effect being also possible). The spontaneous
default without external influence and the infections are described by not
necessarily independent Bernoulli-type random variables. Moreover, several
contaminations could be required to infect another firm. In this paper we
compute the probability distribution function of the total number of defaults
in a dependency context. We also give a simple recursive algorithm to compute
this distribution in an exchangeability context. Numerical applications
illustrate the impact of exchangeability among direct defaults and among
contaminations, on different indicators calculated from the law of the total
number of defaults. We then examine the calibration of the model on iTraxx data
before and during the crisis. The dynamic feature together with the contagion
effect seem to have a significant impact on the model performance, especially
during the recent distressed period.
</summary>
    <author>
      <name>Didier Rullière</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">SAF</arxiv:affiliation>
    </author>
    <author>
      <name>Diana Dorobantu</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">SAF</arxiv:affiliation>
    </author>
    <author>
      <name>Areski Cousin</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">SAF</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/0904.1653v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0904.1653v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0904.1772v1</id>
    <updated>2009-04-11T02:40:00Z</updated>
    <published>2009-04-11T02:40:00Z</published>
    <title>A "Toy" Model for Operational Risk Quantification using Credibility
  Theory</title>
    <summary>  To meet the Basel II regulatory requirements for the Advanced Measurement
Approaches in operational risk, the bank's internal model should make use of
the internal data, relevant external data, scenario analysis and factors
reflecting the business environment and internal control systems. One of the
unresolved challenges in operational risk is combining of these data sources
appropriately. In this paper we focus on quantification of the low frequency
high impact losses exceeding some high threshold. We suggest a full credibility
theory approach to estimate frequency and severity distributions of these
losses by taking into account bank internal data, expert opinions and industry
data.
</summary>
    <author>
      <name>Hans Bühlmann</name>
    </author>
    <author>
      <name>Pavel V. Shevchenko</name>
    </author>
    <author>
      <name>Mario V. Wüthrich</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">The Journal of Operational Risk 2(1), pp. 3-19, 2007.
  www.journalofoperationalrisk.com</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0904.1772v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0904.1772v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0904.2910v1</id>
    <updated>2009-04-19T12:56:50Z</updated>
    <published>2009-04-19T12:56:50Z</published>
    <title>Addressing the Impact of Data Truncation and Parameter Uncertainty on
  Operational Risk Estimates</title>
    <summary>  Typically, operational risk losses are reported above some threshold. This
paper studies the impact of ignoring data truncation on the 0.999 quantile of
the annual loss distribution for operational risk for a broad range of
distribution parameters and truncation levels. Loss frequency and severity are
modelled by the Poisson and Lognormal distributions respectively. Two cases of
ignoring data truncation are studied: the "naive model" - fitting a Lognormal
distribution with support on a positive semi-infinite interval, and "shifted
model" - fitting a Lognormal distribution shifted to the truncation level. For
all practical cases, the "naive model" leads to underestimation (that can be
severe) of the 0.999 quantile. The "shifted model" overestimates the 0.999
quantile except some cases of small underestimation for large truncation
levels. Conservative estimation of capital charge is usually acceptable and the
use of the "shifted model" can be justified while the "naive model" should not
be allowed. However, if parameter uncertainty is taken into account (in
practice it is often ignored), the "shifted model" can lead to considerable
underestimation of capital charge. This is demonstrated with a practical
example.
</summary>
    <author>
      <name>Xiaolin Luo</name>
    </author>
    <author>
      <name>Pavel V. Shevchenko</name>
    </author>
    <author>
      <name>John B. Donnelly</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">The Journal of Operational Risk 2(4), 3-26, 2007
  www.journalofoperationalrisk.com</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0904.2910v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0904.2910v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.CP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0904.4074v2</id>
    <updated>2009-07-31T07:02:31Z</updated>
    <published>2009-04-27T02:12:24Z</published>
    <title>Dynamic operational risk: modeling dependence and combining different
  sources of information</title>
    <summary>  In this paper, we model dependence between operational risks by allowing risk
profiles to evolve stochastically in time and to be dependent. This allows for
a flexible correlation structure where the dependence between frequencies of
different risk categories and between severities of different risk categories
as well as within risk categories can be modeled. The model is estimated using
Bayesian inference methodology, allowing for combination of internal data,
external data and expert opinion in the estimation procedure. We use a
specialized Markov chain Monte Carlo simulation methodology known as Slice
sampling to obtain samples from the resulting posterior distribution and
estimate the model parameters.
</summary>
    <author>
      <name>Gareth W. Peters</name>
    </author>
    <author>
      <name>Pavel V. Shevchenko</name>
    </author>
    <author>
      <name>Mario V. Wüthrich</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">The Journal of Operational Risk 4(2), pp. 69-104, 2009
  www.journalofoperationalrisk.com</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0904.4074v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0904.4074v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.CP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0904.4075v2</id>
    <updated>2009-07-31T01:29:58Z</updated>
    <published>2009-04-27T02:27:43Z</published>
    <title>Modeling operational risk data reported above a time-varying threshold</title>
    <summary>  Typically, operational risk losses are reported above a threshold. Fitting
data reported above a constant threshold is a well known and studied problem.
However, in practice, the losses are scaled for business and other factors
before the fitting and thus the threshold is varying across the scaled data
sample. A reporting level may also change when a bank changes its reporting
policy. We present both the maximum likelihood and Bayesian Markov chain Monte
Carlo approaches to fitting the frequency and severity loss distributions using
data in the case of a time varying threshold. Estimation of the annual loss
distribution accounting for parameter uncertainty is also presented.
</summary>
    <author>
      <name>Pavel V. Shevchenko</name>
    </author>
    <author>
      <name>Grigory Temnov</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">The Journal of Operational Risk 4(2), pp. 19-42, 2009
  www.journalofoperationalrisk.com</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0904.4075v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0904.4075v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.CP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0904.4099v2</id>
    <updated>2011-02-09T02:47:10Z</updated>
    <published>2009-04-27T07:46:12Z</published>
    <title>Local Risk Decomposition for High-frequency Trading Systems</title>
    <summary>  In the present work we address the problem of evaluating the historical
performance of a trading strategy or a certain portfolio of assets. Common
indicators such as the Sharpe ratio and the risk adjusted return have
significant drawbacks. In particular, they are global indices, that is they do
not preserve any 'local' information about the performance dynamics either in
time or for a particular investment horizon. This information could be
fundamental for practitioners as the past performance can be affected by the
non-stationarity of financial market. In order to highlight this feature, we
introduce the 'local risk decomposition' (LRD) formalism, where dynamical
information about a strategy's performance is retained. This framework,
motivated by the multi-scaling techniques used in complex system theory, is
particularly suitable for high-frequency trading systems and can be applied
into problems of strategy optimization.
</summary>
    <author>
      <name>M. Bartolozzi</name>
    </author>
    <author>
      <name>C. Mellen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages and 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0904.4099v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0904.4099v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.TR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0904.4430v2</id>
    <updated>2009-09-29T14:21:34Z</updated>
    <published>2009-04-28T15:36:25Z</published>
    <title>Collective firm bankruptcies and phase transition in rating dynamics</title>
    <summary>  We present a simple model of firm rating evolution. We consider two sources
of defaults: individual dynamics of economic development and Potts-like
interactions between firms. We show that such a defined model leads to phase
transition, which results in collective defaults. The existence of the
collective phase depends on the mean interaction strength. For small
interaction strength parameters, there are many independent bankruptcies of
individual companies. For large parameters, there are giant collective defaults
of firm clusters. In the case when the individual firm dynamics favors dumping
of rating changes, there is an optimal strength of the firm's interactions from
the systemic risk point of view.
</summary>
    <author>
      <name>Paweł Sieczka</name>
    </author>
    <author>
      <name>Janusz A. Hołyst</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1140/epjb/e2009-00322-1</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1140/epjb/e2009-00322-1" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">The European Physical Journal B 71 461-466 (2009)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0904.4430v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0904.4430v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0905.3928v2</id>
    <updated>2010-03-05T09:00:11Z</updated>
    <published>2009-05-24T22:47:49Z</published>
    <title>Estimating discriminatory power and PD curves when the number of
  defaults is small</title>
    <summary>  The intention with this paper is to provide all the estimation concepts and
techniques that are needed to implement a two-phases approach to the parametric
estimation of probability of default (PD) curves. In the first phase of this
approach, a raw PD curve is estimated based on parameters that reflect
discriminatory power. In the second phase of the approach, the raw PD curve is
calibrated to fit a target unconditional PD. The concepts and techniques
presented include a discussion of different definitions of area under the curve
(AUC) and accuracy ratio (AR), a simulation study on the performance of
confidence interval estimators for AUC, a discussion of the one-parametric
approach to the estimation of PD curves by van der Burgt (2008) and alternative
approaches, as well as a simulation study on the performance of the presented
PD curve estimators. The topics are treated in depth in order to provide the
full rationale behind them and to produce results that can be implemented
immediately.
</summary>
    <author>
      <name>Dirk Tasche</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">58 pages, 10 figures, 10 tables, minor corrections</arxiv:comment>
    <link href="http://arxiv.org/abs/0905.3928v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0905.3928v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0906.3425v1</id>
    <updated>2009-06-18T12:22:02Z</updated>
    <published>2009-06-18T12:22:02Z</published>
    <title>Conditional Value-at-Risk Constraint and Loss Aversion Utility Functions</title>
    <summary>  We provide an economic interpretation of the practice consisting in
incorporating risk measures as constraints in a classic expected return
maximization problem. For what we call the infimum of expectations class of
risk measures, we show that if the decision maker (DM) maximizes the
expectation of a random return under constraint that the risk measure is
bounded above, he then behaves as a ``generalized expected utility maximizer''
in the following sense. The DM exhibits ambiguity with respect to a family of
utility functions defined on a larger set of decisions than the original one;
he adopts pessimism and performs first a minimization of expected utility over
this family, then performs a maximization over a new decisions set. This
economic behaviour is called ``Maxmin under risk'' and studied by Maccheroni
(2002). This economic interpretation allows us to exhibit a loss aversion
factor when the risk measure is the Conditional Value-at-Risk.
</summary>
    <author>
      <name>Laetitia Andrieu</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">EDF R&amp;D</arxiv:affiliation>
    </author>
    <author>
      <name>Michel De Lara</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CERMICS</arxiv:affiliation>
    </author>
    <author>
      <name>Babacar Seck</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CERMICS</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/0906.3425v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0906.3425v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0906.3968v2</id>
    <updated>2012-02-12T14:25:41Z</updated>
    <published>2009-06-22T09:39:25Z</published>
    <title>A Bayesian Networks Approach to Operational Risk</title>
    <summary>  A system for Operational Risk management based on the computational paradigm
of Bayesian Networks is presented. The algorithm allows the construction of a
Bayesian Network targeted for each bank using only internal loss data, and
takes into account in a simple and realistic way the correlations among
different processes of the bank. The internal losses are averaged over a
variable time horizon, so that the correlations at different times are removed,
while the correlations at the same time are kept: the averaged losses are thus
suitable to perform the learning of the network topology and parameters. The
algorithm has been validated on synthetic time series. It should be stressed
that the practical implementation of the proposed algorithm has a small impact
on the organizational structure of a bank and requires an investment in human
resources limited to the computational area.
</summary>
    <author>
      <name>V. Aquaro</name>
    </author>
    <author>
      <name>M. Bardoscia</name>
    </author>
    <author>
      <name>R. Bellotti</name>
    </author>
    <author>
      <name>A. Consiglio</name>
    </author>
    <author>
      <name>F. De Carlo</name>
    </author>
    <author>
      <name>G. Ferri</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.physa.2009.12.043</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.physa.2009.12.043" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Physica A 389 (2010), pp. 1721-1728</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0906.3968v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0906.3968v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0907.4093v1</id>
    <updated>2009-07-23T15:04:52Z</updated>
    <published>2009-07-23T15:04:52Z</published>
    <title>Preferences Yielding the "Precautionary Effect"</title>
    <summary>  Consider an agent taking two successive decisions to maximize his expected
utility under uncertainty. After his first decision, a signal is revealed that
provides information about the state of nature. The observation of the signal
allows the decision-maker to revise his prior and the second decision is taken
accordingly. Assuming that the first decision is a scalar representing
consumption, the \emph{precautionary effect} holds when initial consumption is
less in the prospect of future information than without (no signal).
\citeauthor{Epstein1980:decision} in \citep*{Epstein1980:decision} has provided
the most operative tool to exhibit the precautionary effect. Epstein's Theorem
holds true when the difference of two convex functions is either convex or
concave, which is not a straightforward property, and which is difficult to
connect to the primitives of the economic model. Our main contribution consists
in giving a geometric characterization of when the difference of two convex
functions is convex, then in relating this to the primitive utility model. With
this tool, we are able to study and unite a large body of the literature on the
precautionary effect.
</summary>
    <author>
      <name>Michel De Lara</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CERMICS</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/0907.4093v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0907.4093v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0909.1383v3</id>
    <updated>2009-12-15T01:26:22Z</updated>
    <published>2009-09-08T14:50:17Z</published>
    <title>Hidden Noise Structure and Random Matrix Models of Stock Correlations</title>
    <summary>  We find a novel correlation structure in the residual noise of stock market
returns that is remarkably linked to the composition and stability of the top
few significant factors driving the returns, and moreover indicates that the
noise band is composed of multiple subbands that do not fully mix. Our findings
allow us to construct effective generalized random matrix theory market models
that are closely related to correlation and eigenvector clustering. We show how
to use these models in a simulation that incorporates heavy tails. Finally, we
demonstrate how a subtle purely stationary risk estimation bias can arise in
the conventional cleaning prescription.
</summary>
    <author>
      <name>Ivailo I. Dimov</name>
    </author>
    <author>
      <name>Petter N. Kolm</name>
    </author>
    <author>
      <name>Lee Maclin</name>
    </author>
    <author>
      <name>Dan Y. C. Shiber</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 3 figures: author initials added, references added</arxiv:comment>
    <link href="http://arxiv.org/abs/0909.1383v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0909.1383v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0909.3978v2</id>
    <updated>2012-05-07T17:36:38Z</updated>
    <published>2009-09-22T12:33:56Z</published>
    <title>A Generalized Fourier Transform Approach to Risk Measures</title>
    <summary>  We introduce the formalism of generalized Fourier transforms in the context
of risk management. We develop a general framework to efficiently compute the
most popular risk measures, Value-at-Risk and Expected Shortfall (also known as
Conditional Value-at-Risk). The only ingredient required by our approach is the
knowledge of the characteristic function describing the financial data in use.
This allows to extend risk analysis to those non-Gaussian models defined in the
Fourier space, such as Levy noise driven processes and stochastic volatility
models. We test our analytical results on data sets coming from various
financial indexes, finding that our predictions outperform those provided by
the standard Log-Normal dynamics and are in remarkable agreement with those of
the benchmark historical approach.
</summary>
    <author>
      <name>G. Bormetti</name>
    </author>
    <author>
      <name>V. Cazzola</name>
    </author>
    <author>
      <name>G. Livan</name>
    </author>
    <author>
      <name>G. Montagna</name>
    </author>
    <author>
      <name>O. Nicrosini</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1088/1742-5468/2010/01/P01005</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1088/1742-5468/2010/01/P01005" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Feller's condition removed, some typos in Appendix A amended</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">J. Stat. Mech. (2010) P01005</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0909.3978v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0909.3978v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.CP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0910.2367v2</id>
    <updated>2009-12-19T19:53:42Z</updated>
    <published>2009-10-13T11:49:07Z</published>
    <title>Risk Concentration and Diversification: Second-Order Properties</title>
    <summary>  The quantification of diversification benefits due to risk aggregation plays
a prominent role in the (regulatory) capital management of large firms within
the financial industry. However, the complexity of today's risk landscape makes
a quantifiable reduction of risk concentration a challenging task. In the
present paper we discuss some of the issues that may arise. The theory of
second-order regular variation and second-order subexponentiality provides the
ideal methodological framework to derive second-order approximations for the
risk concentration and the diversification benefit.
</summary>
    <author>
      <name>Matthias Degen</name>
    </author>
    <author>
      <name>Dominik D. Lambrigger</name>
    </author>
    <author>
      <name>Johan Segers</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages, 5 figures; status: submitted; references and introduction
  revised with more discussion on Basel II, Solvency II, and risk
  diversification</arxiv:comment>
    <link href="http://arxiv.org/abs/0910.2367v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0910.2367v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1001.1867v1</id>
    <updated>2010-01-12T20:00:20Z</updated>
    <published>2010-01-12T20:00:20Z</published>
    <title>Allocation d'actifs selon le critère de maximisation des fonds propres
  économiques en assurance non-vie</title>
    <summary>  The economic equities maximization criterion (MFPE) leads to the choice of
financial portfolio, which maximizes the ratio of the expected value of the
insurance company on the capital. This criterion is presented in the framework
of a non-life insurance company and is applied within the framework of the
French legislation and in a lawful context inspired of the works in progress
about the European project Solvency 2. In the French regulation case, the
required solvency margin does not depend of the asset allocation. It is quite
different in the Solvency 2 framework because the target capital has to control
the global risk of the company. And the financial risk takes part of this
global risk. Thus the economic equities maximization criterion leads to search
a couple asset allocation / equities which solves a stochastic program. A
numerical illustration makes it possible to analyze the consequences of the
introduction of a Solvency 2 framework on the technical reserves and the
equities of a non-life insurance company and on the optimal allocation due to
the economic equities maximization criterion. Finally, the impact of a
misspecification of the risky asset model on the optimal allocation is
illustrated.
</summary>
    <author>
      <name>Frédéric Planchet</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">SAF</arxiv:affiliation>
    </author>
    <author>
      <name>Pierre-Emanuel Thérond</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">SAF</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Bulletin Fran\c{c}ais d'Actuariat 7, 13 (2007) 10...38</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1001.1867v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1001.1867v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1002.2604v2</id>
    <updated>2015-10-25T23:47:00Z</updated>
    <published>2010-02-12T17:29:48Z</published>
    <title>The two defaults scenario for stressing credit portfolio loss
  distributions</title>
    <summary>  The impact of a stress scenario of default events on the loss distribution of
a credit portfolio can be assessed by determining the loss distribution
conditional on these events. While it is conceptually easy to estimate loss
distributions conditional on default events by means of Monte Carlo simulation,
it becomes impractical for two or more simultaneous defaults as then the
conditioning event is extremely rare. We provide an analytical approach to the
calculation of the conditional loss distribution for the CreditRisk+ portfolio
model with independent random loss given default distributions. The analytical
solution for this case can be used to check the accuracy of an approximation to
the conditional loss distribution whereby the unconditional model is run with
stressed input probabilities of default (PDs). It turns out that this
approximation is unbiased. Numerical examples, however, suggest that the
approximation may be seriously inaccurate but that the inaccuracy leads to
overestimation of tail losses and hence the approach errs on the conservative
side.
</summary>
    <author>
      <name>Dirk Tasche</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.3390/jrfm9010001</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.3390/jrfm9010001" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages, 1 figure, 2 tables</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Risk and Financial Management 9(1), 1-18, 2016</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1002.2604v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1002.2604v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91G10, 91G40" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1002.4817v3</id>
    <updated>2010-05-24T09:47:59Z</updated>
    <published>2010-02-25T16:54:11Z</published>
    <title>Accounting for risk of non linear portfolios: a novel Fourier approach</title>
    <summary>  The presence of non linear instruments is responsible for the emergence of
non Gaussian features in the price changes distribution of realistic
portfolios, even for Normally distributed risk factors. This is especially true
for the benchmark Delta Gamma Normal model, which in general exhibits
exponentially damped power law tails. We show how the knowledge of the model
characteristic function leads to Fourier representations for two standard risk
measures, the Value at Risk and the Expected Shortfall, and for their
sensitivities with respect to the model parameters. We detail the numerical
implementation of our formulae and we emphasizes the reliability and efficiency
of our results in comparison with Monte Carlo simulation.
</summary>
    <author>
      <name>Giacomo Bormetti</name>
    </author>
    <author>
      <name>Valentina Cazzola</name>
    </author>
    <author>
      <name>Danilo Delpini</name>
    </author>
    <author>
      <name>Giacomo Livan</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1140/epjb/e2010-00199-9</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1140/epjb/e2010-00199-9" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 12 figures. Final version accepted for publication on Eur.
  Phys. J. B</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Eur. Phys. J. B 76 157-165 (2010)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1002.4817v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1002.4817v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1003.2688v3</id>
    <updated>2010-03-20T15:48:16Z</updated>
    <published>2010-03-13T08:02:11Z</published>
    <title>WARNING: Physics Envy May Be Hazardous To Your Wealth!</title>
    <summary>  The quantitative aspirations of economists and financial analysts have for
many years been based on the belief that it should be possible to build models
of economic systems - and financial markets in particular - that are as
predictive as those in physics. While this perspective has led to a number of
important breakthroughs in economics, "physics envy" has also created a false
sense of mathematical precision in some cases. We speculate on the origins of
physics envy, and then describe an alternate perspective of economic behavior
based on a new taxonomy of uncertainty. We illustrate the relevance of this
taxonomy with two concrete examples: the classical harmonic oscillator with
some new twists that make physics look more like economics, and a quantitative
equity market-neutral strategy. We conclude by offering a new interpretation of
tail events, proposing an "uncertainty checklist" with which our taxonomy can
be implemented, and considering the role that quants played in the current
financial crisis.
</summary>
    <author>
      <name>Andrew W. Lo</name>
    </author>
    <author>
      <name>Mark T. Mueller</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">v3 adds 2 references</arxiv:comment>
    <link href="http://arxiv.org/abs/1003.2688v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1003.2688v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1004.0595v3</id>
    <updated>2011-06-17T11:21:37Z</updated>
    <published>2010-04-05T08:53:05Z</published>
    <title>Precautionary Measures for Credit Risk Management in Jump Models</title>
    <summary>  Sustaining efficiency and stability by properly controlling the equity to
asset ratio is one of the most important and difficult challenges in bank
management. Due to unexpected and abrupt decline of asset values, a bank must
closely monitor its net worth as well as market conditions, and one of its
important concerns is when to raise more capital so as not to violate capital
adequacy requirements. In this paper, we model the tradeoff between avoiding
costs of delay and premature capital raising, and solve the corresponding
optimal stopping problem. In order to model defaults in a bank's loan/credit
business portfolios, we represent its net worth by Levy processes, and solve
explicitly for the double exponential jump diffusion process and for a general
spectrally negative Levy process.
</summary>
    <author>
      <name>Masahiko Egami</name>
    </author>
    <author>
      <name>Kazutoshi Yamazaki</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1080/17442508.2011.653566</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1080/17442508.2011.653566" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">31 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1004.0595v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1004.0595v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="60G40, 60J75" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1004.0685v3</id>
    <updated>2010-04-12T18:46:12Z</updated>
    <published>2010-04-05T19:22:05Z</published>
    <title>Simple Fuzzy Score for Russian Public Companies Risk of Default</title>
    <summary>  The model is aimed to discriminate the 'good' and the 'bad' companies in
Russian corporate sector based on their financial statements data based on
Russian Accounting Standards. The data sample consists of 126 Russian public
companies- issuers of Ruble bonds which represent about 36% of total number of
corporate bonds issuers. 25 companies have defaulted on their debt in 2008-2009
which represent around 30% of default cases. No SPV companies were included in
the sample. The model shows in-sample Gini AR about 73% and gives a reasonable
and simple rule of mapping to external ratings. The model can be used to
calculate implied credit rating for Russian companies which many of them don't
have.
</summary>
    <author>
      <name>Sergey Ivliev</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1004.0685v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1004.0685v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.5.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1004.1670v4</id>
    <updated>2012-04-20T19:05:19Z</updated>
    <published>2010-04-10T02:24:12Z</published>
    <title>Any Regulation of Risk Increases Risk</title>
    <summary>  We show that any objective risk measurement algorithm mandated by central
banks for regulated financial entities will result in more risk being taken on
by those financial entities than would otherwise be the case. Furthermore, the
risks taken on by the regulated financial entities are far more systemically
concentrated than they would have been otherwise, making the entire financial
system more fragile. This result leaves three directions for the future of
financial regulation: continue regulating by enforcing risk measurement
algorithms at the cost of occasional severe crises, regulate more severely and
subjectively by fully nationalizing all financial entities, or abolish all
central banking regulations including deposit insurance to let risk be
determined by the entities themselves and, ultimately, by their depositors
through voluntary market transactions rather than by the taxpayers through
enforced government participation.
</summary>
    <author>
      <name>Philip Z. Maymin</name>
    </author>
    <author>
      <name>Zakhar G. Maymin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">25 pages; forthcoming in Financial Markets and Portfolio Management</arxiv:comment>
    <link href="http://arxiv.org/abs/1004.1670v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1004.1670v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1004.5524v2</id>
    <updated>2010-12-28T19:35:33Z</updated>
    <published>2010-04-30T13:27:24Z</published>
    <title>Risk measuring under model uncertainty</title>
    <summary>  The framework of this paper is that of risk measuring under uncertainty,
which is when no reference probability measure is given. To every regular
convex risk measure on ${\cal C}_b(\Omega)$, we associate a unique equivalence
class of probability measures on Borel sets, characterizing the riskless non
positive elements of ${\cal C}_b(\Omega)$. We prove that the convex risk
measure has a dual representation with a countable set of probability measures
absolutely continuous with respect to a certain probability measure in this
class.
  To get these results we study the topological properties of the dual of the
Banach space $L^1(c)$ associated to a capacity $c$.
  As application we obtain that every $G$-expectation $\E$ has a representation
with a countable set of probability measures absolutely continuous with respect
to a probability measure $P$ such that $P(|f|)=0$ iff $\E(|f|)=0$. We also
apply our results to the case of uncertain volatility.
</summary>
    <author>
      <name>Jocelyne Bion-Nadal</name>
    </author>
    <author>
      <name>Magali Kervarec</name>
    </author>
    <link href="http://arxiv.org/abs/1004.5524v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1004.5524v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1005.1356v4</id>
    <updated>2010-12-21T05:46:56Z</updated>
    <published>2010-05-09T02:20:28Z</published>
    <title>Theoretical and numerical Analysis on Optimal dividend policy of an
  insurance company with positive transaction cost and higher solvency</title>
    <summary>  Based on a point of view that solvency and security are first, this paper
considers regular-singular stochastic optimal control problem of a large
insurance company facing positive transaction cost asked by reinsurer under
solvency constraint. The company controls proportional reinsurance and dividend
pay-out policy to maximize the expected present value of the dividend pay-outs
until the time of bankruptcy. The paper aims at deriving the optimal retention
ratio, dividend payout level, explicit value function of the insurance company
via stochastic analysis and PDE methods. The results present the best
equilibrium point between maximization of dividend pay-outs and minimization of
risks. The paper also gets a risk-based capital standard to ensure the capital
requirement of can cover the total given risk. We present numerical results to
make analysis how the model parameters, such as, volatility, premium rate, and
risk level, impact on risk-based capital standard, optimal retention ratio,
optimal dividend payout level and the company's profit.
</summary>
    <author>
      <name>Zongxia Liang</name>
    </author>
    <author>
      <name>Jicheng Yao</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">30 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1005.1356v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1005.1356v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="Primary 91B30, 91B70, 93E20, Secondary 60H30, 60H10" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1006.5473v1</id>
    <updated>2010-06-28T21:24:09Z</updated>
    <published>2010-06-28T21:24:09Z</published>
    <title>Alarm System for Insurance Companies: A Strategy for Capital Allocation</title>
    <summary>  One possible way of risk management for an insurance company is to develop an
early and appropriate alarm system before the possible ruin. The ruin is
defined through the status of the aggregate risk process, which in turn is
determined by premium accumulation as well as claim settlement outgo for the
insurance company. The main purpose of this work is to design an effective
alarm system, i.e. to define alarm times and to recommend augmentation of
capital of suitable magnitude at those points to prevent or reduce the chance
of ruin. To draw a fair measure of effectiveness of alarm system, comparison is
drawn between an alarm system, with capital being added at the sound of every
alarm, and the corresponding system without any alarm, but an equivalently
higher initial capital. Analytical results are obtained in general setup and
this is backed up by simulated performances with various types of loss severity
distributions. This provides a strategy for suitably spreading out the capital
and yet addressing survivability concerns at satisfactory level.
</summary>
    <author>
      <name>Shubhabrata Das</name>
    </author>
    <author>
      <name>Marie Kratz</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Keywords: alarm system, capital accumulation function, efficiency,
  quantitative risk management, regulation, risk process, ruin probability. 29
  pages, 9 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1006.5473v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1006.5473v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B30, 60K30" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1007.0026v6</id>
    <updated>2012-02-12T14:13:00Z</updated>
    <published>2010-06-30T21:12:46Z</published>
    <title>A Dynamical Model for Forecasting Operational Losses</title>
    <summary>  A novel dynamical model for the study of operational risk in banks and
suitable for the calculation of the Value at Risk (VaR) is proposed. The
equation of motion takes into account the interactions among different bank's
processes, the spontaneous generation of losses via a noise term and the
efforts made by the bank to avoid their occurrence. Since the model is very
general, it can be tailored on the internal organizational structure of a
specific bank by estimating some of its parameters from historical operational
losses. The model is exactly solved in the case in which there are no causal
loops in the matrix of couplings and it is shown how the solution can be
exploited to estimate also the parameters of the noise. The forecasting power
of the model is investigated by using a fraction $f$ of simulated data to
estimate the parameters, showing that for $f = 0.75$ the VaR can be forecast
with an error $\simeq 10^{-3}$.
</summary>
    <author>
      <name>Marco Bardoscia</name>
    </author>
    <author>
      <name>Roberto Bellotti</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.physa.2011.12.046</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.physa.2011.12.046" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">30 pages, 3 figures, 2 tables</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Physica A 391 (2012), pp. 2641-2655</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1007.0026v6" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1007.0026v6" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1007.1908v1</id>
    <updated>2010-07-12T14:23:09Z</updated>
    <published>2010-07-12T14:23:09Z</published>
    <title>Target market risk evaluation</title>
    <summary>  After the shocking series of bankruptcies started in 2008, the public does
not trust anymore the classical methods of assessing business risks. The global
economic severe downturn caused demand for both developed and emerging
economies' exports to drop and the crisis became truly global. However, this
current crisis offers opportunities for those companies able to play well their
cards. Entering new markets has always been a hazardous entrepreneurial
attempt, but also a rewarding one, in the case of success. The paper presents a
new indicator meant for assessing the prospective of success or failure for a
company trying to enter a new market by using an associative strategy. In order
to take the right decision concerning the optimal market entry strategy,
marketers may use a software application, "AnBilant", created by a research
team from Hyperion University.
</summary>
    <author>
      <name>Anda Gheorghiu</name>
    </author>
    <author>
      <name>Anca Gheorghiu</name>
    </author>
    <author>
      <name>Ion Spanulescu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 15 figures, Conference ENEC2009, Bucharest, Romania</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Econophysics, New Economy and Complexity, ISSN:2065-2550, II-nd
  section (New Economy), pp.113-130</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1007.1908v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1007.1908v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1008.3427v1</id>
    <updated>2010-08-20T02:25:43Z</updated>
    <published>2010-08-20T02:25:43Z</published>
    <title>Log-supermodularity of weight functions and the loading monotonicity of
  weighted insurance premiums</title>
    <summary>  The paper is motivated by a problem concerning the monotonicity of insurance
premiums with respect to their loading parameter: the larger the parameter, the
larger the insurance premium is expected to be. This property, usually called
loading monotonicity, is satisfied by premiums that appear in the literature.
The increased interest in constructing new insurance premiums has raised a
question as to what weight functions would produce loading-monotonic premiums.
In this paper we demonstrate a decisive role of log-supermodularity in
answering this question. As a consequence, we establish - at a stroke - the
loading monotonicity of a number of well-known insurance premiums and offer a
host of further weight functions, and consequently of premiums, thus
illustrating the power of the herein suggested methodology for constructing
loading-monotonic insurance premiums.
</summary>
    <author>
      <name>Hristo S. Sendov</name>
    </author>
    <author>
      <name>Ying Wang</name>
    </author>
    <author>
      <name>Ricardas Zitikis</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1008.3427v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1008.3427v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.FA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.CP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1009.1269v1</id>
    <updated>2010-09-07T12:32:08Z</updated>
    <published>2010-09-07T12:32:08Z</published>
    <title>Optimal Dividend and reinsurance strategy of a Property Insurance
  Company under Catastrophe Risk</title>
    <summary>  We consider an optimal control problem of a property insurance company with
proportional reinsurance strategy. The insurance business brings in catastrophe
risk, such as earthquake and flood. The catastrophe risk could be partly
reduced by reinsurance. The management of the company controls the reinsurance
rate and dividend payments process to maximize the expected present value of
the dividends before bankruptcy. This is the first time to consider the
catastrophe risk in property insurance model, which is more realistic. We
establish the solution of the problem by the mixed singular-regular control of
jump diffusions. We first derive the optimal retention ratio, the optimal
dividend payments level, the optimal return function and the optimal control
strategy of the property insurance company, then the impacts of the catastrophe
risk and key model parameters on the optimal return function and the optimal
control strategy of the company are discussed.
</summary>
    <author>
      <name>Zongxia Liang</name>
    </author>
    <author>
      <name>Lin He</name>
    </author>
    <author>
      <name>Jiaoling Wu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">22 pages, 8 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1009.1269v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1009.1269v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="Primary 91B30, 91B70, 91B28, Secondary 60H10, 60H30" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1009.3638v3</id>
    <updated>2011-11-29T10:45:46Z</updated>
    <published>2010-09-19T13:32:28Z</published>
    <title>Scaling portfolio volatility and calculating risk contributions in the
  presence of serial cross-correlations</title>
    <summary>  In practice daily volatility of portfolio returns is transformed to longer
holding periods by multiplying by the square-root of time which assumes that
returns are not serially correlated. Under this assumption this procedure of
scaling can also be applied to contributions to volatility of the assets in the
portfolio. Close prices are often used to calculate the profit and loss of a
portfolio. Trading at exchanges located in distant time zones this can lead to
significant serial cross-correlations of the closing-time returns of the assets
in the portfolio. These serial correlations cause the square-root-of-time rule
to fail. Moreover volatility contributions in this setting turn out to be
misleading due to non-synchronous correlations. We address this issue and
provide alternative procedures for scaling volatility and calculating risk
contributions for arbitrary holding periods.
</summary>
    <author>
      <name>Nikolaus Rab</name>
    </author>
    <author>
      <name>Richard Warnung</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">26 pages, 3 figures, 3 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1009.3638v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1009.3638v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1009.3760v2</id>
    <updated>2010-10-20T18:32:39Z</updated>
    <published>2010-09-20T10:15:07Z</published>
    <title>Liquidity-adjusted Market Risk Measures with Stochastic Holding Period</title>
    <summary>  Within the context of risk integration, we introduce in risk measurement
stochastic holding period (SHP) models. This is done in order to obtain a
`liquidity-adjusted risk measure' characterized by the absence of a fixed time
horizon. The underlying assumption is that - due to changes on market liquidity
conditions - one operates along an `operational time' to which the P&amp;L process
of liquidating a market portfolio is referred. This framework leads to a
mixture of distributions for the portfolio returns, potentially allowing for
skewness, heavy tails and extreme scenarios. We analyze the impact of possible
distributional choices for the SHP. In a multivariate setting, we hint at the
possible introduction of dependent SHP processes, which potentially lead to non
linear dependence among the P&amp;L processes and therefore to tail dependence
across assets in the portfolio, although this may require drastic choices on
the SHP distributions. We also find that increasing dependence as measured by
Kendall's tau through common SHP's appears to be unfeasible. We finally discuss
potential developments following future availability of market data.
</summary>
    <author>
      <name>Damiano Brigo</name>
    </author>
    <author>
      <name>Claudio Nordio</name>
    </author>
    <link href="http://arxiv.org/abs/1009.3760v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1009.3760v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62G32, 91B28, 91B70" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1009.4143v1</id>
    <updated>2010-09-21T16:54:44Z</updated>
    <published>2010-09-21T16:54:44Z</published>
    <title>On the Savety Loading for Chain Ladder Estimates: A Monte Carlo
  Simulation Study</title>
    <summary>  A method for analysing the risk of taking a too low reserve level by use of
Chain Ladder method is developed. We give an answer to the question of how much
safety loading in terms of the Chain Ladder standard error has to be added to
the Chain Ladder reserve in order to reach a specified security level in loss
reserving. This is an important question in the framework of integrated risk
management of an insurance company. Furthermore we investigate the relative
bias of Chain Ladder estimators. We use Monte Carlo simulation technique as
well as the collective model of risk theory in each cell of run-off table. We
analyse deviation between Chain Ladder reserves and Monte Carlo simulated
reserves statistically. Our results document dependency on claim number and
claim size distribution types and parameters.
</summary>
    <author>
      <name>Magda Schiegl</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ASTIN Bulletin, Vol. 32, No.1, 2002, pp. 107 - 128</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1009.4143v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1009.4143v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.CP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1009.5401v2</id>
    <updated>2012-03-11T10:30:23Z</updated>
    <published>2010-09-27T21:20:31Z</published>
    <title>Capital allocation for credit portfolios under normal and stressed
  market conditions</title>
    <summary>  If the probability of default parameters (PDs) fed as input into a credit
portfolio model are estimated as through-the-cycle (TTC) PDs stressed market
conditions have little impact on the results of the capital calculations
conducted with the model. At first glance, this is totally different if the PDs
are estimated as point-in-time (PIT) PDs. However, it can be argued that the
reflection of stressed market conditions in input PDs should correspond to the
use of reduced correlation parameters or even the removal of correlations in
the model. Additionally, the confidence levels applied for the capital
calculations might be made reflective of the changing market conditions. We
investigate the interplay of PIT PDs, correlations, and confidence levels in a
credit portfolio model in more detail and analyse possible designs of
capital-levelling policies. Our findings may of interest to banks that want to
combine their approaches to capital measurement and allocation with active
portfolio management that, by its nature, needs to be reflective of current
market conditions.
</summary>
    <author>
      <name>Norbert Jobst</name>
    </author>
    <author>
      <name>Dirk Tasche</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, minor updates</arxiv:comment>
    <link href="http://arxiv.org/abs/1009.5401v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1009.5401v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62P05" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1011.1329v1</id>
    <updated>2010-11-05T06:19:33Z</updated>
    <published>2010-11-05T06:19:33Z</published>
    <title>Ruin probability in the presence of risky investments</title>
    <summary>  We consider an insurance company in the case when the premium rate is a
bounded non-negative random function $c_\zs{t}$ and the capital of the
insurance company is invested in a risky asset whose price follows a geometric
Brownian motion with mean return $a$ and volatility $\sigma&gt;0$. If
$\beta:=2a/\sigma^2-1&gt;0$ we find exact the asymptotic upper and lower bounds
for the ruin probability $\Psi(u)$ as the initial endowment $u$ tends to
infinity, i.e. we show that $C_*u^{-\beta}\le\Psi(u)\le C^*u^{-\beta}$ for
sufficiently large $u$. Moreover if $c_\zs{t}=c^*e^{\gamma t}$ with $\gamma\le
0$ we find the exact asymptotics of the ruin probability, namely $\Psi(u)\sim
u^{-\beta}$. If $\beta\le 0$, we show that $\Psi(u)=1$ for any $u\ge 0$.
</summary>
    <author>
      <name>Serguei Pergamenchtchikov</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LMRS</arxiv:affiliation>
    </author>
    <author>
      <name>Zeitouny Omar</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LMRS</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/1011.1329v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1011.1329v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.CP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1011.2827v5</id>
    <updated>2014-10-31T02:01:39Z</updated>
    <published>2010-11-12T04:53:17Z</published>
    <title>Markov chain Monte Carlo estimation of default and recovery: dependent
  via the latent systematic factor</title>
    <summary>  It is a well known fact that recovery rates tend to go down when the number
of defaults goes up in economic downturns. We demonstrate how the loss given
default model with the default and recovery dependent via the latent systematic
risk factor can be estimated using Bayesian inference methodology and Markov
chain Monte Carlo method. This approach is very convenient for joint estimation
of all model parameters and latent systematic factors. Moreover, all relevant
uncertainties are easily quantified. Typically available data are annual
averages of defaults and recoveries and thus the datasets are small and
parameter uncertainty is significant. In this case Bayesian approach is
superior to the maximum likelihood method that relies on a large sample limit
Gaussian approximation for the parameter uncertainty. As an example, we
consider a homogeneous portfolio with one latent factor. However, the approach
can be easily extended to deal with non-homogenous portfolios and several
latent factors.
</summary>
    <author>
      <name>Xiaolin Luo</name>
    </author>
    <author>
      <name>Pavel V. Shevchenko</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">39 pages including 5 tables and 7 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Credit Risk 9(3), pp. 41-76, 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1011.2827v5" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1011.2827v5" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1011.2958v2</id>
    <updated>2012-06-12T11:50:03Z</updated>
    <published>2010-11-12T15:43:00Z</published>
    <title>Superhedging and Dynamic Risk Measures under Volatility Uncertainty</title>
    <summary>  We consider dynamic sublinear expectations (i.e., time-consistent coherent
risk measures) whose scenario sets consist of singular measures corresponding
to a general form of volatility uncertainty. We derive a c\`adl\`ag nonlinear
martingale which is also the value process of a superhedging problem. The
superhedging strategy is obtained from a representation similar to the optional
decomposition. Furthermore, we prove an optional sampling theorem for the
nonlinear martingale and characterize it as the solution of a second order
backward SDE. The uniqueness of dynamic extensions of static sublinear
expectations is also studied.
</summary>
    <author>
      <name>Marcel Nutz</name>
    </author>
    <author>
      <name>H. Mete Soner</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">31 pages; forthcoming in 'SIAM Journal on Control and Optimization'</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">SIAM Journal of Control and Optimization, 50/4, 2065--2089, (2012)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1011.2958v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1011.2958v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B30, 93E20, 60G44, 60H30" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1011.4795v1</id>
    <updated>2010-11-22T13:07:50Z</updated>
    <published>2010-11-22T13:07:50Z</published>
    <title>Static replications with traffic light options</title>
    <summary>  It is well known that any sufficiently regular one-dimensional payoff
function has an explicit static hedge by bonds, forward contracts and lots of
vanilla options. We show that the natural extension of the corresponding
representation leads to a static hedge based on the same instruments along with
traffic light options, which have recently been introduced in the market. One
big advantage of these replication strategies is the easy structure of the
hedge. Hence, traffic light options are particularly powerful building blocks
for more complicated bivariate options. While it is well known that the second
strike derivative of non-discounted prices of vanilla options are related to
the risk-neutral density of the underlying asset price in the corresponding
absolutely continuous settings, similar statements hold for traffic light
options in sufficiently regular bivariate settings.
</summary>
    <author>
      <name>Michael Schmutz</name>
    </author>
    <author>
      <name>Thomas Zürcher</name>
    </author>
    <link href="http://arxiv.org/abs/1011.4795v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1011.4795v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="60E05, 91G20" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1012.0249v3</id>
    <updated>2011-03-15T15:12:15Z</updated>
    <published>2010-12-01T17:07:15Z</published>
    <title>Robust Estimation of Operational Risk</title>
    <summary>  According to the Loss Distribution Approach, the operational risk of a bank
is determined as 99.9% quantile of the respective loss distribution, covering
unexpected severe events. The 99.9% quantile can be considered a tail event. As
supported by the Pickands-Balkema-de Haan Theorem, tail events exceeding some
high threshold are usually modeled by a Generalized Pareto Distribution (GPD).
Estimation of GPD tail quantiles is not a trivial task, in particular if one
takes into account the heavy tails of this distribution, the possibility of
singular outliers, and, moreover, the fact that data is usually pooled among
several sources. Moreover, if, as is frequently the case, operational losses
are pooled anonymously, relevance of the fitting data for the respective bank
is not self-evident. In such situations, robust methods may provide stable
estimates when classical methods already fail. In this paper, optimally-robust
procedures MBRE, OMSE, RMXE are introduced to the application domain of
operational risk. We apply these procedures to parameter estimation of a GPD at
data from Algorithmics Inc. To better understand these results, we provide
supportive diagnostic plots adjusted for this context: influence plots,
outlyingness plots, and QQ plots with robust confidence bands.
</summary>
    <author>
      <name>Nataliya Horbenko</name>
    </author>
    <author>
      <name>Peter Ruckdeschel</name>
    </author>
    <author>
      <name>Taehan Bae</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1012.0249v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1012.0249v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62P05" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1012.0843v2</id>
    <updated>2011-01-19T21:38:04Z</updated>
    <published>2010-12-03T20:53:52Z</published>
    <title>The economic default time and the Arcsine law</title>
    <summary>  This paper develops a structural credit risk model to characterize the
difference between the economic and recorded default times for a firm. Recorded
default occurs when default is recorded in the legal system. The economic
default time is the last time when the firm is able to pay off its debt prior
to the legal default time. It has been empirically documented that these two
times are distinct (see Guo, Jarrow, and Lin (2008)). In our model, the
probability distribution for the time span between economic and recorded
defaults follows a mixture of Arcsine Laws, which is consistent with the
results contained in Guo, Jarrow, and Lin. In addition, we show that the
classical structural model is a limiting case of our model as the time period
between debt repayment dates goes to zero. As a corollary, we show how the firm
value process's parameters can be estimated using the tail index and
correlation structure of the firm's return.
</summary>
    <author>
      <name>Xin Guo</name>
    </author>
    <author>
      <name>Robert A Jarrow</name>
    </author>
    <author>
      <name>Adrien de Larrard</name>
    </author>
    <link href="http://arxiv.org/abs/1012.0843v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1012.0843v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1012.4674v4</id>
    <updated>2011-06-14T12:05:52Z</updated>
    <published>2010-12-21T14:34:08Z</published>
    <title>Marking Systemic Portfolio Risk with Application to the Correlation Skew
  of Equity Baskets</title>
    <summary>  The downside risk of a portfolio of (equity)assets is generally substantially
higher than the downside risk of its components. In particular in times of
crises when assets tend to have high correlation, the understanding of this
difference can be crucial in managing systemic risk of a portfolio. In this
paper we generalize Merton's option formula in the presence jumps to the
multi-asset case. It is shown how common jumps across assets provide an
intuitive and powerful tool to describe systemic risk that is consistent with
data. The methodology provides a new way to mark and risk-manage systemic risk
of portfolios in a systematic way.
</summary>
    <author>
      <name>Alex Langnau</name>
    </author>
    <author>
      <name>Daniel Cangemi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Correlation skew, Systemic Risk, Merton jump model, equity basket</arxiv:comment>
    <link href="http://arxiv.org/abs/1012.4674v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1012.4674v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1101.3926v1</id>
    <updated>2011-01-20T15:15:58Z</updated>
    <published>2011-01-20T15:15:58Z</published>
    <title>Collateral Margining in Arbitrage-Free Counterparty Valuation Adjustment
  including Re-Hypotecation and Netting</title>
    <summary>  This paper generalizes the framework for arbitrage-free valuation of
bilateral counterparty risk to the case where collateral is included, with
possible re-hypotecation. We analyze how the payout of claims is modified when
collateral margining is included in agreement with current ISDA documentation.
We then specialize our analysis to interest-rate swaps as underlying portfolio,
and allow for mutual dependences between the default times of the investor and
the counterparty and the underlying portfolio risk factors. We use
arbitrage-free stochastic dynamical models, including also the effect of
interest rate and credit spread volatilities. The impact of re-hypotecation, of
collateral margining frequency and of dependencies on the bilateral
counterparty risk adjustment is illustrated with a numerical example.
</summary>
    <author>
      <name>Damiano Brigo</name>
    </author>
    <author>
      <name>Agostino Capponi</name>
    </author>
    <author>
      <name>Andrea Pallavicini</name>
    </author>
    <author>
      <name>Vasileios Papatheodorou</name>
    </author>
    <link href="http://arxiv.org/abs/1101.3926v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1101.3926v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.CP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="60J75, 91B70" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1101.3974v1</id>
    <updated>2011-01-20T17:26:32Z</updated>
    <published>2011-01-20T17:26:32Z</published>
    <title>An Active Margin System and its Application in Chinese Margin Lending
  Market</title>
    <summary>  In order to protect brokers from customer defaults in a volatile market, an
active margin system is proposed for the transactions of margin lending in
China. The probability of negative return under the condition that collaterals
are liquidated in a falling market is used to measure the risk associated with
margin loans, and a recursive algorithm is proposed to calculate this
probability under a Markov chain model. The optimal maintenance margin ratio
can be given under the constraint of the proposed risk measurement for a
specified amount of initial margin. An example of such a margin system is
constructed and applied to $26,800$ margin loans of 134 stocks traded on the
Shanghai Stock Exchange. The empirical results indicate that the proposed
method is an operational method for brokers to set margin system with a clearly
specified target of risk control.
</summary>
    <author>
      <name>Guanghui Huang</name>
    </author>
    <author>
      <name>Jianping Wan</name>
    </author>
    <author>
      <name>Cheng Chen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">27 pages, 2 figures, 5 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1101.3974v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1101.3974v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1102.3150v2</id>
    <updated>2011-03-30T09:23:34Z</updated>
    <published>2011-02-15T18:30:47Z</published>
    <title>Dependence of defaults and recoveries in structural credit risk models</title>
    <summary>  The current research on credit risk is primarily focused on modeling default
probabilities. Recovery rates are often treated as an afterthought; they are
modeled independently, in many cases they are even assumed constant. This is
despite of their pronounced effect on the tail of the loss distribution. Here,
we take a step back, historically, and start again from the Merton model, where
defaults and recoveries are both determined by an underlying process. Hence,
they are intrinsically connected. For the diffusion process, we can derive the
functional relation between expected recovery rate and default probability.
This relation depends on a single parameter only. In Monte Carlo simulations we
find that the same functional dependence also holds for jump-diffusion and
GARCH processes. We discuss how to incorporate this structural recovery rate
into reduced form models, in order to restore essential structural information
which is usually neglected in the reduced-form approach.
</summary>
    <author>
      <name>Rudi Schäfer</name>
    </author>
    <author>
      <name>Alexander F. R. Koivusalo</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.econmod.2012.08.033</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.econmod.2012.08.033" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages, 11 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Economic Modelling 30 (2013) 1-9</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1102.3150v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1102.3150v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1102.3534v2</id>
    <updated>2012-10-12T23:26:54Z</updated>
    <published>2011-02-17T09:30:33Z</published>
    <title>Applying hedging strategies to estimate model risk and provision
  calculation</title>
    <summary>  This paper introduces a relative model risk measure of a product priced with
a given model, with respect to another reference model for which the market is
assumed to be driven. This measure allows comparing products valued with
different models (pricing hypothesis) under a homogeneous framework which
allows concluding which model is the closest to the reference. The relative
model risk measure is defined as the expected shortfall of the hedging strategy
at a given time horizon for a chosen significance level. The reference model
has been chosen to be Heston calibrated to market for a given time horizon
(this reference model should be chosen to be a market proxy). The method is
applied to estimate and compare this relative model risk measure under
volga-vanna and Black-Scholes models for double-no-touch options and a
portfolio of forward fader options.
</summary>
    <author>
      <name>Alberto Elices</name>
    </author>
    <author>
      <name>Eduard Giménez</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">32 pages, 9 figures, accepted for publication in Quantitative Finance</arxiv:comment>
    <link href="http://arxiv.org/abs/1102.3534v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1102.3534v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1102.3857v1</id>
    <updated>2011-02-18T15:39:38Z</updated>
    <published>2011-02-18T15:39:38Z</published>
    <title>Transition Probability Matrix Methodology for Incremental Risk Charge</title>
    <summary>  As part of Basel II's incremental risk charge (IRC) methodology, this paper
summarizes our extensive investigations of constructing transition probability
matrices (TPMs) for unsecuritized credit products in the trading book. The
objective is to create monthly or quarterly TPMs with predefined sectors and
ratings that are consistent with the bank's Basel PDs. Constructing a TPM is
not a unique process. We highlight various aspects of three types of
uncertainties embedded in different construction methods: 1) the available
historical data and the bank's rating philosophy; 2) the merger of one-year
Basel PD and the chosen Moody's TPMs; and 3) deriving a monthly or quarterly
TPM when the generator matrix does not exist. Given the fact that TPMs and
specifically their PDs are the most important parameters in IRC, it is our view
that banks may need to make discretionary choices regarding their methodology,
with uncertainties well understood and managed.
</summary>
    <author>
      <name>Tzahi Yavin</name>
    </author>
    <author>
      <name>Hu Zhang</name>
    </author>
    <author>
      <name>Eugene Wang</name>
    </author>
    <author>
      <name>Michael A. Clayton</name>
    </author>
    <link href="http://arxiv.org/abs/1102.3857v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1102.3857v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1102.3900v7</id>
    <updated>2011-06-28T13:33:22Z</updated>
    <published>2011-02-18T20:12:24Z</published>
    <title>A Random Matrix Approach to Credit Risk</title>
    <summary>  We estimate generic statistical properties of a structural credit risk model
by considering an ensemble of correlation matrices. This ensemble is set up by
Random Matrix Theory. We demonstrate analytically that the presence of
correlations severely limits the effect of diversification in a credit
portfolio if the correlations are not identically zero. The existence of
correlations alters the tails of the loss distribution considerably, even if
their average is zero. Under the assumption of randomly fluctuating
correlations, a lower bound for the estimation of the loss distribution is
provided.
</summary>
    <author>
      <name>Michael C. Münnix</name>
    </author>
    <author>
      <name>Rudi Schäfer</name>
    </author>
    <author>
      <name>Thomas Guhr</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Fully revised version; 15 pages, 8 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1102.3900v7" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1102.3900v7" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1102.4489v1</id>
    <updated>2011-02-22T12:43:24Z</updated>
    <published>2011-02-22T12:43:24Z</published>
    <title>Portfolio Insurance under a risk-measure constraint</title>
    <summary>  We study the problem of portfolio insurance from the point of view of a fund
manager, who guarantees to the investor that the portfolio value at maturity
will be above a fixed threshold. If, at maturity, the portfolio value is below
the guaranteed level, a third party will refund the investor up to the
guarantee. In exchange for this protection, the third party imposes a limit on
the risk exposure of the fund manager, in the form of a convex monetary risk
measure. The fund manager therefore tries to maximize the investor's utility
function subject to the risk measure constraint.We give a full solution to this
nonconvex optimization problem in the complete market setting and show in
particular that the choice of the risk measure is crucial for the optimal
portfolio to exist. Explicit results are provided for the entropic risk measure
(for which the optimal portfolio always exists) and for the class of spectral
risk measures (for which the optimal portfolio may fail to exist in some
cases).
</summary>
    <author>
      <name>Carmine De Franco</name>
    </author>
    <author>
      <name>Peter Tankov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">26 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1102.4489v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1102.4489v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91G10" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.0717v2</id>
    <updated>2013-01-03T18:48:11Z</updated>
    <published>2011-03-03T15:32:31Z</published>
    <title>The dynamics of financial stability in complex networks</title>
    <summary>  We address the problem of banking system resilience by applying
off-equilibrium statistical physics to a system of particles, representing the
economic agents, modelled according to the theoretical foundation of the
current banking regulation, the so called Merton-Vasicek model. Economic agents
are attracted to each other to exchange `economic energy', forming a network of
trades. When the capital level of one economic agent drops below a minimum, the
economic agent becomes insolvent. The insolvency of one single economic agent
affects the economic energy of all its neighbours which thus become susceptible
to insolvency, being able to trigger a chain of insolvencies (avalanche). We
show that the distribution of avalanche sizes follows a power-law whose
exponent depends on the minimum capital level. Furthermore, we present evidence
that under an increase in the minimum capital level, large crashes will be
avoided only if one assumes that agents will accept a drop in business levels,
while keeping their trading attitudes and policies unchanged. The alternative
assumption, that agents will try to restore their business levels, may lead to
the unexpected consequence that large crises occur with higher probability.
</summary>
    <author>
      <name>João P. da Cruz</name>
    </author>
    <author>
      <name>Pedro G. Lind</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1140/epjb/e2012-20984-6</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1140/epjb/e2012-20984-6" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Eur. Phys. J. B (2012) 85: 256</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1103.0717v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.0717v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.4943v1</id>
    <updated>2011-03-25T10:49:21Z</updated>
    <published>2011-03-25T10:49:21Z</published>
    <title>An Empirical Analysis of Dynamic Multiscale Hedging using Wavelet
  Decomposition</title>
    <summary>  This paper investigates the hedging effectiveness of a dynamic moving window
OLS hedging model, formed using wavelet decomposed time-series. The wavelet
transform is applied to calculate the appropriate dynamic minimum-variance
hedge ratio for various hedging horizons for a number of assets. The
effectiveness of the dynamic multiscale hedging strategy is then tested, both
in- and out-of-sample, using standard variance reduction and expanded to
include a downside risk metric, the time horizon dependent Value-at-Risk.
Measured using variance reduction, the effectiveness converges to one at longer
scales, while a measure of VaR reduction indicates a portion of residual risk
remains at all scales. Analysis of the hedge portfolio distributions indicate
that this unhedged tail risk is related to excess portfolio kurtosis found at
all scales.
</summary>
    <author>
      <name>Thomas Conlon</name>
    </author>
    <author>
      <name>John Cotter</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To Appear: Journal of Futures Markets</arxiv:comment>
    <link href="http://arxiv.org/abs/1103.4943v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.4943v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.5412v1</id>
    <updated>2011-03-28T16:41:16Z</updated>
    <published>2011-03-28T16:41:16Z</published>
    <title>Margin setting with high-frequency data1</title>
    <summary>  Both in practice and in the academic literature, models for setting margin
requirements in futures markets classically use daily closing price changes.
However, as well documented by research on high-frequency data, financial
markets have recently shown high intraday volatility, which could bring more
risk than expected. This paper tries to answer two questions relevant for
margin committees in practice: is it right to compute margin levels based on
closing prices and ignoring intraday dynamics? Is it justified to implement
intraday margin calls? The paper focuses on the impact of intraday dynamics of
market prices on daily margin levels. Daily margin levels are obtained in two
ways: first, by using daily price changes defined with different time-intervals
(say from 3 pm to 3 pm on the following trading day instead of traditional
closing times); second, by using 5-minute and 1-hour price changes and scaling
the results to one day. Our empirical analysis uses the FTSE 100 futures
contract traded on LIFFE.
</summary>
    <author>
      <name>John Cotter</name>
    </author>
    <author>
      <name>François Longin</name>
    </author>
    <link href="http://arxiv.org/abs/1103.5412v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.5412v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.TR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.5962v1</id>
    <updated>2011-03-30T15:45:46Z</updated>
    <published>2011-03-30T15:45:46Z</published>
    <title>Extreme Measures of Agricultural Financial Risk</title>
    <summary>  Risk is an inherent feature of agricultural production and marketing and
accurate measurement of it helps inform more efficient use of resources. This
paper examines three tail quantile-based risk measures applied to the
estimation of extreme agricultural financial risk for corn and soybean
production in the US: Value at Risk (VaR), Expected Shortfall (ES) and Spectral
Risk Measures (SRMs). We use Extreme Value Theory (EVT) to model the tail
returns and present results for these three different risk measures using
agricultural futures market data. We compare the estimated risk measures in
terms of their size and precision, and find that they are all considerably
higher than normal estimates; they are also quite uncertain, and become more
uncertain as the risks involved become more extreme.
</summary>
    <author>
      <name>John Cotter</name>
    </author>
    <author>
      <name>Kevin Dowd</name>
    </author>
    <author>
      <name>Wyn Morgan</name>
    </author>
    <link href="http://arxiv.org/abs/1103.5962v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.5962v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.5968v1</id>
    <updated>2011-03-30T15:52:19Z</updated>
    <published>2011-03-30T15:52:19Z</published>
    <title>Time Varying Risk Aversion: An Application to Energy Hedging</title>
    <summary>  Risk aversion is a key element of utility maximizing hedge strategies;
however, it has typically been assigned an arbitrary value in the literature.
This paper instead applies a GARCH-in-Mean (GARCH-M) model to estimate a
time-varying measure of risk aversion that is based on the observed risk
preferences of energy hedging market participants. The resulting estimates are
applied to derive explicit risk aversion based optimal hedge strategies for
both short and long hedgers. Out-of-sample results are also presented based on
a unique approach that allows us to forecast risk aversion, thereby estimating
hedge strategies that address the potential future needs of energy hedgers. We
find that the risk aversion based hedges differ significantly from simpler OLS
hedges. When implemented in-sample, risk aversion hedges for short hedgers
outperform the OLS hedge ratio in a utility based comparison.
</summary>
    <author>
      <name>John Cotter</name>
    </author>
    <author>
      <name>Jim Hanly</name>
    </author>
    <link href="http://arxiv.org/abs/1103.5968v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.5968v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1104.0359v5</id>
    <updated>2017-05-24T11:26:06Z</updated>
    <published>2011-04-03T06:40:14Z</published>
    <title>Theoretical Sensitivity Analysis for Quantitative Operational Risk
  Management</title>
    <summary>  We study the asymptotic behavior of the difference between the values at risk
VaR(L) and VaR(L+S) for heavy tailed random variables L and S for application
in sensitivity analysis of quantitative operational risk management within the
framework of the advanced measurement approach of Basel II (and III). Here L
describes the loss amount of the present risk profile and S describes the loss
amount caused by an additional loss factor. We obtain different types of
results according to the relative magnitudes of the thicknesses of the tails of
L and S. In particular, if the tail of S is sufficiently thinner than the tail
of L, then the difference between prior and posterior risk amounts VaR(L+S) -
VaR(L) is asymptotically equivalent to the expectation (expected loss) of S.
</summary>
    <author>
      <name>Takashi Kato</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1142/S0219024917500327</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1142/S0219024917500327" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages, 1 figure, 4 tables, forthcoming in International Journal of
  Theoretical and Applied Finance (IJTAF)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Theoretical and Applied Finance, Vol.20,
  No.5 (2017), 23 pages</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1104.0359v5" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1104.0359v5" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="60G70, 62G32, 91B30" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1104.1773v3</id>
    <updated>2013-02-12T13:50:18Z</updated>
    <published>2011-04-10T14:53:27Z</published>
    <title>Default clustering in large portfolios: Typical events</title>
    <summary>  We develop a dynamic point process model of correlated default timing in a
portfolio of firms, and analyze typical default profiles in the limit as the
size of the pool grows. In our model, a firm defaults at a stochastic intensity
that is influenced by an idiosyncratic risk process, a systematic risk process
common to all firms, and past defaults. We prove a law of large numbers for the
default rate in the pool, which describes the "typical" behavior of defaults.
</summary>
    <author>
      <name>Kay Giesecke</name>
    </author>
    <author>
      <name>Konstantinos Spiliopoulos</name>
    </author>
    <author>
      <name>Richard B. Sowers</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1214/12-AAP845</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1214/12-AAP845" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published in at http://dx.doi.org/10.1214/12-AAP845 the Annals of
  Applied Probability (http://www.imstat.org/aap/) by the Institute of
  Mathematical Statistics (http://www.imstat.org)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Annals of Applied Probability 2013, Vol. 23, No. 1, 348-385</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1104.1773v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1104.1773v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.CP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1104.2625v3</id>
    <updated>2011-08-21T22:46:17Z</updated>
    <published>2011-04-13T21:27:27Z</published>
    <title>Counterparty Risk and the Impact of Collateralization in CDS Contracts</title>
    <summary>  We analyze the counterparty risk embedded in CDS contracts, in presence of a
bilateral margin agreement. First, we investigate the pricing of collateralized
counterparty risk and we derive the bilateral Credit Valuation Adjustment
(CVA), unilateral Credit Valuation Adjustment (UCVA) and Debt Valuation
Adjustment (DVA). We propose a model for the collateral by incorporating all
related factors such as the thresholds, haircuts and margin period of risk. We
derive the dynamics of the bilateral CVA in a general form with related jump
martingales. We also introduce the Spread Value Adjustment (SVA) indicating the
counterparty risk adjusted spread. Counterparty risky and the counterparty
risk-free spread dynamics are derived and the dynamics of the SVA is found as a
consequence. We finally employ a Markovian copula model for default intensities
and illustrate our findings with numerical results.
</summary>
    <author>
      <name>Tomasz R. Bielecki</name>
    </author>
    <author>
      <name>Igor Cialenco</name>
    </author>
    <author>
      <name>Ismail Iyigunler</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">27 pages, 2 Figures. Forthcoming in Robert Elliott Festschrift</arxiv:comment>
    <link href="http://arxiv.org/abs/1104.2625v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1104.2625v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="60G, 60J" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1104.5272v3</id>
    <updated>2011-06-21T09:23:35Z</updated>
    <published>2011-04-27T23:44:13Z</published>
    <title>Credit contagion and risk management with multiple non-ordered defaults</title>
    <summary>  The classical reduced-form and filtration expansion framework in credit risk
is extended to the case of multiple, non-ordered defaults, assuming that
conditional densities of the default times exist. Intensities and pricing
formulas are derived, revealing how information driven default contagion arises
in these models. We then analyze the impact of ordering the default times
before expanding the filtration. While not important for pricing, the effect is
significant in the context of risk management, and becomes even more pronounced
for highly correlated and asymmetrically distributed defaults. Finally, we
provide a general scheme for constructing and simulating the default times,
given that a model for the conditional densities has been chosen.
</summary>
    <author>
      <name>Younes Kchia</name>
    </author>
    <author>
      <name>Martin Larsson</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper has been withdrawn by the authors because some of the main
  results have significant overlap with others available in the literature</arxiv:comment>
    <link href="http://arxiv.org/abs/1104.5272v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1104.5272v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.CP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1105.2968v1</id>
    <updated>2011-05-15T20:54:07Z</updated>
    <published>2011-05-15T20:54:07Z</published>
    <title>Banking retail consumer finance data generator - credit scoring data
  repository</title>
    <summary>  This paper presents two cases of random banking data generators based on
migration matrices and scoring rules. The banking data generator is a new hope
in researches of finding the proving method of comparisons of various credit
scoring techniques. There is analyzed the influence of one cyclic
macro--economic variable on stability in the time account and client
characteristics. Data are very useful for various analyses to understand in the
better way the complexity of the banking processes and also for students and
their researches. There are presented very interesting conclusions for crisis
behavior, namely that if a crisis is impacted by many factors, both customer
characteristics: application and behavioral; then there is very difficult to
indicate these factors in the typical scoring analysis and the crisis is
everywhere, in every kind of risk reports.
</summary>
    <author>
      <name>Karol Przanowski</name>
    </author>
    <link href="http://arxiv.org/abs/1105.2968v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1105.2968v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1106.5081v1</id>
    <updated>2011-06-24T23:22:33Z</updated>
    <published>2011-06-24T23:22:33Z</published>
    <title>A Stochastic Model for the Analysis of Demographic Risk in Pay-As-You-Go
  Pension Funds</title>
    <summary>  This research presents an analysis of the demographic risk related to future
membership patterns in pension funds with restricted entrance, financed under a
pay-as-you-go scheme. The paper, therefore, proposes a stochastic model for
investigating the behaviour of the demographic variable "new entrants" and the
influence it exerts on the financial dynamics of such funds. Further
information on pension funds of Italian professional categories and an
application to the Cassa Nazionale di Previdenza e Assistenza dei Dottori
Commercialisti (CNPADC) are then provided.
</summary>
    <author>
      <name>Alessandro Fiori Maccioni</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CRENoS and University of Sassari</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages, 9 figures, 5 tables. Original paper available at:
  http://sunshine.dma.unive.it/mmef/vol-3-2-2008.html</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Mathemathical Methods in Economics and Finance, Vol. 3, No. 2, pp.
  41-60, 2008</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1106.5081v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1106.5081v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="11K45, 60J10, 60J20, 62N02" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1107.0164v2</id>
    <updated>2012-04-02T14:03:33Z</updated>
    <published>2011-07-01T09:30:05Z</published>
    <title>One-year reserve risk including a tail factor: closed formula and
  bootstrap approaches</title>
    <summary>  In this paper, we detail the main simulation methods used in practice to
measure one-year reserve risk, and describe the bootstrap method providing an
empirical distribution of the Claims Development Result (CDR) whose variance is
identical to the closed-form expression of the prediction error proposed by
W\"uthrich et al. (2008). In particular, we integrate the stochastic modeling
of a tail factor in the bootstrap procedure. We demonstrate the equivalence
with existing analytical results and develop closed-form expressions for the
error of prediction including a tail factor. A numerical example is given at
the end of this study.
</summary>
    <author>
      <name>Alexandre Boumezoued</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">SAF</arxiv:affiliation>
    </author>
    <author>
      <name>Yoboua Angoua</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">SAF</arxiv:affiliation>
    </author>
    <author>
      <name>Laurent Devineau</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">SAF</arxiv:affiliation>
    </author>
    <author>
      <name>Jean-Philippe Boisseau</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">48 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1107.0164v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1107.0164v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1107.4632v3</id>
    <updated>2012-07-16T20:51:47Z</updated>
    <published>2011-07-22T21:41:50Z</published>
    <title>From Smile Asymptotics to Market Risk Measures</title>
    <summary>  The left tail of the implied volatility skew, coming from quotes on
out-of-the-money put options, can be thought to reflect the market's assessment
of the risk of a huge drop in stock prices. We analyze how this market
information can be integrated into the theoretical framework of convex monetary
measures of risk. In particular, we make use of indifference pricing by dynamic
convex risk measures, which are given as solutions of backward stochastic
differential equations (BSDEs), to establish a link between these two
approaches to risk measurement. We derive a characterization of the implied
volatility in terms of the solution of a nonlinear PDE and provide a small
time-to-maturity expansion and numerical solutions. This procedure allows to
choose convex risk measures in a conveniently parametrized class, distorted
entropic dynamic risk measures, which we introduce here, such that the
asymptotic volatility skew under indifference pricing can be matched with the
market skew. We demonstrate this in a calibration exercise to market implied
volatility data.
</summary>
    <author>
      <name>Ronnie Sircar</name>
    </author>
    <author>
      <name>Stephan Sturm</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1111/mafi.12015</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1111/mafi.12015" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">24 pages, 4 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Math. Finance 25:2, 400-425 (2015)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1107.4632v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1107.4632v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91G20, 91G80, 60H30" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1108.5940v3</id>
    <updated>2014-04-28T11:08:43Z</updated>
    <published>2011-08-30T12:43:00Z</published>
    <title>Asymptotically optimal discretization of hedging strategies with jumps</title>
    <summary>  In this work, we consider the hedging error due to discrete trading in models
with jumps. Extending an approach developed by Fukasawa [In Stochastic Analysis
with Financial Applications (2011) 331-346 Birkh\"{a}user/Springer Basel AG]
for continuous processes, we propose a framework enabling us to
(asymptotically) optimize the discretization times. More precisely, a
discretization rule is said to be optimal if for a given cost function, no
strategy has (asymptotically, for large cost) a lower mean square
discretization error for a smaller cost. We focus on discretization rules based
on hitting times and give explicit expressions for the optimal rules within
this class.
</summary>
    <author>
      <name>Mathieu Rosenbaum</name>
    </author>
    <author>
      <name>Peter Tankov</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1214/13-AAP940</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1214/13-AAP940" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published in at http://dx.doi.org/10.1214/13-AAP940 the Annals of
  Applied Probability (http://www.imstat.org/aap/) by the Institute of
  Mathematical Statistics (http://www.imstat.org)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Annals of Applied Probability 2014, Vol. 24, No. 3, 1002-1048</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1108.5940v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1108.5940v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1109.1272v4</id>
    <updated>2015-02-18T21:38:40Z</updated>
    <published>2011-09-06T19:27:19Z</published>
    <title>Large Portfolio Asymptotics for Loss From Default</title>
    <summary>  We prove a law of large numbers for the loss from default and use it for
approximating the distribution of the loss from default in large, potentially
heterogenous portfolios. The density of the limiting measure is shown to solve
a non-linear SPDE, and the moments of the limiting measure are shown to satisfy
an infinite system of SDEs. The solution to this system leads to %the solution
to the SPDE through an inverse moment problem, and to the distribution of the
limiting portfolio loss, which we propose as an approximation to the loss
distribution for a large portfolio. Numerical tests illustrate the accuracy of
the approximation, and highlight its computational advantages over a direct
Monte Carlo simulation of the original stochastic system.
</summary>
    <author>
      <name>Kay Giesecke</name>
    </author>
    <author>
      <name>Konstantinos Spiliopoulos</name>
    </author>
    <author>
      <name>Richard B. Sowers</name>
    </author>
    <author>
      <name>Justin A. Sirignano</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: text overlap with arXiv:1104.1773</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Mathematical Finance, Volume 25, Number 1, 2015, pages 77-114</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1109.1272v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1109.1272v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91G40, 60F05, 60F10" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1110.0159v1</id>
    <updated>2011-10-02T08:56:10Z</updated>
    <published>2011-10-02T08:56:10Z</published>
    <title>Hedging strategies with a put option and their failure rates</title>
    <summary>  The problem of stock hedging is reconsidered in this paper, where a put
option is chosen from a set of available put options to hedge the market risk
of a stock. A formula is proposed to determine the probability that the
potential loss exceeds a predetermined level of Value-at-Risk, which is used to
find the optimal strike price and optimal hedge ratio. The assumptions that the
chosen put option finishes in-the-money and the constraint of hedging budget is
binding are relaxed in this paper. A hypothesis test is proposed to determine
whether the failure rate of hedging strategy is greater than the predetermined
level of risk. The performances of the proposed method and the method with
those two assumptions are compared through simulations. The results of
simulated investigations indicate that the proposed method is much more prudent
than the method with those two assumptions.
</summary>
    <author>
      <name>Guanghui Huang</name>
    </author>
    <author>
      <name>Jing Xu</name>
    </author>
    <author>
      <name>Wenting Xing</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 1 figures, 2 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1110.0159v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1110.0159v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91G20, 91G70" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1110.1436v3</id>
    <updated>2013-04-18T09:42:53Z</updated>
    <published>2011-10-07T06:18:51Z</published>
    <title>Loss-Based Risk Measures</title>
    <summary>  Starting from the requirement that risk measures of financial portfolios
should be based on their losses, not their gains, we define the notion of
loss-based risk measure and study the properties of this class of risk
measures. We characterize loss-based risk measures by a representation theorem
and give examples of such risk measures. We then discuss the statistical
robustness of estimators of loss-based risk measures: we provide a general
criterion for qualitative robustness of risk estimators and compare this
criterion with sensitivity analysis of estimators based on influence functions.
Finally, we provide examples of statistically robust estimators for loss-based
risk measures.
</summary>
    <author>
      <name>Rama Cont</name>
    </author>
    <author>
      <name>Romain Deguest</name>
    </author>
    <author>
      <name>Xuedong He</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1524/strm.2013.1132</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1524/strm.2013.1132" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">40 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Statistics and Risk Modeling, Vol 30, Issue 2, pages 133-167
  (2013)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1110.1436v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1110.1436v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.1349v3</id>
    <updated>2013-04-04T14:26:59Z</updated>
    <published>2011-11-05T21:01:58Z</published>
    <title>On Multivariate Extensions of Value-at-Risk</title>
    <summary>  In this paper, we introduce two alternative extensions of the classical
univariate Value-at-Risk (VaR) in a multivariate setting. The two proposed
multivariate VaR are vector-valued measures with the same dimension as the
underlying risk portfolio. The lower-orthant VaR is constructed from level sets
of multivariate distribution functions whereas the upper-orthant VaR is
constructed from level sets of multivariate survival functions. Several
properties have been derived. In particular, we show that these risk measures
both satisfy the positive homogeneity and the translation invariance property.
Comparison between univariate risk measures and components of multivariate VaR
are provided. We also analyze how these measures are impacted by a change in
marginal distributions, by a change in dependence structure and by a change in
risk level. Illustrations are given in the class of Archimedean copulas.
</summary>
    <author>
      <name>Areski Cousin</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">SAF</arxiv:affiliation>
    </author>
    <author>
      <name>Elena Di Bernadino</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">SAF</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/1111.1349v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.1349v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.5228v2</id>
    <updated>2011-11-25T01:43:55Z</updated>
    <published>2011-11-19T21:21:10Z</published>
    <title>Privacy-Preserving Methods for Sharing Financial Risk Exposures</title>
    <summary>  Unlike other industries in which intellectual property is patentable, the
financial industry relies on trade secrecy to protect its business processes
and methods, which can obscure critical financial risk exposures from
regulators and the public. We develop methods for sharing and aggregating such
risk exposures that protect the privacy of all parties involved and without the
need for a trusted third party. Our approach employs secure multi-party
computation techniques from cryptography in which multiple parties are able to
compute joint functions without revealing their individual inputs. In our
framework, individual financial institutions evaluate a protocol on their
proprietary data which cannot be inverted, leading to secure computations of
real-valued statistics such a concentration indexes, pairwise correlations, and
other single- and multi-point statistics. The proposed protocols are
computationally tractable on realistic sample sizes. Potential financial
applications include: the construction of privacy-preserving real-time indexes
of bank capital and leverage ratios; the monitoring of delegated portfolio
investments; financial audits; and the publication of new indexes of
proprietary trading strategies.
</summary>
    <author>
      <name>Emmanuel A. Abbe</name>
    </author>
    <author>
      <name>Amir E. Khandani</name>
    </author>
    <author>
      <name>Andrew W. Lo</name>
    </author>
    <link href="http://arxiv.org/abs/1111.5228v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.5228v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.CP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.5397v1</id>
    <updated>2011-11-23T04:31:22Z</updated>
    <published>2011-11-23T04:31:22Z</published>
    <title>A Mathematical Method for Deriving the Relative Effect of Serviceability
  on Default Risk</title>
    <summary>  The writers propose a mathematical Method for deriving risk weights which
describe how a borrower's income, relative to their debt service obligations
(serviceability) affects the probability of default of the loan.
  The Method considers the borrower's income not simply as a known quantity at
the time the loan is made, but as an uncertain quantity following a statistical
distribution at some later point in the life of the loan. This allows a
probability to be associated with an income level leading to default, so that
the relative risk associated with different serviceability levels can be
quantified. In a sense, the Method can be thought of as an extension of the
Merton Model to quantities that fail to satisfy Merton's 'critical' assumptions
relating to the efficient markets hypothesis.
  A set of numerical examples of risk weights derived using the Method suggest
that serviceability may be under-represented as a risk factor in many mortgage
credit risk models.
</summary>
    <author>
      <name>Graham Andersen</name>
    </author>
    <author>
      <name>David Chisholm</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1111.5397v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.5397v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1112.1156v1</id>
    <updated>2011-12-06T04:38:06Z</updated>
    <published>2011-12-06T04:38:06Z</published>
    <title>Looking for grass-root sources of systemic risk: the case of
  "cheques-as-collateral" network</title>
    <summary>  The global financial system has become highly connected and complex. Has been
proven in practice that existing models, measures and reports of financial risk
fail to capture some important systemic dimensions. Only lately, advisory
boards have been established in high level and regulations are directly
targeted to systemic risk. In the same direction, a growing number of
researchers employ network analysis to model systemic risk in financial
networks. Current approaches are concentrated on interbank payment network
flows in national and international level. This work builds on existing
approaches to account for systemic risk assessment in micro level.
Particularly, we introduce the analysis of intra-bank financial risk
interconnections, by examining the real case of "cheques-as-collateral" network
for a major Greek bank. Our model offers useful information about the negative
spillovers of disruption to a financial entity in a bank's lending network and
could complement existing credit scoring models that account only for
idiosyncratic customer's financial profile. Most importantly, the proposed
methodology can be employed in many segments of the entire financial system,
providing a useful tool in the hands of regulatory authorities in assessing
more accurate estimates of systemic risk.
</summary>
    <author>
      <name>Michalis Vafopoulos</name>
    </author>
    <link href="http://arxiv.org/abs/1112.1156v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1112.1156v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.CP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91G40, 05C82, 91D30" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1112.1607v2</id>
    <updated>2012-05-06T21:18:29Z</updated>
    <published>2011-12-07T16:11:17Z</published>
    <title>Restructuring Counterparty Credit Risk</title>
    <summary>  We introduce an innovative theoretical framework to model derivative
transactions between defaultable entities based on the principle of arbitrage
freedom. Our framework extends the traditional formulations based on Credit and
Debit Valuation Adjustments (CVA and DVA). Depending on how the default
contingency is accounted for, we list a total of ten different structuring
styles. These include bipartite structures between a bank and a counterparty,
tri-partite structures with one margin lender in addition, quadri-partite
structures with two margin lenders and, most importantly, configurations where
all derivative transactions are cleared through a Central Counterparty (CCP).
We compare the various structuring styles under a number of criteria including
consistency from an accounting standpoint, counterparty risk hedgeability,
numerical complexity, transaction portability upon default, induced behaviour
and macro-economic impact of the implied wealth allocation.
</summary>
    <author>
      <name>Claudio Albanese</name>
    </author>
    <author>
      <name>Damiano Brigo</name>
    </author>
    <author>
      <name>Frank Oertel</name>
    </author>
    <link href="http://arxiv.org/abs/1112.1607v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1112.1607v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B70" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1112.5687v1</id>
    <updated>2011-12-24T02:56:15Z</updated>
    <published>2011-12-24T02:56:15Z</published>
    <title>Resilience to Contagion in Financial Networks</title>
    <summary>  Propagation of balance-sheet or cash-flow insolvency across financial
institutions may be modeled as a cascade process on a network representing
their mutual exposures. We derive rigorous asymptotic results for the magnitude
of contagion in a large financial network and give an analytical expression for
the asymptotic fraction of defaults, in terms of network characteristics. Our
results extend previous studies on contagion in random graphs to inhomogeneous
directed graphs with a given degree sequence and arbitrary distribution of
weights. We introduce a criterion for the resilience of a large financial
network to the insolvency of a small group of financial institutions and
quantify how contagion amplifies small shocks to the network. Our results
emphasize the role played by "contagious links" and show that institutions
which contribute most to network instability in case of default have both large
connectivity and a large fraction of contagious links. The asymptotic results
show good agreement with simulations for networks with realistic sizes.
</summary>
    <author>
      <name>Hamed Amini</name>
    </author>
    <author>
      <name>Rama Cont</name>
    </author>
    <author>
      <name>Andreea Minca</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1111/mafi.12051</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1111/mafi.12051" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">40 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1112.5687v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1112.5687v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1112.5766v1</id>
    <updated>2011-12-25T04:12:46Z</updated>
    <published>2011-12-25T04:12:46Z</published>
    <title>Dependent default and recovery: MCMC study of downturn LGD credit risk
  model</title>
    <summary>  There is empirical evidence that recovery rates tend to go down just when the
number of defaults goes up in economic downturns. This has to be taken into
account in estimation of the capital against credit risk required by Basel II
to cover losses during the adverse economic downturns; the so-called "downturn
LGD" requirement. This paper presents estimation of the LGD credit risk model
with default and recovery dependent via the latent systematic risk factor using
Bayesian inference approach and Markov chain Monte Carlo method. This approach
allows joint estimation of all model parameters and latent systematic factor,
and all relevant uncertainties. Results using Moody's annual default and
recovery rates for corporate bonds for the period 1982-2010 show that the
impact of parameter uncertainty on economic capital can be very significant and
should be assessed by practitioners.
</summary>
    <author>
      <name>Pavel V. Shevchenko</name>
    </author>
    <author>
      <name>Xiaolin Luo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: substantial text overlap with arXiv:1011.2827</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ANZIAM Journal 53, pp. C185-C202, 2012</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1112.5766v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1112.5766v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.CP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1201.1483v2</id>
    <updated>2012-12-21T17:44:23Z</updated>
    <published>2012-01-06T19:57:00Z</published>
    <title>Time consistency of dynamic risk measures in markets with transaction
  costs</title>
    <summary>  The paper concerns primal and dual representations as well as time
consistency of set-valued dynamic risk measures. Set-valued risk measures
appear naturally when markets with transaction costs are considered and capital
requirements can be made in a basket of currencies or assets. Time consistency
of scalar risk measures can be generalized to set-valued risk measures in
different ways. The most intuitive generalization is called time consistency.
We will show that the equivalence between a recursive form of the risk measure
and time consistency, which is a central result in the scalar case, does not
hold in the set-valued framework. Instead, we propose an alternative
generalization, which we will call multi-portfolio time consistency and show in
the main result of the paper that this property is indeed equivalent to the
recursive form as well as to an additive property for the acceptance sets.
Multi-portfolio time consistency is a stronger property than time consistency.
In the scalar case, both notions coincide.
</summary>
    <author>
      <name>Zachary Feinstein</name>
    </author>
    <author>
      <name>Birgit Rudloff</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Quantitative Finance 13 (9), 1473-1489, (2013)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1201.1483v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1201.1483v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B30, 46A20, 46N10, 26E25" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1201.5132v1</id>
    <updated>2012-01-24T21:31:01Z</updated>
    <published>2012-01-24T21:31:01Z</published>
    <title>Quasi self-dual exponential Lévy processes</title>
    <summary>  The important application of semi-static hedging in financial markets
naturally leads to the notion of quasi self-dual processes. The focus of our
study is to give new characterizations of quasi self-duality for exponential
L\'evy processes such that the resulting market does not admit arbitrage
opportunities. We derive a set of equivalent conditions for the stochastic
logarithm of quasi self-dual martingale models and derive a further
characterization of these models not depending on the L\'evy-Khintchine
parametrization. Since for non-vanishing order parameter two martingale
properties have to be satisfied simultaneously, there is a non-trivial relation
between the order and shift parameter representing carrying costs in financial
applications. This leads to an equation containing an integral term which has
to be inverted in applications. We first discuss several important properties
of this equation and, for some well-known models, we derive a family of
closed-form inversion formulae leading to parameterizations of sets of possible
combinations in the corresponding parameter spaces of well-known L\'evy driven
models.
</summary>
    <author>
      <name>Thorsten Rheinländer</name>
    </author>
    <author>
      <name>Michael Schmutz</name>
    </author>
    <link href="http://arxiv.org/abs/1201.5132v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1201.5132v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="60E07, 60G51, 91G20" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.2532v1</id>
    <updated>2012-02-12T14:40:47Z</updated>
    <published>2012-02-12T14:40:47Z</published>
    <title>A Dynamical Approach to Operational Risk Measurement</title>
    <summary>  We propose a dynamical model for the estimation of Operational Risk in
banking institutions. Operational Risk is the risk that a financial loss occurs
as the result of failed processes. Examples of operational losses are the ones
generated by internal frauds, human errors or failed transactions. In order to
encompass the most heterogeneous set of processes, in our approach the losses
of each process are generated by the interplay among random noise, interactions
with other processes and the efforts the bank makes to avoid losses. We show
how some relevant parameters of the model can be estimated from a database of
historical operational losses, validate the estimation procedure and test the
forecasting power of the model. Some advantages of our approach over the
traditional statistical techniques are that it allows to follow the whole time
evolution of the losses and to take into account different-time correlations
among the processes.
</summary>
    <author>
      <name>Marco Bardoscia</name>
    </author>
    <author>
      <name>Roberto Bellotti</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages, 2 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Operational Risk 6-1 (2011), pp. 3-19</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1202.2532v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.2532v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.4913v2</id>
    <updated>2012-02-23T13:59:05Z</updated>
    <published>2012-02-22T14:18:17Z</published>
    <title>Active margin system for margin loans and its application in Chinese
  market: using cash and randomly selected stock as collateral</title>
    <summary>  An active margin system for margin loans is proposed for Chinese margin
lending market, which uses cash and randomly selected stock as collateral. The
conditional probability of negative return(CPNR) after a forced sale of
securities from under-margined account in a falling market is used to measure
the risk faced by the brokers, and the margin system is chosen under the
constraint of the risk measure. In order to calculate CPNR, a recursive
algorithm is proposed under a Markov chain model, which is constructed by
sample learning method. The resulted margin system is an active system, which
is able to adjust actively with respect to the changes of stock prices and the
changes of different collateral. The resulted margin system is applied to
30,000 margin loans of 150 stocks listed on Shanghai Stock Exchange. The
empirical results show the number of margin calls and the average costs of the
loans under the proposed margin system are less than their counterparts under
the system required by SSE and SZSE.
</summary>
    <author>
      <name>Guanghui Huang</name>
    </author>
    <author>
      <name>Wenting Xin</name>
    </author>
    <author>
      <name>Weiqing Gu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages,5 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1202.4913v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.4913v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.5180v1</id>
    <updated>2012-02-23T13:55:30Z</updated>
    <published>2012-02-23T13:55:30Z</published>
    <title>Active margin system for margin loans using cash and stock as collateral
  and its application in Chinese market</title>
    <summary>  Margin system for margin loans using cash and stock as collateral is
considered in this paper, which is the line of defence for brokers against risk
associated with margin trading. The conditional probability of negative return
is used as risk measure, and a recursive algorithm is proposed to realize this
measure under a Markov chain model. Optimal margin system is chosen from those
systems which satisfy the constraint of the risk measure. The resulted margin
system is able to adjust actively with respect to the changes of stock prices.
The margin system required by the Shanghai Stock Exchange is compared with the
proposed system, where 25,200 margin loans of 126 stocks listed on the SSE are
investigated. It is found that the number of margin calls under the proposed
margin system is significantly less than its counterpart under the required
system for the same level of risk, and the average costs of the loans are
similar under the two types of margin systems.
</summary>
    <author>
      <name>Guanghui Huang</name>
    </author>
    <author>
      <name>Weiqing Gu</name>
    </author>
    <author>
      <name>Wenting Xing</name>
    </author>
    <author>
      <name>Hongyu Li</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 5 tables. arXiv admin note: significant text overlap with
  arXiv:1101.3974</arxiv:comment>
    <link href="http://arxiv.org/abs/1202.5180v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.5180v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1203.2287v4</id>
    <updated>2012-08-31T08:32:06Z</updated>
    <published>2012-03-10T21:50:11Z</published>
    <title>Bounds for rating override rates</title>
    <summary>  Overrides of credit ratings are important correctives of ratings that are
determined by statistical rating models. Financial institutions and banking
regulators agree on this because on the one hand errors with ratings of
corporates or banks can have fatal consequences for the lending institutions
and on the other hand errors by statistical methods can be minimised but not
completely avoided. Nonetheless, rating overrides can be misused in order to
conceal the real riskiness of borrowers or even entire portfolios. That is why
rating overrides usually are strictly governed and carefully recorded. It is
not clear, however, which frequency of overrides is appropriate for a given
rating model within a predefined time period. This paper argues that there is a
natural error rate associated with a statistical rating model that may be used
to inform assessment of whether or not an observed override rate is adequate.
The natural error rate is closely related to the rating model's discriminatory
power and can readily be calculated.
</summary>
    <author>
      <name>Dirk Tasche</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">23 pages, 3 figures, 3 tables</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Credit Risk 8(4), 3-29, 2012</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1203.2287v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1203.2287v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62P05 (Primary) 62G05 (Secondary)" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1203.3188v1</id>
    <updated>2012-03-14T19:56:44Z</updated>
    <published>2012-03-14T19:56:44Z</published>
    <title>Empirical Evidence for the Structural Recovery Model</title>
    <summary>  While defaults are rare events, losses can be substantial even for credit
portfolios with a large number of contracts. Therefore, not only a good
evaluation of the probability of default is crucial, but also the severity of
losses needs to be estimated. The recovery rate is often modeled independently
with regard to the default probability, whereas the Merton model yields a
functional dependence of both variables. We use Moody's Default and Recovery
Database in order to investigate the relationship of default probability and
recovery rate for senior secured bonds. The assumptions in the Merton model do
not seem justified by the empirical situation. Yet the empirical dependence of
default probability and recovery rate is well described by the functional
dependence found in the Merton model.
</summary>
    <author>
      <name>Alexander Becker</name>
    </author>
    <author>
      <name>Alexander F. R. Koivusalo</name>
    </author>
    <author>
      <name>Rudi Schäfer</name>
    </author>
    <link href="http://arxiv.org/abs/1203.3188v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1203.3188v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1203.6778v1</id>
    <updated>2012-03-30T11:59:42Z</updated>
    <published>2012-03-30T11:59:42Z</published>
    <title>Systemic losses in banking networks: indirect interaction of nodes via
  asset prices</title>
    <summary>  A simple banking network model is proposed which features multiple waves of
bank defaults and is analytically solvable in the limiting case of an
infinitely large homogeneous network. The model is a collection of nodes
representing individual banks; associated with each node is a balance sheet
consisting of assets and liabilities. Initial node failures are triggered by
external correlated shocks applied to the asset sides of the balance sheets.
These defaults lead to further reductions in asset values of all nodes which in
turn produce additional failures, and so on. This mechanism induces indirect
interactions between the nodes and leads to a cascade of defaults. There are no
interbank links, and therefore no direct interactions, between the nodes. The
resulting probability distribution for the total (direct plus systemic) network
loss can be viewed as a modification of the well-known Vasicek distribution.
</summary>
    <author>
      <name>Igor Tsatskis</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Financial Services Authority, London</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, no figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1203.6778v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1203.6778v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.2458v6</id>
    <updated>2014-01-14T12:58:12Z</updated>
    <published>2012-04-11T14:21:06Z</published>
    <title>Comparative and qualitative robustness for law-invariant risk measures</title>
    <summary>  When estimating the risk of a P&amp;L from historical data or Monte Carlo
simulation, the robustness of the estimate is important. We argue here that
Hampel's classical notion of qualitative robustness is not suitable for risk
measurement and we propose and analyze a refined notion of robustness that
applies to tail-dependent law-invariant convex risk measures on Orlicz space.
This concept of robustness captures the tradeoff between robustness and
sensitivity and can be quantified by an index of qualitative robustness. By
means of this index, we can compare various risk measures, such as distortion
risk measures, in regard to their degree of robustness. Our analysis also
yields results that are of independent interest such as continuity properties
and consistency of estimators for risk measures, or a Skorohod representation
theorem for {\psi}-weak convergence.
</summary>
    <author>
      <name>Volker Krätschmer</name>
    </author>
    <author>
      <name>Alexander Schied</name>
    </author>
    <author>
      <name>Henryk Zähle</name>
    </author>
    <link href="http://arxiv.org/abs/1204.2458v6" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.2458v6" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62G35, 60B10, 60F05, 91B30, 28A33, 62G05" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.3536v2</id>
    <updated>2012-08-29T20:41:52Z</updated>
    <published>2012-04-16T15:46:47Z</published>
    <title>Large deviations for a mean field model of systemic risk</title>
    <summary>  We consider a system of diffusion processes that interact through their
empirical mean and have a stabilizing force acting on each of them,
corresponding to a bistable potential. There are three parameters that
characterize the system: the strength of the intrinsic stabilization, the
strength of the external random perturbations, and the degree of cooperation or
interaction between them. The latter is the rate of mean reversion of each
component to the empirical mean of the system. We interpret this model in the
context of systemic risk and analyze in detail the effect of cooperation
between the components, that is, the rate of mean reversion. We show that in a
certain regime of parameters increasing cooperation tends to increase the
stability of the individual agents but it also increases the overall or
systemic risk. We use the theory of large deviations of diffusions interacting
through their mean field.
</summary>
    <author>
      <name>Josselin Garnier</name>
    </author>
    <author>
      <name>George Papanicolaou</name>
    </author>
    <author>
      <name>Tzu-Wei Yang</name>
    </author>
    <link href="http://arxiv.org/abs/1204.3536v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.3536v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="60F10, 60K35, 91B30, 82C26" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.5661v2</id>
    <updated>2012-11-22T08:59:47Z</updated>
    <published>2012-04-25T14:07:22Z</published>
    <title>Transmission of distress in a bank credit network</title>
    <summary>  The European sovereign debt crisis has impaired many European banks. The
distress on the European banks may transmit worldwide, and result in a
large-scale knock-on default of financial institutions. This study presents a
computer simulation model to analyze the risk of insolvency of banks and
defaults in a bank credit network. Simulation experiments reproduce the
knock-on default, and quantify the impact which is imposed on the number of
bank defaults by heterogeneity of the bank credit network, the equity capital
ratio of banks, and the capital surcharge on big banks.
</summary>
    <author>
      <name>Yoshiharu Maeno</name>
    </author>
    <author>
      <name>Satoshi Morinaga</name>
    </author>
    <author>
      <name>Hirokazu Matsushima</name>
    </author>
    <author>
      <name>Kenichi Amagai</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">presented at the 4th World Congress on Social Simulation, Taipei,
  September 2012</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">presented at the 4th World Congress on Social Simulation, Taipei,
  September 2012</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1204.5661v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.5661v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.0976v1</id>
    <updated>2012-05-04T15:15:37Z</updated>
    <published>2012-05-04T15:15:37Z</published>
    <title>Credit Default Swaps Drawup Networks: Too Tied To Be Stable?</title>
    <summary>  We analyse time series of CDS spreads for a set of major US and European
institutions on a pe- riod overlapping the recent financial crisis. We extend
the existing methodology of {\epsilon}-drawdowns to the one of joint
{\epsilon}-drawups, in order to estimate the conditional probabilities of
abrupt co-movements among spreads. We correct for randomness and for finite
size effects and we find significant prob- ability of joint drawups for certain
pairs of CDS. We also find significant probability of trend rein- forcement,
i.e. drawups in a given CDS followed by drawups in the same CDS. Finally, we
take the matrix of probability of joint drawups as an estimate of the network
of financial dependencies among institutions. We then carry out a network
analysis that provides insights into the role of systemically important
financial institutions.
</summary>
    <author>
      <name>Rahul Kaushik</name>
    </author>
    <author>
      <name>Stefano Battiston</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1371/journal.pone.0061815</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1371/journal.pone.0061815" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 5 figures, Supplementary information</arxiv:comment>
    <link href="http://arxiv.org/abs/1205.0976v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.0976v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.1012v1</id>
    <updated>2012-05-04T17:16:29Z</updated>
    <published>2012-05-04T17:16:29Z</published>
    <title>From Risk Measures to Research Measures</title>
    <summary>  In order to evaluate the quality of the scientific research, we introduce a
new family of scientific performance measures, called Scientific Research
Measures (SRM). Our proposal originates from the more recent developments in
the theory of risk measures and is an attempt to resolve the many problems of
the existing bibliometric indices. The SRM that we introduce are based on the
whole scientist's citation record and are: coherent, as they share the same
structural properties; flexible to fit peculiarities of different areas and
seniorities; granular, as they allow a more precise comparison between
scientists, and inclusive, as they comprehend several popular indices. Another
key feature of our SRM is that they are planned to be calibrated to the
particular scientific community. We also propose a dual formulation of this
problem and explain its relevance in this context.
</summary>
    <author>
      <name>Marco Frittelli</name>
    </author>
    <author>
      <name>Ilaria Peri</name>
    </author>
    <link href="http://arxiv.org/abs/1205.1012v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.1012v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.2513v1</id>
    <updated>2012-05-11T13:13:14Z</updated>
    <published>2012-05-11T13:13:14Z</published>
    <title>A different perspective on retirement income sustainability: the
  blueprint for a ruin contingent life annuity (RCLA)</title>
    <summary>  The purpose of this article is twofold. First, we motivate the need for a new
type of stand-alone retirement income insurance product that would help
individuals protect against personal longevity risk and possible "retirement
ruin" in an economically efficient manner. We label this product a
ruin-contingent life annuity (RCLA), which we elaborate-on and explain with
various numerical examples and a basic pricing model. Second, we argue that
with the proper perspective a similar product actually exists, albeit not
available on a stand-alone basis. Namely, they are fused and embedded within
modern variable annuity (VA) policies with guaranteed living income benefit
(GLiB) riders. Indeed, the popularity of GLiB riders on VA policies point
towards the potential commercial success of such a stand-alone vehicle.
</summary>
    <author>
      <name>Huaxiong Huang</name>
    </author>
    <author>
      <name>Moshe A. Milevsky</name>
    </author>
    <author>
      <name>Thomas S. Salisbury</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">J. of Wealth Management, 11 (2009), pp. 89-97</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1205.2513v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.2513v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.4790v3</id>
    <updated>2013-06-12T14:17:05Z</updated>
    <published>2012-05-22T03:02:03Z</published>
    <title>Dynamic Conic Finance: Pricing and Hedging in Market Models with
  Transaction Costs via Dynamic Coherent Acceptability Indices</title>
    <summary>  In this paper we present a theoretical framework for determining dynamic ask
and bid prices of derivatives using the theory of dynamic coherent
acceptability indices in discrete time. We prove a version of the First
Fundamental Theorem of Asset Pricing using the dynamic coherent risk measures.
We introduce the dynamic ask and bid prices of a derivative contract in markets
with transaction costs. Based on these results, we derive a representation
theorem for the dynamic bid and ask prices in terms of dynamically consistent
sequence of sets of probability measures and risk-neutral measures. To
illustrate our results, we compute the ask and bid prices of some
path-dependent options using the dynamic Gain-Loss Ratio.
</summary>
    <author>
      <name>Tomasz R. Bielecki</name>
    </author>
    <author>
      <name>Igor Cialenco</name>
    </author>
    <author>
      <name>Ismail Iyigunler</name>
    </author>
    <author>
      <name>Rodrigo Rodriguez</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1142/S0219024913500027</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1142/S0219024913500027" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">extended-preprint version of the published paper</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Theoretical and Applied Finance, vol. 16,
  No 1, 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1205.4790v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.4790v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B30, 60G30, 91B06, 62P05" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.1380v1</id>
    <updated>2012-06-07T01:11:36Z</updated>
    <published>2012-06-07T01:11:36Z</published>
    <title>Forecasting Value-at-Risk with Time-Varying Variance, Skewness and
  Kurtosis in an Exponential Weighted Moving Average Framework</title>
    <summary>  This paper provides an insight to the time-varying dynamics of the shape of
the distribution of financial return series by proposing an exponential
weighted moving average model that jointly estimates volatility, skewness and
kurtosis over time using a modified form of the Gram-Charlier density in which
skewness and kurtosis appear directly in the functional form of this density.
In this setting VaR can be described as a function of the time-varying higher
moments by applying the Cornish-Fisher expansion series of the first four
moments. An evaluation of the predictive performance of the proposed model in
the estimation of 1-day and 10-day VaR forecasts is performed in comparison
with the historical simulation, filtered historical simulation and GARCH model.
The adequacy of the VaR forecasts is evaluated under the unconditional,
independence and conditional likelihood ratio tests as well as Basel II
regulatory tests. The results presented have significant implications for risk
management, trading and hedging activities as well as in the pricing of equity
derivatives.
</summary>
    <author>
      <name>A. Gabrielsen</name>
    </author>
    <author>
      <name>P. Zagaglia</name>
    </author>
    <author>
      <name>A. Kirchner</name>
    </author>
    <author>
      <name>Z. Liu</name>
    </author>
    <link href="http://arxiv.org/abs/1206.1380v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.1380v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.2662v1</id>
    <updated>2012-06-12T20:27:14Z</updated>
    <published>2012-06-12T20:27:14Z</published>
    <title>Alpha Representation For Active Portfolio Management and High Frequency
  Trading In Seemingly Efficient Markets</title>
    <summary>  We introduce a trade strategy representation theorem for performance
measurement and portable alpha in high frequency trading, by embedding a robust
trading algorithm that describe portfolio manager market timing behavior, in a
canonical multifactor asset pricing model. First, we present a spectral test
for market timing based on behavioral transformation of the hedge factors
design matrix. Second, we find that the typical trade strategy process is a
local martingale with a background driving Brownian bridge that mimics
portfolio manager price reversal strategies. Third, we show that equilibrium
asset pricing models like the CAPM exists on a set with P-measure zero. So that
excess returns, i.e. positive alpha, relative to a benchmark index is robust to
no arbitrage pricing in turbulent capital markets. Fourth, the path properties
of alpha are such that it is positive between suitably chosen stopping times
for trading. Fifth, we demonstrate how, and why, econometric tests of portfolio
performance tend to under report positive alpha.
</summary>
    <author>
      <name>Godfrey Charles-Cadogan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 0 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings of Joint Statistical Meeting (JSM), Business and
  Economic Statistics Section, Alexandria, VA: American Statistical
  Association. 673-687, 2011</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1206.2662v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.2662v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91G10, 91G70" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.2665v1</id>
    <updated>2012-06-12T20:40:08Z</updated>
    <published>2012-06-12T20:40:08Z</published>
    <title>Representation Theory for Risk On Markowitz-Tversky-Kahneman Topology</title>
    <summary>  We introduce a representation theory for risk operations on locally compact
groups in a partition of unity on a topological manifold for
Markowitz-Tversky-Kahneman (MTK) reference points. We identify (1) risk torsion
induced by the flip rate for risk averse and risk seeking behaviour, and (2) a
structure constant or coupling of that torsion in the paracompact manifold. The
risk torsion operator extends by continuity to prudence and maxmin expected
utility (MEU) operators, as well as other behavioural operators introduced by
the Italian school. In our erstwhile chaotic dynamical system, induced by
behavioural rotations of probability domains, the loss aversion index is an
unobserved gauge transformation; and reference points are hyperbolic on the
utility hypersurface characterized by the special unitary group SU(n). We
identify conditions for existence of harmonic utility functions on paracompact
MTK manifolds induced by transformation groups. And we use those mathematical
objects to estimate: (1) loss aversion index from infinitesimal tangent
vectors; and (2) value function from a classic Dirichlet problem for first exit
time of Brownian motion from regular points on the boundary of MTK base
topology.
</summary>
    <author>
      <name>Godfrey Charles-Cadogan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">27 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.2665v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.2665v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.RT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="54H15, 37CXX" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.5393v3</id>
    <updated>2013-12-11T09:53:41Z</updated>
    <published>2012-06-23T13:52:41Z</published>
    <title>Numerical methods for the quadratic hedging problem in Markov models
  with jumps</title>
    <summary>  We develop algorithms for the numerical computation of the quadratic hedging
strategy in incomplete markets modeled by pure jump Markov process. Using the
Hamilton-Jacobi-Bellman approach, the value function of the quadratic hedging
problem can be related to a triangular system of parabolic partial
integro-differential equations (PIDE), which can be shown to possess unique
smooth solutions in our setting. The first equation is non-linear, but does not
depend on the pay-off of the option to hedge (the pure investment problem),
while the other two equations are linear. We propose convergent finite
difference schemes for the numerical solution of these PIDEs and illustrate our
results with an application to electricity markets, where time-inhomogeneous
pure jump Markov processes appear in a natural manner.
</summary>
    <author>
      <name>Carmine De Franco</name>
    </author>
    <author>
      <name>Peter Tankov</name>
    </author>
    <author>
      <name>Xavier Warin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">37 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.5393v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.5393v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91G60, 91G80" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.6998v1</id>
    <updated>2012-06-29T12:22:03Z</updated>
    <published>2012-06-29T12:22:03Z</published>
    <title>Interest Rate Risk of Bond Prices on Macedonian Stock Exchange -
  Empirical Test of the Duration, Modified Duration and Convexity and Bonds
  Valuation</title>
    <summary>  This article presents valuation of Treasury Bonds (T-Bonds) on Macedonian
Stock Exchange (MSE) and empirical test of duration, modified duration and
convexity of the T-bonds at MSE in order to determine sensitivity of bonds
prices on interest rate changes. The main goal of this study is to determine
how standard valuation models fit in case of T- Bonds that are traded on MSE
and to verify whether they offer reliable results compared with average bonds
prices on MSE. We test the sensitivity of T- Bonds on MSE on interest rate
changes and determine that convexity is more accurate measure as approximation
of bond prices changes than duration. Final conclusion is that T-Bonds traded
at MSE are not sensitive on interest rate changes due to institutional
investors' permanent higher demand and at the same time market limited offer of
risk-free instruments.
</summary>
    <author>
      <name>Zoran Ivanovski</name>
    </author>
    <author>
      <name>Toni Draganov Stojanovski</name>
    </author>
    <author>
      <name>Nadica Ivanovska</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to Economic Research, Juraj Dobrila University of Pula,
  Croatia</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.6998v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.6998v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1208.1189v1</id>
    <updated>2012-08-06T15:22:00Z</updated>
    <published>2012-08-06T15:22:00Z</published>
    <title>Mathematical Definition, Mapping, and Detection of (Anti)Fragility</title>
    <summary>  We provide a mathematical definition of fragility and antifragility as
negative or positive sensitivity to a semi-measure of dispersion and volatility
(a variant of negative or positive "vega") and examine the link to nonlinear
effects. We integrate model error (and biases) into the fragile or antifragile
context. Unlike risk, which is linked to psychological notions such as
subjective preferences (hence cannot apply to a coffee cup) we offer a measure
that is universal and concerns any object that has a probability distribution
(whether such distribution is known or, critically, unknown). We propose a
detection of fragility, robustness, and antifragility using a single
"fast-and-frugal", model-free, probability free heuristic that also picks up
exposure to model error. The heuristic lends itself to immediate
implementation, and uncovers hidden risks related to company size, forecasting
problems, and bank tail exposures (it explains the forecasting biases). While
simple to implement, it outperforms stress testing and other such methods such
as Value-at-Risk.
</summary>
    <author>
      <name>Nassim N. Taleb</name>
    </author>
    <author>
      <name>Raphael Douady</name>
    </author>
    <link href="http://arxiv.org/abs/1208.1189v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1208.1189v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.2298v1</id>
    <updated>2012-09-11T12:18:56Z</updated>
    <published>2012-09-11T12:18:56Z</published>
    <title>The Future Has Thicker Tails than the Past: Model Error As Branching
  Counterfactuals</title>
    <summary>  Ex ante forecast outcomes should be interpreted as counterfactuals (potential
histories), with errors as the spread between outcomes. Reapplying measurements
of uncertainty about the estimation errors of the estimation errors of an
estimation leads to branching counterfactuals. Such recursions of epistemic
uncertainty have markedly different distributial properties from conventional
sampling error. Nested counterfactuals of error rates invariably lead to fat
tails, regardless of the probability distribution used, and to powerlaws under
some conditions. A mere .01% branching error rate about the STD (itself an
error rate), and .01% branching error rate about that error rate, etc.
(recursing all the way) results in explosive (and infinite) higher moments than
1. Missing any degree of regress leads to the underestimation of small
probabilities and concave payoffs (a standard example of which is Fukushima).
The paper states the conditions under which higher order rates of uncertainty
(expressed in spreads of counterfactuals) alters the shapes the of final
distribution and shows which a priori beliefs about conterfactuals are needed
to accept the reliability of conventional probabilistic methods (thin tails or
mildly fat tails).
</summary>
    <author>
      <name>Nassim N. Taleb</name>
    </author>
    <link href="http://arxiv.org/abs/1209.2298v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.2298v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.3513v3</id>
    <updated>2015-03-31T08:36:06Z</updated>
    <published>2012-09-16T18:58:02Z</published>
    <title>Funding Liquidity, Debt Tenor Structure, and Creditor's Belief: An
  Exogenous Dynamic Debt Run Model</title>
    <summary>  We propose a unified structural credit risk model incorporating both
insolvency and illiquidity risks, in order to investigate how a firm's default
probability depends on the liquidity risk associated with its financing
structure. We assume the firm finances its risky assets by mainly issuing
short- and long-term debt. Short-term debt can have either a discrete or a more
realistic staggered tenor structure. At rollover dates of short-term debt,
creditors face a dynamic coordination problem. We show that a unique threshold
strategy (i.e., a debt run barrier) exists for short-term creditors to decide
when to withdraw their funding, and this strategy is closely related to the
solution of a non-standard optimal stopping time problem with control
constraints. We decompose the total credit risk into an insolvency component
and an illiquidity component based on such an endogenous debt run barrier
together with an exogenous insolvency barrier.
</summary>
    <author>
      <name>Gechun Liang</name>
    </author>
    <author>
      <name>Eva Lütkebohmert</name>
    </author>
    <author>
      <name>Wei Wei</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">36 pages, 9 figures. The article was previously circulated under the
  title A Continuous Time Structural Model for Insolvency, Recovery, and
  Rollover Risks in Mathematics and Financial Economics, 2015</arxiv:comment>
    <link href="http://arxiv.org/abs/1209.3513v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.3513v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91G40, 91G50, 91G80" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.5046v1</id>
    <updated>2012-10-18T08:00:13Z</updated>
    <published>2012-10-18T08:00:13Z</published>
    <title>Counterparty Risk and Funding: The Four Wings of the TVA</title>
    <summary>  The credit crisis and the ongoing European sovereign debt crisis have
highlighted the native form of credit risk, namely the counterparty risk. The
related Credit Valuation Adjustment, (CVA), Debt Valuation Adjustment (DVA),
Liquidity Valuation Adjustment (LVA) and Replacement Cost (RC) issues, jointly
referred to in this paper as Total Valuation Adjustment (TVA), have been
thoroughly investigated in the theoretical papers [Cr12a] and [Cr12b]. The
present work provides an executive summary and numerical companion to these
papers, through which the TVA pricing problem can be reduced to Markovian
pre-default TVA BSDEs. The first step consists in the counterparty clean
valuation of a portfolio of contracts, which is the valuation in a hypothetical
situation where the two parties would be risk-free and funded at a risk-free
rate. In the second step, the TVA is obtained as the value of an option on the
counterparty clean value process called Contingent Credit Default Swap (CCDS).
Numerical results are presented for interest rate swaps in the Vasicek, as well
as in the inverse Gaussian Hull-White short rate model, also allowing one to
assess the related model risk issue.
</summary>
    <author>
      <name>Stéphane Crépey</name>
    </author>
    <author>
      <name>Rémi Gerboud</name>
    </author>
    <author>
      <name>Zorana Grbac</name>
    </author>
    <author>
      <name>Nathalie Ngor</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">29 pages, 9 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1210.5046v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.5046v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.6000v2</id>
    <updated>2012-10-23T10:44:34Z</updated>
    <published>2012-10-22T19:01:06Z</published>
    <title>Solvency assessment within the ORSA framework: issues and quantitative
  methodologies</title>
    <summary>  The implementation of the Own Risk and Solvency Assessment is a critical
issue raised by Pillar II of Solvency II framework. In particular the Overall
Solvency Needs calculation left the Insurance companies to define an optimal
entity-specific solvency constraint on a multi-year time horizon. In a life
insurance society framework, the intuitive approaches to answer this problem
can sometimes lead to new implementation issues linked to the highly stochastic
nature of the methodologies used to project a company Net Asset Value over
several years. One alternative approach can be the use of polynomial proxies to
replicate the outcomes of this variable throughout the time horizon. Polynomial
functions are already considered as efficient replication methodologies for the
Net Asset Value over 1 year. The Curve Fitting and Least Squares Monte-Carlo
procedures are the best-known examples of such procedures. In this article we
introduce a possibility of adaptation for these methodologies to be used on a
multi-year time horizon, in order to assess the Overall Solvency Needs.
</summary>
    <author>
      <name>Julien Vedani</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">SAF</arxiv:affiliation>
    </author>
    <author>
      <name>Laurent Devineau</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">SAF</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/1210.6000v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.6000v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.5235v2</id>
    <updated>2013-02-05T07:29:46Z</updated>
    <published>2012-11-22T09:09:04Z</published>
    <title>Optimal portfolio for a robust financial system</title>
    <summary>  This study presents an ANWSER model (asset network systemic risk model) to
quantify the risk of financial contagion which manifests itself in a financial
crisis. The transmission of financial distress is governed by a heterogeneous
bank credit network and an investment portfolio of banks. Bankruptcy
reproductive ratio of a financial system is computed as a function of the
diversity and risk exposure of an investment portfolio of banks, and the
denseness and concentration of a heterogeneous bank credit network. An analytic
solution of the bankruptcy reproductive ratio for a small financial system is
derived and a numerical solution for a large financial system is obtained. For
a large financial system, Large diversity among banks in the investment
portfolio makes financial contagion more damaging on the average. But large
diversity is essentially effective in eliminating the risk of financial
contagion in the worst case of financial crisis scenarios. A bank-unique
specialization portfolio is more suitable than a uniform diversification
portfolio and a system-wide specialization portfolio in strengthening the
robustness of a financial system.
</summary>
    <author>
      <name>Yoshiharu Maeno</name>
    </author>
    <author>
      <name>Kenji Nishiguchi</name>
    </author>
    <author>
      <name>Satoshi Morinaga</name>
    </author>
    <author>
      <name>Hirokazu Matsushima</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/CIFEr.2013.6611695</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/CIFEr.2013.6611695" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">presented at the IEEE Workshop on Computational Intelligence for
  Financial Engineering and Economics, Singapore, April 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1211.5235v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.5235v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.3716v6</id>
    <updated>2013-11-26T18:43:50Z</updated>
    <published>2012-12-15T19:08:46Z</published>
    <title>The art of probability-of-default curve calibration</title>
    <summary>  PD curve calibration refers to the transformation of a set of rating grade
level probabilities of default (PDs) to another average PD level that is
determined by a change of the underlying portfolio-wide PD. This paper presents
a framework that allows to explore a variety of calibration approaches and the
conditions under which they are fit for purpose. We test the approaches
discussed by applying them to publicly available datasets of agency rating and
default statistics that can be considered typical for the scope of application
of the approaches. We show that the popular 'scaled PDs' approach is
theoretically questionable and identify an alternative calibration approach
('scaled likelihood ratio') that is both theoretically sound and performs
better on the test datasets.
  Keywords: Probability of default, calibration, likelihood ratio, Bayes'
formula, rating profile, binary classification.
</summary>
    <author>
      <name>Dirk Tasche</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">35 pages, 1 figure, 12 tables, minor changes</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Credit Risk 9(4), 63-103, 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1212.3716v6" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.3716v6" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62P05" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.5563v5</id>
    <updated>2014-10-10T07:32:37Z</updated>
    <published>2012-12-21T19:10:08Z</published>
    <title>Multiportfolio time consistency for set-valued convex and coherent risk
  measures</title>
    <summary>  Equivalent characterizations of multiportfolio time consistency are deduced
for closed convex and coherent set-valued risk measures on $L^p(\Omega,\mathcal
F, P; R^d)$ with image space in the power set of $L^p(\Omega,\mathcal
F_t,P;R^d)$. In the convex case, multiportfolio time consistency is equivalent
to a cocycle condition on the sum of minimal penalty functions. In the coherent
case, multiportfolio time consistency is equivalent to a generalized version of
stability of the dual variables. As examples, the set-valued entropic risk
measure with constant risk aversion coefficient is shown to satisfy the cocycle
condition for its minimal penalty functions, the set of superhedging portfolios
in markets with proportional transaction costs is shown to have the stability
property and in markets with convex transaction costs is shown to satisfy the
composed cocycle condition, and a multiportfolio time consistent version of the
set-valued average value at risk, the composed AV@R, is given and its dual
representation deduced.
</summary>
    <author>
      <name>Zachary Feinstein</name>
    </author>
    <author>
      <name>Birgit Rudloff</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s00780-014-0247-6</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s00780-014-0247-6" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Finance and Stochastics 19 (1), 67-107 (2015)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1212.5563v5" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.5563v5" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B30, 46A20, 46N10, 26E25" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.5497v7</id>
    <updated>2014-07-12T14:33:25Z</updated>
    <published>2013-01-23T13:28:21Z</published>
    <title>Suitability of Capital Allocations for Performance Measurement</title>
    <summary>  Capital allocation principles are used in various contexts in which a risk
capital or a cost of an aggregate position has to be allocated among its
constituent parts. We study capital allocation principles in a performance
measurement framework. We introduce the notation of suitability of allocations
for performance measurement and show under different assumptions on the
involved reward and risk measures that there exist suitable allocation methods.
The existence of certain suitable allocation principles generally is given
under rather strict assumptions on the underlying risk measure. Therefore we
show, with a reformulated definition of suitability and in a slightly modified
setting, that there is a known suitable allocation principle that does not
require any properties of the underlying risk measure. Additionally we extend a
previous characterization result from the literature from a mean-risk to a
reward-risk setting. Formulations of this theory are also possible in a game
theoretic setting.
</summary>
    <author>
      <name>Eduard Kromer</name>
    </author>
    <author>
      <name>Ludger Overbeck</name>
    </author>
    <link href="http://arxiv.org/abs/1301.5497v7" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.5497v7" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91G10, 91G40, 91B06" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.5821v1</id>
    <updated>2013-01-24T15:47:30Z</updated>
    <published>2013-01-24T15:47:30Z</published>
    <title>Ecosystems perspective on financial networks: diagnostic tools</title>
    <summary>  The economical world consists of a highly interconnected and interdependent
network of firms. Here we develop temporal and structural network tools to
analyze the state of the economy. Our analysis indicates that a strong
clustering can be a warning sign. Reduction in diversity, which was an
essential aspect of the dynamics surrounding the crash in 2008, is seen as a
key emergent feature arising naturally from the evolutionary and adaptive
dynamics inherent to the financial markets. Similarly, collusion amongst
construction firms in a number of regions in Japan in the 2000s can be
identified with the formation of clusters of anomalous highly connected
companies.
</summary>
    <author>
      <name>Eduardo Viegas</name>
    </author>
    <author>
      <name>Misako Takayasu</name>
    </author>
    <author>
      <name>Wataru Miura</name>
    </author>
    <author>
      <name>Koutarou Tamura</name>
    </author>
    <author>
      <name>Takaaki Ohnishi</name>
    </author>
    <author>
      <name>Hideki Takayasu</name>
    </author>
    <author>
      <name>Henrik Jeldtoft Jensen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages, 5 figures and one appendix</arxiv:comment>
    <link href="http://arxiv.org/abs/1301.5821v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.5821v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.6069v1</id>
    <updated>2013-01-25T15:31:59Z</updated>
    <published>2013-01-25T15:31:59Z</published>
    <title>Cross-Ownership as a Structural Explanation for Over- and
  Underestimation of Default Probability</title>
    <summary>  Based on the work of Suzuki (2002), we consider a generalization of Merton's
asset valuation approach (Merton, 1974) in which two firms are linked by
cross-ownership of equity and liabilities. Suzuki's results then provide no
arbitrage prices of firm values, which are derivatives of exogenous asset
values. In contrast to the Merton model, the assumption of lognormally
distributed assets does not result in lognormally distributed firm values,
which also affects the corresponding probabilities of default. In a simulation
study we see that, depending on the type of cross-ownership, the lognormal
model can lead to both, over- and underestimation of the actual probability of
default of a firm under cross-ownership. In the limit, i.e. if the levels of
cross-ownership tend to their maximum possible value, these findings can be
shown theoretically as well. Furthermore, we consider the default probability
of a firm in general, i.e. without a distributional assumption, and show that
the lognormal model is often able to yield only a limited range of
probabilities of default, while the actual probabilities may take any value
between 0 and 1.
</summary>
    <author>
      <name>Sabine Karl</name>
    </author>
    <author>
      <name>Tom Fischer</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1080/14697688.2013.834377</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1080/14697688.2013.834377" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">40 pages, 5 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Quantitative Finance 14 (6), 1031-1046</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1301.6069v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.6069v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B24, 91B25, 91G20, 91G40, 91G50" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.6114v2</id>
    <updated>2014-01-02T21:57:00Z</updated>
    <published>2013-01-25T18:16:24Z</published>
    <title>Leverage-induced systemic risk under Basle II and other credit risk
  policies</title>
    <summary>  We use a simple agent based model of value investors in financial markets to
test three credit regulation policies. The first is the unregulated case, which
only imposes limits on maximum leverage. The second is Basle II and the third
is a hypothetical alternative in which banks perfectly hedge all of their
leverage-induced risk with options. When compared to the unregulated case both
Basle II and the perfect hedge policy reduce the risk of default when leverage
is low but increase it when leverage is high. This is because both regulation
policies increase the amount of synchronized buying and selling needed to
achieve deleveraging, which can destabilize the market. None of these policies
are optimal for everyone: Risk neutral investors prefer the unregulated case
with low maximum leverage, banks prefer the perfect hedge policy, and fund
managers prefer the unregulated case with high maximum leverage. No one prefers
Basle II.
</summary>
    <author>
      <name>Sebastian Poledna</name>
    </author>
    <author>
      <name>Stefan Thurner</name>
    </author>
    <author>
      <name>J. Doyne Farmer</name>
    </author>
    <author>
      <name>John Geanakoplos</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">27 pages, 8 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1301.6114v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.6114v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.6115v1</id>
    <updated>2013-01-25T18:16:29Z</updated>
    <published>2013-01-25T18:16:29Z</published>
    <title>DebtRank-transparency: Controlling systemic risk in financial networks</title>
    <summary>  Banks in the interbank network can not assess the true risks associated with
lending to other banks in the network, unless they have full information on the
riskiness of all the other banks. These risks can be estimated by using network
metrics (for example DebtRank) of the interbank liability network which is
available to Central Banks. With a simple agent based model we show that by
increasing transparency by making the DebtRank of individual nodes (banks)
visible to all nodes, and by imposing a simple incentive scheme, that reduces
interbank borrowing from systemically risky nodes, the systemic risk in the
financial network can be drastically reduced. This incentive scheme is an
effective regulation mechanism, that does not reduce the efficiency of the
financial network, but fosters a more homogeneous distribution of risk within
the system in a self-organized critical way. We show that the reduction of
systemic risk is to a large extent due to the massive reduction of cascading
failures in the transparent system. An implementation of this minimal
regulation scheme in real financial networks should be feasible from a
technical point of view.
</summary>
    <author>
      <name>Stefan Thurner</name>
    </author>
    <author>
      <name>Sebastian Poledna</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1301.6115v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.6115v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1303.1690v3</id>
    <updated>2014-03-31T13:12:28Z</updated>
    <published>2013-03-07T14:03:32Z</published>
    <title>Coherence and elicitability</title>
    <summary>  The risk of a financial position is usually summarized by a risk measure. As
this risk measure has to be estimated from historical data, it is important to
be able to verify and compare competing estimation procedures. In statistical
decision theory, risk measures for which such verification and comparison is
possible, are called elicitable. It is known that quantile based risk measures
such as value at risk are elicitable. In this paper we show that law-invariant
spectral risk measures such as expected shortfall are not elicitable unless
they reduce to minus the expected value. Hence, it is unclear how to perform
forecast verification or comparison. However, the class of elicitable
law-invariant coherent risk measures does not reduce to minus the expected
value. We show that it consists of certain expectiles.
</summary>
    <author>
      <name>Johanna F. Ziegel</name>
    </author>
    <link href="http://arxiv.org/abs/1303.1690v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1303.1690v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1303.5552v1</id>
    <updated>2013-03-22T09:12:01Z</updated>
    <published>2013-03-22T09:12:01Z</published>
    <title>Quantifying the Impact of Leveraging and Diversification on Systemic
  Risk</title>
    <summary>  Excessive leverage, i.e. the abuse of debt financing, is considered one of
the primary factors in the default of financial institutions. Systemic risk
results from correlations between individual default probabilities that cannot
be considered independent. Based on the structural framework by Merton (1974),
we discuss a model in which these correlations arise from overlaps in banks'
portfolios. Portfolio diversification is used as a strategy to mitigate losses
from investments in risky projects. We calculate an optimal level of
diversification that has to be reached for a given level of excessive leverage
to still mitigate an increase in systemic risk. In our model, this optimal
diversification further depends on the market size and the market conditions
(e.g. volatility). It allows to distinguish between a safe regime, in which
excessive leverage does not result in an increase of systemic risk, and a risky
regime, in which excessive leverage cannot be mitigated leading to an increased
systemic risk. Our results are of relevance for financial regulators.
</summary>
    <author>
      <name>Paolo Tasca</name>
    </author>
    <author>
      <name>Pavlin Mavrodiev</name>
    </author>
    <author>
      <name>Frank Schweitzer</name>
    </author>
    <link href="http://arxiv.org/abs/1303.5552v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1303.5552v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.3814v1</id>
    <updated>2013-04-13T15:06:57Z</updated>
    <published>2013-04-13T15:06:57Z</published>
    <title>Measuring the default risk of sovereign debt from the perspective of
  network</title>
    <summary>  Recently, there has been a growing interest in network research, especially
in these fields of biology, computer science, and sociology. It is natural to
address complex financial issues such as the European sovereign debt crisis
from the perspective of network. In this article, we construct a network model
according to the debt--credit relations instead of using the conventional
methodology to measure the default risk. Based on the model, a risk index is
examined using the quarterly report of consolidated foreign claims from the
Bank for International Settlements (BIS) and debt/GDP ratios among these
reporting countries. The empirical results show that this index can help the
regulators and practitioners not only to determine the status of
interconnectivity but also to point out the degree of the sovereign debt
default risk. Our approach sheds new light on the investigation of quantifying
the systemic risk.
</summary>
    <author>
      <name>Hongwei Chuang</name>
    </author>
    <author>
      <name>Hwai-Chung Ho</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.physa.2013.01.004</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.physa.2013.01.004" rel="related"/>
    <link href="http://arxiv.org/abs/1304.3814v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.3814v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1306.1882v1</id>
    <updated>2013-06-08T04:58:09Z</updated>
    <published>2013-06-08T04:58:09Z</published>
    <title>Loss Distribution Approach for Operational Risk Capital Modelling under
  Basel II: Combining Different Data Sources for Risk Estimation</title>
    <summary>  The management of operational risk in the banking industry has undergone
significant changes over the last decade due to substantial changes in
operational risk environment. Globalization, deregulation, the use of complex
financial products and changes in information technology have resulted in
exposure to new risks very different from market and credit risks. In response,
Basel Committee for banking Supervision has developed a regulatory framework,
referred to as Basel II, that introduced operational risk category and
corresponding capital requirements. Over the past five years, major banks in
most parts of the world have received accreditation under the Basel II Advanced
Measurement Approach (AMA) by adopting the loss distribution approach (LDA)
despite there being a number of unresolved methodological challenges in its
implementation. Different approaches and methods are still under hot debate. In
this paper, we review methods proposed in the literature for combining
different data sources (internal data, external data and scenario analysis)
which is one of the regulatory requirement for AMA.
</summary>
    <author>
      <name>Pavel V. Shevchenko</name>
    </author>
    <author>
      <name>Gareth W. Peters</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">The Journal of Governance and Regulation 2(3), pages 33-57, (2013)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1306.1882v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1306.1882v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1306.3479v2</id>
    <updated>2015-03-15T17:31:59Z</updated>
    <published>2013-06-14T18:35:49Z</published>
    <title>Ruin probability of a discrete-time risk process with proportional
  reinsurance and investment for exponential and Pareto distributions</title>
    <summary>  In this paper a quantitative analysis of the ruin probability in finite time
of discrete risk process with proportional reinsurance and investment of
finance surplus is focused on. It is assumed that the total loss on a unit
interval has a light-tailed distribution -- exponential distribution and a
heavy-tailed distribution -- Pareto distribution. The ruin probability for
finite-horizon 5 and 10 was determined from recurrence equations. Moreover for
exponential distribution the upper bound of ruin probability by Lundberg
adjustment coefficient is given. For Pareto distribution the adjustment
coefficient does not exist, hence an asymptotic approximation of the ruin
probability if an initial capital tends to infinity is given. Obtained
numerical results are given as tables and they are illustrated as graphs.
</summary>
    <author>
      <name>Helena Jasiulewicz</name>
    </author>
    <author>
      <name>Wojciech Kordecki</name>
    </author>
    <link href="http://arxiv.org/abs/1306.3479v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1306.3479v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1306.5510v1</id>
    <updated>2013-06-24T04:50:04Z</updated>
    <published>2013-06-24T04:50:04Z</published>
    <title>Compound Wishart Matrices and Noisy Covariance Matrices: Risk
  Underestimation</title>
    <summary>  In this paper, we obtain a property of the expectation of the inverse of
compound Wishart matrices which results from their orthogonal invariance. Using
this property as well as results from random matrix theory (RMT), we derive the
asymptotic effect of the noise induced by estimating the covariance matrix on
computing the risk of the optimal portfolio. This in turn enables us to get an
asymptotically unbiased estimator of the risk of the optimal portfolio not only
for the case of independent observations but also in the case of correlated
observations. This improvement provides a new approach to estimate the risk of
a portfolio based on covariance matrices estimated from exponentially weighted
moving averages of stock returns.
</summary>
    <author>
      <name>Benoît Collins</name>
    </author>
    <author>
      <name>David McDonald</name>
    </author>
    <author>
      <name>Nadia Saad</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">24 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1306.5510v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1306.5510v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1306.6715v1</id>
    <updated>2013-06-28T05:08:53Z</updated>
    <published>2013-06-28T05:08:53Z</published>
    <title>The Meaning of Probability of Default for Asset-backed Loans</title>
    <summary>  The authors examine the concept of probability of default for asset-backed
loans. In contrast to unsecured loans it is shown that probability of default
can be defined as either a measure of the likelihood of the borrower failing to
make required payments, or as the likelihood of an insufficiency of collateral
value on foreclosure. Assuming expected loss is identical under either
definition, this implies a corresponding pair of definitions for loss given
default. Industry treatment of probability of default for asset-backed loans
appears to inconsistently blend the two types of definition.
  The authors develop a mathematical treatment of asset-backed loans which
consistently applies each type of definition in a framework to produce the same
expected loss and allows translation between the two frameworks.
</summary>
    <author>
      <name>David Chisholm</name>
    </author>
    <author>
      <name>Graham Andersen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">28 pages, 13 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1306.6715v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1306.6715v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1308.0652v3</id>
    <updated>2013-12-14T13:41:07Z</updated>
    <published>2013-08-03T02:39:15Z</published>
    <title>Efficient immunization strategies to prevent financial contagion</title>
    <summary>  Many immunization strategies have been proposed to prevent infectious viruses
from spreading through a network. In this study, we propose efficient
immunization strategies to prevent a default contagion that might occur in a
financial network. An essential difference from the previous studies on
immunization strategy is that we take into account the possibility of serious
side effects. Uniform immunization refers to a situation in which banks are
"vaccinated" with a common low-risk asset. The riskiness of immunized banks
will decrease significantly, but the level of systemic risk may increase due to
the de-diversification effect. To overcome this side effect, we propose another
immunization strategy, counteractive immunization, which prevents pairs of
banks from failing simultaneously. We find that counteractive immunization can
efficiently reduce systemic risk without altering the riskiness of individual
banks.
</summary>
    <author>
      <name>Teruyoshi Kobayashi</name>
    </author>
    <author>
      <name>Kohei Hasui</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1038/srep03834</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1038/srep03834" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 6 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Scientific Reports 4, 3834, 2014</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1308.0652v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1308.0652v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1308.0773v1</id>
    <updated>2013-08-04T02:47:35Z</updated>
    <published>2013-08-04T02:47:35Z</published>
    <title>Network versus portfolio structure in financial systems</title>
    <summary>  The question of how to stabilize financial systems has attracted considerable
attention since the global financial crisis of 2007-2009. Recently, Beale et
al. ("Individual versus systemic risk and the regulator's dilemma", Proc Natl
Acad Sci USA 108: 12647-12652, 2011) demonstrated that higher portfolio
diversity among banks would reduce systemic risk by decreasing the risk of
simultaneous defaults at the expense of a higher likelihood of individual
defaults. In practice, however, a bank default has an externality in that it
undermines other banks' balance sheets. This paper explores how each of these
different sources of risk, simultaneity risk and externality, contributes to
systemic risk. The results show that the allocation of external assets that
minimizes systemic risk varies with the topology of the financial network as
long as asset returns have negative correlations. In the model, a well-known
centrality measure, PageRank, reflects an appropriately defined "infectiveness"
of a bank. An important result is that the most infective bank need not always
be the safest bank. Under certain circumstances, the most infective node should
act as a firewall to prevent large-scale collective defaults. The introduction
of a counteractive portfolio structure will significantly reduce systemic risk.
</summary>
    <author>
      <name>Teruyoshi Kobayashi</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1140/epjb/e2013-40072-9</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1140/epjb/e2013-40072-9" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">European Physical Journal B, 86 10 (2013) 434</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1308.0773v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1308.0773v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1308.0889v2</id>
    <updated>2014-06-02T06:11:44Z</updated>
    <published>2013-08-05T05:17:21Z</published>
    <title>The Financing of Innovative SMEs: a multicriteria credit rating model</title>
    <summary>  Small Medium-sized Enterprises (SMEs) face many obstacles when they try to
access credit market. These obstacles are increased if the SMEs are innovative.
In this case, financial data are insufficient or even not reliable. Thus, when
building a judgemental rating model, mainly based on qualitative criteria (soft
information), it is very important to finance SMEs' activities. Until now,
there isn't a multicriteria credit risk model based on soft information for
innovative SMEs. In this paper, we try to fill this gap by presenting a
multicriteria credit risk model, specifically, ELECTRE-TRI. To obtain robust
SMEs' assignments to the risk classes, a SMAA-TRI analysis is also implemented.
In fact, SMAA-TRI incorporates ELECTRE-TRI by considering different sets of
preference parameters with Monte Carlo simulations. Finally, we carry out some
real case studies, with the aim of illustrating the multicriteria credit risk
model proposed.
</summary>
    <author>
      <name>Silvia Angilella</name>
    </author>
    <author>
      <name>Sebastiano Mazzù</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">34 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1308.0889v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1308.0889v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1308.0958v3</id>
    <updated>2014-01-11T11:28:33Z</updated>
    <published>2013-08-05T12:45:29Z</published>
    <title>The Skin In The Game Heuristic for Protection Against Tail Events</title>
    <summary>  Standard economic theory makes an allowance for the agency problem, but not
the compounding of moral hazard in the presence of informational opacity,
particularly in what concerns high-impact events in fat tailed domains (under
slow convergence for the law of large numbers). Nor did it look at exposure as
a filter that removes nefarious risk takers from the system so they stop
harming others. \textcolor{red}{ (In the language of probability, skin in the
game creates an absorbing state for the agent, not just the principal)}. But
the ancients did; so did many aspects of moral philosophy. We propose a global
and morally mandatory heuristic that anyone involved in an action which can
possibly generate harm for others, even probabilistically, should be required
to be exposed to some damage, regardless of context. While perhaps not
sufficient, the heuristic is certainly necessary hence mandatory. It is
supposed to counter voluntary and involuntary risk hiding$-$ and risk transfer
$-$ in the tails. We link the rule to various philosophical approaches to
ethics and moral luck.
</summary>
    <author>
      <name>Nassim N. Taleb</name>
    </author>
    <author>
      <name>Constantine Sandis</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Review of Behavioral Economics, Jan 2014</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1308.0958v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1308.0958v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1308.3331v2</id>
    <updated>2014-03-04T17:21:20Z</updated>
    <published>2013-08-15T08:01:12Z</published>
    <title>Measuring risk with multiple eligible assets</title>
    <summary>  The risk of financial positions is measured by the minimum amount of capital
to raise and invest in eligible portfolios of traded assets in order to meet a
prescribed acceptability constraint. We investigate nondegeneracy, finiteness
and continuity properties of these risk measures with respect to multiple
eligible assets. Our finiteness and continuity results highlight the interplay
between the acceptance set and the class of eligible portfolios. We present a
simple, alternative approach to the dual representation of convex risk measures
by directly applying to the acceptance set the external characterization of
closed, convex sets. We prove that risk measures are nondegenerate if and only
if the pricing functional admits a positive extension which is a supporting
functional for the underlying acceptance set, and provide a characterization of
when such extensions exist. Finally, we discuss applications to set-valued risk
measures, superhedging with shortfall risk, and optimal risk sharing.
</summary>
    <author>
      <name>Walter Farkas</name>
    </author>
    <author>
      <name>Pablo Koch-Medina</name>
    </author>
    <author>
      <name>Cosimo Munari</name>
    </author>
    <link href="http://arxiv.org/abs/1308.3331v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1308.3331v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1308.5152v1</id>
    <updated>2013-08-23T15:10:44Z</updated>
    <published>2013-08-23T15:10:44Z</published>
    <title>Computation of ruin probabilities for general discrete-time Markov
  models</title>
    <summary>  We study the ruin problem over a risk process described by a discrete-time
Markov model. In contrast to previous studies that focused on the asymptotic
behaviour of ruin probabilities for large values of the initial capital, we
provide a new technique to compute the quantity of interest for any initial
value, and with any given precision. Rather than focusing on a particular model
for risk processes, we give a general characterization of the ruin probability
by providing corresponding recursions and fixpoint equations. Since such
equations for the ruin probability are ill-posed in the sense that they do not
allow for unique solutions, we approximate the ruin probability by a
two-barrier ruin probability, for which fixpoint equations are well-posed. We
also show how good the introduced approximation is by providing an explicit
bound on the error and by characterizing the cases when the error converges to
zero. The presented technique and results are supported by two computational
examples over models known in the literature, one of which is extremely
heavy-tailed.
</summary>
    <author>
      <name>Ilya Tkachev</name>
    </author>
    <author>
      <name>Alessandro Abate</name>
    </author>
    <link href="http://arxiv.org/abs/1308.5152v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1308.5152v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1309.3102v1</id>
    <updated>2013-09-12T10:37:21Z</updated>
    <published>2013-09-12T10:37:21Z</published>
    <title>A nested factor model for non-linear dependences in stock returns</title>
    <summary>  The aim of our work is to propose a natural framework to account for all the
empirically known properties of the multivariate distribution of stock returns.
We define and study a "nested factor model", where the linear factors part is
standard, but where the log-volatility of the linear factors and of the
residuals are themselves endowed with a factor structure and residuals. We
propose a calibration procedure to estimate these log-vol factors and the
residuals. We find that whereas the number of relevant linear factors is
relatively large (10 or more), only two or three log-vol factors emerge in our
analysis of the data. In fact, a minimal model where only one log-vol factor is
considered is already very satisfactory, as it accurately reproduces the
properties of bivariate copulas, in particular the dependence of the
medial-point on the linear correlation coefficient, as reported in
Chicheportiche and Bouchaud (2012). We have tested the ability of the model to
predict Out-of-Sample the risk of non-linear portfolios, and found that it
performs significantly better than other schemes.
</summary>
    <author>
      <name>Rémy Chicheportiche</name>
    </author>
    <author>
      <name>Jean-Philippe Bouchaud</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1080/14697688.2014.994668</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1080/14697688.2014.994668" rel="related"/>
    <link href="http://arxiv.org/abs/1309.3102v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1309.3102v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1309.5245v2</id>
    <updated>2013-11-18T15:06:50Z</updated>
    <published>2013-09-20T12:14:09Z</published>
    <title>Credit Risk and the Instability of the Financial System: an Ensemble
  Approach</title>
    <summary>  The instability of the financial system as experienced in recent years and in
previous periods is often linked to credit defaults, i.e., to the failure of
obligors to make promised payments. Given the large number of credit contracts,
this problem is amenable to be treated with approaches developed in statistical
physics. We introduce the idea of ensemble averaging and thereby uncover
generic features of credit risk. We then show that the often advertised concept
of diversification, i.e., reducing the risk by distributing it, is deeply
flawed when it comes to credit risk. The risk of extreme losses remain due to
the ever present correlations, implying a substantial and persistent intrinsic
danger to the financial system.
</summary>
    <author>
      <name>Thilo A. Schmitt</name>
    </author>
    <author>
      <name>Desislava Chetalova</name>
    </author>
    <author>
      <name>Rudi Schäfer</name>
    </author>
    <author>
      <name>Thomas Guhr</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1209/0295-5075/105/38004</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1209/0295-5075/105/38004" rel="related"/>
    <link href="http://arxiv.org/abs/1309.5245v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1309.5245v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1309.7222v2</id>
    <updated>2013-12-23T10:01:53Z</updated>
    <published>2013-09-27T12:33:08Z</published>
    <title>Continuous compliance: a proxy-based monitoring framework</title>
    <summary>  Within the Own Risk and Solvency Assessment framework, the Solvency II
directive introduces the need for insurance undertakings to have efficient
tools enabling the companies to assess the continuous compliance with
regulatory solvency requirements. Because of the great operational complexity
resulting from each complete evaluation of the Solvency Ratio, this monitoring
is often complicated to implement in practice. This issue is particularly
important for life insurance companies due to the high complexity to project
life insurance liabilities. It appears relevant in such a context to use
parametric tools, such as Curve Fitting and Least Squares Monte Carlo in order
to estimate, on a regular basis, the impact on the economic own funds and on
the regulatory capital of the company of any change over time of its underlying
risk factors. In this article, we first outline the principles of the
continuous compliance requirement then we propose and implement a possible
monitoring tool enabling to approximate the eligible elements and the
regulatory capital over time. In a final section we compare the use of the
Curve Fitting and the Least Squares Monte Carlo methodologies in a standard
empirical finite sample framework, and stress adapted advices for future
proxies users.
</summary>
    <author>
      <name>Julien Vedani</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">SAF</arxiv:affiliation>
    </author>
    <author>
      <name>Fabien Ramaharobandro</name>
    </author>
    <link href="http://arxiv.org/abs/1309.7222v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1309.7222v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.8604v1</id>
    <updated>2013-10-31T17:26:19Z</updated>
    <published>2013-10-31T17:26:19Z</published>
    <title>Modeling catastrophic deaths using EVT with a microsimulation approach
  to reinsurance pricing</title>
    <summary>  Recently, a marked Poisson process (MPP) model for life catastrophe risk was
proposed in [6]. We provide a justification and further support for the model
by considering more general Poisson point processes in the context of extreme
value theory (EVT), and basing the choice of model on statistical tests and
model comparisons. A case study examining accidental deaths in the Finnish
population is provided.
  We further extend the applicability of the catastrophe risk model by
considering small and big accidents separately; the resulting combined MPP
model can flexibly capture the whole range of accidental death counts. Using
the proposed model, we present a simulation framework for pricing (life)
catastrophe reinsurance, based on modeling the underlying policies at
individual contract level. The accidents are first simulated at population
level, and their effect on a specific insurance company is then determined by
explicitly simulating the resulting insured deaths. The proposed
microsimulation approach can potentially lead to more accurate results than the
traditional methods, and to a better view of risk, as it can make use of all
the information available to the re/insurer and can explicitly accommodate even
complex re/insurance terms and product features. As an example we price several
excess reinsurance contracts. The proposed simulation model is also suitable
for solvency assessment.
</summary>
    <author>
      <name>Matias Leppisaari</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">32 pages, 9 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1310.8604v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.8604v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1311.4266v1</id>
    <updated>2013-11-18T04:47:03Z</updated>
    <published>2013-11-18T04:47:03Z</published>
    <title>Prévision du risque de crédit : Une étude comparative entre
  l'Analyse Discriminante et l'Approche Neuronale</title>
    <summary>  Banks are interested in evaluating the risk of the financial distress before
giving out a loan. Many researchers proposed the use of models based on the
Neural Networks in order to help the banker better make a decision. The
objective of this paper is to explore a new practical way based on the Neural
Networks that would help improve the capacity of the banker to predict the risk
class of the companies asking for a loan. This work is motivated by the
insufficiency of traditional prevision models. The sample consists of 86
Tunisian firms and 15 financial ratios are calculated, over the period from
2005 to 2007. The results are compared with those of discriminant analysis.
They show that the neural networks technique is the best in term of
predictability.
</summary>
    <author>
      <name>Younes Boujelbène</name>
    </author>
    <author>
      <name>Sihem Khemakhem</name>
    </author>
    <link href="http://arxiv.org/abs/1311.4266v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1311.4266v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1312.0283v1</id>
    <updated>2013-12-01T23:03:41Z</updated>
    <published>2013-12-01T23:03:41Z</published>
    <title>Stochastic areas of diffusions and applications in risk theory</title>
    <summary>  In this paper we study the stochastic area swept by a regular
time-homogeneous diffusion till a stopping time. This unifies some recent
literature in this area. Through stochastic time change we establish a link
between the stochastic area and the stopping time of another associated
time-homogeneous diffusion. Then we characterize the Laplace transform of the
stochastic area in terms of the eigenfunctions of the associated diffusion. We
also explicitly obtain the integer moments of the stochastic area in terms of
scale and speed densities of the associated diffusion. Specifically we study in
detail three stopping times: the first passage time to a constant level, the
first drawdown time and the Azema-Yor stopping time. We also study the total
occupation area of the diffusion below a constant level. We show applications
of the results to a new structural model of default (Yildirim 2006), the Omega
risk model of bankruptcy in risk analysis (Gerber, Shiu and Yang 2012), and a
diffusion risk model with surplus-dependent tax (Albrecher and Hipp 2007, Li,
Tang and Zhou 2013).
</summary>
    <author>
      <name>Zhenyu Cui</name>
    </author>
    <link href="http://arxiv.org/abs/1312.0283v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1312.0283v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="60G44, 91B70, 91B25" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1312.0506v1</id>
    <updated>2013-12-02T16:30:09Z</updated>
    <published>2013-12-02T16:30:09Z</published>
    <title>The impact of systemic risk on the diversification benefits of a risk
  portfolio</title>
    <summary>  Risk diversification is the basis of insurance and investment. It is thus
crucial to study the effects that could limit it. One of them is the existence
of systemic risk that affects all the policies at the same time. We introduce
here a probabilistic approach to examine the consequences of its presence on
the risk loading of the premium of a portfolio of insurance policies. This
approach could be easily generalized for investment risk. We see that, even
with a small probability of occurrence, systemic risk can reduce dramatically
the diversification benefits. It is clearly revealed via a non-diversifiable
term that appears in the analytical expression of the variance of our models.
We propose two ways of introducing it and discuss their advantages and
limitations. By using both VaR and TVaR to compute the loading, we see that
only the latter captures the full effect of systemic risk when its probability
to occur is low
</summary>
    <author>
      <name>Marc Busse</name>
    </author>
    <author>
      <name>Michel Dacorogna</name>
    </author>
    <author>
      <name>Marie Kratz</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages, 5 tableaux</arxiv:comment>
    <link href="http://arxiv.org/abs/1312.0506v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1312.0506v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B30, 91B70, 62P05" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1312.1006v2</id>
    <updated>2014-07-21T02:22:20Z</updated>
    <published>2013-12-04T02:24:40Z</published>
    <title>Dynamic Limit Growth Indices in Discrete Time</title>
    <summary>  We propose a new class of mappings, called Dynamic Limit Growth Indices, that
are designed to measure the long-run performance of a financial portfolio in
discrete time setup. We study various important properties for this new class
of measures, and in particular, we provide necessary and sufficient condition
for a Dynamic Limit Growth Index to be a dynamic assessment index. We also
establish their connection with classical dynamic acceptability indices, and we
show how to construct examples of Dynamic Limit Growth Indices using dynamic
risk measures and dynamic certainty equivalents. Finally, we propose a new
definition of time consistency, suitable for these indices, and we study time
consistency for the most notable representative of this class -- the dynamic
analog of risk sensitive criterion.
</summary>
    <author>
      <name>Tomasz R. Bielecki</name>
    </author>
    <author>
      <name>Igor Cialenco</name>
    </author>
    <author>
      <name>Marcin Pitera</name>
    </author>
    <link href="http://arxiv.org/abs/1312.1006v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1312.1006v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B30, 62P05, 97M30, 91B06" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1401.3133v2</id>
    <updated>2014-02-03T22:05:15Z</updated>
    <published>2014-01-14T10:46:56Z</published>
    <title>Capital adequacy tests and limited liability of financial institutions</title>
    <summary>  The theory of acceptance sets and their associated risk measures plays a key
role in the design of capital adequacy tests. The objective of this paper is to
investigate, in the context of bounded financial positions, the class of
surplus-invariant acceptance sets. These are characterized by the fact that
acceptability does not depend on the positive part, or surplus, of a capital
position. We argue that surplus invariance is a reasonable requirement from a
regulatory perspective, because it focuses on the interests of liability
holders of a financial institution. We provide a dual characterization of
surplus-invariant, convex acceptance sets, and show that the combination of
surplus invariance and coherence leads to a narrow range of capital adequacy
tests, essentially limited to scenario-based tests. Finally, we emphasize the
advantages of dealing with surplus-invariant acceptance sets as the primary
object rather than directly with risk measures, such as loss-based and
excess-invariant risk measures, which have been recently studied by Cont,
Deguest, and He (2013) and by Staum (2013), respectively.
</summary>
    <author>
      <name>Pablo Koch-Medina</name>
    </author>
    <author>
      <name>Santiago Moreno-Bromberg</name>
    </author>
    <author>
      <name>Cosimo Munari</name>
    </author>
    <link href="http://arxiv.org/abs/1401.3133v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1401.3133v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B30, 91B32" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1401.4787v3</id>
    <updated>2015-08-16T14:48:15Z</updated>
    <published>2014-01-20T03:55:15Z</published>
    <title>On the Measurement of Economic Tail Risk</title>
    <summary>  This paper attempts to provide a decision-theoretic foundation for the
measurement of economic tail risk, which is not only closely related to utility
theory but also relevant to statistical model uncertainty. The main result is
that the only risk measures that satisfy a set of economic axioms for the
Choquet expected utility and the statistical property of elicitability (i.e.
there exists an objective function such that minimizing the expected objective
function yields the risk measure) are the mean functional and the median
shortfall, which is the median of tail loss distribution. Elicitability is
important for backtesting. We also extend the result to address model
uncertainty by incorporating multiple scenarios. As an application, we argue
that median shortfall is a better alternative than expected shortfall for
setting capital requirements in Basel Accords.
</summary>
    <author>
      <name>Steven Kou</name>
    </author>
    <author>
      <name>Xianhua Peng</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">51 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1401.4787v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1401.4787v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.OT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91Gxx, 91B30, 62G35, 46N30, 47N30" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1401.6408v2</id>
    <updated>2014-04-16T13:31:56Z</updated>
    <published>2014-01-24T17:34:26Z</published>
    <title>Interconnected risk contributions: an heavy-tail approach to analyse US
  financial sectors</title>
    <summary>  In this paper we consider a multivariate model-based approach to measure the
dynamic evolution of tail risk interdependence among US banks, financial
services and insurance sectors. To deeply investigate the risk contribution of
insurers we consider separately life and non-life companies. To achieve this
goal we apply the multivariate student-t Markov Switching model and the
Multiple-CoVaR (CoES) risk measures introduced in Bernardi et. al. (2013b) to
account for both the known stylised characteristics of the data and the
contemporaneous joint distress events affecting financial sectors. Our
empirical investigation finds that banks appear to be the major source of risk
for all the remaining sectors, followed by the financial services and the
insurance sectors, showing that insurance sector significantly contributes as
well to the overall risk. Moreover, we find that the role of each sector in
contributing to other sectors distress evolves over time accordingly to the
current predominant financial condition, implying different interconnection
strength.
</summary>
    <author>
      <name>M. Bernardi</name>
    </author>
    <author>
      <name>L. Petrella</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: text overlap with arXiv:1312.6407</arxiv:comment>
    <link href="http://arxiv.org/abs/1401.6408v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1401.6408v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1402.3562v3</id>
    <updated>2014-06-23T20:17:37Z</updated>
    <published>2014-02-14T19:52:02Z</published>
    <title>Explicit Solutions of Optimal Consumption, Investment and Insurance
  Problem with Regime Switching</title>
    <summary>  We consider an investor who wants to select her/his optimal consumption,
investment and insurance policies. Motivated by new insurance products, we
allow not only the financial marke but also the insurable loss to depend on the
regime of the economy. The objective of the investor is to maximize her/his
expected total discounted utility of consumption over an infinite time horizon.
For the case of hyperbolic absolute risk aversion (HARA) utility functions, we
obtain the first explicit solutions for simultaneous optimal consumption,
investment, and insurance problems when there is regime switching. We determine
that the optimal insurance contract is either no-insurance or deductible
insurance, and calculate when it is optimal to buy insurance. The optimal
policy depends strongly on the regime of the economy. Through an economic
analysis, we calculate the advantage of buying insurance.
</summary>
    <author>
      <name>Bin Zou</name>
    </author>
    <author>
      <name>Abel Cadenillas</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">42 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1402.3562v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1402.3562v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1402.5352v3</id>
    <updated>2015-02-18T21:30:24Z</updated>
    <published>2014-02-21T17:02:19Z</published>
    <title>Systemic Risk and Default Clustering for Large Financial Systems</title>
    <summary>  As it is known in the finance risk and macroeconomics literature,
risk-sharing in large portfolios may increase the probability of creation of
default clusters and of systemic risk. We review recent developments on
mathematical and computational tools for the quantification of such phenomena.
Limiting analysis such as law of large numbers and central limit theorems allow
to approximate the distribution in large systems and study quantities such as
the loss distribution in large portfolios. Large deviations analysis allow us
to study the tail of the loss distribution and to identify pathways to default
clustering. Sensitivity analysis allows to understand the most likely ways in
which different effects, such as contagion and systematic risks, combine to
lead to large default rates. Such results could give useful insights into how
to optimally safeguard against such events.
</summary>
    <author>
      <name>Konstantinos Spiliopoulos</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">in Large Deviations and Asymptotic Methods in Finance, (Editors: P.
  Friz, J. Gatheral, A. Gulisashvili, A. Jacqier, J. Teichmann) , Springer
  Proceedings in Mathematics and Statistics, Vol. 110 2015,</arxiv:comment>
    <link href="http://arxiv.org/abs/1402.5352v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1402.5352v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.CP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91G40, 91G80, 60F05, 60F10, 60G55, 60G57" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1403.3459v1</id>
    <updated>2014-03-13T23:19:58Z</updated>
    <published>2014-03-13T23:19:58Z</published>
    <title>Structural Models under Additional Information</title>
    <summary>  It has been understood that the ``local" existence of the Markowitz' optimal
portfolio or the solution to the local risk minimization problem is guaranteed
by some specific mathematical structures on the underlying assets price
processes (called ``Structure Conditions" in the literature). In this paper, we
consider a semi-martingale market model (initial market model) fulfilling these
structures, and an arbitrary random time that is not adapted to the flow of the
``public" information. By adding additional uncertainty to the initial market
model, via this random time, those structures may fail. Our aim is to address
the question of how this random time will affect these structures from
different perspectives. Our analysis allowed us to conclude that under some
mild assumptions on the market model and the random time, these structures will
remain valid on the one hand. Furthermore, we provide two examples illustrating
the importance of these assumptions. On the other hand, we describe the random
time models for which these structure conditions are preserved for any market
model. These results are elaborated separately for the two contexts of stopping
with random time and incorporating totally a specific class of random times
respectively.
</summary>
    <author>
      <name>Tahir Choulli</name>
    </author>
    <author>
      <name>Jun Deng</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">24 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1403.3459v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1403.3459v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1403.7680v1</id>
    <updated>2014-03-29T23:48:16Z</updated>
    <published>2014-03-29T23:48:16Z</published>
    <title>Omega risk model with tax</title>
    <summary>  In this paper we study the Omega risk model with surplus-dependent tax
payments in a time-homogeneous diffusion setting. The new model incorporates
practical features from both the Omega risk model(Albrecher and Gerber and Shiu
(2011)) and the risk model with tax(Albrecher and Hipp (2007)). We explicitly
characterize the Laplace transform of the occupation time of an Azema-Yor
process(e.g. a process refracted by functionals of its running maximum) below a
constant level until the first hitting time of another Azema-Yor process or
until an independent exponential time. This result unifies and extends recent
literature(Li and Zhou (2013) and Zhang (2014)) incorporating some of their
results as special cases. We explicitly characterize the Laplace transform of
the time of bankruptcy in the Omega risk model with tax and discuss an
extension to integral functionals. Finally we present examples using a Brownian
motion with drift.
</summary>
    <author>
      <name>Zhenyu Cui</name>
    </author>
    <link href="http://arxiv.org/abs/1403.7680v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1403.7680v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="60G44, 91B25, 91B70" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1403.8018v2</id>
    <updated>2014-10-29T16:34:23Z</updated>
    <published>2014-03-31T14:36:31Z</published>
    <title>Are credit ratings time-homogeneous and Markov?</title>
    <summary>  We introduce a simple approach for testing the reliability of homogeneous
generators and the Markov property of the stochastic processes underlying
empirical time series of credit ratings. We analyze open access data provided
by Moody's and show that the validity of these assumptions - existence of a
homogeneous generator and Markovianity - is not always guaranteed. Our analysis
is based on a comparison between empirical transition matrices aggregated over
fixed time windows and candidate transition matrices generated from
measurements taken over shorter periods. Ratings are widely used in credit
risk, and are a key element in risk assessment; our results provide a tool for
quantifying confidence in predictions extrapolated from these time series.
</summary>
    <author>
      <name>Pedro Lencastre</name>
    </author>
    <author>
      <name>Frank Raischel</name>
    </author>
    <author>
      <name>Pedro G. Lind</name>
    </author>
    <author>
      <name>Tim Rogers</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, Fig 5, for 2014 conference</arxiv:comment>
    <link href="http://arxiv.org/abs/1403.8018v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1403.8018v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.1212v1</id>
    <updated>2014-05-06T10:08:33Z</updated>
    <published>2014-05-06T10:08:33Z</published>
    <title>Market risk modelling in Solvency II regime and hedging options not
  using underlying</title>
    <summary>  In the paper we develop mathematical tools of quantile hedging in incomplete
market. Those could be used for two significant applications:
  o calculating the \textbf{optimal capital requirement imposed by Solvency II}
(Directive 2009/138/EC of the European Parliament and of the Council) when the
market and non-market risk is present in insurance company. We show hot to find
the minimal capital $V_0$ to provide with the one-year hedging strategy for
insurance company satisfying $E\left[{\mathbf 1}_{\{V_1 \geq
D\}}\right]=0.995$, where $V_1$ denotes the value of insurance company in one
year time and $D$ is the payoff of the contract.
  o finding a hedging strategy for derivative not using underlying but an asset
with dynamics correlated or in some other way dependent (no deterministically)
on underlying. The work is a generalisation of the work of Klusik and Palmowski
\cite{KluPal}.
  Keywords: quantile hedging, solvency II, capital modelling, hedging options
on nontradable asset.
</summary>
    <author>
      <name>Przemysław Klusik</name>
    </author>
    <link href="http://arxiv.org/abs/1405.1212v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.1212v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.4905v2</id>
    <updated>2017-09-10T15:19:09Z</updated>
    <published>2014-05-19T22:10:52Z</published>
    <title>Set-valued shortfall and divergence risk measures</title>
    <summary>  Risk measures for multivariate financial positions are studied in a
utility-based framework. Under a certain incomplete preference relation,
shortfall and divergence risk measures are defined as the optimal values of
specific set minimization problems. The dual relationship between these two
classes of multivariate risk measures is constructed via a recent Lagrange
duality for set optimization. In particular, it is shown that a shortfall risk
measure can be written as an intersection over a family of divergence risk
measures indexed by a scalarization parameter. Examples include set-valued
versions of the entropic risk measure and the average value at risk. As a
second step, the minimization of these risk measures subject to trading
opportunities is studied in a general convex market in discrete time. The
optimal value of the minimization problem, called the market risk measure, is
also a set-valued risk measure. A dual representation for the market risk
measure that decomposes the effects of the original risk measure and the
frictions of the market is proved.
</summary>
    <author>
      <name>Çağın Ararat</name>
    </author>
    <author>
      <name>Andreas H. Hamel</name>
    </author>
    <author>
      <name>Birgit Rudloff</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1142/S0219024917500261</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1142/S0219024917500261" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Theoretical and Applied Finance 20 (5)
  1750026 (2017)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1405.4905v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.4905v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B30, 46N10, 46A20, 26E25, 90C46" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1406.5817v1</id>
    <updated>2014-06-23T06:40:44Z</updated>
    <published>2014-06-23T06:40:44Z</published>
    <title>Reduction of systemic risk by means of Pigouvian taxation</title>
    <summary>  We analyze the possibility of reduction of systemic risk in financial markets
through Pigouvian taxation of financial institutions which is used to support
the rescue fund. We introduce the concept of the cascade risk with a clear
operational definition as a subclass and a network related measure of the
systemic risk. Using financial networks constructed from real Italian money
market data and using realistic parameters, we show that the cascade risk can
be substantially reduced by a small rate of taxation and by means of a simple
strategy of the money transfer from the rescue fund to interbanking market
subjects. Furthermore, we show that while negative effects on the return on
investment ($ROI$) are direct and certain, an overall positive effect on risk
adjusted return on investments ($ROI^{RA}$) is visible. Please note that
\emph{the taxation} is introduced as a monetary/regulatory, not as a fiscal
measure, as the term could suggest. \emph{The rescue fund} is implemented in a
form of a common reserve fund.
</summary>
    <author>
      <name>Vinko Zlatić</name>
    </author>
    <author>
      <name>Giampaolo Gabbi</name>
    </author>
    <author>
      <name>Hrvoje Abraham</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1371/journal.pone.0114928</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1371/journal.pone.0114928" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages, 9 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1406.5817v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1406.5817v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.TR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1409.1071v3</id>
    <updated>2016-01-03T09:33:42Z</updated>
    <published>2014-09-03T13:09:45Z</published>
    <title>Default contagion risks in Russian interbank market</title>
    <summary>  Systemic risks of default contagion in the Russian interbank market are
investigated. The analysis is based on considering the bow-tie structure of the
weighted oriented graph describing the structure of the interbank loans. A
probabilistic model of interbank contagion explicitly taking into account the
empirical bow-tie structure reflecting functionality of the corresponding nodes
(borrowers, lenders, borrowers and lenders simultaneously), degree
distributions and disassortativity of the interbank network under consideration
based on empirical data is developed. The characteristics of contagion-related
systemic risk calculated with this model are shown to be in agreement with
those of explicit stress tests.
</summary>
    <author>
      <name>A. V. Leonidov</name>
    </author>
    <author>
      <name>E. L. Rumyantsev</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Final version, to appear in Physica A</arxiv:comment>
    <link href="http://arxiv.org/abs/1409.1071v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1409.1071v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.0852v1</id>
    <updated>2014-10-03T14:00:43Z</updated>
    <published>2014-10-03T14:00:43Z</published>
    <title>A General Duality Relation with Applications in Quantitative Risk
  Management</title>
    <summary>  A fundamental problem in risk management is the robust aggregation of
different sources of risk in a situation where little or no data are available
to infer information about their dependencies. A popular approach to solving
this problem is to formulate an optimization problem under which one maximizes
a risk measure over all multivariate distributions that are consistent with the
available data. In several special cases of such models, there exist dual
problems that are easier to solve or approximate, yielding robust bounds on the
aggregated risk. In this chapter we formulate a general optimization problem,
which can be seen as a doubly infinite linear programming problem, and we show
that the associated dual generalizes several well known special cases and
extends to new risk management models we propose.
</summary>
    <author>
      <name>Raphael Hauser</name>
    </author>
    <author>
      <name>Sergey Shahverdyan</name>
    </author>
    <author>
      <name>Paul Embrechts</name>
    </author>
    <link href="http://arxiv.org/abs/1410.0852v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.0852v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.2034v1</id>
    <updated>2014-10-08T09:30:30Z</updated>
    <published>2014-10-08T09:30:30Z</published>
    <title>An initial approach to Risk Management of Funding Costs</title>
    <summary>  In this note we sketch an initial tentative approach to funding costs
analysis and management for contracts with bilateral counterparty risk in a
simplified setting. We depart from the existing literature by analyzing the
issue of funding costs and benefits under the assumption that the associated
risks cannot be hedged properly. We also model the treasury funding spread by
means of a stochastic Weighted Cost of Funding Spread (WCFS) which helps
describing more realistic financing policies of a financial institution. We
elaborate on some limitations in replication-based Funding / Credit Valuation
Adjustments we worked on ourselves in the past, namely CVA, DVA, FVA and
related quantities as generally discussed in the industry. We advocate as a
different possibility, when replication is not possible, the analysis of the
funding profit and loss distribution and explain how long term funding spreads,
wrong way risk and systemic risk are generally overlooked in most of the
current literature on risk measurement of funding costs. As a matter of initial
illustration, we discuss in detail the funding management of interest rate
swaps with bilateral counterparty risk in the simplified setup of our framework
through numerical examples and via a few simplified assumptions.
</summary>
    <author>
      <name>Damiano Brigo</name>
    </author>
    <author>
      <name>Cyril Durand</name>
    </author>
    <link href="http://arxiv.org/abs/1410.2034v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.2034v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62P5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.6841v1</id>
    <updated>2014-10-24T21:28:29Z</updated>
    <published>2014-10-24T21:28:29Z</published>
    <title>qGaussian model of default</title>
    <summary>  We present the qGaussian generalization of the Merton framework, which takes
into account slow fluctuations of the volatility of the firms market value of
financial assets. The minimal version of the model depends on the Tsallis
entropic parameter q and the generalized distance to default. The empirical
foundation and implications of the model are illustrated by the study of 645
North American industrial firms during the financial crisis, 2006 - 2012. All
defaulters in the sample have exceptionally large, corresponding to unusually
fat-tailed unconditional distributions of log-asset-returns. Using Receiver
Operating Characteristic curves, we demonstrate the high forecasting power of
the model in prediction of 1-year defaults. Our study suggests that the level
of complexity of the realized time series, quantified by q, should be taken
into account to improve valuations of default risk.
</summary>
    <author>
      <name>Yuri A. Katz</name>
    </author>
    <link href="http://arxiv.org/abs/1410.6841v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.6841v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1411.1356v1</id>
    <updated>2014-09-25T02:37:10Z</updated>
    <published>2014-09-25T02:37:10Z</published>
    <title>Impact of credit default swaps on financial contagion</title>
    <summary>  It had been believed in the conventional practice that the risk of a bank
going bankrupt is lessened in a straightforward manner by transferring the risk
of loan defaults. But the failure of American International Group in 2008 posed
a more complex aspect of financial contagion. This study presents an extension
of the asset network systemic risk model (ANWSER) to investigate whether credit
default swaps mitigate or intensify the severity of financial contagion. A
protection buyer bank transfers the risk of every possible debtor bank default
to protection seller banks. The empirical distribution of the number of bank
bankruptcies is obtained with the extended model. Systemic capital buffer ratio
is calculated from the distribution. The ratio quantifies the effective loss
absorbency capability of the entire financial system to force back financial
contagion. The key finding is that the leverage ratio is a good estimate of a
systemic capital buffer ratio as the backstop of a financial system. The risk
transfer from small and medium banks to big banks in an interbank network does
not mitigate the severity of financial contagion.
</summary>
    <author>
      <name>Yoshiharu Maeno</name>
    </author>
    <author>
      <name>Kenji Nishiguchi</name>
    </author>
    <author>
      <name>Satoshi Morinaga</name>
    </author>
    <author>
      <name>Hirokazu Matsushima</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/CIFEr.2014.6924067</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/CIFEr.2014.6924067" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">presented at the IEEE Computational Intelligence for Financial
  Engineering and Economics, London, March 2014</arxiv:comment>
    <link href="http://arxiv.org/abs/1411.1356v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1411.1356v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1411.3977v3</id>
    <updated>2015-10-08T09:11:44Z</updated>
    <published>2014-11-14T17:07:10Z</published>
    <title>Multi-curve HJM modelling for risk management</title>
    <summary>  We present a HJM approach to the projection of multiple yield curves
developed to capture the volatility content of historical term structures for
risk management purposes. Since we observe the empirical data at daily
frequency and only for a finite number of time-to-maturity buckets, we propose
a modelling framework which is inherently discrete. In particular, we show how
to approximate the HJM continuous time description of the multi-curve dynamics
by a Vector Autoregressive process of order one. The resulting dynamics lends
itself to a feasible estimation of the model volatility-correlation structure
and market risk-premia. Then, resorting to the Principal Component Analysis we
further simplify the dynamics reducing the number of covariance components.
Applying the constant volatility version of our model on a sample of curves
from the Euro area, we demonstrate its forecasting ability through an
out-of-sample test.
</summary>
    <author>
      <name>Chiara Sabelli</name>
    </author>
    <author>
      <name>Michele Pioppi</name>
    </author>
    <author>
      <name>Luca Sitzia</name>
    </author>
    <author>
      <name>Giacomo Bormetti</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">63 pages, 18 figures, 15 tables; new calibration procedure to
  estimate market risk-premia; new forecasting methodology; added references;
  minor revisions to the text</arxiv:comment>
    <link href="http://arxiv.org/abs/1411.3977v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1411.3977v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1411.7805v1</id>
    <updated>2014-11-28T10:37:32Z</updated>
    <published>2014-11-28T10:37:32Z</published>
    <title>Improving predictability of time series using maximum entropy methods</title>
    <summary>  We discuss how maximum entropy methods may be applied to the reconstruction
of Markov processes underlying empirical time series and compare this approach
to usual frequency sampling. It is shown that, at least in low dimension, there
exists a subset of the space of stochastic matrices for which the MaxEnt method
is more efficient than sampling, in the sense that shorter historical samples
have to be considered to reach the same accuracy. Considering short samples is
of particular interest when modelling smoothly non-stationary processes, for
then it provides, under some conditions, a powerful forecasting tool. The
method is illustrated for a discretized empirical series of exchange rates.
</summary>
    <author>
      <name>Gregor Chliamovitch</name>
    </author>
    <author>
      <name>Alexandre Dupuis</name>
    </author>
    <author>
      <name>Bastien Chopard</name>
    </author>
    <author>
      <name>Anton Golub</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1209/0295-5075/110/10003</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1209/0295-5075/110/10003" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1411.7805v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1411.7805v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.CD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.0064v2</id>
    <updated>2016-07-08T09:03:06Z</updated>
    <published>2014-11-29T03:16:00Z</published>
    <title>Assessing the Basel II Internal Ratings-Based Approach: Empirical
  Evidence from Australia</title>
    <summary>  The Basel II internal ratings-based (IRB) approach to capital adequacy for
credit risk implements an asymptotic single risk factor (ASRF) model.
Measurements from the ASRF model of the prevailing state of Australia's economy
and the level of capitalisation of its banking sector find general agreement
with macroeconomic indicators, financial statistics and external credit
ratings. However, given the range of economic conditions, from mild contraction
to moderate expansion, experienced in Australia since the implementation of
Basel II, we cannot attest to the validity of the model specification of the
IRB approach for its intended purpose of solvency assessment. With the
implementation of Basel II preceding the time when the effect of the financial
crisis of 2007-09 was most acutely felt, our empirical findings offer a
fundamental assessment of the impact of the crisis on the Australian banking
sector. Access to internal bank data collected by the prudential regulator
distinguishes our research from other empirical studies on the IRB approach and
recent crisis.
</summary>
    <author>
      <name>Silvio Tarca</name>
    </author>
    <author>
      <name>Marek Rutkowski</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1108/JFRC-05-2015-0024</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1108/JFRC-05-2015-0024" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Addressed critiques of the Basel II IRB approach in the literature
  and updated figures, as well as general editing to tighten the prose</arxiv:comment>
    <link href="http://arxiv.org/abs/1412.0064v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.0064v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.1183v2</id>
    <updated>2016-07-07T09:34:39Z</updated>
    <published>2014-12-03T04:25:48Z</published>
    <title>Regulatory Capital Modelling for Credit Risk</title>
    <summary>  The Basel II internal ratings-based (IRB) approach to capital adequacy for
credit risk plays an important role in protecting the Australian banking sector
against insolvency. We outline the mathematical foundations of regulatory
capital for credit risk, and extend the model specification of the IRB approach
to a more general setting than the usual Gaussian case. It rests on the
proposition that quantiles of the distribution of conditional expectation of
portfolio percentage loss may be substituted for quantiles of the portfolio
loss distribution. We present a more economical proof of this proposition under
weaker assumptions. Then, constructing a portfolio that is representative of
credit exposures of the Australian banking sector, we measure the rate of
convergence, in terms of number of obligors, of empirical loss distributions to
the asymptotic (infinitely fine-grained) portfolio loss distribution. Moreover,
we evaluate the sensitivity of credit risk capital to dependence structure as
modelled by asset correlations and elliptical copulas. Access to internal bank
data collected by the prudential regulator distinguishes our research from
other empirical studies on the IRB approach.
</summary>
    <author>
      <name>Marek Rutkowski</name>
    </author>
    <author>
      <name>Silvio Tarca</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1142/S021902491550034X</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1142/S021902491550034X" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Updated figures and references to theorems/laws, as well as general
  editing to tighten the prose. arXiv admin note: text overlap with
  arXiv:1412.0064</arxiv:comment>
    <link href="http://arxiv.org/abs/1412.1183v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.1183v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.1679v1</id>
    <updated>2014-12-04T14:36:01Z</updated>
    <published>2014-12-04T14:36:01Z</published>
    <title>Stess-testing the system: Financial shock contagion in the realm of
  uncertainty</title>
    <summary>  This work proposes an augmented variant of DebtRank with uncertainty
intervals as a method to investigate and assess systemic risk in financial
networks, in a context of incomplete data. The algorithm is tested against a
default contagion algorithm on three ensembles of networks with increasing
density, estimated from real-world banking data related to the largest 227 EU15
financial institutions indexed in a stock market. Results suggest that DebtRank
is capable of capturing increasing rates of systemic risk in a more sensitive
and continuous way, thereby acting as an early-warning signal. The paper
proposes three policy instruments based on this approach: the monitoring of
systemic risk over time by applying the augmented DebtRank on time snapshots of
interbank networks, a stress-testing framework able to test the systemic
importance of financial institutions on different shock scenarios, and the
evaluation of distribution of systemic losses in currency value.
</summary>
    <author>
      <name>Stefano Gurciullo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">50 pages, Paper presented as part of the coursework for the PhD
  Transfer Viva</arxiv:comment>
    <link href="http://arxiv.org/abs/1412.1679v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.1679v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B82, 91B74, 91G99" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.4208v3</id>
    <updated>2016-07-08T08:23:33Z</updated>
    <published>2014-12-13T09:18:48Z</published>
    <title>Equilibrium in risk-sharing games</title>
    <summary>  The large majority of risk-sharing transactions involve few agents, each of
whom can heavily influence the structure and the prices of securities. This
paper proposes a game where agents' strategic sets consist of all possible
sharing securities and pricing kernels that are consistent with Arrow-Debreu
sharing rules. First, it is shown that agents' best response problems have
unique solutions. The risk-sharing Nash equilibrium admits a finite-dimensional
characterisation and it is proved to exist for arbitrary number of agents and
be unique in the two-agent game. In equilibrium, agents declare beliefs on
future random outcomes different than their actual probability assessments, and
the risk-sharing securities are endogenously bounded, implying (among other
things) loss of efficiency. In addition, an analysis regarding extremely risk
tolerant agents indicates that they profit more from the Nash risk-sharing
equilibrium as compared to the Arrow-Debreu one.
</summary>
    <author>
      <name>Michail Anthropelos</name>
    </author>
    <author>
      <name>Constantinos Kardaras</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">48 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1412.4208v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.4208v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.7647v1</id>
    <updated>2014-12-24T12:10:11Z</updated>
    <published>2014-12-24T12:10:11Z</published>
    <title>Tail Risk Constraints and Maximum Entropy</title>
    <summary>  In the world of modern financial theory, portfolio construction has
traditionally operated under at least one of two central assumptions: the
constraints are derived from a utility function and/or the multivariate
probability distribution of the underlying asset returns is fully known. In
practice, both the performance criteria and the informational structure are
markedly different: risk-taking agents are mandated to build portfolios by
primarily constraining the tails of the portfolio return to satisfy VaR, stress
testing, or expected shortfall (CVaR) conditions, and are largely ignorant
about the remaining properties of the probability distributions. As an
alternative, we derive the shape of portfolio distributions which have maximum
entropy subject to real-world left-tail constraints and other expectations. Two
consequences are (i) the left-tail constraints are sufficiently powerful to
overide other considerations in the conventional theory, rendering individual
portfolio components of limited relevance; and (ii) the "barbell" payoff
(maximal certainty/low risk on one side, maximum uncertainty on the other)
emerges naturally from this construction.
</summary>
    <author>
      <name>Donald Geman</name>
    </author>
    <author>
      <name>Hélyette Geman</name>
    </author>
    <author>
      <name>Nassim Nicholas Taleb</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Entropy 17 (6), 3724-3737, 2015</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1412.7647v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.7647v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1501.00833v1</id>
    <updated>2015-01-05T12:16:40Z</updated>
    <published>2015-01-05T12:16:40Z</published>
    <title>Signs of dependence and heavy tails in non-life insurance data</title>
    <summary>  In this paper we study data from the yearly reports the four major Swedish
non-life insurers have sent to the Swedish Financial Supervisory Authority
(FSA). We aim at finding marginal distributions of, and dependence between,
losses on the five largest lines of business (LoBs) in order to create models
for Solvency Capital Requirement (SCR) calculation. We try to use data in an
optimal way by sensibly defining an accounting year loss in terms of actuarial
liability predictions, and by pooling observations from several companies when
possible to decrease the uncertainty about the underlying distributions and
their parameters. We find that dependence between LoBs is weaker in our data
than what is assumed in the Solvency II standard formula. We also find
dependence between companies that may affect financial stability, and must be
taken into account when estimating loss distribution parameters. Moreover, we
discuss under what circumstances an insurer is better (or worse) off using an
internal model for SCR calculation instead of the standard formula.
</summary>
    <author>
      <name>Jonas Alm</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1501.00833v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1501.00833v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1501.02007v4</id>
    <updated>2016-05-10T15:22:27Z</updated>
    <published>2015-01-08T23:54:07Z</published>
    <title>Shortfall Deviation Risk: An alternative to risk measurement</title>
    <summary>  We present the Shortfall Deviation Risk (SDR), a risk measure that represents
the expected loss that occurs with certain probability penalized by the
dispersion of results that are worse than such an expectation. SDR combines
Expected Shortfall (ES) and Shortfall Deviation (SD), which we also introduce,
contemplating two fundamental pillars of the risk concept, the probability of
adverse events and the variability of an expectation, and considers extreme
results. We demonstrate that SD is a generalized deviation measure, whereas SDR
is a coherent risk measure. We achieve the dual representation of SDR, and we
discuss issues such as its representation by a weighted ES, acceptance sets,
convexity, continuity and the relationship with stochastic dominance.
Illustrations with real and simulated data allow us to conclude that SDR offers
greater protection in risk measurement compared with VaR and ES, especially in
times of significant turbulence in riskier scenarios.
</summary>
    <author>
      <name>Marcelo Brutti Righi</name>
    </author>
    <author>
      <name>Paulo Sergio Ceretta</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.21314/JOR.2016.349</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.21314/JOR.2016.349" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Risk 19, 81-116, 2016</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1501.02007v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1501.02007v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.MF" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1501.07297v1</id>
    <updated>2015-01-28T22:03:41Z</updated>
    <published>2015-01-28T22:03:41Z</published>
    <title>Multivariate Stop loss Mixed Erlang Reinsurance risk: Aggregation,
  Capital allocation and Default risk</title>
    <summary>  In this paper, we address the aggregation of dependent stop loss reinsurance
risks where the dependence among the ceding insurer(s) risks is governed by the
Sarmanov distribution and each individual risk belongs to the class of Erlang
mixtures. We investigate the effects of the ceding insurer(s) risk dependencies
on the reinsurer risk profile by deriving a closed formula for the distribution
function of the aggregated stop loss reinsurance risk. Furthermore,
diversification effects from aggregating reinsurance risks are examined by
deriving a closed expression for the risk capital needed for the whole
portfolio of the reinsurer and also the allocated risk capital for each
business unit under the TVaR capital allocation principle. Moreover, given the
risk capital that the reinsurer holds, we express the default probability of
the reinsurer analytically. In case the reinsurer is in default, we determine
analytical expressions for the amount of the aggregate reinsured unpaid losses
and the unpaid losses of each reinsured line of business of the ceding
insurer(s). These results are illustrated by numerical examples.
</summary>
    <author>
      <name>Gildas Ratovomirija</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 Pages, 7 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1501.07297v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1501.07297v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="97M30" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.03252v3</id>
    <updated>2016-04-04T09:26:22Z</updated>
    <published>2015-02-11T10:36:02Z</published>
    <title>Diversification, protection of liability holders and regulatory
  arbitrage</title>
    <summary>  Any solvency regime for financial institutions should be aligned with the
fundamental objectives of regulation: protecting liability holders and securing
the stability of the financial system. The first objective leads to consider
surplus-invariant capital adequacy tests, i.e. tests that do not depend on the
surplus of a financial institution. We provide a complete characterization of
closed, convex, surplus-invariant capital adequacy tests that highlights an
inherent tension between surplus-invariance and the desire to give credit for
diversification. The second objective leads to requiring consistency of capital
adequacy tests across jurisdictions. Of particular importance in this respect
are capital adequacy tests that remain invariant under a change of
num\'{e}raire. We establish an intimate link between surplus- and num\'{e}raire
invariant tests.
</summary>
    <author>
      <name>Pablo Koch-Medina</name>
    </author>
    <author>
      <name>Cosimo Munari</name>
    </author>
    <author>
      <name>Mario Sikic</name>
    </author>
    <link href="http://arxiv.org/abs/1502.03252v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.03252v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.02034v1</id>
    <updated>2015-03-06T18:58:42Z</updated>
    <published>2015-03-06T18:58:42Z</published>
    <title>A generic model for spouse's pensions with a view towards the
  calculation of liabilities</title>
    <summary>  We introduce a generic model for spouse's pensions. The generic model allows
for the modeling of various types of spouse's pensions with payments commencing
at the death of the insured. We derive abstract formulas for cashflows and
liabilities corresponding to common types of spouse's pensions. We show how the
standard formulas from the Danish G82 concession can be obtained as a special
case of our generic model. We also derive expressions for liabilities for
spouse's pensions in models more advanced than found in the G82 concession. The
generic nature of our model and results furthermore enable the calculation of
cashflows and liabilities using simple estimates of marital behaviour among a
population.
</summary>
    <author>
      <name>Alexander Sokol</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.insmatheco.2015.09.003</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.insmatheco.2015.09.003" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Insurance: Mathematics and Economics, Vol. 65, pp. 198--207, 2015</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1503.02034v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.02034v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.03180v1</id>
    <updated>2015-03-11T05:18:43Z</updated>
    <published>2015-03-11T05:18:43Z</published>
    <title>Negative Dependence Concept in Copulas and the Marginal Free Herd
  Behavior Index</title>
    <summary>  We provide a set of copulas that can be interpreted as having the negative
extreme dependence. This set of copulas is interesting because it coincides
with countermonotonic copula for a bivariate case, and more importantly, is
shown to be minimal in concordance ordering in the sense that no copula exists
which is strictly smaller than the given copula outside the proposed copula
set. Admitting the absence of the minimum copula in multivariate dimensions
greater than 2, the study of the set of minimal copulas can be important in the
investigation of various optimization problems. To demonstrate the importance
of the proposed copula set, we provide the variance minimization problem of the
aggregated sum with arbitrarily given uniform marginals. As a
financial/actuarial application of these copulas, we define a new herd behavior
index using weighted Spearman's rho, and determine the sharp lower bound of the
index using the proposed set of copulas.
</summary>
    <author>
      <name>Jae Youn Ahn</name>
    </author>
    <link href="http://arxiv.org/abs/1503.03180v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.03180v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.03726v3</id>
    <updated>2016-04-11T15:01:38Z</updated>
    <published>2015-03-12T14:08:28Z</published>
    <title>Bounds for randomly shared risk of heavy-tailed loss factors</title>
    <summary>  For a risk vector $V$, whose components are shared among agents by some
random mechanism, we obtain asymptotic lower and upper bounds for the
individual agents' exposure risk and the aggregated risk in the market. Risk is
measured by Value-at-Risk or Conditional Tail Expectation. We assume Pareto
tails for the components of $V$ and arbitrary dependence structure in a
multivariate regular variation setting. Upper and lower bounds are given by
asymptotically independent and fully dependent components of $V$ with respect
to the tail index $\alpha$ being smaller or larger than 1. Counterexamples,
where for non-linear aggregation functions no bounds are available, complete
the picture.
</summary>
    <author>
      <name>Oliver Kley</name>
    </author>
    <author>
      <name>Claudia Kluppelberg</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s10687-016-0248-2</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s10687-016-0248-2" rel="related"/>
    <link href="http://arxiv.org/abs/1503.03726v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.03726v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="90B15, 91B30, 60E05, 60G70" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.04460v1</id>
    <updated>2015-03-15T18:52:04Z</updated>
    <published>2015-03-15T18:52:04Z</published>
    <title>Optimal risk allocation in a market with non-convex preferences</title>
    <summary>  The aims of this study are twofold. First, we consider an optimal risk
allocation problem with non-convex preferences. By establishing an infimal
representation for distortion risk measures, we give some necessary and
sufficient conditions for the existence of optimal and asymptotic optimal
allocations. We will show that, similar to a market with convex preferences, in
a non-convex framework with distortion risk measures the boundedness of the
optimal risk allocation problem depends only on the preferences. Second, we
consider the same optimal allocation problem by adding a further assumption
that allocations are co-monotone. We characterize the co-monotone optimal risk
allocations within which we prove the "marginal risk allocations" take only the
values zero or one. Remarkably, we can separate the role of the market
preferences and the total risk in our representation.
</summary>
    <author>
      <name>Hirbod Assa</name>
    </author>
    <link href="http://arxiv.org/abs/1503.04460v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.04460v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.05343v1</id>
    <updated>2015-03-18T11:12:36Z</updated>
    <published>2015-03-18T11:12:36Z</published>
    <title>ON Integrated Chance Constraints in ALM for Pension Funds</title>
    <summary>  We discuss the role of integrated chance constraints (ICC) as quantitative
risk constraints in asset and liability management (ALM) for pension funds. We
define two types of ICC: the one period integrated chance constraint (OICC) and
the multiperiod integrated chance constraint (MICC). As their names suggest,
the OICC covers only one period whereas several periods are taken into account
with the MICC. A multistage stochastic linear programming model is therefore
developed for this purpose and a special mention is paid to the modeling of the
MICC.
  Based on a numerical example, we firstly analyse the effects of the OICC and
the MICC on the optimal decisions (asset allocation and contribution rate) of a
pension fund. By definition, the MICC is more restrictive and safer compared to
the OICC. Secondly, we quantify this MICC safety increase. The results show
that although the optimal decisions from the OICC and the MICC differ, the
total costs are very close, showing that the MICC is definitely a better
approach since it is more prudent.
</summary>
    <author>
      <name>Youssouf A. F. Toukourou</name>
    </author>
    <author>
      <name>François Dufresne</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">29 pages, 16 figures, 5 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1503.05343v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.05343v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="90A 90B 90C 91G" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.06317v2</id>
    <updated>2017-02-22T12:31:45Z</updated>
    <published>2015-03-21T15:52:40Z</published>
    <title>Measuring Systemic Risk: Robust Ranking Techniques Approach</title>
    <summary>  In this research, we introduce a robust metric to identify Systemically
Important Financial Institution (SIFI) in a financial network by taking into
account both common idiosyncratic shocks and contagion through counterparty
exposures. We develop an efficient algorithm to rank financial institutions by
formulating a fixed point problem and reducing it to a non-smooth convex
optimization problem. We then study the underlying distribution of the proposed
metric and analyze the performance of the algorithm by using different
financial network structures. Overall, our findings suggest that the level of
interconnection and position of institutions in the financial network are
important elements to measure systemic risk and identify SIFIs. Results show
that increasing the levels of out- and in-degree connections of an institution
can have a diverse impact on its systemic ranking. Additionally, on the
empirical side, we investigate the factors which lead to the identification of
Global Systemic Important Banks (G-SIB) by using a panel dataset of the largest
banks in each country. Our empirical results supports the main findings of the
theoretical model.
</summary>
    <author>
      <name>Amirhossein Sadoghi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">40 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1503.06317v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.06317v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91G99" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.6; G.2.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.08586v2</id>
    <updated>2016-03-26T13:40:50Z</updated>
    <published>2015-03-30T08:27:10Z</published>
    <title>New class of distortion risk measures and their tail asymptotics with
  emphasis on VaR</title>
    <summary>  Distortion risk measures are extensively used in finance and insurance
applications because of their appealing properties. We present three methods to
construct new class of distortion functions and measures. The approach involves
the composting methods, the mixing methods and the approach that based on the
theory of copula. Subadditivity is an important property when aggregating risks
in order to preserve the benefits of diversification. However, Value at risk
(VaR), as the most well-known example of distortion risk measure is not always
globally subadditive, except of elliptically distributed risks. In this paper,
instead of study subadditivity we investigate the tail subadditivity for VaR
and other distortion risk measures. In particular, we demonstrate that VaR is
tail subadditive for the case where the support of risk is bounded. Various
examples are also presented to illustrate the results.
</summary>
    <author>
      <name>Chuancun Yin</name>
    </author>
    <author>
      <name>Dan Zhu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">35 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1503.08586v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.08586v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.02896v1</id>
    <updated>2015-04-11T16:53:43Z</updated>
    <published>2015-04-11T16:53:43Z</published>
    <title>Pricing and Risk Management with High-Dimensional Quasi Monte Carlo and
  Global Sensitivity Analysis</title>
    <summary>  We review and apply Quasi Monte Carlo (QMC) and Global Sensitivity Analysis
(GSA) techniques to pricing and risk management (greeks) of representative
financial instruments of increasing complexity. We compare QMC vs standard
Monte Carlo (MC) results in great detail, using high-dimensional Sobol' low
discrepancy sequences, different discretization methods, and specific analyses
of convergence, performance, speed up, stability, and error optimization for
finite differences greeks. We find that our QMC outperforms MC in most cases,
including the highest-dimensional simulations and greeks calculations, showing
faster and more stable convergence to exact or almost exact results. Using GSA,
we are able to fully explain our findings in terms of reduced effective
dimension of our QMC simulation, allowed in most cases, but not always, by
Brownian bridge discretization. We conclude that, beyond pricing, QMC is a very
promising technique also for computing risk figures, greeks in particular, as
it allows to reduce the computational effort of high-dimensional Monte Carlo
simulations typical of modern risk management.
</summary>
    <author>
      <name>Marco Bianchetti</name>
    </author>
    <author>
      <name>Sergei Kucherenko</name>
    </author>
    <author>
      <name>Stefano Scoleri</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">43 pages, 21 figures, 6 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1504.02896v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.02896v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.CP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65C05" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.04774v2</id>
    <updated>2016-02-01T09:50:46Z</updated>
    <published>2015-04-18T22:57:22Z</published>
    <title>Time-consistency of risk measures with GARCH volatilities and their
  estimation</title>
    <summary>  In this paper we study time-consistent risk measures for returns that are
given by a GARCH(1,1) model. We present a construction of risk measures based
on their static counterparts that overcomes the lack of time-consistency. We
then study in detail our construction for the risk measures Value-at-Risk (VaR)
and Average Value-at-Risk (AVaR). While in the VaR case we can derive an
analytical formula for its time-consistent counterpart, in the AVaR case we
derive lower and upper bounds to its time-consistent version. Furthermore, we
incorporate techniques from Extreme Value Theory (EVT) to allow for a more
tail-geared statistical analysis of the corresponding risk measures. We
conclude with an application of our results to a data set of stock prices.
</summary>
    <author>
      <name>Claudia Klüppelberg</name>
    </author>
    <author>
      <name>Jianing Zhang</name>
    </author>
    <link href="http://arxiv.org/abs/1504.04774v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.04774v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.CP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.05737v1</id>
    <updated>2015-04-22T11:26:03Z</updated>
    <published>2015-04-22T11:26:03Z</published>
    <title>Agent-based mapping of credit risk for sustainable microfinance</title>
    <summary>  Inspired by recent ideas on how the analysis of complex financial risks can
benefit from analogies with independent research areas, we propose an
unorthodox framework for mapping microfinance credit risk---a major obstacle to
the sustainability of lenders outreaching to the poor. Specifically, using the
elements of network theory, we constructed an agent-based model that obeys the
stylised rules of microfinance industry. We found that in a deteriorating
economic environment confounded with adverse selection, a form of latent moral
hazard may cause a regime shift from a high to a low loan repayment
probability. An after-the-fact recovery, when possible, required the economic
environment to improve beyond that which led to the shift in the first place.
These findings suggest a small set of measurable quantities for mapping
microfinance credit risk and, consequently, for balancing the requirements to
reasonably price loans and to operate on a fully self-financed basis. We
illustrate how the proposed mapping works using a 10-year monthly data set from
one of the best-known microfinance representatives, Grameen Bank in Bangladesh.
Finally, we discuss an entirely new perspective for managing microfinance
credit risk based on enticing spontaneous cooperation by building social
capital.
</summary>
    <author>
      <name>Joung-Hun Lee</name>
    </author>
    <author>
      <name>Marko Jusup</name>
    </author>
    <author>
      <name>Boris Podobnik</name>
    </author>
    <author>
      <name>Yoh Iwasa</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1504.05737v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.05737v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.02292v1</id>
    <updated>2015-05-09T16:23:07Z</updated>
    <published>2015-05-09T16:23:07Z</published>
    <title>Wrong-Way Bounds in Counterparty Credit Risk Management</title>
    <summary>  We study the problem of finding the worst-case joint distribution of a set of
risk factors given prescribed multivariate marginals and a nonlinear loss
function. We show that when the risk measure is CVaR, and the distributions are
discretized, the problem can be conveniently solved using linear programming
technique. The method has applications to any situation where marginals are
provided, and bounds need to be determined on total portfolio risk. This arises
in many financial contexts, including pricing and risk management of exotic
options, analysis of structured finance instruments, and aggregation of
portfolio risk across risk types. Applications to counterparty credit risk are
emphasized, and they include assessing wrong-way risk in the credit valuation
adjustment, and counterparty credit risk measurement. Lastly a detailed
application of the algorithm for counterparty risk measurement to a real
portfolio case is also presented in this paper.
</summary>
    <author>
      <name>Amir Memartoluie</name>
    </author>
    <author>
      <name>David Saunders</name>
    </author>
    <author>
      <name>Tony Wirjanto</name>
    </author>
    <link href="http://arxiv.org/abs/1505.02292v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.02292v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.04757v7</id>
    <updated>2017-04-30T11:04:37Z</updated>
    <published>2015-05-18T18:50:52Z</published>
    <title>Actuarial Applications and Estimation of Extended~CreditRisk$^+$</title>
    <summary>  We introduce an additive stochastic mortality model which allows joint
modelling and forecasting of underlying death causes. Parameter families for
mortality trends can be chosen freely. As model settings become high
dimensional, Markov chain Monte Carlo (MCMC) is used for parameter estimation.
We then link our proposed model to an extended version of the credit risk model
CreditRisk$^+$. This allows exact risk aggregation via an efficient numerically
stable Panjer recursion algorithm and provides numerous applications in credit,
life insurance and annuity portfolios to derive P\&amp;L distributions.
Furthermore, the model allows exact (without Monte Carlo simulation error)
calculation of risk measures and their sensitivities with respect to model
parameters for P\&amp;L distributions such as value-at-risk and expected shortfall.
Numerous examples, including an application to partial internal models under
Solvency II, using Austrian and Australian data are shown.
</summary>
    <author>
      <name>Jonas Hirz</name>
    </author>
    <author>
      <name>Uwe Schmock</name>
    </author>
    <author>
      <name>Pavel V. Shevchenko</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">34 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1505.04757v7" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.04757v7" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62P05, 97M30, 91G60" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.05182v1</id>
    <updated>2015-05-19T20:49:47Z</updated>
    <published>2015-05-19T20:49:47Z</published>
    <title>Market Fragility, Systemic Risk, and Ricci Curvature</title>
    <summary>  Measuring systemic risk or fragility of financial systems is a ubiquitous
task of fundamental importance in analyzing market efficiency, portfolio
allocation, and containment of financial contagions. Recent attempts have shown
that representing such systems as a weighted graph characterizing the complex
web of interacting agents over some information flow (e.g., debt, stock
returns, shareholder ownership) may provide certain keen insights. Here, we
show that fragility, or the ability of system to be prone to failures in the
face of random perturbations, is negatively correlated with geometric notion of
Ricci curvature. The key ingredient relating fragility and curvature is
entropy. As a proof of concept, we examine returns from a set of stocks
comprising the S\&amp;P 500 over a 15 year span to show that financial crashes are
more robust compared to normal "business as usual" fragile market behavior -
i.e., Ricci curvature is a "crash hallmark." Perhaps more importantly, this
work lays the foundation of understanding of how to design systems and policy
regulations in a manner that can combat financial instabilities exposed during
the 2007-2008 crisis.
</summary>
    <author>
      <name>Romeil Sandhu</name>
    </author>
    <author>
      <name>Tryphon Georgiou</name>
    </author>
    <author>
      <name>Allen Tannenbaum</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1505.05182v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.05182v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.03564v2</id>
    <updated>2015-06-19T18:27:36Z</updated>
    <published>2015-06-11T06:54:20Z</published>
    <title>Copula based hierarchical risk aggregation - Tree dependent sampling and
  the space of mild tree dependence</title>
    <summary>  The ability to adequately model risks is crucial for insurance companies. The
method of "Copula-based hierarchical risk aggregation" by Arbenz et al. offers
a flexible way in doing so and has attracted much attention recently. We
briefly introduce the aggregation tree model as well as the sampling algorithm
proposed by they authors.
  An important characteristic of the model is that the joint distribution of
all risk is not fully specified unless an additional assumption (known as
"conditional independence assumption") is added. We show that there is
numerical evidence that the sampling algorithm yields an approximation of the
distribution uniquely specified by the conditional independence assumption. We
propose a modified algorithm and provide a proof that under certain conditions
the said distribution is indeed approximated by our algorithm.
  We further determine the space of feasible distributions for a given
aggregation tree model in case we drop the conditional independence assumption.
We study the impact of the input parameters and the tree structure, which
allows conclusions of the way the aggregation tree should be designed.
</summary>
    <author>
      <name>Fabio Derendinger</name>
    </author>
    <link href="http://arxiv.org/abs/1506.03564v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.03564v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.08595v3</id>
    <updated>2017-02-03T14:56:00Z</updated>
    <published>2015-06-29T11:57:55Z</published>
    <title>Central Clearing Valuation Adjustment</title>
    <summary>  This paper develops an XVA (costs) analysis of centrally cleared trading,
parallel to the one that has been developed in the last years for bilateral
transactions. We introduce a dynamic framework that incorporates the sequence
of cash-flows involved in the waterfall of resources of a clearing house. The
total cost of the clearance framework for a clearing member, called CCVA for
central clearing valuation adjustment, is decomposed into a CVA corresponding
to the cost of its losses on the default fund in case of defaults of other
member, an MVA corresponding to the cost of funding its margins and a KVA
corresponding to the cost of the regulatory capital and also of the capital at
risk that the member implicitly provides to the CCP through its default fund
contribution. In the end the structure of the XVA equations for bilateral and
cleared portfolios is similar, but the input data to these equations are not
the same, reflecting different financial network structures. The resulting XVA
numbers differ, but, interestingly enough, they become comparable after scaling
by a suitable netting ratio.
</summary>
    <author>
      <name>Yannick Armenti</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LaMME</arxiv:affiliation>
    </author>
    <author>
      <name>Stéphane Crépey</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LaMME</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/1506.08595v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.08595v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.CP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.01847v2</id>
    <updated>2016-10-13T20:51:42Z</updated>
    <published>2015-07-07T15:39:12Z</published>
    <title>The Effects of Leverage Requirements and Fire Sales on Financial
  Contagion via Asset Liquidation Strategies in Financial Networks</title>
    <summary>  This paper provides a framework for modeling the financial system with
multiple illiquid assets when liquidation of illiquid assets is caused by
failure to meet a leverage requirement. This extends the network model of
Cifuentes, Shin &amp; Ferrucci (2005) which incorporates a single asset with fire
sales and capital adequacy ratio. This also extends the network model of
Feinstein (2015) which incorporates multiple illiquid assets with fire sales
and no leverage ratios. We prove existence of equilibrium clearing payments and
liquidation prices for a known liquidation strategy when leverage requirements
are required. We also prove sufficient conditions for the existence of an
equilibrium liquidation strategy with corresponding clearing payments and
liquidation prices. Finally we calibrate network models to asset and liability
data for 50 banks in the United States from 2007-2014 in order to draw
conclusions on systemic risk as a function of leverage requirements.
</summary>
    <author>
      <name>Zachary Feinstein</name>
    </author>
    <author>
      <name>Fatena El-Masri</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">38 pages, 23 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1507.01847v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.01847v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.04767v1</id>
    <updated>2015-07-16T20:45:22Z</updated>
    <published>2015-07-16T20:45:22Z</published>
    <title>Semi-parametric time series modelling with autocopulas</title>
    <summary>  In this paper we present an application of the use of autocopulas for
modelling financial time series showing serial dependencies that are not
necessarily linear. The approach presented here is semi-parametric in that it
is characterized by a non-parametric autocopula and parametric marginals. One
advantage of using autocopulas is that they provide a general representation of
the auto-dependency of the time series, in particular making it possible to
study the interdependence of values of the series at different extremes
separately. The specific time series that is studied here comes from daily cash
flows involving the product of daily natural gas price and daily temperature
deviations from normal levels. Seasonality is captured by using a time
dependent normal inverse Gaussian (NIG) distribution fitted to the raw values.
</summary>
    <author>
      <name>Antony Ware</name>
    </author>
    <author>
      <name>Ilnaz Asadzadeh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, AMMCS-CAIMS 2015 Congress</arxiv:comment>
    <link href="http://arxiv.org/abs/1507.04767v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.04767v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.05351v4</id>
    <updated>2017-03-23T05:11:55Z</updated>
    <published>2015-07-19T22:45:22Z</published>
    <title>Multivariate Shortfall Risk Allocation and Systemic Risk</title>
    <summary>  The ongoing concern about systemic risk since the outburst of the global
financial crisis has highlighted the need for risk measures at the level of
sets of interconnected financial components, such as portfolios, institutions
or members of clearing houses. The two main issues in systemic risk measurement
are the computation of an overall reserve level and its allocation to the
different components according to their systemic relevance. We develop here a
pragmatic approach to systemic risk measurement and allocation based on
multivariate shortfall risk measures, where acceptable allocations are first
computed and then aggregated so as to minimize costs. We analyze the
sensitivity of the risk allocations to various factors and highlight its
relevance as an indicator of systemic risk. In particular, we study the
interplay between the loss function and the dependence structure of the
components. Moreover, we address the computational aspects of risk allocation.
Finally, we apply this methodology to the allocation of the default fund of a
CCP on real data.
</summary>
    <author>
      <name>Yannick Armenti</name>
    </author>
    <author>
      <name>Stephane Crepey</name>
    </author>
    <author>
      <name>Samuel Drapeau</name>
    </author>
    <author>
      <name>Antonis Papapantoleon</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Code, results and figures can also be consulted at
  https://github.com/yarmenti/MSRA</arxiv:comment>
    <link href="http://arxiv.org/abs/1507.05351v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.05351v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91G, 91B30, 91G60" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.06015v2</id>
    <updated>2016-07-31T19:47:07Z</updated>
    <published>2015-07-21T23:59:56Z</published>
    <title>Risk Quantification in Stochastic Simulation under Input Uncertainty</title>
    <summary>  When simulating a complex stochastic system, the behavior of output response
depends on input parameters estimated from finite real-world data, and the
finiteness of data brings input uncertainty into the system. The quantification
of the impact of input uncertainty on output response has been extensively
studied. Most of the existing literature focuses on providing inferences on the
mean response at the true but unknown input parameter, including point
estimation and confidence interval construction. Risk quantification of mean
response under input uncertainty often plays an important role in system
evaluation and control, because it provides inferences on extreme scenarios of
mean response in all possible input models. To the best of our knowledge, it
has rarely been systematically studied in the literature. In this paper, first
we introduce risk measures of mean response under input uncertainty, and
propose a nested Monte Carlo simulation approach to estimate them. Then we
develop asymptotical properties such as consistency and asymptotic normality
for the proposed nested risk estimators. Finally we study the associated budget
allocation problem for efficient nested risk simulation.
</summary>
    <author>
      <name>Helin Zhu</name>
    </author>
    <author>
      <name>Enlu Zhou</name>
    </author>
    <link href="http://arxiv.org/abs/1507.06015v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.06015v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.02367v2</id>
    <updated>2016-07-04T16:22:06Z</updated>
    <published>2015-08-10T19:28:35Z</published>
    <title>A recursive algorithm for multivariate risk measures and a set-valued
  Bellman's principle</title>
    <summary>  A method for calculating multi-portfolio time consistent multivariate risk
measures in discrete time is presented. Market models for $d$ assets with
transaction costs or illiquidity and possible trading constraints are
considered on a finite probability space. The set of capital requirements at
each time and state is calculated recursively backwards in time along the event
tree. We motivate why the proposed procedure can be seen as a set-valued
Bellman's principle, that might be of independent interest within the growing
field of set optimization. We give conditions under which the backwards
calculation of the sets reduces to solving a sequence of linear, respectively
convex vector optimization problems. Numerical examples are given and include
superhedging under illiquidity, the set-valued entropic risk measure, and the
multi-portfolio time consistent version of the relaxed worst case risk measure
and of the set-valued average value at risk.
</summary>
    <author>
      <name>Zachary Feinstein</name>
    </author>
    <author>
      <name>Birgit Rudloff</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s10898-016-0459-8</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s10898-016-0459-8" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">25 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1508.02367v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.02367v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.CP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B30, 46N10, 26E25, 90C39" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.02824v3</id>
    <updated>2016-08-25T16:03:56Z</updated>
    <published>2015-08-12T06:36:15Z</published>
    <title>Asyptotic Normality for Maximum Likelihood Estimation and Operational
  Risk</title>
    <summary>  Operational risk models commonly employ maximum likelihood estimation (MLE)
to fit loss data to heavy-tailed distributions. Yet several desirable
properties of MLE (e.g. asymptotic normality) are generally valid only for
large sample-sizes, a situation rarely encountered in operational risk. In this
paper, we study how asymptotic normality does--or does not--hold for common
severity distributions in operational risk models. We then apply these results
to evaluate errors caused by failure of asymptotic normality in constructing
confidence intervals around the MLE fitted parameters.
</summary>
    <author>
      <name>Paul Larsen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Split previous arXiv submission into two parts for journal
  submission. A slightly modified version of this paper will appear in the
  Journal of Operational Risk. The second part on stability of OpVar will be
  posted separately</arxiv:comment>
    <link href="http://arxiv.org/abs/1508.02824v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.02824v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1509.00607v1</id>
    <updated>2015-09-02T09:05:51Z</updated>
    <published>2015-09-02T09:05:51Z</published>
    <title>Assessing systemic risk due to fire sales spillover through maximum
  entropy network reconstruction</title>
    <summary>  Assessing systemic risk in financial markets is of great importance but it
often requires data that are unavailable or available at a very low frequency.
For this reason, systemic risk assessment with partial information is
potentially very useful for regulators and other stakeholders. In this paper we
consider systemic risk due to fire sales spillover and portfolio rebalancing by
using the risk metrics defined by Greenwood et al. (2015). By using the Maximum
Entropy principle we propose a method to assess aggregated and single bank's
systemicness and vulnerability and to statistically test for a change in these
variables when only the information on the size of each bank and the
capitalization of the investment assets are available. We prove the
effectiveness of our method on 2001-2013 quarterly data of US banks for which
portfolio composition is available.
</summary>
    <author>
      <name>Domenico Di Gangi</name>
    </author>
    <author>
      <name>Fabrizio Lillo</name>
    </author>
    <author>
      <name>Davide Pirino</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">36 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1509.00607v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1509.00607v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.00616v1</id>
    <updated>2015-10-02T14:51:53Z</updated>
    <published>2015-10-02T14:51:53Z</published>
    <title>Conditional risk measures in a bipartite market structure</title>
    <summary>  In this paper we study the effect of network structure between agents and
objects on measures for systemic risk. We model the influence of sharing large
exogeneous losses to the financial or (re)insuance market by a bipartite graph.
Using Pareto-tailed losses and multivariate regular variation we obtain
asymptotic results for systemic conditional risk measures based on the
Value-at-Risk and the Conditional Tail Expectation. These results allow us to
assess the influence of an individual institution on the systemic or market
risk and vice versa through a collection of conditional systemic risk measures.
For large markets Poisson approximations of the relevant constants are provided
in the example of an insurance market. The example of an underlying homogeneous
random graph is analysed in detail, and the results are illustrated through
simulations.
</summary>
    <author>
      <name>Oliver Kley</name>
    </author>
    <author>
      <name>Claudia Klüppelberg</name>
    </author>
    <author>
      <name>Gesine Reinert</name>
    </author>
    <link href="http://arxiv.org/abs/1510.00616v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.00616v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.01593v1</id>
    <updated>2015-10-06T14:35:30Z</updated>
    <published>2015-10-06T14:35:30Z</published>
    <title>Efficient Randomized Quasi-Monte Carlo Methods For Portfolio Market Risk</title>
    <summary>  We consider the problem of simulating loss probabilities and conditional
excesses for linear asset portfolios under the t-copula model. Although in the
literature on market risk management there are papers proposing efficient
variance reduction methods for Monte Carlo simulation of portfolio market risk,
there is no paper discussing combining the randomized quasi-Monte Carlo method
with variance reduction techniques. In this paper, we combine the randomized
quasi-Monte Carlo method with importance sampling and stratified importance
sampling. Numerical results for realistic portfolio examples suggest that
replacing pseudorandom numbers (Monte Carlo) with quasi-random sequences
(quasi-Monte Carlo) in the simulations increases the robustness of the
estimates once we reduce the effective dimension and the non-smoothness of the
integrands.
</summary>
    <author>
      <name>Halis Sak</name>
    </author>
    <author>
      <name>İsmail Başoğlu</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.insmatheco.2017.07.001</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.insmatheco.2017.07.001" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1510.01593v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.01593v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.04943v1</id>
    <updated>2015-10-16T16:57:13Z</updated>
    <published>2015-10-16T16:57:13Z</published>
    <title>Portfolio Optimization under Expected Shortfall: Contour Maps of
  Estimation Error</title>
    <summary>  The contour maps of the error of historical resp. parametric estimates for
large random portfolios optimized under the risk measure Expected Shortfall
(ES) are constructed. Similar maps for the sensitivity of the portfolio weights
to small changes in the returns as well as the VaR of the ES-optimized
portfolio are also presented, along with results for the distribution of
portfolio weights over the random samples and for the out-of-sample and
in-the-sample estimates for ES. The contour maps allow one to quantitatively
determine the sample size (the length of the time series) required by the
optimization for a given number of different assets in the portfolio, at a
given confidence level and a given level of relative estimation error. The
necessary sample sizes invariably turn out to be unrealistically large for any
reasonable choice of the number of assets and the confidence level. These
results are obtained via analytical calculations based on methods borrowed from
the statistical physics of random systems, supported by numerical simulations.
</summary>
    <author>
      <name>Fabio Caccioli</name>
    </author>
    <author>
      <name>Imre Kondor</name>
    </author>
    <author>
      <name>Gábor Papp</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">47 pages, 14 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1510.04943v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.04943v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.07030v2</id>
    <updated>2016-06-04T22:24:41Z</updated>
    <published>2015-10-23T19:52:33Z</published>
    <title>Law invariant risk measures and information divergences</title>
    <summary>  A one-to-one correspondence is drawn between law invariant risk measures and
divergences, which we define as functionals of pairs of probability measures on
arbitrary standard Borel spaces satisfying a few natural properties.
Divergences include many classical information divergence measures, such as
relative entropy and $f$-divergences. Several properties of divergence and
their duality with law invariant risk measures are developed, most notably
relating their chain rules or additivity properties with certain notions of
time consistency for dynamic law invariant risk measures known as acceptance
and rejection consistency. These properties are linked also to a peculiar
property of the acceptance sets on the level of distributions, analogous to
results of Weber on weak acceptance and rejection consistency. Finally, the
examples of shortfall risk measures and optimized certainty equivalents are
discussed in some detail, and it is shown that the relative entropy is
essentially the only divergence satisfying the chain rule.
</summary>
    <author>
      <name>Daniel Lacker</name>
    </author>
    <link href="http://arxiv.org/abs/1510.07030v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.07030v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.07033v2</id>
    <updated>2015-10-27T14:55:09Z</updated>
    <published>2015-10-23T19:58:27Z</published>
    <title>Liquidity, risk measures, and concentration of measure</title>
    <summary>  Expanding on techniques of concentration of measure, we develop a
quantitative framework for modeling liquidity risk using convex risk measures.
The fundamental objects of study are curves of the form $(\rho(\lambda
X))_{\lambda \ge 0}$, where $\rho$ is a convex risk measure and $X$ a random
variable, and we call such a curve a \emph{liquidity risk profile}. The shape
of a liquidity risk profile is intimately linked with the tail behavior of the
underlying $X$ for some notable classes of risk measures, namely shortfall risk
measures. We exploit this link to systematically bound liquidity risk profiles
from above by other real functions $\gamma$, deriving tractable necessary and
sufficient conditions for \emph{concentration inequalities} of the form
$\rho(\lambda X) \le \gamma(\lambda)$, for all $\lambda \ge 0$. These
concentration inequalities admit useful dual representations related to
transport inequalities, and this leads to efficient uniform bounds for
liquidity risk profiles for large classes of $X$. On the other hand, some
modest new mathematical results emerge from this analysis, including a new
characterization of some classical transport-entropy inequalities. Lastly, the
analysis is deepened by means of a surprising connection between time
consistency properties of law invariant risk measures and the tensorization of
concentration inequalities.
</summary>
    <author>
      <name>Daniel Lacker</name>
    </author>
    <link href="http://arxiv.org/abs/1510.07033v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.07033v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.08068v3</id>
    <updated>2017-09-05T20:24:06Z</updated>
    <published>2015-11-25T14:15:06Z</published>
    <title>The organization of the interbank network and how ECB unconventional
  measures affected the e-MID overnight market</title>
    <summary>  The topological properties of interbank networks have been discussed widely
in the literature mainly because of their relevance for systemic risk. Here we
propose to use the Stochastic Block Model to investigate and perform a model
selection among several possible two block organizations of the network: these
include bipartite, core-periphery, and modular structures. We apply our method
to the e-MID interbank market in the period 2010-2014 and we show that in
normal conditions the most likely network organization is a bipartite
structure. In exceptional conditions, such as after LTRO, one of the most
important unconventional measures by ECB at the beginning of 2012, the most
likely structure becomes a random one and only in 2014 the e-MID market went
back to a normal bipartite organization. By investigating the strategy of
individual banks, we explore possible explanations and we show that the
disappearance of many lending banks and the strategy switch of a very small set
of banks from borrower to lender is likely at the origin of this structural
change.
</summary>
    <author>
      <name>Paolo Barucca</name>
    </author>
    <author>
      <name>Fabrizio Lillo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">33 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1511.08068v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.08068v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.MF" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.08666v1</id>
    <updated>2015-11-27T13:37:02Z</updated>
    <published>2015-11-27T13:37:02Z</published>
    <title>Singular Problems for Integro-Differential Equations in Dynamic
  Insurance Models</title>
    <summary>  A second order linear integro-differential equation with Volterra integral
operator and strong singularities at the endpoints (zero and infinity) is
considered. Under limit conditions at the singular points, and some natural
assumptions, the problem is a singular initial problem with limit normalizing
conditions at infinity. An existence and uniqueness theorem is proved and
asymptotic representations of the solution are given. A numerical algorithm for
evaluating the solution is proposed, calculations and their interpretation are
discussed. The main singular problem under study describes the survival
(non-ruin) probability of an insurance company on infinite time interval (as a
function of initial surplus) in the Cramer-Lundberg dynamic insurance model
with an exponential claim size distribution and certain company's strategy at
the financial market assuming investment of a fixed part of the surplus
(capital) into risky assets (shares) and the rest of it into a risk free asset
(bank deposit). Accompanying "degenerate" problems are also considered that
have an independent meaning in risk theory
</summary>
    <author>
      <name>Tatiana Belkina</name>
    </author>
    <author>
      <name>Nadezhda Konyukhova</name>
    </author>
    <author>
      <name>Sergey Kurochkin</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-1-4614-7333-6_3</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-1-4614-7333-6_3" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1511.08666v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.08666v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B30, 34K06" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1512.03641v1</id>
    <updated>2015-12-11T13:58:43Z</updated>
    <published>2015-12-11T13:58:43Z</published>
    <title>Time-consistency of cash-subadditive risk measures</title>
    <summary>  The main goal of this paper is to investigate under which conditions
cash-subadditive convex dynamic risk measures are time-consistent. Proceeding
as in Detlefsen and Scandolo \cite{detlef-scandolo} and inspired by their
result, we give a dual representation of dynamic cash-subadditive convex risk
measures (that can also be seen as particular case of the dual quasiconvex
representation). The main result of the paper consists in providing, in the
cash-subadditive case, a sufficient condition for strong time-consistency (or
recursivity) in terms of a generalized cocycle condition. On one hand, our
result can be seen as an extension to cash-subadditive convex dynamic risk
measures of Theorem 2.5 in Bion-Nadal \cite{bion-nadal-FS}; on the other hand,
it is weaker since strong time-consistency is not fully characterized. Finally,
we exploit the relation between different notions of time-consistency.
</summary>
    <author>
      <name>Elisa Mastrogiacomo</name>
    </author>
    <author>
      <name>Emanuela Rosazza Gianin</name>
    </author>
    <link href="http://arxiv.org/abs/1512.03641v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1512.03641v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.MF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="60G44, 91B30, 91G30, 46A20" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1512.06247v1</id>
    <updated>2015-12-19T13:21:44Z</updated>
    <published>2015-12-19T13:21:44Z</published>
    <title>Which measure for PFE? The Risk Appetite Measure, A</title>
    <summary>  Potential Future Exposure (PFE) is a standard risk metric for managing
business unit counterparty credit risk but there is debate on how it should be
calculated. The debate has been whether to use one of many historical
("physical") measures (one per calibration setup), or one of many risk-neutral
measures (one per numeraire). However, we argue that limits should be based on
the bank's own risk appetite provided that this is consistent with regulatory
backtesting and that whichever measure is used it should behave (in a sense
made precise) like a historical measure. Backtesting is only required by
regulators for banks with IMM approval but we expect that similar methods are
part of limit maintenance generally. We provide three methods for computing the
bank price of risk from readily available business unit data, i.e. business
unit budgets (rate of return) and limits (e.g. exposure percentiles). Hence we
define and propose a Risk Appetite Measure, A, for PFE and suggest that this is
uniquely consistent with the bank's Risk Appetite Framework as required by
sound governance.
</summary>
    <author>
      <name>Chris Kenyon</name>
    </author>
    <author>
      <name>Andrew Green</name>
    </author>
    <author>
      <name>Mourad Berrahoui</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1512.06247v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1512.06247v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.MF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B25, 91B16, 91G50, 91G20, 91G10, 91G40, 91B30, 91B32, 91B84" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.02156v1</id>
    <updated>2016-01-09T20:53:39Z</updated>
    <published>2016-01-09T20:53:39Z</published>
    <title>Systemic Risk Management in Financial Networks with Credit Default Swaps</title>
    <summary>  We study insolvency cascades in an interbank system when banks are allowed to
insure their loans with credit default swaps (CDS) sold by other banks. We show
that, by properly shifting financial exposures from one institution to another,
a CDS market can be designed to rewire the network of interbank exposures in a
way that makes it more resilient to insolvency cascades. A regulator can use
information about the topology of the interbank network to devise a systemic
insurance surcharge that is added to the CDS spread. CDS contracts are thus
effectively penalized according to how much they contribute to increasing
systemic risk. CDS contracts that decrease systemic risk remain untaxed. We
simulate this regulated CDS market using an agent-based model (CRISIS
macro-financial model) and we demonstrate that it leads to an interbank system
that is more resilient to insolvency cascades.
</summary>
    <author>
      <name>Matt V. Leduc</name>
    </author>
    <author>
      <name>Sebastian Poledna</name>
    </author>
    <author>
      <name>Stefan Thurner</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, 9 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1601.02156v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.02156v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.03015v1</id>
    <updated>2016-01-12T20:01:39Z</updated>
    <published>2016-01-12T20:01:39Z</published>
    <title>Credit risk: Taking fluctuating asset correlations into account</title>
    <summary>  In structural credit risk models, default events and the ensuing losses are
both derived from the asset values at maturity. Hence it is of utmost
importance to choose a distribution for these asset values which is in
accordance with empirical data. At the same time, it is desirable to still
preserve some analytical tractability. We achieve both goals by putting forward
an ensemble approach for the asset correlations. Consistently with the data, we
view them as fluctuating quantities, for which we may choose the average
correlation as homogeneous. Thereby we can reduce the number of parameters to
two, the average correlation between assets and the strength of the
fluctuations around this average value. Yet, the resulting asset value
distribution describes the empirical data well. This allows us to derive the
distribution of credit portfolio losses. With Monte-Carlo simulations for the
Value at Risk and Expected Tail Loss we validate the assumptions of our
approach and demonstrate the necessity of taking fluctuating correlations into
account.
</summary>
    <author>
      <name>Thilo A. Schmitt</name>
    </author>
    <author>
      <name>Rudi Schäfer</name>
    </author>
    <author>
      <name>Thomas Guhr</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">appears in Journal of Credit Risk, Volume 11, Number 3, 2015</arxiv:comment>
    <link href="http://arxiv.org/abs/1601.03015v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.03015v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.04351v1</id>
    <updated>2016-01-17T21:20:56Z</updated>
    <published>2016-01-17T21:20:56Z</published>
    <title>On bivariate lifetime modelling in life insurance applications</title>
    <summary>  Insurance and annuity products covering several lives require the modelling
of the joint distribution of future lifetimes. In the interest of simplifying
calculations, it is common in practice to assume that the future lifetimes
among a group of people are independent. However, extensive research over the
past decades suggests otherwise. In this paper, a copula approach is used to
model the dependence between lifetimes within a married couple \eH{using data
from a large Canadian insurance company}. As a novelty, the age difference and
the \eH{gender} of the elder partner are introduced as an argument of the
dependence parameter. \green{Maximum likelihood techniques are} thus
implemented for the parameter estimation. Not only do the results make clear
that the correlation decreases with age difference, but also the dependence
between the lifetimes is higher when husband is older than wife. A
goodness-of-fit procedure is applied in order to assess the validity of the
model. Finally, considering several products available on the life insurance
market, the paper concludes with practical illustrations.
</summary>
    <author>
      <name>François Dufresne</name>
    </author>
    <author>
      <name>Enkelejd Hashorva</name>
    </author>
    <author>
      <name>Gildas Ratovomirija</name>
    </author>
    <author>
      <name>Youssouf Toukourou</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">22 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1601.04351v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.04351v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62F, 62G, 62H, 62M, 62N, 62P" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.04557v4</id>
    <updated>2016-11-25T13:32:13Z</updated>
    <published>2016-01-18T15:05:45Z</published>
    <title>Crunching Mortality and Life Insurance Portfolios with extended
  CreditRisk+</title>
    <summary>  Using an extended version of the credit risk model CreditRisk+, we develop a
flexible framework with numerous applications amongst which we find stochastic
mortality modelling, forecasting of death causes as well as profit and loss
modelling of life insurance and annuity portfolios which can be used in
(partial) internal models under Solvency II. Yet, there exists a fast and
numerically stable algorithm to derive loss distributions exactly, even for
large portfolios. We provide various estimation procedures based on publicly
available data. Compared to the Lee-Carter model, we have a more flexible
framework, get tighter bounds and can directly extract several sources of
uncertainty. Straight-forward model validation techniques are available.
</summary>
    <author>
      <name>Jonas Hirz</name>
    </author>
    <author>
      <name>Uwe Schmock</name>
    </author>
    <author>
      <name>Pavel V. Shevchenko</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, 7 figures, 3 tables. arXiv admin note: text overlap with
  arXiv:1505.04757</arxiv:comment>
    <link href="http://arxiv.org/abs/1601.04557v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.04557v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.06204v1</id>
    <updated>2016-01-22T23:27:13Z</updated>
    <published>2016-01-22T23:27:13Z</published>
    <title>RiskRank: Measuring interconnected risk</title>
    <summary>  This paper proposes RiskRank as a joint measure of cyclical and
cross-sectional systemic risk. RiskRank is a general-purpose aggregation
operator that concurrently accounts for risk levels for individual entities and
their interconnectedness. The measure relies on the decomposition of systemic
risk into sub-components that are in turn assessed using a set of risk measures
and their relationships. For this purpose, motivated by the development of the
Choquet integral, we employ the RiskRank function to aggregate risk measures,
allowing for the integration of the interrelation of different factors in the
aggregation process. The use of RiskRank is illustrated through a real-world
case in a European setting, in which we show that it performs well in
out-of-sample analysis. In the example, we provide an estimation of systemic
risk from country-level risk and cross-border linkages.
</summary>
    <author>
      <name>József Mezei</name>
    </author>
    <author>
      <name>Peter Sarlin</name>
    </author>
    <link href="http://arxiv.org/abs/1601.06204v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.06204v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.CP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.MF" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1602.03505v1</id>
    <updated>2016-02-10T20:29:15Z</updated>
    <published>2016-02-10T20:29:15Z</published>
    <title>Basel III capital surcharges for G-SIBs fail to control systemic risk
  and can cause pro-cyclical side effects</title>
    <summary>  In addition to constraining bilateral exposures of financial institutions,
there are essentially two options for future financial regulation of systemic
risk (SR): First, financial regulation could attempt to reduce the financial
fragility of global or domestic systemically important financial institutions
(G-SIBs or D-SIBs), as for instance proposed in Basel III. Second, future
financial regulation could attempt strengthening the financial system as a
whole. This can be achieved by re-shaping the topology of financial networks.
We use an agent-based model (ABM) of a financial system and the real economy to
study and compare the consequences of these two options. By conducting three
"computer experiments" with the ABM we find that re-shaping financial networks
is more effective and efficient than reducing leverage. Capital surcharges for
G-SIBs can reduce SR, but must be larger than those specified in Basel III in
order to have a measurable impact. This can cause a loss of efficiency. Basel
III capital surcharges for G-SIBs can have pro-cyclical side effects.
</summary>
    <author>
      <name>Sebastian Poledna</name>
    </author>
    <author>
      <name>Olaf Bochmann</name>
    </author>
    <author>
      <name>Stefan Thurner</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 3 figures. arXiv admin note: text overlap with
  arXiv:1401.8026</arxiv:comment>
    <link href="http://arxiv.org/abs/1602.03505v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1602.03505v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1602.05477v4</id>
    <updated>2017-08-18T09:57:54Z</updated>
    <published>2016-02-17T16:35:23Z</published>
    <title>Comonotonic risk measures in a world without risk-free assets</title>
    <summary>  We study comonotonicity of risk measures in terms of the primitives of the
theory: acceptance sets and eligible assets. We show that comonotonicity cannot
be characterized by the properties of the acceptance set alone and heavily
depends on the choice of the eligible asset. In fact, in many important cases,
comonotonicity is only compatible with risk-free eligible assets. The
incompatibility with risky eligible assets is systematic whenever the
acceptability criterion is based on Value at Risk or any convex distortion risk
measures such as Expected Shortfall. These findings show the limitations of the
concept of comonotonicity in a world without risk-free assets and raise
questions about the meaning and the role of comonotonicity within a capital
adequacy framework. We also point out some potential traps when using
comonotonicity for "discounted" capital positions.
</summary>
    <author>
      <name>Pablo Koch-Medina</name>
    </author>
    <author>
      <name>Cosimo Munari</name>
    </author>
    <author>
      <name>Gregor Svindland</name>
    </author>
    <link href="http://arxiv.org/abs/1602.05477v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1602.05477v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1602.05883v2</id>
    <updated>2017-02-25T12:25:22Z</updated>
    <published>2016-02-18T17:33:53Z</published>
    <title>Pathways towards instability in financial networks</title>
    <summary>  Following the financial crisis of 2007-2008, a deep analogy between the
origins of instability in financial systems and complex ecosystems has been
pointed out: in both cases, topological features of network structures
influence how easily distress can spread within the system. However, in
financial network models, the details of how financial institutions interact
typically play a decisive role, and a general understanding of precisely how
network topology creates instability remains lacking. Here we show how
processes that are widely believed to stabilise the financial system, i.e.
market integration and diversification, can actually drive it towards
instability, as they contribute to create cyclical structures which tend to
amplify financial distress, thereby undermining systemic stability and making
large crises more likely. This result holds irrespective of the details of how
institutions interact, showing that policy-relevant analysis of the factors
affecting financial stability can be carried out while abstracting away from
such details.
</summary>
    <author>
      <name>Marco Bardoscia</name>
    </author>
    <author>
      <name>Stefano Battiston</name>
    </author>
    <author>
      <name>Fabio Caccioli</name>
    </author>
    <author>
      <name>Guido Caldarelli</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1038/ncomms14416</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1038/ncomms14416" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 3 figures. Supplementary Material: 12 pages, 5 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Nature Communications 8, 14416 (2017)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1602.05883v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1602.05883v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1602.07599v4</id>
    <updated>2017-06-02T14:17:58Z</updated>
    <published>2016-02-24T17:06:25Z</published>
    <title>Backtesting Lambda Value at Risk</title>
    <summary>  A new risk measure, the lambda value at risk (Lambda VaR), has been recently
proposed from a theoretical point of view as a generalization of the value at
risk (VaR). The Lambda VaR appears attractive for its potential ability to
solve several problems of the VaR. In this paper we propose three nonparametric
backtesting methodologies for the Lambda VaR which exploit different features.
Two of these tests directly assess the correctness of the level of coverage
predicted by the model. One of these tests is bilateral and provides an
asymptotic result. A third test assess the accuracy of the Lambda VaR that
depends on the choice of the P&amp;L distribution. However, this test requires the
storage of more information. Finally, we perform a backtesting exercise and we
compare our results with the ones from Hitaj and Peri (2015)
</summary>
    <author>
      <name>Jacopo Corbetta</name>
    </author>
    <author>
      <name>Ilaria Peri</name>
    </author>
    <link href="http://arxiv.org/abs/1602.07599v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1602.07599v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91G70" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.00568v1</id>
    <updated>2016-03-02T03:46:19Z</updated>
    <published>2016-03-02T03:46:19Z</published>
    <title>The Value of A Statistical Life in Absence of Panel Data: What can we
  do?</title>
    <summary>  In this paper I show how reliable estimates of the Value of a Statistical
Life (VSL) can be obtained using cross sectional data using Garen's
instrumental variable (IV) approach. The increase in the range confidence
intervals due to the IV setup can be reduced by a factor of 3 by using a proxy
to risk attitude. In order state the "precision" of the cross sectional VSL
estimates I estimate the VSL using Chilean panel data and use them as benchmark
for different cross sectional specifications. The use of the proxy eliminates
need for using hard-to-find instruments for the job risk level and narrows the
confidence intervals for the workers in the Chilean labor market for the year
2009.
</summary>
    <author>
      <name>Andrés Riquelme</name>
    </author>
    <author>
      <name>Marcela Parada</name>
    </author>
    <link href="http://arxiv.org/abs/1603.00568v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.00568v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.01041v1</id>
    <updated>2016-03-03T10:11:29Z</updated>
    <published>2016-03-03T10:11:29Z</published>
    <title>Estimating Quantile Families of Loss Distributions for Non-Life
  Insurance Modelling via L-moments</title>
    <summary>  This paper discusses different classes of loss models in non-life insurance
settings. It then overviews the class Tukey transform loss models that have not
yet been widely considered in non-life insurance modelling, but offer
opportunities to produce flexible skewness and kurtosis features often required
in loss modelling. In addition, these loss models admit explicit quantile
specifications which make them directly relevant for quantile based risk
measure calculations. We detail various parameterizations and sub-families of
the Tukey transform based models, such as the g-and-h, g-and-k and g-and-j
models, including their properties of relevance to loss modelling.
  One of the challenges with such models is to perform robust estimation for
the loss model parameters that will be amenable to practitioners when fitting
such models. In this paper we develop a novel, efficient and robust estimation
procedure for estimation of model parameters in this family Tukey transform
models, based on L-moments. It is shown to be more robust and efficient than
current state of the art methods of estimation for such families of loss models
and is simple to implement for practical purposes.
</summary>
    <author>
      <name>Gareth W. Peters</name>
    </author>
    <author>
      <name>Wilson Y. Chen</name>
    </author>
    <author>
      <name>Richard H. Gerlach</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">42 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1603.01041v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.01041v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.05373v2</id>
    <updated>2016-05-08T01:49:25Z</updated>
    <published>2016-03-17T06:58:26Z</published>
    <title>Sharp convex bounds on the aggregate sums--An alternative proof</title>
    <summary>  It is well known that a random vector with given marginal distributions is
comonotonic if and only if it has the largest sum with respect to the convex
order [ Kaas, Dhaene, Vyncke, Goovaerts, Denuit (2002), A simple geometric
proof that comonotonic risks have the convex-largest sum, ASTIN Bulletin 32,
71-80. Cheung (2010), Characterizing a comonotonic random vector by the
distribution of the sum of its components, Insurance: Mathematics and Economics
47(2), 130-136] and that a random vector with given marginal distributions is
mutually exclusive if and only if it has the minimal convex sum [Cheung and Lo
(2014), Characterizing mutual exclusivity as the strongest negative
multivariate dependence structure, Insurance: Mathematics and Economics 55,
180-190]. In this note, we give a new proof of this two results using the
theories of distortion risk measure and expected utility.
</summary>
    <author>
      <name>Chuancun Yin</name>
    </author>
    <author>
      <name>Dan Zhu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1603.05373v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.05373v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.09491v2</id>
    <updated>2017-02-06T10:42:26Z</updated>
    <published>2016-03-31T08:51:15Z</published>
    <title>On the properties of the Lambda value at risk: robustness, elicitability
  and consistency</title>
    <summary>  Recently, financial industry and regulators have enhanced the debate on the
good properties of a risk measure. A fundamental issue is the evaluation of the
quality of a risk estimation. On the one hand, a backtesting procedure is
desirable for assessing the accuracy of such an estimation and this can be
naturally achieved by elicitable risk measures. For the same objective, an
alternative approach has been introduced by Davis (2016) through the so-called
consistency property. On the other hand, a risk estimation should be less
sensitive with respect to small changes in the available data set and exhibit
qualitative robustness. A new risk measure, the Lambda value at risk (Lambda
VaR), has been recently proposed by Frittelli et al. (2014), as a
generalization of VaR with the ability to discriminate the risk among P&amp;L
distributions with different tail behaviour. In this article, we show that
Lambda VaR also satisfies the properties of robustness, elicitability and
consistency under some conditions.
</summary>
    <author>
      <name>Matteo Burzoni</name>
    </author>
    <author>
      <name>Ilaria Peri</name>
    </author>
    <author>
      <name>Chiara Maria Ruffo</name>
    </author>
    <link href="http://arxiv.org/abs/1603.09491v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.09491v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.06629v1</id>
    <updated>2016-04-22T12:39:36Z</updated>
    <published>2016-04-22T12:39:36Z</published>
    <title>Entangling credit and funding shocks in interbank markets</title>
    <summary>  Credit and liquidity risks represent main channels of financial contagion for
interbank lending markets. On one hand, banks face potential losses whenever
their counterparties are under distress and thus unable to fulfill their
obligations. On the other hand, solvency constraints may force banks to recover
lost fundings by selling their illiquid assets, resulting in effective losses
in the presence of fire sales - that is, when funding shortcomings are
widespread over the market. Because of the complex structure of the network of
interbank exposures, these losses reverberate among banks and eventually get
amplified, with potentially catastrophic consequences for the whole financial
system. Building on Debt Rank [Battiston et al., 2012], in this work we define
a systemic risk metric that estimates the potential amplification of losses in
interbank markets accounting for both credit and liquidity contagion channels:
the Debt-Solvency Rank. We implement this framework on a dataset of 183
European banks that were publicly traded between 2004 and 2013, showing indeed
that liquidity spillovers substantially increase systemic risk, and thus cannot
be neglected in stress-test scenarios. We also provide additional evidence that
the interbank market was extremely fragile up to the 2008 financial crisis,
becoming slightly more robust only afterwards.
</summary>
    <author>
      <name>Giulio Cimini</name>
    </author>
    <author>
      <name>Matteo Serri</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1371/journal.pone.0161642</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1371/journal.pone.0161642" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">PLoS ONE 11(8): e0161642 (2016)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1604.06629v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.06629v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.05164v2</id>
    <updated>2016-07-27T12:45:25Z</updated>
    <published>2016-06-16T12:45:11Z</published>
    <title>Network Valuation in Financial Systems</title>
    <summary>  We introduce a network valuation model (hereafter NEVA) for the ex-ante
valuation of claims among financial institutions connected in a network of
liabilities. Similar to previous work, the new framework allows to endogenously
determine the recovery rate on all claims upon the default of some
institutions. In addition, it also allows to account for ex-ante uncertainty on
the asset values, in particular the one arising when the valuation is carried
out at some time before the maturity of the claims. The framework encompasses
as special cases both the ex-post approaches of Eisenberg and Noe and its
previous extensions, as well as the ex-ante approaches, in the sense that each
of these models can be recovered exactly for special values of the parameters.
We characterize the existence and uniqueness of the solutions of the valuation
problem under general conditions on how the value of each claim depends on the
equity of the counterparty. Further, we define an algorithm to carry out the
network valuation and we provide sufficient conditions for convergence to the
maximal solution.
</summary>
    <author>
      <name>Paolo Barucca</name>
    </author>
    <author>
      <name>Marco Bardoscia</name>
    </author>
    <author>
      <name>Fabio Caccioli</name>
    </author>
    <author>
      <name>Marco D'Errico</name>
    </author>
    <author>
      <name>Gabriele Visentin</name>
    </author>
    <author>
      <name>Stefano Battiston</name>
    </author>
    <author>
      <name>Guido Caldarelli</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">26 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1606.05164v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.05164v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.06829v1</id>
    <updated>2016-06-22T07:00:30Z</updated>
    <published>2016-06-22T07:00:30Z</published>
    <title>Brexit or Bremain ? Evidence from bubble analysis</title>
    <summary>  We applied the Johansen-Ledoit-Sornette (JLS) model to detect possible
bubbles and crashes related to the Brexit/Bremain referendum scheduled for 23rd
June 2016. Our implementation includes an enhanced model calibration using
Genetic Algorithms. We selected a few historical financial series sensitive to
the Brexit/Bremain scenario, representative of multiple asset classes. We found
that equity and currency asset classes show no bubble signals, while rates,
credit and real estate show super-exponential behaviour and instabilities
typical of bubble regime. Our study suggests that, under the JLS model, equity
and currency markets do not expect crashes or sharp rises following the
referendum results. Instead, rates and credit markets consider the referendum a
risky event, expecting either a Bremain scenario or a Brexit scenario
edulcorated by central banks intervention. In the case of real estate, a crash
is expected, but its relationship with the referendum results is unclear.
</summary>
    <author>
      <name>Marco Bianchetti</name>
    </author>
    <author>
      <name>Davide Galli</name>
    </author>
    <author>
      <name>Camilla Ricci</name>
    </author>
    <author>
      <name>Angelo Salvatori</name>
    </author>
    <author>
      <name>Marco Scaringi</name>
    </author>
    <link href="http://arxiv.org/abs/1606.06829v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.06829v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.CP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.00756v1</id>
    <updated>2016-07-04T07:33:10Z</updated>
    <published>2016-07-04T07:33:10Z</published>
    <title>Comments on the BCBS proposal for a New Standardized Approach for
  Operational Risk</title>
    <summary>  On March 4th 2016 the Basel Committee on Banking Supervision published a
consultative document where a new methodology, called the Standardized
Measurement Approach (SMA), is introduced for computing Operational Risk
regulatory capital for banks. In this note, the behavior of the SMA is studied
under a variety of hypothetical and realistic conditions, showing that the
simplicity of the new approach is very costly on other aspects: we find that
the SMA does not respond appropriately to changes in the risk profile of a
bank, nor is it capable of differentiating among the range of possible risk
profiles across banks; that SMA capital results generally appear to be more
variable across banks than the previous AMA option of fitting the loss data;
that the SMA can result in banks over- or under-insuring against operational
risks relative to previous AMA standards. Finally, we argue that the SMA is not
only retrograde in terms of its capability to measure risk, but perhaps more
importantly, it fails to create any link between management actions and capital
requirement.
</summary>
    <author>
      <name>Giulio Mignola</name>
    </author>
    <author>
      <name>Roberto Ugoccioni</name>
    </author>
    <author>
      <name>Eric Cope</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1607.00756v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.00756v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.02319v2</id>
    <updated>2016-09-14T11:32:42Z</updated>
    <published>2016-07-08T11:21:48Z</published>
    <title>Should the advanced measurement approach be replaced with the
  standardized measurement approach for operational risk?</title>
    <summary>  Recently, Basel Committee for Banking Supervision proposed to replace all
approaches, including Advanced Measurement Approach (AMA), for operational risk
capital with a simple formula referred to as the Standardised Measurement
Approach (SMA). This paper discusses and studies the weaknesses and pitfalls of
SMA such as instability, risk insensitivity, super-additivity and the implicit
relationship between SMA capital model and systemic risk in the banking sector.
We also discuss the issues with closely related operational risk
Capital-at-Risk (OpCar) Basel Committee proposed model which is the precursor
to the SMA. In conclusion, we advocate to maintain the AMA internal model
framework and suggest as an alternative a number of standardization
recommendations that could be considered to unify internal modelling of
operational risk. The findings and views presented in this paper have been
discussed with and supported by many OpRisk practitioners and academics in
Australia, Europe, UK and USA, and recently at OpRisk Europe 2016 conference in
London.
</summary>
    <author>
      <name>Gareth W. Peters</name>
    </author>
    <author>
      <name>Pavel V. Shevchenko</name>
    </author>
    <author>
      <name>Bertrand Hassani</name>
    </author>
    <author>
      <name>Ariane Chapelle</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.21314/JOP.2016.177</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.21314/JOP.2016.177" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Operational Risk, Vol. 11, Issue 3, pp. 1-49, 2016</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1607.02319v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.02319v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.03430v1</id>
    <updated>2016-07-12T16:31:21Z</updated>
    <published>2016-07-12T16:31:21Z</published>
    <title>Dual representations for systemic risk measures</title>
    <summary>  The financial crisis showed the importance of measuring, allocating and
regulating systemic risk. Recently, the systemic risk measures that can be
decomposed into an aggregation function and a scalar measure of risk, received
a lot of attention. In this framework, capital allocations are added after
aggregation and can represent bailout costs. More recently, a framework has
been introduced, where institutions are supplied with capital allocations
before aggregation. This yields an interpretation that is particularly useful
for regulatory purposes. In each framework, the set of all feasible capital
allocations leads to a multivariate risk measure. In this paper, we present
dual representations for scalar systemic risk measures as well as for the
corresponding multivariate risk measures concerning capital allocations. Our
results cover both frameworks: aggregating after allocating and allocating
after aggregation. Economic interpretations of the obtained results are
provided. It turns out that the representations in both frameworks are closely
related.
</summary>
    <author>
      <name>Çağın Ararat</name>
    </author>
    <author>
      <name>Birgit Rudloff</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">30 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1607.03430v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.03430v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B30, 26E25, 49N15" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.04100v1</id>
    <updated>2016-07-14T11:58:28Z</updated>
    <published>2016-07-14T11:58:28Z</published>
    <title>Insurance valuation: a computable multi-period cost-of-capital approach</title>
    <summary>  We present an approach to market-consistent multi-period valuation of
insurance liability cash flows based on a two-stage valuation procedure. First,
a portfolio of traded financial instrument aimed at replicating the liability
cash flow is fixed. Then the residual cash flow is managed by repeated
one-period replication using only cash funds. The latter part takes capital
requirements and costs into account, as well as limited liability and risk
averseness of capital providers. The cost-of-capital margin is the value of the
residual cash flow. We set up a general framework for the cost-of-capital
margin and relate it to dynamic risk measurement. Moreover, we present explicit
formulas and properties of the cost-of-capital margin under further assumptions
on the model for the liability cash flow and on the conditional risk measures
and utility functions. Finally, we highlight computational aspects of the
cost-of-capital margin, and related quantities, in terms of an example from
life insurance.
</summary>
    <author>
      <name>Hampus Engsner</name>
    </author>
    <author>
      <name>Mathias Lindholm</name>
    </author>
    <author>
      <name>Filip Lindskog</name>
    </author>
    <link href="http://arxiv.org/abs/1607.04100v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.04100v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.04737v1</id>
    <updated>2016-07-16T13:17:22Z</updated>
    <published>2016-07-16T13:17:22Z</published>
    <title>A form of multivariate Pareto distribution with applications to
  financial risk measurement</title>
    <summary>  A new multivariate distribution possessing arbitrarily parametrized and
positively dependent univariate Pareto margins is introduced. Unlike the
probability law of Asimit et al. (2010) [Asimit, V., Furman, E. and Vernic, R.
(2010) On a multivariate Pareto distribution. Insurance: Mathematics and
Economics 46(2), 308-316], the structure in this paper is absolutely continuous
with respect to the corresponding Lebesgue measure. The distribution is of
importance to actuaries through its connections to the popular frailty models,
as well as because of the capacity to describe dependent heavy-tailed risks.
The genesis of the new distribution is linked to a number of existing
probability models, and useful characteristic results are proved. Expressions
for, e.g., the decumulative distribution and probability density functions,
(joint) moments and regressions are developed. The distributions of minima and
maxima, as well as, some weighted risk measures are employed to exemplify
possible applications of the distribution in insurance.
</summary>
    <author>
      <name>Jianxi Su</name>
    </author>
    <author>
      <name>Edward Furman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ASTIN Bulletin: The Journal of the International Actuarial
  Association, 2016</arxiv:comment>
    <link href="http://arxiv.org/abs/1607.04737v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.04737v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.08287v2</id>
    <updated>2017-06-08T19:33:17Z</updated>
    <published>2016-07-28T00:29:12Z</published>
    <title>The effect of heterogeneity on flocking behavior and systemic risk</title>
    <summary>  The goal of this paper is to study organized flocking behavior and systemic
risk in heterogeneous mean-field interacting diffusions. We illustrate in a
number of case studies the effect of heterogeneity in the behavior of systemic
risk in the system, i.e., the risk that several agents default simultaneously
as a result of interconnections. We also investigate the effect of
heterogeneity on the "flocking behavior" of different agents, i.e., when agents
with different dynamics end up following very similar paths and follow closely
the mean behavior of the system. Using Laplace asymptotics, we derive an
asymptotic formula for the tail of the loss distribution as the number of
agents grows to infinity. This characterizes the tail of the loss distribution
and the effect of the heterogeneity of the network on the tail loss
probability.
</summary>
    <author>
      <name>Fei Fang</name>
    </author>
    <author>
      <name>Yiwei Sun</name>
    </author>
    <author>
      <name>Konstantinos Spiliopoulos</name>
    </author>
    <link href="http://arxiv.org/abs/1607.08287v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.08287v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.03237v2</id>
    <updated>2016-08-16T22:05:02Z</updated>
    <published>2016-08-10T17:00:50Z</published>
    <title>Managing counterparty credit risk via BSDEs</title>
    <summary>  We discuss a general dynamic replication approach to counterparty credit risk
modeling. This leads to a fundamental jump-process backward stochastic
differential equation (BSDE) for the credit risk adjusted portfolio value. We
then reduce the fundamental BSDE to a continuous BSDE. Depending on the close
out value convention, the reduced fundamental BSDE's solution can be
represented explicitly or through an accurate approximate expression.
Furthermore, we discuss practical aspects of the approach, important for the
its industry applications: (i) efficient numerical methodology for solving a
BSDE driven by a moderate number of Brownian motions, and (ii) factor reduction
methodology that allows one to approximately replace a portfolio driven by a
large number of risk factors with a portfolio driven by a moderate number of
risk factors.
</summary>
    <author>
      <name>Andrew Lesniewski</name>
    </author>
    <author>
      <name>Anja Richter</name>
    </author>
    <link href="http://arxiv.org/abs/1608.03237v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.03237v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.04621v1</id>
    <updated>2016-08-16T14:41:02Z</updated>
    <published>2016-08-16T14:41:02Z</published>
    <title>Optimal importance sampling for Lévy Processes</title>
    <summary>  We develop generic and efficient importance sampling estimators for Monte
Carlo evaluation of prices of single- and multi-asset European and
path-dependent options in asset price models driven by L\'evy processes,
extending earlier works which focused on the Black-Scholes and continuous
stochastic volatility models. Using recent results from the theory of large
deviations on the path space for processes with independent increments, we
compute an explicit asymptotic approximation for the variance of the pay-off
under an Esscher-style change of measure. Minimizing this asymptotic variance
using convex duality, we then obtain an easy to compite asymptotically
efficient importance sampling estimator of the option price. Numerical tests
for European baskets and for Asian options in the variance gamma model show
consistent variance reduction with a very small computational overhead.
</summary>
    <author>
      <name>Adrien Genin</name>
    </author>
    <author>
      <name>Peter Tankov</name>
    </author>
    <link href="http://arxiv.org/abs/1608.04621v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.04621v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91G60, 60G51" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.05498v2</id>
    <updated>2017-02-21T09:07:24Z</updated>
    <published>2016-08-19T05:41:39Z</published>
    <title>Elicitability and backtesting: Perspectives for banking regulation</title>
    <summary>  Conditional forecasts of risk measures play an important role in internal
risk management of financial institutions as well as in regulatory capital
calculations. In order to assess forecasting performance of a risk measurement
procedure, risk measure forecasts are compared to the realized financial losses
over a period of time and a statistical test of correctness of the procedure is
conducted. This process is known as backtesting. Such traditional backtests are
concerned with assessing some optimality property of a set of risk measure
estimates. However, they are not suited to compare different risk estimation
procedures. We investigate the proposal of comparative backtests, which are
better suited for method comparisons on the basis of forecasting accuracy, but
necessitate an elicitable risk measure. We argue that supplementing traditional
backtests with comparative backtests will enhance the existing trading book
regulatory framework for banks by providing the correct incentive for accuracy
of risk measure forecasts. In addition, the comparative backtesting framework
could be used by banks internally as well as by researchers to guide selection
of forecasting methods. The discussion focuses on three risk measures,
Value-at-Risk, expected shortfall and expectiles, and is supported by a
simulation study and data analysis.
</summary>
    <author>
      <name>Natalia Nolde</name>
    </author>
    <author>
      <name>Johanna F. Ziegel</name>
    </author>
    <link href="http://arxiv.org/abs/1608.05498v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.05498v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.05939v2</id>
    <updated>2016-10-03T22:17:07Z</updated>
    <published>2016-09-19T21:02:25Z</published>
    <title>Crises and Physical Phases of a Bipartite Market Model</title>
    <summary>  We analyze the linear response of a market network to shocks based on the
bipartite market model we introduced in an earlier paper, which we claimed to
be able to identify the time-line of the 2009-2011 Eurozone crisis correctly.
We show that this model has three distinct phases that can broadly be
categorized as "stable" and "unstable". Based on the interpretation of our
behavioral parameters, the stable phase describes periods where investors and
traders have confidence in the market (e.g. predict that the market rebounds
from a loss). We show that the unstable phase happens when there is a lack of
confidence and seems to describe "boom-bust" periods in which changes in prices
are exponential. We analytically derive these phases and where the phase
transition happens using a mean field approximation of the model. We show that
the condition for stability is $\alpha \beta &lt;1$ with $\alpha$ being the
inverse of the "price elasticity" and $\beta$ the "income elasticity of
demand", which measures how rash the investors make decisions. We also show
that in the mean-field limit this model reduces to the Langevin model by
Bouchaud et al. for price returns.
</summary>
    <author>
      <name>Nima Dehmamy</name>
    </author>
    <author>
      <name>Sergey Buldyrev</name>
    </author>
    <author>
      <name>Shlomo Havlin</name>
    </author>
    <author>
      <name>Harry Eugene Stanley</name>
    </author>
    <author>
      <name>Irena Vodenska</name>
    </author>
    <link href="http://arxiv.org/abs/1609.05939v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.05939v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1610.02126v1</id>
    <updated>2016-10-07T02:19:46Z</updated>
    <published>2016-10-07T02:19:46Z</published>
    <title>Multiple risk factor dependence structures: Copulas and related
  properties</title>
    <summary>  Copulas have become an important tool in the modern best practice Enterprise
Risk Management, often supplanting other approaches to modelling stochastic
dependence. However, choosing the `right' copula is not an easy task, and the
temptation to prefer a tractable rather than a meaningful candidate from the
encompassing copulas toolbox is strong. The ubiquitous applications of the
Gaussian copula is just one illuminating example.
  Speaking generally, a `good' copula should conform to the problem at hand,
allow for asymmetry in the domain of definition and exhibit some extent of tail
dependence. In this paper we introduce and study a new class of Multiple Risk
Factor (MRF) copula functions, which we show are exactly such. Namely, the MRF
copulas (1) arise from a number of meaningful default risk specification with
stochastic default barriers, (2) are in general non-exchangeable and (3)
possess a variety of tail dependences. That being said, the MRF copulas turn
out to be surprisingly tractable analytically.
</summary>
    <author>
      <name>Jianxi Su</name>
    </author>
    <author>
      <name>Edward Furman</name>
    </author>
    <link href="http://arxiv.org/abs/1610.02126v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1610.02126v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1610.03259v1</id>
    <updated>2016-10-11T10:01:05Z</updated>
    <published>2016-10-11T10:01:05Z</published>
    <title>Epidemics of Liquidity Shortages in Interbank Markets</title>
    <summary>  Financial contagion from liquidity shocks has being recently ascribed as a
prominent driver of systemic risk in interbank lending markets. Building on
standard compartment models used in epidemics, here we develop an EDB
(Exposed-Distressed-Bankrupted) model for the dynamics of liquidity shocks
reverberation between banks, and validate it on electronic market for interbank
deposits data. We show that the interbank network was highly susceptible to
liquidity contagion at the beginning of the 2007/2008 global financial crisis,
and that the subsequent micro-prudential and liquidity hoarding policies
adopted by banks increased the network resilience to systemic risk, yet with
the undesired side effect of drying out liquidity from the market. We finally
show that the individual riskiness of a bank is better captured by its network
centrality than by its participation to the market, along with the currently
debated concept of "too interconnected to fail".
</summary>
    <author>
      <name>Giuseppe Brandi</name>
    </author>
    <author>
      <name>Riccardo Di Clemente</name>
    </author>
    <author>
      <name>Giulio Cimini</name>
    </author>
    <link href="http://arxiv.org/abs/1610.03259v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1610.03259v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1610.03769v2</id>
    <updated>2017-07-30T18:31:15Z</updated>
    <published>2016-10-12T16:12:53Z</published>
    <title>On Origins of Bubbles</title>
    <summary>  We discuss - in what is intended to be a pedagogical fashion - a criterion,
which is a lower bound on a certain ratio, for when a stock (or a similar
instrument) is not a good investment in the long term, which can happen even if
the expected return is positive. The root cause is that prices are positive and
have skewed, long-tailed distributions, which coupled with volatility results
in a long-run asymmetry. This relates to bubbles in stock prices, which we
discuss using a simple binomial tree model, without resorting to the stochastic
calculus machinery. We illustrate empirical properties of the aforesaid ratio.
Log of market cap and sectors appear to be relevant explanatory variables for
this ratio, while price-to-book ratio (or its log) is not. We also discuss a
short-term effect of volatility, to wit, the analog of Heisenberg's uncertainty
principle in finance and a simple derivation thereof using a binary tree.
</summary>
    <author>
      <name>Zura Kakushadze</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">26 pages; a trivial typo corrected, no other changes</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Risk &amp; Control 4(1) (2017) 1-30</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1610.03769v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1610.03769v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="hep-th" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.MF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1610.08782v1</id>
    <updated>2016-10-27T13:57:57Z</updated>
    <published>2016-10-27T13:57:57Z</published>
    <title>Intrinsic risk measures</title>
    <summary>  Monetary risk measures are usually interpreted as the smallest amount of
external capital that must be added to a financial position to make it
acceptable. We propose a new concept: intrinsic risk measures and argue that
this approach provides a direct path from unacceptable positions towards the
acceptance set. Intrinsic risk measures use only internal resources and return
the smallest percentage of the currently held financial position which has to
be sold and reinvested into an eligible asset such that the resulting position
becomes acceptable. While avoiding the problem of infinite values, intrinsic
risk measures allow a free choice of the eligible asset and they preserve
desired properties such as monotonicity and quasi-convexity. A dual
representation on convex acceptance sets is derived and the link of intrinsic
risk measures to their monetary counterparts on cones is detailed.
</summary>
    <author>
      <name>W. Farkas</name>
    </author>
    <author>
      <name>A. Smirnow</name>
    </author>
    <link href="http://arxiv.org/abs/1610.08782v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1610.08782v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.MF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B30, 91B32, 91G99" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.03066v2</id>
    <updated>2017-04-05T18:57:16Z</updated>
    <published>2016-12-09T15:54:11Z</published>
    <title>Parameter uncertainty and reserve risk under Solvency II</title>
    <summary>  In this article we consider the parameter risk in the context of internal
modelling of the reserve risk under Solvency II.
  We discuss two opposed perspectives on parameter uncertainty and point out
that standard methods of classical reserving focusing on the estimation error
of claims reserves are in general not appropriate to model the impact of
parameter uncertainty upon the actual risk of economic losses from the
undertakings's perspective.
  Referring to the requirements of Solvency II we assess methods to model
parameter uncertainty for the reserve risk by comparing the probability of
solvency actually attained when modelling the solvency risk capital requirement
based on the respective method to the required confidence level. Using the
simple example of a normal model we show that the bootstrapping approach is not
appropriate to model parameter uncertainty according to this criterion. We then
present an adaptation of the approach proposed in \cite {froehlich2014}.
Experimental results demonstrate that this new method yields a risk capital
model for the reserve risk achieving the required confidence level in good
approximation.
</summary>
    <author>
      <name>Andreas Fröhlich</name>
    </author>
    <author>
      <name>Annegret Weng</name>
    </author>
    <link href="http://arxiv.org/abs/1612.03066v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.03066v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B30" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.02028v1</id>
    <updated>2017-01-08T22:32:08Z</updated>
    <published>2017-01-08T22:32:08Z</published>
    <title>Asset correlation estimation for inhomogeneous exposure pools</title>
    <summary>  Asset correlations play an important role in credit portfolio modelling. One
possible data source for their estimation are default time series. This study
investigates the systematic error that is made if the exposure pool underlying
a default time series is assumed to be homogeneous when in reality it is not.
We find that the asset correlation will always be underestimated if homogeneity
with respect to the probability of default (PD) is wrongly assumed, and the
error is the larger the more spread out the PD is within the exposure pool. If
the exposure pool is inhomogeneous with respect to the asset correlation itself
then the error may be going in both directions, but for most PD- and asset
correlation ranges relevant in practice the asset correlation is systematically
underestimated. Both effects stack up and the error tends to become even larger
if in addition we assume a negative correlation between asset correlation and
PD within the exposure pool, an assumption that is plausible in many
circumstances and consistent with the Basel RWA formula. It is argued that the
generic inhomogeneity effect described in this paper is one of the reasons why
asset correlations measured from default data tend to be lower than asset
correlations derived from asset value data.
</summary>
    <author>
      <name>Christoph Wunderer</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">35 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1701.02028v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.02028v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.04167v1</id>
    <updated>2017-01-16T04:51:52Z</updated>
    <published>2017-01-16T04:51:52Z</published>
    <title>Worst-Case Expected Shortfall with Univariate and Bivariate Marginals</title>
    <summary>  Worst-case bounds on the expected shortfall risk given only limited
information on the distribution of the random variables has been studied
extensively in the literature. In this paper, we develop a new worst-case bound
on the expected shortfall when the univariate marginals are known exactly and
additional expert information is available in terms of bivariate marginals.
Such expert information allows for one to choose from among the many possible
parametric families of bivariate copulas. By considering a neighborhood of
distance $\rho$ around the bivariate marginals with the Kullback-Leibler
divergence measure, we model the trade-off between conservatism in the
worst-case risk measure and confidence in the expert information. Our bound is
developed when the only information available on the bivariate marginals forms
a tree structure in which case it is efficiently computable using convex
optimization. For consistent marginals, as $\rho$ approaches $\infty$, the
bound reduces to the comonotonic upper bound and as $\rho$ approaches $0$, the
bound reduces to the worst-case bound with bivariates known exactly. We also
discuss extensions to inconsistent marginals and instances where the expert
information which might be captured using other parameters such as
correlations.
</summary>
    <author>
      <name>Anulekha Dhara</name>
    </author>
    <author>
      <name>Bikramjit Das</name>
    </author>
    <author>
      <name>Karthik Natarajan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">23 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1701.04167v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.04167v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.05967v2</id>
    <updated>2017-09-04T23:24:04Z</updated>
    <published>2017-01-21T02:19:02Z</published>
    <title>Fatou Property, representations, and extensions of law-invariant risk
  measures on general Orlicz spaces</title>
    <summary>  We provide a variety of results for (quasi)convex, law-invariant functionals
defined on a general Orlicz space, which extend well-known results in the
setting of bounded random variables. First, we show that Delbaen's
representation of convex functionals with the Fatou property, which fails in a
general Orlicz space, can be always achieved under the assumption of
law-invariance. Second, we identify the range of Orlicz spaces where the
characterization of the Fatou property in terms of norm lower semicontinuity by
Jouini, Schachermayer and Touzi continues to hold. Third, we extend Kusuoka's
representation to a general Orlicz space. Finally, we prove a version of the
extension result by Filipovi\'{c} and Svindland by replacing norm lower
semicontinuity with the (generally non-equivalent) Fatou property. Our results
have natural applications to the theory of risk measures.
</summary>
    <author>
      <name>Niushan Gao</name>
    </author>
    <author>
      <name>Denny H. Leung</name>
    </author>
    <author>
      <name>Cosimo Munari</name>
    </author>
    <author>
      <name>Foivos Xanthos</name>
    </author>
    <link href="http://arxiv.org/abs/1701.05967v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.05967v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1702.03098v1</id>
    <updated>2017-02-10T08:49:04Z</updated>
    <published>2017-02-10T08:49:04Z</published>
    <title>Estimation of Risk Contributions with MCMC</title>
    <summary>  Determining risk contributions by unit exposures to portfolio-wide economic
capital is an important task in financial risk management. Despite its
practical demands, computation of risk contributions is challenging for most
risk models because it often requires rare-event simulation. In this paper, we
address the problem of estimating risk contributions when the total risk is
measured by Value-at-Risk (VaR). We propose a new estimator of VaR
contributions, that utilizes Markov chain Monte Carlo (MCMC) method. Unlike the
existing estimators, our MCMC-based estimator is computed by samples of
conditional loss distribution given the rare event of our interest. MCMC method
enables to generate such samples without evaluating the density of total risk.
Thanks to these features, our estimator has improved sample-efficiency compared
with the crude Monte Carlo method. Moreover, our method is widely applicable to
various risk models specified by joint portfolio loss density. In this paper,
we show that our MCMC-based estimator has several attractive properties, such
as consistency and asymptotic normality. Our numerical experiment also
demonstrates that, in various risk models used in practice, our MCMC estimator
has smaller bias and MSE compared with these of existing estimators.
</summary>
    <author>
      <name>Takaaki Koike</name>
    </author>
    <author>
      <name>Mihoko Minami</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">26 pages, 1 table, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1702.03098v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1702.03098v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.CP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B30, 91G60, 91G70" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1702.08744v2</id>
    <updated>2017-03-10T12:53:28Z</updated>
    <published>2017-02-28T11:12:59Z</published>
    <title>Reverse stress testing interbank networks</title>
    <summary>  We reverse engineer dynamics of financial contagion to find the scenario of
smallest exogenous shock that, should it occur, would lead to a given final
systemic loss. This reverse stress test can be used to identify the potential
triggers of systemic events, and it removes the arbitrariness in the selection
of shock scenarios in stress testing. We consider in particular the case of
distress propagation in an interbank market, and we study a network of 44
European banks, which we reconstruct using data collected from Bloomberg. By
looking at the distribution across banks of the size of smallest exogenous
shocks we rank banks in terms of their systemic importance, and we show the
effectiveness of a policy with capital requirements based on this ranking. We
also study the properties of smallest exogenous shocks as a function of the
largest eigenvalue $\lambda_{\rm max}$ of the matrix of interbank leverages,
which determines the endogenous amplification of shocks. We find that the size
of smallest exogenous shocks reduces and that the distribution across banks
becomes more localized as $\lambda_{\rm max}$ increases.
</summary>
    <author>
      <name>Daniel Grigat</name>
    </author>
    <author>
      <name>Fabio Caccioli</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages, 9 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1702.08744v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1702.08744v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.01329v3</id>
    <updated>2017-07-14T10:41:17Z</updated>
    <published>2017-03-03T20:20:15Z</published>
    <title>Disentangling Price, Risk and Model Risk: V&amp;R measures</title>
    <summary>  We propose a method to assess the intrinsic risk carried by a financial
position $X$ when the agent faces uncertainty about the pricing rule assigning
its present value. Our approach is inspired by a new interpretation of the
quasiconvex duality in a Knightian setting, where a family of probability
measures replaces the single reference probability and is then applied to value
financial positions.
  Diametrically, our construction of Value\&amp;Risk measures is based on the
selection of a basket of claims to test the reliability of models. We compare a
random payoff $X$ with a given class of derivatives written on $X$ , and use
these derivatives to \textquotedblleft test\textquotedblright\ the pricing
measures.
  We further introduce and study a general class of Value\&amp;Risk measures $%
R(p,X,\mathbb{P})$ that describes the additional capital that is required to
make $X$ acceptable under a probability $\mathbb{P}$ and given the initial
price $p$ paid to acquire $X$.
</summary>
    <author>
      <name>Marco Frittelli</name>
    </author>
    <author>
      <name>Marco Maggis</name>
    </author>
    <link href="http://arxiv.org/abs/1703.01329v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.01329v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.MF" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1704.01608v1</id>
    <updated>2017-04-05T18:54:24Z</updated>
    <published>2017-04-05T18:54:24Z</published>
    <title>Parameter uncertainty for integrated risk capital calculations based on
  normally distributed subrisks</title>
    <summary>  In this contribution we consider the overall risk given as the sum of random
subrisks $\mathbf{X}_j$ in the context of value-at-risk (VaR) based risk
calculations. If we assume that the undertaking knows the parametric
distribution family subrisk $\mathbf{X}_j=\mathbf{X}_j(\theta_j)$, but does not
know the true parameter vectors $\theta_j$, the undertaking faces parameter
uncertainty. To assess the appropriateness of methods to model parameter
uncertainty for risk capital calculation we consider a criterion introduced in
the recent literature. According to this criterion, we demonstrate that, in
general, appropriateness of a risk capital model for each subrisk does not
imply appropriateness of the model on the aggregate level of the overall
risk.\\ For the case where the overall risk is given by the sum of normally
distributed subrisks we prove a theoretical result leading to an appropriate
integrated risk capital model taking parameter uncertainty into account. Based
on the theorem we develop a method improving the approximation of the required
confidence level simultaneously for both - on the level of each subrisk as well
as for the overall risk.
</summary>
    <author>
      <name>Andreas Fröhlich</name>
    </author>
    <author>
      <name>Annegret Weng</name>
    </author>
    <link href="http://arxiv.org/abs/1704.01608v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1704.01608v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1704.05332v1</id>
    <updated>2017-04-18T13:27:42Z</updated>
    <published>2017-04-18T13:27:42Z</published>
    <title>The case of 'Less is more': Modelling risk-preference with Expected
  Downside Risk</title>
    <summary>  This paper discusses an alternative explanation for the empirical findings
contradicting the positive relationship between risk (variance) and reward
(expected return). We show that these contradicting results might be due to the
false definition of risk-perception, which we correct by introducing Expected
Downside Risk (EDR). The EDR parameter, similar to the Expected Shortfall or
Conditional Value-at-Risk, measures the tail risk, however, fits and better
explains the utility perception of investors. Our results indicate that when
using the EDR as risk measure, both the positive and negative relationship
between expected return and risk can be derived under standard conditions (e.g.
expected utility theory and positive risk-aversion). Therefore, no alternative
psychological explanation or additional boundary condition on utility theory is
required to explain the phenomenon. Furthermore, we show empirically that it is
a more precise linear predictor of expected return than volatility, both for
individual assets and portfolios.
</summary>
    <author>
      <name>Mihaly Ormos</name>
    </author>
    <author>
      <name>Dusan Timotity</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1515/bejte-2016-0100</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1515/bejte-2016-0100" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">34 pages, 8 figures and 2 tables</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">The B.E. Journal of Theoretical Economics (2017)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1704.05332v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1704.05332v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1704.07235v1</id>
    <updated>2017-04-24T13:52:46Z</updated>
    <published>2017-04-24T13:52:46Z</published>
    <title>Value-at-Risk Diversification of $α$-stable Risks: The
  Tail-Dependence Puzzle</title>
    <summary>  We consider the problem of risk diversification of $\alpha$-stable heavy
tailed risks. We study the behaviour of the aggregated Value-at-Risk, with
particular reference to the impact of different tail dependence structures on
the limits to diversification. We confirm the large evidence of sub-additivity
violations, particularly for risks with low tail index values and positive
dependence. So, reinsurance strategies are not allowed to exploit
diversification gains, or only a very limited amount of them. Concerning the
impact of tail dependence, we find the peculiar results that for high tail
dependence levels the limits to diversification are uniformly lower for all the
levels of dependence, and for all levels of $\alpha&lt;2$. The result is confirmed
as we move towards extreme points in the tail: in this case, we show that at
some point in the tail the aggregated VaR becomes additive above some level of
dependence, but this critical dependence level is lower for copulas with lower
tail dependence.
</summary>
    <author>
      <name>Umberto Cherubini</name>
    </author>
    <author>
      <name>Paolo Neri</name>
    </author>
    <link href="http://arxiv.org/abs/1704.07235v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1704.07235v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1704.08523v1</id>
    <updated>2017-04-27T12:04:15Z</updated>
    <published>2017-04-27T12:04:15Z</published>
    <title>Economic Neutral Position: How to best replicate not fully replicable
  liabilities</title>
    <summary>  Financial undertakings often have to deal with liabilities of the form
'non-hedgeable claim size times value of a tradeable asset', e.g. foreign
property insurance claims times fx rates. Which strategy to invest in the
tradeable asset is risk minimal? We expand the capital requirements based on
value-at-risk and expected shortfall using perturbation techniques. We derive a
stable and fairly model independent approximation of the risk minimal asset
allocation in terms of the claim size distribution and the first three moments
of asset return. The results enable a correct and easy-to-implement
modularization of capital requirements into a market risk and a non-hedgeable
risk component: the paper provides a stable expression for the financial
benchmark against which the company's asset allocation must be measured to
obtain the market risk component.
</summary>
    <author>
      <name>Andreas Kunz</name>
    </author>
    <author>
      <name>Markus Popp</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1704.08523v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1704.08523v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="Primary: 91B30, Secondary: 60E05, 62P05" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.05572v1</id>
    <updated>2017-05-16T08:10:50Z</updated>
    <published>2017-05-16T08:10:50Z</published>
    <title>A Novel Approach to Quantification of Model Risk for Practitioners</title>
    <summary>  Models continue to increase their already broad use across industry as well
as their sophistication. Worldwide regulation oblige financial institutions to
manage and address model risk with the same severity as any other type of risk,
which besides defines model risk as the potential for adverse consequences from
decisions based on incorrect and misused model outputs and reports. Model risk
quantification is essential not only in meeting these requirements but for
institution's basic internal operative. It is however a complex task as any
comprehensive quantification methodology should at least consider the data used
for building the model, its mathematical foundations, the IT infrastructure,
overall performance and (most importantly) usage. Besides, the current amount
of models and different mathematical modelling techniques is overwhelming.
  Our proposal is to define quantification of model risk as a calculation of
the norm of some appropriate function that belongs to a Banach space, defined
over a weighted Riemannian manifold endowed with the Fisher--Rao metric. The
aim of the present contribution is twofold: Introduce a sufficiently general
and sound mathematical framework to cover the aforementioned points and
illustrate how a practitioner may identify the relevant abstract concepts and
put them to work.
</summary>
    <author>
      <name>Zuzana Krajcovicova</name>
    </author>
    <author>
      <name>Pedro Pablo Perez-Velasco</name>
    </author>
    <author>
      <name>Carlos Vazquez</name>
    </author>
    <link href="http://arxiv.org/abs/1705.05572v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.05572v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91G99" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.05812v1</id>
    <updated>2017-06-19T07:46:51Z</updated>
    <published>2017-06-19T07:46:51Z</published>
    <title>News-sentiment networks as a risk indicator</title>
    <summary>  To understand the relationship between news sentiment and company stock price
movements, and to better understand connectivity among companies, we define an
algorithm for measuring sentiment-based network risk. The algorithm ranks
companies in networks of co-occurrences, and measures sentiment-based risk, by
calculating both individual risks and aggregated network risks. We extract
relative sentiment for companies to get a measure of individual company risk,
and input it into our risk model together with co-occurrences of companies
extracted from news on a quarterly basis. We can show that the highest
quarterly risk value outputted by our risk model, is correlated to a higher
chance of stock price decline, up to 70 days after a risk measurement. Our
results show that the highest difference in the probability of stock price
decline, compared to the benchmark containing all risk values for the same
period, is during the interval from 21 to 30 days after a quarterly
measurement. The highest average probability of company stock price decline, is
found at a delay of 28 days, after a company has reached its maximum risk
value. The highest probability differences for a daily decline were calculated
to be 13 percentage points.
</summary>
    <author>
      <name>Thomas Forss</name>
    </author>
    <author>
      <name>Peter Sarlin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">31 pages, 4 figures, 2 tables, 4 pages appendix</arxiv:comment>
    <link href="http://arxiv.org/abs/1706.05812v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.05812v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.TR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.09038v1</id>
    <updated>2017-06-27T20:15:09Z</updated>
    <published>2017-06-27T20:15:09Z</published>
    <title>Risk Model Based on General Compound Hawkes Process</title>
    <summary>  In this paper, we introduce a new model for the risk process based on general
compound Hawkes process (GCHP) for the arrival of claims. We call it risk model
based on general compound Hawkes process (RMGCHP). The Law of Large Numbers
(LLN) and the Functional Central Limit Theorem (FCLT) are proved. We also study
the main properties of this new risk model, net profit condition, premium
principle and ruin time (including ultimate ruin time) applying the LLN and
FCLT for the RMGCHP. We show, as applications of our results, similar results
for risk model based on compound Hawkes process (RMCHP) and apply them to the
classical risk model based on compound Poisson process (RMCPP).
</summary>
    <author>
      <name>Anatoliy Swishchuk</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages; this paper will be presented at the 21st International
  Congress Insurance: Mathematics and Economics-IME 2017, TUW, Vienna</arxiv:comment>
    <link href="http://arxiv.org/abs/1706.09038v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.09038v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="60G55, 91B30" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.09809v1</id>
    <updated>2017-06-29T15:33:02Z</updated>
    <published>2017-06-29T15:33:02Z</published>
    <title>Extreme portfolio loss correlations in credit risk</title>
    <summary>  The stability of the financial system is associated with systemic risk
factors such as the concurrent default of numerous small obligors. Hence it is
of utmost importance to study the mutual dependence of losses for different
creditors in the case of large, overlapping credit portfolios. We analytically
calculate the multivariate joint loss distribution of several credit portfolios
on a non-stationary market. To take fluctuating asset correlations into account
we use an random matrix approach which preserves, as a much appreciated side
effect, analytical tractability and drastically reduces the number of
parameters. We show that for two disjoint credit portfolios diversification
does not work in a correlated market. Additionally we find large concurrent
portfolio losses to be rather likely. We show that significant correlations of
the losses emerge not only for large portfolios with thousands of credit
contracts but also for small portfolios consisting of a few credit contracts
only. Furthermore we include subordination levels, which were established in
collateralized debt obligations to protect the more senior tranches from high
losses. We analytically corroborate the observation that an extreme loss of the
subordinated creditor is likely to also yield a large loss of the senior
creditor.
</summary>
    <author>
      <name>Andreas Mühlbacher</name>
    </author>
    <author>
      <name>Thomas Guhr</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">25 pages, 10 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1706.09809v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.09809v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.10186v1</id>
    <updated>2017-06-30T13:22:11Z</updated>
    <published>2017-06-30T13:22:11Z</published>
    <title>Computational aspects of robust optimized certainty equivalents</title>
    <summary>  Accounting for model uncertainty in risk management leads to infinite
dimensional optimization problems which are both analytically and numerically
untractable. In this article we study when this fact can be overcome for the
so-called optimized certainty equivalent risk measure (OCE) - including the
average value-at-risk as a special case. First we focus on the case where the
set of possible distributions of a financial loss is given by the neighborhood
of a given baseline distribution in the Wasserstein distance, or more
generally, an optimal-transport distance. Here it turns out that the
computation of the robust OCE reduces to a finite dimensional problem, which in
some cases can even be solved explicitly. Further, we derive convex dual
representations of the robust OCE for measurable claims without any assumptions
on the set of distributions and finally give conditions on the latter set under
which the robust average value-at-risk is a tail risk measure.
</summary>
    <author>
      <name>Daniel Bartl</name>
    </author>
    <author>
      <name>Samuel Drapeau</name>
    </author>
    <author>
      <name>Ludovic Tangpi</name>
    </author>
    <link href="http://arxiv.org/abs/1706.10186v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.10186v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91G80, 90B50, 60E10, 91B30" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.00917v1</id>
    <updated>2017-07-04T11:25:54Z</updated>
    <published>2017-07-04T11:25:54Z</published>
    <title>Bonus--malus systems with different claim types and varying deductibles</title>
    <summary>  The paper deals with bonus-malus systems with different claim types and
varying deductibles. The premium relativities are softened for the
policyholders who are in the malus zone and these policyholders are subject to
per claim deductibles depending on their levels in the bonus-malus scale and
the types of the reported claims. We introduce such bonus-malus systems and
study their basic properties. In particular, we investigate when it is possible
to introduce varying deductibles, what restrictions we have and how we can do
this. Moreover, we deal with the special case where varying deductibles are
applied to the claims reported by policyholders occupying the highest level in
the bonus-malus scale and consider two allocation principles for the
deductibles. Finally, numerical illustrations are presented.
</summary>
    <author>
      <name>Olena Ragulina</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.15559/17-VMSTA80</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.15559/17-VMSTA80" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published at http://dx.doi.org/10.15559/17-VMSTA80 in the Modern
  Stochastics: Theory and Applications (https://www.i-journals.org/vtxpp/VMSTA)
  by VTeX (http://www.vtex.lt/)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Modern Stochastics: Theory and Applications 2017, Vol. 4, No. 2,
  141-159</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1707.00917v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.00917v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.03542v1</id>
    <updated>2017-07-12T05:06:37Z</updated>
    <published>2017-07-12T05:06:37Z</published>
    <title>A Model of Interbank Flows, Borrowing, and Investing</title>
    <summary>  We consider a model when private banks with interbank cash flows as in
(Carmona, Fouque, Sun, 2013) borrow from the outside economy at a certain
interest rate, controlled by the central bank, and invest in risky assets. The
cash flow between private banks is also facilitated by the central bank. Each
private bank aims to maximize its expected terminal logarithmic utility. The
central bank, in turn, aims to control the overall size of financial system,
and the rate of circulation between banks. A default occurs when the net worth
of a bank goes below a certain threshold. We consider systemic risk by studying
probability of a certain number of defaults over fixed finite time horizon.
</summary>
    <author>
      <name>Aditya Maheshwari</name>
    </author>
    <author>
      <name>Andrey Sarantsev</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">26 pages, 15 figures. Keywords: systemic risk, stochastic control,
  principal-agent problem, Nash equilibrium, stochastic game, stationary
  distribution, stochastic stability, Lyapunov function</arxiv:comment>
    <link href="http://arxiv.org/abs/1707.03542v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.03542v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="60H10, 60H30, 60J60, 60K35, 91A15, 91B70, 91G80, 93E15" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.03715v1</id>
    <updated>2017-07-11T07:25:10Z</updated>
    <published>2017-07-11T07:25:10Z</published>
    <title>Bayesian Realized-GARCH Models for Financial Tail Risk Forecasting
  Incorporating Two-sided Weibull Distribution</title>
    <summary>  The realized GARCH framework is extended to incorporate the two-sided Weibull
distribution, for the purpose of volatility and tail risk forecasting in a
financial time series. Further, the realized range, as a competitor for
realized variance or daily returns, is employed in the realized GARCH
framework. Further, sub-sampling and scaling methods are applied to both the
realized range and realized variance, to help deal with inherent
micro-structure noise and inefficiency. An adaptive Bayesian Markov Chain Monte
Carlo method is developed and employed for estimation and forecasting, whose
properties are assessed and compared with maximum likelihood, via a simulation
study. Compared to a range of well-known parametric GARCH, GARCH with two-sided
Weibull distribution and realized GARCH models, tail risk forecasting results
across 7 market index return series and 2 individual assets clearly favor the
realized GARCH models incorporating two-sided Weibull distribution, especially
models employing the sub-sampled realized variance and sub-sampled realized
range, over a six year period that includes the global financial crisis.
</summary>
    <author>
      <name>Chao Wang</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Discipline of Business Analytics, The University of Sydney</arxiv:affiliation>
    </author>
    <author>
      <name>Qian Chen</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">HSBC Business School, Peking University</arxiv:affiliation>
    </author>
    <author>
      <name>Richard Gerlach</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Discipline of Business Analytics, The University of Sydney</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">33 pages, 5 figures, 8 tables. arXiv admin note: substantial text
  overlap with arXiv:1612.08488</arxiv:comment>
    <link href="http://arxiv.org/abs/1707.03715v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.03715v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.04831v1</id>
    <updated>2017-07-16T06:56:28Z</updated>
    <published>2017-07-16T06:56:28Z</published>
    <title>Machine learning application in online lending risk prediction</title>
    <summary>  Online leading has disrupted the traditional consumer banking sector with
more effective loan processing. Risk prediction and monitoring is critical for
the success of the business model. Traditional credit score models fall short
in applying big data technology in building risk model. In this manuscript,
data with various format and size were collected from public website,
third-parties and assembled with client's loan application information data.
Ensemble machine learning models, random forest model and XGBoost model, were
built and trained with the historical transaction data and subsequently tested
with separate data. XGBoost model shows higher K-S value, suggesting better
classification capability in this task. Top 10 important features from the two
models suggest external data such as zhimaScore, multi-platform stacking loans
information, and social network information are important factors in predicting
loan default probability.
</summary>
    <author>
      <name>Xiaojiao Yu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1707.04831v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.04831v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.05596v1</id>
    <updated>2017-07-18T13:07:01Z</updated>
    <published>2017-07-18T13:07:01Z</published>
    <title>Surplus-Invariant, Law-Invariant, and Conic Acceptance Sets Must be the
  Sets Induced by Value-at-Risk</title>
    <summary>  The regulator is interested in proposing a capital adequacy test by
specifying an acceptance set for firms' capital positions at the end of a given
period. This set needs to be surplus-invariant, i.e., not to depend on the
surplus of firms' shareholders, because the test means to protect firms'
liability holders. We prove that any surplus-invariant, law-invariant, and
conic acceptance set must be the set of capital positions whose value-at-risk
at a given level is less than zero. The result still holds if we replace
conicity with numeraire-invariance, a property stipulating that whether a firm
passes the test should not depend on the currency used to denominate its
assets.
</summary>
    <author>
      <name>Xue Dong He</name>
    </author>
    <author>
      <name>Xianhua Peng</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">25 pages, 0 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1707.05596v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.05596v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.MF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91Gxx, 91B30, 62G35, 46N30, 47N30" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.02180v1</id>
    <updated>2017-08-07T16:02:12Z</updated>
    <published>2017-08-07T16:02:12Z</published>
    <title>Financial option insurance</title>
    <summary>  The option is a financial derivative, which is regularly employed in reducing
the risk of its underlying securities. However, investing in option is still
risky. Such risk becomes much severer for speculators who utilize option as a
means of leverage to increase their potential returns. In order to mitigate
risk on their positions, the rudimentary concept of financial option insurance
is introduced into practice. Two starkly-dissimilar concepts of insurance and
financial option are integrated into the formation of financial option
insurance. The proposed financial product insures investors option premiums
when misfortune befalls on them. As a trade-off, they are likely to sacrifice a
limited portion of their potential profits. The loopholes of prevailing
financial market are addressed and the void is filled by introducing a stable
three-entity framework. Moreover, a specifically designed mathematical model is
proposed. It consists of two portions: the business strategy of matching and a
verification-and-modification process. The proposed model enables the option
investors with calls and puts of different moneyness to be protected by the
issued option insurance. Meanwhile, it minimizes the exposure of option
insurers position to any potential losses.
</summary>
    <author>
      <name>Qi-Wen Wang</name>
    </author>
    <author>
      <name>Jian-Jun Shu</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1057/s41283-016-0013-5</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1057/s41283-016-0013-5" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Risk Management-Journal of Risk Crisis and Disaster, Vol. 19, No.
  1, pp. 72-101, 2017</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1708.02180v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.02180v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.05319v1</id>
    <updated>2017-08-17T14:54:26Z</updated>
    <published>2017-08-17T14:54:26Z</published>
    <title>An indifference approach to the cost of capital constraints: KVA and
  beyond</title>
    <summary>  The strengthening of capital requirements has induced banks and traders to
consider charging a so called capital valuation adjustment (KVA) to the clients
in OTC transactions. This roughly corresponds to charge the clients ex-ante the
profit requirement that is asked to the trading desk. In the following we try
to delineate a possible way to assess the impact of capital constraints in the
valuation of a deal. We resort to an optimisation stemming from an indifference
pricing approach, and we study both the linear problem from the point of view
of the whole bank and the non-linear problem given by the viewpoint of
shareholders. We also consider the case where one optimises the median rather
than the mean statistics of the profit and loss distribution.
</summary>
    <author>
      <name>Damiano Brigo</name>
    </author>
    <author>
      <name>Marco Francischello</name>
    </author>
    <author>
      <name>Andrea Pallavicini</name>
    </author>
    <link href="http://arxiv.org/abs/1708.05319v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.05319v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.06886v1</id>
    <updated>2017-08-23T05:06:06Z</updated>
    <published>2017-08-23T05:06:06Z</published>
    <title>VIX-linked fees for GMWBs via Explicit Solution Simulation Methods</title>
    <summary>  In a market with stochastic volatility and jumps, we consider a VIX-linked
fee structure for variable annuity contracts with guaranteed minimum withdrawal
benefits (GMWB). Our goal is to assess the effectiveness of the VIX-linked fee
structure in decreasing the sensitivity of the insurer's liability to
volatility risk. Since the GMWB payoff is highly path-dependent, it is
particularly sensitive to volatility risk, and can also be challenging to
price, especially in the presence of the VIX-linked fee. In this paper, we
present an explicit weak solution for the value of the VA account and use it in
Monte Carlo simulations to value the GMWB guarantee. Numerical examples are
provided to analyze the impact of the VIX-linked fee on the sensitivity of the
liability to changes in market volatility.
</summary>
    <author>
      <name>Michael A. Kouritzin</name>
    </author>
    <author>
      <name>Anne MacKay</name>
    </author>
    <link href="http://arxiv.org/abs/1708.06886v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.06886v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1710.01578v1</id>
    <updated>2017-10-04T12:47:49Z</updated>
    <published>2017-10-04T12:47:49Z</published>
    <title>The Computational Complexity of Clearing Financial Networks with Credit
  Default Swaps</title>
    <summary>  We consider the problem of clearing a system of interconnected banks. Prior
work has shown that when banks can only enter into simple debt contracts with
each other, then a clearing vector of payments can be computed in polynomial
time. In this work, we show that the computational complexity of the clearing
problem drastically increases when banks can also enter into credit default
swaps (CDSs), i.e., financial derivative contracts that depend on the default
of another bank. We first show that many important decision problems are
NP-hard once CDSs are allowed. This includes deciding if a specific bank is at
risk of default and deciding if a clearing vector exists in the first place.
Second, we show that computing an approximate solution to the clearing problem
with sufficiently small constant error is PPAD-complete. To prove our results,
we demonstrate how financial networks with debt and CDSs can encode Boolean and
arithmetic operations. Our results have practical importance for network stress
tests and they reveal computational complexity as a new concern regarding the
stability of the financial system.
</summary>
    <author>
      <name>Steffen Schuldenzucker</name>
    </author>
    <author>
      <name>Sven Seuken</name>
    </author>
    <author>
      <name>Stefano Battiston</name>
    </author>
    <link href="http://arxiv.org/abs/1710.01578v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1710.01578v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1710.02127v1</id>
    <updated>2017-10-05T17:39:47Z</updated>
    <published>2017-10-05T17:39:47Z</published>
    <title>Intervention On Default Contagion Under Partial Information</title>
    <summary>  We model the default contagion process in a large heterogeneous financial
network under the interventions of a regulator (a central bank) with only
partial information which is a more realistic setting than most current
literature. We provide the analytical results for the asymptotic optimal
intervention policies and the asymptotic magnitude of default contagion in
terms of the network characteristics. We extend the results of Amini et al.
(2013) to incorporate interventions and the model of Amini et al. (2015); Amini
et al. (2017) to heterogeneous networks with a given degree sequence and
arbitrary initial equity levels. The insights from the results are that the
optimal intervention policy is "monotonic" in terms of the intervention cost,
the closeness to invulnerability and connectivity. Moreover, we should keep
intervening on a bank once we have intervened on it. Our simulation results
show a good agreement with the theoretical results.
</summary>
    <author>
      <name>Yang Xu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">63 pages, 9 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1710.02127v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1710.02127v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cond-mat/9808295v1</id>
    <updated>1998-08-26T19:42:55Z</updated>
    <published>1998-08-26T19:42:55Z</published>
    <title>Probability distribution of drawdowns in risky investments</title>
    <summary>  We study the risk criterion for investments based on the drawdown from the
maximal value of the capital in the past. Depending on investor's risk
attitude, thus his risk exposure, we find that the distribution of these
drawdowns follows a general power law. In particular, if the risk exposure is
Kelly-optimal, the exponent of this power law has the borderline value of 2,
i.e. the average drawdown is just about to diverge
</summary>
    <author>
      <name>Sergei Maslov</name>
    </author>
    <author>
      <name>Yi-Cheng Zhang</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/S0378-4371(98)00416-6</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/S0378-4371(98)00416-6" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 4 figures (included)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Physica A 262, 232-241 (1999).</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cond-mat/9808295v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cond-mat/9808295v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cond-mat/0102304v1</id>
    <updated>2001-02-16T18:11:50Z</updated>
    <published>2001-02-16T18:11:50Z</published>
    <title>Expected Shortfall as a Tool for Financial Risk Management</title>
    <summary>  We study the properties of Expected Shortfall from the point of view of
financial risk management. This measure --- which emerges as a natural remedy
in some cases where Value at Risk (VaR) is not able to distinguish portfolios
which bear different levels of risk --- is indeed shown to have much better
properties than VaR. We show in fact that unlike VaR this variable is in
general subadditive and therefore it is a Coherent Measure of Risk in the sense
of reference (artzner)
</summary>
    <author>
      <name>Carlo Acerbi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Derivatives Desk, Abaxbank, Milano Italy</arxiv:affiliation>
    </author>
    <author>
      <name>Claudio Nordio</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Derivatives Desk, Abaxbank, Milano Italy</arxiv:affiliation>
    </author>
    <author>
      <name>Carlo Sirtori</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Derivatives Desk, Abaxbank, Milano Italy</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/cond-mat/0102304v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cond-mat/0102304v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cond-mat/0105191v1</id>
    <updated>2001-05-09T12:30:37Z</updated>
    <published>2001-05-09T12:30:37Z</published>
    <title>Expected Shortfall: a natural coherent alternative to Value at Risk</title>
    <summary>  We discuss the coherence properties of Expected Shortfall (ES) as a financial
risk measure. This statistic arises in a natural way from the estimation of the
"average of the 100p % worst losses" in a sample of returns to a portfolio.
Here p is some fixed confidence level. We also compare several alternative
representations of ES which turn out to be more appropriate for certain
purposes.
</summary>
    <author>
      <name>Carlo Acerbi</name>
    </author>
    <author>
      <name>Dirk Tasche</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">to be published on "Wilmott Magazine" (http://www.wilmott.com)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Economic notes, 31(2), 379-388, 2002</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cond-mat/0105191v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cond-mat/0105191v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cond-mat/0107208v1</id>
    <updated>2001-07-10T18:36:52Z</updated>
    <published>2001-07-10T18:36:52Z</published>
    <title>Introducing Variety in Risk Management</title>
    <summary>  We review the recently introduced concept of variety of a financial portfolio
and we sketch its importance for risk control purposes. The empirical behaviour
of variety, correlation, exceedance correlation and asymmetry of the
probability density function of daily returns is discussed. The results
obtained are compared with the ones of a one-factor model showing strengths and
limitations of this model.
</summary>
    <author>
      <name>Fabrizio Lillo</name>
    </author>
    <author>
      <name>Rosario N. Mantegna</name>
    </author>
    <author>
      <name>Jean-Philippe Bouchaud</name>
    </author>
    <author>
      <name>Marc Potters</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 5 figures, to appear in Risk</arxiv:comment>
    <link href="http://arxiv.org/abs/cond-mat/0107208v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cond-mat/0107208v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cond-mat/0204593v2</id>
    <updated>2002-10-12T15:04:17Z</updated>
    <published>2002-04-28T14:49:25Z</published>
    <title>A shortcut to sign Incremental Value-at-Risk for risk allocation</title>
    <summary>  Approximate Incremental Value-at-Risk formulae provide an easy-to-use
preliminary guideline for risk allocation. Both the cases of risk adding and
risk pooling are examined and beta-based formulae achieved. Results highlight
how much the conditions for adding new risky positions are stronger than those
required for risk pooling.
  Key words: Incremental Value-at-Risk (IVaR); Risk pooling; Risk adding.
</summary>
    <author>
      <name>Dirk Tasche</name>
    </author>
    <author>
      <name>Luisa Tibiletti</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, LaTeX with hyperref, minor corrections</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Risk Finance 2(4) (Winter 2003), 43-46</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cond-mat/0204593v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cond-mat/0204593v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cond-mat/0207750v2</id>
    <updated>2002-11-24T18:51:12Z</updated>
    <published>2002-07-31T16:21:54Z</published>
    <title>Credit Risk Contributions to Value-at-Risk and Expected Shortfall</title>
    <summary>  This paper presents analytical solutions to the problem of how to calculate
sensible VaR (Value-at-Risk) and ES (Expected Shortfall) contributions in the
CreditRisk+ methodology. Via the ES contributions, ES itself can be exactly
computed in finitely many steps. The methods are illustrated by numerical
examples.
</summary>
    <author>
      <name>Alexandre Kurth</name>
    </author>
    <author>
      <name>Dirk Tasche</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, LaTeX with hyperref package, references updated</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Risk 16(3) (March 2003), 84-88</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cond-mat/0207750v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cond-mat/0207750v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cond-mat" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.CP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cond-mat/0305038v1</id>
    <updated>2003-05-02T10:57:13Z</updated>
    <published>2003-05-02T10:57:13Z</published>
    <title>A traffic lights approach to PD validation</title>
    <summary>  As a consequence of the dependence experienced in loan portfolios, the
standard binomial test which is based on the assumption of independence does
not appear appropriate for validating probabilities of default (PDs). The model
underlying the new rules for minimum capital requirements (Basle II) is taken
as a point of departure for deriving two parametric test procedures that
incorporate dependence effects. The first one makes use of the so-called
granularity adjustment approach while the the second one is based on moment
matching.
</summary>
    <author>
      <name>Dirk Tasche</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, LaTeX with hyperref package</arxiv:comment>
    <link href="http://arxiv.org/abs/cond-mat/0305038v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cond-mat/0305038v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cond-mat" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cond-mat/0401378v1</id>
    <updated>2004-01-21T07:29:14Z</updated>
    <published>2004-01-21T07:29:14Z</published>
    <title>Long range Ising model for credit risk modeling in homogeneous
  portfolios</title>
    <summary>  Within the framework of maximum entropy principle we show that the
finite-size long-range Ising model is the adequate model for the description of
homogeneous credit portfolios and the computation of credit risk when default
correlations between the borrowers are included. The exact analysis of the
model suggest that when the correlation increases a first-order-like transition
may occur inducing a sudden risk increase. Such a feature is not reproduced by
the standard models used in credit risk modeling.
</summary>
    <author>
      <name>Jordi Molins</name>
    </author>
    <author>
      <name>Eduard Vives</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cond-mat/0401378v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cond-mat/0401378v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cond-mat.other" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.other" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cond-mat/0402390v2</id>
    <updated>2004-02-18T19:19:35Z</updated>
    <published>2004-02-14T16:36:50Z</published>
    <title>The single risk factor approach to capital charges in case of correlated
  loss given default rates</title>
    <summary>  A new methodology for incorporating LGD correlation effects into the Basel II
risk weight functions is introduced. This methodology is based on modelling of
LGD and default event with a single loss variable. The resulting formulas for
capital charges are numerically compared to the current proposals by the Basel
Committee on Banking Supervision.
  Keywords: Regulatory capital charge, loss given default (LGD).
</summary>
    <author>
      <name>Dirk Tasche</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, LaTeX</arxiv:comment>
    <link href="http://arxiv.org/abs/cond-mat/0402390v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cond-mat/0402390v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cond-mat.other" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.other" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/math/9806030v2</id>
    <updated>1998-09-02T17:14:23Z</updated>
    <published>1998-06-07T15:13:33Z</published>
    <title>Insurance policy value and Pareto-optimal retention in the hypothesis of
  rare loss events</title>
    <summary>  In the hypothesis of rare loss events, the general expression of the policy
value has been determined as a functional of the "expected frequency / loss
severity" function and of the retention function. Exponential disutility has
been chosen after mathematical characterization of some of its economical
aspects, where functional properties of quasiarithmetic averages have been
used. By means of variational techniques, in the case of a risk neutral Insurer
the Pareto-optimal retention function has been finally determined.
</summary>
    <author>
      <name>Renato Ghisellini</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">33 pages; PDF and PS; three references added; independence hypothesis
  no more invoked in deriving eq. (16), that holds true in any case; typos
  corrected</arxiv:comment>
    <link href="http://arxiv.org/abs/math/9806030v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/math/9806030v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="60G35" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/math/0309211v1</id>
    <updated>2003-09-12T10:19:33Z</updated>
    <published>2003-09-12T10:19:33Z</published>
    <title>Value-at-Risk and expected shortfall for linear portfolios with
  elliptically distributed risk factors</title>
    <summary>  In this paper, we generalize the parametric delta-VaR method from portfolios
with normally distributed risk factors to portfolios with elliptically
distributed ones. We treat both the expected shortfall and the Value-at-Risk of
such portfolios. Special attention is given to the particular case of a
multivariate t-distribution.
</summary>
    <author>
      <name>Jules Sadefo Kamdem</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper has been presented to the workshop of Financial
  Engineering du 6-8 Mai 2003 at Bad Herrelnab Germany. it is a preprint of
  Reims university and it is downloadble at
  http://www.univ-reims.fr\Labos\Mathematiques\pub03.html</arxiv:comment>
    <link href="http://arxiv.org/abs/math/0309211v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/math/0309211v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.CA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/math/0605064v1</id>
    <updated>2006-05-02T14:59:24Z</updated>
    <published>2006-05-02T14:59:24Z</published>
    <title>Pricing and hedging in incomplete markets with coherent risk</title>
    <summary>  We propose a pricing technique based on coherent risk measures, which enables
one to get finer price intervals than in the No Good Deals pricing. The main
idea consists in splitting a liability into several parts and selling these
parts to different agents. The technique is closely connected with the
convolution of coherent risk measures and equilibrium considerations.
  Furthermore, we propose a way to apply the above technique to the coherent
estimation of the Greeks.
</summary>
    <author>
      <name>Alexander S. Cherny</name>
    </author>
    <author>
      <name>Dilip B. Madan</name>
    </author>
    <link href="http://arxiv.org/abs/math/0605064v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/math/0605064v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B24; 91B30; 91B50" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/math/0605065v1</id>
    <updated>2006-05-02T15:05:50Z</updated>
    <published>2006-05-02T15:05:50Z</published>
    <title>CAPM, rewards, and empirical asset pricing with coherent risk</title>
    <summary>  The paper has 2 main goals: 1. We propose a variant of the CAPM based on
coherent risk. 2. In addition to the real-world measure and the risk-neutral
measure, we propose the third one: the extreme measure. The introduction of
this measure provides a powerful tool for investigating the relation between
the first two measures. In particular, this gives us - a new way of measuring
reward; - a new approach to the empirical asset pricing.
</summary>
    <author>
      <name>Alexander S. Cherny</name>
    </author>
    <author>
      <name>Dilip B. Madan</name>
    </author>
    <link href="http://arxiv.org/abs/math/0605065v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/math/0605065v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B28; 91B30, 91B50" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/math/0607212v1</id>
    <updated>2006-07-08T00:47:04Z</updated>
    <published>2006-07-08T00:47:04Z</published>
    <title>Time Consistent Dynamic Risk Processes, Cadlag Modification</title>
    <summary>  Working in a continuous time setting, we extend to the general case of
dynamic risk measures continuous from above the characterization of time
consistency in terms of ``cocycle condition'' of the minimal penalty function.
We prove also the supermartingale property for general time consistent dynamic
risk measures. When the time consistent dynamic risk measure (continuous from
above) is normalized and non degenerate, we prove, under a mild condition, that
the dynamic risk process of any financial instrument has a cadlag modification.
This condition is always satisfied in case of continuity from below.
</summary>
    <author>
      <name>Jocelyne Bion-Nadal</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">23 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/math/0607212v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/math/0607212v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="46A20; 91B30; 91B70" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/math/0610489v1</id>
    <updated>2006-10-16T15:04:21Z</updated>
    <published>2006-10-16T15:04:21Z</published>
    <title>Error calculus and path sensitivity in financial models</title>
    <summary>  In the framework of risk management, for the study of the sensitivity of
pricing and hedging in stochastic financial models to changes of parameters and
to perturbations of the stock prices, we propose an error calculus which is an
extension of the Malliavin calculus based on Dirichlet forms. Although useful
also in physics, this error calculus is well adapted to stochastic analysis and
seems to be the best practicable in finance. This tool is explained here
intuitively and with some simple examples.
</summary>
    <author>
      <name>Nicolas Bouleau</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CERMICS</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Mathematical Finance 13 (2003) n1, 115-134</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/math/0610489v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/math/0610489v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/math/0611187v1</id>
    <updated>2006-11-07T13:50:59Z</updated>
    <published>2006-11-07T13:50:59Z</published>
    <title>Local asymptotic minimax risk bounds in a locally asymptotically mixture
  of normal experiments under asymmetric loss</title>
    <summary>  Local asymptotic minimax risk bounds in a locally asymptotically mixture of
normal family of distributions have been investigated under asymmetric loss
functions and the asymptotic distribution of the optimal estimator that attains
the bound has been obtained.
</summary>
    <author>
      <name>Debasis Bhattacharya</name>
    </author>
    <author>
      <name>A. K. Basu</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1214/074921706000000527</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1214/074921706000000527" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published at http://dx.doi.org/10.1214/074921706000000527 in the IMS
  Lecture Notes--Monograph Series
  (http://www.imstat.org/publications/lecnotes.htm) by the Institute of
  Mathematical Statistics (http://www.imstat.org)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IMS Lecture Notes--Monograph Series 2006, Vol. 49, 312-321</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/math/0611187v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/math/0611187v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62C20, 62F12 (Primary) 62E20, 62C99 (Secondary)" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/math/0703862v2</id>
    <updated>2007-10-05T04:05:13Z</updated>
    <published>2007-03-29T02:24:54Z</published>
    <title>Optimal Deferred Life Annuities to Minimize the Probability of Lifetime
  Ruin</title>
    <summary>  We find the minimum probability of lifetime ruin of an investor who can
invest in a market with a risky and a riskless asset and can purchase a
deferred annuity. Although we let the admissible set of strategies of annuity
purchasing process to be increasing adapted processes, we find that the
individual will not buy a deferred life annuity unless she can cover all her
consumption via the annuity and have enough wealth left over to sustain her
until the end of the deferral period.
</summary>
    <author>
      <name>Erhan Bayraktar</name>
    </author>
    <author>
      <name>Virginia R. Young</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Key Words: Life annuities, retirement, optimal investment, stochastic
  control, free boundary problem</arxiv:comment>
    <link href="http://arxiv.org/abs/math/0703862v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/math/0703862v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/nlin/0209010v1</id>
    <updated>2002-09-03T20:01:33Z</updated>
    <published>2002-09-03T20:01:33Z</published>
    <title>Implications of Correlated Default For Portfolio Allocation To Corporate
  Bonds</title>
    <summary>  This article deals with the problem of optimal allocation of capital to
corporate bonds in fixed income portfolios when there is the possibility of
correlated defaults. Using a multivariate normal Copula function for the joint
default probabilities we show that retaining the first few moments of the
portfolio default loss distribution gives an extremely good approximation to
the full solution of the asset allocation problem. We provide detailed results
on the convergence of the moment expansion and explore how the optimal
portfolio allocation depends on recovery fractions, level of diversification
and investment time horizon. Numerous numerical illustrations exhibit the
results for simple portfolios and utility functions.
</summary>
    <author>
      <name>Mark B. Wise</name>
    </author>
    <author>
      <name>Vineer Bhansali</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/nlin/0209010v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/nlin/0209010v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/physics/0608035v1</id>
    <updated>2006-08-03T09:23:12Z</updated>
    <published>2006-08-03T09:23:12Z</published>
    <title>Risk Minimization through Portfolio Replication</title>
    <summary>  We use a replica approach to deal with portfolio optimization problems. A
given risk measure is minimized using empirical estimates of asset values
correlations. We study the phase transition which happens when the time series
is too short with respect to the size of the portfolio. We also study the noise
sensitivity of portfolio allocation when this transition is approached. We
consider explicitely the cases where the absolute deviation and the conditional
value-at-risk are chosen as a risk measure. We show how the replica method can
study a wide range of risk measures, and deal with various types of time series
correlations, including realistic ones with volatility clustering.
</summary>
    <author>
      <name>Stefano Ciliberti</name>
    </author>
    <author>
      <name>Marc Mezard</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1140/epjb/e2007-00130-7</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1140/epjb/e2007-00130-7" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, APFA5 conference</arxiv:comment>
    <link href="http://arxiv.org/abs/physics/0608035v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/physics/0608035v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/physics/0608190v1</id>
    <updated>2006-08-18T11:19:56Z</updated>
    <published>2006-08-18T11:19:56Z</published>
    <title>On Value at Risk for foreign exchange rates - the copula approach</title>
    <summary>  The aim of this paper is to determine the Value at Risk (VaR) of the
portfolio consisting of long positions in foreign currencies on an emerging
market. Basing on empirical data we restrict ourselves to the case when the
tail parts of distributions of logarithmic returns of these assets follow the
power laws and the lower tail of associated copula C follows the power law of
degree 1. We will illustrate the practical usefulness of this approach by the
analysis of the exchange rates of EUR and CHF at the Polish forex market.
</summary>
    <author>
      <name>Piotr Jaworski</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To be published in Acta Phys. Pol. B</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Acta Phys. Pol. B 37, 3005 (2006)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/physics/0608190v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/physics/0608190v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/physics/0609164v1</id>
    <updated>2006-09-20T07:08:46Z</updated>
    <published>2006-09-20T07:08:46Z</published>
    <title>Credit contagion and credit risk</title>
    <summary>  We study a simple, solvable model that allows us to investigate effects of
credit contagion on the default probability of individual firms, in both
portfolios of firms and on an economy wide scale. While the effect of
interactions may be small in typical (most probable) scenarios they are
magnified, due to feedback, by situations of economic stress, which in turn
leads to fatter tails in loss distributions of large loan portfolios.
</summary>
    <author>
      <name>J. P. L. Hatchett</name>
    </author>
    <author>
      <name>R. Kuehn</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/physics/0609164v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/physics/0609164v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0705.0053v3</id>
    <updated>2008-03-19T21:14:45Z</updated>
    <published>2007-05-01T01:21:40Z</published>
    <title>Mutual Fund Theorems when Minimizing the Probability of Lifetime Ruin</title>
    <summary>  We show that the mutual fund theorems of Merton (1971) extend to the problem
of optimal investment to minimize the probability of lifetime ruin. We obtain
two such theorems by considering a financial market both with and without a
riskless asset for random consumption. The striking result is that we obtain
two-fund theorems despite the additional source of randomness from consumption.
</summary>
    <author>
      <name>Erhan Bayraktar</name>
    </author>
    <author>
      <name>Virginia R. Young</name>
    </author>
    <link href="http://arxiv.org/abs/0705.0053v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0705.0053v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.PM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="93E20 (Primary) 91B28 (Secondary)" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
