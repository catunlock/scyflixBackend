<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3Dall%3Aq-fin.EC%26id_list%3D%26start%3D0%26max_results%3D500" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=all:q-fin.EC&amp;id_list=&amp;start=0&amp;max_results=500</title>
  <id>http://arxiv.org/api/r0XHcrX7H6+Asc5CTj+CTHScprg</id>
  <updated>2017-10-08T00:00:00-04:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">505</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">500</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/1506.08743v1</id>
    <updated>2015-06-29T17:28:24Z</updated>
    <published>2015-06-29T17:28:24Z</published>
    <title>Note on tax enforcement and transfer pricing manipulation</title>
    <summary>  This note proposes the segregation of independent endogenous and exogenous
components of tax penalty probability to introduce a formal demonstration that
enforcement and tax penalties are negatively related with income shifting. JEL
F23; H26.
</summary>
    <author>
      <name>Alex Augusto Timm Rathke</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1506.08743v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.08743v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1602.06188v1</id>
    <updated>2016-02-14T19:22:42Z</updated>
    <published>2016-02-14T19:22:42Z</published>
    <title>Blunt Honesty, Incentives, and Knowledge Exchange</title>
    <summary>  We propose a simple mechanism to facilitate the buying and selling of useful,
bluntly honest information. The for-profit, arm's length knowledge exchange
this mechanism enables may dramatically increase the pace of scientific
progress.
</summary>
    <author>
      <name>Bruce Knuteson</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1602.06188v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1602.06188v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.05545v1</id>
    <updated>2016-05-18T12:19:03Z</updated>
    <published>2016-05-18T12:19:03Z</published>
    <title>Elections in Russia, 1991-2008</title>
    <summary>  In this paper, I review the main trends in voting in national elections in
Russia since 1991, discuss the evidence of manipulation or falsification by the
authorities, and use statistical techniques to examine the determinants of
voting trends.
</summary>
    <author>
      <name>Daniel Treisman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">38 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1605.05545v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.05545v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B12 (Primary), 91F10 (Secondary)" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.04816v1</id>
    <updated>2016-05-23T05:34:16Z</updated>
    <published>2016-05-23T05:34:16Z</published>
    <title>Note on level r consensus</title>
    <summary>  We show that the hierarchy of level $r$ consensus partially collapses. In
particular, any profile $\pi\in \mathcal{P}$ that exhibits consensus of level
$(K-1)!$ around $\succ_0$ in fact exhibits consensus of level $1$ around
$\succ_0$.
</summary>
    <author>
      <name>Nikolay L. Poliakov</name>
    </author>
    <link href="http://arxiv.org/abs/1606.04816v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.04816v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.02378v1</id>
    <updated>2016-07-05T19:31:28Z</updated>
    <published>2016-07-05T19:31:28Z</published>
    <title>Matrix-vector representation of various solution concepts</title>
    <summary>  A unified matrix-vector representation is developed of such solution concepts
as the core, the uncovered, the uncaptured, the minimal weakly stable, the
minimal undominated, the minimal dominant and the untrapped sets. We also
propose several new versions of solution sets.
</summary>
    <author>
      <name>Fuad Aleskerov</name>
    </author>
    <author>
      <name>Andrey Subochev</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">32 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1607.02378v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.02378v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B14" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.02419v1</id>
    <updated>2016-07-05T19:25:02Z</updated>
    <published>2016-07-05T19:25:02Z</published>
    <title>Divisive-agglomerative algorithm and complexity of automatic
  classification problems</title>
    <summary>  An algorithm of solution of the Automatic Classification (AC for brevity)
problem is set forth in the paper. In the AC problem, it is required to find
one or several artitions, starting with the given pattern matrix or
dissimilarity, similarity matrix.
</summary>
    <author>
      <name>Alexander Rubchinsky</name>
    </author>
    <link href="http://arxiv.org/abs/1607.02419v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.02419v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62H30" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.5.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.02421v1</id>
    <updated>2016-07-05T19:11:33Z</updated>
    <published>2016-07-05T19:11:33Z</published>
    <title>Alternative versions of the global competitive industrial performance
  ranking constructed by methods from social choice theory</title>
    <summary>  The Competitive Industrial Performance index (developed by experts of the
UNIDO) is designed as a measure of national competitiveness. Index is an
aggregate of eight observable variables, representing different dimensions of
competitive industrial performance.
</summary>
    <author>
      <name>Andrey Subochev</name>
    </author>
    <author>
      <name>Igor Zakhlebin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">30 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1607.02421v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.02421v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B14" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.6.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.01351v1</id>
    <updated>2016-07-17T14:12:17Z</updated>
    <published>2016-07-17T14:12:17Z</published>
    <title>Multidimensional Polarization Index and its Application to an Analysis
  of the Russian State Duma</title>
    <summary>  The multidimensional extension of the Aleskerov-Golubenko polarization index
is developed. Several versions of the polarization index are proposed based on
different distance functions. Basic properties of the index are examined.
</summary>
    <author>
      <name>Fuad Aleskerov</name>
    </author>
    <author>
      <name>Victoria Oleynik</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">52 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1608.01351v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.01351v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B14 (Primary), 91C15 (Secondary)" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.6.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.07783v1</id>
    <updated>2017-06-23T17:28:25Z</updated>
    <published>2017-06-23T17:28:25Z</published>
    <title>Intergenerational mobility measures in a bivariate normal model</title>
    <summary>  We model the joint log-income distribution of parents and children and derive
analytic expressions for canonical relative and absolute intergenerational
mobility measures. We find that both types of mobility measures can be
expressed as a function of the other.
</summary>
    <author>
      <name>Yonatan Berman</name>
    </author>
    <link href="http://arxiv.org/abs/1706.07783v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.07783v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1406.7115v2</id>
    <updated>2014-09-01T13:37:22Z</updated>
    <published>2014-06-27T08:57:37Z</published>
    <title>Income Inequality in the 21st Century -- A biased summary of Piketty's
  Capital in the Twenty-First Century</title>
    <summary>  Capital usually leads to income, and income is more accurately and easily
measured. Thus we summarize income distributions in USA, Germany, etc.
</summary>
    <author>
      <name>Dietrich Stauffer</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Two pages plus many figures. Revision corrects typos and enlarges
  captions 1 and 4</arxiv:comment>
    <link href="http://arxiv.org/abs/1406.7115v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1406.7115v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1408.1022v2</id>
    <updated>2014-08-06T00:34:52Z</updated>
    <published>2014-08-05T16:25:08Z</published>
    <title>A Note on Kuhn's Theorem with Ambiguity Averse Players</title>
    <summary>  Kuhn's Theorem shows that extensive games with perfect recall can
equivalently be analyzed using mixed or behavioral strategies, as long as
players are expected utility maximizers. This note constructs an example that
illustrate the limits of Kuhn's Theorem in an environment with ambiguity averse
players who use maxmin decision rule and full Bayesian updating.
</summary>
    <author>
      <name>Gaurab Aryal</name>
    </author>
    <author>
      <name>Ronald Stauber</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.econlet.2014.08.018</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.econlet.2014.08.018" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1408.1022v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1408.1022v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1409.4541v1</id>
    <updated>2014-09-16T09:05:38Z</updated>
    <published>2014-09-16T09:05:38Z</published>
    <title>Visualising stock flow consistent models as directed acyclic graphs</title>
    <summary>  We show how every stock-flow consistent model of the macroeconomy can be
represented as a directed acyclic graph. The advantages of representing the
model in this way include graphical clarity, causal inference, and model
specification. We provide many examples implemented with a new software
package.
</summary>
    <author>
      <name>Peter G. Fennell</name>
    </author>
    <author>
      <name>David O'Sullivan</name>
    </author>
    <author>
      <name>Antoine Godin</name>
    </author>
    <author>
      <name>Stephen Kinsella</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1409.4541v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1409.4541v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1409.4857v2</id>
    <updated>2014-10-03T17:11:20Z</updated>
    <published>2014-09-17T03:11:36Z</published>
    <title>A simple dynamical model leading to Pareto wealth distribution and
  stability</title>
    <summary>  We propose a simple dynamical model of wealth evolution. The invariant
distributions are of Pareto type and are dynamically stable as conjectured by
Pareto.
</summary>
    <author>
      <name>Ricardo Pérez-Marco</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages. Formulas corrected from version 1. Results unchanged</arxiv:comment>
    <link href="http://arxiv.org/abs/1409.4857v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1409.4857v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B55, 91B82, 91A60" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.2746v1</id>
    <updated>2014-12-07T10:28:44Z</updated>
    <published>2014-12-07T10:28:44Z</published>
    <title>Taxation as an instrument of stimulation of innovation-active business
  entities</title>
    <summary>  The analysis of the theoretical material revealed the lack of consensus on
defini-tion of the tax stimulation of innovation-active business entities
within the re-gional taxation. The definition tax stimulation of
innovation-active business en-tities is specified.
</summary>
    <author>
      <name>Andrey Nechaev</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">innovation; business entity; taxation; tax rate; return on assets</arxiv:comment>
    <link href="http://arxiv.org/abs/1412.2746v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.2746v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62-07" scheme="http://arxiv.org/schemas/atom"/>
    <category term="K.6.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.02476v1</id>
    <updated>2015-08-11T03:14:10Z</updated>
    <published>2015-08-11T03:14:10Z</published>
    <title>A Model for Tax Evasion with Some Realistic Properties</title>
    <summary>  We present a discrete-time dynamic model of income tax evasion. The model is
solved exactly in the case of a single taxpayer and shown to have some
realistic properties, including avoiding the Yitzhaki paradox. The extension to
an agent-based model with a network of taxpayers is also investigated.
</summary>
    <author>
      <name>Richard Vale</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1508.02476v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.02476v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1509.01214v1</id>
    <updated>2015-06-20T09:40:20Z</updated>
    <published>2015-06-20T09:40:20Z</published>
    <title>The Poker-Litigation Game</title>
    <summary>  Is litigation a serious search for truth or simply a game of skill or luck?
Although the process of litigation has been modeled as a Prisoner's Dilemma, as
a War of Attrition, as a Game of Chicken and even as a simple coin toss, no one
has formally modeled litigation as a game of poker. This paper is the first to
do so. We present a simple "poker-litigation game" and find the optimal
strategy for playing this game.
</summary>
    <author>
      <name>Enrique Guerra-Pujol</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages, 1 appendix</arxiv:comment>
    <link href="http://arxiv.org/abs/1509.01214v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1509.01214v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.06337v1</id>
    <updated>2015-10-20T00:41:53Z</updated>
    <published>2015-10-20T00:41:53Z</published>
    <title>Mathematics of Predicting Growth</title>
    <summary>  Mathematical methods of analysis of data and of predicting growth are
discussed. The starting point is the analysis of the growth rates, which can be
expressed as a function of time or as a function of the size of the growing
entity. Application of these methods is illustrated using the world economic
growth but they can be applied to any other type of growth.
</summary>
    <author>
      <name>Ron W Nielsen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages, 5 figures, 1 table, 5382 words</arxiv:comment>
    <link href="http://arxiv.org/abs/1510.06337v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.06337v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.02422v1</id>
    <updated>2016-07-05T19:04:19Z</updated>
    <published>2016-07-05T19:04:19Z</published>
    <title>Rating models: emerging market distinctions</title>
    <summary>  The Basel II Accords have sparked increased interest in the development of
approaches based on internal ratings systems and have initiated the elaboration
of models for remote ratings forecasts based on external ones as part of Risk
Management and Early Warning Systems. This article evaluates the peculiarities
of current ratings systems and addresses specific issues of development of
econometrical rating models for emerging market companies.
</summary>
    <author>
      <name>Alexander Karminsky</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">34 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1607.02422v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.02422v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B82 (Primary), 62P20 (Secondary)" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.6.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.02423v1</id>
    <updated>2016-07-05T19:05:36Z</updated>
    <published>2016-07-05T19:05:36Z</published>
    <title>Fair division with divisible and indivisible items</title>
    <summary>  In the work the fair division problem for two participants in presence of
both divisible and indivisible items is considered. The set of all divisions is
formally described; it is demonstrated that fair (in terms of Brams and Taylor)
divisions, unlikely the case where all the items are divisible, not always
exist. The necessary and sufficient conditions of existence of proportional and
equitable division were found.
</summary>
    <author>
      <name>Alexander Rubchinsky</name>
    </author>
    <link href="http://arxiv.org/abs/1607.02423v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.02423v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="90B50 (Primary), 90C09 (Secondary)" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.6.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.07318v1</id>
    <updated>2016-11-12T11:53:38Z</updated>
    <published>2016-11-12T11:53:38Z</published>
    <title>Research and Teaching Efficiencies of Turkish Universities with
  Heterogeneity Considerations: Application of Multi-Activity DEA and DEA by
  Sequential Exclusion of Alternatives Methods</title>
    <summary>  The research and teaching efficiencies of 45 Turkish state universities are
evaluated by using Multi-Activity Data Envelopment Analysis (MA-DEA) model
developed by Beasley (1995). Universities are multi-purpose institutions,
therefore they face multiple production functions simultaneously associated
with research and teaching activities. MA-DEA allows assigning priorities and
allocating shared resources to these activities.
</summary>
    <author>
      <name>Y. Çinar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">24 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1701.07318v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.07318v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="90C29" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.6.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.06829v1</id>
    <updated>2017-07-21T10:37:14Z</updated>
    <published>2017-07-21T10:37:14Z</published>
    <title>Geopolitical Model of Investment Project Implementation</title>
    <summary>  Two geopolitical actors implement a geopolitical project that involves
transportaion and storage of some commodities. They interact with each other
through a transport network. The network consists of several interconnected
vertices. Some of the vetrices are trading hubs, storage spaces, production
hubs and goods buyers. Actors wish to satify the demand of buyers and recieve
the highest possible profit subject to compromise solution principle. A
numerical example is given.
</summary>
    <author>
      <name>Oleg Malafeyev</name>
    </author>
    <author>
      <name>Konstantin Farvazov</name>
    </author>
    <author>
      <name>Olga Zenovich</name>
    </author>
    <link href="http://arxiv.org/abs/1707.06829v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.06829v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.04952v1</id>
    <updated>2017-07-05T06:49:01Z</updated>
    <published>2017-07-05T06:49:01Z</published>
    <title>New Market Creation via Innovation: A Study on Tata Nano</title>
    <summary>  This research paper focuses on how innovations support new market creation
emerging from latent opportunities for low-income group. It also emphasizes on
novel strategies that can be implemented for sustaining. The paper concludes
with a discussion on the implications of the study and directions to stimulate
future research on the subject.
</summary>
    <author>
      <name>Swati Singh</name>
    </author>
    <author>
      <name>Manoj Joshi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">aWEshkar Vol. XIX Issue 2, Sept 2015</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1708.04952v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.04952v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.3225v1</id>
    <updated>2014-05-13T16:47:43Z</updated>
    <published>2014-05-13T16:47:43Z</published>
    <title>Can Analysts Predict Rallies Better Than Crashes?</title>
    <summary>  We use the copula approach to study the structure of dependence between
sell-side analysts' consensus recommendations and subsequent security returns,
with a focus on asymmetric tail dependence. We match monthly vintages of
I/B/E/S recommendations for the period January to December 2011 with excess
security returns during six months following recommendation issue. Using a
symmetrized Joe-Clayton Copula (SJC) model we find evidence to suggest that
analysts can identify stocks that will substantially outperform, but not
underperform relative to the market, and that their predictive ability is
conditional on recommendation changes.
</summary>
    <author>
      <name>Ivan Medovikov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1405.3225v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.3225v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62P20" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.4498v1</id>
    <updated>2014-05-18T12:59:05Z</updated>
    <published>2014-05-18T12:59:05Z</published>
    <title>The Economics of BitCoin Price Formation</title>
    <summary>  This paper analyses the relationship between BitCoin price and supply-demand
fundamentals of BitCoin, global macro-financial indicators and BitCoin
attractiveness for investors. Using daily data for the period 2009-2014 and
applying time-series analytical mechanisms, we find that BitCoin market
fundamentals and BitCoin attractiveness for investors have a significant impact
on BitCoin price. Our estimates do not support previous findings that the
macro-financial developments are driving BitCoin price.
</summary>
    <author>
      <name>Pavel Ciaian</name>
    </author>
    <author>
      <name>Miroslava Rajcaniova</name>
    </author>
    <author>
      <name>d'Artis Kancs</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Key words: BitCoin, exchange rate, supply-demand fundamentals,
  financial indicators, attractiveness JEL classification: E31; E42; G12</arxiv:comment>
    <link href="http://arxiv.org/abs/1405.4498v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.4498v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1406.1547v1</id>
    <updated>2014-06-05T23:35:17Z</updated>
    <published>2014-06-05T23:35:17Z</published>
    <title>Arbitrage-free exchange rate ensembles over a general trade network</title>
    <summary>  It is assumed that under suitable economic and information-theoretic
conditions, market exchange rates are free from arbitrage. Commodity markets in
which trades occur over a complete graph are shown to be trivial. We therefore
examine the vector space of no-arbitrage exchange rate ensembles over an
arbitrary connected undirected graph. Consideration is given for the minimal
information for determination of an exchange rate ensemble. We conclude with a
topical discussion of exchanges in which our analyses may be relevant,
including the emergent but highly-regulated (and therefore not a complete
graph) market for digital currencies.
</summary>
    <author>
      <name>Stan Palasek</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1406.1547v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1406.1547v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.TR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1406.5120v1</id>
    <updated>2014-06-15T08:11:35Z</updated>
    <published>2014-06-15T08:11:35Z</published>
    <title>Strategy-proofness and single-peackedness in bounded distributive
  lattices</title>
    <summary>  Two distinct specifications of single peakedness as currently met in the
relevant literature are singled out and discussed. Then, it is shown that,
under both of those specifications, a voting rule as defined on a bounded
distributive lattice is strategy-proof on the set of all profiles of single
peaked total preorders if and only if it can be represented as an iterated
median of projections and constants, or equivalently as the behaviour of a
certain median tree-automaton. The equivalence of individual and coalitional
strategy-proofness that is known to hold for single peaked domains in bounded
linear orders fails in such a general setting. A related impossibility result
on anonymous coalitionally strategy-proof voting rules is also obtained.
</summary>
    <author>
      <name>Ernesto Savaglio</name>
    </author>
    <author>
      <name>Stefano Vannucci</name>
    </author>
    <link href="http://arxiv.org/abs/1406.5120v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1406.5120v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="05C05, 52021, 52037" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1407.1726v1</id>
    <updated>2014-07-07T14:24:47Z</updated>
    <published>2014-07-07T14:24:47Z</published>
    <title>Superstars in politics: the role of the media in the rise and success of
  Junichiro Koizumi</title>
    <summary>  This paper explores the role of mass media in people perceptions of
charismatic leaders, focusing on the case of Junichiro Koizumi, Prime Minister
of Japan from 2001 to 2006. Using survey data collected immediately after his
2005 landslide electoral victory, this study empirically assesses the influence
of television and newspapers on support for Koizumi and for the most
distinctive policy action he announced during his campaign, the privatization
of the postal service.
</summary>
    <author>
      <name>Eiji Yamamura</name>
    </author>
    <author>
      <name>Fabio Sabatini</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Keywords mass media, television, newspapers, elections, Koizumi,
  Japan, superstar effect</arxiv:comment>
    <link href="http://arxiv.org/abs/1407.1726v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1407.1726v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1407.6222v1</id>
    <updated>2014-07-23T14:04:43Z</updated>
    <published>2014-07-23T14:04:43Z</published>
    <title>A finite set of equilibria for the indeterminacy of linear rational
  expectations models</title>
    <summary>  This paper demonstrates the existence of a finite set of equilibria in the
case of the indeterminacy of linear rational expectations models. The number of
equilibria corresponds to the number of ways to select n eigenvectors among a
larger set of eigenvectors related to stable eigenvalues. A finite set of
equilibria is a substitute to continuous (uncountable) sets of sunspots
equilibria, when the number of independent eigenvectors for each stable
eigenvalue is equal to one.
</summary>
    <author>
      <name>Jean-Bernard Chatelain</name>
    </author>
    <author>
      <name>Kirsten Ralf</name>
    </author>
    <link href="http://arxiv.org/abs/1407.6222v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1407.6222v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1407.7140v4</id>
    <updated>2015-06-22T18:34:03Z</updated>
    <published>2014-07-26T16:25:15Z</published>
    <title>Semiparametric Estimation of First-Price Auction Models</title>
    <summary>  We propose a semiparametric method to estimate the density of private values
in first-price auctions. Specifically, we model private values through a set of
conditional moment restrictions and use a two-step procedure. In the first step
we recover a sample of pseudo private values using Local Polynomial Estimator.
In the second step we use a GMM procedure to estimate the parameter(s) of
interest. We show that the proposed semiparametric estimator is consistent, has
an asymptotic normal distribution, and attains the parametric ("root-n") rate
of convergence.
</summary>
    <author>
      <name>Gaurab Aryal</name>
    </author>
    <author>
      <name>Maria Florencia Gabrielli</name>
    </author>
    <author>
      <name>Quang Vuong</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">66 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1407.7140v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1407.7140v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1408.1671v1</id>
    <updated>2014-08-06T09:59:18Z</updated>
    <published>2014-08-06T09:59:18Z</published>
    <title>Structural social capital and health in Italy</title>
    <summary>  This paper presents the first empirical assessment of the causal relationship
between social capital and health in Italy. The analysis draws on the 2000 wave
of the Multipurpose Survey on Household conducted by the Italian Institute of
Statistics on a representative sample of the population (n = 46,868). Our
measure of social capital is the frequency of meetings with friends. Based on
IV and bivariate probit estimates, we find that individuals who meet friends
every day or at least two times a week are approximately 11% to 16% more likely
to report good health.
</summary>
    <author>
      <name>Damiano Fiorillo</name>
    </author>
    <author>
      <name>Fabio Sabatini</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">46 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1408.1671v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1408.1671v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1408.6639v1</id>
    <updated>2014-08-28T07:46:55Z</updated>
    <published>2014-08-28T07:46:55Z</published>
    <title>Can Google searches help nowcast and forecast unemployment rates in the
  Visegrad Group countries?</title>
    <summary>  Online activity of the Internet users has been repeatedly shown to provide a
rich information set for various research fields. We focus on the job-related
searches on Google and their possible usefulness in the region of the Visegrad
Group -- the Czech Republic, Hungary, Poland and Slovakia. Even for rather
small economies, the online searches of their inhabitants can be successfully
utilized for macroeconomic predictions. Specifically, we study the unemployment
rates and their interconnection to the job-related searches. We show that the
Google searches strongly enhance both nowcasting and forecasting models of the
unemployment rates.
</summary>
    <author>
      <name>Jaroslav Pavlicek</name>
    </author>
    <author>
      <name>Ladislav Kristoufek</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1371/journal.pone.0127084</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1371/journal.pone.0127084" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">22 pages, 2 figures, 3 tables</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">PLoS ONE 10(5): e0127084, 2015</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1408.6639v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1408.6639v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1409.4387v1</id>
    <updated>2014-09-02T13:35:45Z</updated>
    <published>2014-09-02T13:35:45Z</published>
    <title>Indicators of availability of non-market relations in the sphere of
  labor market in Ukraine</title>
    <summary>  There are identified indicators of availability a non-market relations in the
sphere of labor market in Ukraine. It is concluded that illegal tax money paid
by legally working in Ukraine, as insurance premiums in the event of
unemployment. It is concluded that increased pressure from the government on
labor market regulators Ukraine established on a parity basis. There are
formulated recommendations for the implementation of the principle of a free
market economy in the regulation of the labor market of Ukraine.
</summary>
    <author>
      <name>Valery Tabakov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages in Ukrainian</arxiv:comment>
    <link href="http://arxiv.org/abs/1409.4387v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1409.4387v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.5466v4</id>
    <updated>2016-01-18T17:35:54Z</updated>
    <published>2014-10-20T21:09:01Z</published>
    <title>Conditional Preference Orders and their Numerical Representations</title>
    <summary>  We provide an axiomatic system modeling conditional preference orders which
is based on conditional set theory. Conditional numerical representations are
introduced, and a conditional version of the theorems of Debreu on the
existence of numerical representations is proved. The conditionally continuous
representations follow from a conditional version of Debreu's Gap Lemma the
proof of which relies on a conditional version of the axiom of choice, free of
any measurable selection argument. We give a conditional version of the von
Neumann and Morgenstern representation as well as automatic conditional
continuity results, and illustrate them by examples.
</summary>
    <author>
      <name>Samuel Drapeau</name>
    </author>
    <author>
      <name>Asgar Jamneshan</name>
    </author>
    <link href="http://arxiv.org/abs/1410.5466v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.5466v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B06" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.6084v1</id>
    <updated>2014-10-22T15:50:20Z</updated>
    <published>2014-10-22T15:50:20Z</published>
    <title>Is mathematics able to give insight into current questions in finance,
  economics and politics?</title>
    <summary>  Democrats in the US say that taxes can be used to "grease the wheels" of the
economy and create wealth enough to recover taxes and thereby increase
employment; the Republicans say that taxation discourages investment and so
increases unemployment. These arguments cannot both be correct, but both
arguments seem meritorious. Faced with this paradox, one might hope that a
rigorous mathematical approach might help determine which is the truth.
</summary>
    <author>
      <name>Larry Shepp</name>
    </author>
    <author>
      <name>Michael Imerman</name>
    </author>
    <link href="http://arxiv.org/abs/1410.6084v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.6084v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="60H30, 91B70" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.8427v1</id>
    <updated>2014-10-30T16:23:08Z</updated>
    <published>2014-10-30T16:23:08Z</published>
    <title>When does the stock market listen to economic news? New evidence from
  copulas and news wires</title>
    <summary>  We study association between macroeconomic news and stock market returns
using the statistical theory of copulas, and a new comprehensive measure of
news based on the indexing of news wires. We find the impact of economic news
on equity returns to be nonlinear and asymmetric. In particular, controlling
for economic conditions and surprises associated with releases of economic
data, we find that the market reacts strongly and negatively to the most
unfavourable macroeconomic news, but appears to largely discount the good news.
This relationship persists throughout the different stages of the business
cycle.
</summary>
    <author>
      <name>Ivan Medovikov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">37 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1410.8427v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.8427v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1411.2167v2</id>
    <updated>2016-07-27T12:55:07Z</updated>
    <published>2014-11-08T22:15:09Z</published>
    <title>Comeback kids: an evolutionary approach of the long-run innovation
  process</title>
    <summary>  We provide a theoretical framework to understand when firms may benefit from
exploiting previously abandoned technologies and brands. We model for the long
run process of innovation, allowing for sustainable diversity and comebacks of
old brands and technologies. We present two extensions to the logistic and
Lotka-Volterra equations, which describe the diffusion of an innovation. First,
we extend the short-term competition to a long-term process characterized by a
sequence of innovations and substitutions. Second, by allowing the
substitutions to be incomplete, we extend the one-dimensional process to a
tree-form multidimensional one featuring diversification throughout the
long-term development.
</summary>
    <author>
      <name>Shidong Wang</name>
    </author>
    <author>
      <name>Renaud Foucart</name>
    </author>
    <author>
      <name>Cheng Wan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">26 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1411.2167v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1411.2167v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.0950v1</id>
    <updated>2014-12-02T15:51:51Z</updated>
    <published>2014-12-02T15:51:51Z</published>
    <title>Firm size distribution in Italy and employment protection</title>
    <summary>  The number of Italian firms in function of the number of workers is well
approximated by an inverse power law up to 15 workers but shows a clear
downward deflection beyond this point, both when using old pre-1999 data and
when using recent (2014) data. This phenomenon could be associated with
employent protection legislation which applies to companies with more than 15
workers (the Statuto dei Lavoratori). The deflection disappears for agriculture
firms, for which the protection legislation applies already above 5 workers. In
this note it is estimated that a correction of this deflection could bring an
increase from 3.9 to 5.8% in new jobs in firms with a workforce between 5 to 25
workers.
</summary>
    <author>
      <name>Luca Amendola</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">ITP, University of Heidelberg</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/1412.0950v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.0950v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1501.00882v1</id>
    <updated>2014-12-19T16:15:30Z</updated>
    <published>2014-12-19T16:15:30Z</published>
    <title>Observing Each Other's Observations in the Electronic Mail Game</title>
    <summary>  We study a Bayesian coordination game where agents receive private
information on the game's payoff structure. In addition, agents receive private
signals on each other's private information. We show that once agents possess
these different types of information, there exists a coordination game in the
evaluation of this information. And even though the precisions of both signal
types is exogenous, the precision with which agents predict each other's
actions at equilibrium turns out to be endogenous. As a consequence, we find
that there exist multiple equilibria if the private signals' precision is high.
These equilibria differ with regard to the way that agents weight their private
information to reason about each other's actions.
</summary>
    <author>
      <name>Dominik Grafenhofer</name>
    </author>
    <author>
      <name>Wolgang Kuhle</name>
    </author>
    <link href="http://arxiv.org/abs/1501.00882v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1501.00882v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.05238v2</id>
    <updated>2017-03-03T10:31:47Z</updated>
    <published>2015-02-18T14:18:24Z</published>
    <title>Pareto Efficient Nash Implementation Via Approval Voting</title>
    <summary>  We study implementation of a social choice correspondence in the case of two
players who have von Neumann - Morgenstern utilities over a finite set of
social alternatives, and the mechanism is allowed to output lotteries. Our main
positive result shows that a close variant of the popular approval voting
mechanism succeeds in selecting only Pareto efficient alternatives as pure Nash
equilibria outcomes. Moreover, we provide an exact characterization of pure
Nash equilibria profiles and outcomes of the mechanism. The characterization
demonstrates a close connection between the approval voting mechanism and the
notion of average fixed point, which is a point that is equal to the average of
all points that it does not Pareto dominate.
</summary>
    <author>
      <name>Yakov Babichenko</name>
    </author>
    <author>
      <name>Leonard J. Schulman</name>
    </author>
    <link href="http://arxiv.org/abs/1502.05238v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.05238v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.06805v1</id>
    <updated>2015-02-24T13:38:03Z</updated>
    <published>2015-02-24T13:38:03Z</published>
    <title>International R&amp;D Spillovers and other Unobserved Common Spillovers and
  Shocks</title>
    <summary>  Studies which are based on Coe and Helpman (1995) and use weighted foreign
R&amp;D variables to estimate channel-specific R&amp;D spillovers disregard the
interaction between international R&amp;D spillovers and other unobserved common
spillovers and shocks. Using a panel of 50 economies from 1970-2011, we find
that disregarding this interaction leads to inconsistent estimates whenever
knowledge spillovers and other unobserved effects are correlated with foreign
and domestic R&amp;D. When this interaction is modeled, estimates are consistent;
however, they confound foreign and domestic R&amp;D effects with unobserved
effects. Thus, the coefficient of a weighted foreign R&amp;D variable cannot
capture genuine channel-specific R&amp;D spillovers.
</summary>
    <author>
      <name>Diego-Ivan Ruge-Leiva</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">28 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1502.06805v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.06805v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.05283v2</id>
    <updated>2015-03-22T04:58:52Z</updated>
    <published>2015-03-18T04:58:18Z</published>
    <title>Re-visiting the Distance Coefficient in Gravity Model</title>
    <summary>  This paper revisits the classic gravity model in international trade and
reexamines the distance coefficient. As pointed out by Frankel (1997), this
coefficient measures the relative unit transportation cost between short
distance and long distance rather than the absolute level of average
transportation cost. Our results confirm this point in the sense that the
coefficient has been very stable between 1991-2006, despite the obvious
technological progress taken place during this period. Moreover, by comparing
the sensitivity of these coefficients to change in oil prices at short periods
of time, in which technology remained unchanged, we conclude that the average
technology has indeed reduced the average trading cost. The results are robust
when we divide the aggregate international trades into different industries.
</summary>
    <author>
      <name>Haonan Wu</name>
    </author>
    <link href="http://arxiv.org/abs/1503.05283v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.05283v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.08900v1</id>
    <updated>2015-03-31T03:45:03Z</updated>
    <published>2015-03-31T03:45:03Z</published>
    <title>Dynamic Games with Almost Perfect Information</title>
    <summary>  This paper aims to solve two fundamental problems on finite or infinite
horizon dynamic games with perfect or almost perfect information. Under some
mild conditions, we prove (1) the existence of subgame-perfect equilibria in
general dynamic games with almost perfect information, and (2) the existence of
pure-strategy subgame-perfect equilibria in perfect-information dynamic games
with uncertainty. Our results go beyond previous works on continuous dynamic
games in the sense that public randomization and the continuity requirement on
the state variables are not needed. As an illustrative application, a dynamic
stochastic oligopoly market with intertemporally dependent payoffs is
considered.
</summary>
    <author>
      <name>Wei He</name>
    </author>
    <author>
      <name>Yeneng Sun</name>
    </author>
    <link href="http://arxiv.org/abs/1503.08900v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.08900v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.02516v1</id>
    <updated>2015-04-09T23:14:39Z</updated>
    <published>2015-04-09T23:14:39Z</published>
    <title>Empirical Relevance of Ambiguity in First Price Auction Models</title>
    <summary>  We study the identification and estimation of first-price auction models
where bidders have ambiguity about the valuation distribution and their
preferences are represented by maxmin expected utility. When entry is
exogenous, the distribution and ambiguity structure are nonparametrically
identified, separately from risk aversion (CRRA). We propose a flexible
Bayesian method based on Bernstein polynomials. Monte Carlo experiments show
that our method estimates parameters precisely, and chooses reserve prices with
(nearly) optimal revenues, whether there is ambiguity or not. Furthermore, if
the model is misspecified -- incorrectly assuming no ambiguity among bidders --
it may induce estimation bias with a substantial revenue loss.
</summary>
    <author>
      <name>Gaurab Aryal</name>
    </author>
    <author>
      <name>Dong-Hyuk Kim</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">43 pages, 12 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1504.02516v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.02516v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.03956v1</id>
    <updated>2015-05-15T04:26:41Z</updated>
    <published>2015-05-15T04:26:41Z</published>
    <title>From 0D to 1D spatial models using OCMat</title>
    <summary>  We show that the standard class of optimal control models in OCMat can be
used to analyze 1D spatial distributed systems. This approach is an
intermediate step on the way to the FEM discretization approach presented in
Grass and Uecker (2015). Therefore, the spatial distributed model is
transformed into a standard model by a finite difference discretization. This
(high dimensional) standard model is then analyzed using OCMAT. As an example
we apply this method to the spatial distributed shallow lake model formulated
in Brock and Xepapadeas (2008). The results are then compared with those of the
FEM discretization in GRass and Uecker (2015)
</summary>
    <author>
      <name>Dieter Grass</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">34 pages, 9 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1505.03956v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.03956v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.04587v1</id>
    <updated>2015-05-18T10:45:31Z</updated>
    <published>2015-05-18T10:45:31Z</published>
    <title>On the Failures of Bonus Plans</title>
    <summary>  A decision maker (DM) has some funds invested through two investment firms.
She wishes to allocate additional funds according to the firms' earnings. The
DM, on the one hand, tries to maximize the total expected earnings, while the
firms, on the other hand, try to maximize the overall expected funds they
manage. In this paper we prove that, for every market, the DM has an optimal
bonus policy such that the firms are motivated to act according to the
interests of the DM. On the other hand, we also prove that the only policy that
is optimal in every market, is independent of the actions and earnings of the
firms.
</summary>
    <author>
      <name>David Lagziel</name>
    </author>
    <author>
      <name>Ehud Lehrer</name>
    </author>
    <link href="http://arxiv.org/abs/1505.04587v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.04587v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.04880v1</id>
    <updated>2015-06-16T08:48:54Z</updated>
    <published>2015-06-16T08:48:54Z</published>
    <title>An Exchange Rate Target Zone Model with a Terminal Condition and
  Mean-Reverting Fundamentals</title>
    <summary>  This paper proposes a target zones exchange rate model with a terminal
condition of entering a currency zone. It is assumed that the exchange rate is
a function of the fundamental and time. Another essential assumptions of the
model is that the fundamental process is bounded inside a band and that
terminal condition for the exchange rate holds. The fundamental is specified in
two ways: as a regulated Brownian motion and Ornstein-Uhlenbeck processes. For
the case of the Brownian motion process the closed form solution of the problem
is obtained, whereas for the Ornstein-Uhlenbeck process the closed form
solution does not exist, therefore we had to use numerical method for solving
of the problem. Both specifications are compared numerically.
</summary>
    <author>
      <name>Viktors Ajevskis</name>
    </author>
    <link href="http://arxiv.org/abs/1506.04880v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.04880v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.00511v1</id>
    <updated>2015-07-24T15:11:23Z</updated>
    <published>2015-07-24T15:11:23Z</published>
    <title>Modélisation spatiale de la formation des agglomérations dans la
  zone algéroise</title>
    <summary>  The goal of this study is to analyze the dynamics underlying Algiers urban
area formation with reference to The New Economic Geography (NEG) theories and
more precisely to the paper of Paul Krugman (1991), "Increasing returns and
economic geography" which explains the mechanisms of economic activities
concentration through two types of forces: centripetal forces enhancing the
economic activities concentration and centrifugal forces hindering the
agglomeration process. In fact, these mechanisms are translated into a system
of nonlinear equations which is very hard to solve analytically. As a
consequence, the use of numerical methods is highly advocated. We present some
numerical simulations using real Algerian data.
</summary>
    <author>
      <name>Smicha Ait Amokthar</name>
    </author>
    <author>
      <name>Nadjia El Saadi</name>
    </author>
    <author>
      <name>Yacine Belarbi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, in French</arxiv:comment>
    <link href="http://arxiv.org/abs/1508.00511v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.00511v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.00607v2</id>
    <updated>2016-08-09T06:59:19Z</updated>
    <published>2015-08-03T21:40:25Z</published>
    <title>Existence of continuous euclidean embeddings for a weak class of orders</title>
    <summary>  We prove that if $X$ is a topological space that admits Debreu's classical
utility theorem (eg.\ $X$ is separable and connected, second countable, etc.),
then order relations on $X$ satisfying milder completeness conditions can be
continuously embedded in $\mathbb R^I$ for $I$ some index set. In the
particular case where $X$ is a compact metric space, this closes a conjecture
of Nishimura \&amp; Ok (2015). We also show that when $\mathbb R^I$ is given a
non-standard partial order coinciding with Pareto improvement, the analogous
embedding theorem fails to hold in the continuous case.
</summary>
    <author>
      <name>Stan Palasek</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, edited for a mathematical audience</arxiv:comment>
    <link href="http://arxiv.org/abs/1508.00607v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.00607v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B08" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.03651v3</id>
    <updated>2015-08-31T01:25:24Z</updated>
    <published>2015-04-18T13:30:47Z</published>
    <title>A conjecture about the efficiency of first price mechanisms</title>
    <summary>  We present different versions of a conjecture which would express that first
price mechanisms never work very badly in a very general class of problems. The
definitions include most of the problems where there is a principal (seller)
who has the right to exclude others from the game. The exact definitions are
motivated by the "first price mechanism" in E Cs: "Efficient Teamwork", but the
conjecture is relevant for most auction problems, e.g. for combinatorial
auctions.
</summary>
    <author>
      <name>Endre Csóka</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The conjecture is disproved in its original form by the author. The
  current status of the question is a part of the paper "Efficient Teamwork"</arxiv:comment>
    <link href="http://arxiv.org/abs/1508.03651v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.03651v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.05114v1</id>
    <updated>2015-07-14T21:25:20Z</updated>
    <published>2015-07-14T21:25:20Z</published>
    <title>The nonlinear Bernstein-Schrödinger equation in Economics</title>
    <summary>  In this paper we relate the Equilibrium Assignment Problem (EAP), which is
underlying in several economics models, to a system of nonlinear equations that
we call the "nonlinear Bernstein-Schr\"odinger system", which is well-known in
the linear case, but whose nonlinear extension does not seem to have been
studied. We apply this connection to derive an existence result for the EAP,
and an efficient computational method.
</summary>
    <author>
      <name>Alfred Galichon</name>
    </author>
    <author>
      <name>Scott Kominers</name>
    </author>
    <author>
      <name>Simon Weber</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, submitted to Lecture Notes in Computer Science</arxiv:comment>
    <link href="http://arxiv.org/abs/1508.05114v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.05114v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1509.01212v1</id>
    <updated>2015-07-02T03:48:17Z</updated>
    <published>2015-07-02T03:48:17Z</published>
    <title>Stochastic Frontier I &amp; D of fractal dimensions for technological
  innovation</title>
    <summary>  This paper presents an analysis of the study variables such as gdp,
employment levels, the level of R &amp; D and technology that will serve as the
basis for stochastic modeling of production possibilities frontier in the
goodness of fractal dimensions Ex Ante and Ex Post a priori to determine the
levels of causality immediately and check its accuracy and power of indexing,
using high frequency data and thus address the response this assumption of
stochastic frontiers with level N of partitions in time.
</summary>
    <author>
      <name>Maria Ramos-Escamilla</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/S0185-0849(13)71335-5</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/S0185-0849(13)71335-5" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages, in Spanish</arxiv:comment>
    <link href="http://arxiv.org/abs/1509.01212v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1509.01212v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1509.01484v1</id>
    <updated>2015-05-28T20:55:29Z</updated>
    <published>2015-05-28T20:55:29Z</published>
    <title>Interdisciplinary Business Games on Sustainable Development: Theoretical
  Foundations and Prospects of Implementation</title>
    <summary>  The article defines the place of business games among all games in general
based on the classification by F.G. Junger; it provides critical analysis of
existing business games types; it also formulates requirements and lays
theoretical foundations and elements of the methodology and organization of
interdisciplinary business games (IBG) on sustainable development as a special
type of business games. In addition, it examines the prospects of IBG
implementation in higher education for sustainable development, using
information technology and computer resources.
</summary>
    <author>
      <name>Boris Bolshakov</name>
    </author>
    <author>
      <name>Ekaterina Shamaeva</name>
    </author>
    <author>
      <name>Eugene Popov</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5281/zenodo.16849</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5281/zenodo.16849" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Report at the XXIII International Scientific Symposium 'Miner's Week
  - 2015' (MISiS, Moscow, 26-30 January 2015) pp 319-325</arxiv:comment>
    <link href="http://arxiv.org/abs/1509.01484v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1509.01484v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1509.01741v1</id>
    <updated>2015-09-05T22:10:20Z</updated>
    <published>2015-09-05T22:10:20Z</published>
    <title>IMF Lending and Economic Growth: An Empirical Analysis of Ukraine</title>
    <summary>  This study uses Vector Autoregression (VAR) Methodology as well as Vector
Error Correction (VEC) Methodology to examine the existence and direction of
causality between economic growth and IMF lending for Ukraine. The paper
examines the IMF lending data for the period of 1991-2010. Robust empirical
analysis indicates that IMF lending has a negative effect of on Ukraine's
economic growth in the short term. Policy implications of this finding are
that, despite short-run decline in economic growth, IMF lending can result in a
long-run sustainable growth for Ukraine. For this, policymakers need to ensure
that fund's money are used not only to cover budget's deficit, but also to
finance institutional reforms.
</summary>
    <author>
      <name>Roman Kononenko</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Master's Thesis</arxiv:comment>
    <link href="http://arxiv.org/abs/1509.01741v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1509.01741v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1509.06612v4</id>
    <updated>2016-05-01T06:30:37Z</updated>
    <published>2015-09-09T08:27:14Z</published>
    <title>Mathematical Analysis of the Historical Economic Growth</title>
    <summary>  Data describing historical economic growth are analysed. Included in the
analysis is the world and regional economic growth. The analysis demonstrates
that historical economic growth had a natural tendency to follow hyperbolic
distributions. Parameters describing hyperbolic distributions have been
determined. A search for takeoffs from stagnation to growth produced negative
results. This analysis throws a new light on the interpretation of the
mechanism of the historical economic growth and suggests new lines of research.
</summary>
    <author>
      <name>Ron W. Nielsen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">23 pages, 23 figures, 1 table, 7150 words. Contains important
  clarification</arxiv:comment>
    <link href="http://arxiv.org/abs/1509.06612v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1509.06612v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.02435v1</id>
    <updated>2015-10-08T18:37:09Z</updated>
    <published>2015-10-08T18:37:09Z</published>
    <title>Information equilibrium as an economic principle</title>
    <summary>  A general information equilibrium model in the case of ideal information
transfer is defined and then used to derive the relationship between supply
(information destination) and demand (information source) with the price as the
detector of information exchange between demand and supply. We recover the
properties of the traditional economic supply-demand diagram. Information
equilibrium is then applied to macroeconomic problems, recovering some common
macroeconomic models in particular limits like the AD-AS model, IS-LM model (in
a low inflation limit), the quantity theory of money (in a high inflation
limit) and the Solow-Swan growth model. Information equilibrium results in
empirically accurate models of inflation and interest rates, and can be used to
motivate a 'statistical economics', analogous to statistical mechanics for
thermodynamics.
</summary>
    <author>
      <name>Jason Smith</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">44 pages, 26 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1510.02435v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.02435v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.06809v2</id>
    <updated>2016-06-22T19:17:19Z</updated>
    <published>2015-10-23T02:36:43Z</published>
    <title>A Link between Sequential Semi-anonymous Nonatomic Games and their Large
  Finite Counterparts</title>
    <summary>  We show that equilibria of a sequential semi-anonymous nonatomic game (SSNG)
can be adopted by players in corresponding large but finite dynamic games to
achieve near-equilibrium payoffs. Such equilibria in the form of random
state-to-action rules are parsimonious in form and easy to execute, as they are
both oblivious of past history and blind to other players' present states. Our
transient results can be extended to a stationary case, where the finite
counterparts are special discounted stochastic games. The kind of equilibria we
adopt for SSNG are similar to distributional equilibria that are well
understood in literature, and they themselves are shown to exist.
</summary>
    <author>
      <name>Jian Yang</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s00182-016-0539-5</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s00182-016-0539-5" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">in International Journal of Game Theory, 2016, forthcoming</arxiv:comment>
    <link href="http://arxiv.org/abs/1510.06809v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.06809v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.02229v1</id>
    <updated>2015-11-06T13:02:03Z</updated>
    <published>2015-11-06T13:02:03Z</published>
    <title>Wage gap between men and women in Tunisia</title>
    <summary>  This paper focuses on estimating wage differences between males and females
in Tunisia by using the Oaxaca-Blinder decomposition, a technical that isolates
wage gap due to characteristics, from wage gap due to discrimination against
women. The data used in the analysis is obtained from the Tunisian Population
and Employment Survey 2005. It is estimated that, the gender wage gap is about
19% and the results ascertain that the gender wage gap is mostly attributed to
discrimination, especially to underestimation of females'caracteristics on the
labor market.
</summary>
    <author>
      <name>Hela Jeddi</name>
    </author>
    <author>
      <name>Dhafer Malouche</name>
    </author>
    <link href="http://arxiv.org/abs/1511.02229v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.02229v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.07203v1</id>
    <updated>2015-11-23T12:48:53Z</updated>
    <published>2015-11-23T12:48:53Z</published>
    <title>Some Dynamic Market Models</title>
    <summary>  In this text, we study the temporal behavior of markets using models
expressible as ordinary differential equations. The markets studied are those
where each customer buys only one copy of the good, for example, subscription
of smartphone service, journals and newspapers, and goods such as books, music
and games. The underlying model is the diffusion model of Frank Bass. Evolution
of markets with no competitors and markets with several competitors are
analyzed where, in particulat, the effects of churning upon the market
evolution is investigated. Analytic solutions are given for the temporal
evolution of several types of interactive games.
</summary>
    <author>
      <name>Jan A. Audestad</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">48 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1511.07203v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.07203v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.07419v1</id>
    <updated>2015-11-23T20:56:39Z</updated>
    <published>2015-11-23T20:56:39Z</published>
    <title>Sustainability in the Stochastic Ramsey Model</title>
    <summary>  In this paper we provide a self-contained exposition of the problem of
sustaining a constant consumption level in a Ramsey model. Our focus is on the
case in which the output capital-ratio is random. After a brief review of the
known results on the probabilities of sustaining a target consumption from an
initial stock, we present some new results on estimating the probabilities by
using Chebyshev inequalities. Some numerical calculations for these estimates
are also provided.
</summary>
    <author>
      <name>Rabi Bhattacharya</name>
    </author>
    <author>
      <name>Hyeonju Kim</name>
    </author>
    <author>
      <name>Mukul Majumdar</name>
    </author>
    <link href="http://arxiv.org/abs/1511.07419v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.07419v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.08622v1</id>
    <updated>2015-11-27T11:16:28Z</updated>
    <published>2015-11-27T11:16:28Z</published>
    <title>Complex economies have a lateral escape from the poverty trap</title>
    <summary>  We analyze the decisive role played by the complexity of economic systems at
the onset of the industrialization process of countries over the past 50 years.
Our analysis of the input growth dynamics, based on a recently introduced
measure of economic complexity, reveals that more differentiated and more
complex economies face a lower barrier (in terms of GDP per capita) when
starting the transition towards industrialization. Moreover, adding the
complexity dimension to the industrialization process description helps to
reconcile current theories with empirical findings.
</summary>
    <author>
      <name>Emanuele Pugliese</name>
    </author>
    <author>
      <name>Guido L. Chiarotti</name>
    </author>
    <author>
      <name>Andrea Zaccaria</name>
    </author>
    <author>
      <name>Luciano Pietronero</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1511.08622v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.08622v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1512.01626v1</id>
    <updated>2015-12-05T05:48:54Z</updated>
    <published>2015-12-05T05:48:54Z</published>
    <title>Optimal environmental tax swaps and double dividend hypothesis</title>
    <summary>  Taking environmental tax rate as given, is there an optimal allocation of tax
revenues to benefit economic variables? This paper analyzes this issue in an
overlapping-generations model with the pollution-related health damage. It
finds the optimal allocations towards pollution abatement and labor income to
maximize the steady-state lifetime welfare and per-worker output, respectively.
Moreover, a greater shift towards labor income might enhance steady-state
welfare while reducing per-worker output.
</summary>
    <author>
      <name>Su-Mei Chen</name>
    </author>
    <author>
      <name>Ling-Yun He</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1512.01626v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1512.01626v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1512.03164v2</id>
    <updated>2016-02-26T23:27:13Z</updated>
    <published>2015-12-10T08:09:40Z</published>
    <title>Unified Growth Theory Contradicted by the Economic Growth in Africa</title>
    <summary>  One of the fundamental postulates of the Unified Growth Theory is the claimed
existence of three distinctly different regimes of economic growth governed by
three distinctly different mechanisms of growth. However, Galor also proposed
that the timing of these regimes is different for developed countries and for
less-developed countries. Africa is the perfect example of economic growth in
less-developed countries. The data used by Galor, but never properly
investigated, are now analysed. They turn out to be in dramatic contradiction
of this theory.
</summary>
    <author>
      <name>Ron W Nielsen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 figures, 8 pages, 2990 words</arxiv:comment>
    <link href="http://arxiv.org/abs/1512.03164v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1512.03164v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1512.06960v1</id>
    <updated>2015-12-22T05:49:31Z</updated>
    <published>2015-12-22T05:49:31Z</published>
    <title>Sovereign Default Risk and Uncertainty Premia</title>
    <summary>  This paper studies how international investors' concerns about model
misspecification affect sovereign bond spreads. We develop a general
equilibrium model of sovereign debt with endogenous default wherein investors
fear that the probability model of the underlying state of the borrowing
economy is misspecified. Consequently, investors demand higher returns on their
bond holdings to compensate for the default risk in the context of uncertainty.
In contrast with the existing literature on sovereign default, we match the
bond spreads dynamics observed in the data together with other business cycle
features for Argentina, while preserving the default frequency at historical
low levels.
</summary>
    <author>
      <name>Demian Pouzo</name>
    </author>
    <author>
      <name>Ignacio Presno</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted for publication at American Economic Journal: Macroeconomics</arxiv:comment>
    <link href="http://arxiv.org/abs/1512.06960v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1512.06960v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.04686v2</id>
    <updated>2016-03-25T04:46:11Z</updated>
    <published>2016-01-18T20:41:46Z</published>
    <title>Unified Growth Theory Contradicted by the Absence of Takeoffs in the
  Gross Domestic Product</title>
    <summary>  Data describing historical economic growth are analysed. They demonstrate
convincingly that the takeoffs from stagnation to growth, claimed in the
Unified Growth Theory, never happened. This theory is again contradicted by
data, which were used, but never properly analysed, during its formulation. The
absence of the claimed takeoffs demonstrates also that the postulate of the
differential takeoffs is contradicted by data.
</summary>
    <author>
      <name>Ron W Nielsen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 7 figures, 4320 words. One figure corrected. Conclusions
  remain unchanged. arXiv admin note: substantial text overlap with
  arXiv:1509.06612, arXiv:1601.07291</arxiv:comment>
    <link href="http://arxiv.org/abs/1601.04686v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.04686v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.04949v1</id>
    <updated>2016-01-19T15:17:53Z</updated>
    <published>2016-01-19T15:17:53Z</published>
    <title>General Equilibrium and Recession Phenomenon</title>
    <summary>  The theorems we proved describe the structure of economic equilibrium in the
exchange economy model. We have studied the structure of property vectors under
given structure of demand vectors at which given price vector is equilibrium
one. On this ground, we describe the general structure of the equilibrium state
and give characteristic of equilibrium state describing economic recession. The
theory developed is applied to explain the state of the economy in some
European countries.
</summary>
    <author>
      <name>Nicholas S. Gonchar</name>
    </author>
    <author>
      <name>Wolodymyr H. Kozyrski</name>
    </author>
    <author>
      <name>Anatol S. Zhokhin</name>
    </author>
    <link href="http://arxiv.org/abs/1601.04949v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.04949v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.TR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1602.07628v1</id>
    <updated>2016-02-24T18:21:04Z</updated>
    <published>2016-02-24T18:21:04Z</published>
    <title>The Invisible Hand of Laplace: the Role of Market Structure in Price
  Convergence and Oscillation</title>
    <summary>  A fundamental question about a market is under what conditions, and then how
rapidly, does price signaling cause price equilibration. Qualitatively, this
ought to depend on how well-connected the market is. We address this question
quantitatively for a certain class of Arrow-Debreu markets with continuous-time
proportional t\^{a}tonnement dynamics. We show that the algebraic connectivity
of the market determines the effectiveness of price signaling equilibration.
This also lets us study the rate of external noise that a market can tolerate
and still maintain near-equilibrium prices.
</summary>
    <author>
      <name>Yuval Rabani</name>
    </author>
    <author>
      <name>Leonard J. Schulman</name>
    </author>
    <link href="http://arxiv.org/abs/1602.07628v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1602.07628v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91A28, 91B55, 35Q91, 35K05" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1602.08533v1</id>
    <updated>2016-02-27T00:02:04Z</updated>
    <published>2016-02-27T00:02:04Z</published>
    <title>A Rank-Based Approach to Zipf's Law</title>
    <summary>  An Atlas model is a rank-based system of continuous semimartingales for which
the steady-state values of the processes follow a power law, or Pareto
distribution. For a power law, the log-log plot of these steady-state values
versus rank is a straight line. Zipf's law is a power law for which the slope
of this line is -1. In this note, rank-based conditions are found under which
an Atlas model will follow Zipf's law. An advantage of this rank-based approach
is that it provides information about the dynamics of systems that result in
Zipf's law.
</summary>
    <author>
      <name>Ricardo T. Fernholz</name>
    </author>
    <author>
      <name>Robert Fernholz</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1602.08533v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1602.08533v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.MF" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.08895v1</id>
    <updated>2016-04-29T16:03:33Z</updated>
    <published>2016-04-29T16:03:33Z</published>
    <title>The puzzle that just isn't</title>
    <summary>  In his stimulating article on the reasons for two puzzling observations about
the behaviour of interest rates, exchange rates and the rate of inflation,
Charles Engel (2016) puts forward an explanation that rests on the concept of a
non-pecuniary liquidity return on assets. Albeit intriguing the analysis
struggles to account for a number of facts which are familiar to participants
of the foreign exchange and bond markets. Reconciling these facts in
conjunction with a careful dissection of the "puzzle" to begin with, shows that
the forward premium puzzle just does not exist, at least not in its canonical
form.
</summary>
    <author>
      <name>Christian Mueller-Kademann</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">25 pages, 2 figures, with a quote from Wonko the Sane</arxiv:comment>
    <link href="http://arxiv.org/abs/1604.08895v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.08895v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.01343v2</id>
    <updated>2016-10-21T22:13:33Z</updated>
    <published>2016-05-03T12:49:05Z</published>
    <title>Electoral Systems Used around the World</title>
    <summary>  We give an overview of the diverse electoral systems used in local, national,
or super-national elections around the world. We discuss existing methods for
selecting single and multiple winners and give real-world examples for some
more elaborate systems. Eventually, we elaborate on some of the better known
strengths and weaknesses of various methods from both the theoretical and
practical points of view.
</summary>
    <author>
      <name>Siamak F. Shahandashti</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This is a personally archived version of a chapter by the same title
  contributed to the book "Real-World Electronic Voting: Design, Analysis and
  Deployment", Feng Hao and Peter Y. A. Ryan (editors), Series in Security,
  Privacy and Trust, CRC Press, 2016</arxiv:comment>
    <link href="http://arxiv.org/abs/1605.01343v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.01343v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B12, 91B14" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.04385v1</id>
    <updated>2016-05-14T06:36:53Z</updated>
    <published>2016-05-14T06:36:53Z</published>
    <title>Knight--Walras Equilibria</title>
    <summary>  Knightian uncertainty leads naturally to nonlinear expectations. We introduce
a corresponding equilibrium concept with sublinear prices and establish their
existence. In general, such equilibria lead to Pareto inefficiency and coincide
with Arrow--Debreu equilibria only if the values of net trades are
ambiguity--free in the mean. Without aggregate uncertainty, inefficiencies
arise generically.
  We introduce a constrained efficiency concept, uncertainty--neutral
efficiency and show that Knight--Walras equilibrium allocations are efficient
in this constrained sense. Arrow--Debreu equilibria turn out to be non--robust
with respect to the introduction of Knightian uncertainty.
</summary>
    <author>
      <name>Patrick Beissner</name>
    </author>
    <author>
      <name>Frank Riedel</name>
    </author>
    <link href="http://arxiv.org/abs/1605.04385v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.04385v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.04155v2</id>
    <updated>2017-08-06T09:16:06Z</updated>
    <published>2016-07-14T14:46:04Z</published>
    <title>Fashion, fads and the popularity of choices: micro-foundations for
  diffusion consumer theory</title>
    <summary>  Knowledge acquisition by consumers is a key process in the diffusion of
innovations. However, in standard theories of the representative agent, agents
do not learn and innovations are adopted instantaneously. Here, we show that in
a discrete choice model where utility-maximising agents with heterogenous
preferences learn about products through peers, their stock of knowledge on
products becomes heterogenous, fads and fashions arise, and transitivity in
aggregate preferences is lost. Non-equilibrium path-dependent dynamics emerge,
the representative agent exhibits behavioural rules different than individual
agents, and aggregate utility cannot be optimised. Instead, an evolutionary
theory of product innovation and diffusion emerges.
</summary>
    <author>
      <name>Jean-Francois Mercure</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages including appendix</arxiv:comment>
    <link href="http://arxiv.org/abs/1607.04155v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.04155v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.01535v2</id>
    <updated>2017-01-11T13:40:03Z</updated>
    <published>2016-08-04T13:53:51Z</published>
    <title>Intergenerational Equity in a Finite Horizon</title>
    <summary>  A favorable population schedule for the entire potential human family is
sought, under the overlapping generations framework, by treating population (or
fertility) as a planning variable in a dynamical social welfare maximization
context. The utilitarian and maximin social welfare functions are examined,
with zero future discounting, while infinity in the maximand is circumvented by
introducing the depletion of energy resources and its postponement through
technological innovations. The model is formulated as a free-horizon dynamical
planning problem, solved via a non-linear optimizer. Under exploratory
scenarios, we visualize the potential trade-offs between the two welfare
criteria.
</summary>
    <author>
      <name>Satoshi Nakano</name>
    </author>
    <author>
      <name>Kazuhiko Nishimura</name>
    </author>
    <link href="http://arxiv.org/abs/1608.01535v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.01535v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.02428v3</id>
    <updated>2016-12-13T18:04:18Z</updated>
    <published>2016-07-18T14:27:32Z</published>
    <title>The Opium for the Poor Is Opium. Medicare Providers in States with Low
  Income Prescribe High Levels of Opiates</title>
    <summary>  The majority of Medicare opioid prescriptions originate with family practice
and internal medicine providers.
  I show that the average number of Medicare opium prescriptions by these
providers vary strongly by state and that 54% of the variance is accounted for
by the state median household income. I also show that there is a very similar
relationship in opioid claims per capita and per Medicare recipient.
  In all cases Alabama is the state with the most claims and Hawaii is the
state with the least claims.
</summary>
    <author>
      <name>Eugen Tarnow</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.13140/RG.2.2.22219.18722</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.13140/RG.2.2.22219.18722" rel="related"/>
    <link href="http://arxiv.org/abs/1608.02428v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.02428v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.05597v1</id>
    <updated>2016-08-19T13:36:55Z</updated>
    <published>2016-08-19T13:36:55Z</published>
    <title>The structure of the climate debate</title>
    <summary>  First-best climate policy is a uniform carbon tax which gradually rises over
time. Civil servants have complicated climate policy to expand bureaucracies,
politicians to create rents. Environmentalists have exaggerated climate change
to gain influence, other activists have joined the climate bandwagon. Opponents
to climate policy have attacked the weaknesses in climate research. The climate
debate is convoluted and polarized as a result, and climate policy complex.
Climate policy should become easier and more rational as the Paris Agreement
has shifted climate policy back towards national governments. Changing
political priorities, austerity, and a maturing bureaucracy should lead to a
more constructive climate debate.
</summary>
    <author>
      <name>Richard S. J. Tol</name>
    </author>
    <link href="http://arxiv.org/abs/1608.05597v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.05597v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.03223v1</id>
    <updated>2016-09-11T22:15:04Z</updated>
    <published>2016-09-11T22:15:04Z</published>
    <title>The Solution to Science's Replication Crisis</title>
    <summary>  The solution to science's replication crisis is a new ecosystem in which
scientists sell what they learn from their research. In each pairwise
transaction, the information seller makes (loses) money if he turns out to be
correct (incorrect). Responsibility for the determination of correctness is
delegated, with appropriate incentives, to the information purchaser. Each
transaction is brokered by a central exchange, which holds money from the
anonymous information buyer and anonymous information seller in escrow, and
which enforces a set of incentives facilitating the transfer of useful, bluntly
honest information from the seller to the buyer. This new ecosystem, capitalist
science, directly addresses socialist science's replication crisis by
explicitly rewarding accuracy and penalizing inaccuracy.
</summary>
    <author>
      <name>Bruce Knuteson</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2 pages (main text) + 5 pages (references)</arxiv:comment>
    <link href="http://arxiv.org/abs/1609.03223v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.03223v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.03471v1</id>
    <updated>2016-09-12T16:37:30Z</updated>
    <published>2016-09-12T16:37:30Z</published>
    <title>The Informational Content of the Limit Order Book: An Empirical Study of
  Prediction Markets</title>
    <summary>  In this paper I empirically investigate prediction markets for binary
options. Advocates of prediction markets have suggested that asset prices are
consistent estimators of the "true" probability of a state of the world being
realized. I test whether the market reaches a "consensus." I find little
evidence for convergence in beliefs. I then determine whether an econometrician
using data beyond execution prices can leverage this data to estimate the
consensus belief. I use an incomplete specification of equilibrium outcomes to
derive bounds on beliefs from order submission decisions. Interval estimates of
mean beliefs cannot exclude aggregate beliefs equal to 0.5.
</summary>
    <author>
      <name>Joachim R. Groeger</name>
    </author>
    <link href="http://arxiv.org/abs/1609.03471v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.03471v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.TR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.05200v1</id>
    <updated>2016-03-07T17:31:27Z</updated>
    <published>2016-03-07T17:31:27Z</published>
    <title>Chinese Medical Device Market and The Investment Vector</title>
    <summary>  China has attracted increasing amounts of foreign investment since it opened
its doors to the world and whilst many analysts have focused on foreign
investment in popular areas, little has been written about medical device
investment. The purpose of this article is to analyze the status of the Chinese
medical device market from the perspective of the healthcare industry and its
important market drivers; the study reveals that the medical device market has
significant growth potential. This article aims to identify and assess the
profitable sectors of medical device technologies as a guide for international
companies and investors.
</summary>
    <author>
      <name>Weifan Zhang</name>
    </author>
    <author>
      <name>Rebecca Liu</name>
    </author>
    <author>
      <name>Chris Chatwin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">34 pages, 11 figures, 5 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1609.05200v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.05200v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1610.05703v1</id>
    <updated>2016-10-18T16:39:15Z</updated>
    <published>2016-10-18T16:39:15Z</published>
    <title>Two approaches to modeling the interaction of small and medium
  price-taking traders with a stock exchange by mathematical programming
  techniques</title>
    <summary>  The paper presents two new approaches to modeling the interaction of small
and medium pricetaking traders with a stock exchange. In the framework of these
approaches, the traders can form and manage their portfolios of financial
instruments traded on a stock exchange with the use of linear, integer, and
mixed programming techniques. Unlike previous authors publications on the
subject, besides standard securities, the present publication considers
derivative financial instruments such as futures and options contracts.
</summary>
    <author>
      <name>A. Belenky</name>
    </author>
    <author>
      <name>L. Egorova</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">88 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1610.05703v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1610.05703v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="90C10" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.6.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1611.02270v1</id>
    <updated>2016-11-02T01:50:07Z</updated>
    <published>2016-11-02T01:50:07Z</published>
    <title>The Average-Marginal Relationship and Tractable Equilibrium Forms</title>
    <summary>  Economic variables with familiar tractable functional forms
(constant-elasticity or linear) are only reweighted in the change from their
average to marginal versions. They are also simple, featuring only one or two
terms. These properties allow for closed-form solutions. We explicitly
characterize all equilibrium systems obeying a generalization of these
properties, showing they form a hierarchy of tractability. The resulting forms
are more realistic (e.g. bell-shaped demand and U-shaped cost) but highly
tractable. These forms have importantly different implications for policy
analysis, as we illustrate with applications from innovation, industrial,
international, auction and public economics. We discuss close connections to
the theory of Laplace transform and completely monotone functions.
</summary>
    <author>
      <name>Michal Fabinger</name>
    </author>
    <author>
      <name>E. Glen Weyl</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">87 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1611.02270v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1611.02270v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.02657v1</id>
    <updated>2016-10-25T15:22:21Z</updated>
    <published>2016-10-25T15:22:21Z</published>
    <title>How do Chinese cities grow? A distribution dynamics approach</title>
    <summary>  This paper examines the dynamic behavior of city size using a distribution
dynamics approach with Chinese city data for the period 1984-2010. Instead of
convergence, divergence or paralleled growth, multimodality and persistence are
the dominant characteristics in the distribution dynamics of Chinese
prefectural cities. Moreover, initial city size matters, initially small and
medium-sized cities exhibit strong tendency of convergence, while large cities
show significant persistence and multimodality in the sample period.
Examination on the regional city groups shows that locational fundamentals have
important impact on the distribution dynamics of city size.
</summary>
    <author>
      <name>Jian-Xin Wu</name>
    </author>
    <author>
      <name>Ling-Yun He</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.physa.2016.11.112</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.physa.2016.11.112" rel="related"/>
    <link href="http://arxiv.org/abs/1612.02657v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.02657v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.06855v2</id>
    <updated>2017-01-06T18:54:38Z</updated>
    <published>2016-10-25T18:30:04Z</published>
    <title>Information, Impact, Ignorance, Illegality, Investing, and Inequality</title>
    <summary>  We note a simple mechanism that may at least partially resolve several
outstanding economic puzzles, including why the cyclically adjusted price to
earnings ratio of the S&amp;P 500 index has been oddly high for the past two
decades, why gains to capital have outpaced gains to wages, and the persistence
of the equity premium.
</summary>
    <author>
      <name>Bruce Knuteson</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2 pages; v2: comment added in the TeX source file with the SHA
  checksum of a longer version of this article sent to the Securities and
  Exchange Commission on September 10, 2015</arxiv:comment>
    <link href="http://arxiv.org/abs/1612.06855v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.06855v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.TR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.09123v1</id>
    <updated>2016-12-27T17:15:36Z</updated>
    <published>2016-12-27T17:15:36Z</published>
    <title>Population and trends in the global mean temperature</title>
    <summary>  The Fisher Ideal index, developed to measure price inflation, is applied to
define a population-weighted temperature trend. This method has the advantages
that the trend is representative for the population distribution throughout the
sample but without conflating the trend in the population distribution and the
trend in the temperature. I show that the trend in the global area-weighted
average surface air temperature is different in key details from the
population-weighted trend. I extend the index to include urbanization and the
urban heat island effect. This substantially changes the trend again. I further
extend the index to include international migration, but this has a minor
impact on the trend.
</summary>
    <author>
      <name>Richard S. J. Tol</name>
    </author>
    <link href="http://arxiv.org/abs/1612.09123v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.09123v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.04491v1</id>
    <updated>2017-01-17T00:29:14Z</updated>
    <published>2017-01-17T00:29:14Z</published>
    <title>A geometric approach to the transfer problem for a finite number of
  traders</title>
    <summary>  We present a complete characterization of the classical transfer problem for
an exchange economy with an arbitrary finite number of traders. Our method is
geometric, using an equilibrium manifold developed by Debreu, Mas-Colell, and
Balasko. We show that for a regular equilibrium the transfer problem arises if
and only if the index at the equilibrium is $-1$. This implies that the
transfer problem does not happen if the equilibrium is Walras tatonnement
stable. Our result generalizes Balasko's analogous result for an exchange
economy with two traders.
</summary>
    <author>
      <name>Tomohiro Uchiyama</name>
    </author>
    <link href="http://arxiv.org/abs/1701.04491v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.04491v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.06410v1</id>
    <updated>2016-10-27T07:56:35Z</updated>
    <published>2016-10-27T07:56:35Z</published>
    <title>Economics cannot isolate itself from political theory: a mathematical
  demonstration</title>
    <summary>  The purpose of this paper is to provide a confession of sorts from an
economist to political science and philosophy. A confession of the weaknesses
of the political position of the economist. It is intended as a guide for
political scientists and philosophers to the ostensible policy criteria of
economics, and an illustration of an argument that demonstrates
logico-mathematically, therefore incontrovertibly, that any policy statement by
an economist contains, or is, a political statement. It develops an inescapable
compulsion that the absolute primacy and priority of political theory and
philosophy in the development of policy criteria must be recognised. Economic
policy cannot be divorced from politics as a matter of mathematical fact, and
rather, as Amartya Sen has done, it ought embrace political theory and
philosophy.
</summary>
    <author>
      <name>Brendan Markey-Towler</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1701.06410v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.06410v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.07321v1</id>
    <updated>2016-11-09T14:26:47Z</updated>
    <published>2016-11-09T14:26:47Z</published>
    <title>An analysis of potential conflict zones in the arctic region</title>
    <summary>  As a result of the climate change the situation in Arctic area leads to
several important consequences. On the one hand, oil and gas resources can be
exploited much easier than before. Thus, one can already observe discussions on
disputed shelf zones where the deposits are located. On the other hand, oil and
gas excavation leads to serious potential threats to fishing by changing
natural habitats which in turn can create serious damage to the economies of
some countries in the region. Another set of problems arises due to the
extension of navigable season for Arctic Shipping Routes.
</summary>
    <author>
      <name>F. Aleskerov</name>
    </author>
    <author>
      <name>E. Victorova</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1701.07321v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.07321v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B14" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.6.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.07322v1</id>
    <updated>2016-11-12T11:53:25Z</updated>
    <published>2016-11-12T11:53:25Z</published>
    <title>Heterogeneity of the educational system: an introduction to the problem</title>
    <summary>  We analyze a heterogeneity of the educational system on the basis of one
parameter: input grades of university students. We propose a mathematical model
based on the construction of universities interval order. We use the Hamming
distance to evaluate the heterogeneity of the educational system, and the
Unified State Examination (USE) scores of Russian students to illustrate the
application of the model. We show that institutions taking weak students turn
the whole system of universities into a poorly structured nonhomogeneous
system. In contrast, after deleting the weakest part, the remaining set of
universities becomes a well-structured system
</summary>
    <author>
      <name>F. Aleskerov</name>
    </author>
    <author>
      <name>I. Frumin</name>
    </author>
    <author>
      <name>E. Kardanova</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">64 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1701.07322v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.07322v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91C15" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.6.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.07323v1</id>
    <updated>2016-12-01T14:02:08Z</updated>
    <published>2016-12-01T14:02:08Z</published>
    <title>Les produits Halal dans les {é}conomies occidentales</title>
    <summary>  In last years, we hear about halal products in non- Muslim societies
including European and American ones. In France, for example, sales of halal
products sold in stores during the year 2010, increased 23 % and represented
5.5 billion euros, including 1.1 billion for the fast food, and it has not
stopped growing since. A new market is not only about Muslims. Halal is a
religious interpretation but its rapid development requires that we question
his true motives are not just religious
</summary>
    <author>
      <name>Abdelatif Kerzabi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">in French</arxiv:comment>
    <link href="http://arxiv.org/abs/1701.07323v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.07323v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.TR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1702.01362v1</id>
    <updated>2017-02-05T02:59:46Z</updated>
    <published>2017-02-05T02:59:46Z</published>
    <title>Hyperbolic Discounting of the Far-Distant Future</title>
    <summary>  We prove an analogue of Weitzman's (1998) famous result that an exponential
discounter who is uncertain of the appropriate exponential discount rate should
discount the far-distant future using the lowest (i.e., most patient) of the
possible discount rates. Our analogous result applies to a hyperbolic
discounter who is uncertain about the appropriate hyperbolic discount rate. In
this case, the far-distant future should be discounted using the
probability-weighted harmonic mean of the possible hyperbolic discount rates.
</summary>
    <author>
      <name>Nina Anchugina</name>
    </author>
    <author>
      <name>Matthew Ryan</name>
    </author>
    <author>
      <name>Arkadii Slinko</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1702.01362v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1702.01362v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1702.03977v1</id>
    <updated>2017-02-13T20:35:58Z</updated>
    <published>2017-02-13T20:35:58Z</published>
    <title>Labor Contract Law -An Economic View</title>
    <summary>  China's new labor law -- Labor Contract Law has been put into practice for
over one year. Since its inception, debates have been whirling around the
nation, if not the world. In this article, we take an economic perspective to
analyze the possible impact of the core item -- open-ended employment contract,
and we find that it deals poorly with adverse selection, with moral hazard
problems arise, which fails to meet the expectations of law-makers and other
parties.
</summary>
    <author>
      <name>Yaofeng Fu</name>
    </author>
    <author>
      <name>Ruokun Huang</name>
    </author>
    <author>
      <name>Yiran Sheng</name>
    </author>
    <link href="http://arxiv.org/abs/1702.03977v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1702.03977v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.02105v2</id>
    <updated>2017-05-24T02:01:01Z</updated>
    <published>2017-02-25T06:49:04Z</published>
    <title>Network Structure and Naive Sequential Learning</title>
    <summary>  We study a sequential learning model featuring naive agents on a network. The
key behavioral assumption is that agents wrongly believe their predecessors act
based only on private information, so correlation between observed actions is
ignored. We provide a simple linear formula characterizing agents' actions in
terms of network paths and use this formula to determine when society
eventually learns correctly. Disproportionately influential early agents can
cause herding on incorrect beliefs and we compute comparative statics of the
probability of herding with respect to network parameters. When networks are
segregated, divergent early signals can lead to persistent disagreement between
groups.
</summary>
    <author>
      <name>Krishna Dasaratha</name>
    </author>
    <author>
      <name>Kevin He</name>
    </author>
    <link href="http://arxiv.org/abs/1703.02105v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.02105v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.10897v2</id>
    <updated>2017-08-28T13:30:18Z</updated>
    <published>2017-03-31T13:56:58Z</published>
    <title>Random Multi-Unit Assignment with Endogenous Quotas</title>
    <summary>  We study the random multi-unit assignment problem in which the number of
goods to be distributed depends on players' preferences.
  In this setup, the egalitarian solution is more appealing than the
competitive equilibrium with equal incomes because it is Lorenz dominant,
unique in utilities, and impossible to manipulate by groups when agents have
dichotomous preferences. Moreover, it can be adapted to satisfy a new fairness
axiom that arises naturally in this context. Both solutions are disjoint.
  Two standard results disappear. The competitive solution can no longer be
computed with the Eisenberg-Gale program maximizing the Nash product, and the
competitive equilibrium with equal incomes is no longer unique in its
corresponding utility profile.
</summary>
    <author>
      <name>Josue Ortega</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">26 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1703.10897v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.10897v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1704.01316v1</id>
    <updated>2017-04-05T09:03:00Z</updated>
    <published>2017-04-05T09:03:00Z</published>
    <title>ICT and Employment in India: A Sectoral Level Analysis</title>
    <summary>  How technology affects growth or employment has long been debated. With a
hiatus, the debate revived once again in the form of how Information and
Communications Technology, as a form of new technology, exerts on productivity
and employment. Information and Communications Technology perceived as General
Purpose Technology like steam engine or electricity in the past, ushered the
world into a new techno-economic paradigm, given its deep social, economic and
cultural implications. For instance, within economic implication, it is hard to
imagine an economic activity that does not it, directly or indirectly.
Eventually, Information and Communications Technology intensity, measure as the
ratio of Information and Communications Technology investment to total
investment, increased phenomenally in industries across sectors.
</summary>
    <author>
      <name>Dr. Pawan Kumar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21</arxiv:comment>
    <link href="http://arxiv.org/abs/1704.01316v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1704.01316v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.02559v1</id>
    <updated>2017-05-07T04:02:25Z</updated>
    <published>2017-05-07T04:02:25Z</published>
    <title>An equation for a time-dependent profit rate</title>
    <summary>  Taking as a hypothesis a form of the labour theory of value, and $without$
$assuming$ $equilibrium$, we derive an equation that yields the profit-rate
$\pi$ as a function of time. For a mature economy, $\pi(t)$ reduces to the
product of two factors: ($i$) a certain $retarded$ $average$ of the sum of the
growth-rates of productivity and of the size of the labour-force measured by
hours worked, and ($ii$) the ratio of the current rate of surplus value to its
own retarded average. We also suggest an empirical test of the equation.
</summary>
    <author>
      <name>Rafael D. Sorkin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">plainTeX, 18 pages, no figures. Most current version will be
  available at http://www.perimeterinstitute.ca/personal/rsorkin/some.papers/
  (or wherever my home-page may be, such as
  http://www.physics.syr.edu/~sorkin/some.papers/)</arxiv:comment>
    <link href="http://arxiv.org/abs/1705.02559v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.02559v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.08033v1</id>
    <updated>2017-05-22T23:00:18Z</updated>
    <published>2017-05-22T23:00:18Z</published>
    <title>Can Everyone Benefit from Social Integration?</title>
    <summary>  There is no matching mechanism that satisfies integration monotonicity and
stability. If we insist on integration monotonicity, not even Pareto optimality
can be achieved: the only option is to remain segregated.
  A weaker monotonicity condition can be combined with Pareto optimality but
not with path independence, which implies that the dynamics of social
integration matter.
  If the outcome of integration is stable, integration is always approved by
majority voting, but a non-vanishing fraction of agents always oppose
segregation. The side who receives the proposals in the deferred acceptance
algorithm suffers significant welfare losses, which nevertheless become
negligible when societies grow large.
</summary>
    <author>
      <name>Josue Ortega</name>
    </author>
    <link href="http://arxiv.org/abs/1705.08033v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.08033v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91A12" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.08955v1</id>
    <updated>2017-04-14T20:34:33Z</updated>
    <published>2017-04-14T20:34:33Z</published>
    <title>Classifications of Innovations Survey and Future Directions</title>
    <summary>  The purpose of this paper is to focus on similarity and/or heterogeneity of
taxonomies of innovation present in the economic fields to show as the economic
literature uses different names to indicate the same type of technical change
and innovation, and the same name for different types of innovation. This
ambiguity of classification makes it impossible to compare the various studies;
moreover the numerous typologies existing in the economics of innovation,
technometrics, economics of technical change, management of technology, etc.,
have hindered the development of knowledge in these fields. The research
presents also new directions on the classification of innovation that try to
overcome these problems.
</summary>
    <author>
      <name>Mario Coccia</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">22</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Working Paper Ceris del Consiglio Nazionale delle Ricerche, vol.
  8, n. 2 (2006)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1705.08955v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.08955v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.09418v1</id>
    <updated>2017-05-26T02:47:31Z</updated>
    <published>2017-05-26T02:47:31Z</published>
    <title>Nonparametric Regressions with Thresholds: Identification and
  Estimations</title>
    <summary>  This paper examines nonparametric regressions with an exogenous threshold
variable, allowing for an unknown number of thresholds. Given the number of
thresholds and corresponding threshold values, we first establish the
asymptotic properties of the local-constant estimator for a nonparametric
regression with multiple thresholds. We then determine the unknown number of
thresholds and derive the limiting distribution of the proposed test. The Monte
Carlo simulation results indicate the adequacy of the modified test and
accuracy of the sequential estimation of the threshold values. We apply our
testing procedure to an empirical study of the 401(k) retirement savings plan
with income thresholds.
</summary>
    <author>
      <name>Yan-Yu Chiou</name>
    </author>
    <author>
      <name>Mei-Yuan Chen</name>
    </author>
    <author>
      <name>Jau-er Chen</name>
    </author>
    <link href="http://arxiv.org/abs/1705.09418v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.09418v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.06302v1</id>
    <updated>2017-06-20T08:08:44Z</updated>
    <published>2017-06-20T08:08:44Z</published>
    <title>Deep Learning in (and of) Agent-Based Models: A Prospectus</title>
    <summary>  A very timely issue for economic agent-based models (ABMs) is their empirical
estimation. This paper describes a line of research that could resolve the
issue by using machine learning techniques, using multi-layer artificial neural
networks (ANNs), or so called Deep Nets. The seminal contribution by Hinton et
al. (2006) introduced a fast and efficient training algorithm called Deep
Learning, and there have been major breakthroughs in machine learning ever
since. Economics has not yet benefited from these developments, and therefore
we believe that now is the right time to apply Deep Learning and multi-layered
neural networks to agent-based models in economics.
</summary>
    <author>
      <name>Sander van der Hoog</name>
    </author>
    <link href="http://arxiv.org/abs/1706.06302v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.06302v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.07759v1</id>
    <updated>2017-04-23T15:28:50Z</updated>
    <published>2017-04-23T15:28:50Z</published>
    <title>The effect of the behavior of an average consumer on the public debt
  dynamics</title>
    <summary>  An important issue within the present economic crisis is understanding the
dynamics of the public debt of a given country, and how the behavior of average
consumers and tax payers in that country affects it. Starting from a model of
the average consumer behavior introduced earlier by the authors, we propose a
simple model to quantitatively address this issue. The model is then studied
and analytically solved under some reasonable simplifying assumptions. In this
way we obtain a condition under which the public debt steadily decreases.
</summary>
    <author>
      <name>Roberto De Luca</name>
    </author>
    <author>
      <name>Marco Di Mauro</name>
    </author>
    <author>
      <name>Angelo Falzarano</name>
    </author>
    <author>
      <name>Adele Naddeo</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.physa.2017.04.099</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.physa.2017.04.099" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 1 figures, submitted for publication to Physica A</arxiv:comment>
    <link href="http://arxiv.org/abs/1706.07759v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.07759v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.08479v2</id>
    <updated>2017-09-14T04:55:18Z</updated>
    <published>2017-06-07T22:08:05Z</published>
    <title>A Partial Solution to Continuous Blotto</title>
    <summary>  This paper analyzes the structure of mixed-strategy equilibria for Colonel
Blotto games, where the outcome on each battlefield is a polynomial function of
the difference between the two players' allocations. This paper severely
reduces the set of strategies that needs to be searched to find a Nash
equilibrium. It finds that there exists a Nash equilibrium where both players'
mixed strategies are discrete distributions, and it places an upper bound on
the number of points in the supports of these discrete distributions.
</summary>
    <author>
      <name>Kostyantyn Mazur</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper cites and relies on another paper, arXiv1706.02060 "Convex
  Hull of (t, t^2, ..., t^N)", that is posted on arXiv at the same time as this
  paper Version 2: added a reference</arxiv:comment>
    <link href="http://arxiv.org/abs/1706.08479v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.08479v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.09365v2</id>
    <updated>2017-07-20T14:52:34Z</updated>
    <published>2017-06-28T17:06:38Z</published>
    <title>Bilateral multifactor CES general equilibrium with state-replicating
  Armington elasticities</title>
    <summary>  We measure elasticity of substitution between foreign and domestic
commodities by two-point calibration such that the Armington aggregator can
replicate the two temporally distant observations of market shares and prices.
Along with the sectoral multifactor CES elasticities which we estimate by
regression using a set of disaggregated linked input--output observations, we
integrate domestic production of two countries, namely, Japan and the Republic
of Korea, with bilateral trade models and construct a bilateral general
equilibrium model. Finally, we make an assessment of a tariff elimination
scheme between the two countries.
</summary>
    <author>
      <name>Jiyoung Kim</name>
    </author>
    <author>
      <name>Satoshi Nakano</name>
    </author>
    <author>
      <name>Kazuhiko Nishimura</name>
    </author>
    <link href="http://arxiv.org/abs/1706.09365v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.09365v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.00947v1</id>
    <updated>2017-06-30T13:25:51Z</updated>
    <published>2017-06-30T13:25:51Z</published>
    <title>The Role of Money in the Business Cycle</title>
    <summary>  The aim of this paper is to reemphasize the money theory of exchange which is
centered on the function of exchange medium of money, and make a contribution
towards linearization of the quantity equation of exchange. A dynamical
quantity equation is presented and an important balanced path of economic
evolution is derived. To understand the business cycle we propose a hypothesis
of natural cycle and driving cycle concerning the evolution of the balanced
path and plentiful conclusions can be made.
</summary>
    <author>
      <name>Zhao Jianglin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">29 pages, 6 figures, 5 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1707.00947v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.00947v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.03335v1</id>
    <updated>2017-07-11T15:46:52Z</updated>
    <published>2017-07-11T15:46:52Z</published>
    <title>Viability and Arbitrage under Knightian Uncertainty</title>
    <summary>  We reconsider the microeconomic foundations of financial economics under
Knightian Uncertainty. In a general framework, we discuss the absence of
arbitrage, its relation to economic viability, and the existence of suitable
nonlinear pricing expectations. Classical financial markets under risk and no
ambiguity are contained as special cases, including various forms of the
Efficient Market Hypothesis. For Knightian uncertainty, our approach unifies
recent versions of the Fundamental Theorem of Asset Pricing under a common
framework.
</summary>
    <author>
      <name>Matteo Burzoni</name>
    </author>
    <author>
      <name>Frank Riedel</name>
    </author>
    <author>
      <name>H. Mete Soner</name>
    </author>
    <link href="http://arxiv.org/abs/1707.03335v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.03335v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B02, 91B52, 60H30" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.04699v1</id>
    <updated>2017-07-15T07:18:27Z</updated>
    <published>2017-07-15T07:18:27Z</published>
    <title>Good signals gone bad: dynamic signalling with switching efforts</title>
    <summary>  This paper examines signalling when the sender exerts effort and receives
benefits over time. Receivers only observe a noisy public signal about the
effort, which has no intrinsic value.
  The modelling of signalling in a dynamic context gives rise to novel
equilibrium outcomes. In some equilibria, a sender with a higher cost of effort
exerts strictly more effort than his low-cost counterpart. The low-cost type
can compensate later for initial low effort, but this is not worthwhile for a
high-cost type. The interpretation of a given signal switches endogenously over
time, depending on which type the receivers expect to send it.
  JEL classification: D82, D83, C73.
  Keywords: Dynamic games, signalling , incomplete information
</summary>
    <author>
      <name>Sander Heinsalu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1707.04699v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.04699v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.01085v1</id>
    <updated>2017-08-03T10:06:26Z</updated>
    <published>2017-08-03T10:06:26Z</published>
    <title>Lorenz curves interpretations of the Bruss-Duerinckx theorem for
  resource dependent branching processes</title>
    <summary>  The Bruss and Duerinckx theorem for resource dependent branching processes
states that the survival of any society form is nested in an envelope formed by
two extreme policies. The objective of this paper is to give a novel
interpretation of this theorem through the use of Lorenz curves. This
representation helps us visualize how the parameters interplay. Besides, as we
will show, it clarifies the impact of inequality in consumption.
</summary>
    <author>
      <name>Alexandre Jacquemain</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages with 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1708.01085v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.01085v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.01161v1</id>
    <updated>2017-08-03T14:35:16Z</updated>
    <published>2017-08-03T14:35:16Z</published>
    <title>Why we like the ECI+ algorithm</title>
    <summary>  Recently a measure for Economic Complexity named ECI+ has been proposed by
Albeaik et al. We like the ECI+ algorithm because it is mathematically
identical to the Fitness algorithm, the measure for Economic Complexity we
introduced in 2012. We demonstrate that the mathematical structure of ECI+ is
strictly equivalent to that of Fitness (up to normalization and rescaling). We
then show how the claims of Albeaik et al. about the ability of Fitness to
describe the Economic Complexity of a country are incorrect. Finally, we
hypothesize how the wrong results reported by these authors could have been
obtained by not iterating the algorithm.
</summary>
    <author>
      <name>Andrea Gabrielli</name>
    </author>
    <author>
      <name>Matthieu Cristelli</name>
    </author>
    <author>
      <name>Dario Mazzilli</name>
    </author>
    <author>
      <name>Andrea Tacchella</name>
    </author>
    <author>
      <name>Andrea Zaccaria</name>
    </author>
    <author>
      <name>Luciano Pietronero</name>
    </author>
    <link href="http://arxiv.org/abs/1708.01161v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.01161v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.01890v1</id>
    <updated>2017-08-06T13:44:10Z</updated>
    <published>2017-08-06T13:44:10Z</published>
    <title>Optimal Learning and Ellsberg's Urns</title>
    <summary>  We consider the dynamics of learning under ambiguity when learning is costly
and is chosen optimally. The setting is Ellsberg's two-urn thought experiment
modified by allowing the agent to postpone her choice between bets so that she
can learn about the composition of the ambiguous urn. Signals are modeled by a
diffusion process whose drift is equal to the true bias of the ambiguous urn
and they are observed at a constant cost per unit time. The resulting optimal
stopping problem is solved and the effect of ambiguity on the extent of
learning is determined. It is shown that rejection of learning opportunities
can be optimal for an ambiguity averse agent even given a small cost.
</summary>
    <author>
      <name>Larry G. Epstein</name>
    </author>
    <author>
      <name>Shaolin Ji</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">25 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1708.01890v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.01890v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.06855v1</id>
    <updated>2017-08-23T00:02:30Z</updated>
    <published>2017-08-23T00:02:30Z</published>
    <title>Systematic Noise: Micro-movements in Equity Options Markets</title>
    <summary>  Equity options are known to be notoriously difficult to price accurately, and
even with the development of established mathematical models there are many
assumptions that must be made about the underlying processes driving market
movements. As such, the theoretical prices outputted by these models are often
slightly different from the realized or actual market price. The choice of
model traders use can create many different valuations on the same asset, which
may lead to a form of systematic micro-movement or noise. The analysis in this
paper demonstrates that approximately 1.7%-4.5% of market volume for options
written on the SPY ETF within the last two years could potentially be due to
systematic noise.
</summary>
    <author>
      <name>Adam Wu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Undergraduate Research Paper</arxiv:comment>
    <link href="http://arxiv.org/abs/1708.06855v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.06855v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.07509v1</id>
    <updated>2017-08-24T11:58:56Z</updated>
    <published>2017-08-24T11:58:56Z</published>
    <title>The Keynesian Model in the General Theory: A Tutorial</title>
    <summary>  This small overview of the General Theory is the kind of summary I would have
liked to have read, before embarking in a comprehensive study of the General
Theory at the time I was a student. As shown here, the main ideas are quite
simple and easy to visualize. Unfortunately, numerous introductions to
Keynesian theory are not actually based on Keynes opus magnum, but in obscure
neoclassical reinterpretations. This is completely pointless since Keynes' book
is so readable.
</summary>
    <author>
      <name>Raul Rojas</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1708.07509v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.07509v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.07996v1</id>
    <updated>2017-08-26T16:55:49Z</updated>
    <published>2017-08-26T16:55:49Z</published>
    <title>A Simple Algorithm for Solving Ramsey Optimal Policy with Exogenous
  Forcing Variables</title>
    <summary>  This algorithm extends Ljungqvist and Sargent (2012) algorithm of Stackelberg
dynamic game to the case of dynamic stochastic general equilibrium models
including exogenous forcing variables. It is based Anderson, Hansen, McGrattan,
Sargent (1996) discounted augmented linear quadratic regulator. It adds an
intermediate step in solving a Sylvester equation. Forward-looking variables
are also optimally anchored on forcing variables. This simple algorithm calls
for already programmed routines for Ricatti, Sylvester and Inverse matrix in
Matlab and Scilab. A final step using a change of basis vector computes a
vector auto regressive representation including Ramsey optimal policy rule
function of lagged observable variables, when the exogenous forcing variables
are not observable.
</summary>
    <author>
      <name>Jean-Bernard Chatelain</name>
    </author>
    <author>
      <name>Kirsten Ralf</name>
    </author>
    <link href="http://arxiv.org/abs/1708.07996v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.07996v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91, 93" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.01024v2</id>
    <updated>2017-09-22T18:57:37Z</updated>
    <published>2017-08-31T20:49:22Z</published>
    <title>Learning and Equilibrium Refinements in Signalling Games</title>
    <summary>  We propose two new signalling-game refinements that are microfounded in a
model of patient Bayesian learning. Agents are born into player roles and play
the signalling game against a random opponent each period. Inexperienced agents
know their opponents' payoff functions but not the prevailing distribution of
opponents' play. One refinement corresponds to an upper bound on the set of
possible learning outcomes while the other provides a lower bound. Both
refinements are closely related to divine equilibrium (Banks and Sobel, 1987).
</summary>
    <author>
      <name>Drew Fudenberg</name>
    </author>
    <author>
      <name>Kevin He</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This material was previously part of a larger paper titled
  "Type-Compatible Equilibria in Signalling Games," which split into two
  smaller papers: "Learning and Type Compatibility in Signalling Games" and
  "Learning and Equilibrium Refinements in Signalling Games."</arxiv:comment>
    <link href="http://arxiv.org/abs/1709.01024v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.01024v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.06380v1</id>
    <updated>2017-09-19T12:55:53Z</updated>
    <published>2017-09-19T12:55:53Z</published>
    <title>Modeling of the Labour Force Redistribution in Investment Projects with
  Account of their Delay</title>
    <summary>  The mathematical model of the labour force redistribution in investment
projects is presented in the article. The redistribution mode of funds, labour
force in particular, according to the equal risk approach applied to the loss
of some assets due to delay in all the investment projects is provided in the
model. The sample of the developed model for three investment projects with the
specified labour force volumes and their defined unit costs at the particular
moment is given.
</summary>
    <author>
      <name>I. D. Kolesin</name>
    </author>
    <author>
      <name>O. A. Malafeyev</name>
    </author>
    <author>
      <name>I. V. Zaitseva</name>
    </author>
    <author>
      <name>A. N. Ermakova</name>
    </author>
    <author>
      <name>D. V. Shlaev</name>
    </author>
    <link href="http://arxiv.org/abs/1709.06380v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.06380v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.4695v1</id>
    <updated>2014-12-15T17:48:36Z</updated>
    <published>2014-12-15T17:48:36Z</published>
    <title>On Pareto theory of circulation of elites</title>
    <summary>  We prove that Pareto theory of circulation of elites results from our wealth
evolution model, Kelly criterion for optimal betting and Keynes' observation of
"animal spirits" that drive the economy and cause that human financial
decisions are prone to excess risk-taking.
</summary>
    <author>
      <name>Ricardo Pérez-Marco</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1412.4695v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.4695v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91D10, 91A60, 91B30, 91B55" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.08591v1</id>
    <updated>2015-11-27T09:39:06Z</updated>
    <published>2015-11-27T09:39:06Z</published>
    <title>On Game-Theoretic Risk Management (Part Two) - Algorithms to Compute
  Nash-Equilibria in Games with Distributions as Payoffs</title>
    <summary>  The game-theoretic risk management framework put forth in the precursor work
"Towards a Theory of Games with Payoffs that are Probability-Distributions"
(arXiv:1506.07368 [q-fin.EC]) is herein extended by algorithmic details on how
to compute equilibria in games where the payoffs are probability distributions.
Our approach is "data driven" in the sense that we assume empirical data
(measurements, simulation, etc.) to be available that can be compiled into
distribution models, which are suitable for efficient decisions about
preferences, and setting up and solving games using these as payoffs. While
preferences among distributions turn out to be quite simple if nonparametric
methods (kernel density estimates) are used, computing Nash-equilibria in games
using such models is discovered as inefficient (if not impossible). In fact, we
give a counterexample in which fictitious play fails to converge for the
(specifically unfortunate) choice of payoff distributions in the game, and
introduce a suitable tail approximation of the payoff densities to tackle the
issue. The overall procedure is essentially a modified version of fictitious
play, and is herein described for standard and multicriteria games, to
iteratively deliver an (approximate) Nash-equilibrium.
</summary>
    <author>
      <name>Stefan Rass</name>
    </author>
    <link href="http://arxiv.org/abs/1511.08591v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.08591v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.3678v2</id>
    <updated>2015-01-24T20:43:02Z</updated>
    <published>2014-04-14T18:17:30Z</published>
    <title>On the properties of nodal price response matrix in electricity markets</title>
    <summary>  We establish sufficient conditions for nodal price response matrix in
electric power system to be symmetric and negative (semi-)definite. The results
are applicable for electricity markets with nonlinear and intertemporal
constraints.
</summary>
    <author>
      <name>Vadim Borokhov</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TPWRS.2014.2376494</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TPWRS.2014.2376494" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Paper shortened and reformatted, some explanations added</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE Transactions on Power Systems, 30(6): 3286-3294 November 2015</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1404.3678v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.3678v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1409.6940v1</id>
    <updated>2014-09-18T15:24:22Z</updated>
    <published>2014-09-18T15:24:22Z</published>
    <title>Non-Implementability of Arrow-Debreu Equilibria by Continuous Trading
  under Knightian Uncertainty</title>
    <summary>  Under risk, Arrow-Debreu equilibria can be implemented as Radner equilibria
by continuous trading of few long-lived securities. We show that this result
generically fails if there is Knightian uncertainty in the volatility.
Implementation is only possible if all discounted net trades of the equilibrium
allocation are mean ambiguity-free.
</summary>
    <author>
      <name>Patrick Beissner</name>
    </author>
    <author>
      <name>Frank Riedel</name>
    </author>
    <link href="http://arxiv.org/abs/1409.6940v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1409.6940v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.MF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.MF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.00893v1</id>
    <updated>2015-08-04T03:35:11Z</updated>
    <published>2015-08-04T03:35:11Z</published>
    <title>Information Cascades and Online Rating Games</title>
    <summary>  Through mathematical analysis and simulations, online ratings and their
impact on businesses are characterized through two parameters: an inherent and
objective restaurant quality factor, and the accuracy of customers' gut feeling
about a business. Within this model, it is found that online ratings are seldom
accurate mainly because of the low or high accuracy in customers' gut feelings.
</summary>
    <author>
      <name>Oussama Fadil</name>
    </author>
    <author>
      <name>Jake Soloff</name>
    </author>
    <link href="http://arxiv.org/abs/1508.00893v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.00893v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1602.06234v1</id>
    <updated>2016-02-19T17:34:31Z</updated>
    <published>2016-02-19T17:34:31Z</published>
    <title>Household Income Distribution in the USA</title>
    <summary>  In this article we present an alternative model for the distribution of
household incomes in the United States. We provide arguments from two differing
perspectives which both yield the proposed income distribution curve, and then
fit this curve to empirical data on household income distribution obtained from
the United States Census Bureau.
</summary>
    <author>
      <name>Costas Efthimiou</name>
    </author>
    <author>
      <name>Adam Wearne</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1140/epjb/e2016-60670-1</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1140/epjb/e2016-60670-1" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">to appear in Eur. Phys. J. B</arxiv:comment>
    <link href="http://arxiv.org/abs/1602.06234v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1602.06234v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.01052v1</id>
    <updated>2016-05-02T20:37:16Z</updated>
    <published>2016-05-02T20:37:16Z</published>
    <title>Regrets, learning and wisdom</title>
    <summary>  This contribution discusses in what respect Econophysics may be able to
contribute to the rebuilding of economics theory. It focuses on aggregation,
individual vs collective learning and functional wisdom of the crowds.
</summary>
    <author>
      <name>Damien Challet</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1140/epjst/e2016-60122-y</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1140/epjst/e2016-60122-y" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 1 figure. Opinion paper submitted to European Physical
  Journal - Special Topics "Can economics be a physical science?"</arxiv:comment>
    <link href="http://arxiv.org/abs/1605.01052v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.01052v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.02688v2</id>
    <updated>2016-07-31T03:51:40Z</updated>
    <published>2016-07-10T03:55:29Z</published>
    <title>On the time consistency of collective preferences</title>
    <summary>  A model of collective decisions made by a finite number of agents with
constant but heterogeneous discount factors is developed. Collective utility is
obtained as the weighted sum of all individual utilities with time-varying
weights. It is shown that under standard separability assumptions, collective
preferences may be nonstationary but still satisfy time consistency.
</summary>
    <author>
      <name>Luis A. Alcala</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">26 pages; typos and minor corrections</arxiv:comment>
    <link href="http://arxiv.org/abs/1607.02688v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.02688v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="37N40, 91B10, 91B69, 49L20, 49K35" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1610.05892v1</id>
    <updated>2016-10-19T07:27:02Z</updated>
    <published>2016-10-19T07:27:02Z</published>
    <title>Centrality measures in networks based on nodes attributes, long-range
  interactions and group influence</title>
    <summary>  We propose a new method for assessing agents influence in network structures,
which takes into consideration nodes attributes, individual and group
influences of nodes, and the intensity of interactions. This approach helps us
to identify both explicit and hidden central elements which cannot be detected
by classical centrality measures or other indices.
</summary>
    <author>
      <name>F. Aleskerov</name>
    </author>
    <author>
      <name>N. Meshcheryakova</name>
    </author>
    <author>
      <name>S. Shvydun</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">44 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1610.05892v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1610.05892v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="90B10" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.6.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1611.01471v1</id>
    <updated>2016-11-04T17:57:28Z</updated>
    <published>2016-11-04T17:57:28Z</published>
    <title>A fair monetization model to reconcile authors and consumers of
  intellectual property</title>
    <summary>  In this small article one compromise monetization strategy is proposed, which
hopefully may lead to a more satisfactory coexistence of IP manufacturers and
consumers. The motto is "fair exchange": you use our IP-product, we use your
product (in form of money); when you do not need our product any more, we
change back.
</summary>
    <author>
      <name>Evgeny Ivanko</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1611.01471v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1611.01471v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.3347v1</id>
    <updated>2014-04-13T06:27:31Z</updated>
    <published>2014-04-13T06:27:31Z</published>
    <title>Stability and Identification with Optimal Macroprudential Policy Rules</title>
    <summary>  This paper investigates the identification, the determinacy and the stability
of ad hoc, "quasi-optimal" and optimal policy rules augmented with financial
stability indicators (such as asset prices deviations from their fundamental
values) and minimizing the volatility of the policy interest rates, when the
central bank precommits to financial stability. Firstly, ad hoc and
quasi-optimal rules parameters of financial stability indicators cannot be
identified. For those rules, non zero policy rule parameters of financial
stability indicators are observationally equivalent to rule parameters set to
zero in another rule, so that they are unable to inform monetary policy.
Secondly, under controllability conditions, optimal policy rules parameters of
financial stability indicators can all be identified, along with a bounded
solution stabilizing an unstable economy as in Woodford (2003), with
determinacy of the initial conditions of non- predetermined variables.
</summary>
    <author>
      <name>Jean-Bernard Chatelain</name>
    </author>
    <author>
      <name>Kirsten Ralf</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1404.3347v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.3347v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.0585v2</id>
    <updated>2015-06-05T13:03:09Z</updated>
    <published>2014-05-03T13:35:41Z</published>
    <title>Evaluating gambles using dynamics</title>
    <summary>  Gambles are random variables that model possible changes in monetary wealth.
Classic decision theory transforms money into utility through a utility
function and defines the value of a gamble as the expectation value of utility
changes. Utility functions aim to capture individual psychological
characteristics, but their generality limits predictive power. Expectation
value maximizers are defined as rational in economics, but expectation values
are only meaningful in the presence of ensembles or in systems with ergodic
properties, whereas decision-makers have no access to ensembles and the
variables representing wealth in the usual growth models do not have the
relevant ergodic properties. Simultaneously addressing the shortcomings of
utility and those of expectations, we propose to evaluate gambles by averaging
wealth growth over time. No utility function is needed, but a dynamic must be
specified to compute time averages. Linear and logarithmic "utility functions"
appear as transformations that generate ergodic observables for purely additive
and purely multiplicative dynamics, respectively. We highlight inconsistencies
throughout the development of decision theory, whose correction clarifies that
our perspective is legitimate. These invalidate a commonly cited argument for
bounded utility functions.
</summary>
    <author>
      <name>Ole Peters</name>
    </author>
    <author>
      <name>Murray Gell-Mann</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1063/1.4940236</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1063/1.4940236" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 2 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Chaos 26, 023103 (2016)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1405.0585v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.0585v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.2051v1</id>
    <updated>2014-05-07T11:58:31Z</updated>
    <published>2014-05-07T11:58:31Z</published>
    <title>Merchant Sharing Towards a Zero Marginal Cost Economy</title>
    <summary>  This paper is the first attempt to formalize a new field of economics;
studding the Intangibles Goods available on the Internet. We are taking
advantage of the digital world's specific rules, in particular the zero
marginal cost, to propose a theory of trading &amp; sharing unified. A function
based money is created as a world-wide currency; "cup". We argue that our
system discourage speculation activities while it makes easy captured taxes for
governments. The implementation removes the today's paywall on the Internet and
provides a simple-to-use, open-source, free-of-charge, highly-secure,
person-to-person, privacy-respectful, digital payment tool for citizens, using
standard smart-phones with a strong authentication. Next step will be the
propagation of the network application and we expect many shared benefits for
the whole economics development.
</summary>
    <author>
      <name>Laurent Fournier</name>
    </author>
    <link href="http://arxiv.org/abs/1405.2051v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.2051v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1406.5022v1</id>
    <updated>2014-06-19T12:30:40Z</updated>
    <published>2014-06-19T12:30:40Z</published>
    <title>Instabilities in large economies: aggregate volatility without
  idiosyncratic shocks</title>
    <summary>  We study a dynamical model of interconnected firms which allows for certain
market imperfections and frictions, restricted here to be myopic price
forecasts and slow adjustment of production. Whereas the standard rational
equilibrium is still formally a stationary solution of the dynamics, we show
that this equilibrium becomes linearly unstable in a whole region of parameter
space. When agents attempt to reach the optimal production target too quickly,
coordination breaks down and the dynamics becomes chaotic. In the unstable,
"turbulent" phase, the aggregate volatility of the total output remains
substantial even when the amplitude of idiosyncratic shocks goes to zero or
when the size of the economy becomes large. In other words, crises become
endogenous. This suggests an interesting resolution of the "small shocks, large
business cycles" puzzle.
</summary>
    <author>
      <name>Julius Bonart</name>
    </author>
    <author>
      <name>Jean-Philippe Bouchaud</name>
    </author>
    <author>
      <name>Augustin Landier</name>
    </author>
    <author>
      <name>David Thesmar</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1088/1742-5468/2014/10/P10040</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1088/1742-5468/2014/10/P10040" rel="related"/>
    <link href="http://arxiv.org/abs/1406.5022v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1406.5022v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1407.3749v2</id>
    <updated>2014-09-12T10:03:13Z</updated>
    <published>2014-05-29T14:48:38Z</published>
    <title>Microscopic Models for Welfare Measures Addressing a Reduction of
  Economic Inequality</title>
    <summary>  We formulate a flexible micro-to-macro kinetic model which is able to explain
the emergence of income profiles out of a whole of individual economic
interactions. The model is expressed by a system of several nonlinear
differential equations which involve parameters defined by probabilities.
Society is described as an ensemble of individuals divided into income classes;
the individuals exchange money through binary and ternary interactions, leaving
the total wealth unchanged. The ternary interactions represent taxation and
redistribution effects. Dynamics is investigated through computational
simulations, the focus being on the effects that different fiscal policies and
differently weighted welfare policies have on the long-run income
distributions. The model provides a tool which may contribute to the
identification of the most effective actions towards a reduction of economic
inequality. We find for instance that, under certain hypotheses, the Gini index
is more affected by a policy of reduction of the welfare and subsidies for the
rich classes than by an increase of the upper tax rate. Such a policy also has
the effect of slightly increasing the total tax revenue.
</summary>
    <author>
      <name>Maria Letizia Bertotti</name>
    </author>
    <author>
      <name>Giovanni Modanese</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1002/cplx.21669</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1002/cplx.21669" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 3 figures. arXiv admin note: text overlap with
  arXiv:1403.0015</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Complexity 21 (2016) 89-98</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1407.3749v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1407.3749v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1408.0440v1</id>
    <updated>2014-08-03T00:02:00Z</updated>
    <published>2014-08-03T00:02:00Z</published>
    <title>Contagious Synchronization and Endogenous Network Formation in Financial
  Networks</title>
    <summary>  When banks choose similar investment strategies the financial system becomes
vulnerable to common shocks. We model a simple financial system in which banks
decide about their investment strategy based on a private belief about the
state of the world and a social belief formed from observing the actions of
peers. Observing a larger group of peers conveys more information and thus
leads to a stronger social belief. Extending the standard model of Bayesian
updating in social networks, we show that the probability that banks
synchronize their investment strategy on a state non-matching action critically
depends on the weighting between private and social belief. This effect is
alleviated when banks choose their peers endogenously in a network formation
process, internalizing the externalities arising from social learning.
</summary>
    <author>
      <name>Christoph Aymanns</name>
    </author>
    <author>
      <name>Co-Pierre Georg</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.jbankfin.2014.06.030</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.jbankfin.2014.06.030" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">41 pages, 10 figures, Journal of Banking &amp; Finance 2014</arxiv:comment>
    <link href="http://arxiv.org/abs/1408.0440v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1408.0440v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.CP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1408.2138v1</id>
    <updated>2014-08-09T17:18:48Z</updated>
    <published>2014-08-09T17:18:48Z</published>
    <title>How the Taxonomy of Products Drives the Economic Development of
  Countries</title>
    <summary>  We introduce an algorithm able to reconstruct the relevant network structure
on which the time evolution of country-product bipartite networks takes place.
The significant links are obtained by selecting the largest values of the
projected matrix. We first perform a number of tests of this filtering
procedure on synthetic cases and a toy model. Then we analyze the bipartite
network constituted by countries and exported products, using two databases for
a total of almost 50 years. It is then possible to build a hierarchically
directed network, in which the taxonomy of products emerges in a natural way.
We study the influence of the structure of this taxonomy network on countries'
development; in particular, guided by an example taken from the
industrialization of South Korea, we link the structure of the taxonomy network
to the empirical temporal connections between product activations, finding that
the most relevant edges for countries' development are the ones suggested by
our network. These results suggest paths in the product space which are easier
to achieve, and so can drive countries' policies in the industrialization
process.
</summary>
    <author>
      <name>Andrea Zaccaria</name>
    </author>
    <author>
      <name>Matthieu Cristelli</name>
    </author>
    <author>
      <name>Andrea Tacchella</name>
    </author>
    <author>
      <name>Luciano Pietronero</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1371/journal.pone.0113770</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1371/journal.pone.0113770" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 8 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">PLoS ONE 9(12): e113770 (2014)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1408.2138v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1408.2138v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1409.7802v1</id>
    <updated>2014-09-27T11:38:22Z</updated>
    <published>2014-09-27T11:38:22Z</published>
    <title>Turnpike Property and Convergence Rate for an Investment Model with
  General Utility Functions</title>
    <summary>  In this paper we aim to address two questions faced by a long-term investor
with a power-type utility at high levels of wealth: one is whether the turnpike
property still holds for a general utility that is not necessarily
differentiable or strictly concave, the other is whether the error and the
convergence rate of the turnpike property can be estimated. We give positive
answers to both questions. To achieve these results, we first show that there
is a classical solution to the HJB equation and give a representation of the
solution in terms of the dual function of the solution to the dual HJB
equation. We demonstrate the usefulness of that representation with some
nontrivial examples that would be difficult to solve with the trial and error
method. We then combine the dual method and the partial differential equation
method to give a direct proof to the turnpike property and to estimate the
error and the convergence rate of the optimal policy when the utility function
is continuously differentiable and strictly concave. We finally relax the
conditions of the utility function and provide some sufficient conditions that
guarantee the turnpike property and the convergence rate in terms of both
primal and dual utility functions.
</summary>
    <author>
      <name>Baojun Bian</name>
    </author>
    <author>
      <name>Harry Zheng</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">29 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1409.7802v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1409.7802v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.0249v2</id>
    <updated>2014-12-12T11:35:10Z</updated>
    <published>2014-10-01T14:57:49Z</published>
    <title>On the convergence of the Fitness-Complexity Algorithm</title>
    <summary>  We investigate the convergence properties of an algorithm which has been
recently proposed to measure the competitiveness of countries and the quality
of their exported products. These quantities are called respectively Fitness F
and Complexity Q. The algorithm was originally based on the adjacency matrix M
of the bipartite network connecting countries with the products they export,
but can be applied to any bipartite network. The structure of the adjacency
matrix turns to be essential to determine which countries and products converge
to non zero values of F and Q. Also the speed of convergence to zero depends on
the matrix structure. A major role is played by the shape of the ordered matrix
and, in particular, only those matrices whose diagonal does not cross the empty
part are guaranteed to have non zero values as outputs when the algorithm
reaches the fixed point. We prove this result analytically for simplified
structures of the matrix, and numerically for real cases. Finally, we propose
some practical indications to take into account our results when the algorithm
is applied.
</summary>
    <author>
      <name>Emanuele Pugliese</name>
    </author>
    <author>
      <name>Andrea Zaccaria</name>
    </author>
    <author>
      <name>Luciano Pietronero</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 8 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1410.0249v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.0249v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.4922v1</id>
    <updated>2014-10-18T09:00:27Z</updated>
    <published>2014-10-18T09:00:27Z</published>
    <title>Assessing the Inequalities of Wealth in Regions: the Italian Case</title>
    <summary>  This paper discusses region wealth size distributions, through their member
cities aggregated tax income. As an illustration, the official data of the
Italian Ministry of Economics and Finance has been considered, for all Italian
municipalities, over the period 2007-2011. Yearly data of the aggregated tax
income is transformed into a few indicators: the Gini, Theil, and
Herfindahl-Hirschman indices. On one hand, the relative interest of each index
is discussed. On the other hand, numerical results confirm that Italy is
divided into very different regional realities, a few which are specifically
outlined. This shows the interest of transforming data in an adequate manner
and of comparing such indices.
</summary>
    <author>
      <name>Roy Cerqueti</name>
    </author>
    <author>
      <name>Marcel Ausloos</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s11135-014-0111-y</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s11135-014-0111-y" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">to be published in Quality and Quantity; 23 pages; 1 figure; 23
  tables; 19 references</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Quality and Quantity, 49(6), 2307-2323 (2015)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1410.4922v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.4922v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.5068v2</id>
    <updated>2014-10-28T10:11:06Z</updated>
    <published>2014-10-19T13:00:34Z</published>
    <title>RHOMOLO: A Dynamic Spatial General Equilibrium Model for Assessing the
  Impact of Cohesion Policy</title>
    <summary>  The paper presents the newly developed dynamic spatial general equilibrium
model of European Commission, RHOMOLO. The model incorporates several elements
from economic geography in a novel and theoretically consistent way. It
describes the location choice of different types of agents and captures the
interplay between agglomeration and dispersion forces in determining the
spatial equilibrium. The model is also dynamic as it allows for the
accumulation of factors of production, human capital and technology. This makes
RHOMOLO well suited for simulating policy scenario related to the EU cohesion
policy and for the analysis of its impact on the regions and the Member States
of the union.
</summary>
    <author>
      <name>Andries Brandsma</name>
    </author>
    <author>
      <name>d'Artis Kancs</name>
    </author>
    <author>
      <name>Philippe Monfort</name>
    </author>
    <author>
      <name>Alexandra Rillaers</name>
    </author>
    <link href="http://arxiv.org/abs/1410.5068v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.5068v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1411.1152v3</id>
    <updated>2016-05-07T15:17:12Z</updated>
    <published>2014-11-05T05:03:24Z</published>
    <title>Berk-Nash Equilibrium: A Framework for Modeling Agents with Misspecified
  Models</title>
    <summary>  We develop an equilibrium framework that relaxes the standard assumption that
people have a correctly-specified view of their environment. Each player is
characterized by a (possibly misspecified) subjective model, which describes
the set of feasible beliefs over payoff-relevant consequences as a function of
actions. We introduce the notion of a Berk-Nash equilibrium: Each player
follows a strategy that is optimal given her belief, and her belief is
restricted to be the best fit among the set of beliefs she considers possible.
The notion of best fit is formalized in terms of minimizing the
Kullback-Leibler divergence, which is endogenous and depends on the equilibrium
strategy profile. Standard solution concepts such as Nash equilibrium and
self-confirming equilibrium constitute special cases where players have
correctly-specified models. We provide a learning foundation for Berk-Nash
equilibrium by extending and combining results from the statistics literature
on misspecified learning and the economics literature on learning in games.
</summary>
    <author>
      <name>Ignacio Esponda</name>
    </author>
    <author>
      <name>Demian Pouzo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">58 pages. Version Accepted in Econometrica</arxiv:comment>
    <link href="http://arxiv.org/abs/1411.1152v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1411.1152v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1411.1368v1</id>
    <updated>2014-10-14T06:14:16Z</updated>
    <published>2014-10-14T06:14:16Z</published>
    <title>Cooperation under Incomplete Information on the Discount Factors</title>
    <summary>  In repeated games, cooperation is possible in equilibrium only if players are
sufficiently patient, and long-term gains from cooperation outweigh short-term
gains from deviation. What happens if the players have incomplete information
regarding each other's discount factors? In this paper we look at repeated
games in which each player has incomplete information regarding the other
player's discount factor, and ask when full cooperation can arise in
equilibrium. We provide necessary and sufficient conditions that allow full
cooperation in equilibrium that is composed of grim trigger strategies, and
characterize the states of the world in which full cooperation occurs. We then
ask whether these "cooperation events" are close to those in the complete
information case, when the information on the other player's discount factor is
"almost" complete.
</summary>
    <author>
      <name>Cy Maor</name>
    </author>
    <author>
      <name>Eilon Solan</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s00182-014-0431-0</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s00182-014-0431-0" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">appears in International Journal of Game Theory, 2014</arxiv:comment>
    <link href="http://arxiv.org/abs/1411.1368v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1411.1368v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1411.2138v1</id>
    <updated>2014-11-08T17:09:39Z</updated>
    <published>2014-11-08T17:09:39Z</published>
    <title>It's not the economy, stupid! How social capital and GDP relate to
  happiness over time</title>
    <summary>  What predicts the evolution over time of subjective well-being? We correlate
the trends of subjective well-being with the trends of social capital and/or
GDP. We find that in the long and medium run social capital largely predicts
the trends of subjective wellbeing in our sample of countries. In the
short-term this relationship weakens. Indeed, in the short run, changes in
social capital predict a much smaller portion of the changes in subjective
well-being than over longer periods. GDP follows a reverse path, thus
confirming the Easterlin paradox: in the short run GDP is more positively
correlated to well-being than in the medium-term, while in the long run this
correlation vanishes.
</summary>
    <author>
      <name>Stefano Bartolini</name>
    </author>
    <author>
      <name>Francesco Sarracino</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">48 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1411.2138v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1411.2138v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1411.3078v6</id>
    <updated>2016-10-04T02:26:00Z</updated>
    <published>2014-11-12T05:43:35Z</published>
    <title>Long Term Risk: A Martingale Approach</title>
    <summary>  This paper extends the long-term factorization of the stochastic discount
factor introduced and studied by Alvarez and Jermann (2005) in discretetime
ergodic environments and by Hansen and Scheinkman (2009) and Hansen (2012) in
Markovian environments to general semimartingale environments. The transitory
component discounts at the stochastic rate of return on the long bond and is
factorized into discounting at the long-term yield and a positive
semimartingale that extends the principal eigenfunction of Hansen and
Scheinkman (2009) to the semimartingale setting. The permanent component is a
martingale that accomplishes a change of probabilities to the long forward
measure, the limit of T-forward measures. The change of probabilities from the
data generating to the long forward measure absorbs the long-term risk-return
trade-off and interprets the latter as the long-term risk-neutral measure.
</summary>
    <author>
      <name>Likuan Qin</name>
    </author>
    <author>
      <name>Vadim Linetsky</name>
    </author>
    <link href="http://arxiv.org/abs/1411.3078v6" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1411.3078v6" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1411.6250v7</id>
    <updated>2015-11-21T04:13:58Z</updated>
    <published>2014-11-23T15:36:45Z</published>
    <title>Identifying Multidiemsnional Adverse Selection Models</title>
    <summary>  In this paper, I study the nonparametric identification of a multidimensional
adverse selection model. In particular, I consider the screening model of
Rochet and Chone (1998), where products have multiple characteristics and
consumers have private information about their multidimensional taste for these
characteristics, and determine the data features and additional condition(s)
that identify model parameters. The parameters include the nonparametric joint
density of consumer taste, the cost function, and the utility function, and the
data includes individual-level data on choices and prices paid from one market.
When the utility is nonlinear in product characteristics, however, data from
one market is not enough, but with data from at least two markets, or over two
periods, with different marginal prices is sufficient for identification as
long as these price differences are due to exogenous (and binary) changes in
cost and not because the two markets are inherently different. I also derive
all testable conditions for a joint distribution of observed choices and prices
to be rationalized by a model of multidimensional adverse selection.
</summary>
    <author>
      <name>Gaurab Aryal</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">43 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1411.6250v7" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1411.6250v7" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1501.00434v2</id>
    <updated>2016-01-12T19:33:34Z</updated>
    <published>2015-01-02T16:31:20Z</published>
    <title>Monetary Policy and Dark Corners in a stylized Agent-Based Model</title>
    <summary>  We extend in a minimal way the stylized model introduced in in "Tipping
Points in Macroeconomic Agent Based Models" [JEDC 50, 29-61 (2015)], with the
aim of investigating the role and efficacy of monetary policy of a `Central
Bank' that sets the interest rate such as to steer the economy towards a
prescribed inflation and employment level. Our major finding is that provided
its policy is not too aggressive (in a sense detailed in the paper) the Central
Bank is successful in achieving its goals. However, the existence of different
equilibrium states of the economy, separated by phase boundaries (or "dark
corners"), can cause the monetary policy itself to trigger instabilities and be
counter-productive. In other words, the Central Bank must navigate in a narrow
window: too little is not enough, too much leads to instabilities and wildly
oscillating economies. This conclusion strongly contrasts with the prediction
of DSGE models.
</summary>
    <author>
      <name>Stanislao Gualdi</name>
    </author>
    <author>
      <name>Marco Tarzia</name>
    </author>
    <author>
      <name>Francesco Zamponi</name>
    </author>
    <author>
      <name>Jean-Philippe Bouchaud</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s11403-016-0174-z</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s11403-016-0174-z" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Contribution to the CRISIS project, 25 pages, 21 figures, pseudo-code
  of the model, revised and improved version</arxiv:comment>
    <link href="http://arxiv.org/abs/1501.00434v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1501.00434v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.00104v1</id>
    <updated>2015-01-31T13:29:34Z</updated>
    <published>2015-01-31T13:29:34Z</published>
    <title>Worldwide clustering of the corruption perception</title>
    <summary>  We inspect a possible clustering structure of the corruption perception among
134 countries. Using the average linkage clustering, we uncover a well-defined
hierarchy in the relationships among countries. Four main clusters are
identified and they suggest that countries worldwide can be quite well
separated according to their perception of corruption. Moreover, we find a
strong connection between corruption levels and a stage of development inside
the clusters. The ranking of countries according to their corruption perfectly
copies the ranking according to the economic performance measured by the gross
domestic product per capita of the member states. To the best of our knowledge,
this study is the first one to present an application of hierarchical and
clustering methods to the specific case of corruption.
</summary>
    <author>
      <name>Michal Paulus</name>
    </author>
    <author>
      <name>Ladislav Kristoufek</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.physa.2015.01.065</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.physa.2015.01.065" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 3 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Physica A: Statistical Mechanics and Its Applications (2015), vol.
  428, pp. 351-358</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1502.00104v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.00104v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.00674v3</id>
    <updated>2017-01-21T22:03:44Z</updated>
    <published>2015-02-02T22:26:21Z</published>
    <title>An equilibrium model for spot and forward prices of commodities</title>
    <summary>  We consider a market model that consists of financial investors and producers
of a commodity. Producers optionally store some production for future sale and
go short on forward contracts to hedge the uncertainty of the future commodity
price. Financial investors take positions in these contracts in order to
diversify their portfolios. The spot and forward equilibrium commodity prices
are endogenously derived as the outcome of the interaction between producers
and investors. Assuming that both are utility maximizers, we first prove the
existence of an equilibrium in an abstract setting. Then, in a framework where
the consumers' demand and the exogenously priced financial market are
correlated, we provide semi-explicit expressions for the equilibrium prices and
analyze their dependence on the model parameters. The model can explain why
increased investors' participation in forward commodity markets and higher
correlation between the commodity and the stock market could result in higher
spot prices and lower forward premia.
</summary>
    <author>
      <name>Michail Anthropelos</name>
    </author>
    <author>
      <name>Michael Kupper</name>
    </author>
    <author>
      <name>Antonis Papapantoleon</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">42 pages, 7 figures. Final version, forthcoming in Mathematics of
  Operations Research</arxiv:comment>
    <link href="http://arxiv.org/abs/1502.00674v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.00674v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B50, 90B05" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.00861v1</id>
    <updated>2015-02-03T13:50:40Z</updated>
    <published>2015-02-03T13:50:40Z</published>
    <title>An Optimal Multiple Stopping Approach to Infrastructure Investment
  Decisions</title>
    <summary>  The energy and material processing industries are traditionally characterized
by very large-scale physical capital that is custom-built with long lead times
and long lifetimes. However, recent technological advancement in low-cost
automation has made possible the parallel operation of large numbers of
small-scale and modular production units. Amenable to mass-production, these
units can be more rapidly deployed but they are also likely to have a much
quicker turnover. Such a paradigm shift motivates the analysis of the combined
effect of lead time and lifetime on infrastructure investment decisions. In
order to value the underlying real option, we introduce an optimal multiple
stopping approach that accounts for operational flexibility, delay induced by
lead time, and multiple (finite/infinite) future investment opportunities. We
provide an analytical characterization of the firm's value function and optimal
stopping rule. This leads us to develop an iterative numerical scheme, and
examine how the investment decisions depend on lead time and lifetime, as well
as other parameters. Furthermore, our model can be used to analyze the critical
investment cost that makes small-scale (short lead time, short lifetime)
alternatives competitive with traditional large-scale infrastructure.
</summary>
    <author>
      <name>Eric Dahlgren</name>
    </author>
    <author>
      <name>Tim Leung</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">27 pages, 7 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Economic Dynamics &amp; Control, vol. 53, pp.251-267, 2015</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1502.00861v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.00861v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="60G40, 62L15, 62L20" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.00882v1</id>
    <updated>2015-02-03T15:09:07Z</updated>
    <published>2015-02-03T15:09:07Z</published>
    <title>A New Methodology for Estimating Internal Credit Risk and Bankruptcy
  Prediction under Basel II Regime</title>
    <summary>  Credit estimation and bankruptcy prediction methods have been utilizing
Altman's $z$ score method for the last several years. It is reported in many
studies that $z$ score is sensitive to changes in accounting figures.
Researches have proposed different variations to conventional $z$ score that
can improve the prediction accuracy. In this paper we develop a new
multivariate non-linear model for computing the $z$ score. In addition we
develop a new credit risk index by fitting a Pearson type-III distribution to
the transformed financial ratios. The results from our study have shown that
the new $z$ score can predict the bankruptcy with an accuracy of $98.6\%$ as
compared to $93.5\%$ by the Altman's $z$ score. Also, the discriminate analysis
revealed that the new transformed financial ratios could predict the bankruptcy
probability with an accuracy of $93.0\%$ as compared to $87.4\%$ using the
weights of Altman's $z$ score.
</summary>
    <author>
      <name>M. Naresh Kumar</name>
    </author>
    <author>
      <name>V. Sree Hari Rao</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s10614-014-9452-9</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s10614-014-9452-9" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 1 figure in Computational Economics, 2014</arxiv:comment>
    <link href="http://arxiv.org/abs/1502.00882v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.00882v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.03840v2</id>
    <updated>2015-07-06T19:26:25Z</updated>
    <published>2015-02-12T21:38:57Z</published>
    <title>Market Dynamics and Indirect Network Effects in Electric Vehicle
  Diffusion</title>
    <summary>  The diffusion of electric vehicles (EVs) is studied in a two-sided market
framework consisting of EVs on the one side and EV charging stations (EVCSs) on
the other. A sequential game is introduced as a model for the interactions
between an EVCS investor and EV consumers. A consumer chooses to purchase an EV
or a conventional gasoline alternative based on the upfront costs of purchase,
the future operating costs and the availability of charging stations. The
investor, on the other hand, maximizes his profit by deciding whether to build
charging facilities at a set of potential EVCS sites or to defer his
investments. The solution of the sequential game characterizes the EV-EVCS
market equilibrium. The market solution is compared with that of a social
planner who invests in EVCSs with the goal of maximizing the social welfare. It
is shown that the market solution underinvests EVCSs, leading to slower EV
diffusion. The effects of subsidies for EV purchase and EVCSs are also
considered.
</summary>
    <author>
      <name>Zhe Yu</name>
    </author>
    <author>
      <name>Shanjun Li</name>
    </author>
    <author>
      <name>Lang Tong</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.trd.2016.06.010</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.trd.2016.06.010" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages, 8 figures, journal paper</arxiv:comment>
    <link href="http://arxiv.org/abs/1502.03840v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.03840v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.05274v4</id>
    <updated>2015-11-25T11:17:54Z</updated>
    <published>2015-02-18T15:32:12Z</published>
    <title>How predictable is technological progress?</title>
    <summary>  Recently it has become clear that many technologies follow a generalized
version of Moore's law, i.e. costs tend to drop exponentially, at different
rates that depend on the technology. Here we formulate Moore's law as a
correlated geometric random walk with drift, and apply it to historical data on
53 technologies. We derive a closed form expression approximating the
distribution of forecast errors as a function of time. Based on hind-casting
experiments we show that this works well, making it possible to collapse the
forecast errors for many different technologies at different time horizons onto
the same universal distribution. This is valuable because it allows us to make
forecasts for any given technology with a clear understanding of the quality of
the forecasts. As a practical demonstration we make distributional forecasts at
different time horizons for solar photovoltaic modules, and show how our method
can be used to estimate the probability that a given technology will outperform
another technology at a given point in the future.
</summary>
    <author>
      <name>J. Doyne Farmer</name>
    </author>
    <author>
      <name>Francois Lafond</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.respol.2015.11.001</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.respol.2015.11.001" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Research Policy, Volume 45, Issue 3, Pages 647-665 (April 2016)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1502.05274v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.05274v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.06901v2</id>
    <updated>2016-05-14T04:42:07Z</updated>
    <published>2015-02-24T18:30:05Z</published>
    <title>Equilibrium in Misspecified Markov Decision Processes</title>
    <summary>  We study Markov decision problems where the agent does not know the
transition probability function mapping current states and actions to future
states. The agent has a prior belief over a set of possible transition
functions and updates beliefs using Bayes' rule. We allow her to be
misspecified in the sense that the true transition probability function is not
in the support of her prior. This problem is relevant in many economic settings
but is usually not amenable to analysis by the researcher. We make the problem
tractable by studying asymptotic behavior. We propose an equilibrium notion and
provide conditions under which it characterizes steady state behavior. In the
special case where the problem is static, equilibrium coincides with the
single-agent version of Berk-Nash equilibrium (Esponda and Pouzo (2016)). We
also discuss subtle issues that arise exclusively in dynamic settings due to
the possibility of a negative value of experimentation.
</summary>
    <author>
      <name>Ignacio Esponda</name>
    </author>
    <author>
      <name>Demian Pouzo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">54 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1502.06901v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.06901v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.07389v5</id>
    <updated>2017-08-15T19:06:33Z</updated>
    <published>2015-03-25T14:20:43Z</published>
    <title>Sorting in Networks: Adversity and Structure</title>
    <summary>  People choose friendships with people similar to themselves, i.e. they sort
by resemblence. Economic studies have shown when sorting is optimal and
constitute an equilibrium, however, this presumes lack of beneficial
spillovers. We investigate formation of economic and social networks where
agents may form or cut ties. We combine a setup with link formation where
agents have types that determine the value of a connection. We provide
conditions for sorting in friendships, i.e. that agents tend to partner only
with those with those sufficiently similar to themselves. Conditions are
provided with and without beneficial spillovers from indirect connections. We
show that sorting may be suboptimal, yet a socially stable outcome, despite
otherwise obeying the conditions for sorting in Becker (1973). We analyze
policy tools to mitigate suboptimal sorting. Another feature is that agents
with higher value are more central in networks under certain conditions; a side
effect is sorting by degree centrality under certain conditions. Finally we
illustrate the limits to patterns of sorting and centrality.
</summary>
    <author>
      <name>Andreas Bjerre-Nielsen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">49 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1503.07389v5" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.07389v5" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.03508v1</id>
    <updated>2015-04-14T12:08:54Z</updated>
    <published>2015-04-14T12:08:54Z</published>
    <title>Systemic trade-risk of critical resources</title>
    <summary>  In the wake of the 2008 financial crisis the role of strongly interconnected
markets in fostering systemic instability has been increasingly acknowledged.
Trade networks of commodities are susceptible to deleterious cascades of supply
shocks that increase systemic trade-risks and pose a threat to geopolitical
stability. On a global and a regional level we show that supply risk, scarcity,
and price volatility of non-fuel mineral resources are intricately connected
with the structure of the world-trade network of or spanned by these resources.
On the global level we demonstrate that the scarcity of a resource, as measured
by its trade volume compared to extractable reserves, is closely related to the
susceptibility of the trade network with respect to cascading shocks. On the
regional level we find that to some extent the region-specific price volatility
and supply risk can be understood by centrality measures that capture systemic
trade-risk. The resources associated with the highest systemic trade-risk
indicators are often those that are produced as byproducts of major metals. We
identify significant shortcomings in the management of systemic trade-risk, in
particular in the EU.
</summary>
    <author>
      <name>Peter Klimek</name>
    </author>
    <author>
      <name>Michael Obersteiner</name>
    </author>
    <author>
      <name>Stefan Thurner</name>
    </author>
    <link href="http://arxiv.org/abs/1504.03508v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.03508v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.03895v2</id>
    <updated>2015-09-10T22:05:20Z</updated>
    <published>2015-04-15T12:54:51Z</published>
    <title>Graph representation of balance sheets: from exogenous to endogenous
  money</title>
    <summary>  The nature of monetary arrangements is often discussed without any reference
to its detailed construction. We present a graph representation which allows
for a clear understanding of modern monetary systems. First, we show that
systems based on commodity money are incompatible with credit. We then study
the current chartalist systems based on pure fiat money, and we discuss the
consolidation of the central bank with the Treasury. We obtain a visual
explanation about how commercial banks are responsible for endogenous money
creation whereas the Treasury and the central bank are in charge of the total
amount of net money. Finally we draw an analogy between systems based on gold
convertibility and currency pegs to show that fixed exchange rates can never be
maintained.
</summary>
    <author>
      <name>Cyril Pitrou</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">29 pages, 12 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1504.03895v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.03895v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.06634v3</id>
    <updated>2015-12-11T15:45:51Z</updated>
    <published>2015-04-24T20:28:53Z</published>
    <title>Efficient Network Structures with Separable Heterogeneous Connection
  Costs</title>
    <summary>  We introduce a heterogeneous connection model for network formation to
capture the effect of cost heterogeneity on the structure of efficient
networks. In the proposed model, connection costs are assumed to be separable,
which means the total connection cost for each agent is uniquely proportional
to its degree. For these sets of networks, we provide the analytical solution
for the efficient network and discuss stability impli- cations. We show that
the efficient network exhibits a core-periphery structure, and for a given
density, we find a lower bound for clustering coefficient of the efficient
network.
</summary>
    <author>
      <name>Babak Heydari</name>
    </author>
    <author>
      <name>Mohsen Mosleh</name>
    </author>
    <author>
      <name>Kia Dalili</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.econlet.2015.06.014</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.econlet.2015.06.014" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Economics Letters, Vol. 134, September 2015, 82-85</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1504.06634v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.06634v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.06909v2</id>
    <updated>2015-04-28T22:04:44Z</updated>
    <published>2015-04-27T02:31:52Z</published>
    <title>The Social Cost of Carbon with Economic and Climate Risks</title>
    <summary>  There is great uncertainty about future climate conditions and the
appropriate policies for managing interactions between the climate and the
economy. We develop a multidimensional computational model to examine how
uncertainties and risks in the economic and climate systems affect the social
cost of carbon (SCC)---that is, the present value of the marginal damage to
economic output caused by carbon emissions. The SCC is substantially increased
by economic and climate risks at both current and future times. Furthermore,
the SCC is itself a stochastic process with significant variation; for example,
the basic elements of risk incorporated into our model cause the SCC in 2100 to
be, with significant probability, ten times what it would be without those
risks. We have only imprecise information about what parameter values are best
for approximating reality. To deal with this parametric uncertainty we perform
extensive uncertainty quantification and show that these findings are robust
for a wide range of alternative specifications. More generally, this work shows
that large-scale computing can enable economists to examine substantially more
complex and realistic models for the purposes of policy analysis.
</summary>
    <author>
      <name>Yongyang Cai</name>
    </author>
    <author>
      <name>Kenneth L. Judd</name>
    </author>
    <author>
      <name>Thomas S. Lontzek</name>
    </author>
    <link href="http://arxiv.org/abs/1504.06909v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.06909v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.00146v2</id>
    <updated>2017-07-11T23:46:56Z</updated>
    <published>2015-05-30T17:57:22Z</published>
    <title>The Theory of a Heliospheric Economy</title>
    <summary>  Despite more than 50 years of human space exploration, no paper in the field
of economics has been published regarding the theory of a space-based economy.
The aim of this paper is to develop quantitative techniques to estimate
conditions of the human heliospheric expansion. An empirical analysis of
current space commercialization and reasoning from first economic principles
yields an evolutionary prisoner's dilemma game on a dynamically scaled
heterogeneous Newman-Watts Small World Network to generate a new space. The
analysis allows for scalar measurements of behavior, market structures, wealth,
and technological prowess, with time measured relative to the system. Four
major phases of heliospheric expansion become evident, in which the dynamic of
the economic environment drives further exploration. Further research could
combine empirical estimations of parameters with computer simulations to prove
results to inform long-term business plans or public policy to further
incentivize human heliospheric domination.
</summary>
    <author>
      <name>Thomas Tarler</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Needs revision, not comfortable with having it up as is. For example,
  citation errors</arxiv:comment>
    <link href="http://arxiv.org/abs/1506.00146v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.00146v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.02521v1</id>
    <updated>2015-06-08T14:34:51Z</updated>
    <published>2015-06-08T14:34:51Z</published>
    <title>Nonlocal Solutions to Dynamic Equilibrium Models: The Approximate Stable
  Manifolds Approach</title>
    <summary>  This study presents a method for constructing a sequence of approximate
solutions of increasing accuracy to general equilibrium models on nonlocal
domains. The method is based on a technique originated from dynamical systems
theory. The approximate solutions are constructed employing the Contraction
Mapping Theorem and the fact that solutions to general equilibrium models
converge to a steady state. The approach allows deriving the a priori and a
posteriori approximation errors of the solutions. Under certain nonlocal
conditions we prove the convergence of the approximate solutions to the true
solution and hence the Stable Manifold Theorem. We also show that the proposed
approach can be treated as a rigorous proof of convergence for the extended
path algorithm to the true solution in a class of nonlinear rational
expectation models.
</summary>
    <author>
      <name>Viktors Ajevskis</name>
    </author>
    <link href="http://arxiv.org/abs/1506.02521v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.02521v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.CP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.02522v1</id>
    <updated>2015-06-08T14:36:29Z</updated>
    <published>2015-06-08T14:36:29Z</published>
    <title>Semi-Global Solutions to DSGE Models: Perturbation around a
  Deterministic Path</title>
    <summary>  This study proposes an approach based on a perturbation technique to
construct global solutions to dynamic stochastic general equilibrium models
(DSGE). The main idea is to expand a solution in a series of powers of a small
parameter scaling the uncertainty in the economy around a solution to the
deterministic model, i.e. the model where the volatility of the shocks
vanishes. If a deterministic path is global in state variables, then so are the
constructed solutions to the stochastic model, whereas these solutions are
local in the scaling parameter. Under the assumption that a deterministic path
is already known the higher order terms in the expansion are obtained
recursively by solving linear rational expectations models with time-varying
parameters. The present work also proposes a method rested on backward
recursion for solving general systems of linear rational expectations models
with time-varying parameters and determines the conditions under which the
solutions of the method exist.
</summary>
    <author>
      <name>Viktors Ajevskis</name>
    </author>
    <link href="http://arxiv.org/abs/1506.02522v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.02522v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.CP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.03106v3</id>
    <updated>2016-02-13T15:40:57Z</updated>
    <published>2015-06-09T21:21:09Z</published>
    <title>Business cycle synchronization within the European Union: A wavelet
  cohesion approach</title>
    <summary>  In this paper, we map the process of business cycle synchronization across
the European Union. We study this synchronization by applying wavelet
techniques, particularly the cohesion measure with time-varying weights. This
novel approach allows us to study the dynamic relationship among selected
countries from a different perspective than the usual time-domain models.
Analyzing monthly data from 1990 to 2014, we show an increasing co-movement of
the Visegrad countries with the European Union after the countries began
preparing for the accession to the European Union. With particular focus on the
Visegrad countries we show that participation in a currency union possibly
increases the co-movement. Furthermore, we find a high degree of
synchronization in long-term horizons by analyzing the Visegrad Four and
Southern European countries' synchronization with the core countries of the
European Union.
</summary>
    <author>
      <name>Lubos Hanus</name>
    </author>
    <author>
      <name>Lukas Vacha</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1506.03106v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.03106v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.03347v3</id>
    <updated>2016-03-24T17:34:48Z</updated>
    <published>2015-06-10T15:02:15Z</published>
    <title>Time-scale analysis of co-movement in EU sovereign bond markets</title>
    <summary>  We study the co-movement of the 10-year sovereign bond yields of 11 EU
countries. Our analysis is focused mainly on changes in co-movement during the
financial crisis period, especially around two significant dates - the fall of
Lehman Brothers, September 15, 2008, and the announcement of the increase of
Greece's public deficit on October 20, 2009. We study co-movement dynamics
using wavelet analysis, which allows us to observe how co-movement changes
across frequencies and over time. We divide the countries into three groups:
the core of the Eurozone, the periphery of the Eurozone and the states outside
the Eurozone. The results indicate that co-movement decreased considerably
during the crisis period for all country pairs but that there are significant
differences among the groups. Furthermore, we demonstrate that the co-movement
of bond yields is frequency (scale) dependent.
</summary>
    <author>
      <name>Filip Smolik</name>
    </author>
    <author>
      <name>Lukas Vacha</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">new version is too large</arxiv:comment>
    <link href="http://arxiv.org/abs/1506.03347v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.03347v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.03597v1</id>
    <updated>2015-06-11T09:26:47Z</updated>
    <published>2015-06-11T09:26:47Z</published>
    <title>How log-normal is your country? An analysis of the statistical
  distribution of the exported volumes of products</title>
    <summary>  We have considered the statistical distributions of the volumes of the
different products exported by 148 countries. We have found that the form of
these distributions is not unique but heavily depends on the level of
development of the nation, as expressed by macroeconomic indicators like GDP,
GDP per capita, total export and a recently introduced measure for countries'
economic complexity called fitness. We have identified three major classes: a)
an incomplete log-normal shape, truncated on the left side, for the less
developed countries, b) a complete log-normal, with a wider range of volumes,
for nations characterized by intermediate economy, and c) a strongly asymmetric
shape for countries with a high degree of development. The ranking curves of
the exported volumes from each country seldom cross each other, showing a clear
hierarchy of export volumes. Finally, the log-normality hypothesis has been
checked for the distributions of all the 148 countries through different tests,
Kolmogorov-Smirnov and Cramer-Von Mises, confirming that it cannot be rejected
only for the countries of intermediate economy.
</summary>
    <author>
      <name>Mario Alberto Annunziata</name>
    </author>
    <author>
      <name>Alberto Petri</name>
    </author>
    <author>
      <name>Giorgio Pontuale</name>
    </author>
    <author>
      <name>Andrea Zaccaria</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1140/epjst/e2015-50320-7</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1140/epjst/e2015-50320-7" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 5 figures, submitted to IWcee15 conference</arxiv:comment>
    <link href="http://arxiv.org/abs/1506.03597v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.03597v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.03917v1</id>
    <updated>2015-06-12T07:08:41Z</updated>
    <published>2015-06-12T07:08:41Z</published>
    <title>On the Characteristics of the Free Market in a Cooperative Society</title>
    <summary>  The key characteristic of a true free market economy is that exchanges are
entirely voluntary. When there is a monopoly in the creation of currency as we
have in today's markets, you no longer have a true free market. Features of the
current economic system such as central banking and taxation would be
nonexistent in a free market. This paper examines how currency monopoly leads
to the instabilities and imbalances that we see in today's economy. It also
proposes that currencies should emerge from the voluntary exchange of goods and
services, and studies economic interaction across all scales, by considering
economic action in cases where the self-interests of individuals are
coincident. By examining the voluntary exchange of goods and services at the
scale of an entire society, it is shown that a new currency system, which
resolves a lot of the problems caused by the current fiat currency system,
emerges naturally from the free market. The new currency system is robust and
efficient, and provides a way for public goods and services to be provided, and
its providers compensated, without the need for direct taxation.
</summary>
    <author>
      <name>Norbert Agbeko</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1506.03917v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.03917v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.04698v1</id>
    <updated>2015-06-15T18:46:41Z</updated>
    <published>2015-06-15T18:46:41Z</published>
    <title>Quick or Persistent? Strategic Investment Demanding Versatility</title>
    <summary>  In this paper we analyse a dynamic model of investment under uncertainty in a
duopoly, in which each firm has an option to switch from the present market to
a new market. We construct a subgame perfect equilibrium in mixed strategies
and show that both preemption and attrition can occur along typical equilibrium
paths. In order to determine the attrition region a two-dimensional constrained
optimal stopping problem needs to be solved, for which we characterize the
non-trivial stopping boundary in the state space. We explicitly determine
Markovian equilibrium stopping rates in the attrition region and show that
there is always a positive probability of eventual preemption, contrasting the
deterministic version of the model. A simulation-based numerical example
illustrates the model and shows the relative likelihoods of investment taking
place in attrition and preemption regions.
</summary>
    <author>
      <name>Jan-Henrik Steg</name>
    </author>
    <author>
      <name>Jacco Thijssen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">34 pages, 10 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1506.04698v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.04698v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="60G40, 91A25, 91A55, 91A60" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.04869v1</id>
    <updated>2015-06-16T08:20:01Z</updated>
    <published>2015-06-16T08:20:01Z</published>
    <title>Modeling and Computation of Mean Field Equilibria in Producers' Game
  with Emission Permits Trading</title>
    <summary>  In this paper, we present a mean field game to model the production behaviors
of a very large number of producers, whose carbon emissions are regulated by
government. Especially, an emission permits trading scheme is considered in our
model, in which each enterprise can trade its own permits flexibly. By means of
the mean field equilibrium, we obtain a Hamilton-Jacobi-Bellman (HJB) equation
coupled with a Kolmogorov equation, which are satisfied by the adjoint state
and the density of producers (agents), respectively. Then, we propose a
so-called fitted finite volume method to solve the HJB equation and the
Kolmogorov equation. The efficiency and the usefulness of this method are
illustrated by the numerical experiments. Under different conditions, the
equilibrium states as well as the effects of the emission permits price are
examined, which demonstrates that the emission permits trading scheme
influences the producers' behaviors, that is, more populations would like to
choose a lower rather than a higher emission level when the emission permits
are expensive.
</summary>
    <author>
      <name>Shuhua Chang</name>
    </author>
    <author>
      <name>Xinyu Wang</name>
    </author>
    <author>
      <name>Alexander Shananin</name>
    </author>
    <link href="http://arxiv.org/abs/1506.04869v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.04869v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.06069v2</id>
    <updated>2016-06-01T15:54:13Z</updated>
    <published>2015-06-18T07:44:52Z</published>
    <title>Resolute refinements of social choice correspondences</title>
    <summary>  Many classical social choice correspondences are resolute only in the case of
two alternatives and an odd number of individuals. Thus, in most cases, they
admit several resolute refinements, each of them naturally interpreted as a
tie-breaking rule, satisfying different properties. In this paper we look for
classes of social choice correspondences which admit resolute refinements
fulfilling suitable versions of anonymity and neutrality. In particular,
supposing that individuals and alternatives have been exogenously partitioned
into subcommittees and subclasses, we find out arithmetical conditions on the
sizes of subcommittees and subclasses that are necessary and sufficient for
making any social choice correspondence which is efficient, anonymous with
respect to subcommittees, neutral with respect to subclasses and possibly
immune to the reversal bias admit a resolute refinement sharing the same
properties.
</summary>
    <author>
      <name>Daniela Bubboloni</name>
    </author>
    <author>
      <name>Michele Gori</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: text overlap with arXiv:1503.04028</arxiv:comment>
    <link href="http://arxiv.org/abs/1506.06069v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.06069v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.07854v1</id>
    <updated>2015-06-20T09:50:25Z</updated>
    <published>2015-06-20T09:50:25Z</published>
    <title>A Bayesian Model of the Litigation Game</title>
    <summary>  Over a century ago, Oliver Wendell Holmes invited scholars to look at the law
through the lens of probability theory: "The prophecies of what the courts will
do in fact, and nothing more pretentious, are what I mean by the law." Yet few
legal scholars have taken up this intriguing invitation. As such, in place of
previous approaches to the study of law, this paper presents a non-normative,
mathematical approach to law and the legal process. Specifically, we present a
formal Bayesian model of civil and criminal litigation, or what we refer to as
the litigation game; that is, instead of focusing on the rules of civil or
criminal procedure or substantive legal doctrine, we ask and attempt to answer
a mathematical question: what is the posterior probability that a defendant in
a civil or criminal trial will be found liable, given that the defendant has,
in fact, committed a wrongful act?
</summary>
    <author>
      <name>Enrique Guerra-Pujol</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">24 pages, 1 table</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">European Journal of Legal Studies, vol. 4, no. 2 (Autumn/Winter
  2011), pp. 220-240</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1506.07854v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.07854v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.00894v3</id>
    <updated>2016-05-11T12:11:53Z</updated>
    <published>2015-07-03T12:39:54Z</published>
    <title>Inequality and risk aversion in economies open to altruistic attitudes</title>
    <summary>  This paper attempts to find a relationship between agents' risk aversion and
inequality of incomes. Specifically, a model is proposed for the evolution in
time of surplus/deficit distribution, and the long-time distributions are
characterized almost completely. They turn out to be weak Pareto laws with
exponent linked to the relative risk aversion index which, in turn, is supposed
to be the same for every agent. On the one hand, the aforesaid link is
expressed by an affine transformation. On the other hand, the level of the
relative risk aversion index results from a frequency distribution of
observable quantities stemming from how agents interact in an economic sense.
Combination of these facts is conducive to the specification of qualitative and
quantitative characteristics of actions fit for the control of income
concentration.
</summary>
    <author>
      <name>Eleonora Perversi</name>
    </author>
    <author>
      <name>Eugenio Regazzini</name>
    </author>
    <link href="http://arxiv.org/abs/1507.00894v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.00894v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B15, 91B55, 82C40" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.02025v3</id>
    <updated>2016-10-06T07:54:47Z</updated>
    <published>2015-07-08T04:54:08Z</published>
    <title>Diversification Preferences in the Theory of Choice</title>
    <summary>  Diversification represents the idea of choosing variety over uniformity.
Within the theory of choice, desirability of diversification is axiomatized as
preference for a convex combination of choices that are equivalently ranked.
This corresponds to the notion of risk aversion when one assumes the
von-Neumann-Morgenstern expected utility model, but the equivalence fails to
hold in other models. This paper studies axiomatizations of the concept of
diversification and their relationship to the related notions of risk aversion
and convex preferences within different choice theoretic models. Implications
of these notions on portfolio choice are discussed. We cover model-independent
diversification preferences, preferences within models of choice under risk,
including expected utility theory and the more general rank-dependent expected
utility theory, as well as models of choice under uncertainty axiomatized via
Choquet expected utility theory. Remarks on interpretations of diversification
preferences within models of behavioral choice are given in the conclusion.
</summary>
    <author>
      <name>Enrico G. De Giorgi</name>
    </author>
    <author>
      <name>Ola Mahmoud</name>
    </author>
    <link href="http://arxiv.org/abs/1507.02025v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.02025v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.MF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.04167v2</id>
    <updated>2016-03-26T19:56:22Z</updated>
    <published>2015-07-15T11:11:22Z</published>
    <title>Axiomatization of the Choquet integral for 2-dimensional heterogeneous
  product sets</title>
    <summary>  We prove a representation theorem for the Choquet integral model. The
preference relation is defined on a two-dimensional heterogeneous product set
$X = X_1 \times X_2$ where elements of $X_1$ and $X_2$ are not necessarily
comparable with each other. However, making such comparisons in a meaningful
way is necessary for the construction of the Choquet integral (and any
rank-dependent model). We construct the representation, study its uniqueness
properties, and look at applications in multicriteria decision analysis,
state-dependent utility theory, and social choice. Previous axiomatizations of
this model, developed for decision making under uncertainty, relied heavily on
the notion of comonotocity and that of a "constant act". However, that requires
$X$ to have a special structure, namely, all factors of this set must be
identical. Our characterization does not assume commensurateness of criteria a
priori, so defining comonotonicity becomes impossible.
</summary>
    <author>
      <name>Mikhail Timonin</name>
    </author>
    <link href="http://arxiv.org/abs/1507.04167v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.04167v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.00275v2</id>
    <updated>2015-08-25T07:59:36Z</updated>
    <published>2015-08-02T19:24:20Z</published>
    <title>On growth-optimal tax rates and the issue of wealth inequalities</title>
    <summary>  We introduce a highly stylized, yet non trivial model of the economy, with a
public and private sector coupled through a wealth tax and a redistribution
policy. The model can be fully solved analytically, and allows one to address
the question of optimal taxation and of wealth inequalities. We find that
according to the assumption made on the relative performance of public and
private sectors, three situations are possible. Not surprisingly, the optimal
wealth tax rate is either 0% for a deeply dysfunctional government and/or
highly productive private sector, or 100 % for a highly efficient public sector
and/or debilitated/risk averse private investors. If the gap between the
public/private performance is moderate, there is an optimal positive wealth tax
rate maximizing economic growth, even -- counter-intuitively -- when the
private sector generates more growth. The compromise between profitable private
investments and taxation however leads to a residual level of inequalities. The
mechanism leading to an optimal growth rate is related the well-known
explore/exploit trade-off.
</summary>
    <author>
      <name>Jean-Philippe Bouchaud</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Capital Fund Management and Ecole Polytechnique</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1088/1742-5468/2015/11/P11011</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1088/1742-5468/2015/11/P11011" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1508.00275v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.00275v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.02056v1</id>
    <updated>2015-04-01T10:19:32Z</updated>
    <published>2015-04-01T10:19:32Z</published>
    <title>Role of non-timber forest products in sustaining forest-based
  livelihoods and rural households' resilience capacity in and around protected
  area- a Bangladesh study</title>
    <summary>  People in developing world derive a significant part of their livelihoods
from various forest products, particularly non-timber forest products. This
article attempts to explore the contribution of NTFPs in sustaining
forest-based rural livelihood in and around a protected area of Bangladesh, and
their potential role in enhancing households resilience capacity. Based on
empirical investigation our study revealed that, local communities gather a
substantial amount of NTFPs from national park despite the official
restrictions. 27 percent households of the area received at least some cash
benefit from the collection, processing and selling of NTFPs, and NTFPs
contribute as HHs primary, supplementary and emergency sources of income. NTFPs
also constituted an estimated 19 percent of HHs net annual income, and were the
primary occupation for about 18 percent of the HHs. HHs dependency on nearby
forests for various NTFPs varied vis-a-vis their socio-economic condition as
well as with their location from the park. Based on our case study the article
also offers some clues for improving the situation in PA.
</summary>
    <author>
      <name>S. A. Mukul</name>
    </author>
    <author>
      <name>A. Z. M. M. Rashid</name>
    </author>
    <author>
      <name>M. B. Uddin</name>
    </author>
    <author>
      <name>N. A. Khan</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1080/09640568.2015.1035774</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1080/09640568.2015.1035774" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in Journal of Environmental Planning and Management, 2015</arxiv:comment>
    <link href="http://arxiv.org/abs/1508.02056v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.02056v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.02636v3</id>
    <updated>2016-02-01T06:57:10Z</updated>
    <published>2015-08-03T04:12:18Z</published>
    <title>Game Design and Analysis for Price based Demand Response: An Aggregate
  Game Approach</title>
    <summary>  In this paper, an aggregate game approach is proposed for the modeling and
analysis of energy consumption control in smart grid. Since the electricity
user's cost function depends on the aggregate load, which is unknown to the end
users, an aggregate load estimator is employed to estimate it. Based on the
communication among the users about their estimations on the aggregate load,
Nash equilibrium seeking strategies are proposed for the electricity users. By
using singular perturbation analysis and Lyapunov stability analysis, a local
convergence result to the Nash equilibrium is presented for the energy
consumption game that may have multiple Nash equilibria. For the energy
consumption game with a unique Nash equilibrium, it is shown that the players'
strategies converge to the Nash equilibrium non-locally. More specially, if the
unique Nash equilibrium is an inner Nash equilibrium, then the convergence rate
can be quantified. Energy consumption game with stubborn players is also
investigated. Convergence to the best response strategies for the rational
players is ensured. Numerical examples are provided to verify the effectiveness
of the proposed methods.
</summary>
    <author>
      <name>Maojiao Ye</name>
    </author>
    <author>
      <name>Guoqiang Hu</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TCYB.2016.2524452</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TCYB.2016.2524452" rel="related"/>
    <link href="http://arxiv.org/abs/1508.02636v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.02636v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.03853v1</id>
    <updated>2015-08-16T18:11:55Z</updated>
    <published>2015-08-16T18:11:55Z</published>
    <title>Transfer pricing manipulation, tax penalty cost and the impact of
  foreign profit taxation</title>
    <summary>  This paper analizes the optimal level of transfer pricing manipulation when
the expected tax penalty is a function of the tax enforcement and the market
price parameter. The arm's length principle implies the existence of a range of
acceptable prices shaped by market, and firms can manipulate transfer prices
more freely if market price range is wide, or if its delimitations are
difficult to determine. Home taxation of foreign profits can reduce income
shifting incentive, depending on the portion of repatriation for tax purposes.
We find that the limited tax credit rule tends to be a less efficient measure,
nonetheless it is the most widely adopted rule by countries, so to spark the
perspective of more powerful approaches for taxation of foreign profits.
</summary>
    <author>
      <name>Alex Augusto Timm Rathke</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1508.03853v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.03853v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.03924v2</id>
    <updated>2016-05-07T15:21:56Z</updated>
    <published>2015-08-17T05:01:21Z</published>
    <title>Optimal Taxation with Endogenous Default under Incomplete Markets</title>
    <summary>  In a dynamic economy, we characterize the fiscal policy of the government
when it levies distortionary taxes and issues defaultable bonds to finance its
stochastic expenditure. Default may occur in equilibrium as it prevents the
government from incurring in future tax distortions that would come along with
the service of the debt. Households anticipate the possibility of default
generating endogenous credit limits. These limits hinder the government's
ability to smooth taxes using debt, implying more volatile and less serially
correlated fiscal policies, higher borrowing costs and lower levels of
indebtedness. In order to exit temporary financial autarky following a default
event, the government has to repay a random fraction of the defaulted debt. We
show that the optimal fiscal and renegotiation policies have implications
aligned with the data.
</summary>
    <author>
      <name>Demian Pouzo</name>
    </author>
    <author>
      <name>Ignacio Presno</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">55 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1508.03924v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.03924v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.05353v2</id>
    <updated>2015-09-23T19:30:39Z</updated>
    <published>2015-05-26T01:48:07Z</published>
    <title>Is Collusion-Proof Procurement Expensive?</title>
    <summary>  Collusion among bidders adversely affects procurement cost and in some cases
efficiency, and it seems collusion is more prevalent that we would like.
Statistical methods of detecting collusion just using bid data, in a hope to
deter future collusion, is perilous, and access to additional data is rare and
often always after the fact. In this paper, we estimate the extra cost of
implementing a new procurement rule proposed by Chen and Micali [2012] that is
robust to collusion and always guarantees the efficient outcome. The rule
requires bidders to report their coalition and to ensure
incentive-compatibility, the mechanism allows them to attain rents. We estimate
this rent using data from California highway construction and find it to be
anywhere between 1.6% to 5%. Even after we factor in the marginal excess burden
of taxes needed to finance these rents, the cost ranges between 2.08% and 6.5%,
suggesting that there is a room to think about running this new auction,
suggesting we should consider this auction.
</summary>
    <author>
      <name>Gaurab Aryal</name>
    </author>
    <author>
      <name>Maria F. Gabrielli</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">26 Pages, 1 Figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1508.05353v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.05353v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1509.01216v1</id>
    <updated>2015-05-27T11:11:47Z</updated>
    <published>2015-05-27T11:11:47Z</published>
    <title>Dynamic Model of the Price Dispersion of Homogeneous Goods</title>
    <summary>  Presented is an analytic microeconomic model of the temporal price dispersion
of homogeneous goods in polypoly markets. This new approach is based on the
idea that the price dispersion has its origin in the dynamics of the purchase
process. The price dispersion is determined by the chance that demanded and
supplied product units meet in a given price interval. It can be characterized
by a fat-tailed Laplace distribution for short and by a lognormal distribution
for long time horizons. Taking random temporal variations of demanded and
supplied units into account both the mean price and also the standard deviation
of the price dispersion are governed by a lognormal distribution. A comparison
with empirical investigations confirms the model statements.
</summary>
    <author>
      <name>Joachim Kaldasch</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.9734/BJEMT/2015/17849</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.9734/BJEMT/2015/17849" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">British Journal of Economics, Management &amp; Trade,8(2): 120-131,
  2015, Article no.BJEMT.2015.104</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1509.01216v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1509.01216v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1509.01526v1</id>
    <updated>2015-09-04T16:51:54Z</updated>
    <published>2015-09-04T16:51:54Z</published>
    <title>The Principle of the Malevolent Hiding Hand; or, the Planning Fallacy
  Writ Large</title>
    <summary>  We identify and document a new principle of economic behavior: the principle
of the Malevolent Hiding Hand. In a famous discussion, Albert Hirschman
celebrated the Hiding Hand, which he saw as a benevolent mechanism by which
unrealistically optimistic planners embark on unexpectedly challenging plans,
only to be rescued by human ingenuity, which they could not anticipate, but
which ultimately led to success, principally in the form of unexpectedly high
net benefits. Studying eleven projects, Hirschman suggested that the Hiding
Hand is a general phenomenon. But the Benevolent Hiding Hand has an evil twin,
the Malevolent Hiding Hand, which blinds excessively optimistic planners not
only to unexpectedly high costs but also to unexpectedly low net benefits.
Studying a much larger sample than Hirschman did, we find that the Malevolent
Hiding Hand is common and that the phenomenon that Hirschman identified is
rare. This sobering finding suggests that Hirschman's phenomenon is a special
case; it attests to the pervasiveness of the planning fallacy, writ very large.
One implication involves the continuing need for unbiased cost-benefit analyses
and other economic decision support tools; another is that such tools might
sometimes prove unreliable.
</summary>
    <author>
      <name>Bent Flyvbjerg</name>
    </author>
    <author>
      <name>Cass R. Sunstein</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Social Research, vol. 83, no. 4, Winter, 2016, pp. 979-1004</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1509.01526v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1509.01526v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1509.05638v1</id>
    <updated>2015-09-18T14:20:42Z</updated>
    <published>2015-09-18T14:20:42Z</published>
    <title>Stochastic Optimal Growth Model with Risk Sensitive Preferences</title>
    <summary>  This paper studies a one-sector optimal growth model with i.i.d. productivity
shocks that are allowed to be unbounded. The utility function is assumed to be
non-negative and unbounded from above. The novel feature in our framework is
that the agent has risk sensitive preferences in the sense of Hansen and
Sargent (1995). Under mild assumptions imposed on the productivity and utility
functions we prove that the maximal discounted non-expected utility in the
infinite time horizon satisfies the optimality equation and the agent possesses
a stationary optimal policy. A new point used in our analysis is an inequality
for the so-called associated random variables. We also establish the Euler
equation that incorporates the solution to the optimality equation.
</summary>
    <author>
      <name>Nicole Bäuerle</name>
    </author>
    <author>
      <name>Anna Jaśkiewicz</name>
    </author>
    <link href="http://arxiv.org/abs/1509.05638v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1509.05638v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B62, 91B70" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.00665v1</id>
    <updated>2015-09-15T14:18:17Z</updated>
    <published>2015-09-15T14:18:17Z</published>
    <title>Universalized Prisoner's Dilemma With Risk</title>
    <summary>  In this paper I present a mathematically novel approach to the Prisoner's
Dilemma. I do so by first defining recursively a distinct action type, what I
call 'universalizing', that I add to the original prisoner's dilemma. Such a
modified version of the Prisoner's Dilemma provides a very food productive
model of the choices that would be made in a prisoner's dilemma by agents who
trust each other. As I show, players playing a universalized prisoner's dilemma
get as far out of the dilemma as is mathematically possible. I then add the
concept of risk to the universalized version of prisoner's dilemma. Doing so
provide a model that is sensitive to the trustworthiness of the agents in any
prisoner's dilemma. As I show, with no risk, agents get out of the prisoners
dilemma; and with maximal risk, the succumb to it. succumb to it.
</summary>
    <author>
      <name>Paul Studtmann</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Includes four pages of Mathematica worksheets that verify the
  mathematical claims made in the paper</arxiv:comment>
    <link href="http://arxiv.org/abs/1510.00665v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.00665v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.03398v1</id>
    <updated>2015-09-06T08:46:09Z</updated>
    <published>2015-09-06T08:46:09Z</published>
    <title>The Corporate Social Responsibility is just a twist in a Möbius Strip</title>
    <summary>  In recent years economics agents and systems have became more and more
interacting and juxtaposed, therefore the social sciences need to rely on the
studies of physical sciences to analyze this complexity in the relationships.
According to this point of view we rely on the geometrical model of the
M\"obius strip used in the electromagnetism which analyzes the moves of the
electrons that produce energy. We use a similar model in a Corporate Social
Responsibility context to devise a new cost function in order to take into
account of three positive crossed effects on the efficiency: i)cooperation
among stakeholders in the same sector, ii)cooperation among similar
stakeholders in different sectors and iii)the stakeholders' loyalty towards the
company. By applying this new cost function to a firm's decisional problem we
find that investing in Corporate Social Responsibility activities is ever
convenient depending on the number of sectors, the stakeholders' sensitivity to
these investments and the decay rate to alienation. Our work suggests a new
method of analysis which should be developed not only at a theoretical but also
at an empirical level.
</summary>
    <author>
      <name>Nazaria Solferino</name>
    </author>
    <author>
      <name>Viviana Solferino</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1510.03398v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.03398v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="Game theory, economics, social and behavioral sciences" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.04550v2</id>
    <updated>2016-03-17T16:34:25Z</updated>
    <published>2015-10-15T14:20:52Z</published>
    <title>Dynamics and Stability in Retail Competition</title>
    <summary>  Retail competition today can be described by three main features: i)
oligopolistic competition, ii) multi-store settings, and iii) the presence of
large economies of scale. In these markets, firms usually apply a centralized
decisions making process in order to take full advantage of economies of
scales, e.g. retail distribution centers. In this paper, we model and analyze
the stability and chaos of retail competition considering all these issues. In
particular, a dynamic multi-market Cournot-Nash equilibrium with global
economies and diseconomies of scale model is developed. We confirm the
non-intuitive hypothesis that retail multi-store competition is more unstable
that traditional small business that cover the same demand. The main sources of
stability are the scale parameter and the number of markets
</summary>
    <author>
      <name>Marcelo J. Villena</name>
    </author>
    <author>
      <name>Axel A. Araneda</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1510.04550v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.04550v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.05698v1</id>
    <updated>2015-10-13T10:08:46Z</updated>
    <published>2015-10-13T10:08:46Z</published>
    <title>Basic industrial funds of cargo motor transport enterprises: problems of
  effective use</title>
    <summary>  This work investigates the structure of basic industrial funds of cargo motor
transport enterprises and peculiarities of the processes of their reproduction
in the conditions of social and economic relations transformation. On the basis
of statistic data of cargo-motor transport enterprises of Ivano-Frankivsk, Lviv
and Ternopil regions the author investigates the effect of production factors
on the level of capital productivity of the basic funds, he determines reserves
of its increase. The author motivates the necessity of adaptive qualitative
changes in the management and realization of industrial potential and
innovations activization in the sphere of cargo motor transportations,
scientiffically grounded recommendations for efficiency increase of the usage
of basic industrial funds of cargo motor transportation enterprises in modern
economic conditions are provided in this work.
</summary>
    <author>
      <name>Oleksandr Vashkiv</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">e.g.: 172 pages,2 figures, 37 tables, ISBN 966-7411-44-9</arxiv:comment>
    <link href="http://arxiv.org/abs/1510.05698v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.05698v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.05854v2</id>
    <updated>2015-11-13T14:37:51Z</updated>
    <published>2015-10-20T12:17:36Z</published>
    <title>Estimating the Impact of Wind Generation in the UK</title>
    <summary>  This paper studies the impact of wind generation on market prices and system
costs in the UK between 2013 and 2014. The wider effects and implications of
wind generation is of direct relevance and importance to policy makers, as well
as the grid operator and market traders. We compare electricity generation from
Coal, Gas and wind, on both the wholesale and imbalance market. We calculate
the system cost of wind generation (government subsidies and curtailment costs)
and the total energy costs. For the first time in the UK, we calculate the
Merit Order Effect on spot price due to the wind component and show a $1.67\%$
price decrease for every percentage point of wind generation (compared to the
``zero-wind'' price). The net result of total costs and price savings is
roughly zero (slight positive gain). We also consider the effect of not having
either an onshore or an offshore wind component. We show that the Merit-Order
Effect savings are heavily reduced, leading to an outgoing cost of wind
generation in both cases. It is therefore important to have a significant total
percentage of wind generation, from both onshore and offshore farms.
</summary>
    <author>
      <name>Lisa MH Hall</name>
    </author>
    <author>
      <name>Alastair Buckley</name>
    </author>
    <author>
      <name>Jose Mawyin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 6 figures, 3 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1510.05854v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.05854v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.06813v3</id>
    <updated>2017-04-02T15:25:40Z</updated>
    <published>2015-10-23T02:55:22Z</published>
    <title>Analysis of Markovian Competitive Situations using Nonatomic Games</title>
    <summary>  For dynamic situations where the evolution of a player's state is influenced
by his own action as well as other players' states and actions, we show that
equilibria derived for nonatomic games (NGs) can be used by their large finite
counterparts to achieve near-equilibrium performances. We focus on the case
with quite general spaces but also with independently generated shocks driving
random actions and state transitions. The NG equilibria we consider are random
state-to-action maps that pay no attention to players' external environments.
They are adoptable by a variety of real situations where awareness of other
players' states can be anywhere between full and non-existent. Transient
results here also form the basis of a link between an NG's stationary
equilibrium (SE) and good stationary profiles for large finite games.
</summary>
    <author>
      <name>Jian Yang</name>
    </author>
    <link href="http://arxiv.org/abs/1510.06813v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.06813v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.07608v1</id>
    <updated>2015-10-26T19:38:59Z</updated>
    <published>2015-10-26T19:38:59Z</published>
    <title>Modern Monetary Circuit Theory, Stability of Interconnected Banking
  Network, and Balance Sheet Optimization for Individual Banks</title>
    <summary>  A modern version of Monetary Circuit Theory with a particular emphasis on
stochastic underpinning mechanisms is developed. It is explained how money is
created by the banking system as a whole and by individual banks. The role of
central banks as system stabilizers and liquidity providers is elucidated. It
is shown how in the process of money creation banks become naturally
interconnected. A novel Extended Structural Default Model describing the
stability of the Interconnected Banking Network is proposed. The purpose of
banks' capital and liquidity is explained. Multi-period constrained
optimization problem for banks's balance sheet is formulated and solved in a
simple case. Both theoretical and practical aspects are covered.
</summary>
    <author>
      <name>Alexander Lipton</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">67 pages, 16 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1510.07608v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.07608v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.CP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.MF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B02, 91B24, 91B55, 91B64, 91G60, 91G80" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.07888v2</id>
    <updated>2016-11-05T12:19:47Z</updated>
    <published>2015-10-27T12:42:50Z</published>
    <title>Exchanging Goods Using Valuable Money</title>
    <summary>  A group of people wishes to use money to exchange goods efficiently over
several time periods. However, there are disadvantages to using any of the
goods as money, and in addition fiat money issued in the form of notes or coins
will be valueless in the final time period, and hence in all earlier periods.
Also, Walrasian market prices are determined only up to an arbitrary rescaling.
Nevertheless we show that it is possible to devise a system which uses money to
exchange goods and in which money has a determinate positive value. In this
system, tokens are initially supplied to all traders by a central authority and
recovered by a purchase tax. All trades must be made using tokens or promissory
notes for tokens. This mechanism controls the flow rather than the stock of
money: it introduces some trading frictions, some redistribution of wealth, and
some distortion of prices, but these effects can all be made small.
</summary>
    <author>
      <name>J. V. Howard</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">23 pages, 10 figures, revised</arxiv:comment>
    <link href="http://arxiv.org/abs/1510.07888v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.07888v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.08335v1</id>
    <updated>2015-10-28T15:02:44Z</updated>
    <published>2015-10-28T15:02:44Z</published>
    <title>A Stochastic Electricity Market Clearing Formulation with Consistent
  Pricing Properties</title>
    <summary>  We argue that deterministic market clearing formulations introduce arbitrary
distortions between day-ahead and expected real-time prices that bias economic
incentives and block diversification. We extend and analyze the stochastic
clearing formulation proposed by Pritchard et al. (2010) in which the social
surplus function induces penalties between day-ahead and real-time quantities.
We prove that the formulation yields price distortions that are bounded by the
bid prices, and we show that adding a similar penalty term to transmission
flows and phase angles ensures boundedness throughout the network. We prove
that when the price distortions are zero, day-ahead quantities converge to the
quantile of real-time counterparts. The undesired effects of price distortions
suggest that stochastic settings provide significant benefits over
deterministic ones that go beyond social surplus improvements. We propose
additional metrics to evaluate these benefits.
</summary>
    <author>
      <name>Victor M. Zavala</name>
    </author>
    <author>
      <name>Kibaek Kim</name>
    </author>
    <author>
      <name>Mihai Anitescu</name>
    </author>
    <author>
      <name>John Birge</name>
    </author>
    <link href="http://arxiv.org/abs/1510.08335v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.08335v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.03863v3</id>
    <updated>2016-05-31T16:15:16Z</updated>
    <published>2015-11-12T11:36:41Z</published>
    <title>Preemptive Investment under Uncertainty</title>
    <summary>  This paper provides a general characterization of subgame perfect equilibria
for strategic timing problems, where two firms have the (real) option to make
an irreversible investment. Profit streams are uncertain and depend on the
market structure. The analysis is based directly on the inherent economic
structure of the model. In particular, the determination of equilibria with
preemptive investment is reduced to solving a single class of constrained
optimal stopping problems. The general results are applied to typical
state-space models, completing commonly insufficient equilibrium arguments,
showing when uncertainty leads to qualitatively different behavior, and
establishing additional equilibria that are Pareto improvements.
</summary>
    <author>
      <name>Jan-Henrik Steg</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">38 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1511.03863v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.03863v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="60G40, 91A25, 91A55, 91A60" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.06454v1</id>
    <updated>2015-11-19T23:41:33Z</updated>
    <published>2015-11-19T23:41:33Z</published>
    <title>A simple framework for the axiomatization of exponential and
  quasi-hyperbolic discounting</title>
    <summary>  The main goal of this paper is to investigate which normative requirements,
or axioms, lead to exponential and quasi-hyperbolic forms of discounting.
Exponential discounting has a well-established axiomatic foundation originally
developed by Koopmans (1960, 1972) and Koopmans et al. (1964) with subsequent
contributions by several other authors, including Bleichrodt et al. (2008). The
papers by Hayashi (2003) and Olea and Strzalecki (2014) axiomatize
quasi-hyperbolic discounting. The main contribution of this paper is to provide
an alternative foundation for exponential and quasi-hyperbolic discounting,
with simple, transparent axioms and relatively straightforward proofs. Using
techniques by Fishburn (1982) and Harvey (1986), we show that Anscombe and
Aumann's (1963) version of Subjective Expected Utility theory can be readily
adapted to axiomatize the aforementioned types of discounting, in both finite
and infinite horizon settings.
</summary>
    <author>
      <name>Nina Anchugina</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s11238-016-9566-8</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s11238-016-9566-8" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">30 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1511.06454v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.06454v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.09203v4</id>
    <updated>2017-04-04T07:38:01Z</updated>
    <published>2015-11-30T08:53:34Z</published>
    <title>Statistical mechanics of complex economies</title>
    <summary>  In the pursuit of ever increasing efficiency and growth, our economies have
evolved to remarkable degrees of complexity, with nested production processes
feeding each other in order to create products of greater sophistication from
less sophisticated ones, down to raw materials. The engine of such an expansion
have been competitive markets that, according to General Equilibrium Theory
(GET), achieve efficient allocations under specific conditions. We study large
random economies within the GET framework, as templates of complex economies,
and we find that a non-trivial phase transition occurs: the economy freezes in
a state where all production processes collapse when either the number of
primary goods or the number of available technologies fall below a critical
threshold. As in other examples of phase transitions in large random systems,
this is an unintended consequence of the growth in complexity. Our findings
suggest that the Industrial Revolution can be regarded as a sharp transition
between different phases, but also imply that well developed economies can
collapse if too many intermediate goods are introduced.
</summary>
    <author>
      <name>Marco Bardoscia</name>
    </author>
    <author>
      <name>Giacomo Livan</name>
    </author>
    <author>
      <name>Matteo Marsili</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1088/1742-5468/aa6688</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1088/1742-5468/aa6688" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">30 pages, 10 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Statistical Mechanics: Theory and Experiment (2017)
  P043401</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1511.09203v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.09203v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1512.01267v1</id>
    <updated>2015-12-02T15:01:45Z</updated>
    <published>2015-12-02T15:01:45Z</published>
    <title>Key drivers of EU budget allocation: Does power matter?</title>
    <summary>  We examine the determinants of the EU budget expenditures allocation among
different countries. In line with earlier literature, we consider two
alternative explanations for the EU budget distribution: political power vs.
needs view. Extending the original data set from Kauppi and Widgr\'en (2004),
we analyze the robustness of their predictions when applying a different
measure of power and more sophisticated econometric techniques. We conclude
that the nucleolus is a good alternative to the Shapley-Shubik index in
distributive situations such as the case of EU budget allocation. Our results
also show that when explaining budget shares, the relative weight of political
power based on the nucleolus is lower than the predictions of previous studies
based on the Shapley-Shubik index.
</summary>
    <author>
      <name>Vera Zaporozhets</name>
    </author>
    <author>
      <name>María García-Valiñas</name>
    </author>
    <author>
      <name>Sascha Kurz</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.ejpoleco.2016.02.004</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.ejpoleco.2016.02.004" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">32 pages, 9 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1512.01267v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1512.01267v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91A12, 91B32" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1512.01676v1</id>
    <updated>2015-12-05T15:15:30Z</updated>
    <published>2015-12-05T15:15:30Z</published>
    <title>Forecasting crude oil market volatility: can the Regime Switching GARCH
  model beat the single-regime GARCH models?</title>
    <summary>  In order to obtain a reasonable and reliable forecast method for crude oil
price volatility, this paper evaluates the forecast performance of
single-regime GARCH models (including the standard linear GARCH model and the
nonlinear GJR-GARCH and EGARCH models) and the two-regime Markov Regime
Switching GARCH (MRS-GARCH) model for crude oil price volatility at different
data frequencies and time horizons. The results indicate that, first, the
two-regime MRS-GARCH model beats other three single-regime GARCH type models in
in-sample data estimation under most evaluation criteria, although it appears
inferior under a few of other evaluation criteria. Second, the two-regime
MRS-GARCH model overall provides more accurate volatility forecast for daily
data but this superiority dies way for weekly and monthly data. Third, among
the three single-regime GARCH type models, the volatility forecast of the
nonlinear GARCH models exhibit greater accuracy than the linear GARCH model for
daily data at longer time horizons. Finally, the linear single-regime GARCH
model overall performs better than other three nonlinear GARCH type models in
Value-at-Risk (VaR) forecast.
</summary>
    <author>
      <name>Yue-Jun Zhang</name>
    </author>
    <author>
      <name>Ting Yao</name>
    </author>
    <author>
      <name>Ling-Yun He</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">30 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1512.01676v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1512.01676v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.00679v2</id>
    <updated>2016-01-14T16:33:44Z</updated>
    <published>2016-01-04T21:58:29Z</published>
    <title>Essay on the State of Research and Innovation in France and the European
  Union</title>
    <summary>  Innovation in the economy is an important engine of growth and no economy,
whatever its complexity and degree of advancement, whether it is based on
industry, agriculture, high tech or the providing of services, can be truly
healthy without innovating actors within it. The aim of this work, done by an
applied mathematician working in finance, not by an economist or a lawyer,
isn't to provide an exhaustive view of the all the mechanisms in France and in
Europe that aim at fostering innovation in the economy and to offer solutions
for removing all the roadblocks that still hinder innovation; indeed such a
study would go far beyond the scope of this study. What I modestly attempted to
achieve in this study was firstly to draw a panorama of what is working and
what needs to perfected as far as innovation is concerned in France and Europe,
then secondly to offer some solutions and personal thoughts to boost
innovation.
</summary>
    <author>
      <name>Antoine Kornprobst</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">26 pages. Modifications in the new version : Reference [7] was
  invalid (it was a report that was never voted and published by the French
  Senate, contrary to what I assumed) and has been replaced. The corresponding
  part has been modified in consequence. Also, minor corrections</arxiv:comment>
    <link href="http://arxiv.org/abs/1601.00679v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.00679v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.01771v1</id>
    <updated>2016-01-08T05:06:17Z</updated>
    <published>2016-01-08T05:06:17Z</published>
    <title>Teaching Economics and Providing Visual "Big Pictures"</title>
    <summary>  The goal of this paper is to investigate the importance of providing visual
"big pictures" in the teaching of economics. The plurality and variety of
concepts, variables, diagrams, and models involved in economics can be a source
of confusion for many economics students. However, reviewing the existing
literature on the importance of providing visual "big pictures" in the process
of learning suggests that furnishing students with a visual "big picture" that
illustrates the ways through which those numerous, diverse concepts are
connected to each other could be an effective solution to clear up the
mentioned mental chaos. As a practical example, this paper introduces a "big
picture" that can be used as a good resource in intermediate macroeconomics
classes. This figure presents twenty-seven commonly-discussed macroeconomic
diagrams in the intermediate macroeconomics course, and gives little detail on
some of these diagrams, aiming at helping students to get the whole picture at
once on a single piece of paper. This macroeconomics big picture mostly focuses
on the routes through which common diagrams in macroeconomics are connected to
each other, and finally introduces the general macroeconomic equilibrium that
is graphically derived through those connections.
</summary>
    <author>
      <name>Seyyed Ali Zeytoon Nejad Moosavian</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The 14th Annual Cambridge Business &amp; Economics Conference, University
  of Cambridge, Cambridge, UK, 1-2 July, 2015</arxiv:comment>
    <link href="http://arxiv.org/abs/1601.01771v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.01771v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.04028v1</id>
    <updated>2016-01-15T18:31:35Z</updated>
    <published>2016-01-15T18:31:35Z</published>
    <title>Do Mature Economies Grow Exponentially?</title>
    <summary>  Most models that try to explain economic growth indicate exponential growth
paths. In recent years, however, a lively discussion has emerged considering
the validity of this notion. In the empirical literature dealing with drivers
of economic growth, the majority of articles is based upon an implicit
assumption of exponential growth. Few scholarly articles have addressed this
issue so far. In order to shed light on this issue, we estimate autoregressive
integrated moving average time series models based on Gross Domestic Product
Per Capita data for 18 mature economies from 1960 to 2013. We compare the
adequacy of linear and exponential growth models and conduct several robustness
checks. Our fndings cast doubts on the widespread belief of exponential growth
and suggest a deeper discussion on alternative economic grow theories.
</summary>
    <author>
      <name>Steffen Lange</name>
    </author>
    <author>
      <name>Peter Pütz</name>
    </author>
    <author>
      <name>Thomas Kopp</name>
    </author>
    <link href="http://arxiv.org/abs/1601.04028v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.04028v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.04093v1</id>
    <updated>2016-01-15T22:39:19Z</updated>
    <published>2016-01-15T22:39:19Z</published>
    <title>A Statistical Model of Inequality</title>
    <summary>  This paper develops a nonparametric statistical model of wealth distribution
that imposes little structure on the fluctuations of household wealth. In this
setting, we use new techniques to obtain a closed-form household-by-household
characterization of the stable distribution of wealth and show that this
distribution is shaped entirely by two factors - the reversion rates (a measure
of cross-sectional mean reversion) and idiosyncratic volatilities of wealth
across different ranked households. By estimating these factors, our model can
exactly match the U.S. wealth distribution. This provides information about the
current trajectory of inequality as well as estimates of the distributional
effects of progressive capital taxes. We find evidence that the U.S. wealth
distribution might be on a temporarily unstable trajectory, thus suggesting
that further increases in top wealth shares are likely in the near future. For
capital taxes, we find that a small tax levied on just 1% of households
substantially reshapes the distribution of wealth and reduces inequality.
</summary>
    <author>
      <name>Ricardo T. Fernholz</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">46 pages, 9 tables, 8 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1601.04093v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.04093v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1602.00090v1</id>
    <updated>2016-01-30T08:42:24Z</updated>
    <published>2016-01-30T08:42:24Z</published>
    <title>A Simple extension of Dematerialization Theory: Incorporation of
  Technical Progress and the Rebound Effect</title>
    <summary>  Dematerialization is the reduction in the quantity of materials needed to
produce something useful over time. Dematerialization fundamentally derives
from ongoing increases in technical performance but it can be counteracted by
demand rebound - increases in usage because of increased value (or decreased
cost) that also results from increasing technical performance. A major question
then is to what extent technological performance improvement can offset and is
offsetting continuously increasing economic consumption. This paper contributes
to answering this question by offering some simple quantitative extensions to
the theory of dematerialization. The paper then empirically examines the
materials consumption trends as well as cost trends for a large set of
materials and a few modern artifacts over the past decades. In each of 57 cases
examined, the particular combinations of demand elasticity and technical
performance rate improvement are not consistent with dematerialization.
Overall, the theory extension and empirical examination indicate that there is
no dematerialization occurring even for cases of information technology with
rapid technical progress. Thus, a fully passive policy stance that relies on
unfettered technological change is not supported by our results.
</summary>
    <author>
      <name>Christopher L. Magee</name>
    </author>
    <author>
      <name>Tessaleno C. Devezas</name>
    </author>
    <link href="http://arxiv.org/abs/1602.00090v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1602.00090v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1602.00159v3</id>
    <updated>2016-06-06T17:43:53Z</updated>
    <published>2016-01-30T20:24:15Z</published>
    <title>Empirical Methods for Dynamic Power Law Distributions in the Social
  Sciences</title>
    <summary>  This paper introduces nonparametric econometric methods that characterize
general power law distributions under basic stability conditions. These methods
extend the literature on power laws in the social sciences in several
directions. First, we show that any stationary distribution in a random growth
setting is shaped entirely by two factors - the idiosyncratic volatilities and
reversion rates (a measure of cross-sectional mean reversion) for different
ranks in the distribution. This result is valid regardless of how growth rates
and volatilities vary across different economic agents, and hence applies to
Gibrat's law and its extensions. Second, we present techniques to estimate
these two factors using panel data. Third, we show how our results offer a
structural explanation for a generalized size effect in which higher-ranked
processes grow more slowly than lower-ranked processes on average. Finally, we
employ our empirical methods using panel data on commodity prices and show that
our techniques accurately describe the empirical distribution of relative
commodity prices. We also show the existence of a generalized "size" effect for
commodities, as predicted by our econometric theory.
</summary>
    <author>
      <name>Ricardo T. Fernholz</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">33 pages, 7 figures. arXiv admin note: text overlap with
  arXiv:1601.04093</arxiv:comment>
    <link href="http://arxiv.org/abs/1602.00159v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1602.00159v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1602.01271v1</id>
    <updated>2016-02-03T11:43:05Z</updated>
    <published>2016-02-03T11:43:05Z</published>
    <title>On the parameter identifiability problem in Agent Based economical
  models</title>
    <summary>  Identifiability of parameters is a fundamental prerequisite for model
identification. It concerns uniqueness of the model parameters determined from
experimental or simulated observations. This dissertation specifically deals
with structural or a priori identifiability: whether or not parameters can be
identified from a given model structure and experimental measurements. We
briefly present the identifiability problem in linear and non linear dynamical
model. We compare DSGE and Agent Based model (ABM) in terms of identifiability
of the structural parameters and we finally discuss limits and perspective of
numerical protocols to test global identifiability in case of ergodic and
markovian economical systems.
</summary>
    <author>
      <name>Di Molfetta Giuseppe</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Master 2 Recherche dissertation in Economie Theorique et Empirique,
  Universite Paris 1 Pantheon - Sorbonne and Supervised by Jean-Bernard
  Chatelain (Director) and Antoine Mandel (Co-Director)</arxiv:comment>
    <link href="http://arxiv.org/abs/1602.01271v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1602.01271v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1602.04423v1</id>
    <updated>2016-02-14T06:39:16Z</updated>
    <published>2016-02-14T06:39:16Z</published>
    <title>Market Dynamics. On Supply and Demand Concepts</title>
    <summary>  The disbalance of Supply and Demand is typically considered as the driving
force of the markets. However, the measurement or estimation of Supply and
Demand at price different from the execution price is not possible even after
the transaction. An approach in which Supply and Demand are always matched, but
the rate $I=dv/dt$ (number of units traded per unit time) of their matching
varies, is proposed. The state of the system is determined not by a price $p$,
but by a probability distribution defined as the square of a wavefunction
$\psi(p)$. The equilibrium state $\psi^{[H]}$ is postulated to be the one
giving maximal $I$ and obtained from maximizing the matching rate functional
$&lt;I\psi^2(p)&gt;/&lt;\psi^2(p)&gt;$, i.e. solving the dynamic equation of the form
"future price tend to the value maximizing the number of shares traded per unit
time". An application of the theory in a quasi--stationary case is
demonstrated. This transition from Supply and Demand concept to Liquidity
Deficit concept, described by the matching rate $I$, allows to operate only
with observable variables, and have a theory applicable to practical problems.
</summary>
    <author>
      <name>Vladislav Gennadievich Malyshkin</name>
    </author>
    <link href="http://arxiv.org/abs/1602.04423v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1602.04423v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.CP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1602.04466v1</id>
    <updated>2016-02-14T15:35:23Z</updated>
    <published>2016-02-14T15:35:23Z</published>
    <title>Mediation with near insolvent defaulting suppliers: a linear
  optimisation model to find an optimal outcome</title>
    <summary>  This paper presents a model to describe contractual dispute resolution by
mediation in situations where a defaulting supplier is near insolvent. While
each party has internal constraints, and if alternate performances are
available, such as more costly alternative goods, the proposed approach allows
the mediator to find an optimal solution. The notion of optimality is presented
as adherence to the initial contract, therefore optimising a value function for
the non defaulting party. The proposed model includes describing the evolution
over time of each party's perceived constraints using a phasor like approach
with a modulation to the core constraints phasing out of the real part and
phasing in the imaginary part of complex numbers. The offers related to
alternative performances by the defaulting party are modelled by a Gompertz
function, being an exponential learning curve of the supplier in regards to the
reaction to its offers, limited by another exponential function when
approaching its internal constraints. Furthermore, the model takes into account
the discount associated to the delay in the delivery time of the alternative
performances.
</summary>
    <author>
      <name>Eric Lavallee</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages,5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1602.04466v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1602.04466v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1602.05718v2</id>
    <updated>2016-03-25T04:16:43Z</updated>
    <published>2016-02-18T08:48:47Z</published>
    <title>The Postulate of the Three Regimes of Economic Growth Contradicted by
  Data</title>
    <summary>  Economic growth in Western Europe, Eastern Europe, Asia, countries of the
former USSR, Africa and Latin America were analysed. It is demonstrated that
the fundamental postulate of the Unified Growth Theory about the existence of
the three regimes of growth (Malthusian regime, post-Malthusian regime and
sustained-growth regime) is contradicted by data. These regimes did not exist.
In particular, there was no escape from the Malthusian trap because there was
no trap. Economic growth in all these regions was not stagnant but hyperbolic.
Unified Growth Theory is fundamentally incorrect. However, this theory is also
dangerously misleading because it claims a transition from the endless epoch of
stagnation to the new era of sustained economic growth, the interpretation
creating the sense of security and a promise of prosperity. The data show that
the opposite is true. Economic growth in the past was sustained and secure.
Now, it is supported by the increasing ecological deficit. The long-term
sustained and secure economic growth has yet to be created. It did not happen
automatically, as suggested incorrectly by the Unified Growth Theory.
</summary>
    <author>
      <name>Ron W Nielsen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">37 pages,20 figures,10,987 words. Corrected two parameters.
  Conclusions remain unchanged</arxiv:comment>
    <link href="http://arxiv.org/abs/1602.05718v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1602.05718v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1602.07300v3</id>
    <updated>2016-04-21T13:33:14Z</updated>
    <published>2016-02-23T14:36:05Z</published>
    <title>When does inequality freeze an economy?</title>
    <summary>  Inequality and its consequences are the subject of intense recent debate.
Using a simplified model of the economy, we address the relation between
inequality and liquidity, the latter understood as the frequency of economic
exchanges. Assuming a Pareto distribution of wealth for the agents, that is
consistent with empirical findings, we find an inverse relation between wealth
inequality and overall liquidity. We show that an increase in the inequality of
wealth results in an even sharper concentration of the liquid financial
resources. This leads to a congestion of the flow of goods and the arrest of
the economy when the Pareto exponent reaches one.
</summary>
    <author>
      <name>João Pedro Jerico</name>
    </author>
    <author>
      <name>François P. Landes</name>
    </author>
    <author>
      <name>Matteo Marsili</name>
    </author>
    <author>
      <name>Isaac Pérez Castillo</name>
    </author>
    <author>
      <name>Valerio Volpati</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1088/1742-5468/2016/07/073402</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1088/1742-5468/2016/07/073402" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages (plus 9 pages appendixes), 8 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1602.07300v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1602.07300v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.00991v2</id>
    <updated>2017-05-09T07:02:47Z</updated>
    <published>2016-03-03T06:35:43Z</published>
    <title>Financial Services, Economic Growth and Well-Being: A Four-Pronged Study</title>
    <summary>  A four-pronged approach to dealing with Social Science Phenomenon is
outlined. This methodology is applied to Financial Services, Economic Growth
and Well-Being. The four prongs are like the four directions for an army
general looking for victory. Just like the four directions, we need to be aware
that there is a degree of interconnectedness in the below four prongs.
-Uncertainty Principle of the Social Sciences -Responsibilities of Fiscal
Janitors -Need for Smaller Organizations -Redirecting Growth that Generates
Garbage The importance of gaining a more profound comprehension of welfare and
delineating its components into those that result from an increase in goods and
services, and hence can be attributed to economic growth, and into those that
are not related to economic growth but lead to a better quality of life, is
highlighted. The reasoning being that economic growth alone is an inadequate
indicator of well-being. Hand in hand with a better understanding of the
characteristics of welfare, comes the need to consider the metrics we currently
have that gauge economic growth and supplement those with measures that capture
well-being more holistically.
</summary>
    <author>
      <name>Ravi Kashyap</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.17010//2015/v9i1/71531</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.17010//2015/v9i1/71531" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Contains Supplementary Material (Research Questions, Methodology and
  Data Sources) in the Appendix</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Indian Journal of Finance, Vol. 9, No. 1 (2015), pp. 9-22</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1603.00991v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.00991v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.01416v2</id>
    <updated>2017-06-01T22:38:10Z</updated>
    <published>2016-03-04T10:31:54Z</published>
    <title>Big is Fragile: An Attempt at Theorizing Scale</title>
    <summary>  In this paper we characterise the propensity of big capital investments to
systematically deliver poor outcomes as "fragility," a notion suggested by
Nassim Taleb. A thing or system that is easily harmed by randomness is fragile.
We argue that, contrary to their appearance, big capital investments break
easily - i.e. deliver negative net present value - due to various sources of
uncertainty that impact them during their long gestation, implementation, and
operation periods. We do not refute the existence of economies of scale and
scope. Instead we argue that big capital investments have a disproportionate
(non-linear) exposure to uncertainties that deliver poor or negative returns
above and beyond their economies of scale and scope. We further argue that to
succeed, leaders of capital projects need to carefully consider where scaling
pays off and where it does not. To automatically assume that "bigger is
better," which is common in megaproject management, is a recipe for failure.
</summary>
    <author>
      <name>Atif Ansar</name>
    </author>
    <author>
      <name>Bent Flyvbjerg</name>
    </author>
    <author>
      <name>Alexander Budzier</name>
    </author>
    <author>
      <name>Daniel Lunn</name>
    </author>
    <link href="http://arxiv.org/abs/1603.01416v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.01416v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.02438v2</id>
    <updated>2017-05-20T11:30:04Z</updated>
    <published>2016-03-08T09:35:58Z</published>
    <title>A Mathematical Model of Foreign Capital Inflow</title>
    <summary>  The paper models foreign capital inflow from the developed to the developing
countries in a stochastic dynamic programming (SDP) framework. Under some
regularity conditions, the existence of the solutions to the SDP problem is
proved and they are then obtained by numerical technique because of the
non-linearity of the related functions. A number of comparative dynamic
analyses explore the impact of parameters of the model on dynamic paths of
capital inflow, interest rate in the international loan market and the exchange
rate.
</summary>
    <author>
      <name>Gopal K. Basak</name>
    </author>
    <author>
      <name>Pranab Kumar Das</name>
    </author>
    <author>
      <name>Allena Rohit</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">32 pages, 4 sets of figures each set consists of capital inflow,
  interest rate and exchange rate</arxiv:comment>
    <link href="http://arxiv.org/abs/1603.02438v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.02438v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="90C39, 91-08, 91G10, 91G30" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.05142v1</id>
    <updated>2016-03-16T15:22:59Z</updated>
    <published>2016-03-16T15:22:59Z</published>
    <title>Can banks default overnight? Modeling endogenous contagion on O/N
  interbank market</title>
    <summary>  We propose a new model of the liquidity driven banking system focusing on
overnight interbank loans. This significant branch of the interbank market is
commonly neglected in the banking system modeling and systemic risk analysis.
We construct a model where banks are allowed to use both the interbank and the
securities markets to manage their liquidity demand and supply as driven by
prudential requirements in a volatile environment. The network of interbank
loans is dynamic and simulated every day. We show how only the intrasystem cash
fluctuations, without any external shocks, may lead to systemic defaults, what
may be a symptom of the self-organized criticality of the system. We also
analyze the impact of different prudential regulations and market conditions on
the interbank market resilience. We confirm that central bank's asset purchase
programs, limiting the declines in government bond prices, can successfully
stabilize bank's liquidity demand. The model can be used to analyze the
interbank market impact of macroprudential tools.
</summary>
    <author>
      <name>Paweł Smaga</name>
    </author>
    <author>
      <name>Mateusz Wiliński</name>
    </author>
    <author>
      <name>Piotr Ochnicki</name>
    </author>
    <author>
      <name>Piotr Arendarski</name>
    </author>
    <author>
      <name>Tomasz Gubiec</name>
    </author>
    <link href="http://arxiv.org/abs/1603.05142v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.05142v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.06407v1</id>
    <updated>2016-03-21T12:27:22Z</updated>
    <published>2016-03-21T12:27:22Z</published>
    <title>The mathematics of non-linear metrics for nested networks</title>
    <summary>  Numerical analysis of data from international trade and ecological networks
has shown that the non-linear fitness-complexity metric is the best candidate
to rank nodes by importance in bipartite networks that exhibit a nested
structure. Despite its relevance for real networks, the mathematical properties
of the metric and its variants remain largely unexplored. Here, we perform an
analytic and numeric study of the fitness-complexity metric and a new variant,
called minimal extremal metric. We rigorously derive exact expressions for node
scores for perfectly nested networks and show that these expressions explain
the non-trivial convergence properties of the metrics. A comparison between the
fitness-complexity metric and the minimal extremal metric on real data reveals
that the latter can produce improved rankings if the input data are reliable.
</summary>
    <author>
      <name>Rui-Jie Wu</name>
    </author>
    <author>
      <name>Gui-Yuan Shi</name>
    </author>
    <author>
      <name>Yi-Cheng Zhang</name>
    </author>
    <author>
      <name>Manuel Sebastian Mariani</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.physa.2016.05.023</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.physa.2016.05.023" rel="related"/>
    <link href="http://arxiv.org/abs/1603.06407v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.06407v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.06888v1</id>
    <updated>2016-03-22T17:48:47Z</updated>
    <published>2016-03-22T17:48:47Z</published>
    <title>The behavioural aspect of green technology investments: a general
  positive model in the context of heterogeneous agents</title>
    <summary>  Studies report that firms do not invest in cost-effective green technologies.
While economic barriers can explain parts of the gap, behavioural aspects cause
further under-valuation. This could be partly due to systematic deviations of
decision-making agents' perceptions from normative benchmarks, and partly due
to their diversity. This paper combines available behavioural knowledge into a
simple model of technology adoption. Firms are modelled as heterogeneous agents
with different behavioural responses. To quantify the gap, the model simulates
their investment decisions from different theoretical perspectives. While
relevant parameters are uncertain at the micro-level, using distributed agent
perspectives provides a realistic representation of the macro adoption rate.
The model is calibrated using audit data for proposed investments in energy
efficient electric motors. The inclusion of behavioural factors reduces
significantly expected adoption rates: from 81% using a normative optimisation
perspective, down to 20% using a behavioural perspective. The effectiveness of
various policies is tested.
</summary>
    <author>
      <name>F. Knobloch</name>
    </author>
    <author>
      <name>J. -F. Mercure</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.eist.2016.03.002</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.eist.2016.03.002" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages, 6 figures, 7 tables, to appear in Environmental Innovation
  and Societal Transitions</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Environmental Innovation and Societal Transitions 21 (2016) 39-55</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1603.06888v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.06888v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.08142v1</id>
    <updated>2016-03-26T19:53:32Z</updated>
    <published>2016-03-26T19:53:32Z</published>
    <title>Conjoint axiomatization of the Choquet integral for heterogeneous
  product sets</title>
    <summary>  We propose an axiomatization of the Choquet integral model for the general
case of a heterogeneous product set $X = X_1 \times \ldots \times X_n$. In MCDA
elements of $X$ are interpreted as alternatives, characterized by criteria
taking values from the sets $X_i$. Previous axiomatizations of the Choquet
integral have been given for particular cases $X = Y^n$ and $X = \mathbb{R}^n$.
However, within multicriteria context such identicalness, hence
commensurateness, of criteria cannot be assumed a priori. This constitutes the
major difference of this paper from the earlier axiomatizations. In particular,
the notion of "comonotonicity" cannot be used in a heterogeneous structure, as
there does not exist a "built-in" order between elements of sets $X_i$ and
$X_j$. However, such an order is implied by the representation model. Our
approach does not assume commensurateness of criteria. We construct the
representation and study its uniqueness properties.
</summary>
    <author>
      <name>Mikhail Timonin</name>
    </author>
    <link href="http://arxiv.org/abs/1603.08142v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.08142v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.08311v1</id>
    <updated>2016-03-28T05:17:31Z</updated>
    <published>2016-03-28T05:17:31Z</published>
    <title>Interest Rates and Inflation</title>
    <summary>  This article is an extension of the work of one of us (Coopersmith, 2011) in
deriving the relationship between certain interest rates and the inflation rate
of a two component economic system. We use the well-known Fisher relation
between the difference of the nominal interest rate and its inflation adjusted
value to eliminate the inflation rate and obtain a delay differential equation.
We provide computer simulated solutions for this equation over regimes of
interest. This paper could be of interest to three audiences: those in
Economics who are interested in interest and inflation; those in Mathematics
who are interested in examining a detailed analysis of a delay differential
equation, which includes a summary of existing results, simulations, and an
exact solution; and those in Physics who are interested in non-traditional
applications of traditional methods of modeling.
</summary>
    <author>
      <name>Michael Coopersmith</name>
    </author>
    <author>
      <name>Pascal J. Gambardella</name>
    </author>
    <link href="http://arxiv.org/abs/1603.08311v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.08311v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.00369v1</id>
    <updated>2016-04-01T19:28:06Z</updated>
    <published>2016-04-01T19:28:06Z</published>
    <title>The Mittag-Leffler Phillips Curve</title>
    <summary>  In this paper, a mathematical model containing two-parameter Mittag-Leffler
function in its definition is proposed to be used for the first time to fit the
relation between unemployment rate and inflation rate, also known as the
Phillips curve. The Phillips curve is in the literature often represented by an
exponential-like shape. On the other hand, Phillips in his fundamental paper
used a power function in the model definition. Considering that the ordinary as
well as generalised Mittag-Leffler function behave between a purely exponential
function and a power function it is natural to implement it in the definition
of the model used to fit the data representing the Phillips curve. The data of
two strong European economies, France and Germany, are used for the modelling
purposes.
</summary>
    <author>
      <name>Tomas Skovranek</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages, 4 figures, 4 tables, 10 numbered equations</arxiv:comment>
    <link href="http://arxiv.org/abs/1604.00369v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.00369v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.01224v3</id>
    <updated>2016-10-12T08:34:35Z</updated>
    <published>2016-04-05T11:42:56Z</published>
    <title>Commodity Dynamics: A Sparse Multi-class Approach</title>
    <summary>  The correct understanding of commodity price dynamics can bring relevant
improvements in terms of policy formulation both for developing and developed
countries. Agricultural, metal and energy commodity prices might depend on each
other: although we expect few important effects among the total number of
possible ones, some price effects among different commodities might still be
substantial. Moreover, the increasing integration of the world economy suggests
that these effects should be comparable for different markets. This paper
introduces a sparse estimator of the Multi-class Vector AutoRegressive model to
detect common price effects between a large number of commodities, for
different markets or investment portfolios. In a first application, we consider
agricultural, metal and energy commodities for three different markets. We show
a large prevalence of effects involving metal commodities in the Chinese and
Indian markets, and the existence of asymmetric price effects. In a second
application, we analyze commodity prices for five different investment
portfolios, and highlight the existence of important effects from energy to
agricultural commodities. The relevance of biofuels is hereby confirmed.
Overall, we find stronger similarities in commodity price effects among
portfolios than among markets.
</summary>
    <author>
      <name>Luca Barbaglia</name>
    </author>
    <author>
      <name>Ines Wilms</name>
    </author>
    <author>
      <name>Christophe Croux</name>
    </author>
    <link href="http://arxiv.org/abs/1604.01224v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.01224v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.01819v1</id>
    <updated>2016-04-06T21:46:10Z</updated>
    <published>2016-04-06T21:46:10Z</published>
    <title>Aggregating time preferences with decreasing impatience</title>
    <summary>  It is well-known that for a group of time-consistent decision makers their
collective time preferences may become time-inconsistent. Jackson and Yariv
(2014) demonstrated that the result of aggregation of exponential discount
functions always exhibits present bias. We show that when preferences satisfy
the axioms of Fishburn and Rubinstein (1982), present bias is equivalent to
decreasing impatience (DI). Applying the notion of comparative DI introduced by
Prelec (2004), we generalize the result of Jackson and Yariv (2014). We prove
that the aggregation of distinct discount functions from comparable DI classes
results in the collective discount function which is strictly more DI than the
least DI of the functions being aggregated. We also prove an analogue of
Weitzman's (1998) result, for hyperbolic rather than exponential discount
functions. We show that if a decision maker is uncertain about her hyperbolic
discount rate, then long-term costs and benefits will be discounted at a rate
which is the probability-weighted harmonic mean of the possible hyperbolic
discount rates.
</summary>
    <author>
      <name>Nina Anchugina</name>
    </author>
    <author>
      <name>Matthew Ryan</name>
    </author>
    <author>
      <name>Arkadii Slinko</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">33 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1604.01819v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.01819v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.05771v1</id>
    <updated>2016-04-19T23:06:38Z</updated>
    <published>2016-04-19T23:06:38Z</published>
    <title>Multidimensional matching</title>
    <summary>  We present a general analysis of multidimensional matching problems with
transferable utility, paying particular attention to the case in which the
dimensions of heterogeneity on the two sides of the market are unequal. A
particular emphasis is put on problems where agents on one side of the market
are multidimensional and agents on the other side are uni-dimensional, we
describe a general approach to solve such problems. Lastly, we analyze several
examples, including an hedonic model with differentiated products, a marriage
market model where wives are differentiated in income and fertility, and a
competitive variation of the Rochet-Chon\'e problem. In the latter example, we
show that the bunching phenomena, observed by Rochet and Chon\'e in the
monopoly context, do not occur in the competitive context
</summary>
    <author>
      <name>Pierre-André Chiappori</name>
    </author>
    <author>
      <name>Robert McCann</name>
    </author>
    <author>
      <name>Brendan Pass</name>
    </author>
    <link href="http://arxiv.org/abs/1604.05771v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.05771v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.06284v2</id>
    <updated>2016-07-06T22:29:08Z</updated>
    <published>2016-04-21T12:52:19Z</published>
    <title>The Impact of Services on Economic Complexity: Service Sophistication as
  Route for Economic Growth</title>
    <summary>  Economic complexity reflects the amount of knowledge that is embedded in the
productive structure of an economy. By combining tools from network science and
econometrics, a robust and stable relationship between a country's productive
structure and its economic growth has been established. Here we report that not
only goods but also services are important for predicting the rate at which
countries will grow. By adopting a terminology which classifies manufactured
goods and delivered services as products, we investigate the influence of
services on the country's productive structure. In particular, we provide
evidence that complexity indices for services are in general higher than those
for goods, which is reflected in a general tendency to rank countries with
developed service sector higher than countries with economy centred on
manufacturing of goods. By focusing on country dynamics based on experimental
data, we investigate the impact of services on the economic complexity of
countries measured in the product space (consisting of both goods and
services). Importantly, we show that diversification of service exports and its
sophistication can provide an additional route for economic growth in both
developing and developed countries.
</summary>
    <author>
      <name>Viktor Stojkoski</name>
    </author>
    <author>
      <name>Zoran Utkovski</name>
    </author>
    <author>
      <name>Ljupco Kocarev</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1371/journal.pone.0161633</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1371/journal.pone.0161633" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">High quality figures available upon request</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">PLoS ONE 11(8) 2016</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1604.06284v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.06284v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.08824v1</id>
    <updated>2016-04-29T13:36:37Z</updated>
    <published>2016-04-29T13:36:37Z</published>
    <title>A new structural stochastic volatility model of asset pricing and its
  stylized facts</title>
    <summary>  Building on a prominent agent-based model, we present a new structural
stochastic volatility asset pricing model of fundamentalists vs. chartists
where the prices are determined based on excess demand. Specifically, this
allows for modelling stochastic interactions between agents, based on a herding
process corrected by a price misalignment, and incorporating strong noise
components in the agents' demand. The model's parameters are estimated using
the method of simulated moments, where the moments reflect the basic properties
of the daily returns of a stock market index. In addition, for the first time
we apply a (parametric) bootstrap method in a setting where the switching
between strategies is modelled using a discrete choice approach. As we
demonstrate, the resulting dynamics replicate a rich set of the stylized facts
of the daily financial data including: heavy tails, volatility clustering, long
memory in absolute returns, as well as the absence of autocorrelation in raw
returns, volatility-volume correlations, aggregate Gaussianity, concave price
impact and extreme price events.
</summary>
    <author>
      <name>Radu T. Pruna</name>
    </author>
    <author>
      <name>Maria Polukarov</name>
    </author>
    <author>
      <name>Nicholas R. Jennings</name>
    </author>
    <link href="http://arxiv.org/abs/1604.08824v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.08824v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.05631v1</id>
    <updated>2016-05-18T15:52:40Z</updated>
    <published>2016-05-18T15:52:40Z</published>
    <title>Far from equilibrium: Wealth reallocation in the United States</title>
    <summary>  Studies of wealth inequality often assume that an observed wealth
distribution reflects a system in equilibrium. This constraint is rarely tested
empirically. We introduce a simple model that allows equilibrium but does not
assume it. To geometric Brownian motion (GBM) we add reallocation: all
individuals contribute in proportion to their wealth and receive equal shares
of the amount collected. We fit the reallocation rate parameter required for
the model to reproduce observed wealth inequality in the United States from
1917 to 2012. We find that this rate was positive until the 1980s, after which
it became negative and of increasing magnitude. With negative reallocation, the
system cannot equilibrate. Even with the positive reallocation rates observed,
equilibration is too slow to be practically relevant. Therefore, studies which
assume equilibrium must be treated skeptically. By design they are unable to
detect the dramatic conditions found here when data are analysed without this
constraint.
</summary>
    <author>
      <name>Yonatan Berman</name>
    </author>
    <author>
      <name>Ole Peters</name>
    </author>
    <author>
      <name>Alexander Adamou</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1605.05631v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.05631v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.08025v1</id>
    <updated>2016-05-25T19:47:01Z</updated>
    <published>2016-05-25T19:47:01Z</published>
    <title>Foreign exchange risk premia: from traditional to state-space analyses</title>
    <summary>  This paper examines foreign exchange risk premia from simple univariate
regressions to the state-space method. The adjusted traditional regressions
properly figure out the existence and time-evolving property of the risk
premia. Successively, the state-space estimations overall are quite rationally
competent in examining the essence of time variability of the unobservable risk
premia. To be more precise, the coefficients on the lagged estimated
time-series are significant and the disturbance combined from the observation
and transition equations in the state-space system, rational and premium
errors, respectively, is statistically white noise. Such the two residuals are
discovered to move oppositely with their covariance approaching zero suggested
by the empirics. Besides, foreign exchange risk premia are projected and found
significantly stationary at level and relatively volatile throughout time with
some clustering. This volatility is however not quite dominant in the
deviations of forward prediction errors.
</summary>
    <author>
      <name>Siwat Nakmai</name>
    </author>
    <link href="http://arxiv.org/abs/1605.08025v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.08025v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.08099v1</id>
    <updated>2016-05-25T22:51:23Z</updated>
    <published>2016-05-25T22:51:23Z</published>
    <title>Contracting theory with competitive interacting agents</title>
    <summary>  In a framework close to the one developed by Holmstr\"om and Milgrom [44], we
study the optimal contracting scheme between a Principal and several Agents.
Each hired Agent is in charge of one project, and can make efforts towards
managing his own project, as well as impact (positively or negatively) the
projects of the other Agents. Considering economic Agents in competition with
relative performance concerns, we derive the optimal contracts in both first
best and moral hazard settings. The enhanced resolution methodology relies
heavily on the connection between Nash equilibria and multidimensional
quadratic BSDEs. The optimal contracts are linear and each agent is paid a
fixed proportion of the terminal value of all the projects of the firm.
Besides, each Agent receives his reservation utility, and those with high
competitive appetence are assigned less volatile projects, and shall even
receive help from the other Agents. From the principal point of view, it is in
the firm interest in our model to strongly diversify the competitive appetence
of the Agents.
</summary>
    <author>
      <name>Romuald Elie</name>
    </author>
    <author>
      <name>Dylan Possamaï</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">36 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1605.08099v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.08099v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.08166v2</id>
    <updated>2017-01-25T09:52:04Z</updated>
    <published>2016-05-26T07:01:10Z</published>
    <title>A constraint-based framework to study rationality, competition and
  cooperation in fisheries</title>
    <summary>  In this paper, we present a simplified framework to represent competition,
coordination and bargaining in fisheries when they operate under financial and
technological constraints. Competition within constraints leads to a particular
type of mathematical game in which the strategy choice by one player changes
strategy set of the other. By studying the equilibria and bargaining space of
this game when players maximize either profit or fishing capacity, we highlight
that differences in financial constraints among players leads to a tougher
play, with a reduced bargaining space as the least constrained player can
readily exclude another from the competition. The exacerbating effects of
constraints on competition are even stronger when players maximize capacity. We
discuss the significance of our results for global ocean governance in a
current context characterized by financialization and technological
development. We suggest that in order to maximize the chances of fruitful
negociations and aim towards a fair sharing of sea resources, it would be
helpful to focus on leveling current differences in the constraints faced
between competing fishing systems by supporting local financial systems and
technological control, before implementing sophisticated economic tools.
</summary>
    <author>
      <name>Christian Mullon</name>
    </author>
    <author>
      <name>Charles Mullon</name>
    </author>
    <link href="http://arxiv.org/abs/1605.08166v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.08166v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.00424v1</id>
    <updated>2016-06-01T19:53:26Z</updated>
    <published>2016-06-01T19:53:26Z</published>
    <title>Price formation on a housing market and spatial income segregation</title>
    <summary>  The price formation in Non-Walrasian markets is notoriously an open problem.
Here we focus on urban housing markets, where the mismatch between supply and
demand has important consequences in terms of social welfare. We propose a
simple Agent-Based Model (ABM) that explicitly reproduces the market mechanism
and which is specifically suited to study issues related to spatial income
segregation. We first find the analytical solution of the ABM in some specific
cases, shedding light on the structure of the model and on the effect of the
parameters. We then simulate the fully-fledged ABM and find that: (i) the
market mechanism easily implies income segregation; (ii) an increase of the
demand in one part of the city can potentially increase the prices all over the
city (in qualitative agreement with the data); (iii) subsidies are more
efficient than taxes in mitigating income segregation. These non-trivial
results provide an example of the kind of insights that can be gained if one
considers bounded rationality, heterogeneity and the potential lack of
(Walrasian) equilibrium, as it would have been much less natural to address
these issues under more standard assumptions.
</summary>
    <author>
      <name>Marco Pangallo</name>
    </author>
    <author>
      <name>Jean Pierre Nadal</name>
    </author>
    <author>
      <name>Annick Vignes</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">WEHIA 2016 Conference Paper</arxiv:comment>
    <link href="http://arxiv.org/abs/1606.00424v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.00424v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.02748v1</id>
    <updated>2016-06-05T16:57:52Z</updated>
    <published>2016-06-05T16:57:52Z</published>
    <title>A Contextual Model Of The Secessionist Rebellion in Eastern Ukraine</title>
    <summary>  This paper explores the possible contextual factors that drove some
individuals to lead, and others to join the pro-secessionist rebellion in the
2013-2014 conflict in Eastern Ukraine. We expand on the existing rational
choice literature on revolutionary participation and rebellious movements by
building a contextual choice model accounting for both cost-benefit and
behavioral considerations taken by Pro-Russian militants and rebels in the
region of Donbass. Our model generates predictions about the characteristics of
the socio-political-cultural context that are most likely to ignite and sustain
hierarchical rebel movements similar to those in Ukraine.
</summary>
    <author>
      <name>Olga Nicoara</name>
    </author>
    <author>
      <name>David White</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This is an applied game theory paper, including a lengthy discussion
  of how game theory has been used in economics papers over the years. The
  second author is a professor of mathematics and computer science, and hopes
  this paper will be of interest to other theorists interested in doing more
  applied work</arxiv:comment>
    <link href="http://arxiv.org/abs/1606.02748v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.02748v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.01999v1</id>
    <updated>2016-07-07T13:14:43Z</updated>
    <published>2016-07-07T13:14:43Z</published>
    <title>Inferring the contiguity matrix for spatial autoregressive analysis with
  applications to house price prediction</title>
    <summary>  Inference methods in traditional statistics, machine learning and data mining
assume that data is generated from an independent and identically distributed
(iid) process. Spatial data exhibits behavior for which the iid assumption must
be relaxed. For example, the standard approach in spatial regression is to
assume the existence of a contiguity matrix which captures the spatial
autoregressive properties of the data. However all spatial methods, till now,
have assumed that the contiguity matrix is given apriori or can be estimated by
using a spatial similarity function. In this paper we propose a convex
optimization formulation to solve the spatial autoregressive regression (SAR)
model in which both the contiguity matrix and the non-spatial regression
parameters are unknown and inferred from the data. We solve the problem using
the alternating direction method of multipliers (ADMM) which provides a
solution which is both robust and efficient. While our approach is general we
use data from housing markets of Boston and Sydney to both guide the analysis
and validate our results. A novel side effect of our approach is the automatic
discovery of spatial clusters which translate to submarkets in the housing data
sets.
</summary>
    <author>
      <name>Somwrita Sarkar</name>
    </author>
    <author>
      <name>Sanjay Chawla</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 Pages, 6 Figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1607.01999v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.01999v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.04484v1</id>
    <updated>2016-07-14T12:17:10Z</updated>
    <published>2016-07-14T12:17:10Z</published>
    <title>The Oxford Olympics Study 2016: Cost and Cost Overrun at the Games</title>
    <summary>  Given that Olympic Games held over the past decade each have cost USD 8.9
billion on average, the size and financial risks of the Games warrant study.
The objectives of the Oxford Olympics study are to (1) establish the actual
outturn costs of previous Olympic Games in a manner where cost can consistently
be compared across Games; (2) establish cost overruns for previous Games, i.e.,
the degree to which final outturn costs reflect projected budgets at the bid
stage, again in a way that allows comparison across Games; (3) test whether the
Olympic Games Knowledge Management Program has reduced cost risk for the Games,
and, finally, (4) benchmark cost and cost overrun for the Rio 2016 Olympics
against previous Games. The main contribution of the Oxford study is to
establish a phenomenology of cost and cost overrun at the Olympics, which
allows consistent and systematic comparison across Games. This has not been
done before. The study concludes that for a city and nation to decide to stage
the Olympic Games is to decide to take on one of the most costly and
financially most risky type of megaproject that exists, something that many
cities and nations have learned to their peril.
</summary>
    <author>
      <name>Bent Flyvbjerg</name>
    </author>
    <author>
      <name>Allison Stewart</name>
    </author>
    <author>
      <name>Alexander Budzier</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">28 pp</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Said Business School Working Papers (Oxford: University of
  Oxford), july 2016</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1607.04484v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.04484v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.06247v1</id>
    <updated>2016-07-21T09:43:56Z</updated>
    <published>2016-07-21T09:43:56Z</published>
    <title>Effects of Sea Level Rise on Economy of the United States</title>
    <summary>  We report the first ex post study of the economic impact of sea level rise.
We apply two econometric approaches to estimate the past effects of sea level
rise on the economy of the USA, viz. Barro type growth regressions adjusted for
spatial patterns and a matching estimator. Unit of analysis is 3063 counties of
the USA. We fit growth regressions for 13 time periods and we estimated
numerous varieties and robustness tests for both growth regressions and
matching estimator. Although there is some evidence that sea level rise has a
positive effect on economic growth, in most specifications the estimated
effects are insignificant. We therefore conclude that there is no stable,
significant effect of sea level rise on economic growth. This finding
contradicts previous ex ante studies.
</summary>
    <author>
      <name>Monika Novackova</name>
    </author>
    <author>
      <name>Richard S. J. Tol</name>
    </author>
    <link href="http://arxiv.org/abs/1607.06247v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.06247v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.00213v1</id>
    <updated>2016-07-31T12:48:01Z</updated>
    <published>2016-07-31T12:48:01Z</published>
    <title>Self-organization in a distributed coordination game through heuristic
  rules</title>
    <summary>  In this paper we consider a distributed coordination game played by a large
number of agents with finite information sets, which characterizes emergence of
a single dominant attribute out of a large number of competitors. Formally, $N$
agents play a coordination game repeatedly which has exactly $N$ Nash
equilibria and all of the equilibria are equally preferred by the agents. The
problem is to select one equilibrium out of $N$ possible equilibria in the
least number of attempts. We propose a number of heuristic rules based on
reinforcement learning to solve the coordination problem. We see that the
agents self-organize into clusters with varying intensities depending on the
heuristic rule applied although all clusters but one are transitory in most
cases. Finally, we characterize a trade-off in terms of the time requirement to
achieve a degree of stability in strategies and the efficiency of such a
solution.
</summary>
    <author>
      <name>S. Agarwal</name>
    </author>
    <author>
      <name>D. Ghosh</name>
    </author>
    <author>
      <name>A. S. Chakrabarti</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1140/epjb/e2016-70464-0</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1140/epjb/e2016-70464-0" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 12 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1608.00213v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.00213v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.01891v1</id>
    <updated>2016-08-04T15:58:24Z</updated>
    <published>2016-08-04T15:58:24Z</published>
    <title>Toward Development of a New Health Economic Evaluation Definition</title>
    <summary>  Economic evaluation is a dynamically advancing knowledge area of health
economics. It has been conceived to provide evidence for allocating scarce
resources to gain the best value for money. The problem of efficiency of
investments becomes even more crucial with advances in modern medicine and
public health which bring about both improved patient outcomes and higher
costs. Despite the abundance of literature on the economic evaluation concepts,
some key notions including the definition of the health economic evaluation
remain open for discussion. Academic literature offers a large number and
growing variety of economic evaluation definitions. It testifies to the fact
that existing definitions do not meet requirements of economists. The aim of
this study was to examine existing definitions and reveal their common
features.
</summary>
    <author>
      <name>Alexei Botchkarev</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1453/jeb.v3i4.1005</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1453/jeb.v3i4.1005" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Economics Bibliography, 2016, (3)4, pp. 590-601</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1608.01891v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.01891v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.04832v1</id>
    <updated>2016-08-17T02:08:06Z</updated>
    <published>2016-08-17T02:08:06Z</published>
    <title>Monetary economics from econophysics perspective</title>
    <summary>  This is an invited article for the Discussion and Debate special issue of The
European Physical Journal Special Topics on the subject "Can Economics Be a
Physical Science?" The first part of the paper traces the personal path of the
author from theoretical physics to economics. It briefly summarizes
applications of statistical physics to monetary transactions in an ensemble of
economic agents. It shows how a highly unequal probability distribution of
money emerges due to irreversible increase of entropy in the system. The second
part examines deep conceptual and controversial issues and fallacies in
monetary economics from econophysics perspective. These issues include the
nature of money, conservation (or not) of money, distinctions between money vs.
wealth and money vs. debt, creation of money by the state and debt by the
banks, the origins of monetary crises and capitalist profit. Presentation uses
plain language understandable to laypeople and may be of interest to both
specialists and general public.
</summary>
    <author>
      <name>Victor M. Yakovenko</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1140/epjst/e2016-60213-3</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1140/epjst/e2016-60213-3" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">23 pages, 1 figure</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Eur. Phys. J. Spec. Top. 225, 3313 (2016)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1608.04832v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.04832v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1610.00274v2</id>
    <updated>2017-05-24T19:34:58Z</updated>
    <published>2016-10-02T13:01:22Z</published>
    <title>The complex dynamics of products and its asymptotic properties</title>
    <summary>  We analyse global export data within the Economic Complexity framework. We
couple the new economic dimension Complexity, which captures how sophisticated
products are, with an index called logPRODY, a measure of the income of the
respective exporters. Products' aggregate motion is treated as a 2-dimensional
dynamical system in the Complexity-logPRODY plane. We find that this motion can
be explained by a quantitative model involving the competition on the markets,
that can be mapped as a scalar field on the Complexity-logPRODY plane and acts
in a way akin to a potential. This explains the movement of products towards
areas of the plane in which the competition is higher. We analyse market
composition in more detail, finding that for most products it tends, over time,
to a characteristic configuration, which depends on the Complexity of the
products. This market configuration, which we called asymptotic, is
characterized by higher levels of competition.
</summary>
    <author>
      <name>Orazio Angelini</name>
    </author>
    <author>
      <name>Matthieu Cristelli</name>
    </author>
    <author>
      <name>Andrea Zaccaria</name>
    </author>
    <author>
      <name>Luciano Pietronero</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1371/journal.pone.0177360</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1371/journal.pone.0177360" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages, 5 figures, supporting information. This paper was published
  on PLOS One on May 17, 2017</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Angelini O, Cristelli M, Zaccaria A, Pietronero L (2017) The
  complex dynamics of products and its asymptotic properties. PLOS ONE 12(5):
  e0177360</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1610.00274v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1610.00274v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1610.05171v1</id>
    <updated>2016-10-17T15:39:25Z</updated>
    <published>2016-10-17T15:39:25Z</published>
    <title>Urban-rural gap and poverty traps in China: A prefecture level analysis</title>
    <summary>  Urban-rural gap and regional inequality are long standing problems in China
and result in considerable number of studies. This paper examines the dynamic
behaviors of incomes for both urban and rural areas with a prefectural data
set. The analysis is conducted by using a distribution dynamics approach, which
have advantages in examination on persistence, polarization and convergence
clubs. The results show that persistence and immobility are the dominant
characteristics in the income distribution dynamics. The prefectural urban and
rural areas converge into their own steady states differentiated in income
levels. This pattern of urban-rural gap also exists in three regional groups,
namely the eastern, central and western regions. Examination on the dynamics of
the poorest areas shows that geographical poverty traps exist in both urban and
rural prefectural areas. Our results indicate that more policy interventions
are required to narrow down the urban-rural gap and to eliminate the poverty
traps in China.
</summary>
    <author>
      <name>Jian-Xin Wu</name>
    </author>
    <author>
      <name>Ling-Yun He</name>
    </author>
    <link href="http://arxiv.org/abs/1610.05171v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1610.05171v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1610.05583v3</id>
    <updated>2017-01-18T10:45:41Z</updated>
    <published>2016-10-18T12:50:52Z</published>
    <title>Price Dynamics Via Expectations, and the Role of Money Therein</title>
    <summary>  Beyond its obvious macro-economic relevance, fiat money has important
micro-economic implications. They matter for addressing No. 8 in Smale's
"Mathematical Problems for the Next Century": extend the mathematical model of
general equilibrium theory to include price adjustments. In the canonical
Arrow-Debreu framework, equilibrium prices are set by a fictitious auctioneer.
Removing that fiction raises the question of how prices are set and adjusted by
decentralised actors with incomplete information. We investigate this question
through a very basic model where a unique factor of production, labour,
produces a single consumption good, called jelly for brevity. The point of the
model is to study a price dynamics based on the firm's expectations about jelly
demand and labour supply. The system tends towards economic equilibrium,
however, depending on the initial conditions it might not get there. In
different model versions, different kinds of money are introduced. Compared to
the case of no money, the introduction of money as a store of value facilitates
the system reaching economic equilibrium. If money is introduced as a third
commodity, i.e. there is also a demand for money, the system dynamics in
general becomes more complex.
</summary>
    <author>
      <name>Gesine A. Steudle</name>
    </author>
    <author>
      <name>Saini Yang</name>
    </author>
    <author>
      <name>Carlo C. Jaeger</name>
    </author>
    <link href="http://arxiv.org/abs/1610.05583v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1610.05583v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1611.01285v2</id>
    <updated>2016-11-09T12:32:03Z</updated>
    <published>2016-11-04T08:21:03Z</published>
    <title>Naive Diversification Preferences and their Representation</title>
    <summary>  A widely applied diversification paradigm is the naive diversification choice
heuristic. It stipulates that an economic agent allocates equal decision
weights to given choice alternatives independent of their individual
characteristics. This article provides mathematically and economically sound
choice theoretic foundations for the naive approach to diversification. We
axiomatize naive diversification by defining it as a preference for equality
over inequality and derive its relationship to the classical diversification
paradigm. In particular, we show that (i) the notion of permutation invariance
lies at the core of naive diversification and that an economic agent is a naive
diversifier if and only if his preferences are convex and permutation
invariant; (ii) Schur-concave utility functions capture the idea of being
inequality averse on top of being risk averse; and (iii) the transformations,
which rebalance unequal decision weights to equality, are characterized in
terms of their implied turnover.
</summary>
    <author>
      <name>Enrico G. De Giorgi</name>
    </author>
    <author>
      <name>Ola Mahmoud</name>
    </author>
    <link href="http://arxiv.org/abs/1611.01285v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1611.01285v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.MF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1611.01767v1</id>
    <updated>2016-11-06T12:37:29Z</updated>
    <published>2016-11-06T12:37:29Z</published>
    <title>EM Algorithm and Stochastic Control in Economics</title>
    <summary>  Generalising the idea of the classical EM algorithm that is widely used for
computing maximum likelihood estimates, we propose an EM-Control (EM-C)
algorithm for solving multi-period finite time horizon stochastic control
problems. The new algorithm sequentially updates the control policies in each
time period using Monte Carlo simulation in a forward-backward manner; in other
words, the algorithm goes forward in simulation and backward in optimization in
each iteration. Similar to the EM algorithm, the EM-C algorithm has the
monotonicity of performance improvement in each iteration, leading to good
convergence properties. We demonstrate the effectiveness of the algorithm by
solving stochastic control problems in the monopoly pricing of perishable
assets and in the study of real business cycle.
</summary>
    <author>
      <name>Steven Kou</name>
    </author>
    <author>
      <name>Xianhua Peng</name>
    </author>
    <author>
      <name>Xingbo Xu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">46 pages, 9 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1611.01767v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1611.01767v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="93E20, 93E35, 91G60, 91G80, 90B05, 90C15, 90C35, 90C39, 90C40" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1611.01771v1</id>
    <updated>2016-11-06T13:13:12Z</updated>
    <published>2016-11-06T13:13:12Z</published>
    <title>An Equilibrium Model with Computationally Constrained Agents</title>
    <summary>  We study a large economy in which firms cannot compute exact solutions to the
non-linear equations that characterize the equilibrium price at which they can
sell future output. Instead, firms use polynomial expansions to approximate
prices. The precision with which they can compute prices is endogenous and
depends on the overall level of supply. At the same time, firms' individual
supplies, and thus aggregate supply, depend on the precision with which they
approximate prices. This interrelation between supply and price forecast
induces multiple equilibria, with inefficiently low output, in economies that
otherwise have a unique, efficient equilibrium. Moreover, exogenous parameter
changes, which would increase output were there no computational frictions, can
diminish agents' ability to approximate future prices, and reduce output. Our
model therefore accommodates the intuition that interventions, such as
unprecedented quantitative easing, can put agents into "uncharted territory".
</summary>
    <author>
      <name>Wolfgang Kuhle</name>
    </author>
    <link href="http://arxiv.org/abs/1611.01771v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1611.01771v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1611.02547v1</id>
    <updated>2016-10-27T17:36:27Z</updated>
    <published>2016-10-27T17:36:27Z</published>
    <title>Optimal Extraction and Taxation of Strategic Natural Resources: A
  Differential Game Approach</title>
    <summary>  This paper studies the optimal extraction and taxation of nonrenewable
natural resources. It is well known the market values of the main strategic
resources such as oil, natural gas, uranium, copper,...,etc, fluctuate randomly
following global and seasonal macro-economic parameters, these values are
modeled using Markov switching L\'evy processes. We formulate this problem as a
differential game where the two players are the mining company whose aim is to
maximize the revenues generated from its extracting activities and the
government agency in charge of regulating and taxing natural resources. We
prove the existence of a Nash equilibrium and characterize the value functions
of this differential game as the unique viscosity solutions of the
corresponding Hamilton Jacobi Isaacs equations. Furthermore, optimal extraction
and taxation policies that should be applied when the equilibrium is reached
are derived. In addition, we construct and prove the convergence of a numerical
scheme for approximating the value functions and optimal policies. A numerical
example is presented to illustrate our findings.
</summary>
    <author>
      <name>Moustapha Pemy</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: text overlap with arXiv:1606.03388. substantial
  text overlap with arXiv:1611.01492</arxiv:comment>
    <link href="http://arxiv.org/abs/1611.02547v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1611.02547v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.MF" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1611.02760v1</id>
    <updated>2016-11-08T23:05:43Z</updated>
    <published>2016-11-08T23:05:43Z</published>
    <title>The missing assets and the size of Shadow Banking: an update</title>
    <summary>  In a recent paper, using data from Forbes Global 2000, we have observed that
the upper tail of the firm size distribution (by assets) falls off much faster
than a Pareto distribution. The missing mass was suggested as an indicator of
the size of the Shadow Banking (SB) sector. This short note provides the latest
figures of the missing assets for 2013, 2014 and 2015. In 2013 and 2014 the
dynamics of the missing assets continued being strongly correlated with
estimates of the size of the SB sector of the Financial Stability Board. In
2015 we find a sharp decrease in the size of missing assets, suggesting that
the SB sector is deflating.
</summary>
    <author>
      <name>Davide Fiaschi</name>
    </author>
    <author>
      <name>Imre Kondor</name>
    </author>
    <author>
      <name>Matteo Marsili</name>
    </author>
    <author>
      <name>Valerio Volpati</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3 pages, 1 figure and 1 table</arxiv:comment>
    <link href="http://arxiv.org/abs/1611.02760v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1611.02760v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1611.05280v1</id>
    <updated>2016-11-15T03:16:05Z</updated>
    <published>2016-11-15T03:16:05Z</published>
    <title>Toward Economics as a New Complex System</title>
    <summary>  The 2015 Nobel Prize in Economic Sciences was awarded to Eugene Fama, Lars
Peter Hansen and Robert Shiller for their contributions to the empirical
analysis of asset prices. Eugene Fama [1] is an advocate of the efficient
market hypothesis. The efficient market hypothesis assumes that asset price is
determined by using all available information and only reacts to new
information not incorporated into the fundamentals. Thus, the movement of stock
prices is unpredictable. Robert Shiller [2] has been studying the existence of
irrational bubbles, which are defined as the long term deviations of asset
price from the fundamentals. This drives us to the unsettled question of how
the market actually works.
  In this paper, I look back at the development of economics and consider the
direction in which we should move in order to truly understand the workings of
an economic society.
</summary>
    <author>
      <name>Taisei Kaizoji</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1140/epjst/e2016-60161-x</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1140/epjst/e2016-60161-x" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Eur. Phyys. J. Special Topics 225, 3225-3230 (2016)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1611.05280v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1611.05280v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.00221v1</id>
    <updated>2016-12-01T12:24:46Z</updated>
    <published>2016-12-01T12:24:46Z</published>
    <title>The Coconut Model with Heterogeneous Strategies and Learning</title>
    <summary>  In this paper, we develop an agent-based version of the Diamond search
equilibrium model - also called Coconut Model. In this model, agents are faced
with production decisions that have to be evaluated based on their expectations
about the future utility of the produced entity which in turn depends on the
global production level via a trading mechanism. While the original dynamical
systems formulation assumes an infinite number of homogeneously adapting agents
obeying strong rationality conditions, the agent-based setting allows to
discuss the effects of heterogeneous and adaptive expectations and enables the
analysis of non-equilibrium trajectories. Starting from a baseline
implementation that matches the asymptotic behavior of the original model, we
show how agent heterogeneity can be accounted for in the aggregate dynamical
equations. We then show that when agents adapt their strategies by a simple
temporal difference learning scheme, the system converges to one of the fixed
points of the original system. Systematic simulations reveal that this is the
only stable equilibrium solution.
</summary>
    <author>
      <name>Sven Banisch</name>
    </author>
    <author>
      <name>Eckehard Olbrich</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted for publication in the Journal of Artificial Societies and
  Social Simulation (JASSS)</arxiv:comment>
    <link href="http://arxiv.org/abs/1612.00221v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.00221v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91-08, 68T05, 60J10" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.01624v1</id>
    <updated>2016-12-06T01:40:54Z</updated>
    <published>2016-12-06T01:40:54Z</published>
    <title>Universal Exponential Structure of Income Inequality: Evidence from 60
  Countries</title>
    <summary>  Economic competition between humans leads to income inequality, but, so far,
there has been little understanding of underlying quantitative mechanisms
governing such a collective behavior. We analyze datasets of household income
from 60 countries, ranging from Europe to Latin America, North America and
Asia. For all of the countries, we find a surprisingly universal rule: Income
distribution for the great majority of populations (low and middle income
classes) follows an exponential law. To explain this empirical observation, we
propose a theoretical model within the standard framework of modern economics
and show that free competition and Rawls fairness are the underlying mechanisms
producing the exponential pattern. The free parameters of the exponential
distribution in our model have an explicit economic interpretation and direct
relevance to policy measures intended to alleviate income inequality.
</summary>
    <author>
      <name>Yong Tao</name>
    </author>
    <author>
      <name>Xiangjun Wu</name>
    </author>
    <author>
      <name>Tao Zhou</name>
    </author>
    <author>
      <name>Weibo Yan</name>
    </author>
    <author>
      <name>Yanyuxiang Huang</name>
    </author>
    <author>
      <name>Han Yu</name>
    </author>
    <author>
      <name>Benedict Mondal</name>
    </author>
    <author>
      <name>Victor M. Yakovenko</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">22 pages, 4 figures, 4 tables, submitted to Journal of Economic
  Interaction and Coordination</arxiv:comment>
    <link href="http://arxiv.org/abs/1612.01624v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.01624v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.02654v1</id>
    <updated>2016-10-25T06:07:34Z</updated>
    <published>2016-10-25T06:07:34Z</published>
    <title>China building energy consumption: definitions and measures from an
  operational perspective</title>
    <summary>  There is an increasing awareness of the significance of Chinese building
energy consumption(BEC). However, something worth discussing is that estimate
the building energy consumption adopting the definition of life cycle or
operation. In the existing studies with various evaluation methods, the issue
about the amount of energy consumed by China buildings has not been understood.
In order to settle the disputes over the calculation of BEC, this paper
establish an appropriate accounting method of building energy to present BEC
situation in China and lay the foundation for building energy efficiency.
Adopting the conception of building operational energy consumption, we find
that the energy consumption of buildings just accounts for 15% - 16% of the
final total energy consumption in China; by contrast, the previous calculations
usually have double accounting through top-down approach if central heat-supply
of buildings was given into additional consideration.
</summary>
    <author>
      <name>Ling-Yun He</name>
    </author>
    <author>
      <name>Wei Wei</name>
    </author>
    <link href="http://arxiv.org/abs/1612.02654v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.02654v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.02658v1</id>
    <updated>2016-10-25T15:26:47Z</updated>
    <published>2016-10-25T15:26:47Z</published>
    <title>The distribution dynamics of Carbon Dioxide Emission intensity across
  Chinese provinces: A weighted Approach</title>
    <summary>  This paper examines the distribution dynamics of carbon dioxide (CO2)
emission intensity across 30 Chinese provinces using a weighted distribution
dynamics approach. The results show that CO2 emission intensity tends to
diverge during the sample period of 1995-2014. However, convergence clubs are
found in the ergodic distributions of the full sample and two sub-sample
periods. Divergence, polarization and stratification are the dominant
characteristics in the distribution dynamics. Weightings with economic and
population sizes have important impacts on current distributions and hence long
run steady distributions. Neglecting economic size may under-estimate the
deterioration in the long run steady state. The result also shows that
conditioning on space and income cannot eliminate the multimodality in the long
run distribution. However, capital intensity has important impact on the
formation of convergence clubs. Our findings have contributions in the
understanding of the spatial dynamic behaviours of CO2 emissions across Chinese
provinces, and have important policy implications for CO2 emissions reduction
in China.
</summary>
    <author>
      <name>Jian-Xin Wu</name>
    </author>
    <author>
      <name>Ling-Yun He</name>
    </author>
    <link href="http://arxiv.org/abs/1612.02658v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.02658v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.06291v1</id>
    <updated>2016-12-19T17:50:26Z</updated>
    <published>2016-12-19T17:50:26Z</published>
    <title>The Topology of Inter-industry Relations from the Portuguese National
  Accounts</title>
    <summary>  In last years, the Portuguese economy has gone through a severe adjustment
process, affecting almost all industrial sectors, the building blocks of
economic structures. Research on economic structural changes has made use of
input/output tables to define networks of industrial relations. Here, these
networks are induced from output tables of the Portuguese national accounting
system, being each inter-industry relation defined by the output made by any
two industries for the products that they both produce. The topological
analysis of these networks allows to uncover a particular structure that comes
out during the Portuguese adjustment program. The evolution of the industrial
networks shows an important structural change in 2011-2014, confirming the
usefulness of inducting similarity networks from output tables and the
consequent promising power of the graph formulation for the analysis of
inter-industry relations.
</summary>
    <author>
      <name>Tanya Araújo</name>
    </author>
    <author>
      <name>Rui Faustino</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.physa.2017.03.018</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.physa.2017.03.018" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1612.06291v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.06291v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.07543v1</id>
    <updated>2016-12-22T11:02:39Z</updated>
    <published>2016-12-22T11:02:39Z</published>
    <title>Rating evaluation of sports development efficiency using statistical
  analysis: evidence from Russian football</title>
    <summary>  Increasing investments into various dimensions of sports draw a significant
amount of attention to the way these resources are being managed and which
organizations achieve development goals with higher efficiency. This paper
reviews the methodology of designing an efficiency rating model for assessing
sports entities, focusing on the experience of Russian football. The Russian
Regional Efficiency of Football Development model aims to evaluate the regional
federations of the Football Union of Russian via 5 dimensions. The scoring
method of the model is based on the three-sigma rule of distribution. Support
factors in the form of population density and climate were also included, since
Russian regions significantly differentiate in these aspects. The findings of
this paper showcased that not a single region was able to achieve a maximum 5-
star rating, while regions set to host the 2018 FIFA World Cup did not score
better compared to others. In conclusion the authors provide various
suggestions on further developing and implementing rating models within global
sports organizations.
</summary>
    <author>
      <name>Ilya Solntsev</name>
    </author>
    <author>
      <name>Anatoly Vorobyev</name>
    </author>
    <author>
      <name>Elnura Irmatova</name>
    </author>
    <author>
      <name>Nikita Osokin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1612.07543v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.07543v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.07903v3</id>
    <updated>2017-08-06T20:21:38Z</updated>
    <published>2016-12-23T08:37:05Z</published>
    <title>Long and Short Memory in Economics: Fractional-Order Difference and
  Differentiation</title>
    <summary>  Long and short memory in economic processes is usually described by the
so-called discrete fractional differencing and fractional integration. We prove
that the discrete fractional differencing and integration are the
Grunwald-Letnikov fractional differences of non-integer order d. Equations of
ARIMA(p,d,q) and ARFIMA(p,d,q) models are the fractional-order difference
equations with the Grunwald-Letnikov differences of order d. We prove that the
long and short memory with power law should be described by the exact
fractional-order differences, for which the Fourier transform demonstrates the
power law exactly. The fractional differencing and the Grunwald-Letnikov
fractional differences cannot give exact results for the long and short memory
with power law, since the Fourier transform of these discrete operators satisfy
the power law in the neighborhood of zero only. We prove that the economic
processes with the continuous time long and short memory, which is
characterized by the power law, should be described by the fractional
differential equations.
</summary>
    <author>
      <name>Vasily E. Tarasov</name>
    </author>
    <author>
      <name>Valentina V. Tarasova</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.21013/jmss.v5.n2.p10</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.21013/jmss.v5.n2.p10" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, PDF</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IRA-International Journal of Management and Social Sciences. 2016.
  Vol.5. No.2. P.327-334</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1612.07903v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.07903v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.MF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B02, 26A33" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.07913v2</id>
    <updated>2017-07-22T07:09:13Z</updated>
    <published>2016-12-23T09:36:38Z</published>
    <title>Economic Accelerator with Memory: Discrete Time Approach</title>
    <summary>  Accelerators with power-law memory are proposed in the framework of the
discrete time approach. To describe discrete accelerators we use the capital
stock adjustment principle, which has been suggested by Matthews.The suggested
discrete accelerators with memory describe the economic processes with the
power-law memory and the periodic sharp splashes (kicks). In continuous time
approach the memory is described by fractional-order differential equations. In
discrete time approach the accelerators with memory are described by discrete
maps with memory, which are derived from the fractional-order differential
equation without approximations. In order to derive these maps we use the
equivalence of fractional-order differential equations and the Volterra
integral equations.
</summary>
    <author>
      <name>Valentina V. Tarasova</name>
    </author>
    <author>
      <name>Vasily E. Tarasov</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.20861/2304-2338-2016-78-002</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.20861/2304-2338-2016-78-002" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, PDF</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Problems of Modern Science and Education. 2016. No.36(78). P.37-42</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1612.07913v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.07913v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.MF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="26A33, 34A08, 39A70, 93C55, 37N40" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.08111v1</id>
    <updated>2016-12-23T23:03:12Z</updated>
    <published>2016-12-23T23:03:12Z</published>
    <title>The prevalence of chaotic dynamics in games with many players</title>
    <summary>  We study adaptive learning in a typical p-player game. The payoffs of the
games are randomly generated and then held fixed. The strategies of the players
evolve through time as the players learn. The trajectories in the strategy
space display a range of qualitatively different behaviors, with attractors
that include unique fixed points, multiple fixed points, limit cycles and
chaos. In the limit where the game is complicated, in the sense that the
players can take many possible actions, we use a generating-functional approach
to establish the parameter range in which learning dynamics converge to a
stable fixed point. The size of this region goes to zero as the number of
players goes to infinity, suggesting that complex non-equilibrium behavior,
exemplified by chaos, may be the norm for complicated games with many players.
</summary>
    <author>
      <name>James B. T. Sanders</name>
    </author>
    <author>
      <name>J. Doyne Farmer</name>
    </author>
    <author>
      <name>Tobias Galla</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages, 11 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1612.08111v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.08111v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.CD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.08583v1</id>
    <updated>2016-12-27T11:43:41Z</updated>
    <published>2016-12-27T11:43:41Z</published>
    <title>A Proposal to Extend Expected Utility in a Quantum Probabilistic
  Framework</title>
    <summary>  Expected utility theory (EUT) is widely used in economic theory. However, its
subjective probability formulation, first elaborated by Savage, is linked to
Ellsberg-like paradoxes and ambiguity aversion. This has led various scholars
to work out non-Bayesian extensions of EUT which cope with its paradoxes and
incorporate attitudes toward ambiguity. A variant of the Ellsberg paradox,
recently proposed by Mark Machina and confirmed experimentally, challenges
existing non-Bayesian models of decision-making under uncertainty. Relying on a
decade of research which has successfully applied the formalism of quantum
theory to model cognitive entities and fallacies of human reasoning, we put
forward a non-Bayesian extension of EUT in which subjective probabilities are
represented by quantum probabilities, while the preference relation between
acts depends on the state of the situation that is the object of the decision.
We show that the benefits of using the quantum theoretical framework enables
the modeling of the Ellsberg and Machina paradoxes, as the representation of
ambiguity and behavioral attitudes toward it. The theoretical framework
presented here is a first step toward the development of a `state-dependent
non-Bayesian extension of EUT' and it has potential applications in economic
modeling.
</summary>
    <author>
      <name>Diederik Aerts</name>
    </author>
    <author>
      <name>Emmanuel Haven</name>
    </author>
    <author>
      <name>Sandro Sozzo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">25 pages, standard latex. arXiv admin note: text overlap with
  arXiv:1510.09058</arxiv:comment>
    <link href="http://arxiv.org/abs/1612.08583v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.08583v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.09060v2</id>
    <updated>2017-01-09T19:59:30Z</updated>
    <published>2016-12-29T07:48:04Z</published>
    <title>Fractional Dynamics of Natural Growth and Memory Effect in Economics</title>
    <summary>  A generalization of the economic model of natural growth, which takes into
account the power-law memory effect, is suggested. The memory effect means the
dependence of the process not only on the current state of the process, but
also on the history of changes of this process in the past. For the
mathematical description of the economic process with power-law memory we used
the theory of derivatives of non-integer order and fractional-order
differential equation. We propose equations take into account the effects of
memory with one-parameter power-law damping. Solutions of these fractional
differential equations are suggested. We proved that the growth and downturn of
output depend on the memory effects. We demonstrate that the memory effect can
lead to decrease of output instead of its growth, which is described by model
without memory effect. Memory effect can lead to increase of output, rather
than decrease, which is described by model without memory effect.
</summary>
    <author>
      <name>Valentina V. Tarasova</name>
    </author>
    <author>
      <name>Vasily E. Tarasov</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.20861/2410-2873-2016-23-004</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.20861/2410-2873-2016-23-004" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, PDF</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">European Research. 2016. No. 12 (23). P. 30-37</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1612.09060v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.09060v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="26A33, 34A08, 91B55" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.09549v1</id>
    <updated>2016-12-30T18:22:25Z</updated>
    <published>2016-12-30T18:22:25Z</published>
    <title>The Industry Supply Function and the Long-Run Competitive Equilibrium
  with Heterogeneous Firms</title>
    <summary>  The theory of long-run competitive equilibrium (LRCE), first developed by
Marshall in the 1890s, has had a profound influence on our understanding of
competitive markets. While Marshall referred to the notion of a representative
firm, the identity of this firm is generally unclear, as the theory has focused
on the case where all firms in the industry are identical. Using Hopenhayn's
(1992) model of competitive industry dynamics, we extend the theory of LRCE to
the case of heterogeneous firms. We show that, under certain conditions, the
(long-run) industry supply function with heterogeneous firms exists and can
indeed be characterized as the solution to the minimization problem of a
"representative" average cost function, as originally envisioned by Marshall.
As an application of the importance of accounting for heterogeneity, we show
that maximal surplus is not maximized in an LRCE and that the only way to
approximate the maximal surplus with a linear tax is to tax all profits and
subsidize all losses.
</summary>
    <author>
      <name>Ignacio Esponda</name>
    </author>
    <author>
      <name>Demian Pouzo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">53 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1612.09549v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.09549v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.02216v5</id>
    <updated>2017-09-25T06:22:53Z</updated>
    <published>2017-01-09T15:36:52Z</published>
    <title>Structural Propagation in a Production Network with State-Replicating
  Elasticities</title>
    <summary>  We model an economy-wide production network by cascading binary compounding
functions, based on the sequential processing nature of the production
activities. As we observe a hierarchy among the intermediate processes spanning
the empirical input--output transactions, we utilize a stylized sequence of
processes for modeling the intra-sectoral production activities. Under the
productivity growth that we calibrate jointly with the elasticity parameters
for each sectoral activity, the network of production replicates the records of
multi-sectoral general equilibrium prices and shares for all factor inputs
observed in two temporally distant states. We further portray how the
propagation of a given productivity shock transpires in the technological
structure, in order to evaluate its potential welfare gain.
</summary>
    <author>
      <name>Satoshi Nakano</name>
    </author>
    <author>
      <name>Kazuhiko Nishimura</name>
    </author>
    <link href="http://arxiv.org/abs/1701.02216v5" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.02216v5" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.02646v1</id>
    <updated>2016-09-16T21:14:59Z</updated>
    <published>2016-09-16T21:14:59Z</published>
    <title>Economic information from Smart Meter: Nexus Between Demand Profile and
  Electricity Retail Price Between Demand Profile and Electricity Retail Price</title>
    <summary>  In this paper, we demonstrate that a consumer's marginal system impact is
only determined by their demand profile rather than their demand level. Demand
profile clustering is identical to cluster consumers according to their
marginal impacts on system costs. A profile-based uniform-rate price is
economically efficient as real-time pricing. We develop a criteria system to
evaluate the economic efficiency of an implemented retail price scheme in a
distribution system by comparing profile clustering and daily-average
clustering. Our criteria system can examine the extent of a retail price
scheme's inefficiency even without information about the distribution system's
daily cost structure. We analyze data from a real distribution system in China.
In this system, targeting each consumer's high-impact days is more efficient
than target high-impact consumers.
</summary>
    <author>
      <name>Yang Yu</name>
    </author>
    <author>
      <name>Guangyi Liu</name>
    </author>
    <author>
      <name>Wendong Zhu</name>
    </author>
    <author>
      <name>Fei Wang</name>
    </author>
    <author>
      <name>Bin Shu</name>
    </author>
    <author>
      <name>Kai Zhang</name>
    </author>
    <author>
      <name>Ram Rajagopal</name>
    </author>
    <author>
      <name>Nicolas Astier</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 5 figures, submitting to IEEE Trans on Smart Grid</arxiv:comment>
    <link href="http://arxiv.org/abs/1701.02646v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.02646v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.02649v1</id>
    <updated>2016-12-26T21:33:46Z</updated>
    <published>2016-12-26T21:33:46Z</published>
    <title>Sur la décomposabilité empirique des indicateurs de pauvreté</title>
    <summary>  We study the empirical decomposition of poverty indicators. This property is
very important and convenient in the context of the fight against poverty.
Indeed, it makes it possible to put in place sectoral poverty reduction
policies on the basis of a relevant stratification laid down at the outset. The
simultaneous impacts of these policies, measured as reduction gains over the
population as a whole, is then obtained by aggregating those obtained at each
stratum by a relatively simple formula. It turns out that indicators as
important as those of Sen and Shorrocks do not verify this property contrary to
the elements of the class of Foster - Greer and Thorbecke. Given the data from
the 1996 Senegalese Survey of Households (ESAM), we show that the lack of
decomposability of these indicators on the income variable for several types of
population stratification is practically zero , of the order of one to two per
thousand. This makes it possible to use the decomposition of the Sen and
Shorrocks indicators without any untoward consequences. An explanatory model of
these results is presented for future research.
</summary>
    <author>
      <name>Gane Samb Lo</name>
    </author>
    <author>
      <name>Cheikh Mohamed Haidara</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, in French</arxiv:comment>
    <link href="http://arxiv.org/abs/1701.02649v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.02649v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B15, 91B02, 91B82" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.04431v1</id>
    <updated>2017-01-16T19:36:10Z</updated>
    <published>2017-01-16T19:36:10Z</published>
    <title>Interpolating between matching and hedonic pricing models</title>
    <summary>  We consider the theoretical properties of a model which encompasses
bi-partite matching under transferable utility on the one hand, and hedonic
pricing on the other. This framework is intimately connected to tripartite
matching problems (known as multi-marginal optimal transport problems in the
mathematical literature). We exploit this relationship in two ways; first, we
show that a known structural result from multi-marginal optimal transport can
be used to establish an upper bound on the dimension of the support of stable
matchings. Next, assuming the distribution of agents on one side of the market
is continuous, we identify a condition on their preferences that ensures purity
and uniqueness of the stable matching; this condition is a variant of a known
condition in the mathematical literature, which guarantees analogous properties
in the multi-marginal optimal transport problem. We exhibit several examples of
surplus functions for which our condition is satisfied, as well as some for
which it fails.
</summary>
    <author>
      <name>Brendan Pass</name>
    </author>
    <link href="http://arxiv.org/abs/1701.04431v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.04431v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.05864v1</id>
    <updated>2017-01-20T17:21:33Z</updated>
    <published>2017-01-20T17:21:33Z</published>
    <title>Bank monitoring incentives under moral hazard and adverse selection</title>
    <summary>  In this paper, we extend the optimal securitization model of Pag\`es [41] and
Possama\"i and Pag\`es [42] between an investor and a bank to a setting
allowing both moral hazard and adverse selection. Following the recent approach
to these problems of Cvitani\'c, Wan and Yang [12], we characterize explicitly
and rigorously the so-called credible set of the continuation and temptation
values of the bank, and obtain the value function of the investor as well as
the optimal contracts through a recursive system of first-order variational
inequalities with gradient constraints. We provide a detailed discussion of the
properties of the optimal menu of contracts.
</summary>
    <author>
      <name>Nicolás Hernández Santibáñez</name>
    </author>
    <author>
      <name>Dylan Possamaï</name>
    </author>
    <author>
      <name>Chao Zhou</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">60 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1701.05864v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.05864v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.06299v1</id>
    <updated>2017-01-23T08:53:46Z</updated>
    <published>2017-01-23T08:53:46Z</published>
    <title>Economic Growth Model with Constant Pace and Dynamic Memory</title>
    <summary>  The article discusses a generalization of model of economic growth with
constant pace, which takes into account the effects of dynamic memory. Memory
means that endogenous or exogenous variable at a given time depends not only on
their value at that time, but also on their values at previous times. To
describe the dynamic memory we use derivatives of non-integer orders. We obtain
the solutions of fractional differential equations with derivatives of
non-integral order, which describe the dynamics of the output caused by the
changes of the net investments and effects of power-law fading memory.
</summary>
    <author>
      <name>Valentina V. Tarasova</name>
    </author>
    <author>
      <name>Vasily E. Tarasov</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.20861/2304-2338-2017-84-001</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.20861/2304-2338-2017-84-001" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, PDF</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Problems of Modern Science and Education. 2017. No.2(84). P.40-45</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1701.06299v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.06299v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B02, 34A08, 26A33," scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.06625v1</id>
    <updated>2017-01-20T12:36:57Z</updated>
    <published>2017-01-20T12:36:57Z</published>
    <title>Econophysics Macroeconomic Model</title>
    <summary>  This paper presents macroeconomic model that is based on parallels between
macroeconomic multi-agent systems and multi-particle systems. We use risk
ratings of economic agents as their coordinates on economic space. Aggregates
of economic or financial variables like Investment, Assets, Demand, Credits and
etc. of economic agents near point x define corresponding macroeconomic
variables as functions of time t and coordinates x on economic space. Parallels
between multi-agent and multi-particle systems on economic space allow describe
transition from economic kinetic-like to economic hydrodynamic-like
approximation and derive macroeconomic hydrodynamic-like equations on economic
space. Economic or financial transactions between economic agents determine
evolution of macroeconomic variables This paper describes local macroeconomic
approximation that takes into account transactions between economic agents with
coordinates near same point x on economic space only and describes interaction
between macroeconomic variables by linear differential operators. For simple
model of interaction between macroeconomic variables as Demand on Investment
and Interest Rate we derive hydrodynamic-like equations in a closed form. For
perturbations of these macroeconomic variables we derive macroeconomic wave
equations. Macroeconomic waves on economic space can propagate with exponential
growth of amplitude and cause irregular time fluctuations of macroeconomic
variables or induce economic crises.
</summary>
    <author>
      <name>Victor Olkhov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">22 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1701.06625v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.06625v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1702.00144v1</id>
    <updated>2017-02-01T06:22:09Z</updated>
    <published>2017-02-01T06:22:09Z</published>
    <title>Zipf's law for share price and company fundamentals</title>
    <summary>  We statistically investigate the distribution of share price and the
distributions of three common financial indicators using data from
approximately 8,000 companies publicly listed worldwide for the period
2004-2013. We find that the distribution of share price follows Zipf's law;
that is, it can be approximated by a power law distribution with exponent equal
to 1. An examination of the distributions of dividends per share, cash flow per
share, and book value per share - three financial indicators that can be
assumed to influence corporate value (i.e. share price) - shows that these
distributions can also be approximated by a power law distribution with
power-law exponent equal to 1. We estimate a panel regression model in which
share price is the dependent variable and the three financial indicators are
explanatory variables. The two-way fixed effects model that was selected as the
best model has quite high power for explaining the actual data. From these
results, we can surmise that the reason why share price follows Zipf's law is
that corporate value, i.e. company fundamentals, follows Zipf's law.
</summary>
    <author>
      <name>Taisei Kaizoji</name>
    </author>
    <author>
      <name>Michiko Miyano</name>
    </author>
    <link href="http://arxiv.org/abs/1702.00144v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1702.00144v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1702.01686v1</id>
    <updated>2017-02-03T11:10:49Z</updated>
    <published>2017-02-03T11:10:49Z</published>
    <title>Demonetization and Its Impact on Employment in India</title>
    <summary>  On November 08, the sudden announcement to demonetization the high
denomination currency notes sent tremors all across the country. Given the
timing, and socioeconomic and political repercussions of the decision, many
termed it a financial emergency. Given high proportion of these notes in
circulation, over 86 percent, it led to most economic activities, particularly
employment, affected in a big way. Political parties, however, seemed divided
on the issue, i.e. those in favor of the decision feel it will help to curb the
galloping size of black money, fake currency, cross boarder terrorism, etc. In
sharp contrast, the others believe it is a purely misleading, decision, based
on no or poor understanding of black economy, and hence is only politically
motivated in wake of the assembly elections due in a couple of states.
</summary>
    <author>
      <name>Pawan Kumar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5</arxiv:comment>
    <link href="http://arxiv.org/abs/1702.01686v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1702.01686v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1702.01819v2</id>
    <updated>2017-08-31T20:20:21Z</updated>
    <published>2017-02-06T23:05:56Z</published>
    <title>Learning and Type Compatibility in Signalling Games</title>
    <summary>  Equilibrium outcomes in signalling games can be very sensitive to the
specification of how receivers interpret and thus respond to deviations from
the path of play. We develop a micro-foundation for these off-path beliefs, and
an associated equilibrium refinement, in a model where equilibrium arises
through non-equilibrium learning by populations of patient and long-lived
senders and receivers. In our model, young senders are uncertain about the
prevailing distribution of play, so they rationally send out-of-equilibrium
signals as experiments to learn about receivers' behavior. Differences in the
payoff functions of the types of senders generate different incentives for
these experiments. Using the Gittins index (Gittins, 1979), we characterize
which sender types use each signal more often, leading to a constraint on the
receiver's off-path beliefs based on "type-compatibility" and hence a
learning-based equilibrium selection.
</summary>
    <author>
      <name>Drew Fudenberg</name>
    </author>
    <author>
      <name>Kevin He</name>
    </author>
    <link href="http://arxiv.org/abs/1702.01819v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1702.01819v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1702.02254v1</id>
    <updated>2017-02-08T02:31:45Z</updated>
    <published>2017-02-08T02:31:45Z</published>
    <title>One-Switch Discount Functions</title>
    <summary>  Bell (1988) introduced the one-switch property for preferences over sequences
of dated outcomes. This property concerns the effect of adding a common delay
to two such sequences: it says that the preference ranking of the delayed
sequences is either independent of the delay, or else there is a unique delay
such that one strict ranking prevails for shorter delays and the opposite
strict ranking for longer delays. For preferences that have a discounted
utility (DU) representation, Bell (1988) argues that the only discount
functions consistent with the one-switch property are sums of exponentials.
This paper proves that discount functions of the linear times exponential form
also satisfy the one-switch property. We further demonstrate that preferences
which have a DU representation with a linear times exponential discount
function exhibit increasing impatience (Takeuchi (2011)). We also clarify an
ambiguity in the original Bell (1988) definition of the one-switch property by
distinguishing a weak one-switch property from the (strong) one-switch
property. We show that the one-switch property and the weak one-switch property
definitions are equivalent in a continuous-time version of the Anscombe and
Aumann (1963) setting.
</summary>
    <author>
      <name>Nina Anchugina</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">37 pages, 11 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1702.02254v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1702.02254v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1702.08391v1</id>
    <updated>2017-02-23T16:05:02Z</updated>
    <published>2017-02-23T16:05:02Z</published>
    <title>Economic inequality and mobility for stochastic models with
  multiplicative noise</title>
    <summary>  In this article, we discuss a dynamical stochastic model that represents the
time evolution of income distribution of a population, where the dynamics
develop from an interplay of multiple economic exchanges in the presence of
multiplicative noise. The model remit stretches beyond the conventional
framework of a Langevin-type kinetic equation in that our model dynamics is
self-consistently constrained by dynamical conservation laws emerging from
population and wealth conservation. This model is numerically solved and
analyzed to interpret the inequality of income as a function of relevant
dynamical parameters like the {\it mobility} $M$ and the {\it total income}
$\mu$. In our model, inequality is quantified by the {\it Gini index} $G$. In
particular, correlations between any two of the mobility index $M$ and/or the
total income $\mu$ with the Gini index $G$ are investigated and compared with
the analogous correlations resulting from an equivalent additive noise model.
Our findings highlight the importance of a multiplicative noise based economic
modeling structure in the analysis of inequality. The model also depicts the
nature of correlation between mobility and total income of a population from
the perspective of inequality measure.
</summary>
    <author>
      <name>Maria Letizia Bertotti</name>
    </author>
    <author>
      <name>Amit K Chattopadhyay</name>
    </author>
    <author>
      <name>Giovanni Modanese</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1702.08391v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1702.08391v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.01292v1</id>
    <updated>2017-03-05T02:22:08Z</updated>
    <published>2017-03-05T02:22:08Z</published>
    <title>Quantifying China's Regional Economic Complexity</title>
    <summary>  China has experienced an outstanding economic expansion during the past
decades, however, literature on non-monetary metrics that reveal the status of
China's regional economic development are still lacking. In this paper, we fill
this gap by quantifying the economic complexity of China's provinces through
analyzing 25 years' firm data. First, we estimate the regional Economic
Complexity Index (ECI), and show that the overall time evolution of provinces'
ECI is relatively stable and slow. Then, after linking ECI to the economic
development and the income inequality, we find that the predictive power of ECI
is positive for the former but negative for the latter. Next, we compare
different measures of economic diversity and explore their relationships with
monetary macroeconomic indicators. Results show that ECI and Fitness are
comparative and they have better predictive power than other benchmark measures
like entropy. Further multivariate regressions suggest the robustness of our
results after controlling other socioeconomic factors. Our work moves forward a
step towards better understanding China's regional economic development and
non-monetary macroeconomic indicators.
</summary>
    <author>
      <name>Jian Gao</name>
    </author>
    <author>
      <name>Tao Zhou</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 6 figures, 1 table</arxiv:comment>
    <link href="http://arxiv.org/abs/1703.01292v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.01292v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.05979v2</id>
    <updated>2017-09-15T13:53:13Z</updated>
    <published>2017-03-17T11:59:36Z</published>
    <title>How well do experience curves predict technological progress? A method
  for making distributional forecasts</title>
    <summary>  Experience curves are widely used to predict the cost benefits of increasing
the deployment of a technology. But how good are such forecasts? Can one
predict their accuracy a priori? In this paper we answer these questions by
developing a method to make distributional forecasts for experience curves. We
test our method using a dataset with proxies for cost and experience for 51
products and technologies and show that it works reasonably well. The framework
that we develop helps clarify why the experience curve method often gives
similar results to simply assuming that costs decrease exponentially. To
illustrate our method we make a distributional forecast for prices of solar
photovoltaic modules.
</summary>
    <author>
      <name>François Lafond</name>
    </author>
    <author>
      <name>Aimee Gotway Bailey</name>
    </author>
    <author>
      <name>Jan David Bakker</name>
    </author>
    <author>
      <name>Dylan Rebois</name>
    </author>
    <author>
      <name>Rubina Zadourian</name>
    </author>
    <author>
      <name>Patrick McSharry</name>
    </author>
    <author>
      <name>J. Doyne Farmer</name>
    </author>
    <link href="http://arxiv.org/abs/1703.05979v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.05979v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.08807v1</id>
    <updated>2017-03-26T11:23:42Z</updated>
    <published>2017-03-26T11:23:42Z</published>
    <title>Ex-post core, fine core and rational expectations equilibrium
  allocations</title>
    <summary>  This paper investigates the ex-post core and its relationships to the fine
core and the set of rational expectations equilibrium allocations in an
oligopolistic economy with asymmetric information, in which the set of agents
consists of some large agents and a continuum of small agents and the space of
states of nature is a general probability space. We show that under appropriate
assumptions, the ex-post core is not empty and contains the set of rational
expectations equilibrium allocations. We provide an example of a pure exchange
continuum economy with asymmetric information and infinitely many states of
nature, in which the ex-post core does not coincide with the set of rational
expectations equilibrium allocations. We also show that when our economic model
contains either no large agents or at least two large agents with the same
characteristics, the fine core is contained in the ex-post core.
</summary>
    <author>
      <name>Anuj Bhowmik</name>
    </author>
    <author>
      <name>Jiling Cao</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">23 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1703.08807v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.08807v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B50, 28B20" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.10639v2</id>
    <updated>2017-04-06T07:30:13Z</updated>
    <published>2017-03-30T18:57:56Z</published>
    <title>Agent-Based Model Calibration using Machine Learning Surrogates</title>
    <summary>  Taking agent-based models (ABM) closer to the data is an open challenge. This
paper explicitly tackles parameter space exploration and calibration of ABMs
combining supervised machine-learning and intelligent sampling to build a
surrogate meta-model. The proposed approach provides a fast and accurate
approximation of model behaviour, dramatically reducing computation time. In
that, our machine-learning surrogate facilitates large scale explorations of
the parameter-space, while providing a powerful filter to gain insights into
the complex functioning of agent-based models. The algorithm introduced in this
paper merges model simulation and output analysis into a surrogate meta-model,
which substantially ease ABM calibration. We successfully apply our approach to
the Brock and Hommes (1998) asset pricing model and to the "Island" endogenous
growth model (Fagiolo and Dosi, 2003). Performance is evaluated against a
relatively large out-of-sample set of parameter combinations, while employing
different user-defined statistical tests for output analysis. The results
demonstrate the capacity of machine learning surrogates to facilitate fast and
precise exploration of agent-based models' behaviour over their often rugged
parameter spaces.
</summary>
    <author>
      <name>Francesco Lamperti</name>
    </author>
    <author>
      <name>Andrea Roventini</name>
    </author>
    <author>
      <name>Amir Sani</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">32 pages, 19 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1703.10639v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.10639v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1704.03597v2</id>
    <updated>2017-08-03T16:28:40Z</updated>
    <published>2017-04-12T02:07:28Z</published>
    <title>Exploring the relationship between technological improvement and
  innovation diffusion: An empirical test</title>
    <summary>  It is now clear that different technological domains have significantly
different rates of performance improvement. Prior theory indicates that such
differing rates should influence the relative speed of diffusion of the
products since improvement in performance during the diffusion process
increases the desirability of the product diffusing. However, there has not
been a broad empirical attempt to examine this effect and to clarify the
underlying cause. Therefore, this paper reviews the theoretical basis and
focuses upon empirical tests of this effect across multiple products and their
underlying technologies. The results for 18 different diffusing products show
the expected relationship-faster diffusion for products based on more rapidly
improving technological domains- between technological improvement and
diffusion with strong statistical significance. The empirical examination also
demonstrates that technological improvement does not slow down in the latter
parts of diffusion when penetration does slow down. This finding is not
consistent with ideas that explain technological performance increases as due
to competition among firms.
</summary>
    <author>
      <name>JongRoul Woo</name>
    </author>
    <author>
      <name>Christopher L. Magee</name>
    </author>
    <link href="http://arxiv.org/abs/1704.03597v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1704.03597v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.05943v2</id>
    <updated>2017-06-26T17:51:47Z</updated>
    <published>2017-05-16T22:19:33Z</published>
    <title>Banks as Tanks: A Continuous-Time Model of Financial Clearing</title>
    <summary>  We present a simple model of clearing in financial networks in continuous
time. In the model, firms (banks) are represented as reservoirs (tanks) with
liquid (money) flowing in and out. This approach provides a simple recursive
solution to a classical static model of financial clearing introduced by
Eisenberg and Noe (2001). The dynamic structure of our model helps to answer
other related questions and, potentially, opens the way to handle more
complicated dynamic financial networks. Also, our approach provides a useful
tool for solving nonlinear equations involving linear system and max min
operations similar to the Bellman equation for the optimal stopping of Markov
chains and other optimization problems.
</summary>
    <author>
      <name>Isaac M. Sonin</name>
    </author>
    <author>
      <name>Konstantin Sonin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1705.05943v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.05943v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="90B10, 90B50 (Primary), 60J20 (Secondary), JEL: G21, G33" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.08536v1</id>
    <updated>2017-04-15T19:53:13Z</updated>
    <published>2017-04-15T19:53:13Z</published>
    <title>A Quantum-like Model of Selection Behavior</title>
    <summary>  In this paper, we introduce a new model of selection behavior under risk that
describes an essential cognitive process for comparing values of objects and
making a selection decision. This model is constructed by the quantum-like
approach that employs the state representation specific to quantum theory,
which has the mathematical framework beyond the classical probability theory.
We show that our quantum approach can clearly explain the famous examples of
anomalies for the expected utility theory, the Ellsberg paradox, the Machina
paradox and the disparity between WTA and WTP. Further, we point out that our
model mathematically specifies the characteristics of the probability weighting
function and the value function, which are basic concepts in the prospect
theory.
</summary>
    <author>
      <name>Masanari Asano</name>
    </author>
    <author>
      <name>Irina Basieva</name>
    </author>
    <author>
      <name>Andrei Khrennikov</name>
    </author>
    <author>
      <name>Masanori Ohya</name>
    </author>
    <author>
      <name>Yoshiharu Tanaka</name>
    </author>
    <link href="http://arxiv.org/abs/1705.08536v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.08536v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.QA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.01437v1</id>
    <updated>2017-06-05T17:42:05Z</updated>
    <published>2017-06-05T17:42:05Z</published>
    <title>Exploring the determinants of Bitcoin's price: an application of
  Bayesian Structural Time Series</title>
    <summary>  Currently, there is no consensus on the real properties of Bitcoin. The
discussion comprises its use as a speculative or safe haven assets, while other
authors argue that the augmented attractiveness could end accomplishing money's
functions that economic theory demands. This paper explores the association
between Bitcoin's market price and a set of internal and external factors using
Bayesian Structural Time Series Approach. I aim to contribute to the discussion
by differentiating among several attractiveness sources and employing a method
that provides a more flexible analytic framework that decompose each of the
components of the time series, apply variable selection, include information on
previous studies, and dynamically examine the behavior of the explanatory
variables, all in a transparent and tractable setting. The results show that
the Bitcoin price is negatively associated with a neutral investor's sentiment,
gold's price and Yuan to USD exchange rate, while positively related to stock
market index, USD to Euro exchange rate and variated signs among the different
countries' search trends. Hence, I find that Bitcoin has mixed properties since
still seems to act as a speculative, safe haven and a potential a capital
flights instrument.
</summary>
    <author>
      <name>Obryan Poyser</name>
    </author>
    <link href="http://arxiv.org/abs/1706.01437v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.01437v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.02168v1</id>
    <updated>2017-06-06T08:48:14Z</updated>
    <published>2017-06-06T08:48:14Z</published>
    <title>Testing Ambiguity and Machina Preferences Within a Quantum-theoretic
  Framework for Decision-making</title>
    <summary>  The Machina thought experiments pose to major non-expected utility models
challenges that are similar to those posed by the Ellsberg thought experiments
to subjective expected utility theory (SEUT). We test human choices in the
`Ellsberg three-color example', confirming typical ambiguity aversion patterns,
and the `Machina 50/51 and reflection examples', partially confirming the
preferences hypothesized by Machina. Then, we show that a quantum-theoretic
framework for decision-making under uncertainty recently elaborated by some of
us allows faithful modeling of all data on the Ellsberg and Machina paradox
situations. In the quantum-theoretic framework subjective probabilities are
represented by quantum probabilities, while quantum state transformations
enable representations of ambiguity aversion and subjective attitudes toward
it.
</summary>
    <author>
      <name>Diederik Aerts</name>
    </author>
    <author>
      <name>Suzette Geriente</name>
    </author>
    <author>
      <name>Catarina Moreira</name>
    </author>
    <author>
      <name>Sandro Sozzo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages, 1 figure, standard LaTex. arXiv admin note: substantial
  text overlap with arXiv:1612.08583, arXiv:1510.09058</arxiv:comment>
    <link href="http://arxiv.org/abs/1706.02168v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.02168v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.MF" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.03502v1</id>
    <updated>2017-06-12T08:15:05Z</updated>
    <published>2017-06-12T08:15:05Z</published>
    <title>Economics of limiting cumulative CO2 emissions</title>
    <summary>  Global warming from carbon dioxide (CO2) is known to depend on cumulative CO2
emissions. We introduce a model of global expenditures on limiting cumulative
CO2 emissions, taking into account effects of decarbonization and rising global
income and making an approximation to the marginal abatement costs (MAC) of
CO2. Discounted mitigation expenditures are shown to be a convex function of
cumulative CO2 emissions. We also consider minimum-expenditure solutions for
meeting cumulative emissions goals, using a regularized variational method
yielding an initial value problem in the integrated decarbonization rate. A
quasi-stationary solution to this problem can be obtained for a special case,
yielding decarbonization rate that is proportional to annual CO2 emissions.
Minimum-expenditure trajectories in scenarios where CO2 emissions decrease must
begin with rapid decarbonization at rate decreasing with time. Due to the shape
of global MAC the fraction of global income spent on CO2 mitigation ("burden")
generally increases with time, as cheaper avenues for mitigation are exhausted.
Therefore failure to rapidly decarbonize early on reduces expenditures by a
small fraction (on the order of 0.01 %) of income in the present, but leads to
much higher burden to future generations (on the order of 1 % of income).
</summary>
    <author>
      <name>Ashwin K Seshadri</name>
    </author>
    <link href="http://arxiv.org/abs/1706.03502v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.03502v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.07216v1</id>
    <updated>2017-06-22T09:15:16Z</updated>
    <published>2017-06-22T09:15:16Z</published>
    <title>Virtual Relationships: Short- and Long-run Evidence from BitCoin and
  Altcoin Markets</title>
    <summary>  This study empirically examines interdependencies between BitCoin and altcoin
markets in the short- and long-run. We apply time-series analytical mechanisms
to daily data of 17 virtual currencies (BitCoin + 16 alternative virtual
currencies) and two Altcoin price indices for the period 2013-2016. Our
empirical findings confirm that indeed BitCoin and Altcoin markets are
interdependent. The BitCoin-Altcoin price relationship is significantly
stronger in the short-run than in the long-run. We cannot fully confirm the
hypothesis that the BitCoin price relationship is stronger with those Altcoins
that are more similar in their price formation mechanism to BitCoin. In the
long-run, macro-financial indicators determine the altcoin price formation to a
greater degree than BitCoin does. The virtual currency supply is exogenous and
therefore plays only a limited role in the price formation.
</summary>
    <author>
      <name>Pavel Ciaian</name>
    </author>
    <author>
      <name>Miroslava Rajcaniova</name>
    </author>
    <author>
      <name>d'Artis Kancs</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">36 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1706.07216v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.07216v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.09756v1</id>
    <updated>2017-05-03T20:53:13Z</updated>
    <published>2017-05-03T20:53:13Z</published>
    <title>Parameter estimation for stable distributions with application to
  commodity futures log returns</title>
    <summary>  This paper explores the theory behind the rich and robust family of
{\alpha}-stable distributions to estimate parameters from financial asset
log-returns data. We discuss four-parameter estimation methods including the
quantiles, logarithmic moments method, maximum likelihood (ML), and the
empirical characteristics function (ECF) method. The contribution of the paper
is two-fold: first, we discuss the above parametric approaches and investigate
their performance through error analysis. Moreover, we argue that the ECF
performs better than the ML over a wide range of shape parameter values,
{\alpha}{\alpha} including values closest to 0 and 2 and that the ECF has a
better convergence rate than the ML. Secondly, we compare the t location-scale
distribution to the general stable distribution and show that the former fails
to capture skewness which might exist in the data. This is observed through
applying the ECF to commodity futures log-returns data to obtain the skewness
parameter.
</summary>
    <author>
      <name>Michael Kateregga</name>
    </author>
    <author>
      <name>Sure Mataramvura</name>
    </author>
    <author>
      <name>David Taylor</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1080/23322039.2017.1318813</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1080/23322039.2017.1318813" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">23 pages, 11 Figures and 3 Tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1706.09756v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.09756v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62G07, 62G05" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.02188v1</id>
    <updated>2017-07-07T14:15:22Z</updated>
    <published>2017-07-07T14:15:22Z</published>
    <title>Coherent diversification in corporate technological portfolios</title>
    <summary>  We study the relationship between firms' performance and their technological
portfolios using tools borrowed from the complexity science. In particular, we
ask whether the accumulation of knowledge and capabilities related to a
coherent set of technologies leads firms to experience advantages in terms of
productive efficiency. To this end, we analyzed both the balance sheets and the
patenting activity of about 70 thousand firms that have filed at least one
patent over the period 2004-2013. From this database it is possible to define a
measure of the firms' coherent diversification, based on the network of
technological fields, and relate it to the firms' perfomance in terms of labor
productivity. Such a measure favors companies with a diversification structure
comprising blocks of closely related fields over firms with the same breadth of
scope, but a more scattered diversification structure. We find that the
coherent diversification of firms is quantitatively related to their economic
performance and captures relevant information about their productive structure.
In particular, we prove on a statistical basis that a naive definition of
technological diversification can explain labor productivity only as a proxy of
size and coherent diversification. This approach can be used to investigate
possible synergies within firms and to recommend viable partners for merging
and acquisitions.
</summary>
    <author>
      <name>Emanuele Pugliese</name>
    </author>
    <author>
      <name>Lorenzo Napolitano</name>
    </author>
    <author>
      <name>Andrea Zaccaria</name>
    </author>
    <author>
      <name>Luciano Pietronero</name>
    </author>
    <link href="http://arxiv.org/abs/1707.02188v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.02188v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.04285v2</id>
    <updated>2017-09-26T01:10:25Z</updated>
    <published>2017-07-13T19:24:19Z</published>
    <title>The Universality of Zipf's Law for Time-Dependent Rank-Based Random
  Systems</title>
    <summary>  We provide necessary and sufficient conditions for rank-based systems of
continuous semimartingales to generate an asymptotic size distribution that
satisfies Zipf's law. For a system that follows the strong form of Gibrat's
law, with growth rates and volatilities that do not vary across rank, these
conditions require that the system be conservative and complete, and are
satisfied by many large systems of time-dependent ranked observations. We
generalize Zipf's law to a less restrictive form in which a log-log plot of
size versus rank does not have to be a straight line of slope -1, but rather is
concave with a tangent line of slope -1 at some point. Under certain regularity
conditions, we show that the same conditions of conservation and completeness
imply that rank-based systems that deviate from Gibrat's law in a specific but
realistic manner generate an asymptotic size distribution that is
quasi-Zipfian. Because many real-world systems that follow the strong form of
Gibrat's law satisfy Zipf's law, and even more systems that do not follow the
strong form of Gibrat's law are quasi-Zipfian, our results explain the
universality of Zipf's law for time-dependent rank-based systems.
</summary>
    <author>
      <name>Ricardo T. Fernholz</name>
    </author>
    <author>
      <name>Robert Fernholz</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">24 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1707.04285v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.04285v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.05108v1</id>
    <updated>2017-07-17T11:37:54Z</updated>
    <published>2017-07-17T11:37:54Z</published>
    <title>Dynamic Semiparametric Models for Expected Shortfall (and Value-at-Risk)</title>
    <summary>  Expected Shortfall (ES) is the average return on a risky asset conditional on
the return being below some quantile of its distribution, namely its
Value-at-Risk (VaR). The Basel III Accord, which will be implemented in the
years leading up to 2019, places new attention on ES, but unlike VaR, there is
little existing work on modeling ES. We use recent results from statistical
decision theory to overcome the problem of "elicitability" for ES by jointly
modelling ES and VaR, and propose new dynamic models for these risk measures.
We provide estimation and inference methods for the proposed models, and
confirm via simulation studies that the methods have good finite-sample
properties. We apply these models to daily returns on four international equity
indices, and find the proposed new ES-VaR models outperform forecasts based on
GARCH or rolling window models.
</summary>
    <author>
      <name>Andrew J. Patton</name>
    </author>
    <author>
      <name>Johanna F. Ziegel</name>
    </author>
    <author>
      <name>Rui Chen</name>
    </author>
    <link href="http://arxiv.org/abs/1707.05108v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.05108v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.05146v2</id>
    <updated>2017-10-04T15:20:58Z</updated>
    <published>2017-07-17T13:31:31Z</published>
    <title>Unfolding the innovation system for the development of countries:
  co-evolution of Science, Technology and Production</title>
    <summary>  We show that the space in which scientific, technological and economic
developments interplay with each other can be mathematically shaped using
pioneering multilayer network and complexity techniques. We build the
tri-layered network of human activities (scientific production, patenting, and
industrial production) and study the interactions among them, also taking into
account the possible time delays. Within this construction we can identify
which capabilities and prerequisites are needed to be competitive in a given
activity, and even measure how much time is needed to transform, for instance,
the technological know-how into economic wealth and scientific innovation,
being able to make predictions with a very long time horizon. Quite
unexpectedly, we find empirical evidence that the naive knowledge flow from
science, to patents, to products is not supported by data, being instead
technology the best predictor for industrial and scientific production for the
next decades.
</summary>
    <author>
      <name>Emanuele Pugliese</name>
    </author>
    <author>
      <name>Giulio Cimini</name>
    </author>
    <author>
      <name>Aurelio Patelli</name>
    </author>
    <author>
      <name>Andrea Zaccaria</name>
    </author>
    <author>
      <name>Luciano Pietronero</name>
    </author>
    <author>
      <name>Andrea Gabrielli</name>
    </author>
    <link href="http://arxiv.org/abs/1707.05146v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.05146v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.02193v1</id>
    <updated>2017-08-07T16:40:34Z</updated>
    <published>2017-08-07T16:40:34Z</published>
    <title>The phase space structure of the oligopoly dynamical system by means of
  Darboux integrability</title>
    <summary>  We investigate the dynamical complexity of Cournot oligopoly dynamics of
three firms by using the qualitative methods of dynamical systems to study the
phase structure of this model. The phase space is organized with
one-dimensional and two-dimensional invariant submanifolds (for the monopoly
and duopoly) and unique stable node (global attractor) in the positive quadrant
of the phase space (Cournot equilibrium). We also study the integrability of
the system. We demonstrate the effectiveness of the method of the Darboux
polynomials in searching for first integrals of the oligopoly. The general
method as well as examples of adopting this method are presented. We study
Darboux non-integrability of the oligopoly for linear demand functions and find
first integrals of this system for special classes of the system, in
particular, rational integrals can be found for a quite general set of model
parameters. We show how first integral can be useful in lowering the dimension
of the system using the example of $n$ almost identical firms. This first
integral also gives information about the structure of the phase space and the
behaviour of trajectories in the neighbourhood of a Nash equilibrium
</summary>
    <author>
      <name>Adam Krawiec</name>
    </author>
    <author>
      <name>Tomasz Stachowiak</name>
    </author>
    <author>
      <name>Marek Szydlowski</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">25 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1708.02193v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.02193v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.02365v1</id>
    <updated>2017-08-08T04:04:02Z</updated>
    <published>2017-08-08T04:04:02Z</published>
    <title>Derivative-Based Optimization with a Non-Smooth Simulated Criterion</title>
    <summary>  Indirect inference requires simulating realizations of endogenous variables
from the model under study. When the endogenous variables are discontinuous
functions of the model parameters, the resulting indirect inference criterion
function is discontinuous and does not permit the use of derivative-based
optimization routines. Using a specific class of measure changes, we propose a
novel simulation algorithm that alleviates the underlying discontinuities
inherent in the indirect inference criterion function, permitting the
application of derivative-based optimization routines to estimate the unknown
model parameters. Unlike competing approaches, this approach does not rely on
kernel smoothing or bandwidth parameters. Several Monte Carlo examples that
have featured in the literature on indirect inference with discontinuous
outcomes illustrate the approach. These examples demonstrate that this new
method gives superior performance over existing alternatives in terms of bias,
variance and coverage.
</summary>
    <author>
      <name>David T. Frazier</name>
    </author>
    <author>
      <name>Dan Zhu</name>
    </author>
    <link href="http://arxiv.org/abs/1708.02365v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.02365v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.03511v1</id>
    <updated>2017-08-11T12:02:02Z</updated>
    <published>2017-08-11T12:02:02Z</published>
    <title>Technology networks: the autocatalytic origins of innovation</title>
    <summary>  We search an autocatalytic structure in networks of technological fields and
evaluate its significance for technological change. To this aim we define a
technology network based on the International Patents Classification, and we
study if autocatalytic structures in the network foster innovation as measured
by the rate of production of patents. The network is identified through
patenting activity of geographical regions in different technology fields.
Through our analysis we show how the technological landscape of the patents
database evolves as a self-organising autocatalytic structure that grows in
size, and arrives to cover the most part of the technology network. Technology
classes in the core of the autocatalytic structure perform better in terms of
their innovativeness, as measured by the rate of growth of the number of
patents. Finally, the links between classes that define the autocatalytic
structure of the technology network break the hierarchical structure of the
database, and indicate that recombinant innovation and its autocatalytic
patterns are an important stylised fact of technological change.
</summary>
    <author>
      <name>Paolo Zeppini</name>
    </author>
    <author>
      <name>Evangelos Evangelou</name>
    </author>
    <author>
      <name>Emanuele Pugliese</name>
    </author>
    <author>
      <name>Lorenzo Napolitano</name>
    </author>
    <author>
      <name>Graham Room</name>
    </author>
    <link href="http://arxiv.org/abs/1708.03511v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.03511v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.04430v1</id>
    <updated>2017-08-15T08:36:39Z</updated>
    <published>2017-08-15T08:36:39Z</published>
    <title>Dynamics of Investor Spanning Trees Around Dot-Com Bubble</title>
    <summary>  We identify temporal investor networks for Nokia stock by constructing
networks from correlations between investor-specific net-volumes and analyze
changes in the networks around dot-com bubble. We conduct the analysis
separately for households, non-financial institutions, and financial
institutions. Our results indicate that spanning tree measures for households
reflected the boom and crisis: the maximum spanning tree measures had clear
upward tendency in the bull markets when the bubble was building up, and, even
more importantly, the minimum spanning tree measures pre-reacted the burst of
bubble. At the same time, we find less clear reactions in minimal and maximal
spanning trees of non-financial and financial institutions around the bubble,
which suggest that household investors can have a greater herding tendency
around bubbles.
</summary>
    <author>
      <name>Sindhuja Ranganathan</name>
    </author>
    <author>
      <name>Mikko Kivelä</name>
    </author>
    <author>
      <name>Juho Kanniainen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1708.04430v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.04430v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.04711v1</id>
    <updated>2017-08-15T22:48:35Z</updated>
    <published>2017-08-15T22:48:35Z</published>
    <title>Generalizations of Szpilrajn's Theorem in economic and game theories</title>
    <summary>  Szpilrajn's Lemma entails that each partial order extends to a linear order.
Dushnik and Miller use Szpilrajn's Lemma to show that each partial order has a
relizer. Since then, many authors utilize Szpilrajn's Theorem and the
Well-ordering principle to prove more general existence type theorems on
extending binary relations. Nevertheless, we are often interested not only in
the existence of extensions of a binary relation $R$ satisfying certain axioms
of orderability, but in something more: (A) The conditions of the sets of
alternatives and the properties which $R$ satisfies to be inherited when one
passes to any member of a subfamily of the family of extensions of $R$ and: (B)
The size of a family of ordering extensions of $R$, whose intersection is $R$,
to be the smallest one. The key to addressing these kinds of problems is the
szpilrajn inherited method. In this paper, we define the notion of
$\Lambda(m)$-consistency, where $m$ can reach the first infinite ordinal
$\omega$, and we give two general inherited type theorems on extending binary
relations, a Szpilrajn type and a Dushnik-Miller type theorem, which generalize
all the well known existence and inherited type extension theorems in the
literature. \keywords{Consistent binary relations, Extension theorems,
Intersection of binary relations.
</summary>
    <author>
      <name>Athanasios Andrikopoulos</name>
    </author>
    <link href="http://arxiv.org/abs/1708.04711v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.04711v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.05689v1</id>
    <updated>2017-08-10T19:07:20Z</updated>
    <published>2017-08-10T19:07:20Z</published>
    <title>Quantum Barro--Gordon Game in Monetary Economics</title>
    <summary>  Classical game theory addresses decision problems in multi-agent environment
where one rational agent's decision affects other agents' payoffs. Game theory
has widespread application in economic, social and biological sciences. In
recent years quantum versions of classical games have been proposed and
studied. In this paper, we consider a quantum version of the classical
Barro-Gordon game which captures the problem of time inconsistency in monetary
economics. Such time inconsistency refers to the temptation of weak policy
maker to implement high inflation when the public expects low inflation. The
inconsistency arises when the public punishes the weak policy maker in the next
cycle. We first present a quantum version of the Barro-Gordon game. Next, we
show that in a particular case of the quantum game, time-consistent Nash
equilibrium could be achieved when public expects low inflation, thus resolving
the game.
</summary>
    <author>
      <name>Ali Hussein Samadi</name>
    </author>
    <author>
      <name>Afshin Montakhab</name>
    </author>
    <author>
      <name>Hussein Marzban</name>
    </author>
    <author>
      <name>Sakine Owjimehr</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 2 tables. Accepted for publication in Physica A</arxiv:comment>
    <link href="http://arxiv.org/abs/1708.05689v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.05689v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.07037v1</id>
    <updated>2017-07-28T08:57:26Z</updated>
    <published>2017-07-28T08:57:26Z</published>
    <title>Relationship between Remittances and Macroeconomic Variables in Times of
  Political and Social Upheaval: Evidence from Tunisia's Arab Spring</title>
    <summary>  If Tunisia was hailed as a success story with its high rankings on economic,
educational, and other indicators compared to other Arab countries, the 2011
popular uprisings demonstrate the need for political reforms but also major
economic reforms. The Arab spring highlights the fragility of its main economic
pillars including the tourism and the foreign direct investment. In such
turbulent times, the paper examines the economic impact of migrant'
remittances, expected to have a countercyclical behavior. Our results reveal
that prior to the Arab Spring, the impacts of remittances on growth and
consumption seem negative and positive respectively, while they varyingly
influence local investment. These three relationships held in the short-run. By
considering the period surrounding the 2011 uprisings, the investment effect of
remittances becomes negative and weak in the short-and medium-run, whereas
positive and strong remittances' impacts on growth and consumption are found in
the long term.
</summary>
    <author>
      <name>Jamal Bouoiyour</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CATT</arxiv:affiliation>
    </author>
    <author>
      <name>Refk Selmi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CATT</arxiv:affiliation>
    </author>
    <author>
      <name>Amal Miftah</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CATT</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ERF 23rd Annual Conference , Mar 2017, Amman, Jordan</arxiv:comment>
    <link href="http://arxiv.org/abs/1708.07037v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.07037v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.07723v1</id>
    <updated>2017-08-23T22:02:17Z</updated>
    <published>2017-08-23T22:02:17Z</published>
    <title>Promotion through Connections: Favors or Information?</title>
    <summary>  Connections appear to be helpful in many contexts such as obtaining a job, a
promotion, a grant, a loan or publishing a paper. This may be due to favoritism
or to information conveyed by connections. Attempts at identifying both effects
have relied on measures of true quality, generally built from data collected
long after promotion. This empirical strategy faces important limitations.
Building on earlier work on discrimination, we propose a new method to identify
favors and information from classical data collected at time of promotion.
Under natural assumptions, we show that promotion decisions look more random
for connected candidates, due to the information channel. We obtain new
identification results and show how probit models with heteroscedasticity can
be used to estimate the strength of the two effects. We apply our method to the
data on academic promotions in Spain studied in Zinovyeva &amp; Bagues (2015). We
find evidence of both favors and information effects at work. Empirical results
are consistent with evidence obtained from quality measures collected five
years after promotion.
</summary>
    <author>
      <name>Yann Bramoullé</name>
    </author>
    <author>
      <name>Kenan Huremović</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">35 pages, 2 figures, 13 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1708.07723v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.07723v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.08275v1</id>
    <updated>2017-08-28T11:42:08Z</updated>
    <published>2017-08-28T11:42:08Z</published>
    <title>An equilibrium-conserving taxation scheme for income from capital</title>
    <summary>  Under conditions of market equilibrium, the distribution of capital income
follows a Pareto power law, with an exponent that characterizes the given
equilibrium. Here, a simple taxation scheme is proposed such that the post-tax
capital income distribution remains an equilibrium distribution, albeit with a
different exponent. This taxation scheme is shown to be progressive, and its
parameters can be simply derived from (i) the total amount of tax that will be
levied, (ii) the threshold selected above which capital income will be taxed
and (iii) the total amount of capital income. The latter can be obtained either
by using Piketty's estimates of the capital/labor income ratio or by fitting
the initial Pareto exponent. Both ways moreover provide a check on the amount
of declared income from capital.
</summary>
    <author>
      <name>Jacques Tempere</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1708.08275v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.08275v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.09327v1</id>
    <updated>2017-08-30T15:38:32Z</updated>
    <published>2017-08-30T15:38:32Z</published>
    <title>Spontaneous Segregation of Agents Across Double Auction Markets</title>
    <summary>  In this paper we investigate the possibility of spontaneous segregation into
groups of traders that have to choose among several markets. Even in the
simplest case of two markets and Zero Intelligence traders, we are able to
observe segregation effects below a critical value Tc of the temperature T; the
latter regulates how strongly traders bias their decisions towards choices with
large accumulated scores. It is notable that segregation occurs even though the
traders are statistically homogeneous. Traders can in principle change their
loyalty to a market, but the relevant persistence times become long below Tc.
</summary>
    <author>
      <name>Aleksandra Alorić</name>
    </author>
    <author>
      <name>Peter Sollich</name>
    </author>
    <author>
      <name>Peter McBurney</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-319-09578-3_7</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-319-09578-3_7" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 7 figures; Artificial Economics 2014 conference; Published
  online: 17 October 2014</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Advances in Artificial Economics (2015) pp 79-90. Lecture Notes in
  Economics and Mathematical Systems, vol 676. Springer, Cham</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1708.09327v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.09327v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.00282v1</id>
    <updated>2017-08-31T13:11:11Z</updated>
    <published>2017-08-31T13:11:11Z</published>
    <title>Econophysics of Business Cycles: Aggregate Economic Fluctuations, Mean
  Risks and Mean Square Risks</title>
    <summary>  This paper presents hydrodynamic-like model of business cycles aggregate
fluctuations of economic and financial variables. We model macroeconomics as
ensemble of economic agents on economic space and agent's risk ratings play
role of their coordinates. Sum of economic variables of agents with coordinate
x define macroeconomic variables as functions of time and coordinates x. We
describe evolution and interactions between macro variables on economic space
by hydrodynamic-like equations. Integral of macro variables over economic space
defines aggregate economic or financial variables as functions of time t only.
Hydrodynamic-like equations define fluctuations of aggregate variables. Motion
of agents from low risk to high risk area and back define the origin for
repeated fluctuations of aggregate variables. Economic or financial variables
on economic space may define statistical moments like mean risk, mean square
risk and higher. Fluctuations of statistical moments describe phases of
financial and economic cycles. As example we present a simple model relations
between Assets and Revenue-on-Assets and derive hydrodynamic-like equations
that describe evolution and interaction between these variables.
Hydrodynamic-like equations permit derive systems of ordinary differential
equations that describe fluctuations of aggregate Assets, Assets mean risks and
Assets mean square risks. Our approach allows describe business cycle aggregate
fluctuations induced by interactions between any number of economic or
financial variables.
</summary>
    <author>
      <name>Victor Olkhov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">31 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1709.00282v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.00282v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.05117v1</id>
    <updated>2017-09-15T09:07:09Z</updated>
    <published>2017-09-15T09:07:09Z</published>
    <title>Optimal Inflation Target: Insights from an Agent-Based Model</title>
    <summary>  Which level of inflation should Central Banks be targeting? We investigate
this issue in the context of a simplified Agent Based Model of the economy.
Depending on the value of the parameters that describe the micro-behaviour of
agents (in particular inflation anticipations), we find a surprisingly rich
variety of behaviour at the macro-level. Without any monetary policy, our ABM
economy can be in a high inflation/high output state, or in a low inflation/low
output state. Hyper-inflation, stagflation, deflation and business cycles are
also possible. We then introduce a Central Bank with a Taylor-rule-based
inflation target, and study the resulting aggregate variables. Our main result
is that too low inflation targets are in general detrimental to a CB-controlled
economy. One symptom is a persistent under-realisation of inflation, perhaps
similar to the current macroeconomic situation. This predicament is alleviated
by higher inflation targets that are found to improve both unemployment and
negative interest rate episodes, up to the point where erosion of savings
becomes unacceptable. Our results are contrasted with the predictions of the
standard DSGE model.
</summary>
    <author>
      <name>Jean-Philippe Bouchaud</name>
    </author>
    <author>
      <name>Stanislao Gualdi</name>
    </author>
    <author>
      <name>Marco Tarzia</name>
    </author>
    <author>
      <name>Francesco Zamponi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1709.05117v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.05117v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.05272v1</id>
    <updated>2017-09-15T15:36:48Z</updated>
    <published>2017-09-15T15:36:48Z</published>
    <title>Economic Complexity: "Buttarla in caciara" vs a constructive approach</title>
    <summary>  This note is a contribution to the debate about the optimal algorithm for
Economic Complexity that recently appeared on ArXiv [1, 2] . The authors of [2]
eventually agree that the ECI+ algorithm [1] consists just in a renaming of the
Fitness algorithm we introduced in 2012, as we explicitly showed in [3].
However, they omit any comment on the fact that their extensive numerical tests
claimed to demonstrate that the same algorithm works well if they name it ECI+,
but not if its name is Fitness. They should realize that this eliminates any
credibility to their numerical methods and therefore also to their new
analysis, in which they consider many algorithms [2]. Since by their own
admission the best algorithm is the Fitness one, their new claim became that
the search for the best algorithm is pointless and all algorithms are alike.
This is exactly the opposite of what they claimed a few days ago and it does
not deserve much comments. After these clarifications we also present a
constructive analysis of the status of Economic Complexity, its algorithms, its
successes and its perspectives. For us the discussion closes here, we will not
reply to further comments.
</summary>
    <author>
      <name>Luciano Pietronero</name>
    </author>
    <author>
      <name>Matthieu Cristelli</name>
    </author>
    <author>
      <name>Andrea Gabrielli</name>
    </author>
    <author>
      <name>Dario Mazzilli</name>
    </author>
    <author>
      <name>Emanuele Pugliese</name>
    </author>
    <author>
      <name>Andrea Tacchella</name>
    </author>
    <author>
      <name>Andrea Zaccaria</name>
    </author>
    <link href="http://arxiv.org/abs/1709.05272v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.05272v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.08023v1</id>
    <updated>2017-09-23T08:52:40Z</updated>
    <published>2017-09-23T08:52:40Z</published>
    <title>Ownership Cost Calculations for Distributed Energy Resources Using
  Uncertainty and Risk Analyses</title>
    <summary>  Ownership cost calculation plays an important role in optimal operation of
distributed energy resources (DERs) and microgrids (MGs) in the future power
system, known as smart grid. In this paper, a general framework for ownership
cost calculation is proposed using uncertainty and risk analyses. Four
ownership cost calculation approaches are introduced and compared based on
their associated risk values. Finally, the best method is chosen based on a
series of simulation results, performed for a typical diesel generator (DiG).
Although simulation results are given for a DiG (as commonly used in MGs), the
proposed approaches can be applied to other MG components, such as batteries,
with slight modifications, as presented in this paper. The analyses and
proposed approaches can be useful in MG optimal design, optimal power flow, and
market-based operation of the smart grid for accurate operational cost
calculations.
</summary>
    <author>
      <name>S. Ali Pourmousavi</name>
    </author>
    <author>
      <name>Mahdi Behrangrad</name>
    </author>
    <author>
      <name>Ali Jahanbani Ardakani</name>
    </author>
    <author>
      <name>M. Hashem Nehrir</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 7 figures, 3 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1709.08023v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.08023v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1407.7738v1</id>
    <updated>2014-07-29T14:30:25Z</updated>
    <published>2014-07-29T14:30:25Z</published>
    <title>Multivariate Self-Exciting Threshold Autoregressive Models with
  eXogenous Input</title>
    <summary>  This study defines a multivariate Self--Exciting Threshold Autoregressive
with eXogenous input (MSETARX) models and present an estimation procedure for
the parameters. The conditions for stationarity of the nonlinear MSETARX models
is provided. In particular, the efficiency of an adaptive parameter estimation
algorithm and LSE (least squares estimate) algorithm for this class of models
is then provided via simulations.
</summary>
    <author>
      <name>Peter Martey Addo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This is a preliminary version of the paper-- please do not quote</arxiv:comment>
    <link href="http://arxiv.org/abs/1407.7738v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1407.7738v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.CP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1409.3296v1</id>
    <updated>2014-09-11T02:19:27Z</updated>
    <published>2014-09-11T02:19:27Z</published>
    <title>Endogenous crisis waves: a stochastic model with synchronized collective
  behavior</title>
    <summary>  We propose a simple framework to understand commonly observed crisis waves in
macroeconomic Agent Based models, that is also relevant to a variety of other
physical or biological situations where synchronization occurs. We compute
exactly the phase diagram of the model and the location of the synchronization
transition in parameter space. Many modifications and extensions can be
studied, confirming that the synchronization transition is extremely robust
against various sources of noise or imperfections.
</summary>
    <author>
      <name>Stanislao Gualdi</name>
    </author>
    <author>
      <name>Jean-Philippe Bouchaud</name>
    </author>
    <author>
      <name>Giulia Cencetti</name>
    </author>
    <author>
      <name>Marco Tarzia</name>
    </author>
    <author>
      <name>Francesco Zamponi</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1103/PhysRevLett.114.088701</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1103/PhysRevLett.114.088701" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 3 figures. This paper is part of the CRISIS project,
  http://www.crisis-economics.eu</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Phys. Rev. Lett. 114, 088701 (2015)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1409.3296v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1409.3296v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1411.7880v1</id>
    <updated>2014-11-28T14:34:08Z</updated>
    <published>2014-11-28T14:34:08Z</published>
    <title>Evidence of Economic Regularities and Disparities of Italian Regions
  From Aggregated Tax Income Size Data</title>
    <summary>  This paper discusses the size distribution, - in economic terms - of the
Italian municipalities over the period 2007-2011. Yearly data are rather well
fitted by a modified Lavalette law, while Zipf-Mandelbrot-Pareto law seems to
fail in this doing. The analysis is performed either at a national as well as
at a local (regional and provincial) level. Deviations are discussed as
originating in so called king and vice-roy effects. Results confirm that Italy
is shared among very different regional realities. The case of Lazio is
puzzling.
</summary>
    <author>
      <name>Roy Cerqueti</name>
    </author>
    <author>
      <name>Marcel Ausloos</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.physa.2014.11.027</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.physa.2014.11.027" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">34 pages; 49 references; 29 figures; 9 Tables; to be published in
  Physica A</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Physica A 421 (2015) 187-207</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1411.7880v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1411.7880v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1501.02513v2</id>
    <updated>2015-08-20T04:15:01Z</updated>
    <published>2015-01-12T00:41:49Z</published>
    <title>The 20-60-20 Rule</title>
    <summary>  In this paper we discuss an empirical phenomena known as the 20-60-20 rule.
It says that if we split the population into three groups, according to some
arbitrary benchmark criterion, then this particular ratio implies some sort of
balance. From practical point of view, this feature often leads to efficient
management or control. We provide a mathematical illustration, justifying the
occurrence of this rule in many real world situations. We show that for any
population, which could be described using multivariate normal vector, this
fixed ratio leads to a global equilibrium state, when dispersion and linear
dependance measurement is considered.
</summary>
    <author>
      <name>Piotr Jaworski</name>
    </author>
    <author>
      <name>Marcin Pitera</name>
    </author>
    <link href="http://arxiv.org/abs/1501.02513v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1501.02513v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
    <category term="60K30, 91B10, 91B14, 91B52, 60A86, 62A86" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.05416v1</id>
    <updated>2015-03-18T14:01:22Z</updated>
    <published>2015-03-18T14:01:22Z</published>
    <title>The Principal-Agent Problem With Time Inconsistent Utility Functions</title>
    <summary>  In this paper we study a generalization of the continuous time
Principal-Agent problem allowing for time inconsistent utility functions, for
instance of mean-variance type. Using recent results on the Pontryagin maximum
principle for FBSDEs we suggest a method of characterizing optimal contracts
for such models. To illustrate this we consider a fully solved explicit example
in the linear quadratic setting.
</summary>
    <author>
      <name>Boualem Djehiche</name>
    </author>
    <author>
      <name>Peter Helgesson</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: substantial text overlap with arXiv:1410.6392</arxiv:comment>
    <link href="http://arxiv.org/abs/1503.05416v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.05416v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.06113v1</id>
    <updated>2015-04-23T09:52:10Z</updated>
    <published>2015-04-23T09:52:10Z</published>
    <title>Transitions in the Stock Markets of the US, UK, and Germany</title>
    <summary>  In an analysis of the US, the UK, and the German stock market we find a
change in the behavior based on the stock's beta values. Before 2006 risky
trades were concentrated on stocks in the IT and technology sector. Afterwards
risky trading takes place for stocks from the financial sector. We show that an
agent-based model can reproduce these changes. We further show that the initial
impulse for the transition might stem from the increase of high frequency
trading at that time.
</summary>
    <author>
      <name>Matthias Raddant</name>
    </author>
    <author>
      <name>Friedrich Wagner</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1080/14697688.2016.1183812</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1080/14697688.2016.1183812" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Quantitative Finance, 17(2), 289-297 (2017)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1504.06113v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.06113v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.PM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.04227v1</id>
    <updated>2015-06-13T05:45:51Z</updated>
    <published>2015-06-13T05:45:51Z</published>
    <title>Safety Third: Roy's Criterion and Higher Order Moments</title>
    <summary>  Roy's `Safety First' criterion for selecting one risky asset from many is
adapted to the case of non-normal returns, via Cornish Fisher expansion. The
resulting investment objective is consistent with first order stochastic
dominance, and is equal to the Sharpe ratio for the case of normal returns. An
investor selecting assets via this objective is not universally attracted to
positive skew, rather the preference for skew depends on term, the expected
return and the disastrous rate of return.
</summary>
    <author>
      <name>Steven E. Pav</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1506.04227v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.04227v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62P20" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.04655v2</id>
    <updated>2017-07-13T16:17:20Z</updated>
    <published>2015-07-16T17:06:40Z</published>
    <title>Insurance makes wealth grow faster</title>
    <summary>  Voluntary insurance contracts constitute a puzzle because they increase the
expectation value of one party's wealth, whereas both parties must sign for
such contracts to exist. Classically, the puzzle is resolved by introducing
non-linear utility functions, which encode asymmetric risk preferences; or by
assuming the parties have asymmetric information. Here we show the puzzle goes
away if contracts are evaluated by their effect on the time-average growth rate
of wealth. Our solution assumes only knowledge of wealth dynamics. Time
averages and expectation values differ because wealth changes are non-ergodic.
Our reasoning is generalisable: business happens when both parties grow faster.
</summary>
    <author>
      <name>Ole Peters</name>
    </author>
    <author>
      <name>Alexander Adamou</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">27 pages, 3 figures, 3 tables, 1 glossary</arxiv:comment>
    <link href="http://arxiv.org/abs/1507.04655v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.04655v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.07219v3</id>
    <updated>2017-06-01T13:54:59Z</updated>
    <published>2015-07-26T16:34:36Z</published>
    <title>Why Quantitative Structuring?</title>
    <summary>  Quality-designed products are easy to recognize. Wouldn't it be great if the
quality of financial products became just as apparent? This paper is addressed
to financial practitioners. It provides an informal introduction to
Quantitative Structuring -- a technology of manufacturing quality financial
products. The presentation is arranged in three parts: the main text assumes no
prior knowledge of the topic; important detailed discussions are arranged as a
set of appendices; finally, a list of references provides further details
including applications beyond product design: from model risk to economics.
</summary>
    <author>
      <name>Andrei N. Soklakov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1507.07219v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.07219v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.08863v1</id>
    <updated>2015-07-31T13:05:20Z</updated>
    <published>2015-07-31T13:05:20Z</published>
    <title>Keeping up with the e-Joneses: Do online social networks raise social
  comparisons?</title>
    <summary>  Online social networks such as Facebook disclose an unprecedented volume of
personal information amplifying the occasions for social comparisons. We test
the hypothesis that the use of social networking sites (SNS) increases people's
dissatisfaction with their income. After addressing endogeneity issues, our
results suggest that SNS users have a higher probability to compare their
achievements with those of others. This effect seems stronger than the one
exerted by TV watching, it is particularly strong for younger people, and it
affects men and women in a similar way.
</summary>
    <author>
      <name>Fabio Sabatini</name>
    </author>
    <author>
      <name>Francesco Sarracino</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">25 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1507.08863v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.08863v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.05948v2</id>
    <updated>2015-12-21T14:11:58Z</updated>
    <published>2015-08-18T11:06:23Z</published>
    <title>On the reversal bias of the Minimax social choice correspondence</title>
    <summary>  We introduce three different qualifications of the reversal bias in the
framework of social choice correspondences. For each of them, we prove that the
Minimax social choice correspondence is immune to it if and only if the number
of voters and the number of alternatives satisfy suitable arithmetical
conditions. We prove those facts thanks to a new characterization of the
Minimax social choice correspondence and using a graph theory approach. We
discuss the same issue for the Borda and Copeland social choice
correspondences.
</summary>
    <author>
      <name>Daniela Bubboloni</name>
    </author>
    <author>
      <name>Michele Gori</name>
    </author>
    <link href="http://arxiv.org/abs/1508.05948v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.05948v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="05C20" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.04346v1</id>
    <updated>2015-10-14T23:28:35Z</updated>
    <published>2015-10-14T23:28:35Z</published>
    <title>Explicit solutions to a vector time series model and its induced model
  for business cycles</title>
    <summary>  This article gives the explicit solution to a general vector time series
model that describes interacting, heterogeneous agents that operate under
uncertainties but according to Keynesian principles, from which a model for
business cycle is induced by a weighted average of the growth rates of the
agents in the model. The explicit solution enables a direct simulation of the
time series defined by the model and better understanding of the joint behavior
of the growth rates. In addition, the induced model for business cycles and its
solutions are explicitly given and analyzed. The explicit solutions provide a
better understanding of the mathematics of these models and the econometric
properties they try to incorporate.
</summary>
    <author>
      <name>Xiongzhi Chen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 page2, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1510.04346v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.04346v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="Primary 91B62, 62M10, Secondary 91B70" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.02716v2</id>
    <updated>2017-06-15T09:20:02Z</updated>
    <published>2015-11-09T15:27:20Z</published>
    <title>Nash equilibria for non zero-sum ergodic stochastic differential games</title>
    <summary>  In this paper we consider non zero-sum games where multiple players control
the drift of a process, and their payoffs depend on its ergodic behaviour. We
establish their connection with systems of Ergodic BSDEs, and prove the
existence of a Nash equilibrium under the generalised Isaac's conditions. We
also study the case of interacting players of different type.
</summary>
    <author>
      <name>Samuel N. Cohen</name>
    </author>
    <author>
      <name>Victor Fedyashov</name>
    </author>
    <link href="http://arxiv.org/abs/1511.02716v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.02716v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91A60, 49N70, 93E20" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.03616v2</id>
    <updated>2016-10-24T15:39:51Z</updated>
    <published>2015-10-26T17:14:10Z</published>
    <title>Moral hazard under ambiguity</title>
    <summary>  In this paper, we extend the Holmstro\"om and Milgrom problem [47] by adding
uncertainty about the volatility of the output for both the Agent and the
Principal. We study more precisely the impact of the "Nature" playing against
the Agent and the Principal by choosing the worst possible volatility of the
output. We solve the first--best and the second--best problems associated with
this framework and we show that optimal contracts are in a class of contracts
similar to [14, 15], linear with respect to the output and its quadratic
variation. We compare our results with the classical problem in [47].
</summary>
    <author>
      <name>Thibaut Mastrolia</name>
    </author>
    <author>
      <name>Dylan Possamaï</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">52 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1511.03616v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.03616v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.05012v2</id>
    <updated>2016-01-20T20:50:54Z</updated>
    <published>2016-01-19T17:38:33Z</published>
    <title>A Simple Measure of Economic Complexity</title>
    <summary>  We show from a simple model that a country's technological development can be
measured by the logarithm of the number of products it makes. We show that much
of the income gaps among countries are due to differences in technology, as
measured by this simple metric. Finally, we show that the so-called Economic
Complexity Index (ECI), a recently proposed measure of collective knowhow, is
in fact an estimate of this simple metric (with correlation above 0.9).
</summary>
    <author>
      <name>Sabiou Inoua</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 5 figures, 1 table</arxiv:comment>
    <link href="http://arxiv.org/abs/1601.05012v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.05012v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.03709v3</id>
    <updated>2017-01-23T15:43:54Z</updated>
    <published>2016-06-12T13:22:28Z</published>
    <title>Mean field games of timing and models for bank runs</title>
    <summary>  The goal of the paper is to introduce a set of problems which we call mean
field games of timing. We motivate the formulation by a dynamic model of bank
run in a continuous-time setting. We briefly review the economic and game
theoretic contributions at the root of our effort, and we develop a
mathematical theory for continuous-time stochastic games where the strategic
decisions of the players are merely choices of times at which they leave the
game, and the interaction between the strategic players is of a mean field
nature.
</summary>
    <author>
      <name>Rene Carmona</name>
    </author>
    <author>
      <name>Francois Delarue</name>
    </author>
    <author>
      <name>Daniel Lacker</name>
    </author>
    <link href="http://arxiv.org/abs/1606.03709v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.03709v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.08269v1</id>
    <updated>2016-06-27T13:33:00Z</updated>
    <published>2016-06-27T13:33:00Z</published>
    <title>An agent behavior based model for diffusion price processes with
  application to phase transition and oscillations</title>
    <summary>  We present an agent behavior based microscopic model for diffusion price
processes. As such we provide a model not only containing a convenient
framework for describing socio-economic behavior, but also a sophisticated link
to price dynamics. We furthermore establish the circumstances under which the
dynamics converge to diffusion processes in the large market limit. To
demonstrate the applicability of a separation of behavior and price process, we
show how herding behavior of market participants can lead to equilibria
transition and oscillations in diffusion price processes.
</summary>
    <author>
      <name>Christof Henkel</name>
    </author>
    <link href="http://arxiv.org/abs/1606.08269v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.08269v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="60F05, 60J60, 60K35, 91B69, 91D30" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.03161v1</id>
    <updated>2016-06-29T10:30:24Z</updated>
    <published>2016-06-29T10:30:24Z</published>
    <title>A mathematical model for a gaming community</title>
    <summary>  We consider a large community of individuals who mix strongly and meet in
pairs to bet on a coin toss. We investigate the asset distribution of the
players involved in this zero-sum repeated game. Our main result is that the
asset distribution converges to the exponential distribution, irrespective of
the size of the bet, as long as players can never go bankrupt. Analytical
results suggests that the exponential distribution is a stable fixed point for
this zero-sum repreated game. This is confirmed in numerical experiments.
</summary>
    <author>
      <name>Romulus Breban</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1607.03161v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.03161v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.06959v1</id>
    <updated>2016-08-24T20:26:25Z</updated>
    <published>2016-08-24T20:26:25Z</published>
    <title>Strategic Growth with Recursive Preferences: Decreasing Marginal
  Impatience</title>
    <summary>  We study the interaction between strategy, heterogeneity and growth in a
two-agent model of capital accumulation. Preferences are represented by
recursive utility functions with decreasing marginal impatience. The stationary
equilibria of this dynamic game are analyzed under two alternative information
structures: one in which agents precommit to future actions, and another one
where agents use Markovian strategies. In both cases, we develop sufficient
conditions to prove the existence of equilibria and characterize their
stability properties. The precommitment case is characterized by monotone
convergence, but Markovian equilibria may exhibit nonmonotonic paths, even in
the long-run.
</summary>
    <author>
      <name>Luis Alcala</name>
    </author>
    <author>
      <name>Fernando Tohme</name>
    </author>
    <author>
      <name>Carlos Dabus</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">55 pages, 14 figures, 2 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1608.06959v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.06959v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.05286v2</id>
    <updated>2016-10-17T07:10:28Z</updated>
    <published>2016-09-17T06:19:27Z</published>
    <title>From quantum mechanics to finance: Microfoundations for jumps, spikes
  and high volatility phases in diffusion price processes</title>
    <summary>  We present an agent behavior based microscopic model that induces jumps,
spikes and high volatility phases in the price process of a traded asset. We
transfer dynamics of thermally activated jumps of an unexcited/ excited two
state system discussed in the context of quantum mechanics to agent
socio-economic behavior and provide microfoundations. After we link the
endogenous agent behavior to price dynamics we establish the circumstances
under which the dynamics converge to an It\^o-diffusion price processes in the
large market limit.
</summary>
    <author>
      <name>Christof Henkel</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.physa.2016.11.125</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.physa.2016.11.125" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: text overlap with arXiv:1606.08269</arxiv:comment>
    <link href="http://arxiv.org/abs/1609.05286v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.05286v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.TR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.TR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="60F05, 60J60, 60K35, 91D30, 91B69, 91B80" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.02024v2</id>
    <updated>2016-12-09T03:35:34Z</updated>
    <published>2016-12-06T21:15:33Z</published>
    <title>Impossible Inference in Econometrics: Theory and Applications to
  Regression Discontinuity, Bunching, and Exogeneity Tests</title>
    <summary>  This paper presents necessary and sufficient conditions for tests to have
trivial power. By inverting these impractical tests, we demonstrate that the
bounded confidence regions have error probability equal to one. This
theoretical framework establishes a connection among many existing
impossibility results in econometrics, those using the total variation metric
and those using the L\'{e}vy-Prokhorov metric (convergence in distribution). In
particular, the theory establishes conditions under which the two types of
impossibility exist in econometric models. We then apply our theory to
Regression Discontinuity Design models and exogeneity tests based on bunching.
</summary>
    <author>
      <name>Marinho Bertanha</name>
    </author>
    <author>
      <name>Marcelo J. Moreira</name>
    </author>
    <link href="http://arxiv.org/abs/1612.02024v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.02024v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1702.01017v1</id>
    <updated>2017-02-02T17:37:44Z</updated>
    <published>2017-02-02T17:37:44Z</published>
    <title>Emergence of Distributed Coordination in the Kolkata Paise Restaurant
  Problem with Finite Information</title>
    <summary>  In this paper, we study a large-scale distributed coordination problem and
propose efficient adaptive strategies to solve the problem. The basic problem
is to allocate finite number of resources to individual agents such that there
is as little congestion as possible and the fraction of unutilized resources is
reduced as far as possible. In the absence of a central planner and global
information, agents can employ adaptive strategies that uses only finite
knowledge about the competitors. In this paper, we show that a combination of
finite information sets and reinforcement learning can increase the utilization
rate of resources substantially.
</summary>
    <author>
      <name>Diptesh Ghosh</name>
    </author>
    <author>
      <name>Anindya S. Chakrabarti</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.physa.2017.04.171</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.physa.2017.04.171" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1702.01017v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1702.01017v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1704.02392v1</id>
    <updated>2017-04-07T22:36:38Z</updated>
    <published>2017-04-07T22:36:38Z</published>
    <title>Market Crashes as Critical Phenomena? Explanation, Idealization, and
  Universality in Econophysics</title>
    <summary>  We study the Johansen-Ledoit-Sornette (JLS) model of financial market crashes
(Johansen, Ledoit, and Sornette [2000] "Crashes as Critical Points." Int. J.
Theor. Appl. Finan. 3(2) 219-255). On our view, the JLS model is a curious case
from the perspective of the recent philosophy of science literature, as it is
naturally construed as a "minimal model" in the sense of Batterman and Rice
(Batterman and Rice [2014] "Minimal Model Explanations." Phil. Sci. 81(3):
349-376) that nonetheless provides a causal explanation of market crashes, in
the sense of Woodward's interventionist account of causation (Woodward [2003].
Making Things Happen. Oxford:Oxford University Press).
</summary>
    <author>
      <name>Jennifer Jhun</name>
    </author>
    <author>
      <name>Patricia Palacios</name>
    </author>
    <author>
      <name>James Owen Weatherall</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">32 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1704.02392v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1704.02392v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.hist-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.hist-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1704.05015v1</id>
    <updated>2017-04-17T16:22:52Z</updated>
    <published>2017-04-17T16:22:52Z</published>
    <title>Measurement of Economic Growth, Development and Under Development: New
  Model and Application</title>
    <summary>  This paper presents a simple model to measure the relative economic growth of
economic systems. The model considers S-Shaped patterns of economic growth
that, represented with a linear model, measure how an economic system grows in
comparison with another one. In particular, this model introduces an approach
which indicates if the economic system has a process of economic growth,
development or under development. The application of the model is provided for
regions and macro regions of the Italian economic system.
</summary>
    <author>
      <name>Mario Coccia</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">24</arxiv:comment>
    <link href="http://arxiv.org/abs/1704.05015v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1704.05015v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.01454v2</id>
    <updated>2017-05-09T09:40:10Z</updated>
    <published>2017-05-03T14:42:41Z</published>
    <title>The Payoff Region of a Strategic Game and Its Extreme Points</title>
    <summary>  The range of a payoff function in an $n$-player finite strategic game is
investigated using a novel approach, the notion of extreme points of a
non-convex set. A basic structural characteristic of a noncooperative payoff
region is that any subregion must be non-strictly convex if it contains a
relative neighborhood of a boundary point of the noncooperative payoff region.
This can be proved efficiently in terms of its extreme points. Besides,
applying the properties of extreme points of noncooperative payoff regions is a
simple and efficient way to prove some results about Pareto analysis in game
theory.
</summary>
    <author>
      <name>Yu-Sung Tu</name>
    </author>
    <author>
      <name>Wei-Torng Juang</name>
    </author>
    <link href="http://arxiv.org/abs/1705.01454v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.01454v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.00849v1</id>
    <updated>2017-06-02T20:45:27Z</updated>
    <published>2017-06-02T20:45:27Z</published>
    <title>A Game of Nontransitive Dice</title>
    <summary>  We consider a two player simultaneous-move game where the two players each
select any permissible $n$-sided die for a fixed integer $n$. A player wins if
the outcome of his roll is greater than that of his opponent. Remarkably, for
$n&gt;3$, there is a unique Nash Equilibrium in pure strategies. The unique Nash
Equilibrium is for each player to throw the Standard $n$-sided die, where each
side has a different number. Our proof of uniqueness is constructive. We
introduce an algorithm with which, for any nonstandard die, we may generate
another die that beats it.
</summary>
    <author>
      <name>Artem Hulko</name>
    </author>
    <author>
      <name>Mark Whitmeyer</name>
    </author>
    <link href="http://arxiv.org/abs/1706.00849v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.00849v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.03746v3</id>
    <updated>2017-08-03T07:27:29Z</updated>
    <published>2017-07-12T14:47:37Z</published>
    <title>Modeling the price of Bitcoin with geometric fractional Brownian motion:
  a Monte Carlo approach</title>
    <summary>  The long-term dependence of Bitcoin (BTC), manifesting itself through a Hurst
exponent $H&gt;0.5$, is exploited in order to predict future BTC/USD price. A
Monte Carlo simulation with $10^4$ geometric fractional Brownian motion
realisations is performed as extensions of historical data. The accuracy of
statistical inferences is 10\%. The most probable Bitcoin price at the
beginning of 2018 is 6358 USD.
</summary>
    <author>
      <name>Mariusz Tarnopolski</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1707.03746v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.03746v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.CP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.CP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.06837v1</id>
    <updated>2017-07-21T10:52:28Z</updated>
    <published>2017-07-21T10:52:28Z</published>
    <title>An Alternative Estimation of a Time-Varying Parameter Model</title>
    <summary>  A non-Bayesian, generalized least squares (GLS)-based approach is formally
proposed to estimate a class of time-varying AR parameter models. This approach
has partly been used by Ito et al. (2014, 2016a,b), and is proven very
efficient because, unlike conventional methods, it does not require the Kalman
filtering and smoothing procedures, but yields a smoothed estimate that is
identical to the Kalman-smoothed estimate. Unlike the maximum likelihood
estimator, the possibility of the pile-up problem is shown to be small. In
addition, this approach enables us to possibly deal with stochastic volatility
models and models with a time-dependent variance-covariance matrix.
</summary>
    <author>
      <name>Mikio Ito</name>
    </author>
    <author>
      <name>Akihiko Noda</name>
    </author>
    <author>
      <name>Tatsuma Wada</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">30 pages, 2 tables, 11 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1707.06837v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.06837v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.01308v1</id>
    <updated>2017-08-03T20:58:47Z</updated>
    <published>2017-08-03T20:58:47Z</published>
    <title>A Mean Field Competition</title>
    <summary>  We introduce a mean field game with rank-based reward: competing agents
optimize their effort to achieve a goal, are ranked according to their
completion time, and paid a reward based on their relative rank. First, we
propose a tractable Poissonian model in which we can describe the optimal
effort for a given reward scheme. Second, we study the principal--agent problem
of designing an optimal reward scheme. A surprising, explicit design is found
to minimize the time until a given fraction of the population has reached the
goal.
</summary>
    <author>
      <name>Marcel Nutz</name>
    </author>
    <author>
      <name>Yuchong Zhang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">33 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1708.01308v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.01308v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91A13, 91B40, 93E20" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.3167v1</id>
    <updated>2014-04-10T15:16:05Z</updated>
    <published>2014-04-10T15:16:05Z</published>
    <title>A Dynamical Model of the Industrial Economy of the Humber Region</title>
    <summary>  The Humber region in the UK is a large and diverse industrial area centred
around oil refining, chemical industries and energy production. However there
is currently a desire to see the region transition towards a more bio-based
economy. New bio-related industries are being situated in the region as a
consequence of policy and economic incentives. Many of these industries are
connected through their supply chains, either directly, or by sharing common
suppliers or customers and the growth or decline of one industry can hence have
impacts on many others. Therefore an important question to consider is what
effect this movement towards bio-based industry will actually have on the
regional economy as a whole. In this paper we develop a general abstract
dynamical model for the metabolic interactions of firms or industries. This
dynamical model has been applied to the Humber region in order to gain a deeper
understanding of how the region may develop. The model suggests that the
transition to a bio-based economy will occur with oil refining losing its
dominance to bioethanol production and biological chemical production, whilst
anaerobic digestion grows as a major source of electricity, in turn driving up
the value of regional waste aggregators and arable farming in the overall
economy.
</summary>
    <author>
      <name>Christopher J. K. Knight</name>
    </author>
    <author>
      <name>Alexandra S. Penn</name>
    </author>
    <author>
      <name>Rebecca B. Hoyle</name>
    </author>
    <link href="http://arxiv.org/abs/1404.3167v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.3167v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.7801v2</id>
    <updated>2016-02-04T14:23:30Z</updated>
    <published>2014-05-30T09:03:38Z</published>
    <title>Gambling in contests with random initial law</title>
    <summary>  This paper studies a variant of the contest model introduced in Seel and
Strack [J. Econom. Theory 148 (2013) 2033-2048]. In the Seel-Strack contest,
each agent or contestant privately observes a Brownian motion, absorbed at
zero, and chooses when to stop it. The winner of the contest is the agent who
stops at the highest value. The model assumes that all the processes start from
a common value $x_0&gt;0$ and the symmetric Nash equilibrium is for each agent to
utilise a stopping rule which yields a randomised value for the stopped
process. In the two-player contest, this randomised value has a uniform
distribution on $[0,2x_0]$. In this paper, we consider a variant of the problem
whereby the starting values of the Brownian motions are independent,
nonnegative random variables that have a common law $\mu$. We consider a
two-player contest and prove the existence and uniqueness of a symmetric Nash
equilibrium for the problem. The solution is that each agent should aim for the
target law $\nu$, where $\nu$ is greater than or equal to $\mu$ in convex
order; $\nu$ has an atom at zero of the same size as any atom of $\mu$ at zero,
and otherwise is atom free; on $(0,\infty)$ $\nu$ has a decreasing density; and
the density of $\nu$ only decreases at points where the convex order constraint
is binding.
</summary>
    <author>
      <name>Han Feng</name>
    </author>
    <author>
      <name>David Hobson</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1214/14-AAP1088</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1214/14-AAP1088" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published at http://dx.doi.org/10.1214/14-AAP1088 in the Annals of
  Applied Probability (http://www.imstat.org/aap/) by the Institute of
  Mathematical Statistics (http://www.imstat.org)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Annals of Applied Probability 2016, Vol. 26, No. 1, 186-215</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1405.7801v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.7801v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1406.6620v2</id>
    <updated>2014-11-12T18:32:53Z</updated>
    <published>2014-06-25T16:01:22Z</published>
    <title>Game Theory, Statistical Mechanics and Income Inequality</title>
    <summary>  The widening inequality in income distribution in recent years, and the
associated excessive pay packages of CEOs in the U.S. and elsewhere, is of
growing concern among policy makers as well as the common person. However,
there seems to be no satisfactory answer, in conventional economic theories and
models, to the fundamental question of what kind of pay distribution we ought
to see, at least under ideal conditions, in a free market environment and
whether this distribution is fair. We propose a game theoretic framework that
addresses these questions and show that the lognormal distribution is the
fairest inequality of pay in an organization comprising of homogenous agents,
achieved at equilibrium, under ideal free market conditions. We also show that
for a population of two different classes of agents, the final distribution is
a combination of two different lognormal distributions where one of them,
corresponding to the top 3-5% of the population, can be misidentified as a
Pareto distribution. Our theory also shows the deep and direct connection
between potential game theory and statistical mechanics through entropy, which
is a measure of fairness in a distribution. This leads us to propose the fair
market hypothesis, that the self-organizing dynamics of the ideal free market,
i.e., Adam Smith's "invisible hand", not only promotes efficiency but also
maximizes fairness under the given constraints.
</summary>
    <author>
      <name>Venkat Venkatasubramanian</name>
    </author>
    <author>
      <name>Yu Luo</name>
    </author>
    <author>
      <name>Jay Sethuraman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Corresponding author: Venkat@columbia.edu</arxiv:comment>
    <link href="http://arxiv.org/abs/1406.6620v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1406.6620v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1407.5305v2</id>
    <updated>2014-08-17T15:27:10Z</updated>
    <published>2014-07-20T16:28:23Z</published>
    <title>The dynamics of the leverage cycle</title>
    <summary>  We present a simple agent-based model of a financial system composed of
leveraged investors such as banks that invest in stocks and manage their risk
using a Value-at-Risk constraint, based on historical observations of asset
prices. The Value-at-Risk constraint implies that when perceived risk is low,
leverage is high and vice versa, a phenomenon that has been dubbed pro-cyclical
leverage. We show that this leads to endogenous irregular oscillations, in
which gradual increases in stock prices and leverage are followed by drastic
market collapses, i.e. a leverage cycle. This phenomenon is studied using
simplified models that give a deeper understanding of the dynamics and the
nature of the feedback loops and instabilities underlying the leverage cycle.
We introduce a flexible leverage regulation policy in which it is possible to
continuously tune from pro-cyclical to countercyclical leverage. When the
policy is sufficiently countercyclical and bank risk is sufficiently low the
endogenous oscillation disappears and prices go to a fixed point. While there
is always a leverage ceiling above which the dynamics are unstable,
countercyclical leverage can be used to raise the ceiling. We also study the
impact on leverage cycles of direct, temporal control of the bank's riskiness
via the bank's required Value-at-Risk quantile. Under such a rule the regulator
relaxes the Value-at-Risk quantile following a negative stock price shock and
tightens it following a positive shock. While such a policy rule can reduce the
amplitude of leverage cycles, its effectiveness is highly dependent on the
choice of parameters. Finally, we investigate fixed limits on leverage and show
how they can control the leverage cycle.
</summary>
    <author>
      <name>Christoph Aymanns</name>
    </author>
    <author>
      <name>J. Doyne Farmer</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">35 pages, 9 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1407.5305v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1407.5305v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.03232v1</id>
    <updated>2015-01-27T14:59:44Z</updated>
    <published>2015-01-27T14:59:44Z</published>
    <title>Economic inequality and mobility in kinetic models for social sciences</title>
    <summary>  Statistical evaluations of the economic mobility of a society are more
difficult than measurements of the income distribution, because they require to
follow the evolution of the individuals' income for at least one or two
generations. In micro-to-macro theoretical models of economic exchanges based
on kinetic equations, the income distribution depends only on the asymptotic
equilibrium solutions, while mobility estimates also involve the detailed
structure of the transition probabilities of the model, and are thus an
important tool for assessing its validity. Empirical data show a remarkably
general negative correlation between economic inequality and mobility, whose
explanation is still unclear. It is therefore particularly interesting to study
this correlation in analytical models. In previous work we investigated the
behavior of the Gini inequality index in kinetic models in dependence on
several parameters which define the binary interactions and the taxation and
redistribution processes: saving propensity, taxation rates gap, tax evasion
rate, welfare means-testing etc. Here, we check the correlation of mobility
with inequality by analyzing the mobility dependence from the same parameters.
According to several numerical solutions, the correlation is confirmed to be
negative.
</summary>
    <author>
      <name>Maria Letizia Bertotti</name>
    </author>
    <author>
      <name>Giovanni Modanese</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1140/epjst/e2015-50117-8</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1140/epjst/e2015-50117-8" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 6 figures. Proceedings of the Sigma-Phi Conference on
  Statistical Physics, Rhodes, 2014</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Europ. Phys. J. ST, 225 (2016) 1945-1958</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1504.03232v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.03232v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.03874v1</id>
    <updated>2015-05-14T20:13:46Z</updated>
    <published>2015-05-14T20:13:46Z</published>
    <title>Homogenization and Clustering as a Technique to Compare Maintenance
  Strategies in Heterogeneous Production Settings</title>
    <summary>  We study the economic incentives to safeguard high levels of production
quality by maintenance, comparing three basic strategies commonly found in
industry: zero maintenance, inspection, and in-process monitoring. While zero
maintenance is the baseline strategy, we specifically focus on inspection
versus its technological rival monitoring, both maintenance strategies being
widespread in industry. With the unit production costs as the performance
measure, we identify mathematical conditions under which either strategy
outperforms the other two. Our model is based on a sequential production chain
with defect propensities and maintenance effectiveness as the main variables.
We develop a novel methodology based on canonical transformation to homogenize
heterogeneous production settings and discuss different clustering scenarios to
derive key trade-offs. Based on analytical and numerical study we find that
while zero maintenance is the most economical choice only at the margins of
perfection, monitoring outperforms inspection as a pure strategy in commonly
found defect ranges, specifically when (i) variable and fixed maintenance costs
are comparable and (ii) external quality effects such as reputation and
goodwill effects need to be considered. This general result even holds when
monitoring is less effective than inspection. The important practical value of
our analysis is the insight that a change from inspection to the hitherto
underrepresented monitoring might be economically more self-evident than
commonly assumed. The theoretical value of our approach rests on the
development of a new methodology to derive key insights from homogenization.
The methodology presented enables production engineers to get a clearer
economic assessment of maintenance strategies. Our findings have practical
value for all industries and service companies with standard operating
procedures.
</summary>
    <author>
      <name>Johannes Freiesleben</name>
    </author>
    <author>
      <name>Nicolas Guérin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">38 pages, 9 figures, 2 tables, full paper</arxiv:comment>
    <link href="http://arxiv.org/abs/1505.03874v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.03874v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.05669v2</id>
    <updated>2015-10-30T08:23:11Z</updated>
    <published>2015-05-21T10:38:08Z</published>
    <title>Optimal forest rotation age under efficient climate change mitigation</title>
    <summary>  This paper considers the optimal rotation of forests when the carbon flows of
forest growth and harvest are priced with an increasing price. Such an
evolution of carbon price is generally associated with economically efficient
climate change mitigation, and would provide incentives for the land-owner for
enhanced carbon sequestration. With an infinitely long sequence of even-aged
forest rotations, the optimal harvest age changes with subsequent rotations due
to the changing carbon price. The first-order optimality conditions therefore
also involve an infinite chain of lengths for consecutive forest rotations, and
allow the approximation of the infinite-time problem with a truncated series of
forest rotations.
  Illustrative numerical calculations show that when starting from bare land,
the initial carbon price and its growth rate both primarily increase the length
of the first rotation. With some combinations of the carbon pricing parameters,
the optimal harvest age can be several hundred years if the forest carbon is
released to the atmosphere upon harvest. This effect is not, however, entirely
monotonous. Consequently, the currently optimal harvest ages are generally
lower with higher rates of carbon price increase. This creates an interesting
temporal aspect, suggesting that the supply of wood and carbon sequestration by
forests can change considerably during subsequent rotations under an increasing
price on carbon.
</summary>
    <author>
      <name>Tommi Ekholm</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.forpol.2015.10.007</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.forpol.2015.10.007" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">in Forest Policy and Economics, 2015</arxiv:comment>
    <link href="http://arxiv.org/abs/1505.05669v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.05669v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.07907v4</id>
    <updated>2017-01-04T21:24:34Z</updated>
    <published>2015-05-29T02:18:51Z</published>
    <title>Linking Economic Complexity, Institutions and Income Inequality</title>
    <summary>  A country's mix of products predicts its subsequent pattern of
diversification and economic growth. But does this product mix also predict
income inequality? Here we combine methods from econometrics, network science,
and economic complexity to show that countries exporting complex products (as
measured by the Economic Complexity Index) have lower levels of income
inequality than countries exporting simpler products. Using multivariate
regression analysis, we show that economic complexity is a significant and
negative predictor of income inequality and that this relationship is robust to
controlling for aggregate measures of income, institutions, export
concentration, and human capital. Moreover, we introduce a measure that
associates a product to a level of income inequality equal to the average GINI
of the countries exporting that product (weighted by the share the product
represents in that country's export basket). We use this measure together with
the network of related products (or product space) to illustrate how the
development of new products is associated with changes in income inequality.
These findings show that economic complexity captures information about an
economy's level of development that is relevant to the ways an economy
generates and distributes its income. Moreover, these findings suggest that a
country's productive structure may limit its range of income inequality.
Finally, we make our results available through an online resource that allows
for its users to visualize the structural transformation of over 150 countries
and their associated changes in income inequality between 1963 and 2008.
</summary>
    <author>
      <name>D. Hartmann</name>
    </author>
    <author>
      <name>M. R. Guevara</name>
    </author>
    <author>
      <name>C. Jara-Figueroa</name>
    </author>
    <author>
      <name>M. Aristaran</name>
    </author>
    <author>
      <name>C. A. Hidalgo</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.worlddev.2016.12.020</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.worlddev.2016.12.020" rel="related"/>
    <link href="http://arxiv.org/abs/1505.07907v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.07907v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.06669v3</id>
    <updated>2016-07-12T20:28:38Z</updated>
    <published>2015-06-22T16:23:51Z</published>
    <title>Understanding the Impact of Microcredit Expansions: A Bayesian
  Hierarchical Analysis of 7 Randomised Experiments</title>
    <summary>  Bayesian hierarchical models are a methodology for aggregation and synthesis
of data from heterogeneous settings, used widely in statistics and other
disciplines. I apply this framework to the evidence from 7 randomized
experiments of expanding access to microcredit to assess the general impact of
the intervention on household outcomes and the heterogeneity in this impact
across sites. The results suggest that the effect of microcredit is likely to
be positive but small relative to control group average levels, and the
possibility of a negative impact cannot be ruled out. By contrast, common
meta-analytic methods that pool all the data without assessing the
heterogeneity misleadingly produce "statistically significant" results in 2 of
the 6 household outcomes. Standard pooling metrics for the studies indicate on
average 60% pooling on the treatment effects, suggesting that the site-specific
effects are reasonably externally valid, and thus informative for each other
and for the general case. The cross-study heterogeneity is almost entirely
generated by heterogeneous effects for the 27% households who previously
operated businesses before microcredit expansion, although this group is likely
to see much larger impacts overall. A Ridge regression procedure to assess the
correlations between site-specific covariates and treatment effects indicates
that the remaining heterogeneity is strongly correlated with differences in
economic variables, but not with differences in study design protocols. The
average interest rate and the average loan size have the strongest correlation
with the treatment effects, and both are negative.
</summary>
    <author>
      <name>Rachael Meager</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This draft is preliminary and incomplete; future versions of this
  paper will contain substantive additional results</arxiv:comment>
    <link href="http://arxiv.org/abs/1506.06669v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.06669v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.07368v4</id>
    <updated>2015-09-17T11:58:18Z</updated>
    <published>2015-06-24T14:00:41Z</published>
    <title>On Game-Theoretic Risk Management (Part One) - Towards a Theory of Games
  with Payoffs that are Probability-Distributions</title>
    <summary>  Optimal behavior in (competitive) situation is traditionally determined with
the help of utility functions that measure the payoff of different actions.
Given an ordering on the space of revenues (payoffs), the classical axiomatic
approach of von Neumann and Morgenstern establishes the existence of suitable
utility functions, and yields to game-theory as the most prominent
materialization of a theory to determine optimal behavior. Although this
appears to be a most natural approach to risk management too, applications in
critical infrastructures often violate the implicit assumption of actions
leading to deterministic consequences. In that sense, the gameplay in a
critical infrastructure risk control competition is intrinsically random in the
sense of actions having uncertain consequences. Mathematically, this takes us
to utility functions that are probability-distribution-valued, in which case we
loose the canonic (in fact every possible) ordering on the space of payoffs,
and the original techniques of von Neumann and Morgenstern no longer apply.
  This work introduces a new kind of game in which uncertainty applies to the
payoff functions rather than the player's actions (a setting that has been
widely studied in the literature, yielding to celebrated notions like the
trembling hands equilibrium or the purification theorem). In detail, we show
how to fix the non-existence of a (canonic) ordering on the space of
probability distributions by only mildly restricting the full set to a subset
that can be totally ordered. Our vehicle to define the ordering and establish
basic game-theory is non-standard analysis and hyperreal numbers.
</summary>
    <author>
      <name>Stefan Rass</name>
    </author>
    <link href="http://arxiv.org/abs/1506.07368v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.07368v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.00578v1</id>
    <updated>2015-06-30T06:17:48Z</updated>
    <published>2015-06-30T06:17:48Z</published>
    <title>Analysis of Professional Trajectories using Disconnected Self-Organizing
  Maps</title>
    <summary>  In this paper we address an important economic question. Is there, as
mainstream economic theory asserts it, an homogeneous labor market with
mechanisms which govern supply and demand for work, producing an equilibrium
with its remarkable properties? Using the Panel Study of Income Dynamics (PSID)
collected on the period 1984-2003, we study the situations of American workers
with respect to employment. The data include all heads of household (men or
women) as well as the partners who are on the labor market, working or not.
They are extracted from the complete survey and we compute a few relevant
features which characterize the worker's situations. To perform this analysis,
we suggest using a Self-Organizing Map (SOM, Kohonen algorithm) with specific
structure based on planar graphs, with disconnected components (called D-SOM),
especially interesting for clustering. We compare the results to those obtained
with a classical SOM grid and a star-shaped map (called SOS). Each component of
D-SOM takes the form of a string and corresponds to an organized cluster. From
this clustering, we study the trajectories of the individuals among the classes
by using the transition probability matrices for each period and the
corresponding stationary distributions. As a matter of fact, we find clear
evidence of heterogeneous parts, each one with high homo-geneity, representing
situations well identified in terms of activity and wage levels and in degree
of stability in the workplace. These results and their interpretation in
economic terms contribute to the debate about flexibility which is commonly
seen as a way to obtain a better level of equilibrium on the labor market.
</summary>
    <author>
      <name>Etienne Côme</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IFSTTAR/COSYS/GRETTIA</arxiv:affiliation>
    </author>
    <author>
      <name>Marie Cottrell</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">SAMM</arxiv:affiliation>
    </author>
    <author>
      <name>Patrice Gaubert</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">ERUDITE</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.neucom.2013.12.058</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.neucom.2013.12.058" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Neurocomputing, Elsevier, 2014, 147, pp.185-196</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1507.00578v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.00578v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.03169v1</id>
    <updated>2015-07-11T23:12:57Z</updated>
    <published>2015-07-11T23:12:57Z</published>
    <title>Intransitivity in Theory and in the Real World</title>
    <summary>  This work considers reasons for and implications of discarding the assumption
of transitivity, which (transitivity) is the fundamental postulate in the
utility theory of Von Neumann and Morgenstern, the adiabatic accessibility
principle of Caratheodory and most other theories related to preferences or
competition. The examples of intransitivity are drawn from different fields,
such as law, biology, game theory, economics and competitive evolutionary
dynamic. This work is intended as a common platform that allows us to discuss
intransitivity in the context of different disciplines. The basic concepts and
terms that are needed for consistent treatment of intransitivity in various
applications are presented and analysed in a unified manner. The analysis
points out conditions that necessitate appearance of intransitivity, such as
multiplicity of preference criteria and imperfect (i.e. approximate)
discrimination of different cases. The present work observes that with
increasing presence and strength of intransitivity, thermodynamics gradually
fades away leaving space for more general kinetic considerations.
Intransitivity in competitive systems is linked to complex phenomena that would
be difficult or impossible to explain on the basis of transitive assumptions.
Human preferences that seem irrational from the perspective of the conventional
utility theory, become perfectly logical in the intransitive and relativistic
framework suggested here. The example of competitive simulations for the
risk/benefit dilemma demonstrates the significance of intransitivity in cyclic
behaviour and abrupt changes in the system. The evolutionary intransitivity
parameter, which is introduced in the Appendix, is a general measure of
intransitivity, which is particularly useful in evolving competitive systems.
Quantum preferences are also considered in the Appendix.
</summary>
    <author>
      <name>A. Y. Klimenko</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.3390/e17064364</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.3390/e17064364" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">44 pages, 14 figures, 47 references, 6 appendices</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Entropy 2015, 17, 4364-4412</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1507.03169v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.03169v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.04065v3</id>
    <updated>2016-06-08T18:14:05Z</updated>
    <published>2015-07-15T01:36:49Z</published>
    <title>Reputational Learning and Network Dynamics</title>
    <summary>  In many real world networks agents are initially unsure of each other's
qualities and must learn about each other over time via repeated interactions.
This paper is the first to provide a methodology for studying the dynamics of
such networks, taking into account that agents differ from each other, that
they begin with incomplete information, and that they must learn through past
experiences which connections/links to form and which to break. The network
dynamics in our model vary drastically from the dynamics in models of complete
information. With incomplete information and learning, agents who provide high
benefits will develop high reputations and remain in the network, while agents
who provide low benefits will drop in reputation and become ostracized. We
show, among many other things, that the information to which agents have access
and the speed at which they learn and act can have a tremendous impact on the
resulting network dynamics. Using our model, we can also compute the ex ante
social welfare given an arbitrary initial network, which allows us to
characterize the socially optimal network structures for different sets of
agents. Importantly, we show through examples that the optimal network
structure depends sharply on both the initial beliefs of the agents, as well as
the rate of learning by the agents. Due to the potential negative consequences
of ostracism, it may be necessary to place agents with lower initial
reputations at less central positions within the network.
</summary>
    <author>
      <name>Simpson Zhang</name>
    </author>
    <author>
      <name>Mihaela van der Schaar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Added Agent Re-Entry Section Added Simulations Modified Literature
  Review Expanded Star Networks Section</arxiv:comment>
    <link href="http://arxiv.org/abs/1507.04065v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.04065v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.06242v2</id>
    <updated>2015-11-04T15:06:17Z</updated>
    <published>2015-07-22T16:31:03Z</published>
    <title>Return spillovers around the globe: A network approach</title>
    <summary>  Using a rolling windows analysis of filtered and aligned stock index returns
from 40 countries during the period 2006-2014, we construct Granger causality
networks and investigate the ensuing structure of the relationships by studying
network properties and fitting spatial probit models. We provide evidence that
stock market volatility and market size increases, while foreign exchange
volatility decreases the probability of return spillover from a given market.
We also show that market development and returns on the foreign exchange market
and stock market also matter, but they exhibit significant time-varying
behaviour with alternating effects. These results suggest that higher market
integration periods are alternated with periods where investors appear to be
chasing returns. Despite the significance of market characteristics and market
conditions, what in reality matters for information propagation is the temporal
distance between closing hours, i.e. the temporal proximity effect. This
implies that choosing markets which trade in similar hours bears additional
costs to investors, as the probability of return spillovers increases. The same
effect was observed with regard to the temporal distance to the US market.
Finally, we confirm the existence of the preferential attachment effect, i.e.
the probability of a given market to propagate return spillovers to a new
market depends endogenously and positively on the existing number of return
spillovers from that market.
</summary>
    <author>
      <name>Stefan Lyocsa</name>
    </author>
    <author>
      <name>Tomas Vyrost</name>
    </author>
    <author>
      <name>Eduard Baumohl</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This work was supported by the Slovak Research and Development Agency
  under the contract No. APVV-0666-11 and No. APVV-14-0357. Authors also
  appreciate the support provided from the Slovak Grant Agency for Science
  (VEGA project No. 1/0392/15)</arxiv:comment>
    <link href="http://arxiv.org/abs/1507.06242v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.06242v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.00975v2</id>
    <updated>2015-09-29T04:29:00Z</updated>
    <published>2015-08-05T05:19:17Z</published>
    <title>Symmetry restoration by pricing in a duopoly of perishable goods</title>
    <summary>  Competition is a main tenet of economics, and the reason is that a perfectly
competitive equilibrium is Pareto-efficient in the absence of externalities and
public goods. Whether a product is selected in a market crucially relates to
its competitiveness, but the selection in turn affects the landscape of
competition. Such a feedback mechanism has been illustrated in a duopoly model
by Lambert et al., in which a buyer's satisfaction is updated depending on the
{\em freshness} of a purchased product. The probability for buyer $n$ to select
seller $i$ is assumed to be $p_{n,i} \propto e^{ S_{n,i}/T}$, where $S_{n,i}$
is the buyer's satisfaction and $T$ is an effective temperature to introduce
stochasticity. If $T$ decreases below a critical point $T_c$, the system
undergoes a transition from a symmetric phase to an asymmetric one, in which
only one of the two sellers is selected. In this work, we extend the model by
incorporating a simple price system. By considering a greed factor $g$ to
control how the satisfaction depends on the price, we argue the existence of an
oscillatory phase in addition to the symmetric and asymmetric ones in the
$(T,g)$ plane, and estimate the phase boundaries through mean-field
approximations. The analytic results show that the market preserves the
inherent symmetry between the sellers for lower $T$ in the presence of the
price system, which is confirmed by our numerical simulations.
</summary>
    <author>
      <name>Su Do Yi</name>
    </author>
    <author>
      <name>Seung Ki Baek</name>
    </author>
    <author>
      <name>Guillaume Chevereau</name>
    </author>
    <author>
      <name>Eric Bertin</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1088/1742-5468/2015/11/P11001</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1088/1742-5468/2015/11/P11001" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1508.00975v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.00975v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1509.01482v1</id>
    <updated>2015-09-04T15:03:56Z</updated>
    <published>2015-09-04T15:03:56Z</published>
    <title>Measuring economic complexity of countries and products: which metric to
  use?</title>
    <summary>  Evaluating the economies of countries and their relations with products in
the global market is a central problem in economics, with far-reaching
implications to our theoretical understanding of the international trade as
well as to practical applications, such as policy making and financial
investment planning. The recent Economic Complexity approach aims to quantify
the competitiveness of countries and the quality of the exported products based
on the empirical observation that the most competitive countries have
diversified exports, whereas developing countries only export few low quality
products -- typically those exported by many other countries. Two different
metrics, Fitness-Complexity and the Method of Reflections, have been proposed
to measure country and product score in the Economic Complexity framework. We
use international trade data and a recent ranking evaluation measure to
quantitatively compare the ability of the two metrics to rank countries and
products according to their importance in the network. The results show that
the Fitness-Complexity metric outperforms the Method of Reflections in both the
ranking of products and the ranking of countries. We also investigate a
Generalization of the Fitness-Complexity metric and show that it can produce
improved rankings provided that the input data are reliable.
</summary>
    <author>
      <name>Manuel Sebastian Mariani</name>
    </author>
    <author>
      <name>Alexandre Vidmer</name>
    </author>
    <author>
      <name>Matus Medo</name>
    </author>
    <author>
      <name>Yi-Cheng Zhang</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1140/epjb/e2015-60298-7</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1140/epjb/e2015-60298-7" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">The European Physical Journal B 88 (11), 1-9 (2015)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1509.01482v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1509.01482v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1509.04264v2</id>
    <updated>2015-11-25T13:00:05Z</updated>
    <published>2015-09-12T11:46:00Z</published>
    <title>Agent based simulations visualize Adam Smith's invisible hand by solving
  Friedrich Hayek's Economic Calculus</title>
    <summary>  Inspired by Adam Smith and Friedrich Hayek, many economists have postulated
the existence of invisible forces that drive economic markets. These market
forces interact in complex ways making it difficult to visualize or understand
the interactions in every detail. Here I show how these forces can transcend a
zero-sum game and become a win-win business interaction, thanks to emergent
social synergies triggered by division of labor. Computer simulations with the
model Sociodynamica show here the detailed dynamics underlying this phenomenon
in a simple virtual economy. In these simulations, independent agents act in an
economy exploiting and trading two different goods in a heterogeneous
environment. All and each of the various forces and individuals were tracked
continuously, allowing to unveil a synergistic effect on economic output
produced by the division of labor between agents. Running simulations in a
homogeneous environment, for example, eliminated all benefits of division of
labor. The simulations showed that the synergies unleashed by division of labor
arise if: Economies work in a heterogeneous environment; agents engage in
complementary activities whose optimization processes diverge; agents have
means to synchronize their activities. This insight, although trivial if viewed
a posteriori, improve our understanding of the source and nature of synergies
in real economic markets and might render economic and natural sciences more
consilient.
</summary>
    <author>
      <name>Klaus Jaffe</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Econophysics, Complexity, Synergy</arxiv:comment>
    <link href="http://arxiv.org/abs/1509.04264v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1509.04264v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1509.06544v5</id>
    <updated>2017-06-26T13:52:58Z</updated>
    <published>2015-09-22T10:48:08Z</published>
    <title>Pricing and Referrals in Diffusion on Networks</title>
    <summary>  When a new product or technology is introduced, potential consumers can learn
its quality by trying the product, at a risk, or by letting others try it and
free-riding on the information that they generate. We propose a dynamic game to
study the adoption of technologies of uncertain value, when agents are
connected by a network and a monopolist seller chooses a policy to maximize
profits. Consumers with low degree (few friends) have incentives to adopt
early, while consumers with high degree have incentives to free ride. The
seller can induce high-degree consumers to adopt early by offering referral
incentives - rewards to early adopters whose friends buy in the second period.
Referral incentives thus lead to a `double-threshold strategy' by which low and
high-degree agents adopt the product early while middle-degree agents wait. We
show that referral incentives are optimal on certain networks while
inter-temporal price discrimination (i.e., a first-period price discount) is
optimal on others, and discuss welfare implications.
</summary>
    <author>
      <name>Matt V. Leduc</name>
    </author>
    <author>
      <name>Matthew O. Jackson</name>
    </author>
    <author>
      <name>Ramesh Johari</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.geb.2017.05.011</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.geb.2017.05.011" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">44 pages, 3 tables, 8 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Games and Economic Behavior 104 (2017) 568-594</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1509.06544v5" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1509.06544v5" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91D30, 05C82, 91A43" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.06812v4</id>
    <updated>2017-04-02T15:29:17Z</updated>
    <published>2015-10-23T02:47:01Z</published>
    <title>Game-theoretic Modeling of Players' Ambiguities on External Factors</title>
    <summary>  We propose a game-theoretic framework that incorporates both incomplete
information and general ambiguity attitudes on factors external to all players.
Our starting point is players' preferences on payoff-distribution vectors,
essentially mappings from states of the world to distributions of payoffs to be
received by players. There are two ways in which equilibria for this preference
game can be defined. When the preferences possess ever more features, we can
gradually add ever more structures to the game. These include real-valued
utility-like functions over payoff-distribution vectors, sets of probabilistic
priors over states of the world, and eventually the traditional
expected-utility framework involving one single prior. We establish equilibrium
existence results, show the upper hemi-continuity of equilibrium sets over
changing ambiguity attitudes, and uncover relations between the two versions of
equilibria. Some attention is paid to the enterprising game, in which players
exhibit ambiguity seeking attitudes while betting optimistically on the
favorable resolution of ambiguities. The two solution concepts are unified at
this game's pure equilibria, whose existence is guaranteed when strategic
complementarities are present. The current framework can be applied to settings
like auctions involving ambiguity on competitors' assessments of item worths.
</summary>
    <author>
      <name>Jian Yang</name>
    </author>
    <link href="http://arxiv.org/abs/1510.06812v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.06812v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.07927v2</id>
    <updated>2017-08-30T11:20:51Z</updated>
    <published>2015-10-20T21:52:42Z</published>
    <title>Emergence of Cooperative Long-term Market Loyalty in Double Auction
  Markets</title>
    <summary>  Loyal buyer-seller relationships can arise by design, e.g. when a seller
tailors a product to a specific market niche to accomplish the best possible
returns, and buyers respond to the dedicated efforts the seller makes to meet
their needs. We ask whether it is possible, instead, for loyalty to arise
spontaneously, and in particular as a consequence of repeated interaction and
co-adaptation among the agents in a market. We devise a stylized model of
double auction markets and adaptive traders that incorporates these features.
Traders choose where to trade (which market) and how to trade (to buy or to
sell) based on their previous experience. We find that when the typical scale
of market returns (or, at fixed scale of returns, the intensity of choice)
become higher than some threshold, the preferred state of the system is
segregated: both buyers and sellers are segmented into subgroups that are
persistently loyal to one market over another. We characterize the segregated
state analytically in the limit of large markets: it is stabilized by some
agents acting cooperatively to enable trade, and provides higher rewards than
its unsegregated counterpart both for individual traders and the population as
a whole.
</summary>
    <author>
      <name>Aleksandra Aloric</name>
    </author>
    <author>
      <name>Peter Sollich</name>
    </author>
    <author>
      <name>Peter McBurney</name>
    </author>
    <author>
      <name>Tobias Galla</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1371/journal.pone.0154606</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1371/journal.pone.0154606" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">33 pages, 11 figures; referee remarks included, published: April 27,
  2016</arxiv:comment>
    <link href="http://arxiv.org/abs/1510.07927v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.07927v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.TR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.00065v1</id>
    <updated>2015-10-31T03:30:44Z</updated>
    <published>2015-10-31T03:30:44Z</published>
    <title>A New Class of Problems in the Calculus of Variations</title>
    <summary>  This paper investigates an infinite-horizon problems in the one-dimensional
calculus of variations, arising from the Ramsey model of endogeneous economic
growth. Following Chichilnisky, we introduce an additional term, which models
concern for the well-being of future generations. We show that there are no
optimal solutions, but that there are equilibrium strateges, i.e. Nash
equilibria of the leader-follower game between successive generations. To solve
the problem, we approximate the Chichilnisky criterion by a biexponential
criterion, we characterize its equilibria by a pair of coupled differential
equations of HJB type, and we go to the limit. We find all the equilibrium
strategies for the Chichilnisky criterion. The mathematical analysis is
difficult because one has to solve an implicit differential equation in the
sense of Thom. Our analysis extends earlier work by Ekeland and Lazrak. It is
shown that optimal solutions a class of problems raising from time
inconsistency problems in the framework of the neoclassical one-sector model of
economic growth, and contains new results in environment economics. Without
exogenous commitment mechanism, a notion of the equilibrium strategies instead
of the optimal strategies is introduced. We characterized the equilibrium
strategies by an integro-differential equation system. For two special
criteria, the bi-exponential criteria and the Chichilnisky criteria, we
established the existence of the equilibrium strategies.
</summary>
    <author>
      <name>Ivar Ekeland</name>
    </author>
    <author>
      <name>Yiming Long</name>
    </author>
    <author>
      <name>Qinglong Zhou</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1134/S1560354713060026</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1134/S1560354713060026" rel="related"/>
    <link href="http://arxiv.org/abs/1511.00065v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.00065v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="49J40, 91B02, 49L99" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1512.02912v1</id>
    <updated>2015-12-09T15:53:21Z</updated>
    <published>2015-12-09T15:53:21Z</published>
    <title>The role of money and the financial sector in energy-economy models used
  for assessing climate policy</title>
    <summary>  This paper outlines a critical gap in the assessment methodology used to
estimate the macroeconomic costs and benefits of climate policy. It shows that
the vast majority of models used for assessing climate policy use assumptions
about the financial system that sit at odds with the observed reality. In
particular, the models' assumptions lead to `crowding out' of capital, which
cause them to show negative impacts from climate policy in virtually all cases.
We compare this approach with that of the E3ME model, which follows
non-equilibrium economic theory and adopts a more empirical approach. While the
non-equilibrium model also has limitations, its treatment of the financial
system is more consistent with reality and it shows that green investment need
not crowd out investment in other parts of the economy -- and may therefore
offer an economic stimulus.
  The implication of this finding is that standard CGE models consistently
over-estimate the costs of climate policy in terms of GDP and welfare,
potentially by a substantial amount. These findings overly restrict the range
of possible emission pathways accessible using climate policy from the
viewpoint of the decision-maker, and may also lead to misleading information
used for policy making. Improvements in both modelling approaches should be
sought with some urgency -- both to provide a better assessment of potential
climate policy and to improve understanding of the dynamics of the global
financial system more generally.
</summary>
    <author>
      <name>H. Pollitt</name>
    </author>
    <author>
      <name>J. -F. Mercure</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1080/14693062.2016.1277685</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1080/14693062.2016.1277685" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6000 words, 12 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Climate Policy 2017</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1512.02912v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1512.02912v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1512.08067v2</id>
    <updated>2016-02-27T05:20:16Z</updated>
    <published>2015-12-26T02:52:39Z</published>
    <title>Unified Growth Theory Contradicted by the Economic Growth in Europe</title>
    <summary>  Historical economic growth in Western and Eastern Europe is analysed. These
regions should have produced the best and the most convincing confirmation of
the Unified Growth Theory because they, and in particular Western Europe, were
the centre of the Industrial Revolution, which according to Galor was the prime
engine of economic growth. However, the data for Western and Eastern Europe
show a remarkable disagreement with the Unified Growth Theory. There is no
connection, whatever, between the data and the Unified Growth Theory. The data
show that there was never a transition from stagnation to growth because there
was no stagnation. Industrial Revolution, which should have the strongest
influence in these regions, had absolutely no impact on changing the economic
growth trajectories. The alleged remarkable or stunning escape from Malthusian
trap did not happen because there was no trap. Unified Growth Theory does not
explain the mechanism of the economic growth because its explanations are based
on mythical features, which did not exist, the features contradicted by data.
This theory needs to be either thoroughly revised or most likely replaced by a
theory supported by a professional analysis of economic growth data.
</summary>
    <author>
      <name>Ron W Nielsen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 6 figures, 3989 words; fourth paper in the series of 5
  discussing economic growth in Africa, Asia, former USSR, Europe and Latin
  America</arxiv:comment>
    <link href="http://arxiv.org/abs/1512.08067v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1512.08067v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.02677v2</id>
    <updated>2016-02-23T02:47:00Z</updated>
    <published>2016-01-11T22:38:24Z</published>
    <title>Dependence of technological improvement on artifact interactions</title>
    <summary>  Empirical research has shown performance improvement of many different
technological domains occurs exponentially but with widely varying improvement
rates. What causes some technologies to improve faster than others do? Previous
quantitative modeling research has identified artifact interactions, where a
design change in one component influences others, as an important determinant
of improvement rates. The models predict that improvement rate for a domain is
proportional to the inverse of the domain interaction parameter. However, no
empirical research has previously studied and tested the dependence of
improvement rates on artifact interactions. A challenge to testing the
dependence is that any method for measuring interactions has to be applicable
to a wide variety of technologies. Here we propose a patent-based method that
is both technology domain-agnostic and less costly than alternative methods. We
use textual content from patent sets in 27 domains to find the influence of
interactions on improvement rates. Qualitative analysis identified six specific
keywords that signal artifact interactions. Patent sets from each domain were
then examined to determine the total count of these 6 keywords in each domain,
giving an estimate of artifact interactions in each domain. It is found that
improvement rates are positively correlated with the inverse of the total count
of keywords with correlation coefficient of +0.56 with a p-value of 0.002. The
empirical results agree with model predictions and support the suggestion that
domains with higher number of artifacts interactions (higher complexity) will
improve at a slower pace.
</summary>
    <author>
      <name>Subarna Basnet</name>
    </author>
    <author>
      <name>Christopher L. Magee</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Main manuscript: 18 pages including, 5 figures; supplemental
  information: 30 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1601.02677v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.02677v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1602.02348v4</id>
    <updated>2016-12-07T08:15:33Z</updated>
    <published>2016-02-07T08:03:19Z</published>
    <title>Economic and Technological Complexity: A Model Study of Indicators of
  Knowledge-based Innovation Systems</title>
    <summary>  The Economic Complexity Index (ECI; Hidalgo &amp; Hausmann, 2009) measures the
complexity of national economies in terms of product groups. Analogously to
ECI, a Patent Complexity Index (PatCI) can be developed on the basis of a
matrix of nations versus patent classes. Using linear algebra, the three
dimensions: countries, product groups, and patent classes can be combined into
a measure of "Triple Helix" complexity (THCI) including the trilateral
interaction terms between knowledge production, wealth generation, and
(national) control. THCI can be expected to capture the extent of systems
integration between the global dynamics of markets (ECI) and technologies
(PatCI) in each national system of innovation. We measure ECI, PatCI, and THCI
during the period 2000-2014 for the 34 OECD member states, the BRICS countries,
and a group of emerging and affiliated economies (Argentina, Hong Kong,
Indonesia, Malaysia, Romania, and Singapore). The three complexity indicators
are correlated between themselves; but the correlations with GDP per capita are
virtually absent. Of the world's major economies, Japan scores highest on all
three indicators, while China has been increasingly successful in combining
economic and technological complexity. We could not reproduce the correlation
between ECI and average income that has been central to the argument about the
fruitfulness of the economic complexity approach.
</summary>
    <author>
      <name>Inga Ivanova</name>
    </author>
    <author>
      <name>Oivind Strand</name>
    </author>
    <author>
      <name>Duncan Kushnir</name>
    </author>
    <author>
      <name>Loet Leydesdorff</name>
    </author>
    <link href="http://arxiv.org/abs/1602.02348v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1602.02348v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1602.09071v1</id>
    <updated>2016-02-29T18:01:09Z</updated>
    <published>2016-02-29T18:01:09Z</published>
    <title>Fairs for e-commerce: the benefits of aggregating buyers and sellers</title>
    <summary>  In recent years, many new and interesting models of successful online
business have been developed. Many of these are based on the competition
between users, such as online auctions, where the product price is not fixed
and tends to rise. Other models, including group-buying, are based on
cooperation between users, characterized by a dynamic price of the product that
tends to go down. There is not yet a business model in which both sellers and
buyers are grouped in order to negotiate on a specific product or service. The
present study investigates a new extension of the group-buying model, called
fair, which allows aggregation of demand and supply for price optimization, in
a cooperative manner. Additionally, our system also aggregates products and
destinations for shipping optimization. We introduced the following new
relevant input parameters in order to implement a double-side aggregation: (a)
price-quantity curves provided by the seller; (b) waiting time, that is, the
longer buyers wait, the greater discount they get; (c) payment time, which
determines if the buyer pays before, during or after receiving the product; (d)
the distance between the place where products are available and the place of
shipment, provided in advance by the buyer or dynamically suggested by the
system. To analyze the proposed model we implemented a system prototype and a
simulator that allow to study effects of changing some input parameters. We
analyzed the dynamic price model in fairs having one single seller and a
combination of selected sellers. The results are very encouraging and motivate
further investigation on this topic.
</summary>
    <author>
      <name>Pierluigi Gallo</name>
    </author>
    <author>
      <name>Francesco Randazzo</name>
    </author>
    <author>
      <name>Ignazio Gallo</name>
    </author>
    <link href="http://arxiv.org/abs/1602.09071v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1602.09071v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.00850v3</id>
    <updated>2016-07-11T14:33:23Z</updated>
    <published>2016-03-02T20:16:10Z</published>
    <title>Tipping elements and climate-economic shocks: Pathways toward integrated
  assessment</title>
    <summary>  The literature on the costs of climate change often draws a link between
climatic 'tipping points' and large economic shocks, frequently called
'catastrophes'. The use of the phrase 'tipping points' in this context can be
misleading. In popular and social scientific discourse, 'tipping points'
involve abrupt state changes. For some climatic 'tipping points,' the
commitment to a state change may occur abruptly, but the change itself may be
rate-limited and take centuries or longer to realize. Additionally, the
connection between climatic 'tipping points' and economic losses is tenuous,
though emerging empirical and process-model-based tools provide pathways for
investigating it. We propose terminology to clarify the distinction between
'tipping points' in the popular sense, the critical thresholds exhibited by
climatic and social 'tipping elements,' and 'economic shocks'. The last may be
associated with tipping elements, gradual climate change, or non-climatic
triggers. We illustrate our proposed distinctions by surveying the literature
on climatic tipping elements, climatically sensitive social tipping elements,
and climate-economic shocks, and we propose a research agenda to advance the
integrated assessment of all three.
</summary>
    <author>
      <name>Robert E. Kopp</name>
    </author>
    <author>
      <name>Rachael Shwom</name>
    </author>
    <author>
      <name>Gernot Wagner</name>
    </author>
    <author>
      <name>Jiacan Yuan</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1002/2016EF000362</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1002/2016EF000362" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">43 pages, 2 figure, 2 tables. Published in Earth's Future</arxiv:comment>
    <link href="http://arxiv.org/abs/1603.00850v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.00850v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.01685v3</id>
    <updated>2016-04-29T21:15:09Z</updated>
    <published>2016-03-05T06:30:18Z</published>
    <title>Mathematical analysis of historical income per capita distributions</title>
    <summary>  Data describing historical growth of income per capita [Gross Domestic
Product per capita (GDP/cap)] for the world economic growth and for the growth
in Western Europe, Eastern Europe, Asia, former USSR, Africa and Latin America
are analysed. They follow closely the linearly-modulated hyperbolic
distributions represented by the ratios of hyperbolic distributions obtained by
fitting the GDP and population data. Results of this analysis demonstrate that
income per capita was increasing monotonically. There was no stagnation and
there were no transitions from stagnation to growth. The usually postulated
dramatic escapes from the Malthusian trap never happened because there was no
trap. Unified Growth Theory is fundamentally incorrect because its central
postulates are contradicted repeatedly by data, which were used but never
analysed during the formulation of this theory. The large body of
readily-available data opens new avenues for the economic and demographic
research. They show that certain fundamental postulates revolving around the
concept of Malthusian stagnation need to be replaced by the evidence-based
interpretations. Within the range of analysable data, which for the growth of
population extends down to 10,000 BC, growth of human population and economic
growth were hyperbolic. There was no Malthusian stagnation and there were no
transitions to distinctly faster trajectories. Industrial Revolution had no
impact on changing growth trajectories.
</summary>
    <author>
      <name>Ron W Nielsen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages, 8 figures, 1 table, 8331 words</arxiv:comment>
    <link href="http://arxiv.org/abs/1603.01685v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.01685v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.08344v2</id>
    <updated>2016-05-11T00:27:08Z</updated>
    <published>2016-03-28T09:00:44Z</published>
    <title>The unresolved mystery of the great divergence is solved</title>
    <summary>  The so-called great divergence in the income per capita is described in the
Unified Growth Theory as the mind-boggling and unresolved mystery about the
growth process. This mystery has now been solved: the great divergence never
happened. It was created by the manipulation of data. Economic growth in
various regions is at different levels of development but it follows similar,
non-divergent trajectories. Unified Growth Theory is shown yet again to be
incorrect and scientifically unacceptable. It promotes incorrect and even
potentially dangerous concepts. The distorted presentation of data supporting
the concept of the great divergence shows that economic growth is now
developing along moderately-increasing trajectories but mathematical analysis
of the same data and even their undistorted presentation shows that these
trajectories are now increasing approximately vertically with time. So, while
the distorted presentation of data used in the Unified Growth Theory suggests
generally sustainable and secure economic growth, the undistorted presentation
of data demonstrates that the growth is unsustainable and insecure. The concept
of takeoffs from stagnation to the sustained-growth regime promoted in the
Unified Growth Theory is also dangerously misleading because it suggests a
sustainable and prosperous future while the mathematical analysis of data shows
that the current economic growth is insecure and unsustainable.
</summary>
    <author>
      <name>Ron W Nielsen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">26pages, 19 figures, 9282 words</arxiv:comment>
    <link href="http://arxiv.org/abs/1603.08344v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.08344v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.04223v1</id>
    <updated>2016-04-14T17:17:56Z</updated>
    <published>2016-04-14T17:17:56Z</published>
    <title>On the survival of poor peasants</title>
    <summary>  Previously, in underdeveloped countries, people tried to keep the prices of
food products artificially low, in order to help the poor to buy their food.
But it became soon clear that such system, although helpful for the city poor,
was disastrous for the peasants (who usually are even poorer), so that hunger
increased, instead of decreasing. More recently, thus, higher prices have been
imposed. But a high-price system does not solve the problems. It helps, indeed,
a peasant to buy in the city non-edible products, but not to buy (more
expensive) food products from other peasants. The question is discussed here in
more detail starting from the simplest conceivable case of two peasants
producing each a different food product (bread and cheese, say), then
generalizing to several food items and to any number of peasants producing a
given food item j. Like in every economic system which wants to be sustainable,
or able to reproduce itself in a stationary state at least, prices are
determined by the necessity of exchanging "means of production" among
"industries", except that here industriesare replaced by working peasants and
means of production are replaced by food. It is found that prices must obey
certain inequalities related to the minimal amount of each food item necessary
for survival. Inequalities may be rewritten as equations and, in an important
special case, such equations give rise to a simple version of the matrix
equation used by famous authors to describe the economy.
</summary>
    <author>
      <name>Andrea C. Levi</name>
    </author>
    <author>
      <name>Ubaldo Garibaldi</name>
    </author>
    <link href="http://arxiv.org/abs/1604.04223v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.04223v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.03133v1</id>
    <updated>2016-05-10T18:09:59Z</updated>
    <published>2016-05-10T18:09:59Z</published>
    <title>Economic Development and Inequality: a complex system analysis</title>
    <summary>  By borrowing methods from complex system analysis, in this paper we analyze
the features of the complex relationship that links the development and the
industrialization of a country to economic inequality. In order to do this, we
identify industrialization as a combination of a monetary index, the GDP per
capita, and a recently introduced measure of the complexity of an economy, the
Fitness. At first we explore these relations on a global scale over the time
period 1990--2008 focusing on two different dimensions of inequality: the
capital share of income and a Theil measure of wage inequality. In both cases,
the movement of inequality follows a pattern similar to the one theorized by
Kuznets in the fifties. We then narrow down the object of study ad we
concentrate on wage inequality within the United States. By employing data on
wages and employment on the approximately 3100 US counties for the time
interval 1990--2014, we generalize the Fitness-Complexity algorithm for
counties and NAICS sectors, and we investigate wage inequality between
industrial sectors within counties. At this scale, in the early nineties we
recover a behavior similar to the global one. While, in more recent years, we
uncover a trend reversal: wage inequality monotonically increases as
industrialization levels grow. Hence at a county level, at net of the social
and institutional factors that differ among countries, we not only observe an
upturn in inequality but also a change in the structure of the relation between
wage inequality and development.
</summary>
    <author>
      <name>Angelica Sbardella</name>
    </author>
    <author>
      <name>Emanuele Pugliese</name>
    </author>
    <author>
      <name>Luciano Pietronero</name>
    </author>
    <link href="http://arxiv.org/abs/1605.03133v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.03133v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.02783v1</id>
    <updated>2016-06-08T23:27:11Z</updated>
    <published>2016-06-08T23:27:11Z</published>
    <title>A non-equilibrium formulation of food security resilience</title>
    <summary>  Resilience, the ability to recover from adverse events ("shocks"), is of
fundamental importance to food security. This is especially true in poor
countries, where basic needs are frequently threatened by economic,
environmental, and health shocks. An empirically sound formalization of the
concept of food security resilience, however, is lacking. Here we introduce a
general framework for quantifying resilience based on a simple definition: a
unit is resilient if $(a)$ its long-term food security trend is not
deteriorating and $(b)$ the effects of shocks on this trend do not persist over
time. Our approach can be applied to any food security variable for which
high-frequency time-series data is available, can accommodate any unit of
analysis (e.g., individuals, households, countries), and is especially useful
in rapidly changing contexts wherein standard equilibrium-based economic models
are ineffective. We illustrate our method with an analysis of per capita
kilocalorie availability for 161 countries between 1961 and 2011. We find that
resilient countries are not necessarily those that are characterized by high
levels or less volatile fluctuations of kilocalorie intake. Accordingly, food
security policies and programs will need to be tailored not only to welfare
levels at any one time, but also to long-run welfare dynamics.
</summary>
    <author>
      <name>Matteo Smerlak</name>
    </author>
    <author>
      <name>Bapu Vaitla</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1098/rsos.160874</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1098/rsos.160874" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 4 figures + appendix</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">R. Soc. open sci. 4: 160874 (2017)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1606.02783v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.02783v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.03595v5</id>
    <updated>2017-06-23T12:52:31Z</updated>
    <published>2016-06-11T13:47:49Z</published>
    <title>Incentivizing Resilience in Financial Networks</title>
    <summary>  When banks extend loans to each other, they generate a negative externality
in the form of systemic risk. They create a network of interbank exposures by
which they expose other banks to potential insolvency cascades. In this paper,
we show how a regulator can use information about the financial network to
devise a transaction-specific tax based on a network centrality measure that
captures systemic importance. Since different transactions have different
impact on creating systemic risk, they are taxed differently. We call this tax
a Systemic Risk Tax (SRT). We use an equilibrium concept inspired by the
matching markets literature to show analytically that this SRT induces a unique
equilibrium matching of lenders and borrowers that is systemic-risk efficient,
i.e. it minimizes systemic risk given a certain transaction volume. On the
other hand, we show that without this SRT multiple equilibrium matchings exist,
which are generally inefficient. This allows the regulator to effectively
stimulate a `rewiring' of the equilibrium interbank network so as to make it
more resilient to insolvency cascades, without sacrificing transaction volume.
Moreover, we show that a standard financial transaction tax (e.g. a Tobin-like
tax) has no impact on reshaping the equilibrium financial network because it
taxes all transactions indiscriminately. A Tobin-like tax is indeed shown to
have a limited effect on reducing systemic risk while it decreases transaction
volume.
</summary>
    <author>
      <name>Matt V. Leduc</name>
    </author>
    <author>
      <name>Stefan Thurner</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.jedc.2017.05.010</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.jedc.2017.05.010" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">38 pages, 9 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Economic Dynamics &amp; Control 82 (2017) 44-66</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1606.03595v5" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.03595v5" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.08984v1</id>
    <updated>2016-06-29T07:32:28Z</updated>
    <published>2016-06-29T07:32:28Z</published>
    <title>Optimal Consumption, Investment and Housing with Means-tested Public
  Pension in Retirement</title>
    <summary>  In this paper, we develop an expected utility model for the retirement
behavior in the decumulation phase of Australian retirees with sequential
family status subject to consumption, housing, investment, bequest and
government provided means-tested Age Pension. We account for mortality risk and
risky investment assets, and introduce a health proxy to capture the decreasing
level of consumption for older retirees. Then we find optimal housing at
retirement, and optimal consumption and optimal risky asset allocation
depending on age and wealth. The model is solved numerically as a stochastic
control problem, and is calibrated using the maximum likelihood method on
empirical data of consumption and housing from the Australian Bureau of
Statistics 2009-2010 Survey. The model fits the characteristics of the data
well to explain the behavior of Australian retirees. The key findings are the
following: First, the optimal policy is highly sensitive to means-tested Age
Pension early in retirement but this sensitivity fades with age. Secondly, the
allocation to risky assets shows a complex relationship with the means-tested
Age Pension that disappears once minimum withdrawal rules are enforced. As a
general rule, when wealth decreases the proportion allocated to risky assets
increases, due to the Age Pension working as a buffer against investment
losses. Finally, couples can be more aggressive with risky allocations due to
their longer life expectancy compared with singles.
</summary>
    <author>
      <name>Johan G. Andreasson</name>
    </author>
    <author>
      <name>Pavel V. Shevchenko</name>
    </author>
    <author>
      <name>Alex Novikov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">28 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1606.08984v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.08984v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.07398v1</id>
    <updated>2015-05-25T07:46:14Z</updated>
    <published>2015-05-25T07:46:14Z</published>
    <title>The fallacy of evidence based policy</title>
    <summary>  The use of science for policy is at the core of a perfect storm generated by
the insurgence of several concurrent crises: of science, of trust, of
sustainability. The modern positivistic model of science for policy, known as
evidence based policy, is based on dramatic simplifications and compressions of
available perceptions of the state of affairs and possible explanations
(hypocognition). This model can result in flawed prescriptions. The flaws
become more evident when dealing with complex issues characterized by
concomitant uncertainties in the normative, descriptive and ethical domains. In
this situation evidence-based policy may concur to the fragility of the social
system. Science plays an important role in reducing the feeling of
vulnerability of humans by projecting a promise of protection against
uncertainties. In many applications quantitative science is used to remove
uncertainty by transforming it into probability, so that mathematical modelling
can play the ritual role of haruspices. This epistemic governance arrangement
is today in crisis. The primacy of science to adjudicate political issues must
pass through an assessment of the level of maturity and effectiveness of the
various disciplines deployed. The solution implies abandoning dreams of
prediction, control and optimization obtained by relying on a limited set of
simplified narratives to define the problem and moving instead to an open
exploration of a broader set of plausible and relevant stories. Evidence based
policy has to be replaced by robust policy, where robustness is tested with
respect to feasibility (compatibility with processes outside human control);
viability (compatibility with processes under human control, in relation to
both the economic and technical dimensions), and desirability domain
(compatibility with a plurality of normative considerations relevant to a
plurality of actors).
</summary>
    <author>
      <name>Andrea Saltelli</name>
    </author>
    <author>
      <name>Mario Giampietro</name>
    </author>
    <link href="http://arxiv.org/abs/1607.07398v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.07398v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.6.0" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.05038v1</id>
    <updated>2016-08-16T05:17:34Z</updated>
    <published>2016-08-16T05:17:34Z</published>
    <title>Electoral Stability and Rigidity</title>
    <summary>  Some argue that political stability is best served through a two-party
system. This study refutes this. The author mathematically defines the
stability and rigidity of electoral systems comprised of any quantity of
electors and parties. In fact, stability is a function of the quantity of
electors - i.e., the number of occupied seats at the table. As the number of
electors increases, the properties of an electorate are increasingly well
resolved, and well described by those of an electorate that is least excessive
-- that is to say an electorate that is closest to equilibrium. Further,
electoral rigidity is a function of the quantity of parties and their
probabilities of representation. An absolutely rigid system admits no
fluctuations -- whatever happens to one elector will happen to all electors. As
the quantity of parties increases so does the number of party lines, and with
it the quantity of alternatives with which to respond to an external stimulus.
Rigidity is significant in a social system that places high value on party
loyalty. In conclusion, (i) electoral stability is best served by increasing
the quantity of electors; (ii) electoral rigidity is best served by decreasing
the quantity of parties, and by increasing the representation of some parties
at the expense of others; and (iii) the less stable a branch of government, the
more concern is placed on those who would hold those offices for the people.
</summary>
    <author>
      <name>Michael Y. Levy</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">34 pages (body = 28, appendix = 6), 3 Figures, 3 tables, includes 2
  apendices</arxiv:comment>
    <link href="http://arxiv.org/abs/1608.05038v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.05038v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.02334v1</id>
    <updated>2016-09-08T09:02:37Z</updated>
    <published>2016-09-08T09:02:37Z</published>
    <title>The interaction between trade and FDI: the CEE countries experience</title>
    <summary>  Inside the EU, the commercial integration of the CEE countries has gained
remarkable momentum before the crisis appearance, but it has slightly slowed
down afterwards. Consequently, the interest in identifying the factors
supporting the commercial integration process is high. Recent findings in the
new trade theory suggest that FDI influence the trade intensity but the studies
approaching this relationship for the CEE countries present mixed evidence, and
investigate the commercial integration of CEE countries with the old EU
members. Against this background, the purpose of this paper is to assess the
CEE countries' intra-integration, focusing on the Czech Republic, Hungary,
Poland and the Slovak Republic. For each country we employ a panel
gravitational model for the bilateral trade and FDI, considering its
interactions with the other three countries in the sample on the one hand, and
with the three EU main commercial partners on the other hand. We investigate
different facets of the trade -- FDI nexus, resorting to a fixed effects model,
a random effects model, as well as to an instrumental variable estimator, over
the period 2000-2013. Our results suggest that outward FDI sustains the CEE
countries' commercial integration, while inward FDI has no significant effect.
In all the cases a complementarity effect between trade and FDI is documented,
which is stronger for the CEE countries' historical trade partners.
Consequently, these findings show that CEE countries' policymakers are
interested in encouraging the outward FDI toward their neighbour countries in
order to increase the commercial integration.
</summary>
    <author>
      <name>Claudiu Tiberiu Albulescu</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">UPT</arxiv:affiliation>
    </author>
    <author>
      <name>Daniel Goyeau</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CRIEF</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/1609.02334v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.02334v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.04956v1</id>
    <updated>2016-09-16T08:53:16Z</updated>
    <published>2016-09-16T08:53:16Z</published>
    <title>Export dynamics as an optimal growth problem in the network of global
  economy</title>
    <summary>  We analyze export data aggregated at world global level of 219 classes of
products over a period of 39 years. Our main goal is to set up a dynamical
model to identify and quantify plausible mechanisms by which the evolutions of
the various exports affect each other. This is pursued through a stochastic
differential description, partly inspired by approaches used in population
dynamics or directed polymers in random media. We outline a complex network of
transfer rates which describes how resources are shifted between different
product classes, and determines how casual favorable conditions for one export
can spread to the other ones. A calibration procedure allows to fit four free
model-parameters such that the dynamical evolution becomes consistent with the
average growth, the fluctuations, and the ranking of the export values observed
in real data. Growth crucially depends on the balance between maintaining and
shifting resources to different exports, like in an explore-exploit problem.
Remarkably, the calibrated parameters warrant a close-to-maximum growth rate
under the transient conditions realized in the period covered by data, implying
an optimal self organization of the global export. According to the model,
major structural changes in the global economy take tens of years.
</summary>
    <author>
      <name>Michele Caraglio</name>
    </author>
    <author>
      <name>Fulvio Baldovin</name>
    </author>
    <author>
      <name>Attilio L. Stella</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1038/srep31461</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1038/srep31461" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 8 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Scientific Reports 6, 31461 (2016)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1609.04956v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.04956v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1611.09926v1</id>
    <updated>2016-11-29T22:36:01Z</updated>
    <published>2016-11-29T22:36:01Z</published>
    <title>Choquet integral in decision analysis - lessons from the axiomatization</title>
    <summary>  The Choquet integral is a powerful aggregation operator which lists many
well-known models as its special cases. We look at these special cases and
provide their axiomatic analysis. In cases where an axiomatization has been
previously given in the literature, we connect the existing results with the
framework that we have developed. Next we turn to the question of learning,
which is especially important for the practical applications of the model. So
far, learning of the Choquet integral has been mostly confined to the learning
of the capacity. Such an approach requires making a powerful assumption that
all dimensions (e.g. criteria) are evaluated on the same scale, which is rarely
justified in practice. Too often categorical data is given arbitrary numerical
labels (e.g. AHP), and numerical data is considered cardinally and ordinally
commensurate, sometimes after a simple normalization. Such approaches clearly
lack scientific rigour, and yet they are commonly seen in all kinds of
applications. We discuss the pros and cons of making such an assumption and
look at the consequences which axiomatization uniqueness results have for the
learning problems. Finally, we review some of the applications of the Choquet
integral in decision analysis. Apart from MCDA, which is the main area of
interest for our results, we also discuss how the model can be interpreted in
the social choice context. We look in detail at the state-dependent utility,
and show how comonotonicity, central to the previous axiomatizations, actually
implies state-independency in the Choquet integral model. We also discuss the
conditions required to have a meaningful state-dependent utility representation
and show the novelty of our results compared to the previous methods of
building state-dependent models.
</summary>
    <author>
      <name>Mikhail Timonin</name>
    </author>
    <link href="http://arxiv.org/abs/1611.09926v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1611.09926v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.02653v1</id>
    <updated>2016-10-25T07:26:15Z</updated>
    <published>2016-10-25T07:26:15Z</published>
    <title>Are Chinese transport policies effective? A new perspective from direct
  pollution rebound effect, and empirical evidence from road transport sector</title>
    <summary>  The air pollution has become a serious challenge in China. Emissions from
motor vehicles have been found as one main source of air pollution. Although
the Chinese government has taken numerous policies to mitigate the harmful
emissions from road transport sector, it is still uncertain for both policy
makers and researchers to know to what extent the policies are effective in the
short and long terms. Inspired by the concept and empirical results from
current literature on energy rebound effect (ERE), we first propose a new
concept of pollution rebound effect (PRE). Then, we estimate direct air PRE as
a measure for the effectiveness of the policies of reducing air pollution from
transport sector based on time-series data from the period 1986-2014. We find
that the short-term direct air PRE is -1.4105, and the corresponding long-run
PRE is -1.246. The negative results indicate that the direct air PRE does not
exist in road passenger transport sector in China, either in the short term or
in the long term during the period 1986-2014. This implies that the Chinese
transport policies are effective in terms of harmful emissions reduction in the
transport sector. This research, to the best of our knowledge, is the first
attempt to quantify the effectiveness of the transport policies in the
transitional China.
</summary>
    <author>
      <name>Lu-Yi Qiu</name>
    </author>
    <author>
      <name>Ling-Yun He</name>
    </author>
    <link href="http://arxiv.org/abs/1612.02653v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.02653v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.02656v1</id>
    <updated>2016-10-24T04:03:08Z</updated>
    <published>2016-10-24T04:03:08Z</published>
    <title>The demand for road transport in China: imposing theoretical regularity
  and flexible functional forms selection</title>
    <summary>  Road transport sector is found to be one of the major emitters, and
responsible for serious air pollution and huge pubic health losses. One
important parameter for determining the consequences of transport demand shocks
for the macroeconomy, air pollution and public health is the elasticity of the
demand for transport. Most published studies that use flexible functional forms
have ignored the theoretical regularity conditions implied by microeconomic
theories. Moreover, even a few studies have checked and/or imposed regularity
conditions, most of them equate curvature alone with regularity, thus ignoring
or minimizing the importance of other regularities. And then, the results
appear biased and may in fact be biased. Therefore, we select three of the most
widely used flexible functional forms, the Rotterdam model, the Almost Ideal
Demand System (AIDS), and the quadratic AIDS (QUAIDS) to investigate the demand
for road transport in China using recent annual expenditure data, over a 13
year period from 2002 to 2014, on three expenditure categories in the
transportation sector: private transportation, local transportation and
intercity transportation. Estimation shows that the AIDS model is the only
model that is able to provide theoretically consistent estimates of the
residents demand for road transport in China. Our estimates show that the
private transportation is a luxury among the transportation goods, and is
elastic in price changes relatively. The empirical results imply that the
private and the local transportation, the local and intercity transportation
are gross complements. And, the private transportation is a substitute for the
inter-city transportation, while the intercity transportation is a complement
of the private transportation.
</summary>
    <author>
      <name>Ling-yun He</name>
    </author>
    <author>
      <name>Li Liu</name>
    </author>
    <link href="http://arxiv.org/abs/1612.02656v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.02656v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.09553v1</id>
    <updated>2016-12-30T18:37:01Z</updated>
    <published>2016-12-30T18:37:01Z</published>
    <title>A Theory of Experience Effects</title>
    <summary>  How do financial crises and stock-market fluctuations affect investor
behavior and the dynamics of financial markets in the long run? Recent evidence
suggests that individuals overweight personal experiences of macroeconomic
shocks when forming beliefs and making investment decisions. We propose a
theoretical foundation for such experience-based learning and derive its
dynamic implications in a simple OLG model. Risk averse agents invest in a
risky and a risk-free asset. They form beliefs about the payoff of the risky
asset based on the two key components of experience effects: (1) they
overweight data observed during their lifetimes so far, and (2) they exhibit
recency bias. In equilibrium, prices depend on past dividends, but only on
those observed by the generations that are alive, and they are more sensitive
to more recent dividends. Younger generations react more strongly to recent
experiences than older generations, and hence have higher demand for the risky
asset in good times, but lower demand in bad times. As a result, a crisis
increases the average age of stock market participants, while booms have the
opposite effect. The stronger the disagreement across generations (e.g., after
a recent shock), the higher is the trade volume. We also show that, vice versa,
the demographic composition of markets significantly influences the response to
aggregate shocks. We generate empirical results on stock-market participation,
stock-market investment, and trade volume from the \emph{Survey of Consumer
Finances}, merged with CRSP and historical data on stock-market performance,
that are consistent with the model predictions.
</summary>
    <author>
      <name>Ulrike Malmendier</name>
    </author>
    <author>
      <name>Demian Pouzo</name>
    </author>
    <author>
      <name>Vicotria Vanasco</name>
    </author>
    <link href="http://arxiv.org/abs/1612.09553v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.09553v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.05632v1</id>
    <updated>2017-01-19T22:35:46Z</updated>
    <published>2017-01-19T22:35:46Z</published>
    <title>The Internet as Quantitative Social Science Platform: Insights from a
  Trillion Observations</title>
    <summary>  With the large-scale penetration of the internet, for the first time,
humanity has become linked by a single, open, communications platform.
Harnessing this fact, we report insights arising from a unified internet
activity and location dataset of an unparalleled scope and accuracy drawn from
over a trillion (1.5$\times 10^{12}$) observations of end-user internet
connections, with temporal resolution of just 15min over 2006-2012. We first
apply this dataset to the expansion of the internet itself over 1,647 urban
agglomerations globally. We find that unique IP per capita counts reach
saturation at approximately one IP per three people, and take, on average, 16.1
years to achieve; eclipsing the estimated 100- and 60- year saturation times
for steam-power and electrification respectively. Next, we use intra-diurnal
internet activity features to up-scale traditional over-night sleep
observations, producing the first global estimate of over-night sleep duration
in 645 cities over 7 years. We find statistically significant variation between
continental, national and regional sleep durations including some evidence of
global sleep duration convergence. Finally, we estimate the relationship
between internet concentration and economic outcomes in 411 OECD regions and
find that the internet's expansion is associated with negative or positive
productivity gains, depending strongly on sectoral considerations. To our
knowledge, our study is the first of its kind to use online/offline activity of
the entire internet to infer social science insights, demonstrating the
unparalleled potential of the internet as a social data-science platform.
</summary>
    <author>
      <name>Klaus Ackermann</name>
    </author>
    <author>
      <name>Simon D Angus</name>
    </author>
    <author>
      <name>Paul A Raschky</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">40 pages, including 4 main figures, and appendix</arxiv:comment>
    <link href="http://arxiv.org/abs/1701.05632v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.05632v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.06038v1</id>
    <updated>2017-01-21T15:22:51Z</updated>
    <published>2017-01-21T15:22:51Z</published>
    <title>Asymptotic efficiency of the proportional compensation scheme for a
  large number of producers</title>
    <summary>  We consider a manager, who allocates some fixed total payment amount between
$N$ rational agents in order to maximize the aggregate production. The profit
of $i$-th agent is the difference between the compensation (reward) obtained
from the manager and the production cost. We compare (i) the \emph{normative}
compensation scheme, where the manager enforces the agents to follow an optimal
cooperative strategy; (ii) the \emph{linear piece rates} compensation scheme,
where the manager announces an optimal reward per unit good; (iii) the
\emph{proportional} compensation scheme, where agent's reward is proportional
to his contribution to the total output. Denoting the correspondent total
production levels by $s^*$, $\hat s$ and $\overline s$ respectively, where the
last one is related to the unique Nash equilibrium, we examine the limits of
the prices of anarchy $\mathscr A_N=s^*/\overline s$, $\mathscr A_N'=\hat
s/\overline s$ as $N\to\infty$. These limits are calculated for the cases of
identical convex costs with power asymptotics at the origin, and for power
costs, corresponding to the Coob-Douglas and generalized CES production
functions with decreasing returns to scale. Our results show that
asymptotically no performance is lost in terms of $\mathscr A'_N$, and in terms
of $\mathscr A_N$ the loss does not exceed $31\%$.
</summary>
    <author>
      <name>Dmitry B. Rokhlin</name>
    </author>
    <author>
      <name>Anatoly Usov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1701.06038v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.06038v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B32, 91B40, 91B38" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.08567v2</id>
    <updated>2017-03-22T20:01:00Z</updated>
    <published>2017-01-30T12:18:30Z</published>
    <title>Decision structure of risky choice</title>
    <summary>  As we know, there is a controversy about the decision making under risk
between economists and psychologists. We discuss to build a unified theory of
risky choice, which would explain both of compensatory and non-compensatory
theories. For risky choice, according to cognition ability, we argue that
people could not build a continuous and accurate subjective probability world,
but several order concepts, such as small, middle and large probability. People
make decisions based on information, experience, imagination and other things.
All of these things are so huge that people have to prepare some strategies.
That is, people have different strategies when facing to different situations.
The distributions of these things have different decision structures. More
precisely, decision making is a process of simplifying the decision structure.
However, the process of decision structure simplifying is not stuck in a rut,
but through different path when facing problems repeatedly. It is why
preference reversal always happens when making decisions. The most efficient
way to simplify the decision structure is calculating expected value or making
decisions based on one or two dimensions. We also argue that the deliberation
time at least has four parts, which are consist of substitution time, first
order time, second order time and calculation time. Decision structure also can
simply explain the phenomenon of paradoxes and anomalies. JEL Codes: C10, D03,
D81
</summary>
    <author>
      <name>Lamb Wubin</name>
    </author>
    <author>
      <name>Naixin Ren</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1701.08567v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.08567v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.09043v2</id>
    <updated>2017-02-07T22:03:25Z</updated>
    <published>2017-01-31T14:13:43Z</published>
    <title>A taxonomy of learning dynamics in 2 x 2 games</title>
    <summary>  Learning would be a convincing method to achieve coordination on an
equilibrium. But does learning converge, and to what? We answer this question
in generic 2-player, 2-strategy games, using Experience-Weighted Attraction
(EWA), which encompasses many extensively studied learning algorithms. We
exhaustively characterize the parameter space of EWA learning, for any payoff
matrix, and we understand the generic properties that imply convergent or
non-convergent behaviour in 2 x 2 games.
  Irrational choice and lack of incentives imply convergence to a mixed
strategy in the centre of the strategy simplex, possibly far from the Nash
Equilibrium (NE). In the opposite limit, in which the players quickly modify
their strategies, the behaviour depends on the payoff matrix: (i) a strong
discrepancy between the pure strategies describes dominance-solvable games,
which show convergence to a unique fixed point close to the NE; (ii) a
preference towards profiles of strategies along the main diagonal describes
coordination games, with multiple stable fixed points corresponding to the NE;
(iii) a cycle of best responses defines discoordination games, which commonly
yield limit cycles or low-dimensional chaos.
  While it is well known that mixed strategy equilibria may be unstable, our
approach is novel from several perspectives: we fully analyse EWA and provide
explicit thresholds that define the onset of instability; we find an emerging
taxonomy of the learning dynamics, without focusing on specific classes of
games ex-ante; we show that chaos can occur even in the simplest games; we make
a precise theoretical prediction that can be tested against data on
experimental learning of discoordination games.
</summary>
    <author>
      <name>Marco Pangallo</name>
    </author>
    <author>
      <name>James Sanders</name>
    </author>
    <author>
      <name>Tobias Galla</name>
    </author>
    <author>
      <name>Doyne Farmer</name>
    </author>
    <link href="http://arxiv.org/abs/1701.09043v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.09043v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.CD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1702.02763v1</id>
    <updated>2017-02-09T09:36:46Z</updated>
    <published>2017-02-09T09:36:46Z</published>
    <title>Econophysics of Macroeconomics: "Action-at-a-Distance" and Waves</title>
    <summary>  We present macroeconomic model that describes evolution of macroeconomic
variables and macroeconomic waves on economic space. Risk ratings of economic
agents play role of their coordinates on economic space. Aggregation of
economic variables like Assets and Investment, Credits and Loans of economic
agents at point x define corresponding macroeconomic variables as functions of
time t and coordinates x on economic space. Evolution of macroeconomic
variables is determined by economic and financial transactions between economic
agents. Such transactions can occur between economic agents with any
coordinates x and y and that reflect non-local "action-at-a-distance" character
of internal macroeconomic interactions. For instance, Buy-Sell transactions
between points x and y on economic space define dynamics of Assets at point x
and Investment at point y. Aggregates of transactions between economic agents
at point x and y on economic space define economic fields as functions of two
coordinates. To describe dynamics of economic fields on economic space we
derive hydrodynamic-like equations. For simple models of interactions between
economic fields we derive hydrodynamic-like equations in a closed form and
obtain wave equations for their perturbations. Economic field waves propagate
on economic space and their amplitudes can grow up as exponent in time and may
disturb economic stability. Diversities of macroeconomic and financial waves on
economic space in simple models uncover importance of wave processes for
macroeconomic modeling and forecasting.
</summary>
    <author>
      <name>Victor Olkhov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">24 pages. arXiv admin note: text overlap with arXiv:1701.06625</arxiv:comment>
    <link href="http://arxiv.org/abs/1702.02763v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1702.02763v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1702.03290v1</id>
    <updated>2017-02-09T23:30:34Z</updated>
    <published>2017-02-09T23:30:34Z</published>
    <title>A Theory of Market Efficiency</title>
    <summary>  We introduce a mathematical theory called market connectivity that gives
concrete ways to both measure the efficiency of markets and find inefficiencies
in large markets. The theory leads to new methods for testing the famous
efficient markets hypothesis that do not suffer from the joint-hypothesis
problem that has plagued past work. Our theory suggests metrics that can be
used to compare the efficiency of one market with another, to find
inefficiencies that may be profitable to exploit, and to evaluate the impact of
policy and regulations on market efficiency.
  A market's efficiency is tied to its ability to communicate information
relevant to market participants. Market connectivity calculates the speed and
reliability with which this communication is carried out via trade in the
market. We model the market by a network called the trade network, which can be
computed by recording transactions in the market over a fixed interval of time.
The nodes of the network correspond to participants in the market. Every pair
of nodes that trades in the market is connected by an edge that is weighted by
the rate of trade, and associated with a vector that represents the type of
item that is bought or sold.
  We evaluate the ability of the market to communicate by considering how it
deals with shocks. A shock is a change in the beliefs of market participants
about the value of the products that they trade. We compute the effect of every
potential significant shock on trade in the market. We give mathematical
definitions for a few concepts that measure the ability of the market to
effectively dissipate shocks.
</summary>
    <author>
      <name>Anup Rao</name>
    </author>
    <link href="http://arxiv.org/abs/1702.03290v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1702.03290v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1702.04967v2</id>
    <updated>2017-03-29T14:20:42Z</updated>
    <published>2017-02-16T13:56:36Z</published>
    <title>Multi-Dimensional Pass-Through, Incidence, and the Welfare Burden of
  Taxation in Oligopoly</title>
    <summary>  This paper studies welfare consequences of unit and ad valorem taxes in
oligopoly with general demand, non-constant marginal costs, and a generalized
type of competition. We present formulas providing connections between marginal
cost of public funds, tax incidence, unit tax pass-through, ad valorem tax
pass-through, and other economic quantities of interest. First, in the case of
symmetric firms, we show that there exists a simple, empirically relevant set
of sufficient statistics for the marginal cost of public funds, namely the
pass-through and the industry demand elasticity. Specializing to the case of
price or quantity competition, we show how marginal cost of public funds and
pass-through are expressed using elasticities and curvatures of demand and
inverse demand. These results also apply to symmetric oligopoly with
multi-product firms. Second, we present a generalization with the tax revenue
function specified as a general function parameterized by a vector of tax
parameters. We analyze multi-dimensional pass-through, generalizing the results
of Weyl and Fabinger (2013), and show that it is crucial for evaluating welfare
changes in response to changes in taxation. Finally, we generalize our results
to the case of heterogeneous firms, as well as to the case of changes in both
production costs and taxes.
</summary>
    <author>
      <name>Takanori Adachi</name>
    </author>
    <author>
      <name>Michal Fabinger</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">43 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1702.04967v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1702.04967v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.02104v1</id>
    <updated>2017-02-27T10:29:34Z</updated>
    <published>2017-02-27T10:29:34Z</published>
    <title>Long-run dynamics of the U.S. patent classification system</title>
    <summary>  Almost by definition, radical innovations create a need to revise existing
classification systems. As a result, the evolution of technological
classification systems reflects technological evolution. We present three sets
of findings regarding classification volatility in the U.S. Patent
Classification System. First, we study the evolution of the number of distinct
classes. Reconstructed time series based on the current classification scheme
are very different from historical data. This suggests that using the current
classification to analyze the past produces a distorted view of the evolution
of the system. Second, we study the relative sizes of classes. The size
distribution is exponential so classes can be of quite different sizes, but the
largest classes are not necessarily the oldest. To explain this pattern with a
simple stochastic growth model, we introduce the assumption that classes have a
regular chance to be split. Third, we study reclassification. The share of
patents that are in a different class now than they were at birth can be quite
high. Reclassification mostly occurs across classes belonging to the same
1-digit NBER category, but not always. We also document that reclassified
patents tend to be more cited than non-reclassified ones, even after
controlling for grant year and class of origin. More generally we argue that
classification changes and patent reclassification are quite common, reveal
interesting information about technological evolution, and must be taken into
account when using classification as a basis for forecasting.
</summary>
    <author>
      <name>Francois Lafond</name>
    </author>
    <author>
      <name>Daniel Kim</name>
    </author>
    <link href="http://arxiv.org/abs/1703.02104v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.02104v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1704.06429v1</id>
    <updated>2017-04-21T07:50:22Z</updated>
    <published>2017-04-21T07:50:22Z</published>
    <title>Simple wealth distribution model causing inequality-induced crisis
  without external shocks</title>
    <summary>  We address the issue of the dynamics of wealth accumulation and economic
crisis triggered by extreme inequality, attempting to stick to most possibly
intrinsic assumptions. Our general framework is that of pure or modified
multiplicative processes, basically geometric Brownian motions. In contrast
with the usual approach of injecting into such stochastic agent models either
specific, idiosyncratic internal nonlinear interaction patterns, or macroscopic
disruptive features, we propose a dynamic inequality model where the attainment
of a sizable fraction of the total wealth by very few agents induces a crisis
regime with strong intermittency, the explicit coupling between the richest and
the rest being a mere normalization mechanism, hence with minimal extrinsic
assumptions. The model thus harnesses the recognized lack of ergodicity of
geometric Brownian motions. It also provides a statistical intuition to the
consequences of Thomas Piketty's recent "$r&gt;g$" (return rate $&gt;$ growth rate)
paradigmatic analysis of very-long-term wealth trends. We suggest that the
"water-divide" of wealth flow may define effective classes, making an objective
entry point to calibrate the model. Consistently, we check that a tax mechanism
associated to a few percent relative bias on elementary daily transactions is
able to slow or stop the build-up of large wealth. When extreme fluctuations
are tamed down to a stationary regime with sizable but steadier inequalities,
it should still offer opportunities to study the dynamics of crisis and the
inner effective classes induced through external or internal factors.
</summary>
    <author>
      <name>Henri Benisty</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1103/PhysRevE.95.052307</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1103/PhysRevE.95.052307" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 11 figures. Work initiated from discussion on Aristotle's
  status revisited by Paul Jorion in the many cases where the law of supply and
  demand fails. Accepted for publication in Physical Review E on April 19, 2017</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Phys. Rev. E 95, 052307 (2017)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1704.06429v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1704.06429v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1704.08161v2</id>
    <updated>2017-08-23T13:41:54Z</updated>
    <published>2017-04-26T15:27:13Z</published>
    <title>Stability of zero-growth economics analysed with a Minskyan model</title>
    <summary>  As humanity is becoming increasingly confronted by Earth's finite biophysical
limits, there is increasing interest in questions about the stability and
equitability of a zero-growth capitalist economy, most notably: if one
maintains a positive interest rate for loans, can a zero-growth economy be
stable? This question has been explored on a few different macroeconomic
models, and both `yes' and `no' answers have been obtained. However, economies
can become unstable whether or not there is ongoing underlying growth in
productivity with which to sustain growth in output. Here we attempt, for the
first time, to assess via a model the relative stability of growth versus
no-growth scenarios. The model employed draws from Keen's model of the Minsky
financial instability hypothesis. The analysis focuses on dynamics as opposed
to equilibrium, and scenarios of growth and no-growth of output (GDP) are
obtained by tweaking a productivity growth input parameter. We confirm that,
with or without growth, there can be both stable and unstable scenarios. To
maintain stability, firms must not change their debt levels or target debt
levels too quickly. Further, according to the model, the wages share is higher
for zero-growth scenarios, although there are more frequent substantial drops
in employment.
</summary>
    <author>
      <name>Adam B. Barrett</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages, 5 figures, paper at the Fourth Nordic Post-Keynesian
  Conference, Aalborg, Denmark, April 2017</arxiv:comment>
    <link href="http://arxiv.org/abs/1704.08161v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1704.08161v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.03423v1</id>
    <updated>2017-05-09T16:53:34Z</updated>
    <published>2017-05-09T16:53:34Z</published>
    <title>Wright meets Markowitz: How standard portfolio theory changes when
  assets are technologies following experience curves</title>
    <summary>  This paper considers how to optimally allocate investments in a portfolio of
competing technologies. We introduce a simple model representing the underlying
trade-off - between investing enough effort in any one project to spur rapid
progress, and diversifying effort over many projects simultaneously to hedge
against failure. We use stochastic experience curves to model the idea that
investing more in a technology reduces its unit costs, and we use a
mean-variance objective function to understand the effects of risk aversion. In
contrast to portfolio theory for standard financial assets, the feedback from
the experience curves results in multiple local optima of the objective
function, so different optimal portfolios may exist simultaneously. We study
the two-technology case and characterize the optimal diversification as a
function of relative progress rates, variability, initial cost and experience,
risk aversion and total demand. There are critical regions of the parameter
space in which the globally optimal portfolio changes sharply from one local
minimum to another, even though the underlying parameters change only
marginally, so a good understanding of the parameter space is essential. We use
the efficient frontier framework to visualize technology portfolios and show
that the feedback leads to nonlinear distortions of the feasible set.
</summary>
    <author>
      <name>Rupert Way</name>
    </author>
    <author>
      <name>François Lafond</name>
    </author>
    <author>
      <name>J. Doyne Farmer</name>
    </author>
    <author>
      <name>Fabrizio Lillo</name>
    </author>
    <author>
      <name>Valentyn Panchenko</name>
    </author>
    <link href="http://arxiv.org/abs/1705.03423v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.03423v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.01748v1</id>
    <updated>2017-05-17T16:38:06Z</updated>
    <published>2017-05-17T16:38:06Z</published>
    <title>Econophysics of Macro-Finance: Local Multi-fluid Models and Surface-like
  Waves of Financial Variables</title>
    <summary>  This paper models macro financial variables alike to financial fluids with
local interactions and describes surface-like waves of Investment and Profits.
We regard macro-finance as ensemble of economic agents and use their risk
ratings as coordinates on economic space. Aggregations of agent's financial
variables with risk coordinates x on economic space define macro financial
variables as function of x. We describe evolution and interactions between
macro financial variables alike to financial fluids by hydrodynamic-like
equations. Minimum and maximum risk grades define most secure and most risky
agents respectively. That determines borders of macro-finance domain that is
filled by economic agents. Perturbations of agent's risk coordinates near risk
borders of macro domain cause disturbances of macro financial variables like
Investment and Profits. Such disturbances can generate waves that propagate
along risk borders. These waves may exponentially amplify perturbations inside
of macro domain and impact financial sustainability. We study simple model
Investment and Profits and describe linear approximation of steady state
distributions of Investment and Profits on macro-finance domain that fulfill
dreams of Investors: "more risks-more Profits". We describe Investment and
Profits waves on risk border of economic space alike to surface waves in
fluids. We present simple examples that specify waves as possible origin of
time fluctuations of macro financial variables. Description of possible steady
state distributions of macro financial variables and financial risk waves on
economic space could help for better policy-making and managing sustainable
macro-finance.
</summary>
    <author>
      <name>Victor Olkhov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1706.01748v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.01748v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.02090v1</id>
    <updated>2017-06-07T08:38:14Z</updated>
    <published>2017-06-07T08:38:14Z</published>
    <title>Informing Additive Manufacturing technology adoption: total cost and the
  impact of capacity utilisation</title>
    <summary>  Informing Additive Manufacturing (AM) technology adoption decisions, this
paper investigates the relationship between build volume capacity utilisation
and efficient technology operation in an inter-process comparison of the costs
of manufacturing a complex component used in the packaging industry.
Confronting the reported costs of a conventional machining and welding pathway
with an estimator of the costs incurred through an AM route utilising Direct
Metal Laser Sintering (DMLS), we weave together four aspects: optimised
capacity utilisation, ancillary process steps, the effect of build failure, and
design adaptation. Recognising that AM users can fill unused machine capacity
with other, potentially unrelated, geometries, we posit a characteristic of
'fungible' build capacity. This aspect is integrated in the cost estimation
framework through computational build volume packing, drawing on a basket of
sample geometries. We show that the unit cost in mixed builds at full capacity
is lower than in builds limited to a single type of geometry; in our study this
results in a mean unit cost overstatement of 157%. The estimated manufacturing
costs savings from AM adoption range from 36% to 46%. Additionally, we indicate
that operating cost savings resulting from design adaptation are likely to far
outweigh the manufacturing cost advantage.
</summary>
    <author>
      <name>Martin Baumers</name>
    </author>
    <author>
      <name>Luca Beltrametti</name>
    </author>
    <author>
      <name>Angelo Gasparre</name>
    </author>
    <author>
      <name>Richard Hague</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1080/00207543.2017.1334978</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1080/00207543.2017.1334978" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">pre-submission manuscript for green open access</arxiv:comment>
    <link href="http://arxiv.org/abs/1706.02090v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.02090v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.07758v1</id>
    <updated>2017-05-29T07:55:41Z</updated>
    <published>2017-05-29T07:55:41Z</published>
    <title>Non-Local Macroeconomic Transactions and Credits-Loans Surface-Like
  Waves</title>
    <summary>  This paper describes surface-like waves of macroeconomic Credits-Loans
transactions on economic space. We use agent's risk ratings as their
coordinates and describe evolution of macro variables by transactions between
agents. Aggregations of agent's variables with risk coordinates x on economic
space define macro variables as function of x. Aggregations of transactions
between agents at point x and y determine functions of two variables (x,y) on
economic space. As example we study Credits transactions provided from agents
at point x to agents at point y and thus amount of Loans received by agents at
point y from agents at point x at moment t during time term dt. We model
evolution of macro transactions by hydrodynamic-like equations. Agents fill
macro domain on economic space that is bounded by minimum risk ratings of most
secure and maximum risk ratings of most risky agents. Economic and financial
shocks can disturb steady borders of macro domain and cause perturbations of
transactions. Such disturbances can generate waves that can propagate along
risk borders alike to surface waves in fluids. As example, we describe simple
model interactions between two transactions by hydrodynamic like equations in a
closed form. We introduce notions of "macro accelerations" and their potentials
that establish steady state distributions of transactions on economic space.
For this model in linear approximation we describe surface-like waves and show
that perturbations induced by surface-like waves can exponentially grow up
inside macro domain and induce macro instabilities in a low risk area.
Description of possible steady state distributions of transactions and
surface-like waves on economic space might be important for macro modeling and
policy-making.
</summary>
    <author>
      <name>Victor Olkhov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1706.07758v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.07758v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.03960v1</id>
    <updated>2017-07-13T02:21:52Z</updated>
    <published>2017-07-13T02:21:52Z</published>
    <title>How do fishery policies affect Hawaii's longline fishing industry?
  Calibrating a positive mathematical programming model</title>
    <summary>  We present a vessel and target-specific positive mathematical programming
model (PMP) for Hawaii's longline fishing fleet. Although common in
agricultural economics, PMP modeling is rarely attempted in fisheries. To
demonstrate the flexibility of the PMP framework, we separate tuna and
swordfish production technologies into three policy relevant fishing targets.
We find the model most accurately predicts vessel-specific annual bigeye catch
in the WCPO, with an accuracy of 12% to 35%, and a correlation between 0.30 and
0.53. To demonstrate the model's usefulness to policy makers, we simulate the
economic impact to individual vessels from increasing and decreasing the bigeye
catch limit in the WCPO by 10%. Our results suggest that such policy changes
will have moderate impacts on most vessels, but large impacts on a few
generating a fat tailed distribution. These results offer insights into the
range of winners and losers resulting from changes in fishery policies, and
therefore, which policies are more likely to gain widespread industry support.
As a tool for fishery management, the calibrated PMP model offers a flexible
and easy-to-use framework, capable of capturing the heterogeneous response of
fishing vessels to evaluate policy changes.
</summary>
    <author>
      <name>Jonathan R. Sweeney</name>
    </author>
    <author>
      <name>Richard E. Howitt</name>
    </author>
    <author>
      <name>Hing Ling Chan</name>
    </author>
    <author>
      <name>Minling Pan</name>
    </author>
    <author>
      <name>PingSun Leung</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Natural Resource Modeling, 30(2) (2017)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1707.03960v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.03960v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.06704v1</id>
    <updated>2017-08-21T03:09:56Z</updated>
    <published>2017-08-21T03:09:56Z</published>
    <title>Unemployment: Study of Causes and Possible Solutions</title>
    <summary>  The following measures against unemployment are proposed: In the short term,
to promote greater income for the poorest sectors. It is shown that this can be
paid with the resulting increased production, without losing income to the
other economic agents. In the mid term, the creation of ad-hoc companies for
investment in projects profitable but long lasting. And in the long run, the
abandonment of the competitive models. As these proposals go against current
ideas (liberalisation, labour market flexibility, free market, etc.), the
statements are rigorously demonstrated, even at the risk of making the lecture
harder.
  Part 1 explores the problem and uses a simple model and others heuristic
arguments to create familiarity with macroeconomic models. Part 2 is a
simplified summary of Macroeconomic Theory textbook. It serves as a review to
the reader whose knowledge in economy are out of date, or as a first
approximation to the topic if he or she does not have them. In the light of the
theory, economic policies are evaluated for the Argentine case in the 90's. The
work accepts the Keynesian explanation of unemployment (insufficient demand),
but we disagree on its solution (public expenditure). Finally, in Part 3 we
elaborate and justify the proposals.
</summary>
    <author>
      <name>Thomas Pedro Eggarter</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">T.P.Eggarter (physicist) passed away in August 1997. This work was
  done during his last months of life and only locally published up to now.
  Work is in Spanish and could be translated upon request. Please contact E.
  Alvarez sequi@df.uba.ar</arxiv:comment>
    <link href="http://arxiv.org/abs/1708.06704v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.06704v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.05392v1</id>
    <updated>2017-09-15T20:36:40Z</updated>
    <published>2017-09-15T20:36:40Z</published>
    <title>Relatedness, Knowledge Diffusion, and the Evolution of Bilateral Trade</title>
    <summary>  During the last decades two important contributions have reshaped our
understanding of international trade. First, countries trade more with those
with whom they share history, language, and culture, suggesting that trade is
limited by information frictions. Second, countries are more likely to start
exporting products that are similar to their current exports, suggesting that
knowledge diffusion among related industries is a key constrain shaping the
diversification of exports. But does knowledge about how to export to a
destination also diffuses among related products and geographic neighbors? Do
countries need to learn how to trade each product to each destination? Here, we
use bilateral trade data from 2000 to 2015 to show that countries are more
likely to increase their exports of a product to a destination when: (i) they
export related products to it, (ii) they export the same product to the
neighbor of a destination, (iii) they have neighbors who export the same
product to that destination. Then, we explore the magnitude of these effects
for new, nascent, and experienced exporters, (exporters with and without
comparative advantage in a product) and also for groups of products with
different level of technological sophistication. We find that the effects of
product and geographic relatedness are stronger for new exporters, and also,
that the effect of product relatedness is stronger for more technologically
sophisticated products. These findings support the idea that international
trade is shaped by information frictions that are reduced in the presence of
related products and experienced geographic neighbors.
</summary>
    <author>
      <name>Bogang Jun</name>
    </author>
    <author>
      <name>Aamena Alshamsi</name>
    </author>
    <author>
      <name>Jian Gao</name>
    </author>
    <author>
      <name>Cesar A Hidalgo</name>
    </author>
    <link href="http://arxiv.org/abs/1709.05392v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.05392v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.7377v1</id>
    <updated>2014-04-28T08:15:57Z</updated>
    <published>2014-04-28T08:15:57Z</published>
    <title>The Italian Crisis and Producer Households Debt: a Source of Stability?
  A Reproducible Research</title>
    <summary>  The European Credit Research Institute Research Report 2013 identifies
Households debt "rapid increase and abrupt retrenchment" among the causes of
macroeconomic instability in the European Union after 2008. In our research: i)
we accessed the Bank of Italy Online Statistical Database on Customers and Risk
for Producer Households and Non-Financial Corporations with R Sweave open
access statistical software, which makes our analysis freely reproducible by
other researchers; ii) we subset the European System of Accounts sector
Households into the Bank of Italy sub-sectors Households and Producer
Households, which are market producing entities limited to informal
partnerships, de facto companies and sole proprietorships with up to five
employees and iii) we tested the hypothesis of "rapid increase and abrupt
retrenchment" of debt for this subset in Italy for the period 1996-2013. We
found that PH debt (bad debt) has been more stable with a lower Variation
Coefficient of 10.3% (14.2%) versus 13.2% (20.1%) in NFC. We also found that
the time series of the ratio of debt granted to NFC (numerator) versus PH
(denominator) is best described (Multiple Squared 0.95) by the concavity of the
5th degree coefficient (slope -1.22; 95% CI -1.52 - -0.91) of a 5th order
polynomial linear regression and by the convexity of the 2nd degree coefficient
(slope 4.26; 95% CI 2.53 - 5.99) for bad debt (Multiple R Squared 0.47), with
this concavity of debt and convexity of bad debt beginning with the Italian
crisis in the second trimester of 2008. We reject the hypothesis (p &lt; 0.01) of
"rapid increase and abrupt retrenchment" of debt for the subset Producer
Households during the Italian Crisis. We generate the hypothesis that this
subset could represent a prospective source of stability relative to
Non-Financial Corporation.
</summary>
    <author>
      <name>Stefano Olgiati</name>
    </author>
    <author>
      <name>Gilberto Bronzini</name>
    </author>
    <author>
      <name>Alessandro Danovi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at the Risk, Banking and Finance Society, University of
  Florence, New York University Stern Salomon Center, and Warsaw School of
  Economics International Credit Risk Management Conference 2014, June 23,24 in
  Warsaw, Poland</arxiv:comment>
    <link href="http://arxiv.org/abs/1404.7377v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.7377v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.5397v2</id>
    <updated>2015-01-08T02:11:35Z</updated>
    <published>2014-12-17T14:03:38Z</published>
    <title>Comprehensive Time-Series Regression Models Using GRETL - U.S. GDP and
  Government Consumption Expenditures &amp; Gross Investment from 1980 to 2013</title>
    <summary>  Using Gretl, I apply ARMA, Vector ARMA, VAR, state-space model with a Kalman
filter, transfer-function and intervention models, unit root tests,
cointegration test, volatility models (ARCH, GARCH, ARCH-M, GARCH-M,
Taylor-Schwert GARCH, GJR, TARCH, NARCH, APARCH, EGARCH) to analyze quarterly
time series of GDP and Government Consumption Expenditures &amp; Gross Investment
(GCEGI) from 1980 to 2013. The article is organized as: (I) Definition; (II)
Regression Models; (III) Discussion. Additionally, I discovered a unique
interaction between GDP and GCEGI in both the short-run and the long-run and
provided policy makers with some suggestions. For example in the short run, GDP
responded positively and very significantly (0.00248) to GCEGI, while GCEGI
reacted positively but not too significantly (0.08051) to GDP. In the long run,
current GDP responded negatively and permanently (0.09229) to a shock in past
GCEGI, while current GCEGI reacted negatively yet temporarily (0.29821) to a
shock in past GDP. Therefore, policy makers should not adjust current GCEGI
based merely on the condition of current and past GDP. Although increasing
GCEGI does help GDP in the short-term, significantly abrupt increase in GCEGI
might not be good to the long-term health of GDP. Instead, a balanced,
sustainable, and economically viable solution is recommended, so that the
short-term benefits to the current economy from increasing GCEGI often largely
secured by the long-term loan outweigh or at least equal to the negative effect
to the future economy from the long-term debt incurred by the loan. Finally, I
found that non-normally distributed volatility models generally perform better
than normally distributed ones. More specifically, TARCH-GED performs the best
in the group of non-normally distributed, while GARCH-M does the best in the
group of normally distributed.
</summary>
    <author>
      <name>Juehui Shi</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.2139/ssrn.2540535</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.2139/ssrn.2540535" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">82 Pages with Gretl codes included</arxiv:comment>
    <link href="http://arxiv.org/abs/1412.5397v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.5397v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.02414v1</id>
    <updated>2015-06-08T09:32:40Z</updated>
    <published>2015-06-08T09:32:40Z</published>
    <title>Cross Ranking of Cities and Regions: Population vs. Income</title>
    <summary>  This paper explores the relationship between the inner economical structure
of communities and their population distribution through a rank-rank analysis
of official data, along statistical physics ideas within two techniques. The
data is taken on Italian cities. The analysis is performed both at a global
(national) and at a more local (regional) level in order to distinguish "macro"
and "micro" aspects. First, the rank-size rule is found not to be a standard
power law, as in many other studies, but a doubly decreasing power law. Next,
the Kendall and the Spearman rank correlation coefficients which measure pair
concordance and the correlation between fluctuations in two rankings,
respectively, - as a correlation function does in thermodynamics, are
calculated for finding rank correlation (if any) between demography and wealth.
Results show non only global disparities for the whole (country) set, but also
(regional) disparities, when comparing the number of cities in regions, the
number of inhabitants in cities and that in regions, as well as when comparing
the aggregated tax income of the cities and that of regions. Different outliers
are pointed out and justified. Interestingly, two classes of cities in the
country and two classes of regions in the country are found. "Common sense"
social, political, and economic considerations sustain the findings. More
importantly, the methods show that they allow to distinguish communities, very
clearly, when specific criteria are numerically sound. A specific modeling for
the findings is presented, i.e. for the doubly decreasing power law and the two
phase system, based on statistics theory, e.g., urn filling. The model ideas
can be expected to hold when similar rank relationship features are observed in
fields. It is emphasized that the analysis makes more sense than one through a
Pearson value-value correlation analysis.
</summary>
    <author>
      <name>Roy Cerqueti</name>
    </author>
    <author>
      <name>Marcel Ausloos</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1088/1742-5468/2015/00/000000</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1088/1742-5468/2015/00/000000" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">34 pages, 13 figures, 6 tables, 81 references; prepared for Journal
  of Statistical Mechanics: Theory and Experiment (JSTAT)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">J. Stat. Mech. (2015) P07002</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1506.02414v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.02414v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.04136v1</id>
    <updated>2015-07-15T09:14:10Z</updated>
    <published>2015-07-15T09:14:10Z</published>
    <title>Taming the Basel Leverage Cycle</title>
    <summary>  Effective risk control must make a tradeoff between the microprudential risk
of exogenous shocks to individual institutions and the macroprudential risks
caused by their systemic interactions. We investigate a simple dynamical model
for understanding this tradeoff, consisting of a bank with a leverage target
and an unleveraged fundamental investor subject to exogenous noise with
clustered volatility. The parameter space has three regions: (i) a stable
region, where the system always reaches a fixed point equilibrium; (ii) a
locally unstable region, characterized by cycles and chaotic behavior; and
(iii) a globally unstable region. A crude calibration of parameters to data
puts the model in region (ii). In this region there is a slowly building price
bubble, resembling a "Great Moderation", followed by a crash, with a period of
approximately 10-15 years, which we dub the "Basel leverage cycle". We propose
a criterion for rating macroprudential policies based on their ability to
minimize risk for a given average leverage. We construct a one parameter family
of leverage policies that allows us to vary from the procyclical policies of
Basel II or III, in which leverage decreases when volatility increases, to
countercyclical policies in which leverage increases when volatility increases.
We find the best policy depends critically on three parameters: The average
leverage used by the bank; the relative size of the bank and the
fundamentalist, and the amplitude of the exogenous noise. Basel II is optimal
when the exogenous noise is high, the bank is small and leverage is low; in the
opposite limit where the bank is large or leverage is high the optimal policy
is closer to constant leverage. We also find that systemic risk can be
dramatically decreased by lowering the leverage target adjustment speed of the
banks.
</summary>
    <author>
      <name>Christoph Aymanns</name>
    </author>
    <author>
      <name>Fabio Caccioli</name>
    </author>
    <author>
      <name>J. Doyne Farmer</name>
    </author>
    <author>
      <name>Vincent W. C. Tan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">41 pages, 12 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1507.04136v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.04136v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.05355v1</id>
    <updated>2015-06-08T01:31:46Z</updated>
    <published>2015-06-08T01:31:46Z</published>
    <title>Autonomics: an autonomous and intelligent economic platform and next
  generation money tool</title>
    <summary>  We propose a high level network architecture for an economic system that
integrates money, governance and reputation. We introduce a method for issuing,
and redeeming a digital coin using a mechanism to create a sustainable global
economy and a free market. To maintain a currency's value over time, and
therefore be money proper, we claim it must be issued by the buyer and backed
for value by the seller, exchanging the products of labour, in a free market.
We also claim that a free market and sustainable economy cannot be maintained
using economically arbitrary creation and allocation of money. Nakamoto, with
Bitcoin, introduced a new technology called the cryptographic blockchain to
operate a decentralised and distributed accounts ledger without the need for an
untrusted third party. This blockchain technology creates and allocates new
digital currency as a reward for "proof-of-work", to secure the network.
However, no currency, digital or otherwise, has solved how to create and
allocate money in an economically non-arbitrary way, or how to govern and trust
a world-scale free enterprise money system. We propose an "Ontologically
Networked Exchange" (ONE), with purpose as its highest order domain. Each
purpose is defined in a contract, and the entire economy of contracts is
structured in a unified ontology. We claim to secure the ONE network using
economically non-arbitrary methodologies and economically incented human
behaviour. Decisions influenced by reputation help to secure the network
without an untrusted third party. The stack of contracts, organised in a
unified ontology, functions as a super recursive algorithm, with individual use
programming the algorithm, acting as the "oracle". The state of the algorithm
becomes the "memory" of a scalable and trustable artificial intelligence (AI).
This AI offers a new platform for what we call the "Autonomy-of-Things" (AoT).
</summary>
    <author>
      <name>Benjamin Munro</name>
    </author>
    <author>
      <name>Julia McLachlan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">55 pages, 9 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1508.05355v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.05355v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.08449v1</id>
    <updated>2015-11-26T16:51:23Z</updated>
    <published>2015-11-26T16:51:23Z</published>
    <title>Water Stress on U.S. Power Production at Decadal Time Horizons</title>
    <summary>  Thermoelectric power production at risk, owing to current and projected water
scarcity and rising stream temperatures, is assessed for the contiguous United
States at decadal scales. Regional water scarcity is driven by climate
variability and change, as well as by multi-sector water demand. While a
planning horizon of zero to about thirty years is occasionally prescribed by
stakeholders, the challenges to risk assessment at these scales include the
difficulty in delineating decadal climate trends from intrinsic natural or
multiple model variability. Current generation global climate or earth system
models are not credible at the spatial resolutions of power plants, especially
for surface water quantity and stream temperatures, which further exacerbates
the assessment challenge. Population changes, which are difficult to project,
cannot serve as adequate proxies for changes in the water demand across
sectors. The hypothesis that robust assessments of power production at risk are
possible, despite the uncertainties, has been examined as a proof of concept.
An approach is presented for delineating water scarcity and temperature from
climate models, observations and population storylines, as well as for
assessing power production at risk by examining geospatial correlations of
power plant locations within regions where the usable water supply for energy
production happens to be scarcer and warmer. Our analyses showed that in the
near term, more than 200 counties are likely to be exposed to water scarcity in
the next three decades. Further, we noticed that stream gauges in more than
five counties in the 2030s and ten counties in the 2040s showed a significant
increase in water temperature, which exceeded the power plant effluent
temperature threshold set by the EPA. Power plants in South Carolina,
Louisiana, and Texas are likely to be vulnerable owing to climate-driven water
stresses.
</summary>
    <author>
      <name>Poulomi Ganguli</name>
    </author>
    <author>
      <name>Devashish Kumar</name>
    </author>
    <author>
      <name>Auroop R. Ganguly</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Tech Report prepared for Advanced Research Projects Agency Energy,
  United States Department of Energy</arxiv:comment>
    <link href="http://arxiv.org/abs/1511.08449v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.08449v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1512.03618v1</id>
    <updated>2015-12-11T12:19:50Z</updated>
    <published>2015-12-11T12:19:50Z</published>
    <title>Macroeconomic Dynamics of Assets, Leverage and Trust</title>
    <summary>  A macroeconomic model based on the economic variables (i) assets, (ii)
leverage (defined as debt over asset) and (iii) trust (defined as the maximum
sustainable leverage) is proposed to investigate the role of credit in the
dynamics of economic growth, and how credit may be associated with both
economic performance and confidence. Our first notable finding is the mechanism
of reward/penalty associated with patience, as quantified by the return on
assets. In regular economies where the EBITA/Assets ratio is larger than the
cost of debt, starting with a trust higher than leverage results in the highest
long-term return on assets (which can be seen as a proxy for economic growth).
Our second main finding concerns a recommendation for the reaction of a central
bank to an external shock that affects negatively the economic growth. We find
that late policy intervention in the model economy results in the highest
long-term return on assets and largest asset value. But this comes at the cost
of suffering longer from the crisis until the intervention occurs. The
phenomenon can be ascribed to the fact that postponing intervention allows
trust to increase first, and it is most effective to intervene when trust is
high. These results derive from two fundamental assumptions underlying our
model: (a) trust tends to increase when it is above leverage; (b) economic
agents learn optimally to adjust debt for a given level of trust and amount of
assets. Using a Markov Switching Model for the EBITA/Assets ratio, we have
successfully calibrated our model to the empirical data of the return on equity
of the EURO STOXX 50 for the time period 2000-2013. We find that dynamics of
leverage and trust can be highly non-monotonous with curved trajectories, as a
result of the nonlinear coupling between the variables.
</summary>
    <author>
      <name>Jeroen Rozendaal</name>
    </author>
    <author>
      <name>Yannick Malevergne</name>
    </author>
    <author>
      <name>Didier Sornette</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1142/S0218127416501339</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1142/S0218127416501339" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">32 pages with 10 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1512.03618v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1512.03618v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1512.05343v1</id>
    <updated>2015-12-16T16:45:17Z</updated>
    <published>2015-12-16T16:45:17Z</published>
    <title>European Union gas market development</title>
    <summary>  The recently announced Energy Union by the European Commission is the most
recent step in a series of developments aiming at integrating the EU's gas
markets to increase social welfare (SW) and security of gas supply. Based on a
spatial partial equilibrium model, we analyze the changes in consumption,
prices, and SW up to 2022 induced by the infrastructure expansions planned for
this period. We find that wholesale prices decrease slightly and converge at
Western European levels, the potential of suppliers to exert market power
decreases significantly, and consumer surplus increases by 15.9% in the EU. Our
results allow us to distinguish three categories of projects: (i) New gas
sources developed and brought to the EU markets. These projects decrease prices
and increase SW in a large number of countries. The only project in this
category is the Trans-Anatolian Gas Pipeline; (ii) Existing gas sources made
available to additional countries. This leads to an increase of SW in the newly
connected countries, and a decrease everywhere else. These projects mainly
involve pipeline and regasification terminal capacity enhancements; (iii)
Projects with a marginal effect on the (fully functioning) market. Most storage
expansion projects fall into this category, plus the recently announced Turkish
Stream. Our results indicate that if all proposed infrastructure projects are
realized, the EU's single market will become a reality in 2019. However, we
also find that SW can only be increased significantly for the EU as a whole if
new gas sources become accessible. Consequently, we suggest that the EU should
emphasize on measures to increase the available volumes, in particular once the
integration of the market is completed. At the same time, efficiency gains,
albeit decreasing SW, help to improve the situation of consumers and decrease
the dependency of the EU as a whole on external suppliers.
</summary>
    <author>
      <name>Tobias Baltensperger</name>
    </author>
    <author>
      <name>Rudolf M. Füchslin</name>
    </author>
    <author>
      <name>Pius Krütli</name>
    </author>
    <author>
      <name>John Lygeros</name>
    </author>
    <link href="http://arxiv.org/abs/1512.05343v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1512.05343v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.00085v2</id>
    <updated>2016-02-02T05:29:18Z</updated>
    <published>2016-01-01T15:20:49Z</published>
    <title>Dynamic Multi-Factor Bid-Offer Adjustment Model: A Feedback Mechanism
  for Dealers (Market Makers) to Deal (Grapple) with the Uncertainty Principle
  of the Social Sciences</title>
    <summary>  The author seeks to develop a model to alter the bid-offer spread, currently
quoted by market makers, that varies with the market and trading conditions.
The dynamic nature of financial markets and trading, as with the rest of social
sciences, where changes can be observed and decisions can be made by
participants to influence the system, means that this model has to be adaptive
and include a feedback loop that alters the bid-offer adjustment based on the
modifications observed in the market and trading conditions, without a
significant time delay.
  The factors used to adjust the spread are price volatility, which is publicly
observable, and trade count and volume, which are generally known only to the
market maker, in various instruments over different historical durations in
time. The contributions of each factor to the bid-offer adjustment are computed
separately and then consolidated to produce a very adaptive bid-offer
quotation. The author uses the currency markets to build the sample model
because they are extremely liquid and trading in them is not as transparent as
other financial instruments, such as equities. Simulating the number of trades
and the average size of trades from a lognormal distribution, the parameters of
the lognormal distributions are chosen such that the total volume in a certain
interval matches the volume publicly mentioned by currency trading firms. This
methodology can easily be extended to other financial instruments and possibly
to any product with the ability to make electronic price quotations, or can
even be used to periodically perform manual price updates on products that are
traded non-electronically.
</summary>
    <author>
      <name>Ravi Kashyap</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.3905/jot.2014.9.3.042</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.3905/jot.2014.9.3.042" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">The Journal of Trading, 9(3) 2014, 42-55</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1601.00085v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.00085v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1602.06855v2</id>
    <updated>2016-03-09T22:08:52Z</updated>
    <published>2016-02-22T16:58:11Z</published>
    <title>Tsallis statistics in the income distribution of Brazil</title>
    <summary>  This paper discusses the empirical evidence of Tsallis statistical functions
in the personal income distribution of Brazil. Yearly samples from 1978 to 2014
were linearized by the q-logarithm and straight lines were fitted to the entire
range of the income data in all samples, producing a two-parameters-only single
function representation of the whole distribution in every year. The results
showed that the time evolution of the parameters is periodic and plotting one
in terms of the other reveals a cycle mostly clockwise. It was also found that
the empirical data oscillate periodically around the fitted straight lines with
the amplitude growing as the income values increase. Since the entire income
data range can be fitted by a single function, this raises questions on
previous results claiming that the income distribution is constituted by a well
defined two-classes-base income structure, since such a division in two very
distinct income classes might not be an intrinsic property of societies, but a
consequence of an a priori fitting-choice procedure that may leave aside
possibly important income dynamics at the intermediate levels.
</summary>
    <author>
      <name>Abner D. Soares</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Comissão Nacional de Energia Nuclear - CNEN, Rio de Janeiro</arxiv:affiliation>
    </author>
    <author>
      <name>Newton J. Moura Jr.</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Instituto Brasileiro de Geografia e Estatística - IBGE, Rio de Janeiro</arxiv:affiliation>
    </author>
    <author>
      <name>Marcelo B. Ribeiro</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Instituto de Física, Universidade Federal do Rio de Janeiro - UFRJ</arxiv:affiliation>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Observatório do Valongo, Universidade Federal do Rio de Janeiro - UFRJ</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.chaos.2016.02.026</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.chaos.2016.02.026" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 figures, 39 graphs, 17 pages, LaTeX. Minor changes to match
  version sent to publisher. To appear in "Chaos, Solitons &amp; Fractals"</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Chaos, Solitons and Fractals 88 (2016) 158-171</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1602.06855v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1602.06855v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.02740v4</id>
    <updated>2017-07-31T10:48:01Z</updated>
    <published>2016-08-09T09:30:37Z</published>
    <title>Bayesian Nonparametric Sparse Seemingly Unrelated Regression Model (SUR)</title>
    <summary>  Seemingly unrelated regression (SUR) models are useful in studying the
interactions among different variables. In a high dimensional setting or when
applied to large panel of time series, these models require a large number of
parameters to be estimated and suffer of inferential problems. To avoid
overparametrization and overfitting issues, we propose a hierarchical Dirichlet
process prior for SUR models, which allows shrinkage of SUR coefficients toward
multiple locations and identification of group of coefficients. We propose a
two-stage hierarchical prior distribution, where the first stage of the
hierarchy consists in a Lasso conditionally independent prior distribution of
the Normal-Gamma family for the SUR coefficients. The second stage is given by
a random mixture distribution for the Normal-Gamma hyperparameters, which
allows for parameter parsimony through two components: the first one is a
random Dirac point-mass distribution, which induces sparsity in the SUR
coefficients; the second is a Dirichlet process prior, which allows for
clustering of the SUR coefficients. Our sparse SUR model with multiple
locations, scales and shapes includes the Vector autoregressive models (VAR)
and dynamic panel models as special cases. We consider an international
business cycle applications to show the effectiveness of our model and
inference approach. Our new multiple shrinkage prior model allows us to better
understand shock transmission phenomena, to extract coloured networks and to
classify the linkages strenght. The empirical results represent a different
point of view on international business cycles providing interesting new
findings in the relationship between core and pheriphery countries.
</summary>
    <author>
      <name>Monica Billio</name>
    </author>
    <author>
      <name>Roberto Casarin</name>
    </author>
    <author>
      <name>Luca Rossini</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">New completed version of the paper. New plot and new interesting
  results 38 pages, 9 Figures, 2 Tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1608.02740v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.02740v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.06186v3</id>
    <updated>2017-09-02T18:04:47Z</updated>
    <published>2016-11-26T12:14:53Z</published>
    <title>A Markovian Model of the Evolving World Input-Output Network</title>
    <summary>  The initial theoretical connections between Leontief input-output models and
Markov chains were established back in 1950s. However, considering the wide
variety of mathematical properties of Markov chains, there has not been a full
investigation of evolving world economic networks with Markov chain formalism.
Using the recently available world input-output database, we modeled the
evolution of the world economic network from 1995 to 2011 through analysis of a
series of finite Markov chains. We assessed different aspects of this evolving
system via different properties of the Markov chains such as mixing time,
Kemeny constant, steady state probabilities and perturbation analysis of the
transition matrices. First, we showed how the time series of mixing times and
Kemeny constants could be used as an aggregate index of globalization. Next, we
focused on the steady state probabilities as a measure of structural power of
the economies that are comparable to GDP shares of economies as the traditional
index of economies. Further, we introduced two measures of systemic risk,
called systemic influence and systemic fragility, where the former is the ratio
of number of influenced nodes to the total number of nodes, caused by a shock
in the activity of a node and the latter is based on the number of times a
specific economic node is affected by a shock in the activity of any of the
other nodes. Finally, focusing on Kemeny constant as a global indicator of
monetary flow across the network, we showed that there is a paradoxical effect
of a change in activity levels of economic nodes on the overall flow of the
network. While the economic slowdown of the majority of nodes with high
structural power results to a slower average monetary flow over the network,
there are some nodes, where their slowdowns improve the overall quality of the
network in terms of connectivity and the average monetary flow.
</summary>
    <author>
      <name>Vahid Moosavi</name>
    </author>
    <author>
      <name>Giulio Isacchini</name>
    </author>
    <link href="http://arxiv.org/abs/1612.06186v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.06186v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1702.02007v1</id>
    <updated>2017-02-07T13:40:33Z</updated>
    <published>2017-02-07T13:40:33Z</published>
    <title>The Installation Costs of a Satellite and Space Shuttle Launch Complex
  as a Public Expenditure Project</title>
    <summary>  From the 1940's to the present, space explorations, which is a highly
important topic for the world and human beings, penetrate into many areas from
the communication to the national security as well as from the discovery of
exoplanets and new life forms to space mining. On the top of the countries
which do researches on these fields are the developed countries and the
developing countries are only used as launch areas, in an irrelevant manner of
the research and development. However, developing countries can significantly
reduce foreign dependency and security flaws as well as providing important
reputation gain in international platforms by conducting space research and
development activities as already done by developed countries. All the large
scale space probes conducted by developed countries oblige Turkey to develop
space researches in terms of economy, security and scientific aspects. Due to
these reasons, the approximate costs of a launch base, which will be installed
to conduct space researches in Turkey, and of a satellite or a spacecraft,
which will be able to launch from this base and serve a variety of purposes,
are calculated in this study. In an effort to make the mentioned calculations,
examples of various countries that have already established a launch base and
already launched from these bases are analyzed and some projections are built
for Turkey by calculating the estimated costs. Since these projections must be
carried out by the Republic of Turkey since the private sector in Turkey will
not be willing to invest in such activities, the possible public advantages can
be gained through these activities are also mentioned and evaluated.
</summary>
    <author>
      <name>Dogus Ozuyar</name>
    </author>
    <author>
      <name>Sevilay Gumus Ozuyar</name>
    </author>
    <author>
      <name>Oguzhan Karadeniz</name>
    </author>
    <author>
      <name>Ozge Varol</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2nd International Annual Meeting of Sosyoekonomi Society</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Sosyoekonomi proceedings book, ISBN:978-605-9190-61-9, 2016</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1702.02007v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1702.02007v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91-06" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.01369v1</id>
    <updated>2017-03-04T00:57:27Z</updated>
    <published>2017-03-04T00:57:27Z</published>
    <title>Collective Learning in China's Regional Economic Development</title>
    <summary>  Industrial development is the process by which economies learn how to produce
new products and services. But how do economies learn? And who do they learn
from? The literature on economic geography and economic development has
emphasized two learning channels: inter-industry learning, which involves
learning from related industries; and inter-regional learning, which involves
learning from neighboring regions. Here we use 25 years of data describing the
evolution of China's economy between 1990 and 2015--a period when China
multiplied its GDP per capita by a factor of ten--to explore how Chinese
provinces diversified their economies. First, we show that the probability that
a province will develop a new industry increases with the number of related
industries that are already present in that province, a fact that is suggestive
of inter-industry learning. Also, we show that the probability that a province
will develop an industry increases with the number of neighboring provinces
that are developed in that industry, a fact suggestive of inter-regional
learning. Moreover, we find that the combination of these two channels exhibit
diminishing returns, meaning that the contribution of either of these learning
channels is redundant when the other one is present. Finally, we address
endogeneity concerns by using the introduction of high-speed rail as an
instrument to isolate the effects of inter-regional learning. Our
differences-in-differences (DID) analysis reveals that the introduction of high
speed-rail increased the industrial similarity of pairs of provinces connected
by high-speed rail. Also, industries in provinces that were connected by rail
increased their productivity when they were connected by rail to other
provinces where that industry was already present. These findings suggest that
inter-regional and inter-industry learning played a role in China's great
economic expansion.
</summary>
    <author>
      <name>Jian Gao</name>
    </author>
    <author>
      <name>Bogang Jun</name>
    </author>
    <author>
      <name>Alex "Sandy" Pentland</name>
    </author>
    <author>
      <name>Tao Zhou</name>
    </author>
    <author>
      <name>Cesar A. Hidalgo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">29 pages, 9 figures, 4 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1703.01369v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.01369v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.05911v1</id>
    <updated>2017-06-09T15:30:42Z</updated>
    <published>2017-06-09T15:30:42Z</published>
    <title>Food Productivity Trends from Hybrid Corn: Statistical Analysis of
  Patents and Field-test data</title>
    <summary>  In this research we study productivity trends of hybrid corn - an important
subdomain of food production. We estimate the yearly rate of yield improvement
of hybrid corn (measured as bushel per acre) by using both information on
yields contained in US patent documents for patented hybrid corn varieties and
on field-test data of several hybrid corn varieties performed at US State
level. We have used a generalization of Moore's law to fit productivity trends
and obtain the performance improvement rate by analyzing time series of hybrid
corn performance for a period covering the last thirty years. The linear
regressions results obtained from different data sources indicate that the
estimated improvement rates per year are between 1.2 and 2.4 percent. In
particular, using yields reported in a sample of patents filed between 1985 and
2010, we estimated an improvement rate of 0.015 (R2 = 0.74, Pvalue = 1.37 x
10^-8). Moreover, we apply two predicting models developed by Benson and Magee
(2015) and Triulzi and Magee (2016) that only use patent metadata to estimate
the rate of improvement. We compare these predicted values to the rate
estimated using US States field-test data. We find that, due to a turning point
in patenting practices which begun in 2008, only the predicted rate (rate =
0.015) using patents filed before 2008 is consistent with the empirical rate.
Finally, we also investigate at the micro level - on the basis of 70 patents
(granted between 1986 and 2015) - whether the number of citations received by a
patent is correlated with performance achieved by the patented variety. We find
that the relative performance (yield ratio) of the patented seed is positively
correlated with the total number of citations received by the patent (until
December 2015) but not the citations received within 3 years after the granted
year, with the patent application year used as control variable.
</summary>
    <author>
      <name>Mariam Barry</name>
    </author>
    <author>
      <name>Giorgio Triulzi</name>
    </author>
    <author>
      <name>Christopher L. Magee</name>
    </author>
    <link href="http://arxiv.org/abs/1706.05911v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.05911v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.05826v3</id>
    <updated>2017-07-24T21:26:01Z</updated>
    <published>2017-07-18T19:19:24Z</published>
    <title>Improving the Economic Complexity Index</title>
    <summary>  How much knowledge is there in an economy? In recent years, data on the mix
of products that countries export has been used to construct measures of
economic complexity that estimate the knowledge available in an economy and
predict future economic growth. Here we introduce a new and simpler metric of
economic complexity (ECI+) that measures the total exports of an economy
corrected by how difficult it is to export each product. We use data from 1973
to 2013 to compare the ability of ECI+, the Economic Complexity Index (ECI),
and Fitness complexity, to predict future economic growth using 5, 10, and
20-year panels in a pooled OLS, a random effects model, and a fixed effects
model. We find that ECI+ outperforms ECI and Fitness in its ability to predict
economic growth and in the consistency of its estimators across most
econometric specifications. On average, one standard deviation increase in ECI+
is associated with an increase in annualized growth of about 4% to 5%. We then
combine ECI+ with measures of physical capital, human capital, and
institutions, to find a robust model of economic growth. The ability of ECI+ to
predict growth, and the value of its coefficient, is robust to these controls.
Also, we find that human capital, political stability, and control of
corruption; are positively associated with future economic growth, and that
income is negatively associated with growth, in agreement with the traditional
growth literature. Finally, we use ECI+ to generate economic growth predictions
for the next 20 years and compare these predictions with the ones obtained
using ECI and Fitness. These findings improve the methods available to estimate
the knowledge intensity of economies and predict future economic growth.
</summary>
    <author>
      <name>Saleh Albeaik</name>
    </author>
    <author>
      <name>Mary Kaltenberg</name>
    </author>
    <author>
      <name>Mansour Alsaleh</name>
    </author>
    <author>
      <name>Cesar A. Hidalgo</name>
    </author>
    <link href="http://arxiv.org/abs/1707.05826v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.05826v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.04107v1</id>
    <updated>2017-08-09T19:41:16Z</updated>
    <published>2017-08-09T19:41:16Z</published>
    <title>729 new measures of economic complexity (Addendum to Improving the
  Economic Complexity Index)</title>
    <summary>  Recently we uploaded to the arxiv a paper entitled: Improving the Economic
Complexity Index. There, we compared three metrics of the knowledge intensity
of an economy, the original metric we published in 2009 (the Economic
Complexity Index or ECI), a variation of the metric proposed in 2012, and a
variation we called ECI+. It was brought to our attention that the definition
of ECI+ was equivalent to the variation of the metric proposed in 2012. We have
verified this claim, and found that while the equations are not exactly the
same, they are similar enough to be our own oversight. More importantly, we now
ask: how many variations of the original ECI work? In this paper we provide a
simple unifying framework to explore multiple variations of ECI, including both
the original 2009 ECI and the 2012 variation. We found that a large fraction of
variations have a similar predictive power, indicating that the chance of
finding a variation of ECI that works, after the seminal 2009 measure, are
surprisingly high. In fact, more than 28 percent of these variations have a
predictive power that is within 90 percent of the maximum for any variation.
These findings show that, once the idea of measuring economic complexity was
out, creating a variation with a similar predictive power (like the ones
proposed in 2012) was trivial (a 1 in 3 shot). More importantly, the result
show that using exports data to measure the knowledge intensity of an economy
is a robust phenomenon that works for multiple functional forms. Moreover, the
fact that multiple variations of the 2009 ECI perform close to the maximum,
tells us that no variation of ECI will have a performance that is substantially
better. This suggests that research efforts should focus on uncovering the
mechanisms that contribute to the diffusion and accumulation of productive
knowledge instead of on exploring small variations to existing measures.
</summary>
    <author>
      <name>Saleh Albeaik</name>
    </author>
    <author>
      <name>Mary Kaltenberg</name>
    </author>
    <author>
      <name>Mansour Alsaleh</name>
    </author>
    <author>
      <name>César A. Hidalgo</name>
    </author>
    <link href="http://arxiv.org/abs/1708.04107v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.04107v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1710.01768v1</id>
    <updated>2017-09-04T06:07:33Z</updated>
    <published>2017-09-04T06:07:33Z</published>
    <title>Explaining the Mechanism of Growth in the Past Two Million Years Vol. I</title>
    <summary>  Economic growth and the growth of human population in the past 2,000,000
years are extensively examined. Data are found to be in a clear contradiction
of the currently accepted explanations of the mechanism of growth, which
revolve around two fundamental but incorrect doctrines: (1) the doctrine of
stagnation (inappropriately labelled also as Malthusian stagnation, because
Malthus never claimed that his positive checks would cause a long-lasting and
wide-spread stagnation) and (2) the doctrine of explosion described also as a
takeoff, sprint, spike or by other similar attributes. These doctrines and
other related postulates are contradicted even by precisely the same data,
which are used in the economic research and by the research results published
in a prestigious scientific journal as early as in 1960. The generally accepted
explanations are not based on a rigorous analysis of data but on impressions
created by the easily misleading features of hyperbolic distributions. Two
leading theories: the Demographic Transitions Theory (or Model) and the Unified
Growth Theory are fundamentally incorrect. Descriptions of the past
socio-economic conditions are not questioned. They might have been harsh,
difficult and primitive but they are not reflected in the growth trajectories.
They did not create stagnation in the economic growth and in the growth of
population. Likewise, impacts of the Industrial Revolution on many aspects of
life are not questioned. It is only demonstrated that this event had absolutely
no impact on shaping growth trajectories. A general law of growth is formulated
and used to explain the mechanism of growth of human population and of economic
growth. The growth was predominantly hyperbolic. Such a growth is described by
exceptionally simple mathematical function and the explanation of the mechanism
of growth turns out to be also simple.
</summary>
    <author>
      <name>Ron W. Nielsen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">85 pages, 44,161 words. arXiv admin note: substantial text overlap
  with arXiv:1708.08673, arXiv:1601.07291, arXiv:1601.04686, arXiv:1510.00992,
  arXiv:1603.01685, arXiv:1509.06612</arxiv:comment>
    <link href="http://arxiv.org/abs/1710.01768v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1710.01768v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1406.0209v3</id>
    <updated>2017-08-07T15:34:01Z</updated>
    <published>2014-06-01T21:27:18Z</published>
    <title>An inverse optimal stopping problem for diffusion processes</title>
    <summary>  Let $X$ be a one-dimensional diffusion and let
$g\colon[0,T]\times\mathbb{R}\to\mathbb{R}$ be a payoff function depending on
time and the value of $X$. The paper analyzes the inverse optimal stopping
problem of finding a time-dependent function $\pi:[0,T]\to\mathbb{R}$ such that
a given stopping time $\tau^{\star}$ is a solution of the stopping problem
$\sup_{\tau}\mathbb{E}\left[g(\tau,X_{\tau})+\pi(\tau)\right]\,.$ Under
regularity and monotonicity conditions, there exists a solution $\pi$ if and
only if $\tau^{\star}$ is the first time when $X$ exceeds a time-dependent
barrier $b$, i.e. $\tau^{\star}=\inf\left\{ t\ge0\,|\,X_{t}\ge b(t)\right\}
\,.$ We prove uniqueness of the solution $\pi$ and derive a closed form
representation. The representation is based on an auxiliary process which is a
version of the original diffusion $X$ reflected at $b$ towards the continuation
region. The results lead to a new integral equation characterizing the stopping
boundary $b$ of the stopping problem
$\sup_{\tau}\mathbb{E}\left[g(\tau,X_{\tau})\right]$.
</summary>
    <author>
      <name>Thomas Kruse</name>
    </author>
    <author>
      <name>Philipp Strack</name>
    </author>
    <link href="http://arxiv.org/abs/1406.0209v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1406.0209v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1406.6441v4</id>
    <updated>2014-11-30T15:28:15Z</updated>
    <published>2014-06-25T02:53:37Z</published>
    <title>Thermodynamics of inequalities: from precariousness to economic
  stratification</title>
    <summary>  Growing economic inequalities are observed in several countries throughout
the world. Following Pareto, the power-law structure of these inequalities has
been the subject of much theoretical and empirical work. But their
nonequilibrium dynamics, e.g. after a policy change, remains incompletely
understood. Here we introduce a thermodynamical theory of inequalities based on
the analogy between economic stratification and statistical entropy. Within
this framework we identify the combination of upward mobility with
precariousness as a fundamental driver of inequality. We formalize this
statement by a "second-law" inequality displaying upward mobility and
precariousness as thermodynamic conjugate variables. We estimate the time scale
for the "relaxation" of the wealth distribution after a sudden change of the
after-tax return on capital. Our method can be generalized to gain insight into
the dynamics of inequalities in any Markovian model of socioeconomic
interactions.
</summary>
    <author>
      <name>Matteo Smerlak</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.physa.2015.09.001</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.physa.2015.09.001" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Physica A 441, 40-50 (2016)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1406.6441v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1406.6441v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1408.5951v5</id>
    <updated>2016-06-30T22:20:32Z</updated>
    <published>2014-08-26T00:22:36Z</published>
    <title>Fragility of the Commons under Prospect-Theoretic Risk Attitudes</title>
    <summary>  We study a common-pool resource game where the resource experiences failure
with a probability that grows with the aggregate investment in the resource. To
capture decision making under such uncertainty, we model each player's risk
preference according to the value function from prospect theory. We show the
existence and uniqueness of a pure Nash equilibrium when the players have
heterogeneous risk preferences and under certain assumptions on the rate of
return and failure probability of the resource. Greater competition, vis-a-vis
the number of players, increases the failure probability at the Nash
equilibrium; we quantify this effect by obtaining bounds on the ratio of the
failure probability at the Nash equilibrium to the failure probability under
investment by a single user. We further show that heterogeneity in attitudes
towards loss aversion leads to higher failure probability of the resource at
the equilibrium.
</summary>
    <author>
      <name>Ashish R. Hota</name>
    </author>
    <author>
      <name>Siddharth Garg</name>
    </author>
    <author>
      <name>Shreyas Sundaram</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.geb.2016.06.003</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.geb.2016.06.003" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted for publication in Games and Economic Behavior, 2016</arxiv:comment>
    <link href="http://arxiv.org/abs/1408.5951v5" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1408.5951v5" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1409.1786v2</id>
    <updated>2014-09-30T09:52:03Z</updated>
    <published>2014-09-05T13:35:02Z</published>
    <title>Zero-determinant strategies in iterated multi-strategy games</title>
    <summary>  Self-serving, rational agents sometimes cooperate to their mutual benefit.
The two-player iterated prisoner's dilemma game is a model for including the
emergence of cooperation. It is generally believed that there is no simple
ultimatum strategy which a player can control the return of the other
participants. The recent discovery of the powerful class of zero-determinant
strategies in the iterated prisoner's dilemma dramatically expands our
understanding of the classic game by uncovering strategies that provide a
unilateral advantage to sentient players pitted against unwitting opponents.
However, strategies in the prisoner's dilemma game are only two strategies. Are
there these results for general multi-strategy games? To address this question,
the paper develops a theory for zero-determinant strategies for multi-strategy
games, with any number of strategies. The analytical results exhibit a similar
yet different scenario to the case of two-strategy games. Zero-determinant
strategies in iterated prisoner's dilemma can be seen as degenerate case of our
results. The results are also applied to the snowdrift game, the hawk-dove game
and the chicken game.
</summary>
    <author>
      <name>Jin-Li Guo</name>
    </author>
    <link href="http://arxiv.org/abs/1409.1786v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1409.1786v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1409.2760v1</id>
    <updated>2014-09-08T10:06:35Z</updated>
    <published>2014-09-08T10:06:35Z</published>
    <title>Synergy cycles in the Norwegian innovation system: The relation between
  synergy and cycle values</title>
    <summary>  The knowledge base of an economy measured in terms of Triple Helix relations
can be analyzed in terms of mutual information among geographical, sectorial,
and size distributions of firms as dimensions of the probabilistic entropy. The
resulting synergy values of a TH system provide static snapshots. In this
study, we add the time dimension and analyze the synergy dynamics using the
Norwegian innovation system as an example. The synergy among the three
dimensions can be mapped as a set of partial time series and spectrally
analyzed. The results suggest that the synergy at the level of both the country
and its 19 counties shoe non-chaotic oscillatory behavior and resonates in a
set of natural frequencies. That is, synergy surges and drops are non-random
and can be analyzed and predicted. There is a proportional dependence between
the amplitudes of oscillations and synergy values and an inverse proportional
dependence between the oscillation frequencies' relative inputs and synergy
values. This analysis of the data informs us that one can expect
frequency-related synergy-volatility growth in relation to the synergy value
and a shift in the synergy volatility towards the long-term fluctuations with
the synergy growth.
</summary>
    <author>
      <name>Inga Ivanova</name>
    </author>
    <author>
      <name>Oivind Strand</name>
    </author>
    <author>
      <name>Loet Leydesdorff</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">31 pages, 16 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1409.2760v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1409.2760v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.0127v1</id>
    <updated>2014-11-29T17:38:56Z</updated>
    <published>2014-11-29T17:38:56Z</published>
    <title>A biased view of a few possible components when reflecting on the
  present decade financial and economic crisis</title>
    <summary>  Is the present economic and financial crisis similar to some previous one? It
would be so nice to prove that universality laws exist for predicting such rare
events under a minimum set of realistic hypotheses. First, I briefly recall
whether patterns, like business cycles, are indeed found, and can be modeled
within a statistical physics, or econophysics, framework. I point to a
simulation model for describing such so called business cycles, under exo- and
endo-genous conditions I discuss self-organized and provoked crashes and their
predictions. I emphasize the role of an of- ten forgotten ingredient: the time
delay in the information flow. I wonder about the information content of
financial data, its mis-interpretation and market manipulation.
</summary>
    <author>
      <name>Marcel Ausloos</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages; 70 refs.; a chapter prepared for "Polymorphic Crisis
  Readings on the Great Recession of the 21st century" edited by Roy Cerqueti</arxiv:comment>
    <link href="http://arxiv.org/abs/1412.0127v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.0127v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.0542v1</id>
    <updated>2014-11-07T15:01:01Z</updated>
    <published>2014-11-07T15:01:01Z</published>
    <title>Budget Imbalance Criteria for Auctions: A Formalized Theorem</title>
    <summary>  We present an original theorem in auction theory: it specifies general
conditions under which the sum of the payments of all bidders is necessarily
not identically zero, and more generally not constant. Moreover, it explicitly
supplies a construction for a finite minimal set of possible bids on which such
a sum is not constant. In particular, this theorem applies to the important
case of a second-price Vickrey auction, where it reduces to a basic result of
which a novel proof is given. To enhance the confidence in this new theorem, it
has been formalized in Isabelle/HOL: the main results and definitions of the
formal proof are re- produced here in common mathematical language, and are
accompanied by an informal discussion about the underlying ideas.
</summary>
    <author>
      <name>Marco B. Caminati</name>
    </author>
    <author>
      <name>Manfred Kerber</name>
    </author>
    <author>
      <name>Colin Rowat</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6th Podlasie Conference on Mathematics 2014, 11 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1412.0542v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.0542v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.MF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.MF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B26 62P20" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.4428v5</id>
    <updated>2017-05-19T18:28:46Z</updated>
    <published>2014-12-15T00:00:15Z</published>
    <title>Nonparametric Stochastic Discount Factor Decomposition</title>
    <summary>  Stochastic discount factor (SDF) processes in dynamic economies admit a
permanent-transitory decomposition in which the permanent component
characterizes pricing over long investment horizons. This paper introduces an
empirical framework to analyze the permanent-transitory decomposition of SDF
processes. Specifically, we show how to estimate nonparametrically the solution
to the Perron-Frobenius eigenfunction problem of Hansen and Scheinkman (2009).
Our empirical framework allows researchers to (i) recover the time series of
the estimated permanent and transitory components and (ii) estimate the yield
and the change of measure which characterize pricing over long investment
horizons. We also introduce nonparametric estimators of the continuation value
function in a class of models with recursive preferences by reinterpreting the
value function recursion as a nonlinear Perron-Frobenius problem. We establish
consistency and convergence rates of the eigenfunction estimators and
asymptotic normality of the eigenvalue estimator and estimators of related
functionals. As an application, we study an economy where the representative
agent is endowed with recursive preferences, allowing for general (nonlinear)
consumption and earnings growth dynamics.
</summary>
    <author>
      <name>Timothy Christensen</name>
    </author>
    <link href="http://arxiv.org/abs/1412.4428v5" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.4428v5" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.MF" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.5452v2</id>
    <updated>2014-12-27T00:00:26Z</updated>
    <published>2014-12-17T15:55:00Z</published>
    <title>Aggregation operators for the measurement of systemic risk</title>
    <summary>  The policy objective of safeguarding financial stability has stimulated a
wave of research on systemic risk analytics, yet it still faces challenges in
measurability. This paper models systemic risk by tapping into expert knowledge
of financial supervisors. We decompose systemic risk into a number of
interconnected segments, for which the level of vulnerability is measured. The
system is modeled in the form of a Fuzzy Cognitive Map (FCM), in which nodes
represent vulnerability in segments and links their interconnectedness. A main
problem tackled in this paper is the aggregation of values in different
interrelated nodes of the network to obtain an estimate systemic risk. To this
end, the Choquet integral is employed for aggregating expert evaluations of
measures, as it allows for the integration of interrelations among factors in
the aggregation process. The approach is illustrated through two applications
in a European setting. First, we provide an estimation of systemic risk with a
of pan-European set-up. Second, we estimate country-level risks, allowing for a
more granular decomposition. This sets a starting point for the use of the
rich, oftentimes tacit, knowledge in policy organizations.
</summary>
    <author>
      <name>Jozsef Mezei</name>
    </author>
    <author>
      <name>Peter Sarlin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted</arxiv:comment>
    <link href="http://arxiv.org/abs/1412.5452v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.5452v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1501.02276v2</id>
    <updated>2015-01-22T17:50:56Z</updated>
    <published>2015-01-09T21:13:54Z</published>
    <title>The Golden Target: Analyzing the Tracking Performance of Leveraged Gold
  ETFs</title>
    <summary>  This paper studies the empirical tracking performance of leveraged ETFs on
gold, and their price relationships with gold spot and futures. For tracking
the gold spot, we find that our optimized portfolios with short-term gold
futures are highly effective in replicating prices. The market-traded gold ETF
(GLD) also exhibits a similar tracking performance. However, we show that
leveraged gold ETFs tend to underperform their corresponding leveraged
benchmark. Moreover, the underperformance worsens over a longer holding period.
In contrast, we illustrate that a dynamic portfolio of gold futures tracks
significantly better than various static portfolios. The dynamic portfolio also
consistently outperforms the respective market-traded LETFs for different
leverage ratios over multiple years.
</summary>
    <author>
      <name>Tim Leung</name>
    </author>
    <author>
      <name>Brian Ward</name>
    </author>
    <link href="http://arxiv.org/abs/1501.02276v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1501.02276v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1501.04682v3</id>
    <updated>2016-04-01T14:22:36Z</updated>
    <published>2015-01-20T00:18:18Z</published>
    <title>Toward robust early-warning models: A horse race, ensembles and model
  uncertainty</title>
    <summary>  This paper presents first steps toward robust models for crisis prediction.
We conduct a horse race of conventional statistical methods and more recent
machine learning methods as early-warning models. As individual models are in
the literature most often built in isolation of other methods, the exercise is
of high relevance for assessing the relative performance of a wide variety of
methods. Further, we test various ensemble approaches to aggregating the
information products of the built models, providing a more robust basis for
measuring country-level vulnerabilities. Finally, we provide approaches to
estimating model uncertainty in early-warning exercises, particularly model
performance uncertainty and model output uncertainty. The approaches put
forward in this paper are shown with Europe as a playground. Generally, our
results show that the conventional statistical approaches are outperformed by
more advanced machine learning methods, such as k-nearest neighbors and neural
networks, and particularly by model aggregation approaches through ensemble
learning.
</summary>
    <author>
      <name>Markus Holopainen</name>
    </author>
    <author>
      <name>Peter Sarlin</name>
    </author>
    <link href="http://arxiv.org/abs/1501.04682v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1501.04682v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.CP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1501.05771v1</id>
    <updated>2015-01-23T11:22:46Z</updated>
    <published>2015-01-23T11:22:46Z</published>
    <title>Positively-homogeneous Konus-Divisia indices and their applications to
  demand analysis and forecasting</title>
    <summary>  This paper is devoted to revealed preference theory and its applications to
testing economic data for consistency with utility maximization hypothesis,
construction of index numbers, and forecasting. The quantitative measures of
inconsistency of economic data with utility maximization behavior are also
discussed. The structure of the paper is based on comparison between the two
tests of revealed preference theory - generalized axiom of revealed preference
(GARP) and homothetic axiom of revealed prefernce (HARP). We do this comparison
both theoretically and empirically. In particular we assess empirically the
power of these tests for consistency with maximization behavior and the size of
forecasting sets based on them. For the forecasting problem we show that when
using HARP there is an effective way of building the forecasting set since this
set is given by the solution of the system of linear inequalities. The paper
also touches upon the question of testing a set of Engel curves rather than
finite set of observations for consistency with utility maximization behavior
and shows that this question has effective solution when we require the
rationalizing utility function to be positively homogeneous.
</summary>
    <author>
      <name>Nikolay Klemashev</name>
    </author>
    <author>
      <name>Alexander Shananin</name>
    </author>
    <link href="http://arxiv.org/abs/1501.05771v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1501.05771v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.04772v1</id>
    <updated>2015-03-12T18:11:59Z</updated>
    <published>2015-03-12T18:11:59Z</published>
    <title>A dynamic game on Green Supply Chain Management</title>
    <summary>  In this paper, we establish a dynamic game to allocate CSR (Corporate Social
Responsibility) to the members of a supply chain. We propose a model of
three-tier supply chain in decentralized state that is including supplier,
manufacturer and retailer. For analyzing supply chain performance in
decentralized state and the relationships between the members of supply chain,
we use Stackelberg game and we consider in this paper a hierarchical
equilibrium solution for a two-level game. Specially, we formulate a model that
crosses through multi-periods by a dynamic discreet Stackelberg game. We try to
obtain an equilibrium point at where both the profits of members and the level
of CSR taken by supply chains are maximized.
</summary>
    <author>
      <name>Mehrnoosh Khademi</name>
    </author>
    <author>
      <name>Massimiliano Ferrara</name>
    </author>
    <author>
      <name>Bruno Pansera</name>
    </author>
    <author>
      <name>Mehdi Salimi</name>
    </author>
    <link href="http://arxiv.org/abs/1503.04772v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.04772v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.00475v1</id>
    <updated>2015-05-03T20:56:27Z</updated>
    <published>2015-05-03T20:56:27Z</published>
    <title>On the Forecast Combination Puzzle</title>
    <summary>  It is often reported in forecast combination literature that a simple average
of candidate forecasts is more robust than sophisticated combining methods.
This phenomenon is usually referred to as the "forecast combination puzzle".
Motivated by this puzzle, we explore its possible explanations including
estimation error, invalid weighting formulas and model screening. We show that
existing understanding of the puzzle should be complemented by the distinction
of different forecast combination scenarios known as combining for adaptation
and combining for improvement. Applying combining methods without consideration
of the underlying scenario can itself cause the puzzle. Based on our new
understandings, both simulations and real data evaluations are conducted to
illustrate the causes of the puzzle. We further propose a multi-level AFTER
strategy that can integrate the strengths of different combining methods and
adapt intelligently to the underlying scenario. In particular, by treating the
simple average as a candidate forecast, the proposed strategy is shown to avoid
the heavy cost of estimation error and, to a large extent, solve the forecast
combination puzzle.
</summary>
    <author>
      <name>Wei Qian</name>
    </author>
    <author>
      <name>Craig A. Rolling</name>
    </author>
    <author>
      <name>Gang Cheng</name>
    </author>
    <author>
      <name>Yuhong Yang</name>
    </author>
    <link href="http://arxiv.org/abs/1505.00475v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.00475v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.05737v3</id>
    <updated>2017-07-19T12:05:14Z</updated>
    <published>2015-05-15T01:16:21Z</published>
    <title>Product-Mix Auctions and Tropical Geometry</title>
    <summary>  In a recent and ongoing work, Baldwin and Klemperer explored a connection
between tropical geometry and economics. They gave a sufficient condition for
the existence of competitive equilibrium in product-mix auctions of indivisible
goods. This result, which we call the Unimodularity Theorem, can also be traced
back to the work of Danilov, Koshevoy, and Murota in discrete convex analysis.
We give a new proof of the Unimodularity Theorem via the classical
unimodularity theorem in integer programming. We give a unified treatment of
these results via tropical geometry and formulate a new sufficient condition
for competitive equilibrium when there are only two types of product.
Generalizations of our theorem in higher dimensions are equivalent to various
forms of the Oda conjecture in algebraic geometry.
</summary>
    <author>
      <name>Ngoc Mai Tran</name>
    </author>
    <author>
      <name>Josephine Yu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">23 pages plus references, 4 figures. Exposition improved. Added
  Section 6 on connections to toric geometry</arxiv:comment>
    <link href="http://arxiv.org/abs/1505.05737v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.05737v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B26, 14T05, 52B20" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.01315v1</id>
    <updated>2015-06-01T04:42:36Z</updated>
    <published>2015-06-01T04:42:36Z</published>
    <title>Impossibility Theorems and the Universal Algebraic Toolkit</title>
    <summary>  We elucidate a close connection between the Theory of Judgment Aggregation
(more generally, Evaluation Aggregation), and a relatively young but rapidly
growing field of universal algebra, that was primarily developed to investigate
constraint satisfaction problems. Our connection yields a full classification
of non-binary evaluations into possibility and impossibility domains both under
the idempotent and the supportive conditions. Prior to the current result E.
Dokow and R. Holzman nearly classified non-binary evaluations in the supportive
case, by combinatorial means. The algebraic approach gives us new insights to
the easier binary case as well, which had been fully classified by the above
authors. Our algebraic view lets us put forth a suggestion about a
strengthening of the Non-dictatorship criterion, that helps us avoid "outliers"
like the affine subspace. Finally, we give upper bounds on the complexity of
computing if a domain is impossible or not (to our best knowledge no finite
time bounds were given earlier).
</summary>
    <author>
      <name>Mario Szegedy</name>
    </author>
    <author>
      <name>Yixin Xu</name>
    </author>
    <link href="http://arxiv.org/abs/1506.01315v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.01315v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.05497v1</id>
    <updated>2015-06-17T21:08:02Z</updated>
    <published>2015-06-17T21:08:02Z</published>
    <title>Optimal Dynamic Contracts for a Large-Scale Principal-Agent Hierarchy: A
  Concavity-Preserving Approach</title>
    <summary>  We present a continuous-time contract whereby a top-level player can
incentivize a hierarchy of players below him to act in his best interest
despite only observing the output of his direct subordinate. This paper extends
Sannikov's approach from a situation of asymmetric information between a
principal and an agent to one of hierarchical information between several
players. We develop an iterative algorithm for constructing an incentive
compatible contract and define the correct notion of concavity which must be
preserved during iteration. We identify conditions under which a dynamic
programming construction of an optimal dynamic contract can be reduced to only
a one-dimensional state space and one-dimensional control set, independent of
the size of the hierarchy. In this sense, our results contribute to the
applicability of dynamic programming on dynamic contracts for a large-scale
principal-agent hierarchy.
</summary>
    <author>
      <name>Christopher W. Miller</name>
    </author>
    <author>
      <name>Insoon Yang</name>
    </author>
    <link href="http://arxiv.org/abs/1506.05497v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.05497v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.01729v3</id>
    <updated>2017-04-29T15:04:16Z</updated>
    <published>2015-07-07T09:44:30Z</published>
    <title>Measuring the frequency dynamics of financial connectedness and systemic
  risk</title>
    <summary>  Risk management has generally focused on aggregate connectedness, overlooking
its cyclical sources. We argue that the frequency dynamics is insightful for
studying this connectedness because shocks with heterogeneous frequency
responses create linkages with various degrees of persistence. Such connections
are important for understanding the possible sources of systemic risk specific
to economic cycles but remain hidden when aggregate measures of connectedness
are used. To estimate connectedness on short-, medium-, and long-term financial
cycles, we propose a general framework based on spectral representation of
variance decompositions. In an empirical application, we document the rich
dynamics of volatility connectedness in the US financial institutions with
short-term connections due to contemporaneous correlations as well as
significant weekly, monthly, and longer connections that play a role. Hence, we
find that the financial market clears part of the information but that the
permanent changes in investors' expectations having longer-term responses are
non-negligible.
</summary>
    <author>
      <name>Jozef Barunik</name>
    </author>
    <author>
      <name>Tomas Krehlik</name>
    </author>
    <link href="http://arxiv.org/abs/1507.01729v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.01729v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.04236v2</id>
    <updated>2015-09-07T14:10:56Z</updated>
    <published>2015-07-15T14:45:11Z</published>
    <title>Invariant features of spatial inequality in consumption: the case of
  India</title>
    <summary>  We study the distributional features and inequality of consumption
expenditure across India, for different states, castes, religion and
urban-rural divide. We find that even though the aggregate measures of
inequality are fairly diversified across states, the consumption distributions
show near identical statistics, once properly normalized. This feature is seen
to be robust with respect to variations in sociological and economic factors.
We also show that state-wise inequality seems to be positively correlated with
growth which is in accord with the traditional idea of Kuznets' curve. We
present a brief model to account for the invariance found empirically and show
that better but riskier technology draws can create a positive correlation
between inequality and growth.
</summary>
    <author>
      <name>Arnab Chatterjee</name>
    </author>
    <author>
      <name>Anindya S. Chakrabarti</name>
    </author>
    <author>
      <name>Asim Ghosh</name>
    </author>
    <author>
      <name>Anirban Chakraborti</name>
    </author>
    <author>
      <name>Tushar K. Nandi</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.physa.2015.09.019</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.physa.2015.09.019" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 5 figs, 4 tables; Accepted in Physica A</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Physica A 442 (2016) 169-181</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1507.04236v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.04236v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.04797v1</id>
    <updated>2015-07-16T23:11:39Z</updated>
    <published>2015-07-16T23:11:39Z</published>
    <title>Symmetric Equilibria in Stochastic Timing Games</title>
    <summary>  We construct subgame-perfect equilibria with mixed strategies for symmetric
stochastic timing games with arbitrary strategic incentives. The strategies are
qualitatively different for local first- or second-mover advantages, which we
analyse in turn. When there is a local second-mover advantage, the players may
conduct a war of attrition with stopping rates that we characterize in terms of
the Snell envelope from the general theory of optimal stopping, which is very
general but provides a clear interpretation. With a local first-mover
advantage, stopping typically results from preemption and is abrupt. Equilibria
may differ in the degree of preemption, precisely at which points it is
triggered. We provide an algorithm to characterize where preemption is
inevitable and to establish the existence of corresponding payoff-maximal
symmetric equilibria.
</summary>
    <author>
      <name>Jan-Henrik Steg</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Working Paper 543, Center for Mathematical Economics, Bielefeld
  University</arxiv:comment>
    <link href="http://arxiv.org/abs/1507.04797v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.04797v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="60G40, 91A25, 91A40, 91A55" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.07214v6</id>
    <updated>2017-05-28T07:32:28Z</updated>
    <published>2015-07-26T15:59:16Z</published>
    <title>One trade at a time -- unraveling the Equity Premium Puzzle</title>
    <summary>  Financial markets provide a natural quantitative lab for understanding some
of the most advanced human behaviours. Among them is the invention and use of
mathematical tools known as financial instruments. Besides money, the two most
fundamental financial instruments are bonds and equities. More than 30 years
ago Mehra and Prescott found the numerical performance of equities relative to
government bonds could not be explained by mainstream economics. This empirical
observation, known as the Equity Premium Puzzle, has been defying mainstream
economics ever since. The recent financial crisis revealed an even deeper need
for understanding human behaviour involving financial products. We show how
understanding the rational nature of product design resolves the Equity Premium
Puzzle.
</summary>
    <author>
      <name>Andrei N. Soklakov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1507.07214v6" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.07214v6" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.MF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.02919v2</id>
    <updated>2016-01-15T03:27:51Z</updated>
    <published>2015-08-12T13:58:06Z</published>
    <title>Identification of Insurance Models with Multidimensional Screening</title>
    <summary>  This paper addresses the identification of insurance models with
multidimensional screening where insurees have private information about their
risk and risk aversion. The model includes a random damage and the possibility
of several claims. Screening of insurees relies on their certainty equivalence.
The paper then investigates how data availability on the number of offered
coverages and reported claims affects the identification of the model
primitives under four different scenarios. We show that the model structure is
identified despite bunching due to multidimensional screening and/or a finite
number of offered coverages. The observed number of claims plays a key role in
the identification of the joint distribution of risk and risk aversion. In
addition, the paper derives all the restrictions imposed by the model on
observables. Our results are constructive with explicit equations for
estimation and model testing.
</summary>
    <author>
      <name>Gaurab Aryal</name>
    </author>
    <author>
      <name>Isabelle Perrigne</name>
    </author>
    <author>
      <name>Quang Vuong</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">55 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1508.02919v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.02919v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.MF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.MF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.03677v1</id>
    <updated>2015-08-14T23:38:18Z</updated>
    <published>2015-08-14T23:38:18Z</published>
    <title>Commodity Prices Rise Sharply at Turning Points</title>
    <summary>  Commodity prices depend on supply and demand. With an uneven distribution of
resources, prices are high at locations starved of commodity and low where it
is abundant. We introduce an agent-based model in which agents set their prices
to maximize profit. At steady state, the market self-organizes into three
groups: excess producers, consumers, and balanced agents. When resources are
scarce, prices rise sharply at a turning point due to the disappearance of
excess producers. Market data of commodities provide evidence of turning points
for essential commodities, as well as a yield point for non-essential ones.
</summary>
    <author>
      <name>Bin Li</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Physics, The Hong Kong University of Science and Technology, Hong Kong</arxiv:affiliation>
    </author>
    <author>
      <name>K. Y. Michael Wong</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Physics, The Hong Kong University of Science and Technology, Hong Kong</arxiv:affiliation>
    </author>
    <author>
      <name>Amos H. M. Chan</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Physics, The Hong Kong University of Science and Technology, Hong Kong</arxiv:affiliation>
    </author>
    <author>
      <name>Tsz Yan So</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Physics, The Hong Kong University of Science and Technology, Hong Kong</arxiv:affiliation>
    </author>
    <author>
      <name>Hermanni Heimonen</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Physics, The Hong Kong University of Science and Technology, Hong Kong</arxiv:affiliation>
    </author>
    <author>
      <name>David Saad</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">The Nonlinearity and Complexity Research Group, Aston University, Birmingham B4 7ET, United Kingdom</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 7 figures, 1 table, Supporting Information available at
  http://physics.ust.hk/phkywong/supporting2.pdf</arxiv:comment>
    <link href="http://arxiv.org/abs/1508.03677v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.03677v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1509.01839v1</id>
    <updated>2015-09-06T18:17:29Z</updated>
    <published>2015-09-06T18:17:29Z</published>
    <title>Efficiency and credit ratings: a permutation-information-theory analysis</title>
    <summary>  The role of credit rating agencies has been under severe scrutiny after the
subprime crisis. In this paper we explore the relationship between credit
ratings and informational efficiency of a sample of thirty nine corporate bonds
of US oil and energy companies from April 2008 to November 2012. For that
purpose, we use a powerful statistical tool relatively new in the financial
literature: the complexity-entropy causality plane. This representation space
allows to graphically classify the different bonds according to their degree of
informational efficiency. We find that this classification agrees with the
credit ratings assigned by Moody's. Particularly, we detect the formation of
two clusters, that correspond to the global categories of investment and
speculative grades. Regarding to the latter cluster, two subgroups reflect
distinct levels of efficiency. Additionally, we also find an intriguing absence
of correlation between informational efficiency and firm characteristics. This
allows us to conclude that the proposed permutation-information-theory approach
provides an alternative practical way to justify bond classification.
</summary>
    <author>
      <name>Aurelio F. Bariviera</name>
    </author>
    <author>
      <name>Luciano Zunino</name>
    </author>
    <author>
      <name>M. Belen Guercio</name>
    </author>
    <author>
      <name>Lisana B. Martinez</name>
    </author>
    <author>
      <name>Osvaldo A. Rosso</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1088/1742-5468/2013/08/P08007</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1088/1742-5468/2013/08/P08007" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Statistical Mechanics: Theory and Experiment, Vol 2013,
  Number 08, P08007, 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1509.01839v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1509.01839v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1509.03703v2</id>
    <updated>2015-09-21T22:37:13Z</updated>
    <published>2015-09-12T04:29:22Z</published>
    <title>Production Function of the Mining Sector of Iran</title>
    <summary>  The purpose of this study is to estimate the production function and examine
the structure of production in the mining sector of Iran. Several studies have
already been conducted in estimating production functions of various economic
sectors; however, less attention has been paid to mining sectors. After
examining the stationarity of variables using augmented Dickey-Fuller and
Phillips-Perron tests, this study estimated the production function of the
mining sector of Iran under different scenarios using the co-integration method
and time-series data for 1976-2006. The unconstrained Cobb-Douglas production
function in Tinbergen form provided better results in terms of theoretical
foundations of economics, statistics, and econometrics. These results show that
the structure of the mining sector of Iran is both capital-intensive and
labour-intensive. Based on the findings of this study, the elasticity of
production with respect to capital and labour have been 0.44 and 0.41,
respectively. In addition, the coefficient of time variable, as an indicator of
technological progress in the production process, is statistically significant
representing a positive effect of technological changes on the output of Iran's
mining sector.
</summary>
    <author>
      <name>Seyyed Ali Zeytoon Nejad Moosavian</name>
    </author>
    <link href="http://arxiv.org/abs/1509.03703v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1509.03703v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1509.08291v1</id>
    <updated>2015-09-28T12:18:55Z</updated>
    <published>2015-09-28T12:18:55Z</published>
    <title>The spatial component of R&amp;D networks</title>
    <summary>  We study the role of geography in R&amp;D networks by means of a quantitative,
micro-geographic approach. Using a large database that covers international R&amp;D
collaborations from 1984 to 2009, we localize each actor precisely in space
through its latitude and longitude. This allows us to analyze the R&amp;D network
at all geographic scales simultaneously. Our empirical results show that
despite the high importance of the city level, transnational R&amp;D collaborations
at large distances are much more frequent than expected from similar networks.
This provides evidence for the ambiguity of distance in economic cooperation
which is also suggested by the existing literature. In addition we test whether
the hypothesis of local buzz and global pipelines applies to the observed R&amp;D
network by calculating well-defined metrics from network theory.
</summary>
    <author>
      <name>Tobias Scholl</name>
    </author>
    <author>
      <name>Antonios Garas</name>
    </author>
    <author>
      <name>Frank Schweitzer</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Working paper, 22 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1509.08291v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1509.08291v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.01210v2</id>
    <updated>2016-02-08T17:55:35Z</updated>
    <published>2015-10-01T15:03:55Z</published>
    <title>Trading Networks with Bilateral Contracts</title>
    <summary>  We consider general networks of bilateral contracts that include supply
chains. We define a new stability concept, called trail stability, and show
that any network of bilateral contracts has a trail-stable outcome whenever
agents' preferences satisfy full substitutability. Trail stability is a natural
extension of chain stability, but is a stronger solution concept in general
contract networks. Trail-stable outcomes are not immune to deviations of
arbitrary sets of firms. In fact, we show that outcomes satisfying an even more
demanding stability property -- full trail stability -- always exist. We pin
down conditions under which trail-stable and fully trail-stable outcomes have a
lattice structure. We then completely describe the relationships between all
stability concepts. When contracts specify trades and prices, we also show that
competitive equilibrium exists in networked markets even in the absence of
fully transferrable utility. The competitive equilibrium outcome is
trail-stable.
</summary>
    <author>
      <name>Tamás Fleiner</name>
    </author>
    <author>
      <name>Zsuzsanna Jankó</name>
    </author>
    <author>
      <name>Akihisa Tamura</name>
    </author>
    <author>
      <name>Alexander Teytelboym</name>
    </author>
    <link href="http://arxiv.org/abs/1510.01210v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.01210v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.4; G.2.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.04841v1</id>
    <updated>2015-10-16T11:24:16Z</updated>
    <published>2015-10-16T11:24:16Z</published>
    <title>How to (Not) Estimate Gini Coefficients for Fat Tailed Variables</title>
    <summary>  Direct measurements of Gini coefficients by conventional arithmetic
calculations are a poor estimator, even if paradoxically, they include the
entire population, as because of super-additivity they cannot lend themselves
to comparisons between units of different size, and intertemporal analyses are
vitiated by the population changes. The Gini of aggregated units A and B will
be higher than those of A and B computed separately. This effect becomes more
acute with fatness of tails. When the sample size is smaller than entire
population, the error is extremely high. The conventional literature on Gini
coefficients cannot be trusted and comparing countries of different sizes makes
no sense; nor does it make sense to make claims of "changes in inequality"
based on conventional measures. We compare the standard methodologies to the
indirect methods via maximum likelihood estimation of tail exponent. We compare
to the tail method which is unbiased, with considerably lower error rate. We
also consider measurement errors of the tail exponent and suggest a simple but
efficient methodology to calculate Gini coefficients.
</summary>
    <author>
      <name>Nassim Nicholas Taleb</name>
    </author>
    <link href="http://arxiv.org/abs/1510.04841v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.04841v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.06946v1</id>
    <updated>2015-10-23T14:38:15Z</updated>
    <published>2015-10-23T14:38:15Z</published>
    <title>Quantile Cross-Spectral Measures of Dependence between Economic
  Variables</title>
    <summary>  In this paper we introduce quantile cross-spectral analysis of multiple time
series which is designed to detect general dependence structures emerging in
quantiles of the joint distribution in the frequency domain. We argue that this
type of dependence is natural for economic time series but remains invisible
when the traditional analysis is employed. To illustrate how such dependence
structures can arise between variables in different parts of the joint
distribution and across frequencies, we consider quantile vector autoregression
processes. We define new estimators which capture the general dependence
structure, provide a detailed analysis of their asymptotic properties and
discuss how to conduct inference for a general class of possibly nonlinear
processes. In an empirical illustration we examine one of the most prominent
time series in economics and shed new light on the dependence of bivariate
stock market returns.
</summary>
    <author>
      <name>Jozef Baruník</name>
    </author>
    <author>
      <name>Tobias Kley</name>
    </author>
    <link href="http://arxiv.org/abs/1510.06946v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.06946v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.07111v3</id>
    <updated>2017-01-09T13:20:42Z</updated>
    <published>2015-10-24T06:02:35Z</published>
    <title>Dynamic programming approach to principal-agent problems</title>
    <summary>  We consider a general formulation of the Principal-Agent problem with a
lump-sum payment on a finite horizon, providing a systematic method for solving
such problems. Our approach is the following: we first find the contract that
is optimal among those for which the agent's value process allows a dynamic
programming representation, for which the agent's optimal effort is
straightforward to find. We then show that the optimization over the restricted
family of contracts represents no loss of generality. As a consequence, we have
reduced this non-zero sum stochastic differential game to a stochastic control
problem which may be addressed by the standard tools of control theory. Our
proofs rely on the backward stochastic differential equations approach to
non-Markovian stochastic control, and more specifically, on the recent
extensions to the second order case.
</summary>
    <author>
      <name>Jakša Cvitanić</name>
    </author>
    <author>
      <name>Dylan Possamaï</name>
    </author>
    <author>
      <name>Nizar Touzi</name>
    </author>
    <link href="http://arxiv.org/abs/1510.07111v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.07111v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1512.01742v1</id>
    <updated>2015-12-06T05:39:22Z</updated>
    <published>2015-12-06T05:39:22Z</published>
    <title>Oil price shocks, road transport pollution emissions and residents'
  health losses in China</title>
    <summary>  China's rapid economic growth resulted in serious air pollution, which caused
substantial losses to economic development and residents' health. In
particular, the road transport sector has been blamed to be one of the major
emitters. During the past decades, fluctuation in the international oil prices
has imposed significant impacts on the China's road transport sector.
Therefore, we propose an assumption that China's provincial economies are
independent "economic entities". Based on this assumption, we investigate the
China's road transport fuel (i.e., gasoline and diesel) demand system by using
the panel data of all 31 Chinese provinces except Hong Kong, Macau and Taiwan.
To connect the fuel demand system and the air pollution emissions, we propose
the concept of pollution emissions elasticities to estimate the air pollution
emissions from the road transport sector, and residents' health losses by a
simplified approach consisting of air pollution concentrations and health loss
assessment models under different scenarios based on real-world oil price
fluctuations. Our framework, to the best of our knowledge, is the first attempt
to address the transmission mechanism between the fuel demand system in road
transport sector and residents' health losses in the transitional China.
</summary>
    <author>
      <name>Sheng Yang</name>
    </author>
    <author>
      <name>Ling-Yun He</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.trd.2015.10.019</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.trd.2015.10.019" rel="related"/>
    <link href="http://arxiv.org/abs/1512.01742v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1512.01742v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1512.05074v2</id>
    <updated>2016-02-27T00:24:13Z</updated>
    <published>2015-12-16T07:37:27Z</published>
    <title>Unified Growth Theory Contradicted by the Economic Growth in Asia</title>
    <summary>  Historical economic growth in Asia (excluding Japan) is analysed. It is shown
that Unified Growth Theory is contradicted by the data, which were used (but
not analysed) during the formulation of this theory. Unified Growth Theory does
not explain the mechanism of economic growth. It explains the mechanism of
Malthusian stagnation, which did not exist and it explains the mechanism of the
transition from stagnation to growth that did not happen. The data show that
the economic growth in Asia was never stagnant but hyperbolic. The alleged
dramatic takeoff around 1900 or around any other time did not happen. However,
the theory contains also a dangerous and strongly-misleading concept that after
a long epoch of stagnation we have now entered the epoch of sustained economic
growth, the concept creating the sense of security. The opposite is true. After
the epoch of sustained and secure economic growth we have now entered the epoch
of a fast-increasing and insecure economic growth.
</summary>
    <author>
      <name>Ron W Nielsen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 2 figures, 3848 words</arxiv:comment>
    <link href="http://arxiv.org/abs/1512.05074v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1512.05074v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1512.06309v2</id>
    <updated>2016-02-27T00:37:27Z</updated>
    <published>2015-12-20T02:43:34Z</published>
    <title>Unified Growth Theory Contradicted by the Economic Growth in the Former
  USSR</title>
    <summary>  Historical economic growth in countries of the former USSR is analysed. It is
shown that Unified Growth Theory is contradicted by the data, which were used,
but not analysed, during the formulation of this theory. Unified Growth Theory
does not explain the mechanism of economic growth. It explains the mechanism of
Malthusian stagnation, which did not exist and it explains the mechanism of the
transition from stagnation to growth that did not happen. Unified Growth Theory
is full of stories but it is hard to decide which of them are reliable because
they are based on unprofessional examination of data. The data show that the
economic growth in the former USSR was never stagnant but hyperbolic.
Industrial Revolution did not boost the economic growth in the former USSR.
Unified Growth Theory needs to be revised or replaced by a reliable theory to
reconcile it with data and to avoid creating the unwarranted sense of security
about the current economic growth.
</summary>
    <author>
      <name>Ron W Nielsen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 3 figures, 3379 words</arxiv:comment>
    <link href="http://arxiv.org/abs/1512.06309v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1512.06309v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.02463v1</id>
    <updated>2016-01-11T14:40:20Z</updated>
    <published>2016-01-11T14:40:20Z</published>
    <title>Quantifying invariant features of within-group inequality in consumption
  across groups</title>
    <summary>  We study unit-level expenditure on consumption across multiple countries and
multiple years, in order to extract invariant features of consumption
distribution. We show that the bulk of it is lognormally distributed, followed
by a power law tail at the limit. The distributions coincide with each other
under normalization by mean expenditure and log scaling even though the data is
sampled across multiple dimension including, e.g., time, social structure and
locations. This phenomenon indicates that the dispersions in consumption
expenditure across various social and economic groups are significantly similar
subject to suitable scaling and normalization. Further, the results provide a
measurement of the core distributional features. Other descriptive factors
including those of sociological, demographic and political nature, add further
layers of variation on the this core distribution. We present a stochastic
multiplicative model to quantitatively characterize the invariance and the
distributional features.
</summary>
    <author>
      <name>Anindya S. Chakrabarti</name>
    </author>
    <author>
      <name>Arnab Chatterjee</name>
    </author>
    <author>
      <name>Tushar K. Nandi</name>
    </author>
    <author>
      <name>Asim Ghosh</name>
    </author>
    <author>
      <name>Anirban Chakraborti</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s11403-017-0189-0</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s11403-017-0189-0" rel="related"/>
    <link href="http://arxiv.org/abs/1601.02463v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.02463v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.05660v2</id>
    <updated>2017-08-02T12:17:05Z</updated>
    <published>2016-01-21T14:43:11Z</published>
    <title>The role of consumer networks in firms' multi-characteristics
  competition and market-share inequality</title>
    <summary>  We develop a location analysis spatial model of firms' competition in
multi-characteristics space, where consumers' opinions about the firms'
products are distributed on multilayered networks. Firms do not compete on
price but only on location upon the products' multi-characteristics space, and
they aim to attract the maximum number of consumers. Boundedly rational
consumers have distinct ideal points/tastes over the possible available firm
locations but, crucially, they are affected by the opinions of their neighbors.
Proposing a dynamic agent-based analysis on firms' location choice we
characterize multi-dimensional product differentiation competition as adaptive
learning by firms' managers and we argue that such a complex systems approach
advances the analysis in alternative ways, beyond game-theoretic calculations.
</summary>
    <author>
      <name>Antonios Garas</name>
    </author>
    <author>
      <name>Athanasios Lapatinas</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">33 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1601.05660v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.05660v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1602.05356v1</id>
    <updated>2016-02-17T10:08:39Z</updated>
    <published>2016-02-17T10:08:39Z</published>
    <title>Studies on Regional Wealth Inequalities: the case of Italy</title>
    <summary>  The paper contains a short review of techniques examining regional wealth
inequalities based on recently published research work but is also presenting
unpublished features.
  The data pertains to Italy (IT), over the period 2007-2011: the number of
cities in regions, the number of inhabitants in cities and in regions, as well
as the aggregated tax income of the cities and of regions. Frequency-size plots
and cumulative distribution function plots, scatter plots and rank-size plots
are displayed. The rank-size rule of a few cases is discussed. Yearly data of
the aggregated tax income is transformed into a few indicators: the Gini,
Theil, and Herfindahl-Hirschman indices. Numerical results confirm that IT is
divided into very different regional realities. One region is selected for a
short discussion: Molise.
  A note on the "first digit Benford law" for testing data validity is
presented.
</summary>
    <author>
      <name>Marcel Ausloos</name>
    </author>
    <author>
      <name>Roy Cerqueti</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages; 2 tables; 7 figures; 25 references; prepared for Acta
  Physica Polonica (FENS 2015)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Acta Physica Polonica A 129 (2016) 959-964</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1602.05356v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1602.05356v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.CP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.CP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.05828v1</id>
    <updated>2016-03-18T10:51:38Z</updated>
    <published>2016-03-18T10:51:38Z</published>
    <title>Online Networks, Social Interaction and Segregation: An Evolutionary
  Approach</title>
    <summary>  We have developed an evolutionary game model, where agents can choose between
two forms of social participation: interaction via online social networks and
interaction by exclusive means of face-to-face encounters. We illustrate the
societal dynamics that the model predicts, in light of the empirical evidence
provided by previous literature. We then assess their welfare implications. We
show that dynamics, starting from a world in which online social interaction is
less gratifying than offline encounters, will lead to the extinction of the
sub-population of online networks users, thereby making Facebook and alike
disappear in the long run. Furthermore, we show that the higher the propensity
for discrimination between the two sub-populations of socially active
individuals, the greater the probability that individuals will ultimately
segregate themselves, making society fall into a social poverty trap.
</summary>
    <author>
      <name>Angelo Antoci</name>
    </author>
    <author>
      <name>Fabio Sabatini</name>
    </author>
    <author>
      <name>Francesco Sarracino</name>
    </author>
    <link href="http://arxiv.org/abs/1603.05828v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.05828v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.07682v3</id>
    <updated>2016-12-21T18:05:22Z</updated>
    <published>2016-03-24T17:49:24Z</published>
    <title>Descending Price Optimally Coordinates Search</title>
    <summary>  Investigating potential purchases is often a substantial investment under
uncertainty. Standard market designs, such as simultaneous or English auctions,
compound this with uncertainty about the price a bidder will have to pay in
order to win. As a result they tend to confuse the process of search both by
leading to wasteful information acquisition on goods that have already found a
good purchaser and by discouraging needed investigations of objects,
potentially eliminating all gains from trade. In contrast, we show that the
Dutch auction preserves all of its properties from a standard setting without
information costs because it guarantees, at the time of information
acquisition, a price at which the good can be purchased. Calibrations to
start-up acquisition and timber auctions suggest that in practice the social
losses through poor search coordination in standard formats are an order of
magnitude or two larger than the (negligible) inefficiencies arising from
ex-ante bidder asymmetries.
</summary>
    <author>
      <name>Robert Kleinberg</name>
    </author>
    <author>
      <name>Bo Waggoner</name>
    </author>
    <author>
      <name>E. Glen Weyl</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">JEL Classification: D44, D47, D82, D83. 117 pages, of which 74 are
  appendix</arxiv:comment>
    <link href="http://arxiv.org/abs/1603.07682v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.07682v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.08961v3</id>
    <updated>2016-07-11T22:16:35Z</updated>
    <published>2016-03-29T20:53:57Z</published>
    <title>Betting and Belief: Prediction Markets and Attribution of Climate Change</title>
    <summary>  Despite much scientific evidence, a large fraction of the American public
doubts that greenhouse gases are causing global warming. We present a
simulation model as a computational test-bed for climate prediction markets.
Traders adapt their beliefs about future temperatures based on the profits of
other traders in their social network. We simulate two alternative climate
futures, in which global temperatures are primarily driven either by carbon
dioxide or by solar irradiance. These represent, respectively, the scientific
consensus and a hypothesis advanced by prominent skeptics. We conduct
sensitivity analyses to determine how a variety of factors describing both the
market and the physical climate may affect traders' beliefs about the cause of
global climate change. Market participation causes most traders to converge
quickly toward believing the "true" climate model, suggesting that a climate
market could be useful for building public consensus.
</summary>
    <author>
      <name>John J. Nay</name>
    </author>
    <author>
      <name>Martin Van der Linden</name>
    </author>
    <author>
      <name>Jonathan M. Gilligan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">All code and data for the model is available at
  http://johnjnay.com/predMarket/. Forthcoming in Proceedings of the 2016
  Winter Simulation Conference. IEEE Press</arxiv:comment>
    <link href="http://arxiv.org/abs/1603.08961v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.08961v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.09060v3</id>
    <updated>2016-11-25T04:30:07Z</updated>
    <published>2016-03-30T07:36:20Z</published>
    <title>Combining Dimension Reduction, Distance Measures and Covariance</title>
    <summary>  We consider a measure of similarity, the Bhattacharyya distance, across
distributions of random variables. We develop a novel methodology based on the
marriage between the Bhattacharyya distance and the Johnson Lindenstrauss
Lemma, a technique for dimension reduction, providing us with a simple yet
powerful tool that allows comparisons between data-sets representing any two
distributions. We demonstrate a relationship between covariance and distance
measures based on a generic extension of Stein's Lemma. The degree to which
different markets or sub groups of securities have different measures of their
corresponding distributions tells us the extent to which they are different.
This can aid investors looking for diversification or looking for more of the
same thing. We consider an asset pricing application and then briefly discuss
how this methodology lends itself to numerous Marketstructure studies and even
applications outside the realm of finance / social sciences by illustrating a
biological application.
</summary>
    <author>
      <name>Ravi Kashyap</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Incomplete Early Draft - Soliciting suggestions, omissions and other
  feedback</arxiv:comment>
    <link href="http://arxiv.org/abs/1603.09060v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.09060v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.TR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.TR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.00976v1</id>
    <updated>2016-04-04T18:31:43Z</updated>
    <published>2016-04-04T18:31:43Z</published>
    <title>From Big Data To Important Information</title>
    <summary>  Advances in science are being sought in newly available opportunities to
collect massive quantities of data about complex systems. While key advances
are being made in detailed mapping of systems, how to relate this data to
solving many of the challenges facing humanity is unclear. The questions we
often wish to address require identifying the impact of interventions on the
system and that impact is not apparent in the detailed data that is available.
Here we review key concepts and motivate a general framework for building
larger scale views of complex systems and for characterizing the importance of
information in physical, biological and social systems. We provide examples of
its application to evolutionary biology with relevance to ecology,
biodiversity, pandemics, and human lifespan, and in the context of social
systems with relevance to ethnic violence, global food prices, and stock market
panic. Framing scientific inquiry as an effort to determine what is important
and unimportant is a means for advancing our understanding and addressing many
practical concerns, such as economic development or treating disease.
</summary>
    <author>
      <name>Yaneer Bar-Yam</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">24 pages, 7 figures (Complexity, in press), New England Complex
  Systems Institute Report 04-01-2016</arxiv:comment>
    <link href="http://arxiv.org/abs/1604.00976v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.00976v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.PE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.03776v2</id>
    <updated>2016-11-18T23:22:21Z</updated>
    <published>2016-04-13T14:00:30Z</published>
    <title>Detecting a Structural Change in Functional Time Series Using Local
  Wilcoxon Statistic</title>
    <summary>  Functional data analysis (FDA) is a part of modern multivariate statistics
that analyses data providing information about curves, surfaces or anything
else varying over a certain continuum. In economics and empirical finance we
often have to deal with time series of functional data, where we cannot easily
decide, whether they are to be considered as homogeneous or heterogeneous. At
present a discussion on adequate tests of homogenity for functional data is
carried. We propose a novel statistic for detetecting a structural change in
functional time series based on a local Wilcoxon statistic induced by a local
depth function proposed by Paindaveine and Van Bever (2013).
</summary>
    <author>
      <name>Daniel Kosiorowski</name>
    </author>
    <author>
      <name>Jerzy P. Rydlewski</name>
    </author>
    <author>
      <name>Małgorzata Snarska</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s00362-017-0891-y</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s00362-017-0891-y" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages, 19 figures, LaTeX svjour3 class</arxiv:comment>
    <link href="http://arxiv.org/abs/1604.03776v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.03776v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62G30, 62-07, 62G35, 62P20" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.00039v2</id>
    <updated>2017-05-11T09:22:04Z</updated>
    <published>2016-04-29T23:02:25Z</published>
    <title>Nonzero-sum stochastic differential games with impulse controls: a
  verification theorem with applications</title>
    <summary>  We consider a general nonzero-sum impulse game with two players. The main
mathematical contribution of the paper is a verification theorem which
provides, under some regularity conditions, a suitable system of
quasi-variational inequalities for the value functions and the optimal
strategies of the two players. As an application, we study an impulse game with
a one-dimensional state variable, following a real-valued scaled Brownian
motion, and two players with linear and symmetric running payoffs. Thanks to
the verification theorem, we find and fully characterize a Nash equilibrium by
providing explicit expressions for the value functions and the optimal
strategies of the players. Finally, we prove some asymptotic results with
respect to the intervention costs for the one-dimensional symmetric game.
</summary>
    <author>
      <name>René Aïd</name>
    </author>
    <author>
      <name>Matteo Basei</name>
    </author>
    <author>
      <name>Giorgia Callegaro</name>
    </author>
    <author>
      <name>Luciano Campi</name>
    </author>
    <author>
      <name>Tiziano Vargiolu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1605.00039v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.00039v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.01071v1</id>
    <updated>2016-05-03T20:06:34Z</updated>
    <published>2016-05-03T20:06:34Z</published>
    <title>Lie symmetries of (1+2) nonautonomous evolution equations in Financial
  Mathematics</title>
    <summary>  We analyse two classes of $(1+2)$ evolution equations which are of special
interest in Financial Mathematics, namely the Two-dimensional Black-Scholes
Equation and the equation for the Two-factor Commodities Problem. Our approach
is that of Lie Symmetry Analysis. We study these equations for the case in
which they are autonomous and for the case in which the parameters of the
equations are unspecified functions of time. For the autonomous Black-Scholes
Equation we find that the symmetry is maximal and so the equation is reducible
to the $(1+2)$ Classical Heat Equation. This is not the case for the
nonautonomous equation for which the number of symmetries is submaximal. In the
case of the two-factor equation the number of symmetries is submaximal in both
autonomous and nonautonomous cases. When the solution symmetries are used to
reduce each equation to a $(1+1)$ equation, the resulting equation is of
maximal symmetry and so equivalent to the $(1+1)$ Classical Heat Equation.
</summary>
    <author>
      <name>A. Paliathanasis</name>
    </author>
    <author>
      <name>R. M. Morris</name>
    </author>
    <author>
      <name>P. G. L. Leach</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 1 figure, to be published in Mathematics in the Special
  issue "Mathematical Finance"</arxiv:comment>
    <link href="http://arxiv.org/abs/1605.01071v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.01071v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.03653v2</id>
    <updated>2017-03-29T03:56:42Z</updated>
    <published>2016-05-12T02:05:24Z</published>
    <title>High-Roller Impact: A Large Generalized Game Model of Parimutuel
  Wagering</title>
    <summary>  How do large-scale participants in parimutuel wagering events affect the
house and ordinary bettors? A standard narrative suggests that they may
temporarily benefit the former at the expense of the latter. To approach this
problem, we begin by developing a model based on the theory of large
generalized games. Constrained only by their budgets, a continuum of diffuse
(ordinary) players and a single atomic (large-scale) player simultaneously
wager to maximize their expected profits according to their individual beliefs.
Our main theoretical result gives necessary and sufficient conditions for the
existence and uniqueness of a pure-strategy Nash equilibrium. Using this
framework, we analyze our question in concrete scenarios. First, we study a
situation in which both predicted effects are observed. Neither is always
observed in our remaining examples, suggesting the need for a more nuanced view
of large-scale participants.
</summary>
    <author>
      <name>Erhan Bayraktar</name>
    </author>
    <author>
      <name>Alexander Munk</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Final version. To appear in Market Microstructure and Liquidity. Key
  words: Parimutuel wagering, Large generalized games, Nash equilibrium</arxiv:comment>
    <link href="http://arxiv.org/abs/1605.03653v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.03653v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="Primary 91B26, 91B69, 91B74" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.04938v1</id>
    <updated>2016-02-23T11:01:45Z</updated>
    <published>2016-02-23T11:01:45Z</published>
    <title>The topology of card transaction money flows</title>
    <summary>  Money flow models are essential tools to understand different economical
phenomena, like saving propensities and wealth distributions. In spite of their
importance, most of them are based on synthetic transaction networks with
simple topologies, e.g. random or scale-free ones, as the characterisation of
real networks is made difficult by the confidentiality and sensitivity of money
transaction data. Here we present an analysis of the topology created by real
credit card transactions from one of the biggest world banks, and show how
different distributions, e.g. number of transactions per card or amount, have
nontrivial characteristics. We further describe a stochastic model to create
transactions data sets, feeding from the obtained distributions, which will
allow researchers to create more realistic money flow models.
</summary>
    <author>
      <name>Massimiliano Zanin</name>
    </author>
    <author>
      <name>David Papo</name>
    </author>
    <author>
      <name>Miguel Romance</name>
    </author>
    <author>
      <name>Regino Criado</name>
    </author>
    <author>
      <name>Santiago Moral</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.physa.2016.06.091</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.physa.2016.06.091" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to Physica A</arxiv:comment>
    <link href="http://arxiv.org/abs/1605.04938v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.04938v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62P20, 91B55, 91B84" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.06829v1</id>
    <updated>2016-06-22T07:00:30Z</updated>
    <published>2016-06-22T07:00:30Z</published>
    <title>Brexit or Bremain ? Evidence from bubble analysis</title>
    <summary>  We applied the Johansen-Ledoit-Sornette (JLS) model to detect possible
bubbles and crashes related to the Brexit/Bremain referendum scheduled for 23rd
June 2016. Our implementation includes an enhanced model calibration using
Genetic Algorithms. We selected a few historical financial series sensitive to
the Brexit/Bremain scenario, representative of multiple asset classes. We found
that equity and currency asset classes show no bubble signals, while rates,
credit and real estate show super-exponential behaviour and instabilities
typical of bubble regime. Our study suggests that, under the JLS model, equity
and currency markets do not expect crashes or sharp rises following the
referendum results. Instead, rates and credit markets consider the referendum a
risky event, expecting either a Bremain scenario or a Brexit scenario
edulcorated by central banks intervention. In the case of real estate, a crash
is expected, but its relationship with the referendum results is unclear.
</summary>
    <author>
      <name>Marco Bianchetti</name>
    </author>
    <author>
      <name>Davide Galli</name>
    </author>
    <author>
      <name>Camilla Ricci</name>
    </author>
    <author>
      <name>Angelo Salvatori</name>
    </author>
    <author>
      <name>Marco Scaringi</name>
    </author>
    <link href="http://arxiv.org/abs/1606.06829v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.06829v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.CP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.03996v1</id>
    <updated>2016-09-13T19:45:59Z</updated>
    <published>2016-09-13T19:45:59Z</published>
    <title>SEAL's operating manual: a Spatially-bounded Economic Agent-based Lab</title>
    <summary>  This text reports in detail how SEAL, a modeling framework for the economy
based on individual agents and firms, works. Thus, it aims to be an usage
manual for those wishing to use SEAL or SEAL's results. As a reference work,
theoretical and research studies are only cited. SEAL is thought as a Lab that
enables the simulation of the economy with spatially bounded
microeconomic-based computational agents. Part of the novelty of SEAL comes
from the possibility of simulating the economy in space and the instantiation
of different public offices, i.e. government institutions, with embedded
markets and actual data. SEAL is designed for Public Policy analysis,
specifically those related to Public Finance, Taxes and Real Estate.
</summary>
    <author>
      <name>Bernardo Alves Furtado</name>
    </author>
    <author>
      <name>Isaque Daniel Rocha Eberhardt</name>
    </author>
    <author>
      <name>Alexandre Messa</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, 1 figure, Research Report</arxiv:comment>
    <link href="http://arxiv.org/abs/1609.03996v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.03996v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1610.07292v1</id>
    <updated>2016-10-24T06:22:26Z</updated>
    <published>2016-10-24T06:22:26Z</published>
    <title>Population growth, interest rate, and housing tax in the transitional
  China</title>
    <summary>  This paper combines and develops the models in Lastrapes (2002) and Mankiw &amp;
Weil (1989), which enables us to analyze the effects of interest rate and
population growth shocks on housing price in one integrated framework. Based on
this model, we carry out policy simulations to examine whether the housing
(stock or flow) tax reduces the housing price fluctuations caused by interest
rate or population growth shocks. Simulation results imply that the choice of
housing tax tools depends on the kind of shock that housing market faces. In
the situation where the housing price volatility is caused by the population
growth shock, the flow tax can reduce the volatility of housing price while the
stock tax makes no difference to it. If the shock is resulting from the
interest rate, the policy maker should not impose any kind of the housing
taxes. Furthermore, the effect of one kind of the housing tax can be
strengthened by that of the other type of housing tax.
</summary>
    <author>
      <name>Ling-Yun He</name>
    </author>
    <author>
      <name>Xing-Chun Wen</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.physa.2016.11.057</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.physa.2016.11.057" rel="related"/>
    <link href="http://arxiv.org/abs/1610.07292v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1610.07292v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1611.00156v1</id>
    <updated>2016-11-01T08:06:15Z</updated>
    <published>2016-11-01T08:06:15Z</published>
    <title>Globalization Process in Emerging Capital Markets -- Lessons and
  Implications to China</title>
    <summary>  Since 2002 when China first introduced QFII (Qualified Foreign Institutional
Investors) system, QFII has been developing in China for 14 years, during when
RQFII, Shanghai-Hongkong Stock Connect Program, Shanghai-London Stock Connect
Program furthur broadened the avenue for foreign capital to invest in Chinese
Security Market. As FTA (Free Trade Area) Financial Reform Program emerged, RMB
(CNY) Capital Project is likely to make the currency exchangeable. With the
success in QFII, RQFII and Shanghai-Hongkong Stock Connect Program, China's
long term advantage in interest rate, and the relatively low stock index value
after the recent stock market crashes in mid 2015 and early 2016, foreign
capitals' demand for Chinese market to loosen its restrictions continually
increases. This article picks the three most representative emerging capital
markets in the world, namely Taiwan, Korea and India, by comparing and
analyzing their paths of globalization, attempts to shed light on China's next
steps regarding globalization.
</summary>
    <author>
      <name>Zichong Li</name>
    </author>
    <author>
      <name>Pengyu Huang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1611.00156v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1611.00156v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1611.01381v1</id>
    <updated>2016-11-04T14:04:50Z</updated>
    <published>2016-11-04T14:04:50Z</published>
    <title>Revealing the Anatomy of Vote Trading</title>
    <summary>  Cooperation in the form of vote trading, also known as logrolling, is central
for law-making processes, shaping the development of democratic societies.
Empirical evidence of logrolling is scarce and limited to highly specific
situations because existing methods are not easily applicable to broader
contexts. We have developed a general and scalable methodology for revealing a
network of vote traders, allowing us to measure logrolling on a large scale.
Analysis on more than 9 million votes spanning 40 years in the U.S. Congress
reveals a higher logrolling prevalence in the Senate and an overall decreasing
trend over recent congresses, coincidental with high levels of political
polarization. Our method is applicable in multiple contexts, shedding light on
many aspects of logrolling and opening new doors in the study of hidden
cooperation.
</summary>
    <author>
      <name>Omar A. Guerrero</name>
    </author>
    <author>
      <name>Ulrich Matter</name>
    </author>
    <link href="http://arxiv.org/abs/1611.01381v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1611.01381v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.01677v2</id>
    <updated>2017-06-07T18:29:08Z</updated>
    <published>2017-01-06T16:07:10Z</published>
    <title>The Shapley Value of Digraph Games</title>
    <summary>  In this paper the Shapley value of digraph (directed graph) games are
considered. Digraph games are transferable utility (TU) games with limited
cooperation among players, where players are represented by nodes. A
restrictive relation between two adjacent players is established by a directed
line segment. Directed path, connecting the initial player with the terminal
player, form the coalition among players. A dominance relation is established
between players and this relation determines whether or not a player wants to
cooperate. To cooperate, we assume that a player joins a coalition where he/she
is not dominated by any other players.The Shapley value is defined as the
average of marginal contribution vectors corresponding to all permutations that
do not violate the subordination of players. The Shapley value for cyclic
digraph games is calculated and analyzed. For a given family of characteristic
functions, a quick way to calculate Shapley values is formulated.
</summary>
    <author>
      <name>Krishna Khatri</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1701.01677v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.01677v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91A43" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.07175v1</id>
    <updated>2017-01-25T06:11:35Z</updated>
    <published>2017-01-25T06:11:35Z</published>
    <title>Day of the Week Effect in biotechnology stocks: An Application of the
  GARCH processes</title>
    <summary>  This study examines the presence of the day-of-the-week effect on daily
returns of biotechnology stocks over a 16-year period from January 2002 to
December 2015. Using daily returns from the NASDAQ Biotechnology Index (NBI),
we find that the stock returns were the lowest on Mondays, and compared to the
Mondays the stock returns were significantly higher on Wednesdays, Thursdays,
and Fridays. Moreover, the results from using the asymmetric GARCH processes
reveal that momentum and small-firm effect were positively associated with the
market risk-adjusted returns of the biotechnology stocks during this period.
The findings of our study suggest that active portfolio managers need to
consider the day of the week, momentum, and small-firm effect when making
trading decisions for biotechnology stocks.
</summary>
    <author>
      <name>Swarn Chatterjee</name>
    </author>
    <link href="http://arxiv.org/abs/1701.07175v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.07175v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.08711v3</id>
    <updated>2017-02-14T16:36:38Z</updated>
    <published>2017-01-30T17:14:25Z</published>
    <title>Predicting Auction Price of Vehicle License Plate with Deep Recurrent
  Neural Network</title>
    <summary>  In Chinese societies, superstition is of paramount importance, and vehicle
license plates with desirable numbers can fetch very high prices in auctions.
Unlike other valuable items, license plates are not allocated an estimated
price before auction. I propose that the task of predicting plate prices can be
viewed as a natural language processing (NLP) task, as the value depends on the
meaning of each individual character on the plate and its semantics. I
construct a deep recurrent neural network (RNN) to predict the prices of
vehicle license plates in Hong Kong, based on the characters on a plate. I
demonstrate the importance of having a deep network and of retraining.
Evaluated on 13 years of historical auction prices, the deep RNN outperforms
previous models by a significant margin.
</summary>
    <author>
      <name>Vinci Chow</name>
    </author>
    <link href="http://arxiv.org/abs/1701.08711v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.08711v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.08789v1</id>
    <updated>2017-01-30T19:22:01Z</updated>
    <published>2017-01-30T19:22:01Z</published>
    <title>Understanding food inflation in India: A Machine Learning approach</title>
    <summary>  Over the past decade, the stellar growth of Indian economy has been
challenged by persistently high levels of inflation, particularly in food
prices. The primary reason behind this stubborn food inflation is mismatch in
supply-demand, as domestic agricultural production has failed to keep up with
rising demand owing to a number of proximate factors. The relative significance
of these factors in determining the change in food prices have been analysed
using gradient boosted regression trees (BRT), a machine learning technique.
The results from BRT indicates all predictor variables to be fairly significant
in explaining the change in food prices, with MSP and farm wages being
relatively more important than others. International food prices were found to
have limited relevance in explaining the variation in domestic food prices. The
challenge of ensuring food and nutritional security for growing Indian
population with rising incomes needs to be addressed through resolute policy
reforms.
</summary>
    <author>
      <name>Akash Malhotra</name>
    </author>
    <author>
      <name>Mayank Maloo</name>
    </author>
    <link href="http://arxiv.org/abs/1701.08789v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.08789v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1702.02826v6</id>
    <updated>2017-08-21T20:33:27Z</updated>
    <published>2017-02-09T13:23:17Z</published>
    <title>Super Generalized Central Limit Theorem: Limit distributions for sums of
  non-identical random variables with power-laws</title>
    <summary>  In nature or societies, the power-law is present ubiquitously, and then it is
important to investigate the mathematical characteristics of power-laws in the
recent era of big data. In this paper we prove the superposition of
non-identical stochastic processes with power-laws converges in density to a
unique stable distribution. This property can be used to explain the
universality of stable laws such that the sums of the logarithmic return of
non-identical stock price fluctuations follow stable distributions.
</summary>
    <author>
      <name>Masaru Shintani</name>
    </author>
    <author>
      <name>Ken Umeno</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4pages,1figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1702.02826v6" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1702.02826v6" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.MP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1702.03226v2</id>
    <updated>2017-03-24T11:29:52Z</updated>
    <published>2017-02-10T15:53:45Z</published>
    <title>An applied spatial agent-based model of administrative boundaries using
  SEAL</title>
    <summary>  This paper extends and adapts an existing abstract model into an empirical
metropolitan region in Brazil. The model - named SEAL: a Spatial Economic
Agent-based Lab - comprehends a framework to enable public policy ex-ante
analysis. The aim of the model is to use official data and municipalities
spatial boundaries to allow for policy experimentation. The current version
considers three markets: housing, labor and goods. Families' members age,
consume, join the labor market and trade houses. A single consumption tax is
collected by municipalities that invest back into quality of life improvements.
We test whether a single metropolitan government - which is an aggregation of
municipalities - would be in the best interest of its citizens. Preliminary
results for 20 simulation runs indicate that it may be the case. Future
developments include improving performance to enable running of higher
percentage of the population and a number of runs that make the model more
robust.
</summary>
    <author>
      <name>Bernardo Alves Furtado</name>
    </author>
    <author>
      <name>Isaque Daniel Eberhardt Rocha</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages. 4 figures. Accepted ABMUS 2017 as part of AAMAS 2017, S\~ao
  Paulo, Brazil</arxiv:comment>
    <link href="http://arxiv.org/abs/1702.03226v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1702.03226v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1704.01028v1</id>
    <updated>2017-04-04T14:11:57Z</updated>
    <published>2017-04-04T14:11:57Z</published>
    <title>Interconnectedness in the Global Financial Market</title>
    <summary>  The global financial system is highly complex, with cross-border
interconnections and interdependencies. In this highly interconnected
environment, local financial shocks and events can be easily amplified and
turned into global events. This paper analyzes the dependencies among nearly
4,000 stocks from 15 countries. The returns are normalized by the estimated
volatility using a GARCH model and a robust regression process estimates
pairwise statistical relationships between stocks from different markets. The
estimation results are used as a measure of statistical interconnectedness, and
to derive network representations, both by country and by sector. The results
show that countries like the United States and Germany are in the core of the
global stock market. The energy, materials, and financial sectors play an
important role in connecting markets, and this role has increased over time for
the energy and materials sectors. Our results confirm the role of global
sectoral factors in stock market dependence. Moreover, our results show that
the dependencies are rather volatile and that heterogeneity among stocks is a
non-negligible aspect of this volatility.
</summary>
    <author>
      <name>Matthias Raddant</name>
    </author>
    <author>
      <name>Dror Y. Kenett</name>
    </author>
    <link href="http://arxiv.org/abs/1704.01028v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1704.01028v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1704.04442v1</id>
    <updated>2017-04-14T14:49:00Z</updated>
    <published>2017-04-14T14:49:00Z</published>
    <title>Crude oil market and geopolitical events: an analysis based on
  information-theory-based quantifiers</title>
    <summary>  This paper analyzes the informational efficiency of oil market during the
last three decades, and examines changes in informational efficiency with major
geopolitical events, such as terrorist attacks, financial crisis and other
important events. The series under study is the daily prices of West Texas
Intermediate (WTI) in USD/BBL, commonly used as a benchmark in oil pricing. The
analysis is performed using information-theory-derived quantifiers, namely
permutation entropy and permutation statistical complexity. These metrics allow
capturing the hidden structure in the market dynamics, and allow discriminating
different degrees of informational efficiency. We find that some geopolitical
events impact on the underlying dynamical structure of the market.
</summary>
    <author>
      <name>Aurelio F. Bariviera</name>
    </author>
    <author>
      <name>Luciano Zunino</name>
    </author>
    <author>
      <name>Osvaldo A. Rosso</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: text overlap with arXiv:1603.02874</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Fuzzy Economic Review, 2016, 21(1),41-51</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1704.04442v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1704.04442v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1704.05276v1</id>
    <updated>2017-04-18T11:27:50Z</updated>
    <published>2017-04-18T11:27:50Z</published>
    <title>Best reply structure and equilibrium convergence in generic games</title>
    <summary>  Game theory often assumes rational players that play equilibrium strategies.
But when the players have to learn their strategies by playing the game
repeatedly, how often do the strategies converge? We analyze generic two player
games using a standard learning algorithm, and also study replicator dynamics,
which is closely related. We show that the frequency with which strategies
converge to a fixed point can be understood by analyzing the best reply
structure of the payoff matrix. A Boolean transformation of the payoff matrix,
replacing all best replies by one and all other entries by zero, provides a
reasonable approximation of the asymptotic strategic dynamics. We analyze the
generic structure of randomly generated payoff matrices using combinatorial
methods to compute the frequency of cycles of different lengths under the
microcanonical ensemble. For a game with $N$ possible moves the frequency of
cycles and non-convergence increases with $N$, becoming dominant when $N &gt; 10$.
This is especially the case when the interactions are competitive.
</summary>
    <author>
      <name>Marco Pangallo</name>
    </author>
    <author>
      <name>Torsten Heinrich</name>
    </author>
    <author>
      <name>J Doyne Farmer</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Main paper + Supplemental Information</arxiv:comment>
    <link href="http://arxiv.org/abs/1704.05276v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1704.05276v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.01254v1</id>
    <updated>2017-06-05T09:58:04Z</updated>
    <published>2017-06-05T09:58:04Z</published>
    <title>Moral hazard in welfare economics: on the advantage of Planner's advices
  to manage employees' actions</title>
    <summary>  In this paper, we study moral hazard problems in contract theory by adding an
exogenous Planner to manage the actions of Agents hired by a Principal. We
provide conditions ensuring that Pareto optima exist for the Agents using the
scalarization method associated with the multi-objective optimization problem
and we solve the problem of the Principal by finding optimal remunerations
given to the Agents. We illustrate our study with a linear-quadratic model by
comparing the results obtained when we add a Planner in the
Principal/multi-Agents problem with the results obtained in the classical
second-best case. More particularly in this example, we give necessary and
sufficient conditions ensuring that Pareto optima are Nash equilibria and we
prove that the Principal takes the benefit of the action of the Planner in some
cases
</summary>
    <author>
      <name>Thibaut Mastrolia</name>
    </author>
    <link href="http://arxiv.org/abs/1706.01254v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.01254v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.01934v1</id>
    <updated>2017-06-06T19:07:03Z</updated>
    <published>2017-06-06T19:07:03Z</published>
    <title>An adverse selection approach to power pricing</title>
    <summary>  We study the optimal design of electricity contracts among a population of
consumers with different needs. This question is tackled within the framework
of Principal-Agent problem in presence of adverse selection. The particular
features of electricity induce an unusual structure on the production cost,
with no decreasing return to scale. We are nevertheless able to provide an
explicit solution for the problem at hand. The optimal contracts are either
linear or polynomial with respect to the consumption. Whenever the outside
options offered by competitors are not uniform among the different type of
consumers, we exhibit situations where the electricity provider should contract
with consumers with either low or high appetite for electricity.
</summary>
    <author>
      <name>Clémence Alasseur</name>
    </author>
    <author>
      <name>Ivar Ekeland</name>
    </author>
    <author>
      <name>Romuald Elie</name>
    </author>
    <author>
      <name>Nicolás Hernández Santibáñez</name>
    </author>
    <author>
      <name>Dylan Possamaï</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">46 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1706.01934v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.01934v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.05735v1</id>
    <updated>2017-06-18T22:07:43Z</updated>
    <published>2017-06-18T22:07:43Z</published>
    <title>Quantifying the Benefits of Infrastructure Sharing</title>
    <summary>  We analyze the benefits of network sharing between telecommunications
operators. Sharing is seen as one way to speed the roll out of expensive
technologies such as 5G since it allows the service providers to divide the
cost of providing ubiquitous coverage. Our theoretical analysis focuses on
scenarios with two service providers and compares the system dynamics when they
are competing with the dynamics when they are cooperating. We show that sharing
can be beneficial to a service provider even when it has the power to drive the
other service provider out of the market, a byproduct of a non-convex cost
function. A key element of this study is an analysis of the competitive
equilibria for both cooperative and non-cooperative 2-person games in the
presence of (non-convex) cost functions that involve a fixed cost component.
</summary>
    <author>
      <name>Matthew Andrews</name>
    </author>
    <author>
      <name>Milan Bradonjic</name>
    </author>
    <author>
      <name>Iraj Saniee</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Shorter version accepted to NetEcon 2017</arxiv:comment>
    <link href="http://arxiv.org/abs/1706.05735v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.05735v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="C.2.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.09038v1</id>
    <updated>2017-06-27T20:15:09Z</updated>
    <published>2017-06-27T20:15:09Z</published>
    <title>Risk Model Based on General Compound Hawkes Process</title>
    <summary>  In this paper, we introduce a new model for the risk process based on general
compound Hawkes process (GCHP) for the arrival of claims. We call it risk model
based on general compound Hawkes process (RMGCHP). The Law of Large Numbers
(LLN) and the Functional Central Limit Theorem (FCLT) are proved. We also study
the main properties of this new risk model, net profit condition, premium
principle and ruin time (including ultimate ruin time) applying the LLN and
FCLT for the RMGCHP. We show, as applications of our results, similar results
for risk model based on compound Hawkes process (RMCHP) and apply them to the
classical risk model based on compound Poisson process (RMCPP).
</summary>
    <author>
      <name>Anatoliy Swishchuk</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages; this paper will be presented at the 21st International
  Congress Insurance: Mathematics and Economics-IME 2017, TUW, Vienna</arxiv:comment>
    <link href="http://arxiv.org/abs/1706.09038v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.09038v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="60G55, 91B30" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.09763v1</id>
    <updated>2017-06-29T14:02:04Z</updated>
    <published>2017-06-29T14:02:04Z</published>
    <title>Dynamical selection of Nash equilibria using Experience Weighted
  Attraction Learning: emergence of heterogeneous mixed equilibria</title>
    <summary>  We study the distribution of strategies in a large game that models how
agents choose among different double auction markets. We classify the possible
mean field Nash equilibria, which include potentially segregated states where
an agent population can split into subpopulations adopting different
strategies. As the game is aggregative, the actual equilibrium strategy
distributions remain undetermined, however. We therefore compare with the
results of Experience-Weighted Attraction (EWA) learning, which at long times
leads to Nash equilibria in the appropriate limits of large intensity of
choice, low noise (long agent memory) and perfect imputation of missing scores
(fictitious play). The learning dynamics breaks the indeterminacy of the Nash
equilibria. Non-trivially, depending on how the relevant limits are taken, more
than one type of equilibrium can be selected. These include the standard
homogeneous mixed and heterogeneous pure states, but also \emph{heterogeneous
mixed} states where different agents play different strategies that are not all
pure. The analysis of the EWA learning involves Fokker-Planck modeling combined
with large deviation methods. The theoretical results are confirmed by
multi-agent simulations.
</summary>
    <author>
      <name>Robin Nicole</name>
    </author>
    <author>
      <name>Peter Sollich</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">35 pages, 16 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1706.09763v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.09763v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.10141v1</id>
    <updated>2017-06-21T16:25:44Z</updated>
    <published>2017-06-21T16:25:44Z</published>
    <title>Oscillations in the Tsallis income distribution</title>
    <summary>  Oscillations in the cumulative individual income distribution have been found
in the data of various countries studied by different authors at different time
periods, but the dynamical origins of this behavior are currently unknown.
These data sets can be fitted by different functions at different income
ranges, but recently the Tsallis distribution has been found capable of fitting
the whole distribution by means of only two parameters, procedure which showed
even more clearly such oscillatory features in the entire income range. This
behavior can be described by assuming log-periodic functions, however a
different approach to naturally disclose such oscillatory characteristics is to
allow the Tsallis $q$-parameter to become complex. In this paper we have used
these ideas in order to describe the behavior of the complementary cumulative
distribution function of the personal income of Brazil recently studied
empirically by Soares et al. (2016). Typical elements of periodic motion, such
as amplitude and angular frequency coupled to this income analysis, were
obtained.
</summary>
    <author>
      <name>Everton M. C. Abreu</name>
    </author>
    <author>
      <name>Newton J. Moura Jr.</name>
    </author>
    <author>
      <name>Abner D. Soares</name>
    </author>
    <author>
      <name>Marcelo B. Ribeiro</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages. Pre-print format</arxiv:comment>
    <link href="http://arxiv.org/abs/1706.10141v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.10141v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.05580v1</id>
    <updated>2017-07-18T12:13:30Z</updated>
    <published>2017-07-18T12:13:30Z</published>
    <title>Impact and Recovery Process of Mini Flash Crashes: An Empirical Study</title>
    <summary>  In an Ultrafast Extreme Event (or Mini Flash Crash), the price of a traded
stock increases or decreases strongly within milliseconds. We present a
detailed study of Ultrafast Extreme Events in stock market data. In contrast to
popular belief, our analysis suggests that most of the Ultrafast Extreme Events
are not primarily due to High Frequency Trading. In at least 60 percent of the
observed Ultrafast Extreme Events, the main cause for the events are large
market orders. In times of financial crisis, large market orders are more
likely which can be linked to the significant increase of Ultrafast Extreme
Events occurrences. Furthermore, we analyze the 100 trades following each
Ultrafast Extreme Events. While we observe a tendency of the prices to
partially recover, less than 40 percent recover completely. On the other hand
we find 25 percent of the Ultrafast Extreme Events to be almost recovered after
only one trade which differs from the usually found price impact of market
orders.
</summary>
    <author>
      <name>Tobias Braun</name>
    </author>
    <author>
      <name>Jonas A. Fiegen</name>
    </author>
    <author>
      <name>Daniel C. Wagner</name>
    </author>
    <author>
      <name>Sebastian M. Krause</name>
    </author>
    <author>
      <name>Thomas Guhr</name>
    </author>
    <link href="http://arxiv.org/abs/1707.05580v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.05580v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.TR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.TR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.01974v1</id>
    <updated>2017-08-07T03:10:04Z</updated>
    <published>2017-08-07T03:10:04Z</published>
    <title>Model Misspecification in ABC: Consequences and Diagnostics</title>
    <summary>  We analyze the behavior of approximate Bayesian computation (ABC) when the
model generating the simulated data differs from the actual data generating
process; i.e., when the data simulator in ABC is misspecified. We demonstrate
both theoretically and in simple, but practically relevant, examples that when
the model is misspecified different versions of ABC can lead to substantially
different results. Our theoretical results demonstrate that under regularity a
version of the ABC accept-reject approach concentrates posterior mass on an
appropriately defined pseudo-true parameter value, while the popular linear
regression adjustment to ABC concentrates posterior mass on a completely
different pseudo-true value. Our results suggest two diagnostic approaches to
diagnose model misspecification in ABC.
</summary>
    <author>
      <name>David T. Frazier</name>
    </author>
    <author>
      <name>Christian P. Robert</name>
    </author>
    <author>
      <name>Judith Rousseau</name>
    </author>
    <link href="http://arxiv.org/abs/1708.01974v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.01974v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.06160v1</id>
    <updated>2017-08-21T11:38:26Z</updated>
    <published>2017-08-21T11:38:26Z</published>
    <title>Economic Design of Memory-Type Control Charts: The Fallacy of the
  Formula Proposed by Lorenzen and Vance (1986)</title>
    <summary>  The memory-type control charts, such as EWMA and CUSUM, are powerful tools
for detecting small quality changes in univariate and multivariate processes.
Many papers on economic design of these control charts use the formula proposed
by Lorenzen and Vance (1986) [Lorenzen, T. J., &amp; Vance, L. C. (1986). The
economic design of control charts: A unified approach. Technometrics, 28(1),
3-10, DOI: 10.2307/1269598]. This paper shows that this formula is not correct
for memory-type control charts and its values can significantly deviate from
the original values even if the ARL values used in this formula are accurately
computed. Consequently, the use of this formula can result in charts that are
not economically optimal. The formula is corrected for memory-type control
charts, but unfortunately the modified formula is not a helpful tool from a
computational perspective. We show that simulation-based optimization is a
possible alternative method.
</summary>
    <author>
      <name>Amir Ahmadi-Javid</name>
    </author>
    <author>
      <name>Mohsen Ebadi</name>
    </author>
    <link href="http://arxiv.org/abs/1708.06160v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.06160v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.03535v1</id>
    <updated>2017-09-11T18:23:23Z</updated>
    <published>2017-09-11T18:23:23Z</published>
    <title>Stopping Behaviors of Naive and Non-Committed Sophisticated Agents when
  They Distort Probability</title>
    <summary>  We consider the problem of stopping a diffusion process with a payoff
functional involving probability distortion. The problem is inherently
time-inconsistent as the level of distortion of a same event changes over time.
We study stopping decisions of naive agents who reoptimize continuously in
time, as well as equilibrium strategies of sophisticated agents who anticipate
but lack control over their future selves' behaviors. When the state process is
one dimensional and the payoff functional satisfies some regularity conditions,
we prove that any equilibrium can be obtained as a fixed point of an operator.
This operator represents strategic reasoning that takes the future selves'
behaviors into account. In particular, we show how such strategic reasoning may
turn a naive agent into a sophisticated one. Finally, when the diffusion
process is a geometric Brownian motion we derive stopping strategies of these
two types of agent for various parameter specifications of the problem,
illustrating rich behaviors beyond the extreme ones such as "never-stopping" or
"never-starting".
</summary>
    <author>
      <name>Yu-Jui Huang</name>
    </author>
    <author>
      <name>Adrien Nguyen-Huu</name>
    </author>
    <author>
      <name>Xun Yu Zhou</name>
    </author>
    <link href="http://arxiv.org/abs/1709.03535v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.03535v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.MF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.MF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="60G40, 91B06" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.10402v1</id>
    <updated>2017-09-29T13:34:03Z</updated>
    <published>2017-09-29T13:34:03Z</published>
    <title>Distributions of Centrality on Networks</title>
    <summary>  In many social and economic networks, agents' outcomes depend substantially
on the centrality of their network position. Our current understanding of
network centrality is largely restricted to deterministic settings, but in many
applications data limitations or theoretical concerns lead practitioners to use
random network models. We provide a foundation for understanding how central
agents in random networks are likely to be. Our main theorems show that on
large random networks, centrality measures are close to their expected values
with high probability. By applying these theorems to stochastic block models,
we study how segregated networks contribute to inequality. When networks are
segregated, benefits from peer effects tend to accrue unevenly to the advantage
of more central individuals and groups. We also discuss applications to more
general network formation models, including models where link probabilities are
governed by geography.
</summary>
    <author>
      <name>Krishna Dasaratha</name>
    </author>
    <link href="http://arxiv.org/abs/1709.10402v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.10402v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.10478v1</id>
    <updated>2017-09-29T16:14:58Z</updated>
    <published>2017-09-29T16:14:58Z</published>
    <title>The Strength of Absent Ties: Social Integration via Online Dating</title>
    <summary>  We used to marry people to which we were somehow connected to: friends of
friends, schoolmates, neighbours. Since we were more connected to people
similar to us, we were likely to marry someone from our own race.
  However, online dating has changed this pattern: people who meet online tend
to be complete strangers. Given that one-third of modern marriages start
online, we investigate theoretically, using random graphs and matching theory,
the effects of those previously absent ties in the diversity of modern
societies.
  We find that when a society benefits from previously absent ties, social
integration occurs rapidly, even if the number of partners met online is small.
Our findings are consistent with the sharp increase in interracial marriages in
the U.S. in the last two decades.
</summary>
    <author>
      <name>Josue Ortega</name>
    </author>
    <author>
      <name>Philipp Hergovich</name>
    </author>
    <link href="http://arxiv.org/abs/1709.10478v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.10478v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91D30" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.0733v1</id>
    <updated>2014-05-04T19:21:40Z</updated>
    <published>2014-05-04T19:21:40Z</published>
    <title>Spatial interactions in agent-based modeling</title>
    <summary>  Agent Based Modeling (ABM) has become a widespread approach to model complex
interactions. In this chapter after briefly summarizing some features of ABM
the different approaches in modeling spatial interactions are discussed.
  It is stressed that agents can interact either indirectly through a shared
environment and/or directly with each other. In such an approach, higher-order
variables such as commodity prices, population dynamics or even institutions,
are not exogenously specified but instead are seen as the results of
interactions. It is highlighted in the chapter that the understanding of
patterns emerging from such spatial interaction between agents is a key problem
as much as their description through analytical or simulation means.
  The chapter reviews different approaches for modeling agents' behavior,
taking into account either explicit spatial (lattice based) structures or
networks. Some emphasis is placed on recent ABM as applied to the description
of the dynamics of the geographical distribution of economic activities, - out
of equilibrium. The Eurace@Unibi Model, an agent-based macroeconomic model with
spatial structure, is used to illustrate the potential of such an approach for
spatial policy analysis.
</summary>
    <author>
      <name>Marcel Ausloos</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Liege &amp; Amsterdam</arxiv:affiliation>
    </author>
    <author>
      <name>Herbert Dawid</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Bielefeld</arxiv:affiliation>
    </author>
    <author>
      <name>Ugo Merlone</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Torino</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">26 pages, 5 figures, 105 references; a chapter prepared for the book
  "Complexity and Geographical Economics - Topics and Tools", P. Commendatore,
  S.S. Kayam and I. Kubin, Eds. (Springer, in press, 2014)</arxiv:comment>
    <link href="http://arxiv.org/abs/1405.0733v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.0733v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1409.1620v1</id>
    <updated>2014-09-04T21:43:29Z</updated>
    <published>2014-09-04T21:43:29Z</published>
    <title>Orthogonal Polynomials for Seminonparametric Instrumental Variables
  Model</title>
    <summary>  We develop an approach that resolves a {\it polynomial basis problem} for a
class of models with discrete endogenous covariate, and for a class of
econometric models considered in the work of Newey and Powell (2003), where the
endogenous covariate is continuous. Suppose $X$ is a $d$-dimensional endogenous
random variable, $Z_1$ and $Z_2$ are the instrumental variables (vectors), and
$Z=\left(\begin{array}{c}Z_1 \\Z_2\end{array}\right)$. Now, assume that the
conditional distributions of $X$ given $Z$ satisfy the conditions sufficient
for solving the identification problem as in Newey and Powell (2003) or as in
Proposition 1.1 of the current paper. That is, for a function $\pi(z)$ in the
image space there is a.s. a unique function $g(x,z_1)$ in the domain space such
that $$E[g(X,Z_1)~|~Z]=\pi(Z) \qquad Z-a.s.$$ In this paper, for a class of
conditional distributions $X|Z$, we produce an orthogonal polynomial basis
$Q_j(x,z_1)$ such that for a.e. $Z_1=z_1$, and for all $j \in \mathbb{Z}_+^d$,
and a certain $\mu(Z)$, $$P_j(\mu(Z))=E[Q_j(X, Z_1)~|~Z ],$$ where $P_j$ is a
polynomial of degree $j$. This is what we call solving the {\it polynomial
basis problem}.
  Assuming the knowledge of $X|Z$ and an inference of $\pi(z)$, our approach
provides a natural way of estimating the structural function of interest
$g(x,z_1)$. Our polynomial basis approach is naturally extended to Pearson-like
and Ord-like families of distributions.
</summary>
    <author>
      <name>Yevgeniy Kovchegov</name>
    </author>
    <author>
      <name>Nese Yildiz</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1409.1620v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1409.1620v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62P20" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1409.3799v1</id>
    <updated>2014-09-12T17:23:21Z</updated>
    <published>2014-09-12T17:23:21Z</published>
    <title>The World Trade Web: A Multiple-Network Perspective</title>
    <summary>  International Trade (IT) plays a fundamental role in today's economy: by
connecting world countries production and consumption processes, it radically
contributes in shaping their economy and development path. Although its
evolving structure and determinants have been widely analyzed in the
literature, much less has been done to understand its interplay with other
complex phenomena. The aim of this work is, precisely in this direction, to
study the relations of IT with International Migration (IM) and Foreign Direct
Investments (FDI). In both cases the procedure used is to first approach the
problem in a multiple-networks perspective and than deepen the analysis by
using ad hoc econometrics techniques. With respect to IM, a general positive
correlation with IT is highlighted and product categories for which this effect
is stronger are identified and cross-checked with previous classifications.
Next, employing spatial econometric techniques and proposing a new way to
define country neighbors based on the most intense IM flows, direct/indirect
network effects are studied and a stronger competitive effect of third country
migrants is identified for a specific product class. In the case of FDI, first
correlations between the two networks are identified, highlighting how they can
be mostly explained by countries economic/demographic size and geographical
distance. Then, using the Heckman selection model with a gravity equation,
(non-linear) components arising from distance, position in the Global Supply
Chain and presence of Regional Trade Agreements are studied. Finally, it is
shown how IT and FDI correlation changes with sectors: they are complements in
manufacturing, but substitutes in services.
</summary>
    <author>
      <name>Paolo Sgrignoli</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.6092/imtlucca/e-theses/137</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.6092/imtlucca/e-theses/137" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">PhD thesis at IMT Institute for Advanced Studies Lucca. 114 pages, 12
  figures, 18 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1409.3799v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1409.3799v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.06163v1</id>
    <updated>2015-02-22T01:41:37Z</updated>
    <published>2015-02-22T01:41:37Z</published>
    <title>Threadneedle: An Experimental Tool for the Simulation and Analysis of
  Fractional Reserve Banking Systems</title>
    <summary>  Threadneedle is a multi-agent simulation framework, based on a full double
entry book keeping implementation of the banking system's fundamental
transactions. It is designed to serve as an experimental test bed for economic
simulations that can explore the banking system's influence on the
macro-economy under varying assumptions for its regulatory framework, mix of
financial instruments, and activities of borrowers and lenders. Support is
provided for Basel Capital and central bank reserve regulatory frameworks,
inter-bank lending and correct handling of loan defaults within the bank
accounting framework.
  In this paper we provide an overview of the design of Threadneedle, and the
rational for the double entry book keeping approach used in its implementation.
We then provide evidence from a series of experiments using the simulation that
the macro-economic behaviour of the banking system is in some cases sensitive
to double entry book keeping ledger definitions, and in particular that loss
provisions can be systemically affecting. We also show that credit and money
expansion in Basel regulated systems is now dominated by the Basel capital
requirements, rather than the older central bank reserve requirements. This
implies that bank profitability is now the main factor in providing new capital
to support lending, meaning that lowering interest rates can act to restrict
loan supply, rather than increasing borrowing as currently believed. We also
show that long term liquidity flows due to interest repayment act in favour of
the bank making the loan, and do not provide any long term throttling effect on
loan expansion and money expansion as has been claimed by Keynes and others.
</summary>
    <author>
      <name>Jacky Mallett</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages, 7 figures, Eastern Economic Association, 41st Conference
  2015 (Accepted)</arxiv:comment>
    <link href="http://arxiv.org/abs/1502.06163v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.06163v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.02479v2</id>
    <updated>2017-08-14T04:19:26Z</updated>
    <published>2015-03-09T14:00:11Z</published>
    <title>Competition and Efficiency of Coalitions in Cournot Games with
  Uncertainty</title>
    <summary>  We investigate the impact of coalition formation on the efficiency of Cournot
games where producers face uncertainties. In particular, we study a market
model where firms must determine their output before an uncertain production
capacity is realized. In contrast to standard Cournot models, we show that the
game is not efficient when there are many small firms. Instead, producers tend
to act conservatively to hedge against their risks. We show that in the
presence of uncertainty, the game becomes efficient when firms are allowed to
take advantage of diversity to form groups of certain sizes. We characterize
the tradeoff between market power and uncertainty reduction as a function of
group size. In particular, we compare the welfare and output obtained with
coalitional competition, with the same benchmarks when output is controlled by
a single system operator. We show when there are $N$ firms present, competition
between groups of size $\Omega(\sqrt{N})$ results in equilibria that are
socially optimal in terms of welfare and groups of size $\Omega(N^{2/3})$ are
socially optimal in terms of production. We also extend our results to the case
of uncertain demand by establishing an equivalency between Cournot oligopoly
and Cournot Oligopsony. We demonstrate our results with real data from
electricity markets with significant wind power penetration.
</summary>
    <author>
      <name>Baosen Zhang</name>
    </author>
    <author>
      <name>Ramesh Johari</name>
    </author>
    <author>
      <name>Ram Rajagopal</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to IEEE TCNS</arxiv:comment>
    <link href="http://arxiv.org/abs/1503.02479v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.02479v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.00348v2</id>
    <updated>2017-03-16T00:12:38Z</updated>
    <published>2015-06-01T04:44:25Z</published>
    <title>Enhanced Gravity Model of trade: reconciling macroeconomic and network
  models</title>
    <summary>  The structure of the International Trade Network (ITN), whose nodes and links
represent world countries and their trade relations respectively, affects key
economic processes worldwide, including globalization, economic integration,
industrial production, and the propagation of shocks and instabilities.
Characterizing the ITN via a simple yet accurate model is an open problem. The
traditional Gravity Model successfully reproduces the volume of trade between
connected countries, using macroeconomic properties such as GDP, geographic
distance, and possibly other factors. However, it predicts a network with
complete or homogeneous topology, thus failing to reproduce the highly
heterogeneous structure of the ITN. On the other hand, recent maximum-entropy
network models successfully reproduce the complex topology of the ITN, but
provide no information about trade volumes. Here we integrate these two
currently incompatible approaches via the introduction of an Enhanced Gravity
Model (EGM) of trade. The EGM is the simplest model combining the Gravity Model
with the network approach within a maximum-entropy framework. Via a unified and
principled mechanism that is transparent enough to be generalized to any
economic network, the EGM provides a new econometric framework wherein trade
probabilities and trade volumes can be separately controlled by any combination
of dyadic and country-specific macroeconomic variables. The model successfully
reproduces both the global topology and the local link weights of the ITN,
parsimoniously reconciling the conflicting approaches. It also indicates that
the probability that any two countries trade a certain volume should follow a
geometric or exponential distribution with an additional point mass at zero
volume.
</summary>
    <author>
      <name>Assaf Almog</name>
    </author>
    <author>
      <name>Rhys Bird</name>
    </author>
    <author>
      <name>Diego Garlaschelli</name>
    </author>
    <link href="http://arxiv.org/abs/1506.00348v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.00348v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.dis-nn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.05415v1</id>
    <updated>2015-07-20T08:36:34Z</updated>
    <published>2015-07-20T08:36:34Z</published>
    <title>Endogenous Derivation and Forecast of Lifetime PDs</title>
    <summary>  This paper proposes a simple technical approach for the derivation of future
(forward) point-in-time PD forecasts, with minimal data requirements. The
inputs required are the current and future through-the-cycle PDs of the
obligors, their last known default rates, and a measure for the systematic
dependence of the obligors. Technically, the forecasts are made from within a
classical asset-based credit portfolio model, just with the assumption of a
suitable autoregressive process for the systematic factor. The paper discusses
in detail the practical issues of implementation, in particular the
parametrization alternatives.
  The paper also shows how the approach can be naturally extended to
low-default portfolios with volatile default rates, using Bayesian methodology.
Furthermore, the expert judgments about the current macroeconomic state,
although not necessary for the forecasts, can be embedded using the Bayesian
technique.
  The presented forward PDs can be used for the derivation of lifetime credit
losses required by the new accounting standard IFRS 9. In doing so, the
presented approach is endogenous, as it does not require any exogenous
macroeconomic forecasts which are notoriously unreliable and often subjective.
</summary>
    <author>
      <name>Volodymyr Perederiy</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">JEL Classification: C13, C11, C22, C51, C53, E32, E37, M41, G33
  Keywords: Prediction, Probability of Default, PD, Default Rates,
  Through-the-Cycle, TTC, Point-in-Time, PIT, Credit Portfolio Model,
  Systematic Factor, Macroeconomic Factor, Time Series, Autoregression,
  Bayesian Analysis, IFRS 9, Accounting, Financial Instruments, Lifetime,
  Expected Credit Losses</arxiv:comment>
    <link href="http://arxiv.org/abs/1507.05415v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.05415v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.02473v4</id>
    <updated>2016-08-24T16:10:33Z</updated>
    <published>2015-08-11T02:49:45Z</published>
    <title>Bridging AIC and BIC: a new criterion for autoregression</title>
    <summary>  We introduce a new criterion to determine the order of an autoregressive
model fitted to time series data. It has the benefits of the two well-known
model selection techniques, the Akaike information criterion and the Bayesian
information criterion. When the data is generated from a finite order
autoregression, the Bayesian information criterion is known to be consistent,
and so is the new criterion. When the true order is infinity or suitably high
with respect to the sample size, the Akaike information criterion is known to
be efficient in the sense that its prediction performance is asymptotically
equivalent to the best offered by the candidate models; in this case, the new
criterion behaves in a similar manner. Different from the two classical
criteria, the proposed criterion adaptively achieves either consistency or
efficiency depending on the underlying true model. In practice where the
observed time series is given without any prior information about the model
specification, the proposed order selection criterion is more flexible and
robust compared with classical approaches. Numerical results are presented
demonstrating the adaptivity of the proposed technique when applied to various
datasets.
</summary>
    <author>
      <name>Jie Ding</name>
    </author>
    <author>
      <name>Vahid Tarokh</name>
    </author>
    <author>
      <name>Yuhong Yang</name>
    </author>
    <link href="http://arxiv.org/abs/1508.02473v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.02473v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.08103v1</id>
    <updated>2015-10-27T21:34:11Z</updated>
    <published>2015-10-27T21:34:11Z</published>
    <title>From Acquaintances to Friends: Homophily and Learning in Networks</title>
    <summary>  This paper considers the evolution of a network in a discrete time,
stochastic setting in which agents learn about each other through repeated
interactions and maintain/break links on the basis of what they learn from
these interactions. Agents have homophilous preferences and limited capacity,
so they maintain links with others who are learned to be similar to themselves
and cut links to others who are learned to be dissimilar to themselves. Thus
learning influences the evolution of the network, but learning is imperfect so
the evolution is stochastic. Homophily matters. Higher levels of homophily
decrease the (average) number of links that agents form. However, the effect of
homophily is anomalous: mutually beneficial links may be dropped before
learning is completed, thereby resulting in sparser networks and less
clustering than under complete information. There may be big differences
between the networks that emerge under complete and incomplete information.
Homophily matters here as well: initially, greater levels of homophily increase
the difference between the complete and incomplete information networks, but
sufficiently high levels of homophily eventually decrease the difference.
Complete and incomplete information networks differ the most when the degree of
homophily is intermediate. With multiple stages of life, the effects of
incomplete information are large initially but fade somewhat over time.
</summary>
    <author>
      <name>Mihaela van der Schaar</name>
    </author>
    <author>
      <name>Simpson Zhang</name>
    </author>
    <link href="http://arxiv.org/abs/1510.08103v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.08103v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.01804v2</id>
    <updated>2016-03-25T04:23:41Z</updated>
    <published>2016-01-08T09:41:36Z</published>
    <title>Unified Growth Theory Contradicted by the Economic Growth in Latin
  America</title>
    <summary>  Historical economic growth in Latin America is analysed using the data of
Maddison. Unified Growth Theory is found to be contradicted by these data in
the same way as it is contradicted by the economic growth in Africa, Asia,
former USSR, Western Europe, Eastern Europe and by the world economic growth.
Paradoxically, Unified Growth Theory is repeatedly and consistently
contradicted by the same data, which were used, but never properly analysed,
during the formulation of this theory. Unified Growth Theory does not explain
the mechanism of the economic growth because it explains features contradicted
by data. This theory is based fundamentally on the unfortunate lack of
understanding of the properties of hyperbolic distribution and on the
unscientific analysis of data. There was no transition from stagnation to
growth at the end of the alleged Malthusian regime because the economic growth
was hyperbolic. There was no escape from Malthusian trap because there was no
trap. There was no takeoff. On the contrary, at the time of the alleged takeoff
economic growth started to be diverted to a slower trajectory. Unified Growth
Theory is dissociated from the reality. This theory needs to be revised or
replaced. In its present form, it is a collection of irrelevant stories based
on impressions and on the unscientific use of data.
</summary>
    <author>
      <name>Ron W Nielsen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 2 figures, 3185 words.Corrected two parameters. Conclusions
  remain unchanged</arxiv:comment>
    <link href="http://arxiv.org/abs/1601.01804v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.01804v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.07792v2</id>
    <updated>2016-04-05T20:20:42Z</updated>
    <published>2016-01-28T15:03:23Z</published>
    <title>Predicting Human Cooperation</title>
    <summary>  The Prisoner's Dilemma has been a subject of extensive research due to its
importance in understanding the ever-present tension between individual
self-interest and social benefit. A strictly dominant strategy in a Prisoner's
Dilemma (defection), when played by both players, is mutually harmful.
Repetition of the Prisoner's Dilemma can give rise to cooperation as an
equilibrium, but defection is as well, and this ambiguity is difficult to
resolve. The numerous behavioral experiments investigating the Prisoner's
Dilemma highlight that players often cooperate, but the level of cooperation
varies significantly with the specifics of the experimental predicament. We
present the first computational model of human behavior in repeated Prisoner's
Dilemma games that unifies the diversity of experimental observations in a
systematic and quantitatively reliable manner. Our model relies on data we
integrated from many experiments, comprising 168,386 individual decisions. The
computational model is composed of two pieces: the first predicts the
first-period action using solely the structural game parameters, while the
second predicts dynamic actions using both game parameters and history of play.
Our model is extremely successful not merely at fitting the data, but in
predicting behavior at multiple scales in experimental designs not used for
calibration, using only information about the game structure. We demonstrate
the power of our approach through a simulation analysis revealing how to best
promote human cooperation.
</summary>
    <author>
      <name>John J. Nay</name>
    </author>
    <author>
      <name>Yevgeniy Vorobeychik</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1371/journal.pone.0155656</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1371/journal.pone.0155656" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Added references. New inline citation style. Added small portions of
  text. Re-compiled Rmarkdown file with updated ggplot2 so small aesthetic
  changes to plots</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">PLoS ONE 11(5): e0155656 (2016)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1601.07792v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.07792v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.06034v5</id>
    <updated>2017-03-26T12:34:07Z</updated>
    <published>2016-03-19T02:43:06Z</published>
    <title>Solving Society's Big Ills, A Small Step</title>
    <summary>  We look at a collection of conjectures with the unifying message that smaller
social systems, tend to be less complex and can be aligned better, towards
fulfilling their intended objectives. We touch upon a framework, referred to as
the four pronged approach that can aid the analysis of social systems. The four
prongs are:
  1. The Uncertainty Principle of the Social Sciences
  2. The Objectives of a Social System or the Responsibilities of the Players
  3. The Need for Smaller Organizations
  4. Redirecting Unintended Outcomes
  Smaller organizations mitigating the disruptive effects of corruption is
discussed and also the need for organizations, whose objective is to foster the
development of other smaller organizations. We consider a way of life, which is
about respect for knowledge and a desire to seek it. Knowledge can help
eradicate ignorance, but the accumulation of knowledge can lead to
overconfidence. Hence it becomes important to instill an attitude that does not
knowledge too seriously, along with the thirst for knowledge. All of this is
important to create an environment that is conducive for smaller organizations
and can be viewed as a natural extension of studies that fall under the wider
category of understanding factors and policies aimed at increasing the welfare
or well-being to society.
</summary>
    <author>
      <name>Ravi Kashyap</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5539/ass.v13n4p175</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5539/ass.v13n4p175" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: substantial text overlap with arXiv:1603.00991</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Asian Social Science, (April 2017), Canadian Center of Science and
  Education, Vol. 13, No. 4, pp. 175-191</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1603.06034v5" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.06034v5" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.00142v1</id>
    <updated>2016-06-01T07:22:01Z</updated>
    <published>2016-06-01T07:22:01Z</published>
    <title>Model selection consistency from the perspective of generalization
  ability and VC theory with an application to Lasso</title>
    <summary>  Model selection is difficult to analyse yet theoretically and empirically
important, especially for high-dimensional data analysis. Recently the least
absolute shrinkage and selection operator (Lasso) has been applied in the
statistical and econometric literature. Consis- tency of Lasso has been
established under various conditions, some of which are difficult to verify in
practice. In this paper, we study model selection from the perspective of
generalization ability, under the framework of structural risk minimization
(SRM) and Vapnik-Chervonenkis (VC) theory. The approach emphasizes the balance
between the in-sample and out-of-sample fit, which can be achieved by using
cross-validation to select a penalty on model complexity. We show that an exact
relationship exists between the generalization ability of a model and model
selection consistency. By implementing SRM and the VC inequality, we show that
Lasso is L2-consistent for model selection under assumptions similar to those
imposed on OLS. Furthermore, we derive a probabilistic bound for the distance
between the penalized extremum estimator and the extremum estimator without
penalty, which is dominated by overfitting. We also propose a new measurement
of overfitting, GR2, based on generalization ability, that converges to zero if
model selection is consistent. Using simulations, we demonstrate that the
proposed CV-Lasso algorithm performs well in terms of model selection and
overfitting control.
</summary>
    <author>
      <name>Ning Xu</name>
    </author>
    <author>
      <name>Jian Hong</name>
    </author>
    <author>
      <name>Timothy C. G. Fisher</name>
    </author>
    <link href="http://arxiv.org/abs/1606.00142v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.00142v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.06163v2</id>
    <updated>2016-08-30T06:18:18Z</updated>
    <published>2016-07-21T00:57:10Z</published>
    <title>Indirect Inference With(Out) Constraints</title>
    <summary>  The traditional implementation of Indirect Inference (I-I) is to perform
inference on structural parameters $\theta$ by matching observed and simulated
auxiliary statistics. These auxiliary statistics are consistent estimators of
instrumental parameters whose value depends on the value of structural
parameters through a binding function. Since instrumental parameters
encapsulate the statistical information used for inference about the structural
parameters, it sounds paradoxical to constrain these parameters, that is, to
restrain the information used for inference. However, there are situations
where the definition of instrumental parameters $\beta$ naturally comes with a
set of $q$ restrictions. Such situations include: settings where the auxiliary
parameters must be estimated subject to $q$ possibly binding strict inequality
constraints $g(\cdot) &gt; 0$; cases where the auxiliary model is obtained by
imposing $q$ equality constraints $g(\theta) = 0$ on the structural model to
define tractable auxiliary parameter estimates of $\beta$ that are seen as an
approximation of the true $\theta$, since the simplifying constraints are
misspecified; examples where the auxiliary parameters are defined by $q$
estimating equations that overidentify them. We demonstrate that the optimal
solution in these settings is to disregard the constrained auxiliary
statistics, and perform I-I without these constraints using appropriately
modified unconstrained versions of the auxiliary statistics. In each of the
above examples, we outline how such unconstrained auxiliary statistics can be
constructed and demonstrate that this I-I approach without constraints can be
reinterpreted as a standard implementation of I-I through a properly modified
binding function.
</summary>
    <author>
      <name>David T. Frazier</name>
    </author>
    <author>
      <name>Eric Renault</name>
    </author>
    <link href="http://arxiv.org/abs/1607.06163v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.06163v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.00275v1</id>
    <updated>2016-07-31T22:37:27Z</updated>
    <published>2016-07-31T22:37:27Z</published>
    <title>Metastable Features of Economic Networks and Responses to Exogenous
  Shocks</title>
    <summary>  It has been proved that network structure plays an important role in
addressing a collective behaviour. In this paper we consider a network of firms
and corporations and study its metastable features in an Ising based model. In
our model, we observe that if in a recession the government imposes a demand
shock to stimulate the network, metastable features shape its response.
Actually we find that there is a minimum bound where demand shocks with a size
below it are unable to trigger the market out from recession. We then
investigate the impact of network characteristics on this minimum bound. We
surprisingly observe that in a Watts-Strogatz network though the minimum bound
depends on the average of the degrees, when translated into the economics
language, such a bound is independent of the average degrees. This bound is
about $0.44 \Delta$GDP, where $\Delta$GDP is the gap of GDP between recession
and expansion. We examine our suggestions for the cases of the United States
and the European Union in the recent recession, and compare them with the
imposed stimulations. While stimulation in the US has been above our threshold,
in the EU it has been far below our threshold. Beside providing a minimum bound
for a successful stimulation, our study on the metastable features suggests
that in the time of crisis there is a "golden time passage" in which the
minimum bound for successful stimulation can be much lower. So, our study
strongly suggests stimulations to be started within this time passage.
</summary>
    <author>
      <name>Ali Hosseiny</name>
    </author>
    <author>
      <name>Mohammad Bahrami</name>
    </author>
    <author>
      <name>Antonio Palestrini</name>
    </author>
    <author>
      <name>Mauro Gallegati</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1371/journal.pone.0160363</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1371/journal.pone.0160363" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 10 figures, accepted for publication in PloS One</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">PloS one 11 (10), e0160363 (2016)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1608.00275v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.00275v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.00878v1</id>
    <updated>2016-08-02T15:55:33Z</updated>
    <published>2016-08-02T15:55:33Z</published>
    <title>On the Use of Computer Programs as Money</title>
    <summary>  Money is a technology for promoting economic prosperity. Over history money
has become increasingly abstract, it used to be hardware, gold coins and the
like, now it is mostly software, data structures located in banks. Here I
propose the logical conclusion of the abstraction of money: to use as money the
most general form of information - computer programs. The key advantage that
using programs for money (program-money) adds to the technology of money is
agency. Program-money is active and thereby can fully participate in economics
as economic agents. I describe the three basic technologies required to
implement program-money: computational languages/logics to unambiguously
describe the actions and interactions of program-money; computational
cryptography to ensure that only the correct actions and interactions are
performed; and a distributed computational environment in which the money can
execute. I demonstrate that most of the technology for program-money has
already been developed. The adoption of program-money transfers responsibility
from human economic agents to money itself and has great potential economic
advantages over the current passive form of money. For example in
microeconomics, adding agency to money will simplify the exchange of ownership,
ensure money is only used legally, automate the negotiation and forming of
contracts, etc. Similar advantages occur in macroeconomics, where for example
the control of the money supply could be transferred from central banks to
money. It is also possible to envisage money that is not owned by any external
human agent or corporation. One motivation for this is to force economic
systems to behave more rationally and/or more like a specific economic theory,
thereby increasing the success of economic forecasting.
</summary>
    <author>
      <name>Ross D. King</name>
    </author>
    <link href="http://arxiv.org/abs/1608.00878v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.00878v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68U99" scheme="http://arxiv.org/schemas/atom"/>
    <category term="K.4.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.05002v4</id>
    <updated>2017-04-22T17:11:48Z</updated>
    <published>2016-08-17T15:33:53Z</published>
    <title>Bayesian Posteriors For Arbitrarily Rare Events</title>
    <summary>  We study how much data a Bayesian observer needs to correctly infer the
relative likelihoods of two events when both events are arbitrarily rare. Each
period, either a blue die or a red die is tossed. The two dice land on side $1$
with unknown probabilities $p_1$ and $q_1$, which can be arbitrarily low. Given
a data-generating process where $p_1\ge c q_1$, we are interested in how much
data is required to guarantee that with high probability the observer's
Bayesian posterior mean for $p_1$ exceeds $(1-\delta)c$ times that for $q_1$.
If the prior densities for the two dice are positive on the interior of the
parameter space and behave like power functions at the boundary, then for every
$\epsilon&gt;0,$ there exists a finite $N$ so that the observer obtains such an
inference after $n$ periods with probability at least $1-\epsilon$ whenever
$np_1\ge N$. The condition on $n$ and $p_1$ is the best possible. The result
can fail if one of the prior densities converges to zero exponentially fast at
the boundary.
</summary>
    <author>
      <name>Drew Fudenberg</name>
    </author>
    <author>
      <name>Kevin He</name>
    </author>
    <author>
      <name>Lorens Imhof</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1073/pnas.1618780114</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1073/pnas.1618780114" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the National Academy of Sciences 114(19):4925-4929,
  May 2017</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1608.05002v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.05002v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.00415v1</id>
    <updated>2016-09-01T22:18:59Z</updated>
    <published>2016-09-01T22:18:59Z</published>
    <title>Does Infrastructure Investment Lead to Economic Growth or Economic
  Fragility? Evidence from China</title>
    <summary>  The prevalent view in the economics literature is that a high level of
infrastructure investment is a precursor to economic growth. China is
especially held up as a model to emulate. Based on the largest dataset of its
kind, this paper punctures the twin myths that, first, infrastructure creates
economic value, and, second, China has a distinct advantage in its delivery.
Far from being an engine of economic growth, the typical infrastructure
investment fails to deliver a positive risk adjusted return. Moreover, China's
track record in delivering infrastructure is no better than that of rich
democracies. Where investments are debt-financed, overinvesting in unproductive
projects results in the buildup of debt, monetary expansion, instability in
financial markets, and economic fragility, exactly as we see in China today. We
conclude that poorly managed infrastructure investments are a main explanation
of surfacing economic and financial problems in China. We predict that, unless
China shifts to a lower level of higher-quality infrastructure investments, the
country is headed for an infrastructure-led national financial and economic
crisis, which is likely also to be a crisis for the international economy.
China's infrastructure investment model is not one to follow for other
countries but one to avoid.
</summary>
    <author>
      <name>Atif Ansar</name>
    </author>
    <author>
      <name>Bent Flyvbjerg</name>
    </author>
    <author>
      <name>Alexander Budzier</name>
    </author>
    <author>
      <name>Daniel Lunn</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1093/oxrep/grw022</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1093/oxrep/grw022" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Oxford Review of Economic Policy, vol 32, 2016</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1609.00415v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.00415v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.01274v4</id>
    <updated>2016-11-06T11:36:48Z</updated>
    <published>2016-09-06T05:45:08Z</published>
    <title>Securities Lending Strategies, Valuation of Term Loans using Option
  Theory</title>
    <summary>  We develop models to price long term loans in the securities lending
business. These longer horizon deals can be viewed as contracts with
optionality embedded in them and can be priced using established methods from
derivatives theory, becoming to our limited knowledge, the first application
that can lead to greater synergies between the operations of derivative and
delta-one trading desks, perhaps even being able to combine certain aspects of
the day to day operations of these seemingly disparate entities. We develop a
heuristic that can mitigate the loss of information that sets in, when
parameters are estimated first and then the valuation is performed, by directly
calculating the valuation using the historical time series. We run numerical
simulations to demonstrate the practical applicability of these models. These
models are part of one of the least explored yet profit laden areas of modern
investment management.
  We illustrate how the methodologies developed here could be useful for
inventory management. All these techniques could have applications for dealing
with other financial instruments, non-financial commodities and many forms of
uncertainty. Admittedly, our initial ambitions to produce a normative theory on
long term loan valuations are undone by the present state of affairs in social
science modeling. Though we consider many elements of a securities lending
system at face value, this cannot be termed a positive theory. For now, if it
ends up producing a useful theory, our work is done.
</summary>
    <author>
      <name>Ravi Kashyap</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: text overlap with arXiv:1603.00987</arxiv:comment>
    <link href="http://arxiv.org/abs/1609.01274v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.01274v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.PM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.TR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.03344v2</id>
    <updated>2016-09-13T09:34:17Z</updated>
    <published>2016-09-12T11:09:50Z</published>
    <title>Finite-sample and asymptotic analysis of generalization ability with an
  application to penalized regression</title>
    <summary>  In this paper, we study the performance of extremum estimators from the
perspective of generalization ability (GA): the ability of a model to predict
outcomes in new samples from the same population. By adapting the classical
concentration inequalities, we derive upper bounds on the empirical
out-of-sample prediction errors as a function of the in-sample errors,
in-sample data size, heaviness in the tails of the error distribution, and
model complexity. We show that the error bounds may be used for tuning key
estimation hyper-parameters, such as the number of folds $K$ in
cross-validation. We also show how $K$ affects the bias-variance trade-off for
cross-validation. We demonstrate that the $\mathcal{L}_2$-norm difference
between penalized and the corresponding un-penalized regression estimates is
directly explained by the GA of the estimates and the GA of empirical moment
conditions. Lastly, we prove that all penalized regression estimates are
$L_2$-consistent for both the $n \geqslant p$ and the $n &lt; p$ cases.
Simulations are used to demonstrate key results.
  Keywords: generalization ability, upper bound of generalization error,
penalized regression, cross-validation, bias-variance trade-off,
$\mathcal{L}_2$ difference between penalized and unpenalized regression, lasso,
high-dimensional data.
</summary>
    <author>
      <name>Ning Xu</name>
    </author>
    <author>
      <name>Jian Hong</name>
    </author>
    <author>
      <name>Timothy C. G. Fisher</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The theoretical generalization and extension of arXiv:1606.00142</arxiv:comment>
    <link href="http://arxiv.org/abs/1609.03344v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.03344v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1610.05448v1</id>
    <updated>2016-10-18T06:26:47Z</updated>
    <published>2016-10-18T06:26:47Z</published>
    <title>Generalization error minimization: a new approach to model evaluation
  and selection with an application to penalized regression</title>
    <summary>  We study model evaluation and model selection from the perspective of
generalization ability (GA): the ability of a model to predict outcomes in new
samples from the same population. We believe that GA is one way formally to
address concerns about the external validity of a model. The GA of a model
estimated on a sample can be measured by its empirical out-of-sample errors,
called the generalization errors (GE). We derive upper bounds for the GE, which
depend on sample sizes, model complexity and the distribution of the loss
function. The upper bounds can be used to evaluate the GA of a model, ex ante.
We propose using generalization error minimization (GEM) as a framework for
model selection. Using GEM, we are able to unify a big class of penalized
regression estimators, including lasso, ridge and bridge, under the same set of
assumptions. We establish finite-sample and asymptotic properties (including
$\mathcal{L}_2$-consistency) of the GEM estimator for both the $n \geqslant p$
and the $n &lt; p$ cases. We also derive the $\mathcal{L}_2$-distance between the
penalized and corresponding unpenalized regression estimates. In practice, GEM
can be implemented by validation or cross-validation. We show that the GE
bounds can be used for selecting the optimal number of folds in $K$-fold
cross-validation. We propose a variant of $R^2$, the $GR^2$, as a measure of
GA, which considers both both in-sample and out-of-sample goodness of fit.
Simulations are used to demonstrate our key results.
</summary>
    <author>
      <name>Ning Xu</name>
    </author>
    <author>
      <name>Jian Hong</name>
    </author>
    <author>
      <name>Timothy C. G. Fisher</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The theoretical generalization and extension of arXiv:1606.00142 and
  arXiv:1609.03344</arxiv:comment>
    <link href="http://arxiv.org/abs/1610.05448v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1610.05448v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1611.08330v1</id>
    <updated>2016-11-25T00:43:15Z</updated>
    <published>2016-11-25T00:43:15Z</published>
    <title>The 2015-2017 policy changes to the means-tests of Australian Age
  Pension: implication to decisions in retirement</title>
    <summary>  The Australian Government uses the means-test as a way of managing the
pension budget. Changes in Age Pension policy impose difficulties in retirement
modelling due to policy risk, but any major changes tend to be `grandfathered'
meaning that current retirees are exempt from the new changes. In 2015, two
important changes were made in regards to allocated pension accounts -- the
income means-test is now based on deemed income rather than account
withdrawals, and the income-test deduction no longer applies. We examine the
implications of the new changes in regards to optimal decisions for
consumption, investment, and housing. We account for regulatory minimum
withdrawal rules that are imposed by regulations on allocated pension accounts,
as well as the 2017 asset-test rebalancing. The new policy changes are modelled
in a utility maximizing lifecycle model and solved as an optimal stochastic
control problem. We find that the new rules decrease the benefits from planning
the consumption in relation to the means-test, while the housing allocation
increases slightly in order to receive additional Age Pension. The difference
in optimal drawdown between the old and new policy are only noticeable early in
retirement until regulatory minimum withdrawal rates are enforced. However, the
amount of extra Age Pension received for many households is now significantly
different due to the new deeming income rules, which benefit slightly wealthier
households who previously would receive no Age Pension due to the income-test
and minimum withdrawals.
</summary>
    <author>
      <name>Johan G. Andreasson</name>
    </author>
    <author>
      <name>Pavel V. Shevchenko</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, 8 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1611.08330v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1611.08330v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.06451v1</id>
    <updated>2016-12-19T23:05:35Z</updated>
    <published>2016-12-19T23:05:35Z</published>
    <title>Panel dataset description for econometric analysis of the ISP-OTT
  relationship in the years 2008-2013</title>
    <summary>  The latest technological advancements in the telecommunications domain (e.g.,
widespread adoption of mobile devices, introduction of 5G wireless
communications, etc.) have brought new stakeholders into the spotlight. More
specifically, Over-the-Top (OTT) providers have recently appeared, offering
their services over the existing deployed telecommunication networks. The entry
of the new players has changed the dynamics in the domain, as it creates
conflicting situations with the Internet Service Providers (ISPs), who
traditionally dominate the area, motivating the necessity for novel analytical
studies for this relationship. However, despite the importance of accessing
real observational data, there is no database with the aggregate information
that can serve as a solid base for this research. To that end, this document
provides a detailed summary report for financial and statistic data for the
period 2008-2013 that can be exploited for realistic econometric models that
will provide useful insights on this topic. The document summarizes data from
various sources with regard to the ISP revenues and Capital Expenditures
(CAPEX), the OTT revenues, the Internet penetration and the Gross Domestic
Product (GDP), taking into account three big OTT providers (i.e., Facebook,
Skype, WhatsApp) and ten major ISPs that operate in seven different countries.
</summary>
    <author>
      <name>Chiara Perillo</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Zurich, Department of Banking and Finance, Zurich, Switzerland</arxiv:affiliation>
    </author>
    <author>
      <name>Angelos Antonopoulos</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Telecommunications Technological Centre of Catalonia</arxiv:affiliation>
    </author>
    <author>
      <name>Christos Verikoukis</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Telecommunications Technological Centre of Catalonia</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">34 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1612.06451v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.06451v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="C.2.0; C.2.1; C.2.3; C.2.5; G.3; K.6.0" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.05240v2</id>
    <updated>2017-03-21T17:38:04Z</updated>
    <published>2017-03-15T16:33:18Z</published>
    <title>Humans of Simulated New York (HOSNY): an exploratory comprehensive model
  of city life</title>
    <summary>  The model presented in this paper experiments with a comprehensive simulant
agent in order to provide an exploratory platform in which simulation modelers
may try alternative scenarios and participation in policy decision-making. The
framework is built in a computationally distributed online format in which
users can join in and visually explore the results. Modeled activity involves
daily routine errands, such as shopping, visiting the doctor or engaging in the
labor market. Further, agents make everyday decisions based on individual
behavioral attributes and minimal requirements, according to social and
contagion networks. Fully developed firms and governments are also included in
the model allowing for taxes collection, production decisions, bankruptcy and
change in ownership. The contributions to the literature are multifold. They
include (a) a comprehensive model with detailing of the agents and firms'
activities and processes and original use of simultaneously (b) reinforcement
learning for firm pricing and demand allocation; (c) social contagion for
disease spreading and social network for hiring opportunities; and (d) Bayesian
networks for demographic-like generation of agents. All of that within a (e)
visually rich environment and multiple use of databases. Hence, the model
provides a comprehensive framework from where interactions among citizens,
firms and governments can be easily explored allowing for learning and
visualization of policies and scenarios.
</summary>
    <author>
      <name>Francis Tseng</name>
    </author>
    <author>
      <name>Fei Liu</name>
    </author>
    <author>
      <name>Bernardo Alves Furtado</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, 5 figures, submitted (in review), typos corrected</arxiv:comment>
    <link href="http://arxiv.org/abs/1703.05240v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.05240v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.08750v1</id>
    <updated>2017-03-26T01:18:35Z</updated>
    <published>2017-03-26T01:18:35Z</published>
    <title>Game-Theoretic Protection Against Networked SIS Epidemics by Human
  Decision-Makers</title>
    <summary>  We study decentralized protection strategies by human decision-makers against
Susceptible-Infected-Susceptible (SIS) epidemics on networks. Specifically, we
examine the impact of behavioral (mis)-perceptions of infection probabilities
(captured by Prospect theory) on the Nash equilibrium strategies in two classes
of games. In the first class of games, nodes choose their curing rates to
minimize the steady-state infection probability under the degree-based
mean-field approximation plus the cost of their selected curing rate. We
establish the existence of pure Nash equilibria under both risk neutral and
behavioral decision-makers. When the per-unit cost of curing rate is
sufficiently high, we show that risk neutral players choose the curing rate to
be zero at the equilibrium, while curing rate is nonzero under behavioral
decision-making for any finite cost. In the second class of games, the nodes
choose whether or not to vaccinate themselves. We establish the existence of
unique threshold equilibria where nodes with degrees larger than a certain
threshold vaccinate. When the vaccination cost is sufficiently high, fewer
behavioral players vaccinate compared to risk neutral players, and vice versa.
Finally, we provide a rigorous comparison of the equilibrium thresholds under
behavioral and risk neutral players in networks with power-law degree
distributions.
</summary>
    <author>
      <name>Ashish R. Hota</name>
    </author>
    <author>
      <name>Shreyas Sundaram</name>
    </author>
    <link href="http://arxiv.org/abs/1703.08750v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.08750v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1704.06508v1</id>
    <updated>2017-04-21T12:41:30Z</updated>
    <published>2017-04-21T12:41:30Z</published>
    <title>Scaling evidence of the homothetic nature of cities</title>
    <summary>  In this paper we analyse the profile of land use and population density with
respect to the distance to the city centre for the European city. In addition
to providing the radial population density and soil-sealing profiles for a
large set of cities, we demonstrate a remarkable constancy of the profiles
across city size.
  Our analysis combines the GMES/Copernicus Urban Atlas 2006 land use database
at 5m resolution for 300 European cities with more than 100.000 inhabitants and
the Geostat population grid at 1km resolution. Population is allocated
proportionally to surface and weighted by soil sealing and density classes of
the Urban Atlas. We analyse the profile of each artificial land use and
population with distance to the town hall.
  In line with earlier literature, we confirm the strong monocentricity of the
European city and the negative exponential curve for population density.
Moreover, we find that land use curves, in particular the share of housing and
roads, scale along the two horizontal dimensions with the square root of city
population, while population curves scale in three dimensions with the cubic
root of city population. In short, European cities of different sizes are
homothetic in terms of land use and population density. While earlier
literature documented the scaling of average densities (total surface and
population) with city size, we document the scaling of the whole radial
distance profile with city size, thus liaising intra-urban radial analysis and
systems of cities. In addition to providing a new empirical view of the
European city, our scaling offers a set of practical and coherent definitions
of a city, independent of its population, from which we can re-question urban
scaling laws and Zipf's law for cities.
</summary>
    <author>
      <name>Rémi Lemoy</name>
    </author>
    <author>
      <name>Geoffrey Caruso</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages, 11 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1704.06508v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1704.06508v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.01302v1</id>
    <updated>2017-05-03T08:32:28Z</updated>
    <published>2017-05-03T08:32:28Z</published>
    <title>The coordination of centralised and distributed generation</title>
    <summary>  This paper analyses the interaction between centralised carbon emissive
technologies and distributed intermittent non-emissive technologies. In our
model, there is a representative consumer who can satisfy her electricity
demand by investing in distributed generation (solar panels) and by buying
power from a centralised firm at a price the firm sets. Distributed generation
is intermittent and induces an externality cost to the consumer. The firm
provides non-random electricity generation subject to a carbon tax and to
transmission costs. The objective of the consumer is to satisfy her demand
while minimising investment costs, payments to the firm and intermittency
costs. The objective of the firm is to satisfy the consumer's residual demand
while minimising investment costs, demand deviation costs, and maximising the
payments from the consumer. We formulate the investment decisions as
McKean-Vlasov control problems with stochastic coefficients. We provide
explicit, price model-free solutions to the optimal decision problems faced by
each player, the solution of the Pareto optimum, and the Stackelberg
equilibrium where the firm is the leader. We find that, from the social
planner's point of view, the carbon tax or transmission costs are necessary to
justify a positive share of distributed capacity in the long-term, whatever the
respective investment costs of both technologies are. The Stackelberg
equilibrium is far from the Pareto equilibrium and leads to an over-investment
in distributed energy and to a much higher price for centralised energy.
</summary>
    <author>
      <name>René Aïd</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LEDa</arxiv:affiliation>
    </author>
    <author>
      <name>Matteo Basei</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LPMA</arxiv:affiliation>
    </author>
    <author>
      <name>Huyên Pham</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CREST, LPMA</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/1705.01302v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.01302v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.05882v2</id>
    <updated>2017-08-18T16:05:00Z</updated>
    <published>2017-05-16T19:36:56Z</published>
    <title>Supply and Shorting in Speculative Markets</title>
    <summary>  We propose a continuous-time model of trading among risk-neutral agents with
heterogeneous beliefs. Agents face quadratic costs-of-carry on their positions
and as a consequence, their marginal valuation of the asset decreases when the
magnitude of their position increases, as it would be the case for risk-averse
agents. In the equilibrium models of investors with heterogeneous beliefs that
followed the original work by Harrison and Kreps, investors are risk-neutral,
short-selling is prohibited and agents face a constant marginal cost of
carrying positions. The resulting resale option guarantees that the equilibrium
price exceeds the price of the asset in a static buy-and-hold model where
speculation is ruled out. Our model features three main novelties. First,
increasing marginal costs entail that the price depends on the exogenous
supply. Second, in addition to the resale option, agents may also value an
option to delay, and this may cause the market to equilibrate \emph{below} the
static buy-and-hold price. Third, we introduce the possibility of
short-selling; then the resale option for agents with short positions partly
compensates the resale option for long agents. We characterize the unique
equilibrium of our model through a Hamilton-Jacobi-Bellman equation of a novel
form and use it to derive several comparative statics results.
</summary>
    <author>
      <name>Marcel Nutz</name>
    </author>
    <author>
      <name>José A. Scheinkman</name>
    </author>
    <link href="http://arxiv.org/abs/1705.05882v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.05882v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.MF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.MF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91B51" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.04870v1</id>
    <updated>2017-07-16T11:43:45Z</updated>
    <published>2017-07-16T11:43:45Z</published>
    <title>Environmental impact assessment for climate change policy with the
  simulation-based integrated assessment model E3ME-FTT-GENIE</title>
    <summary>  A high degree of consensus exists in the climate sciences over the role that
human interference with the atmosphere is playing in changing the climate.
Following the Paris Agreement, a similar consensus exists in the policy
community over the urgency of policy solutions to the climate problem. The
context for climate policy is thus moving from agenda setting, which has now
been established, to impact assessment, in which we identify policy pathways to
implement the Paris Agreement. Most integrated assessment models currently used
to address the economic and technical feasibility of avoiding climate change
are based purely on engineering with a normative systems optimisation
philosophy, and are thus unsuitable to assess the socio-economic impacts of
realistic baskets of climate policies. Here, we introduce a fully descriptive
simulation-based integrated assessment model designed specifically to assess
policies, formed by the combination of (1) a highly disaggregated
macro-econometric simulation of the global economy based on time series
regressions (E3ME), (2) a family of bottom-up evolutionary simulations of
technology diffusion based on cross-sectional discrete choice models (FTT), and
(3) a carbon cycle and atmosphere circulation model of intermediate complexity
(GENIE-1). We use this combined model to create a detailed global and sectoral
policy map and scenario that achieves the goals of the Paris Agreement with 80%
probability of not exceeding 2{\deg}C of global warming. We propose a blueprint
for a new role for integrated assessment models in this upcoming policy
assessment context.
</summary>
    <author>
      <name>J-F Mercure</name>
    </author>
    <author>
      <name>H. Pollitt</name>
    </author>
    <author>
      <name>N. R. Edwards</name>
    </author>
    <author>
      <name>P. B. Holden</name>
    </author>
    <author>
      <name>U. Chewpreecha</name>
    </author>
    <author>
      <name>P. Salas</name>
    </author>
    <author>
      <name>A. Lam</name>
    </author>
    <author>
      <name>F. Knobloch</name>
    </author>
    <author>
      <name>J. Vinuales</name>
    </author>
    <link href="http://arxiv.org/abs/1707.04870v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.04870v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.09203v1</id>
    <updated>2017-07-28T12:14:51Z</updated>
    <published>2017-07-28T12:14:51Z</published>
    <title>A hydrodynamic model for cooperating solidary countries</title>
    <summary>  The goal of international trade theories is to explain the exchange of goods
and services between different countries, aiming to benefit from it. Albeit the
idea is very simple and known since ancient history, smart policy and business
strategies need to be implemented by each subject, resulting in a complex as
well as not obvious interplay. In order to understand such a complexity,
different theories have been developed since the sixteenth century and today
new ideas still continue to enter the game. Among them, the so called classical
theories are country-based and range from Absolute and Comparative Advantage
theories by A. Smith and D. Ricardo to Factor Proportions theory by E.
Heckscher and B. Ohlin. In this work we build a simple hydrodynamic model, able
to reproduce the main conclusions of Comparative Advantage theory in its
simplest setup, i.e. a two-country world with country A and country B
exchanging two goods within a genuine exchange-based economy and a trade flow
ruled only by market forces. The model is further generalized by introducing
money in order to discuss its role in shaping trade patterns. Advantages and
drawbacks of the model are also discussed together with perspectives for its
improvement.
</summary>
    <author>
      <name>Roberto De Luca</name>
    </author>
    <author>
      <name>Marco Di Mauro</name>
    </author>
    <author>
      <name>Angelo Falzarano</name>
    </author>
    <author>
      <name>Adele Naddeo</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1140/epjb/e2017-80126-4</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1140/epjb/e2017-80126-4" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 2 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Eur. Phys. J. B (2017) 90, 134</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1707.09203v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.09203v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.06233v1</id>
    <updated>2017-08-21T14:09:31Z</updated>
    <published>2017-08-21T14:09:31Z</published>
    <title>Fake News in Social Networks</title>
    <summary>  We model the spread of news as a social learning game on a network. Agents
can either endorse or oppose a claim made in a piece of news, which itself may
be either true or false. Agents base their decision on a private signal and
their neighbors' past actions. Given these inputs, agents follow strategies
derived via multi-agent deep reinforcement learning and receive utility from
acting in accordance with the veracity of claims. Our framework yields
strategies with agent utility close to a theoretical, Bayes optimal benchmark,
while remaining flexible to model re-specification. Optimized strategies allow
agents to correctly identify most false claims, when all agents receive
unbiased private signals. However, an adversary's attempt to spread fake news
by targeting a subset of agents with a biased private signal can be successful.
Even more so when the adversary has information about agents' network position
or private signal. When agents are aware of the presence of an adversary they
re-optimize their strategies in the training stage and the adversary's attack
is less effective. Hence, exposing agents to the possibility of fake news can
be an effective way to curtail the spread of fake news in social networks. Our
results also highlight that information about the users' private beliefs and
their social network structure can be extremely valuable to adversaries and
should be well protected.
</summary>
    <author>
      <name>Christoph Aymanns</name>
    </author>
    <author>
      <name>Jakob Foerster</name>
    </author>
    <author>
      <name>Co-Pierre Georg</name>
    </author>
    <link href="http://arxiv.org/abs/1708.06233v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.06233v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.1; I.2.6; J.4; K.4.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.08673v1</id>
    <updated>2017-08-29T09:59:23Z</updated>
    <published>2017-08-29T09:59:23Z</published>
    <title>Changing the Direction of the Economic and Demographic Research</title>
    <summary>  A simple but useful method of reciprocal values is introduced, explained and
illustrated. This method simplifies the analysis of hyperbolic distributions,
which are causing serious problems in the demographic and economic research. It
allows for a unique identification of hyperbolic distributions and for
unravelling components of more complicated trajectories. This method is
illustrated by a few examples. They show that fundamental postulates of the
demographic and economic research are contradicted by data, even by precisely
the same data, which are used in this research. The generally accepted
postulates are based on the incorrect understanding of hyperbolic
distributions, which characterise the historical growth of population and the
historical economic growth. In particular, data used, but never analysed,
during the formulation of the Unified Growth Theory show that this theory is
based on fundamentally incorrect premises and thus is fundamentally defective.
Application of this simple method of analysis points to new directions in the
demographic and economic research. It suggests simpler interpretations of the
mechanism of growth. The concept or the evidence of the past primitive and
difficult living conditions, which might be perhaps described as some kind of
stagnation, is not questioned or disputed. It is only demonstrated that
trajectories of the past economic growth and of the growth of population were
not reflecting any form of stagnation and thus that they were not shaped by
these primitive and difficult living conditions. The concept or evidence of an
explosion in technology, medicine, education and in the improved living
conditions is not questioned or disputed. It is only demonstrated that this
possible explosion is not reflected in the trajectories of the economic growth
and of the growth of population.
</summary>
    <author>
      <name>Ron W. Nielsen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages,10 figures, 11729 words</arxiv:comment>
    <link href="http://arxiv.org/abs/1708.08673v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.08673v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1408.5618v1</id>
    <updated>2014-08-24T16:20:25Z</updated>
    <published>2014-08-24T16:20:25Z</published>
    <title>Symmetric thermal optimal path and time-dependent lead-lag relationship:
  Novel statistical tests and application to UK and US real-estate and monetary
  policies</title>
    <summary>  We present the symmetric thermal optimal path (TOPS) method to determine the
time-dependent lead-lag relationship between two stochastic time series. This
novel version of the previously introduced TOP method alleviates some
inconsistencies by imposing that the lead-lag relationship should be invariant
with respect to a time reversal of the time series after a change of sign. This
means that, if `$X$ comes before $Y$', this transforms into `$Y$ comes before
$X$' under a time reversal. We show that previously proposed bootstrap test
lacks power and leads too often to a lack of rejection of the null that there
is no lead-lag correlation when it is present. We introduce instead two novel
tests. The first free energy p-value $\rho$ criterion quantifies the
probability that a given lead-lag structure could be obtained from random time
series with similar characteristics except of the lead-lag information. The
second self-consistent test embodies the idea that, for the lead-lag path to be
significant, synchronising the two time series using the time varying lead-lag
path should lead to a statistically significant correlation. We perform
intensive synthetic tests to demonstrate their performance and limitations.
Finally, we apply the TOPS method with the two new tests to the time dependent
lead-lag structures of house price and monetary policy of the United Kingdom
(UK) and United States (US) from 1991 to 2011. The TOPS approach stresses the
importance of accounting for change of regimes, so that similar pieces of
information or policies may have drastically different impacts and
developments, conditional on the economic, financial and geopolitical
conditions. This study reinforces the view that the hypothesis of statistical
stationarity is highly questionable.
</summary>
    <author>
      <name>Hao Meng</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">ECUST</arxiv:affiliation>
    </author>
    <author>
      <name>Wei-Xing Zhou</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">ECUST</arxiv:affiliation>
    </author>
    <author>
      <name>Didier Sornette</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">ETH Zurich</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">23 Latex pages including 14 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1408.5618v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1408.5618v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1409.1451v1</id>
    <updated>2014-09-04T14:22:25Z</updated>
    <published>2014-09-04T14:22:25Z</published>
    <title>Opening discussion on banking sector risk exposures and vulnerabilities
  from virtual currencies: An operational risk perspective</title>
    <summary>  We develop the first basic Operational Risk perspective on key risk
management issues associated with the development of new forms of electronic
currency in the real economy. In particular, we focus on understanding the
development of new risks types and the evolution of current risk types as new
components of financial institutions arise to cater for an increasing demand
for electronic money, micro-payment systems, Virtual money and cryptographic
(Crypto) currencies. In particular, this paper proposes a framework of risk
identification and assessment applied to Virtual and Crypto currencies from a
banking regulation perspective. In doing so, it addresses the topical issues of
understanding important key Operational Risk vulnerabilities and exposure risk
drivers under the framework of the Basel II/III banking regulation,
specifically associated with Virtual and Crypto currencies. This is critical to
consider should such alternative currencies continue to grow in utilisation to
the point that they enter into the banking sector, through commercial banks and
financial institutions who are beginning to contemplate their recognition in
terms of deposits, transactions and exchangeability for fiat currencies.
  We highlight how some of the features of Virtual and Crypto currencies are
important drivers of Operational Risk, posing both management and regulatory
challenges that must start to be considered and addressed both by regulators,
central banks and security exchanges. In this paper we focus purely on the
Operational Risk perspective of banks operating in an environment where such
electronic Virtual currencies are available. Some aspects of this discussion
are directly relevant now, whilst others can be understood as discussions to
raise awareness of issues in Operational Risk that will arise as Virtual
currency start to interact more widely in the real economy.
</summary>
    <author>
      <name>Gareth W. Peters</name>
    </author>
    <author>
      <name>Ariane Chapelle</name>
    </author>
    <author>
      <name>Efstathios Panayi</name>
    </author>
    <link href="http://arxiv.org/abs/1409.1451v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1409.1451v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.RM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.00529v2</id>
    <updated>2015-07-14T18:39:20Z</updated>
    <published>2015-03-02T14:03:39Z</published>
    <title>Diversity waves in collapse-driven population dynamics</title>
    <summary>  Populations of species in ecosystems are often constrained by availability of
resources within their environment. In effect this means that a growth of one
population, needs to be balanced by comparable reduction in populations of
others. In neutral models of biodiversity all populations are assumed to change
incrementally due to stochastic births and deaths of individuals. Here we
propose and model another redistribution mechanism driven by abrupt and severe
collapses of the entire population of a single species freeing up resources for
the remaining ones. This mechanism may be relevant e.g. for communities of
bacteria, with strain-specific collapses caused e.g. by invading
bacteriophages, or for other ecosystems where infectious diseases play an
important role.
  The emergent dynamics of our system is cyclic "diversity waves" triggered by
collapses of globally dominating populations. The population diversity peaks at
the beginning of each wave and exponentially decreases afterwards. Species
abundances are characterized by a bimodal time-aggregated distribution with the
lower peak formed by populations of recently collapsed or newly introduced
species, while the upper peak - species that has not yet collapsed in the
current wave. In most waves both upper and lower peaks are composed of several
smaller peaks. This self-organized hierarchical peak structure has a long-term
memory transmitted across several waves. It gives rise to a scale-free tail of
the time-aggregated population distribution with a universal exponent of 1.7.
We show that diversity wave dynamics is robust with respect to variations in
the rules of our model such as diffusion between multiple environments,
species-specific growth and extinction rates, and bet-hedging strategies.
</summary>
    <author>
      <name>Sergei Maslov</name>
    </author>
    <author>
      <name>Kim Sneppen</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1371/journal.pcbi.1004440</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1371/journal.pcbi.1004440" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages (including SI), 6 figures + 7 supplementary figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1503.00529v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.00529v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.PE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.PE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.EC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-fin.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
