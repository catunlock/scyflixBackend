<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3Dall%3Acs.LG%26id_list%3D%26start%3D0%26max_results%3D500" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=all:cs.LG&amp;id_list=&amp;start=0&amp;max_results=500</title>
  <id>http://arxiv.org/api/yZG0EHUaqwO6RG20fp5sPj4PP0k</id>
  <updated>2017-10-08T00:00:00-04:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">15711</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">500</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/cs/0607136v1</id>
    <updated>2006-07-28T21:45:41Z</updated>
    <published>2006-07-28T21:45:41Z</published>
    <title>Competing with Markov prediction strategies</title>
    <summary>  Assuming that the loss function is convex in the prediction, we construct a
prediction strategy universal for the class of Markov prediction strategies,
not necessarily continuous. Allowing randomization, we remove the requirement
of convexity.
</summary>
    <author>
      <name>Vladimir Vovk</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0607136v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0607136v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0902.1258v1</id>
    <updated>2009-02-07T18:01:09Z</updated>
    <published>2009-02-07T18:01:09Z</published>
    <title>Extraction de concepts sous contraintes dans des données d'expression
  de gènes</title>
    <summary>  In this paper, we propose a technique to extract constrained formal concepts.
</summary>
    <author>
      <name>Baptiste Jeudy</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LAHC</arxiv:affiliation>
    </author>
    <author>
      <name>François Rioult</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">GREYC</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Conf\'erence sur l'apprentissage automatique, Nice : France (2005)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0902.1258v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0902.1258v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0903.2299v3</id>
    <updated>2013-07-08T15:17:20Z</updated>
    <published>2009-03-13T13:47:03Z</published>
    <title>Differential Contrastive Divergence</title>
    <summary>  This paper has been retracted.
</summary>
    <author>
      <name>David McAllester</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper was a rediscovery of known material</arxiv:comment>
    <link href="http://arxiv.org/abs/0903.2299v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0903.2299v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0907.0453v2</id>
    <updated>2009-07-20T08:59:45Z</updated>
    <published>2009-07-02T17:54:45Z</published>
    <title>Random DFAs are Efficiently PAC Learnable</title>
    <summary>  This paper has been withdrawn due to an error found by Dana Angluin and Lev
Reyzin.
</summary>
    <author>
      <name>Leonid Aryeh Kontorovich</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">withdrawn</arxiv:comment>
    <link href="http://arxiv.org/abs/0907.0453v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0907.0453v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1006.2899v2</id>
    <updated>2012-07-09T18:22:27Z</updated>
    <published>2010-06-15T06:55:03Z</published>
    <title>Approximated Structured Prediction for Learning Large Scale Graphical
  Models</title>
    <summary>  This manuscripts contains the proofs for "A Primal-Dual Message-Passing
Algorithm for Approximated Large Scale Structured Prediction".
</summary>
    <author>
      <name>Tamir Hazan</name>
    </author>
    <author>
      <name>Raquel Urtasun</name>
    </author>
    <link href="http://arxiv.org/abs/1006.2899v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1006.2899v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1107.4080v1</id>
    <updated>2011-07-20T19:34:00Z</updated>
    <published>2011-07-20T19:34:00Z</published>
    <title>On the Universality of Online Mirror Descent</title>
    <summary>  We show that for a general class of convex online learning problems, Mirror
Descent can always achieve a (nearly) optimal regret guarantee.
</summary>
    <author>
      <name>Nathan Srebro</name>
    </author>
    <author>
      <name>Karthik Sridharan</name>
    </author>
    <author>
      <name>Ambuj Tewari</name>
    </author>
    <link href="http://arxiv.org/abs/1107.4080v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1107.4080v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.7897v1</id>
    <updated>2014-05-30T15:50:28Z</updated>
    <published>2014-05-30T15:50:28Z</published>
    <title>Flip-Flop Sublinear Models for Graphs: Proof of Theorem 1</title>
    <summary>  We prove that there is no class-dual for almost all sublinear models on
graphs.
</summary>
    <author>
      <name>Brijnesh Jain</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Supplementary material for B. Jain. Flip-Flop Sublinear Models for
  Graphs, S+SSPR 2014</arxiv:comment>
    <link href="http://arxiv.org/abs/1405.7897v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.7897v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.5330v1</id>
    <updated>2014-10-17T00:50:42Z</updated>
    <published>2014-10-17T00:50:42Z</published>
    <title>An Overview of General Performance Metrics of Binary Classifier Systems</title>
    <summary>  This document provides a brief overview of different metrics and terminology
that is used to measure the performance of binary classification systems.
</summary>
    <author>
      <name>Sebastian Raschka</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1410.5330v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.5330v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.03326v2</id>
    <updated>2016-02-01T07:33:08Z</updated>
    <published>2015-08-13T19:49:08Z</published>
    <title>A Survey on Contextual Multi-armed Bandits</title>
    <summary>  In this survey we cover a few stochastic and adversarial contextual bandit
algorithms. We analyze each algorithm's assumption and regret bound.
</summary>
    <author>
      <name>Li Zhou</name>
    </author>
    <link href="http://arxiv.org/abs/1508.03326v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.03326v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0201009v1</id>
    <updated>2002-01-14T18:38:55Z</updated>
    <published>2002-01-14T18:38:55Z</published>
    <title>The performance of the batch learner algorithm</title>
    <summary>  We analyze completely the convergence speed of the \emph{batch learning
algorithm}, and compare its speed to that of the memoryless learning algorithm
and of learning with memory. We show that the batch learning algorithm is never
worse than the memoryless learning algorithm (at least asymptotically). Its
performance \emph{vis-a-vis} learning with full memory is less clearcut, and
depends on certain probabilistic assumptions.
</summary>
    <author>
      <name>Igor Rivin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Supercedes a part of cs.LG/0107033</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0201009v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0201009v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I2.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0411099v1</id>
    <updated>2004-11-30T08:36:59Z</updated>
    <published>2004-11-30T08:36:59Z</published>
    <title>A Note on the PAC Bayesian Theorem</title>
    <summary>  We prove general exponential moment inequalities for averages of [0,1]-valued
iid random variables and use them to tighten the PAC Bayesian Theorem. The
logarithmic dependence on the sample count in the enumerator of the PAC
Bayesian bound is halved.
</summary>
    <author>
      <name>Andreas Maurer</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0411099v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0411099v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.5.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0506057v2</id>
    <updated>2005-07-21T02:43:12Z</updated>
    <published>2005-06-14T04:00:38Z</published>
    <title>About one 3-parameter Model of Testing</title>
    <summary>  This article offers a 3-parameter model of testing, with 1) the difference
between the ability level of the examinee and item difficulty; 2) the examinee
discrimination and 3) the item discrimination as model parameters.
</summary>
    <author>
      <name>Kromer Victor</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages; in Russian; Paper with changed content</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0506057v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0506057v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.6; K.3.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0801.1988v1</id>
    <updated>2008-01-14T06:56:42Z</updated>
    <published>2008-01-14T06:56:42Z</published>
    <title>Online variants of the cross-entropy method</title>
    <summary>  The cross-entropy method is a simple but efficient method for global
optimization. In this paper we provide two online variants of the basic CEM,
together with a proof of convergence.
</summary>
    <author>
      <name>Istvan Szita</name>
    </author>
    <author>
      <name>Andras Lorincz</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/0801.1988v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0801.1988v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0801.4061v1</id>
    <updated>2008-01-26T07:32:48Z</updated>
    <published>2008-01-26T07:32:48Z</published>
    <title>The optimal assignment kernel is not positive definite</title>
    <summary>  We prove that the optimal assignment kernel, proposed recently as an attempt
to embed labeled graphs and more generally tuples of basic data to a Hilbert
space, is in fact not always positive definite.
</summary>
    <author>
      <name>Jean-Philippe Vert</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CB</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/0801.4061v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0801.4061v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0805.2362v1</id>
    <updated>2008-05-15T17:25:03Z</updated>
    <published>2008-05-15T17:25:03Z</published>
    <title>An optimization problem on the sphere</title>
    <summary>  We prove existence and uniqueness of the minimizer for the average geodesic
distance to the points of a geodesically convex set on the sphere. This implies
a corresponding existence and uniqueness result for an optimal algorithm for
halfspace learning, when data and target functions are drawn from the uniform
distribution.
</summary>
    <author>
      <name>Andreas Maurer</name>
    </author>
    <link href="http://arxiv.org/abs/0805.2362v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0805.2362v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0904.3664v1</id>
    <updated>2009-04-23T11:40:57Z</updated>
    <published>2009-04-23T11:40:57Z</published>
    <title>Introduction to Machine Learning: Class Notes 67577</title>
    <summary>  Introduction to Machine learning covering Statistical Inference (Bayes, EM,
ML/MaxEnt duality), algebraic and spectral methods (PCA, LDA, CCA, Clustering),
and PAC learning (the Formal model, VC dimension, Double Sampling theorem).
</summary>
    <author>
      <name>Amnon Shashua</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">109 pages, class notes of Machine Learning course given at the Hebrew
  University of Jerusalem</arxiv:comment>
    <link href="http://arxiv.org/abs/0904.3664v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0904.3664v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0908.4144v1</id>
    <updated>2009-08-28T07:09:19Z</updated>
    <published>2009-08-28T07:09:19Z</published>
    <title>ABC-LogitBoost for Multi-class Classification</title>
    <summary>  We develop abc-logitboost, based on the prior work on abc-boost and robust
logitboost. Our extensive experiments on a variety of datasets demonstrate the
considerable improvement of abc-logitboost over logitboost and abc-mart.
</summary>
    <author>
      <name>Ping Li</name>
    </author>
    <link href="http://arxiv.org/abs/0908.4144v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0908.4144v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.3095v1</id>
    <updated>2011-03-16T04:54:58Z</updated>
    <published>2011-03-16T04:54:58Z</published>
    <title>A note on active learning for smooth problems</title>
    <summary>  We show that the disagreement coefficient of certain smooth hypothesis
classes is $O(m)$, where $m$ is the dimension of the hypothesis space, thereby
answering a question posed in \cite{friedman09}.
</summary>
    <author>
      <name>Satyaki Mahalanabis</name>
    </author>
    <link href="http://arxiv.org/abs/1103.3095v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.3095v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68Q32: Computational learning theory" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1110.2392v2</id>
    <updated>2011-10-13T19:04:19Z</updated>
    <published>2011-10-11T14:53:35Z</published>
    <title>A Variant of Azuma's Inequality for Martingales with Subgaussian Tails</title>
    <summary>  We provide a variant of Azuma's concentration inequality for martingales, in
which the standard boundedness requirement is replaced by the milder
requirement of a subgaussian tail.
</summary>
    <author>
      <name>Ohad Shamir</name>
    </author>
    <link href="http://arxiv.org/abs/1110.2392v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1110.2392v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.4295v1</id>
    <updated>2012-05-19T04:25:04Z</updated>
    <published>2012-05-19T04:25:04Z</published>
    <title>Efficient Methods for Unsupervised Learning of Probabilistic Models</title>
    <summary>  In this thesis I develop a variety of techniques to train, evaluate, and
sample from intractable and high dimensional probabilistic models. Abstract
exceeds arXiv space limitations -- see PDF.
</summary>
    <author>
      <name>Jascha Sohl-Dickstein</name>
    </author>
    <link href="http://arxiv.org/abs/1205.4295v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.4295v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.3524v1</id>
    <updated>2013-01-15T22:51:40Z</updated>
    <published>2013-01-15T22:51:40Z</published>
    <title>How good is the Electricity benchmark for evaluating concept drift
  adaptation</title>
    <summary>  In this correspondence, we will point out a problem with testing adaptive
classifiers on autocorrelated data. In such a case random change alarms may
boost the accuracy figures. Hence, we cannot be sure if the adaptation is
working well.
</summary>
    <author>
      <name>Indre Zliobaite</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2 pages of content, 1 appendix, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1301.3524v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.3524v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.4917v1</id>
    <updated>2013-01-21T16:27:17Z</updated>
    <published>2013-01-21T16:27:17Z</published>
    <title>Dirichlet draws are sparse with high probability</title>
    <summary>  This note provides an elementary proof of the folklore fact that draws from a
Dirichlet distribution (with parameters less than 1) are typically sparse (most
coordinates are small).
</summary>
    <author>
      <name>Matus Telgarsky</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1301.4917v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.4917v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1302.0406v1</id>
    <updated>2013-02-02T17:20:47Z</updated>
    <published>2013-02-02T17:20:47Z</published>
    <title>Generalization Guarantees for a Binary Classification Framework for
  Two-Stage Multiple Kernel Learning</title>
    <summary>  We present generalization bounds for the TS-MKL framework for two stage
multiple kernel learning. We also present bounds for sparse kernel learning
formulations within the TS-MKL framework.
</summary>
    <author>
      <name>Purushottam Kar</name>
    </author>
    <link href="http://arxiv.org/abs/1302.0406v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1302.0406v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1303.2417v1</id>
    <updated>2013-03-11T03:29:35Z</updated>
    <published>2013-03-11T03:29:35Z</published>
    <title>Linear NDCG and Pair-wise Loss</title>
    <summary>  Linear NDCG is used for measuring the performance of the Web content quality
assessment in ECML/PKDD Discovery Challenge 2010. In this paper, we will prove
that the DCG error equals a new pair-wise loss.
</summary>
    <author>
      <name>Xiao-Bo Jin</name>
    </author>
    <author>
      <name>Guang-Gang Geng</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1303.2417v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1303.2417v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1305.0208v2</id>
    <updated>2013-07-23T02:13:57Z</updated>
    <published>2013-05-01T15:45:34Z</published>
    <title>Perceptron Mistake Bounds</title>
    <summary>  We present a brief survey of existing mistake bounds and introduce novel
bounds for the Perceptron or the kernel Perceptron algorithm. Our novel bounds
generalize beyond standard margin-loss type bounds, allow for any convex and
Lipschitz loss function, and admit a very simple proof.
</summary>
    <author>
      <name>Mehryar Mohri</name>
    </author>
    <author>
      <name>Afshin Rostamizadeh</name>
    </author>
    <link href="http://arxiv.org/abs/1305.0208v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1305.0208v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1406.5600v1</id>
    <updated>2014-06-21T11:47:21Z</updated>
    <published>2014-06-21T11:47:21Z</published>
    <title>From conformal to probabilistic prediction</title>
    <summary>  This paper proposes a new method of probabilistic prediction, which is based
on conformal prediction. The method is applied to the standard USPS data set
and gives encouraging results.
</summary>
    <author>
      <name>Vladimir Vovk</name>
    </author>
    <author>
      <name>Ivan Petej</name>
    </author>
    <author>
      <name>Valentina Fedorova</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 2 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1406.5600v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1406.5600v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T10" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1406.7429v1</id>
    <updated>2014-06-28T18:59:44Z</updated>
    <published>2014-06-28T18:59:44Z</published>
    <title>Comparison of SVM Optimization Techniques in the Primal</title>
    <summary>  This paper examines the efficacy of different optimization techniques in a
primal formulation of a support vector machine (SVM). Three main techniques are
compared. The dataset used to compare all three techniques was the Sentiment
Analysis on Movie Reviews dataset, from kaggle.com.
</summary>
    <author>
      <name>Jonathan Katzman</name>
    </author>
    <author>
      <name>Diane Duros</name>
    </author>
    <link href="http://arxiv.org/abs/1406.7429v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1406.7429v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1408.6618v1</id>
    <updated>2014-08-28T03:29:06Z</updated>
    <published>2014-08-28T03:29:06Z</published>
    <title>Falsifiable implies Learnable</title>
    <summary>  The paper demonstrates that falsifiability is fundamental to learning. We
prove the following theorem for statistical learning and sequential prediction:
If a theory is falsifiable then it is learnable -- i.e. admits a strategy that
predicts optimally. An analogous result is shown for universal induction.
</summary>
    <author>
      <name>David Balduzzi</name>
    </author>
    <link href="http://arxiv.org/abs/1408.6618v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1408.6618v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.01632v1</id>
    <updated>2015-02-05T16:37:31Z</updated>
    <published>2015-02-05T16:37:31Z</published>
    <title>A Simple Expression for Mill's Ratio of the Student's $t$-Distribution</title>
    <summary>  I show a simple expression of the Mill's ratio of the Student's
t-Distribution. I use it to prove Conjecture 1 in P. Auer, N. Cesa-Bianchi, and
P. Fischer. Finite-time analysis of the multiarmed bandit problem. Mach.
Learn., 47(2-3):235--256, May 2002.
</summary>
    <author>
      <name>Francesco Orabona</name>
    </author>
    <link href="http://arxiv.org/abs/1502.01632v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.01632v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.02704v1</id>
    <updated>2015-02-09T22:05:25Z</updated>
    <published>2015-02-09T22:05:25Z</published>
    <title>Learning Reductions that Really Work</title>
    <summary>  We provide a summary of the mathematical and computational techniques that
have enabled learning reductions to effectively address a wide class of
problems, and show that this approach to solving machine learning problems can
be broadly useful.
</summary>
    <author>
      <name>Alina Beygelzimer</name>
    </author>
    <author>
      <name>Hal Daumé III</name>
    </author>
    <author>
      <name>John Langford</name>
    </author>
    <author>
      <name>Paul Mineiro</name>
    </author>
    <link href="http://arxiv.org/abs/1502.02704v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.02704v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.06177v1</id>
    <updated>2015-02-22T04:42:01Z</updated>
    <published>2015-02-22T04:42:01Z</published>
    <title>SDCA without Duality</title>
    <summary>  Stochastic Dual Coordinate Ascent is a popular method for solving regularized
loss minimization for the case of convex losses. In this paper we show how a
variant of SDCA can be applied for non-convex losses. We prove linear
convergence rate even if individual loss functions are non-convex as long as
the expected loss is convex.
</summary>
    <author>
      <name>Shai Shalev-Shwartz</name>
    </author>
    <link href="http://arxiv.org/abs/1502.06177v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.06177v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.00036v2</id>
    <updated>2015-04-14T22:55:08Z</updated>
    <published>2015-02-27T23:50:22Z</published>
    <title>Norm-Based Capacity Control in Neural Networks</title>
    <summary>  We investigate the capacity, convexity and characterization of a general
family of norm-constrained feed-forward networks.
</summary>
    <author>
      <name>Behnam Neyshabur</name>
    </author>
    <author>
      <name>Ryota Tomioka</name>
    </author>
    <author>
      <name>Nathan Srebro</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">29 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1503.00036v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.00036v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.00600v1</id>
    <updated>2015-03-02T16:35:02Z</updated>
    <published>2015-03-02T16:35:02Z</published>
    <title>An $\mathcal{O}(n\log n)$ projection operator for weighted $\ell_1$-norm
  regularization with sum constraint</title>
    <summary>  We provide a simple and efficient algorithm for the projection operator for
weighted $\ell_1$-norm regularization subject to a sum constraint, together
with an elementary proof. The implementation of the proposed algorithm can be
downloaded from the author's homepage.
</summary>
    <author>
      <name>Weiran Wang</name>
    </author>
    <link href="http://arxiv.org/abs/1503.00600v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.00600v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.01002v1</id>
    <updated>2015-03-03T16:40:17Z</updated>
    <published>2015-03-03T16:40:17Z</published>
    <title>Projection onto the capped simplex</title>
    <summary>  We provide a simple and efficient algorithm for computing the Euclidean
projection of a point onto the capped simplex---a simplex with an additional
uniform bound on each coordinate---together with an elementary proof. Both the
MATLAB and C++ implementations of the proposed algorithm can be downloaded at
https://eng.ucmerced.edu/people/wwang5.
</summary>
    <author>
      <name>Weiran Wang</name>
    </author>
    <author>
      <name>Canyi Lu</name>
    </author>
    <link href="http://arxiv.org/abs/1503.01002v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.01002v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.06902v1</id>
    <updated>2015-03-24T03:26:28Z</updated>
    <published>2015-03-24T03:26:28Z</published>
    <title>A Note on Information-Directed Sampling and Thompson Sampling</title>
    <summary>  This note introduce three Bayesian style Multi-armed bandit algorithms:
Information-directed sampling, Thompson Sampling and Generalized Thompson
Sampling. The goal is to give an intuitive explanation for these three
algorithms and their regret bounds, and provide some derivations that are
omitted in the original papers.
</summary>
    <author>
      <name>Li Zhou</name>
    </author>
    <link href="http://arxiv.org/abs/1503.06902v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.06902v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.07000v1</id>
    <updated>2015-04-27T09:41:36Z</updated>
    <published>2015-04-27T09:41:36Z</published>
    <title>Accelerated nonlinear discriminant analysis</title>
    <summary>  In this paper, a novel nonlinear discriminant analysis is proposed.
Experimental results show that the new method provides state of the art
performance when combined with LSVM in terms of training time and accuracy.
</summary>
    <author>
      <name>Nikolaos Gkalelis</name>
    </author>
    <author>
      <name>Vasileios Mezaris</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, report</arxiv:comment>
    <link href="http://arxiv.org/abs/1504.07000v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.07000v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.01703v1</id>
    <updated>2016-05-05T19:34:08Z</updated>
    <published>2016-05-05T19:34:08Z</published>
    <title>A note on adjusting $R^2$ for using with cross-validation</title>
    <summary>  We show how to adjust the coefficient of determination ($R^2$) when used for
measuring predictive accuracy via leave-one-out cross-validation.
</summary>
    <author>
      <name>Indre Zliobaite</name>
    </author>
    <author>
      <name>Nikolaj Tatti</name>
    </author>
    <link href="http://arxiv.org/abs/1605.01703v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.01703v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.03559v1</id>
    <updated>2016-07-13T01:22:04Z</updated>
    <published>2016-07-13T01:22:04Z</published>
    <title>Fast Sampling for Strongly Rayleigh Measures with Application to
  Determinantal Point Processes</title>
    <summary>  In this note we consider sampling from (non-homogeneous) strongly Rayleigh
probability measures. As an important corollary, we obtain a fast mixing Markov
Chain sampler for Determinantal Point Processes.
</summary>
    <author>
      <name>Chengtao Li</name>
    </author>
    <author>
      <name>Stefanie Jegelka</name>
    </author>
    <author>
      <name>Suvrit Sra</name>
    </author>
    <link href="http://arxiv.org/abs/1607.03559v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.03559v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.04077v3</id>
    <updated>2017-01-27T09:11:59Z</updated>
    <published>2017-01-15T17:06:08Z</published>
    <title>Breeding electric zebras in the fields of Medicine</title>
    <summary>  A few notes on the use of machine learning in medicine and the related
unintended consequences.
</summary>
    <author>
      <name>Federico Cabitza</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Work-in-progress</arxiv:comment>
    <link href="http://arxiv.org/abs/1701.04077v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.04077v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.04849v1</id>
    <updated>2017-07-16T09:15:08Z</updated>
    <published>2017-07-16T09:15:08Z</published>
    <title>Minimax deviation strategies for machine learning and recognition with
  short learning samples</title>
    <summary>  The article is devoted to the problem of small learning samples in machine
learning. The flaws of maximum likelihood learning and minimax learning are
looked into and the concept of minimax deviation learning is introduced that is
free of those flaws.
</summary>
    <author>
      <name>Michail Schlesinger</name>
    </author>
    <author>
      <name>Evgeniy Vodolazskiy</name>
    </author>
    <link href="http://arxiv.org/abs/1707.04849v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.04849v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.05721v3</id>
    <updated>2017-08-03T14:32:30Z</updated>
    <published>2017-07-18T16:04:08Z</published>
    <title>Submodular Mini-Batch Training in Generative Moment Matching Networks</title>
    <summary>  This article was withdrawn because (1) it was uploaded without the
co-authors' knowledge or consent, and (2) there are allegations of plagiarism.
</summary>
    <author>
      <name>Jun Qi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The paper has been withdrawn. See the abstract for the reason</arxiv:comment>
    <link href="http://arxiv.org/abs/1707.05721v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.05721v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.01902v2</id>
    <updated>2017-08-30T12:06:15Z</updated>
    <published>2017-08-06T15:28:37Z</published>
    <title>Universally consistent predictive distributions</title>
    <summary>  This paper describes simple universally consistent procedures of probability
forecasting that satisfy a natural property of small-sample validity, under the
assumption that the observations are produced independently in the IID fashion.
</summary>
    <author>
      <name>Vladimir Vovk</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">26 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1708.01902v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.01902v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68Q32, 62G20 (Primary) 68M20, 68T05 (Secondary)" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.08177v1</id>
    <updated>2017-08-28T03:52:40Z</updated>
    <published>2017-08-28T03:52:40Z</published>
    <title>Hyperprior on symmetric Dirichlet distribution</title>
    <summary>  In this article we introduce how to put vague hyperprior on Dirichlet
distribution, and we update the parameter of it by adaptive rejection sampling
(ARS). Finally we analyze this hyperprior in an over-fitted mixture model by
some synthetic experiments.
</summary>
    <author>
      <name>Jun Lu</name>
    </author>
    <link href="http://arxiv.org/abs/1708.08177v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.08177v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9902026v1</id>
    <updated>1999-02-15T01:52:45Z</updated>
    <published>1999-02-15T01:52:45Z</published>
    <title>Probabilistic Inductive Inference:a Survey</title>
    <summary>  Inductive inference is a recursion-theoretic theory of learning, first
developed by E. M. Gold (1967). This paper surveys developments in
probabilistic inductive inference. We mainly focus on finite inference of
recursive functions, since this simple paradigm has produced the most
interesting (and most complex) results.
</summary>
    <author>
      <name>Andris Ambainis</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, to appear in Theoretical Computer Science</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/9902026v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9902026v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.1.1., F.4.1., I.2.3., I.2.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0312004v1</id>
    <updated>2003-11-30T20:41:18Z</updated>
    <published>2003-11-30T20:41:18Z</published>
    <title>Improving spam filtering by combining Naive Bayes with simple k-nearest
  neighbor searches</title>
    <summary>  Using naive Bayes for email classification has become very popular within the
last few months. They are quite easy to implement and very efficient. In this
paper we want to present empirical results of email classification using a
combination of naive Bayes and k-nearest neighbor searches. Using this
technique we show that the accuracy of a Bayes filter can be improved slightly
for a high number of features and significantly for a small number of features.
</summary>
    <author>
      <name>Daniel Etzold</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0312004v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0312004v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0401005v1</id>
    <updated>2004-01-08T07:50:51Z</updated>
    <published>2004-01-08T07:50:51Z</published>
    <title>About Unitary Rating Score Constructing</title>
    <summary>  It is offered to pool test points of different subjects and different aspects
of the same subject together in order to get the unitary rating score, by the
way of nonlinear transformation of indicator points in accordance with Zipf's
distribution. It is proposed to use the well-studied distribution of
Intellectuality Quotient IQ as the reference distribution for latent variable
"progress in studies".
</summary>
    <author>
      <name>Kromer Victor</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0401005v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0401005v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="1.2.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0506085v1</id>
    <updated>2005-06-22T21:21:13Z</updated>
    <published>2005-06-22T21:21:13Z</published>
    <title>On the Job Training</title>
    <summary>  We propose a new framework for building and evaluating machine learning
algorithms. We argue that many real-world problems require an agent which must
quickly learn to respond to demands, yet can continue to perform and respond to
new training throughout its useful life. We give a framework for how such
agents can be built, describe several metrics for evaluating them, and show
that subtle changes in system construction can significantly affect agent
performance.
</summary>
    <author>
      <name>Jason E. Holt</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">BYU</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, submitted to NIPS 2005</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0506085v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0506085v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="K.3.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0508073v1</id>
    <updated>2005-08-16T16:27:25Z</updated>
    <published>2005-08-16T16:27:25Z</published>
    <title>Universal Learning of Repeated Matrix Games</title>
    <summary>  We study and compare the learning dynamics of two universal learning
algorithms, one based on Bayesian learning and the other on prediction with
expert advice. Both approaches have strong asymptotic performance guarantees.
When confronted with the task of finding good long-term strategies in repeated
2x2 matrix games, they behave quite differently.
</summary>
    <author>
      <name>Jan Poland</name>
    </author>
    <author>
      <name>Marcus Hutter</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 LaTeX pages, 8 eps figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. 15th Annual Machine Learning Conf. of Belgium and The
  Netherlands (Benelearn 2006) pages 7-14</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0508073v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0508073v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0601087v1</id>
    <updated>2006-01-20T05:40:44Z</updated>
    <published>2006-01-20T05:40:44Z</published>
    <title>Processing of Test Matrices with Guessing Correction</title>
    <summary>  It is suggested to insert into test matrix 1s for correct responses, 0s for
response refusals, and negative corrective elements for incorrect responses.
With the classical test theory approach test scores of examinees and items are
calculated traditionally as sums of matrix elements, organized in rows and
columns. Correlation coefficients are estimated using correction coefficients.
In item response theory approach examinee and item logits are estimated using
maximum likelihood method and probabilities of all matrix elements.
</summary>
    <author>
      <name>Kromer Victor</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, in Russian</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0601087v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0601087v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.6; K.3.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0606093v1</id>
    <updated>2006-06-22T04:31:51Z</updated>
    <published>2006-06-22T04:31:51Z</published>
    <title>Predictions as statements and decisions</title>
    <summary>  Prediction is a complex notion, and different predictors (such as people,
computer programs, and probabilistic theories) can pursue very different goals.
In this paper I will review some popular kinds of prediction and argue that the
theory of competitive on-line learning can benefit from the kinds of prediction
that are now foreign to it.
</summary>
    <author>
      <name>Vladimir Vovk</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">48 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0606093v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0606093v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0606100v4</id>
    <updated>2011-10-11T10:21:45Z</updated>
    <published>2006-06-23T10:19:40Z</published>
    <title>The generating function of the polytope of transport matrices $U(r,c)$
  as a positive semidefinite kernel of the marginals $r$ and $c$</title>
    <summary>  This paper has been withdrawn by the author due to a crucial error in the
proof of Lemma 5.
</summary>
    <author>
      <name>Marco Cuturi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper has been withdrawn</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0606100v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0606100v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0607067v1</id>
    <updated>2006-07-13T15:52:04Z</updated>
    <published>2006-07-13T15:52:04Z</published>
    <title>Competing with stationary prediction strategies</title>
    <summary>  In this paper we introduce the class of stationary prediction strategies and
construct a prediction algorithm that asymptotically performs as well as the
best continuous stationary strategy. We make mild compactness assumptions but
no stochastic assumptions about the environment. In particular, no assumption
of stationarity is made about the environment, and the stationarity of the
considered strategies only means that they do not depend explicitly on time; we
argue that it is natural to consider only stationary strategies even for highly
non-stationary environments.
</summary>
    <author>
      <name>Vladimir Vovk</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0607067v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0607067v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0611150v3</id>
    <updated>2006-12-05T15:04:52Z</updated>
    <published>2006-11-29T13:59:31Z</published>
    <title>A Novel Bayesian Classifier using Copula Functions</title>
    <summary>  A useful method for representing Bayesian classifiers is through
\emph{discriminant functions}. Here, using copula functions, we propose a new
model for discriminants. This model provides a rich and generalized class of
decision boundaries. These decision boundaries significantly boost the
classification accuracy especially for high dimensional feature spaces. We
strengthen our analysis through simulation results.
</summary>
    <author>
      <name>Saket Sathe</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0611150v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0611150v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0704.1409v3</id>
    <updated>2012-06-08T14:08:19Z</updated>
    <published>2007-04-11T13:17:01Z</published>
    <title>Preconditioned Temporal Difference Learning</title>
    <summary>  This paper has been withdrawn by the author. This draft is withdrawn for its
poor quality in english, unfortunately produced by the author when he was just
starting his science route. Look at the ICML version instead:
http://icml2008.cs.helsinki.fi/papers/111.pdf
</summary>
    <author>
      <name>Yao HengShuai</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper has been withdrawn by the author. Look at the ICML version
  instead: http://icml2008.cs.helsinki.fi/papers/111.pdf</arxiv:comment>
    <link href="http://arxiv.org/abs/0704.1409v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0704.1409v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0708.1503v1</id>
    <updated>2007-08-10T19:19:54Z</updated>
    <published>2007-08-10T19:19:54Z</published>
    <title>Defensive forecasting for optimal prediction with expert advice</title>
    <summary>  The method of defensive forecasting is applied to the problem of prediction
with expert advice for binary outcomes. It turns out that defensive forecasting
is not only competitive with the Aggregating Algorithm but also handles the
case of "second-guessing" experts, whose advice depends on the learner's
prediction; this paper assumes that the dependence on the learner's prediction
is continuous.
</summary>
    <author>
      <name>Vladimir Vovk</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/0708.1503v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0708.1503v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0710.2848v1</id>
    <updated>2007-10-15T15:38:33Z</updated>
    <published>2007-10-15T15:38:33Z</published>
    <title>Consistency of trace norm minimization</title>
    <summary>  Regularization by the sum of singular values, also referred to as the trace
norm, is a popular technique for estimating low rank rectangular matrices. In
this paper, we extend some of the consistency results of the Lasso to provide
necessary and sufficient conditions for rank consistency of trace norm
minimization with the square loss. We also provide an adaptive version that is
rank consistent even when the necessary condition for the non adaptive version
is not fulfilled.
</summary>
    <author>
      <name>Francis Bach</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">WILLOW Project - Inria/Ens</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/0710.2848v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0710.2848v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0712.0840v1</id>
    <updated>2007-12-05T22:25:03Z</updated>
    <published>2007-12-05T22:25:03Z</published>
    <title>A Universal Kernel for Learning Regular Languages</title>
    <summary>  We give a universal kernel that renders all the regular languages linearly
separable. We are not able to compute this kernel efficiently and conjecture
that it is intractable, but we do have an efficient $\eps$-approximation.
</summary>
    <author>
      <name> Leonid</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Aryeh</arxiv:affiliation>
    </author>
    <author>
      <name> Kontorovich</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">The 5th International Workshop on Mining and Learning with Graphs,
  2007</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0712.0840v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0712.0840v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.1.1; D.3.1; F.4.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0811.1250v1</id>
    <updated>2008-11-08T23:23:08Z</updated>
    <published>2008-11-08T23:23:08Z</published>
    <title>Adaptive Base Class Boost for Multi-class Classification</title>
    <summary>  We develop the concept of ABC-Boost (Adaptive Base Class Boost) for
multi-class classification and present ABC-MART, a concrete implementation of
ABC-Boost. The original MART (Multiple Additive Regression Trees) algorithm has
been very successful in large-scale applications. For binary classification,
ABC-MART recovers MART. For multi-class classification, ABC-MART considerably
improves MART, as evaluated on several public data sets.
</summary>
    <author>
      <name>Ping Li</name>
    </author>
    <link href="http://arxiv.org/abs/0811.1250v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0811.1250v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0812.3145v2</id>
    <updated>2008-12-16T21:05:28Z</updated>
    <published>2008-12-16T20:41:06Z</published>
    <title>Binary Classification Based on Potentials</title>
    <summary>  We introduce a simple and computationally trivial method for binary
classification based on the evaluation of potential functions. We demonstrate
that despite the conceptual and computational simplicity of the method its
performance can match or exceed that of standard Support Vector Machine
methods.
</summary>
    <author>
      <name>Erik Boczko</name>
    </author>
    <author>
      <name>Andrew DiLullo</name>
    </author>
    <author>
      <name>Todd Young</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 2 figures. Presented at the Ohio Collaborative Conference on
  Bioinformatics (OCCBIO) June 2006</arxiv:comment>
    <link href="http://arxiv.org/abs/0812.3145v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0812.3145v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0903.2972v3</id>
    <updated>2009-05-20T18:44:07Z</updated>
    <published>2009-03-17T14:24:13Z</published>
    <title>Optimistic Simulated Exploration as an Incentive for Real Exploration</title>
    <summary>  Many reinforcement learning exploration techniques are overly optimistic and
try to explore every state. Such exploration is impossible in environments with
the unlimited number of states. I propose to use simulated exploration with an
optimistic model to discover promising paths for real exploration. This reduces
the needs for the real exploration.
</summary>
    <author>
      <name>Ivo Danihelka</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">accepted, noted that the initial path was 217 steps long</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">POSTER 2009</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0903.2972v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0903.2972v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0904.1227v1</id>
    <updated>2009-04-07T21:15:42Z</updated>
    <published>2009-04-07T21:15:42Z</published>
    <title>Learning convex bodies is hard</title>
    <summary>  We show that learning a convex body in $\RR^d$, given random samples from the
body, requires $2^{\Omega(\sqrt{d/\eps})}$ samples. By learning a convex body
we mean finding a set having at most $\eps$ relative symmetric difference with
the input body. To prove the lower bound we construct a hard to learn family of
convex bodies. Our construction of this family is very simple and based on
error correcting codes.
</summary>
    <author>
      <name>Navin Goyal</name>
    </author>
    <author>
      <name>Luis Rademacher</name>
    </author>
    <link href="http://arxiv.org/abs/0904.1227v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0904.1227v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0906.4032v1</id>
    <updated>2009-06-22T15:25:23Z</updated>
    <published>2009-06-22T15:25:23Z</published>
    <title>Bayesian two-sample tests</title>
    <summary>  In this paper, we present two classes of Bayesian approaches to the
two-sample problem. Our first class of methods extends the Bayesian t-test to
include all parametric models in the exponential family and their conjugate
priors. Our second class of methods uses Dirichlet process mixtures (DPM) of
such conjugate-exponential distributions as flexible nonparametric priors over
the unknown distributions.
</summary>
    <author>
      <name>Karsten M. Borgwardt</name>
    </author>
    <author>
      <name>Zoubin Ghahramani</name>
    </author>
    <link href="http://arxiv.org/abs/0906.4032v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0906.4032v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0907.0783v1</id>
    <updated>2009-07-04T18:35:52Z</updated>
    <published>2009-07-04T18:35:52Z</published>
    <title>Bayesian Multitask Learning with Latent Hierarchies</title>
    <summary>  We learn multiple hypotheses for related tasks under a latent hierarchical
relationship between tasks. We exploit the intuition that for domain
adaptation, we wish to share classifier structure, but for multitask learning,
we wish to share covariance structure. Our hierarchical model is seen to
subsume several previously proposed multitask learning models and performs well
on three distinct real-world data sets.
</summary>
    <author>
      <name>Hal Daumé III</name>
    </author>
    <link href="http://arxiv.org/abs/0907.0783v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0907.0783v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0907.0784v1</id>
    <updated>2009-07-04T18:42:01Z</updated>
    <published>2009-07-04T18:42:01Z</published>
    <title>Cross-Task Knowledge-Constrained Self Training</title>
    <summary>  We present an algorithmic framework for learning multiple related tasks. Our
framework exploits a form of prior knowledge that relates the output spaces of
these tasks. We present PAC learning results that analyze the conditions under
which such learning is possible. We present results on learning a shallow
parser and named-entity recognition system that exploits our framework, showing
consistent improvements over baseline methods.
</summary>
    <author>
      <name>Hal Daumé III</name>
    </author>
    <link href="http://arxiv.org/abs/0907.0784v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0907.0784v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0907.1413v3</id>
    <updated>2011-06-21T17:05:53Z</updated>
    <published>2009-07-09T06:51:54Z</published>
    <title>Privacy constraints in regularized convex optimization</title>
    <summary>  This paper is withdrawn due to some errors, which are corrected in
arXiv:0912.0071v4 [cs.LG].
</summary>
    <author>
      <name>Kamalika Chaudhuri</name>
    </author>
    <author>
      <name>Anand D. Sarwate</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper has been withdrawn by the authors due to some errors.
  Corrections have been included in arXiv:0912.0071v4</arxiv:comment>
    <link href="http://arxiv.org/abs/0907.1413v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0907.1413v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0908.0570v1</id>
    <updated>2009-08-05T01:10:09Z</updated>
    <published>2009-08-05T01:10:09Z</published>
    <title>The Infinite Hierarchical Factor Regression Model</title>
    <summary>  We propose a nonparametric Bayesian factor regression model that accounts for
uncertainty in the number of factors, and the relationship between factors. To
accomplish this, we propose a sparse variant of the Indian Buffet Process and
couple this with a hierarchical model over factors, based on Kingman's
coalescent. We apply this model to two problems (factor analysis and factor
regression) in gene-expression data analysis.
</summary>
    <author>
      <name>Piyush Rai</name>
    </author>
    <author>
      <name>Hal Daumé III</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">NIPS 2008</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0908.0570v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0908.0570v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0908.1769v1</id>
    <updated>2009-08-12T18:27:54Z</updated>
    <published>2009-08-12T18:27:54Z</published>
    <title>Approximating the Permanent with Belief Propagation</title>
    <summary>  This work describes a method of approximating matrix permanents efficiently
using belief propagation. We formulate a probability distribution whose
partition function is exactly the permanent, then use Bethe free energy to
approximate this partition function. After deriving some speedups to standard
belief propagation, the resulting algorithm requires $(n^2)$ time per
iteration. Finally, we demonstrate the advantages of using this approximation.
</summary>
    <author>
      <name>Bert Huang</name>
    </author>
    <author>
      <name>Tony Jebara</name>
    </author>
    <link href="http://arxiv.org/abs/0908.1769v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0908.1769v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0909.4603v1</id>
    <updated>2009-09-25T05:23:33Z</updated>
    <published>2009-09-25T05:23:33Z</published>
    <title>Scalable Inference for Latent Dirichlet Allocation</title>
    <summary>  We investigate the problem of learning a topic model - the well-known Latent
Dirichlet Allocation - in a distributed manner, using a cluster of C processors
and dividing the corpus to be learned equally among them. We propose a simple
approximated method that can be tuned, trading speed for accuracy according to
the task at hand. Our approach is asynchronous, and therefore suitable for
clusters of heterogenous machines.
</summary>
    <author>
      <name>James Petterson</name>
    </author>
    <author>
      <name>Tiberio Caetano</name>
    </author>
    <link href="http://arxiv.org/abs/0909.4603v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0909.4603v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0910.4683v2</id>
    <updated>2010-05-10T23:01:30Z</updated>
    <published>2009-10-24T22:40:40Z</published>
    <title>Competing with Gaussian linear experts</title>
    <summary>  We study the problem of online regression. We prove a theoretical bound on
the square loss of Ridge Regression. We do not make any assumptions about input
vectors or outcomes. We also show that Bayesian Ridge Regression can be thought
of as an online algorithm competing with all the Gaussian linear experts.
</summary>
    <author>
      <name>Fedor Zhdanov</name>
    </author>
    <author>
      <name>Vladimir Vovk</name>
    </author>
    <link href="http://arxiv.org/abs/0910.4683v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0910.4683v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1001.0700v1</id>
    <updated>2010-01-05T13:06:21Z</updated>
    <published>2010-01-05T13:06:21Z</published>
    <title>Vandalism Detection in Wikipedia: a Bag-of-Words Classifier Approach</title>
    <summary>  A bag-of-words based probabilistic classifier is trained using regularized
logistic regression to detect vandalism in the English Wikipedia. Isotonic
regression is used to calibrate the class membership probabilities. Learning
curve, reliability, ROC, and cost analysis are performed.
</summary>
    <author>
      <name>Amit Belani</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1001.0700v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1001.0700v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.6; I.2.7; G.3; K.4.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1002.2780v1</id>
    <updated>2010-02-14T16:37:04Z</updated>
    <published>2010-02-14T16:37:04Z</published>
    <title>Collaborative Filtering in a Non-Uniform World: Learning with the
  Weighted Trace Norm</title>
    <summary>  We show that matrix completion with trace-norm regularization can be
significantly hurt when entries of the matrix are sampled non-uniformly. We
introduce a weighted version of the trace-norm regularizer that works well also
with non-uniform sampling. Our experimental results demonstrate that the
weighted trace-norm regularization indeed yields significant gains on the
(highly non-uniformly sampled) Netflix dataset.
</summary>
    <author>
      <name>Ruslan Salakhutdinov</name>
    </author>
    <author>
      <name>Nathan Srebro</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1002.2780v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1002.2780v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1003.0696v1</id>
    <updated>2010-03-02T22:27:31Z</updated>
    <published>2010-03-02T22:27:31Z</published>
    <title>Exponential Family Hybrid Semi-Supervised Learning</title>
    <summary>  We present an approach to semi-supervised learning based on an exponential
family characterization. Our approach generalizes previous work on coupled
priors for hybrid generative/discriminative models. Our model is more flexible
and natural than previous approaches. Experimental results on several data sets
show that our approach also performs better in practice.
</summary>
    <author>
      <name>Arvind Agarwal</name>
    </author>
    <author>
      <name>Hal Daume III</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 3 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Twenty-First International Joint Conference on Artificial
  Intelligence 2009, pg 974-979</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1003.0696v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1003.0696v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1005.1918v2</id>
    <updated>2010-06-04T19:13:37Z</updated>
    <published>2010-05-11T19:27:35Z</published>
    <title>Prediction with Expert Advice under Discounted Loss</title>
    <summary>  We study prediction with expert advice in the setting where the losses are
accumulated with some discounting---the impact of old losses may gradually
vanish. We generalize the Aggregating Algorithm and the Aggregating Algorithm
for Regression to this case, propose a suitable new variant of exponential
weights algorithm, and prove respective loss bounds.
</summary>
    <author>
      <name>Alexey Chernov</name>
    </author>
    <author>
      <name>Fedor Zhdanov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">26 pages; expanded (2 remarks -&gt; theorems), some misprints corrected</arxiv:comment>
    <link href="http://arxiv.org/abs/1005.1918v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1005.1918v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1005.2243v1</id>
    <updated>2010-05-13T01:59:57Z</updated>
    <published>2010-05-13T01:59:57Z</published>
    <title>Robustness and Generalization</title>
    <summary>  We derive generalization bounds for learning algorithms based on their
robustness: the property that if a testing sample is "similar" to a training
sample, then the testing error is close to the training error. This provides a
novel approach, different from the complexity or stability arguments, to study
generalization of learning algorithms. We further show that a weak notion of
robustness is both sufficient and necessary for generalizability, which implies
that robustness is a fundamental property for learning algorithms to work.
</summary>
    <author>
      <name>Huan Xu</name>
    </author>
    <author>
      <name>Shie Mannor</name>
    </author>
    <link href="http://arxiv.org/abs/1005.2243v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1005.2243v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1005.2364v2</id>
    <updated>2010-05-14T11:28:03Z</updated>
    <published>2010-05-13T15:59:01Z</published>
    <title>A Short Introduction to Model Selection, Kolmogorov Complexity and
  Minimum Description Length (MDL)</title>
    <summary>  The concept of overfitting in model selection is explained and demonstrated
with an example. After providing some background information on information
theory and Kolmogorov complexity, we provide a short explanation of Minimum
Description Length and error minimization. We conclude with a discussion of the
typical features of overfitting in model selection.
</summary>
    <author>
      <name>Volker Nannen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages, Chapter 1 of The Paradox of Overfitting, Master's thesis,
  Rijksuniversiteit Groningen, 2003</arxiv:comment>
    <link href="http://arxiv.org/abs/1005.2364v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1005.2364v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.2.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1006.2588v1</id>
    <updated>2010-06-14T02:03:12Z</updated>
    <published>2010-06-14T02:03:12Z</published>
    <title>Agnostic Active Learning Without Constraints</title>
    <summary>  We present and analyze an agnostic active learning algorithm that works
without keeping a version space. This is unlike all previous approaches where a
restricted set of candidate hypotheses is maintained throughout learning, and
only hypotheses from this set are ever returned. By avoiding this version space
approach, our algorithm sheds the computational burden and brittleness
associated with maintaining version spaces, yet still allows for substantial
improvements over supervised learning for classification.
</summary>
    <author>
      <name>Alina Beygelzimer</name>
    </author>
    <author>
      <name>Daniel Hsu</name>
    </author>
    <author>
      <name>John Langford</name>
    </author>
    <author>
      <name>Tong Zhang</name>
    </author>
    <link href="http://arxiv.org/abs/1006.2588v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1006.2588v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1007.0660v1</id>
    <updated>2010-07-05T11:46:35Z</updated>
    <published>2010-07-05T11:46:35Z</published>
    <title>The Latent Bernoulli-Gauss Model for Data Analysis</title>
    <summary>  We present a new latent-variable model employing a Gaussian mixture
integrated with a feature selection procedure (the Bernoulli part of the model)
which together form a "Latent Bernoulli-Gauss" distribution. The model is
applied to MAP estimation, clustering, feature selection and collaborative
filtering and fares favorably with the state-of-the-art latent-variable models.
</summary>
    <author>
      <name>Amnon Shashua</name>
    </author>
    <author>
      <name>Gabi Pragier</name>
    </author>
    <link href="http://arxiv.org/abs/1007.0660v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1007.0660v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1009.0117v1</id>
    <updated>2010-09-01T08:29:49Z</updated>
    <published>2010-09-01T08:29:49Z</published>
    <title>Exploring Language-Independent Emotional Acoustic Features via Feature
  Selection</title>
    <summary>  We propose a novel feature selection strategy to discover
language-independent acoustic features that tend to be responsible for emotions
regardless of languages, linguistics and other factors. Experimental results
suggest that the language-independent feature subset discovered yields the
performance comparable to the full feature set on various emotional speech
corpora.
</summary>
    <author>
      <name>Arslan Shaukat</name>
    </author>
    <author>
      <name>Ke Chen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 2 figures, 6 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1009.0117v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1009.0117v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1010.4050v1</id>
    <updated>2010-10-19T21:01:45Z</updated>
    <published>2010-10-19T21:01:45Z</published>
    <title>Efficient Matrix Completion with Gaussian Models</title>
    <summary>  A general framework based on Gaussian models and a MAP-EM algorithm is
introduced in this paper for solving matrix/table completion problems. The
numerical experiments with the standard and challenging movie ratings data show
that the proposed approach, based on probably one of the simplest probabilistic
models, leads to the results in the same ballpark as the state-of-the-art, at a
lower computational cost.
</summary>
    <author>
      <name>Flavien Léger</name>
    </author>
    <author>
      <name>Guoshen Yu</name>
    </author>
    <author>
      <name>Guillermo Sapiro</name>
    </author>
    <link href="http://arxiv.org/abs/1010.4050v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1010.4050v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1010.5290v2</id>
    <updated>2011-03-16T05:53:38Z</updated>
    <published>2010-10-26T00:28:36Z</published>
    <title>Converged Algorithms for Orthogonal Nonnegative Matrix Factorizations</title>
    <summary>  This paper proposes uni-orthogonal and bi-orthogonal nonnegative matrix
factorization algorithms with robust convergence proofs. We design the
algorithms based on the work of Lee and Seung [1], and derive the converged
versions by utilizing ideas from the work of Lin [2]. The experimental results
confirm the theoretical guarantees of the convergences.
</summary>
    <author>
      <name>Andri Mirzal</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">55 pages, 11 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1010.5290v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1010.5290v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1011.5668v1</id>
    <updated>2010-11-25T18:52:30Z</updated>
    <published>2010-11-25T18:52:30Z</published>
    <title>On Theorem 2.3 in "Prediction, Learning, and Games" by Cesa-Bianchi and
  Lugosi</title>
    <summary>  The note presents a modified proof of a loss bound for the exponentially
weighted average forecaster with time-varying potential. The regret term of the
algorithm is upper-bounded by sqrt{n ln(N)} (uniformly in n), where N is the
number of experts and n is the number of steps.
</summary>
    <author>
      <name>Alexey Chernov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3 pages; excerpt from arXiv:1005.1918, simplified and rewritten using
  the notation of the monograph by Cesa-Bianchi and Lugosi</arxiv:comment>
    <link href="http://arxiv.org/abs/1011.5668v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1011.5668v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1012.4249v1</id>
    <updated>2010-12-20T07:36:42Z</updated>
    <published>2010-12-20T07:36:42Z</published>
    <title>Travel Time Estimation Using Floating Car Data</title>
    <summary>  This report explores the use of machine learning techniques to accurately
predict travel times in city streets and highways using floating car data
(location information of user vehicles on a road network). The aim of this
report is twofold, first we present a general architecture of solving this
problem, then present and evaluate few techniques on real floating car data
gathered over a month on a 5 Km highway in New Delhi.
</summary>
    <author>
      <name>Raffi Sevlian</name>
    </author>
    <author>
      <name>Ram Rajagopal</name>
    </author>
    <link href="http://arxiv.org/abs/1012.4249v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1012.4249v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1102.2467v1</id>
    <updated>2011-02-12T01:34:52Z</updated>
    <published>2011-02-12T01:34:52Z</published>
    <title>Universal Learning Theory</title>
    <summary>  This encyclopedic article gives a mini-introduction into the theory of
universal learning, founded by Ray Solomonoff in the 1960s and significantly
developed and extended in the last decade. It explains the spirit of universal
learning, but necessarily glosses over technical subtleties.
</summary>
    <author>
      <name>Marcus Hutter</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 LaTeX pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Encyclopedia of Machine Learning (2011) pages 1001-1008</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1102.2467v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1102.2467v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1107.1564v3</id>
    <updated>2014-03-12T07:08:13Z</updated>
    <published>2011-07-08T06:26:03Z</published>
    <title>Polyceptron: A Polyhedral Learning Algorithm</title>
    <summary>  In this paper we propose a new algorithm for learning polyhedral classifiers
which we call as Polyceptron. It is a Perception like algorithm which updates
the parameters only when the current classifier misclassifies any training
data. We give both batch and online version of Polyceptron algorithm. Finally
we give experimental results to show the effectiveness of our approach.
</summary>
    <author>
      <name>Naresh Manwani</name>
    </author>
    <author>
      <name>P. S. Sastry</name>
    </author>
    <link href="http://arxiv.org/abs/1107.1564v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1107.1564v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1108.4961v1</id>
    <updated>2011-08-24T22:38:40Z</updated>
    <published>2011-08-24T22:38:40Z</published>
    <title>Non-trivial two-armed partial-monitoring games are bandits</title>
    <summary>  We consider online learning in partial-monitoring games against an oblivious
adversary. We show that when the number of actions available to the learner is
two and the game is nontrivial then it is reducible to a bandit-like game and
thus the minimax regret is $\Theta(\sqrt{T})$.
</summary>
    <author>
      <name>András Antos</name>
    </author>
    <author>
      <name>Gábor Bartók</name>
    </author>
    <author>
      <name>Csaba Szepesvári</name>
    </author>
    <link href="http://arxiv.org/abs/1108.4961v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1108.4961v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1110.0593v1</id>
    <updated>2011-10-04T07:34:13Z</updated>
    <published>2011-10-04T07:34:13Z</published>
    <title>Two Projection Pursuit Algorithms for Machine Learning under
  Non-Stationarity</title>
    <summary>  This thesis derives, tests and applies two linear projection algorithms for
machine learning under non-stationarity. The first finds a direction in a
linear space upon which a data set is maximally non-stationary. The second aims
to robustify two-way classification against non-stationarity. The algorithm is
tested on a key application scenario, namely Brain Computer Interfacing.
</summary>
    <author>
      <name>Duncan A. J. Blythe</name>
    </author>
    <link href="http://arxiv.org/abs/1110.0593v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1110.0593v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1112.1390v1</id>
    <updated>2011-12-06T20:15:37Z</updated>
    <published>2011-12-06T20:15:37Z</published>
    <title>An Identity for Kernel Ridge Regression</title>
    <summary>  This paper derives an identity connecting the square loss of ridge regression
in on-line mode with the loss of the retrospectively best regressor. Some
corollaries about the properties of the cumulative loss of on-line ridge
regression are also obtained.
</summary>
    <author>
      <name>Fedor Zhdanov</name>
    </author>
    <author>
      <name>Yuri Kalnishkan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">35 pages; extended version of ALT 2010 paper (Proceedings of ALT
  2010, LNCS 6331, Springer, 2010)</arxiv:comment>
    <link href="http://arxiv.org/abs/1112.1390v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1112.1390v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.5598v4</id>
    <updated>2012-04-13T06:52:44Z</updated>
    <published>2012-02-25T02:10:20Z</published>
    <title>Clustering using Max-norm Constrained Optimization</title>
    <summary>  We suggest using the max-norm as a convex surrogate constraint for
clustering. We show how this yields a better exact cluster recovery guarantee
than previously suggested nuclear-norm relaxation, and study the effectiveness
of our method, and other related convex relaxations, compared to other
clustering approaches.
</summary>
    <author>
      <name>Ali Jalali</name>
    </author>
    <author>
      <name>Nathan Srebro</name>
    </author>
    <link href="http://arxiv.org/abs/1202.5598v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.5598v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.0566v2</id>
    <updated>2012-06-21T12:14:24Z</updated>
    <published>2012-04-03T00:33:53Z</published>
    <title>The Kernelized Stochastic Batch Perceptron</title>
    <summary>  We present a novel approach for training kernel Support Vector Machines,
establish learning runtime guarantees for our method that are better then those
of any other known kernelized SVM optimization approach, and show that our
method works well in practice compared to existing alternatives.
</summary>
    <author>
      <name>Andrew Cotter</name>
    </author>
    <author>
      <name>Shai Shalev-Shwartz</name>
    </author>
    <author>
      <name>Nathan Srebro</name>
    </author>
    <link href="http://arxiv.org/abs/1204.0566v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.0566v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.4294v1</id>
    <updated>2012-04-19T09:29:10Z</updated>
    <published>2012-04-19T09:29:10Z</published>
    <title>Learning in Riemannian Orbifolds</title>
    <summary>  Learning in Riemannian orbifolds is motivated by existing machine learning
algorithms that directly operate on finite combinatorial structures such as
point patterns, trees, and graphs. These methods, however, lack statistical
justification. This contribution derives consistency results for learning
problems in structured domains and thereby generalizes learning in vector
spaces and manifolds.
</summary>
    <author>
      <name>Brijnesh J. Jain</name>
    </author>
    <author>
      <name>Klaus Obermayer</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: substantial text overlap with arXiv:1001.0921</arxiv:comment>
    <link href="http://arxiv.org/abs/1204.4294v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.4294v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.4234v2</id>
    <updated>2012-05-25T10:24:35Z</updated>
    <published>2012-05-19T08:16:21Z</published>
    <title>Visualization of features of a series of measurements with
  one-dimensional cellular structure</title>
    <summary>  This paper describes the method of visualization of periodic constituents and
instability areas in series of measurements, being based on the algorithm of
smoothing out and concept of one-dimensional cellular automata. A method can be
used at the analysis of temporal series, related to the volumes of thematic
publications in web-space.
</summary>
    <author>
      <name>D. V. Lande</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, russian language</arxiv:comment>
    <link href="http://arxiv.org/abs/1205.4234v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.4234v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68R" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.6446v1</id>
    <updated>2012-06-27T19:59:59Z</updated>
    <published>2012-06-27T19:59:59Z</published>
    <title>Agglomerative Bregman Clustering</title>
    <summary>  This manuscript develops the theory of agglomerative clustering with Bregman
divergences. Geometric smoothing techniques are developed to deal with
degenerate clusters. To allow for cluster models based on exponential families
with overcomplete representations, Bregman divergences are developed for
nondifferentiable convex functions.
</summary>
    <author>
      <name>Matus Telgarsky</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">UCSD</arxiv:affiliation>
    </author>
    <author>
      <name>Sanjoy Dasgupta</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">UCSD</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.6446v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.6446v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.4676v2</id>
    <updated>2012-09-16T11:24:54Z</updated>
    <published>2012-07-19T14:08:22Z</published>
    <title>Proceedings of the 29th International Conference on Machine Learning
  (ICML-12)</title>
    <summary>  This is an index to the papers that appear in the Proceedings of the 29th
International Conference on Machine Learning (ICML-12). The conference was held
in Edinburgh, Scotland, June 27th - July 3rd, 2012.
</summary>
    <author>
      <name>John Langford</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Editors</arxiv:affiliation>
    </author>
    <author>
      <name>Joelle Pineau</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Editors</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 29th International Conference on Machine Learning
  (ICML-12). Editors: John Langford and Joelle Pineau. Publisher: Omnipress,
  2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1207.4676v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.4676v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.0699v1</id>
    <updated>2012-10-02T08:40:46Z</updated>
    <published>2012-10-02T08:40:46Z</published>
    <title>TV-SVM: Total Variation Support Vector Machine for Semi-Supervised Data
  Classification</title>
    <summary>  We introduce semi-supervised data classification algorithms based on total
variation (TV), Reproducing Kernel Hilbert Space (RKHS), support vector machine
(SVM), Cheeger cut, labeled and unlabeled data points. We design binary and
multi-class semi-supervised classification algorithms. We compare the TV-based
classification algorithms with the related Laplacian-based algorithms, and show
that TV classification perform significantly better when the number of labeled
data is small.
</summary>
    <author>
      <name>Xavier Bresson</name>
    </author>
    <author>
      <name>Ruiliang Zhang</name>
    </author>
    <link href="http://arxiv.org/abs/1210.0699v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.0699v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.6248v2</id>
    <updated>2012-12-04T13:50:19Z</updated>
    <published>2012-11-27T09:36:22Z</published>
    <title>A simple non-parametric Topic Mixture for Authors and Documents</title>
    <summary>  This article reviews the Author-Topic Model and presents a new non-parametric
extension based on the Hierarchical Dirichlet Process. The extension is
especially suitable when no prior information about the number of components
necessary is available. A blocked Gibbs sampler is described and focus put on
staying as close as possible to the original model with only the minimum of
theoretical and implementation overhead necessary.
</summary>
    <author>
      <name>Arnim Bleier</name>
    </author>
    <link href="http://arxiv.org/abs/1211.6248v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.6248v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.2474v1</id>
    <updated>2012-10-19T15:06:27Z</updated>
    <published>2012-10-19T15:06:27Z</published>
    <title>Learning Riemannian Metrics</title>
    <summary>  We propose a solution to the problem of estimating a Riemannian metric
associated with a given differentiable manifold. The metric learning problem is
based on minimizing the relative volume of a given set of points. We derive the
details for a family of metrics on the multinomial simplex. The resulting
metric has applications in text classification and bears some similarity to
TFIDF representation of text documents.
</summary>
    <author>
      <name>Guy Lebanon</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the Nineteenth Conference on Uncertainty in
  Artificial Intelligence (UAI2003)</arxiv:comment>
    <link href="http://arxiv.org/abs/1212.2474v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.2474v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.4347v1</id>
    <updated>2012-12-18T13:35:38Z</updated>
    <published>2012-12-18T13:35:38Z</published>
    <title>Bayesian Group Nonnegative Matrix Factorization for EEG Analysis</title>
    <summary>  We propose a generative model of a group EEG analysis, based on appropriate
kernel assumptions on EEG data. We derive the variational inference update rule
using various approximation techniques. The proposed model outperforms the
current state-of-the-art algorithms in terms of common pattern extraction. The
validity of the proposed model is tested on the BCI competition dataset.
</summary>
    <author>
      <name>Bonggun Shin</name>
    </author>
    <author>
      <name>Alice Oh</name>
    </author>
    <link href="http://arxiv.org/abs/1212.4347v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.4347v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.5091v1</id>
    <updated>2012-12-19T17:40:07Z</updated>
    <published>2012-12-19T17:40:07Z</published>
    <title>Maximally Informative Observables and Categorical Perception</title>
    <summary>  We formulate the problem of perception in the framework of information
theory, and prove that categorical perception is equivalent to the existence of
an observable that has the maximum possible information on the target of
perception. We call such an observable maximally informative. Regardless
whether categorical perception is real, maximally informative observables can
form the basis of a theory of perception. We conclude with the implications of
such a theory for the problem of speech perception.
</summary>
    <author>
      <name>Elaine Tsiang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1212.5091v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.5091v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.3849v1</id>
    <updated>2013-01-16T15:49:46Z</updated>
    <published>2013-01-16T15:49:46Z</published>
    <title>Experiments with Random Projection</title>
    <summary>  Recent theoretical work has identified random projection as a promising
dimensionality reduction technique for learning mixtures of Gausians. Here we
summarize these results and illustrate them by a wide variety of experiments on
synthetic and real data.
</summary>
    <author>
      <name>Sanjoy Dasgupta</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the Sixteenth Conference on Uncertainty in
  Artificial Intelligence (UAI2000)</arxiv:comment>
    <link href="http://arxiv.org/abs/1301.3849v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.3849v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.6316v3</id>
    <updated>2013-03-18T18:37:37Z</updated>
    <published>2013-01-27T04:51:21Z</published>
    <title>Hierarchical Data Representation Model - Multi-layer NMF</title>
    <summary>  In this paper, we propose a data representation model that demonstrates
hierarchical feature learning using nsNMF. We extend unit algorithm into
several layers. Experiments with document and image data successfully
discovered feature hierarchies. We also prove that proposed method results in
much better classification and reconstruction performance, especially for small
number of features. feature hierarchies.
</summary>
    <author>
      <name>Hyun Ah Song</name>
    </author>
    <author>
      <name>Soo-Young Lee</name>
    </author>
    <link href="http://arxiv.org/abs/1301.6316v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.6316v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1302.2550v1</id>
    <updated>2013-02-11T17:44:10Z</updated>
    <published>2013-02-11T17:44:10Z</published>
    <title>Online Regret Bounds for Undiscounted Continuous Reinforcement Learning</title>
    <summary>  We derive sublinear regret bounds for undiscounted reinforcement learning in
continuous state space. The proposed algorithm combines state aggregation with
the use of upper confidence bounds for implementing optimism in the face of
uncertainty. Beside the existence of an optimal policy which satisfies the
Poisson equation, the only assumptions made are Holder continuity of rewards
and transition probabilities.
</summary>
    <author>
      <name>Ronald Ortner</name>
    </author>
    <author>
      <name>Daniil Ryabko</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">in proceedings of NIPS 2012, pp. 1772--1780</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1302.2550v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1302.2550v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1303.6390v2</id>
    <updated>2013-03-27T16:23:48Z</updated>
    <published>2013-03-26T06:01:34Z</published>
    <title>A Note on k-support Norm Regularized Risk Minimization</title>
    <summary>  The k-support norm has been recently introduced to perform correlated
sparsity regularization. Although Argyriou et al. only reported experiments
using squared loss, here we apply it to several other commonly used settings
resulting in novel machine learning algorithms with interesting and familiar
limit cases. Source code for the algorithms described here is available.
</summary>
    <author>
      <name>Matthew Blaschko</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Saclay - Ile de France, CVN</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/1303.6390v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1303.6390v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.6899v1</id>
    <updated>2013-04-25T12:59:31Z</updated>
    <published>2013-04-25T12:59:31Z</published>
    <title>An implementation of the relational k-means algorithm</title>
    <summary>  A C# implementation of a generalized k-means variant called relational
k-means is described here. Relational k-means is a generalization of the
well-known k-means clustering method which works for non-Euclidean scenarios as
well. The input is an arbitrary distance matrix, as opposed to the traditional
k-means method, where the clustered objects need to be identified with vectors.
</summary>
    <author>
      <name>Balázs Szalkai</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1304.6899v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.6899v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1305.2218v1</id>
    <updated>2013-05-09T21:31:47Z</updated>
    <published>2013-05-09T21:31:47Z</published>
    <title>Stochastic gradient descent algorithms for strongly convex functions at
  O(1/T) convergence rates</title>
    <summary>  With a weighting scheme proportional to t, a traditional stochastic gradient
descent (SGD) algorithm achieves a high probability convergence rate of
O({\kappa}/T) for strongly convex functions, instead of O({\kappa} ln(T)/T). We
also prove that an accelerated SGD algorithm also achieves a rate of
O({\kappa}/T).
</summary>
    <author>
      <name>Shenghuo Zhu</name>
    </author>
    <link href="http://arxiv.org/abs/1305.2218v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1305.2218v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1305.6646v1</id>
    <updated>2013-05-28T22:12:59Z</updated>
    <published>2013-05-28T22:12:59Z</published>
    <title>Normalized Online Learning</title>
    <summary>  We introduce online learning algorithms which are independent of feature
scales, proving regret bounds dependent on the ratio of scales existent in the
data rather than the absolute scale. This has several useful effects: there is
no need to pre-normalize data, the test-time and test-space complexity are
reduced, and the algorithms are more robust.
</summary>
    <author>
      <name>Stephane Ross</name>
    </author>
    <author>
      <name>Paul Mineiro</name>
    </author>
    <author>
      <name>John Langford</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</arxiv:comment>
    <link href="http://arxiv.org/abs/1305.6646v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1305.6646v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1306.1433v3</id>
    <updated>2013-11-11T04:43:10Z</updated>
    <published>2013-06-06T15:15:07Z</published>
    <title>Tight Lower Bound on the Probability of a Binomial Exceeding its
  Expectation</title>
    <summary>  We give the proof of a tight lower bound on the probability that a binomial
random variable exceeds its expected value. The inequality plays an important
role in a variety of contexts, including the analysis of relative deviation
bounds in learning theory and generalization bounds for unbounded loss
functions.
</summary>
    <author>
      <name>Spencer Greenberg</name>
    </author>
    <author>
      <name>Mehryar Mohri</name>
    </author>
    <link href="http://arxiv.org/abs/1306.1433v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1306.1433v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.0317v1</id>
    <updated>2013-07-01T10:03:58Z</updated>
    <published>2013-07-01T10:03:58Z</published>
    <title>Algorithms of the LDA model [REPORT]</title>
    <summary>  We review three algorithms for Latent Dirichlet Allocation (LDA). Two of them
are variational inference algorithms: Variational Bayesian inference and Online
Variational Bayesian inference and one is Markov Chain Monte Carlo (MCMC)
algorithm -- Collapsed Gibbs sampling. We compare their time complexity and
performance. We find that online variational Bayesian inference is the fastest
algorithm and still returns reasonably good results.
</summary>
    <author>
      <name>Jaka Špeh</name>
    </author>
    <author>
      <name>Andrej Muhič</name>
    </author>
    <author>
      <name>Jan Rupnik</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 4 figures, report</arxiv:comment>
    <link href="http://arxiv.org/abs/1307.0317v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.0317v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.3675v1</id>
    <updated>2013-07-13T19:38:09Z</updated>
    <published>2013-07-13T19:38:09Z</published>
    <title>Minimum Error Rate Training and the Convex Hull Semiring</title>
    <summary>  We describe the line search used in the minimum error rate training algorithm
MERT as the "inside score" of a weighted proof forest under a semiring defined
in terms of well-understood operations from computational geometry. This
conception leads to a straightforward complexity analysis of the dynamic
programming MERT algorithms of Macherey et al. (2008) and Kumar et al. (2009)
and practical approaches to implementation.
</summary>
    <author>
      <name>Chris Dyer</name>
    </author>
    <link href="http://arxiv.org/abs/1307.3675v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.3675v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.6; I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.8305v1</id>
    <updated>2013-07-31T12:38:20Z</updated>
    <published>2013-07-31T12:38:20Z</published>
    <title>The Planning-ahead SMO Algorithm</title>
    <summary>  The sequential minimal optimization (SMO) algorithm and variants thereof are
the de facto standard method for solving large quadratic programs for support
vector machine (SVM) training. In this paper we propose a simple yet powerful
modification. The main emphasis is on an algorithm improving the SMO step size
by planning-ahead. The theoretical analysis ensures its convergence to the
optimum. Experiments involving a large number of datasets were carried out to
demonstrate the superiority of the new algorithm.
</summary>
    <author>
      <name>Tobias Glasmachers</name>
    </author>
    <link href="http://arxiv.org/abs/1307.8305v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.8305v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1309.1541v1</id>
    <updated>2013-09-06T05:48:40Z</updated>
    <published>2013-09-06T05:48:40Z</published>
    <title>Projection onto the probability simplex: An efficient algorithm with a
  simple proof, and an application</title>
    <summary>  We provide an elementary proof of a simple, efficient algorithm for computing
the Euclidean projection of a point onto the probability simplex. We also show
an application in Laplacian K-modes clustering.
</summary>
    <author>
      <name>Weiran Wang</name>
    </author>
    <author>
      <name>Miguel Á. Carreira-Perpiñán</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1309.1541v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1309.1541v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.8320v1</id>
    <updated>2013-10-30T20:56:50Z</updated>
    <published>2013-10-30T20:56:50Z</published>
    <title>Safe and Efficient Screening For Sparse Support Vector Machine</title>
    <summary>  Screening is an effective technique for speeding up the training process of a
sparse learning model by removing the features that are guaranteed to be
inactive the process. In this paper, we present a efficient screening technique
for sparse support vector machine based on variational inequality. The
technique is both efficient and safe.
</summary>
    <author>
      <name>Zheng Zhao</name>
    </author>
    <author>
      <name>Jun Liu</name>
    </author>
    <link href="http://arxiv.org/abs/1310.8320v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.8320v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1311.0636v1</id>
    <updated>2013-11-04T10:31:11Z</updated>
    <published>2013-11-04T10:31:11Z</published>
    <title>A Parallel SGD method with Strong Convergence</title>
    <summary>  This paper proposes a novel parallel stochastic gradient descent (SGD) method
that is obtained by applying parallel sets of SGD iterations (each set
operating on one node using the data residing in it) for finding the direction
in each iteration of a batch descent method. The method has strong convergence
properties. Experiments on datasets with high dimensional feature spaces show
the value of this method.
</summary>
    <author>
      <name>Dhruv Mahajan</name>
    </author>
    <author>
      <name>S. Sathiya Keerthi</name>
    </author>
    <author>
      <name>S. Sundararajan</name>
    </author>
    <author>
      <name>Leon Bottou</name>
    </author>
    <link href="http://arxiv.org/abs/1311.0636v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1311.0636v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1311.3157v1</id>
    <updated>2013-11-12T17:25:29Z</updated>
    <published>2013-11-12T17:25:29Z</published>
    <title>Multiple Closed-Form Local Metric Learning for K-Nearest Neighbor
  Classifier</title>
    <summary>  Many researches have been devoted to learn a Mahalanobis distance metric,
which can effectively improve the performance of kNN classification. Most
approaches are iterative and computational expensive and linear rigidity still
critically limits metric learning algorithm to perform better. We proposed a
computational economical framework to learn multiple metrics in closed-form.
</summary>
    <author>
      <name>Jianbo Ye</name>
    </author>
    <link href="http://arxiv.org/abs/1311.3157v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1311.3157v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1311.7198v1</id>
    <updated>2013-11-28T03:59:31Z</updated>
    <published>2013-11-28T03:59:31Z</published>
    <title>ADMM Algorithm for Graphical Lasso with an $\ell_{\infty}$ Element-wise
  Norm Constraint</title>
    <summary>  We consider the problem of Graphical lasso with an additional $\ell_{\infty}$
element-wise norm constraint on the precision matrix. This problem has
applications in high-dimensional covariance decomposition such as in
\citep{Janzamin-12}. We propose an ADMM algorithm to solve this problem. We
also use a continuation strategy on the penalty parameter to have a fast
implemenation of the algorithm.
</summary>
    <author>
      <name>Karthik Mohan</name>
    </author>
    <link href="http://arxiv.org/abs/1311.7198v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1311.7198v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1312.0048v1</id>
    <updated>2013-11-30T01:07:25Z</updated>
    <published>2013-11-30T01:07:25Z</published>
    <title>Stochastic Optimization of Smooth Loss</title>
    <summary>  In this paper, we first prove a high probability bound rather than an
expectation bound for stochastic optimization with smooth loss. Furthermore,
the existing analysis requires the knowledge of optimal classifier for tuning
the step size in order to achieve the desired bound. However, this information
is usually not accessible in advanced. We also propose a strategy to address
the limitation.
</summary>
    <author>
      <name>Rong Jin</name>
    </author>
    <link href="http://arxiv.org/abs/1312.0048v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1312.0048v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1312.5853v4</id>
    <updated>2014-02-18T21:35:13Z</updated>
    <published>2013-12-20T08:45:07Z</published>
    <title>Multi-GPU Training of ConvNets</title>
    <summary>  In this work we evaluate different approaches to parallelize computation of
convolutional neural networks across several GPUs.
</summary>
    <author>
      <name>Omry Yadan</name>
    </author>
    <author>
      <name>Keith Adams</name>
    </author>
    <author>
      <name>Yaniv Taigman</name>
    </author>
    <author>
      <name>Marc'Aurelio Ranzato</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Machine Learning, Deep Learning, Convolutional Networks, Computer
  Vision, GPU, CUDA</arxiv:comment>
    <link href="http://arxiv.org/abs/1312.5853v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1312.5853v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1312.6042v4</id>
    <updated>2014-06-17T10:24:51Z</updated>
    <published>2013-12-20T17:03:50Z</published>
    <title>Learning States Representations in POMDP</title>
    <summary>  We propose to deal with sequential processes where only partial observations
are available by learning a latent representation space on which policies may
be accurately learned.
</summary>
    <author>
      <name>Gabriella Contardo</name>
    </author>
    <author>
      <name>Ludovic Denoyer</name>
    </author>
    <author>
      <name>Thierry Artieres</name>
    </author>
    <author>
      <name>Patrick Gallinari</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1312.6042v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1312.6042v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1402.4845v1</id>
    <updated>2014-02-19T22:59:14Z</updated>
    <published>2014-02-19T22:59:14Z</published>
    <title>Diffusion Least Mean Square: Simulations</title>
    <summary>  In this technical report we analyse the performance of diffusion strategies
applied to the Least-Mean-Square adaptive filter. We configure a network of
cooperative agents running adaptive filters and discuss their behaviour when
compared with a non-cooperative agent which represents the average of the
network. The analysis provides conditions under which diversity in the filter
parameters is beneficial in terms of convergence and stability. Simulations
drive and support the analysis.
</summary>
    <author>
      <name>Jonathan Gelati</name>
    </author>
    <author>
      <name>Sithan Kanna</name>
    </author>
    <link href="http://arxiv.org/abs/1402.4845v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1402.4845v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1402.5766v1</id>
    <updated>2014-02-24T09:49:04Z</updated>
    <published>2014-02-24T09:49:04Z</published>
    <title>No more meta-parameter tuning in unsupervised sparse feature learning</title>
    <summary>  We propose a meta-parameter free, off-the-shelf, simple and fast unsupervised
feature learning algorithm, which exploits a new way of optimizing for
sparsity. Experiments on STL-10 show that the method presents state-of-the-art
performance and provides discriminative features that generalize well.
</summary>
    <author>
      <name>Adriana Romero</name>
    </author>
    <author>
      <name>Petia Radeva</name>
    </author>
    <author>
      <name>Carlo Gatta</name>
    </author>
    <link href="http://arxiv.org/abs/1402.5766v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1402.5766v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1402.6013v1</id>
    <updated>2014-02-24T23:12:42Z</updated>
    <published>2014-02-24T23:12:42Z</published>
    <title>Open science in machine learning</title>
    <summary>  We present OpenML and mldata, open science platforms that provides easy
access to machine learning data, software and results to encourage further
study and application. They go beyond the more traditional repositories for
data sets and software packages in that they allow researchers to also easily
share the results they obtained in experiments and to compare their solutions
with those of others.
</summary>
    <author>
      <name>Joaquin Vanschoren</name>
    </author>
    <author>
      <name>Mikio L. Braun</name>
    </author>
    <author>
      <name>Cheng Soon Ong</name>
    </author>
    <link href="http://arxiv.org/abs/1402.6013v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1402.6013v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1403.5341v2</id>
    <updated>2015-06-08T19:05:44Z</updated>
    <published>2014-03-21T01:42:53Z</published>
    <title>An Information-Theoretic Analysis of Thompson Sampling</title>
    <summary>  We provide an information-theoretic analysis of Thompson sampling that
applies across a broad range of online optimization problems in which a
decision-maker must learn from partial feedback. This analysis inherits the
simplicity and elegance of information theory and leads to regret bounds that
scale with the entropy of the optimal-action distribution. This strengthens
preexisting results and yields new insight into how information improves
performance.
</summary>
    <author>
      <name>Daniel Russo</name>
    </author>
    <author>
      <name>Benjamin Van Roy</name>
    </author>
    <link href="http://arxiv.org/abs/1403.5341v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1403.5341v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1403.7746v1</id>
    <updated>2014-03-30T12:22:36Z</updated>
    <published>2014-03-30T12:22:36Z</published>
    <title>Multi-label Ferns for Efficient Recognition of Musical Instruments in
  Recordings</title>
    <summary>  In this paper we introduce multi-label ferns, and apply this technique for
automatic classification of musical instruments in audio recordings. We compare
the performance of our proposed method to a set of binary random ferns, using
jazz recordings as input data. Our main result is obtaining much faster
classification and higher F-score. We also achieve substantial reduction of the
model size.
</summary>
    <author>
      <name>Miron B. Kursa</name>
    </author>
    <author>
      <name>Alicja A. Wieczorkowska</name>
    </author>
    <link href="http://arxiv.org/abs/1403.7746v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1403.7746v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.0833v1</id>
    <updated>2014-05-05T09:29:17Z</updated>
    <published>2014-05-05T09:29:17Z</published>
    <title>Generalized Risk-Aversion in Stochastic Multi-Armed Bandits</title>
    <summary>  We consider the problem of minimizing the regret in stochastic multi-armed
bandit, when the measure of goodness of an arm is not the mean return, but some
general function of the mean and the variance.We characterize the conditions
under which learning is possible and present examples for which no natural
algorithm can achieve sublinear regret.
</summary>
    <author>
      <name>Alexander Zimin</name>
    </author>
    <author>
      <name>Rasmus Ibsen-Jensen</name>
    </author>
    <author>
      <name>Krishnendu Chatterjee</name>
    </author>
    <link href="http://arxiv.org/abs/1405.0833v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.0833v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.3167v1</id>
    <updated>2014-05-13T14:36:59Z</updated>
    <published>2014-05-13T14:36:59Z</published>
    <title>Clustering, Hamming Embedding, Generalized LSH and the Max Norm</title>
    <summary>  We study the convex relaxation of clustering and hamming embedding, focusing
on the asymmetric case (co-clustering and asymmetric hamming embedding),
understanding their relationship to LSH as studied by (Charikar 2002) and to
the max-norm ball, and the differences between their symmetric and asymmetric
versions.
</summary>
    <author>
      <name>Behnam Neyshabur</name>
    </author>
    <author>
      <name>Yury Makarychev</name>
    </author>
    <author>
      <name>Nathan Srebro</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1405.3167v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.3167v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.7430v1</id>
    <updated>2014-05-29T00:37:28Z</updated>
    <published>2014-05-29T00:37:28Z</published>
    <title>BayesOpt: A Bayesian Optimization Library for Nonlinear Optimization,
  Experimental Design and Bandits</title>
    <summary>  BayesOpt is a library with state-of-the-art Bayesian optimization methods to
solve nonlinear optimization, stochastic bandits or sequential experimental
design problems. Bayesian optimization is sample efficient by building a
posterior distribution to capture the evidence and prior knowledge for the
target function. Built in standard C++, the library is extremely efficient
while being portable and flexible. It includes a common interface for C, C++,
Python, Matlab and Octave.
</summary>
    <author>
      <name>Ruben Martinez-Cantin</name>
    </author>
    <link href="http://arxiv.org/abs/1405.7430v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.7430v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1406.3726v1</id>
    <updated>2014-06-14T13:08:30Z</updated>
    <published>2014-06-14T13:08:30Z</published>
    <title>Evaluation of Machine Learning Techniques for Green Energy Prediction</title>
    <summary>  We evaluate the following Machine Learning techniques for Green Energy (Wind,
Solar) Prediction: Bayesian Inference, Neural Networks, Support Vector
Machines, Clustering techniques (PCA). Our objective is to predict green energy
using weather forecasts, predict deviations from forecast green energy, find
correlation amongst different weather parameters and green energy availability,
recover lost or missing energy (/ weather) data. We use historical weather data
and weather forecasts for the same.
</summary>
    <author>
      <name>Ankur Sahai</name>
    </author>
    <link href="http://arxiv.org/abs/1406.3726v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1406.3726v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1406.5143v2</id>
    <updated>2014-06-21T08:27:42Z</updated>
    <published>2014-06-19T18:42:12Z</published>
    <title>The Sample Complexity of Learning Linear Predictors with the Squared
  Loss</title>
    <summary>  In this short note, we provide tight sample complexity bounds for learning
linear predictors with respect to the squared loss. Our focus is on an agnostic
setting, where no assumptions are made on the data distribution. This contrasts
with standard results in the literature, which either make distributional
assumptions, refer to specific parameter settings, or use other performance
measures.
</summary>
    <author>
      <name>Ohad Shamir</name>
    </author>
    <link href="http://arxiv.org/abs/1406.5143v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1406.5143v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1408.2065v1</id>
    <updated>2014-08-09T06:05:51Z</updated>
    <published>2014-08-09T06:05:51Z</published>
    <title>Normalized Online Learning</title>
    <summary>  We introduce online learning algorithms which are independent of feature
scales, proving regret bounds dependent on the ratio of scales existent in the
data rather than the absolute scale. This has several useful effects: there is
no need to pre-normalize data, the test-time and test-space complexity are
reduced, and the algorithms are more robust.
</summary>
    <author>
      <name>Stephane Ross</name>
    </author>
    <author>
      <name>Paul Mineiro</name>
    </author>
    <author>
      <name>John Langford</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</arxiv:comment>
    <link href="http://arxiv.org/abs/1408.2065v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1408.2065v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1408.4673v2</id>
    <updated>2017-08-09T12:50:11Z</updated>
    <published>2014-08-20T14:29:11Z</published>
    <title>AFP Algorithm and a Canonical Normal Form for Horn Formulas</title>
    <summary>  AFP Algorithm is a learning algorithm for Horn formulas. We show that it does
not improve the complexity of AFP Algorithm, if after each negative
counterexample more that just one refinements are performed. Moreover, a
canonical normal form for Horn formulas is presented, and it is proved that the
output formula of AFP Algorithm is in this normal form.
</summary>
    <author>
      <name>Ruhollah Majdoddin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Some minor corrections in the text</arxiv:comment>
    <link href="http://arxiv.org/abs/1408.4673v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1408.4673v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68Q32, 68T27" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1408.5449v1</id>
    <updated>2014-08-23T01:23:23Z</updated>
    <published>2014-08-23T01:23:23Z</published>
    <title>Stretchy Polynomial Regression</title>
    <summary>  This article proposes a novel solution for stretchy polynomial regression
learning. The solution comes in primal and dual closed-forms similar to that of
ridge regression. Essentially, the proposed solution stretches the covariance
computation via a power term thereby compresses or amplifies the estimation.
Our experiments on both synthetic data and real-world data show effectiveness
of the proposed method for compressive learning.
</summary>
    <author>
      <name>Kar-Ann Toh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Article created in April and revised in August 2014. Submitted to
  ICARCV 2014</arxiv:comment>
    <link href="http://arxiv.org/abs/1408.5449v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1408.5449v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.0440v1</id>
    <updated>2014-10-02T02:28:04Z</updated>
    <published>2014-10-02T02:28:04Z</published>
    <title>Scalable Nonlinear Learning with Adaptive Polynomial Expansions</title>
    <summary>  Can we effectively learn a nonlinear representation in time comparable to
linear learning? We describe a new algorithm that explicitly and adaptively
expands higher-order interaction features over base linear representations. The
algorithm is designed for extreme computational efficiency, and an extensive
experimental study shows that its computation/prediction tradeoff ability
compares very favorably against strong baselines.
</summary>
    <author>
      <name>Alekh Agarwal</name>
    </author>
    <author>
      <name>Alina Beygelzimer</name>
    </author>
    <author>
      <name>Daniel Hsu</name>
    </author>
    <author>
      <name>John Langford</name>
    </author>
    <author>
      <name>Matus Telgarsky</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in NIPS 2014</arxiv:comment>
    <link href="http://arxiv.org/abs/1410.0440v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.0440v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.4604v1</id>
    <updated>2014-10-16T23:30:08Z</updated>
    <published>2014-10-16T23:30:08Z</published>
    <title>Domain-Independent Optimistic Initialization for Reinforcement Learning</title>
    <summary>  In Reinforcement Learning (RL), it is common to use optimistic initialization
of value functions to encourage exploration. However, such an approach
generally depends on the domain, viz., the scale of the rewards must be known,
and the feature representation must have a constant norm. We present a simple
approach that performs optimistic initialization with less dependence on the
domain.
</summary>
    <author>
      <name>Marlos C. Machado</name>
    </author>
    <author>
      <name>Sriram Srinivasan</name>
    </author>
    <author>
      <name>Michael Bowling</name>
    </author>
    <link href="http://arxiv.org/abs/1410.4604v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.4604v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1411.2635v1</id>
    <updated>2014-11-10T21:41:32Z</updated>
    <published>2014-11-10T21:41:32Z</published>
    <title>A chain rule for the expected suprema of Gaussian processes</title>
    <summary>  The expected supremum of a Gaussian process indexed by the image of an index
set under a function class is bounded in terms of separate properties of the
index set and the function class. The bound is relevant to the estimation of
nonlinear transformations or the analysis of learning algorithms whenever
hypotheses are chosen from composite classes, as is the case for multi-layer
models.
</summary>
    <author>
      <name>Andreas Maurer</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-319-11662-4_18</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-319-11662-4_18" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Lecture Notes in Computer Science Volume 8776, 2014, pp 245-259</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1411.2635v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1411.2635v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1411.2919v1</id>
    <updated>2014-11-11T18:55:35Z</updated>
    <published>2014-11-11T18:55:35Z</published>
    <title>Bounded Regret for Finite-Armed Structured Bandits</title>
    <summary>  We study a new type of K-armed bandit problem where the expected return of
one arm may depend on the returns of other arms. We present a new algorithm for
this general class of problems and show that under certain circumstances it is
possible to achieve finite expected cumulative regret. We also give
problem-dependent lower bounds on the cumulative regret showing that at least
in special cases the new algorithm is nearly optimal.
</summary>
    <author>
      <name>Tor Lattimore</name>
    </author>
    <author>
      <name>Remi Munos</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1411.2919v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1411.2919v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.3276v1</id>
    <updated>2014-12-10T12:28:34Z</updated>
    <published>2014-12-10T12:28:34Z</published>
    <title>Generalised Entropy MDPs and Minimax Regret</title>
    <summary>  Bayesian methods suffer from the problem of how to specify prior beliefs. One
interesting idea is to consider worst-case priors. This requires solving a
stochastic zero-sum game. In this paper, we extend well-known results from
bandit theory in order to discover minimax-Bayes policies and discuss when they
are practical.
</summary>
    <author>
      <name>Emmanouil G. Androulakis</name>
    </author>
    <author>
      <name>Christos Dimitrakakis</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, NIPS workshop "From bad models to good policies"</arxiv:comment>
    <link href="http://arxiv.org/abs/1412.3276v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.3276v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1501.03838v1</id>
    <updated>2015-01-15T21:59:39Z</updated>
    <published>2015-01-15T21:59:39Z</published>
    <title>PAC-Bayes with Minimax for Confidence-Rated Transduction</title>
    <summary>  We consider using an ensemble of binary classifiers for transductive
prediction, when unlabeled test data are known in advance. We derive minimax
optimal rules for confidence-rated prediction in this setting. By using
PAC-Bayes analysis on these rules, we obtain data-dependent performance
guarantees without distributional assumptions on the data. Our analysis
techniques are readily extended to a setting in which the predictor is allowed
to abstain.
</summary>
    <author>
      <name>Akshay Balsubramani</name>
    </author>
    <author>
      <name>Yoav Freund</name>
    </author>
    <link href="http://arxiv.org/abs/1501.03838v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1501.03838v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1501.04244v1</id>
    <updated>2015-01-17T23:42:08Z</updated>
    <published>2015-01-17T23:42:08Z</published>
    <title>Generalised Random Forest Space Overview</title>
    <summary>  Assuming a view of the Random Forest as a special case of a nested ensemble
of interchangeable modules, we construct a generalisation space allowing one to
easily develop novel methods based on this algorithm. We discuss the role and
required properties of modules at each level, especially in context of some
already proposed RF generalisations.
</summary>
    <author>
      <name>Miron B. Kursa</name>
    </author>
    <link href="http://arxiv.org/abs/1501.04244v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1501.04244v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.04137v1</id>
    <updated>2015-02-13T21:32:12Z</updated>
    <published>2015-02-13T21:32:12Z</published>
    <title>Non-Adaptive Learning a Hidden Hipergraph</title>
    <summary>  We give a new deterministic algorithm that non-adaptively learns a hidden
hypergraph from edge-detecting queries. All previous non-adaptive algorithms
either run in exponential time or have non-optimal query complexity. We give
the first polynomial time non-adaptive learning algorithm for learning
hypergraph that asks almost optimal number of queries.
</summary>
    <author>
      <name>Hasan Abasi</name>
    </author>
    <author>
      <name>Nader H. Bshouty</name>
    </author>
    <author>
      <name>Hanna Mazzawi</name>
    </author>
    <link href="http://arxiv.org/abs/1502.04137v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.04137v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.05675v2</id>
    <updated>2015-02-20T13:00:17Z</updated>
    <published>2015-02-19T19:30:46Z</published>
    <title>NP-Hardness and Inapproximability of Sparse PCA</title>
    <summary>  We give a reduction from {\sc clique} to establish that sparse PCA is
NP-hard. The reduction has a gap which we use to exclude an FPTAS for sparse
PCA (unless P=NP). Under weaker complexity assumptions, we also exclude
polynomial constant-factor approximation algorithms.
</summary>
    <author>
      <name>Malik Magdon-Ismail</name>
    </author>
    <link href="http://arxiv.org/abs/1502.05675v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.05675v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.07073v3</id>
    <updated>2015-06-19T07:31:45Z</updated>
    <published>2015-02-25T07:24:40Z</published>
    <title>Strongly Adaptive Online Learning</title>
    <summary>  Strongly adaptive algorithms are algorithms whose performance on every time
interval is close to optimal. We present a reduction that can transform
standard low-regret algorithms to strongly adaptive. As a consequence, we
derive simple, yet efficient, strongly adaptive algorithms for a handful of
problems.
</summary>
    <author>
      <name>Amit Daniely</name>
    </author>
    <author>
      <name>Alon Gonen</name>
    </author>
    <author>
      <name>Shai Shalev-Shwartz</name>
    </author>
    <link href="http://arxiv.org/abs/1502.07073v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.07073v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.05938v1</id>
    <updated>2015-03-19T20:30:46Z</updated>
    <published>2015-03-19T20:30:46Z</published>
    <title>On Invariance and Selectivity in Representation Learning</title>
    <summary>  We discuss data representation which can be learned automatically from data,
are invariant to transformations, and at the same time selective, in the sense
that two points have the same representation only if they are one the
transformation of the other. The mathematical results here sharpen some of the
key claims of i-theory -- a recent theory of feedforward processing in sensory
cortex.
</summary>
    <author>
      <name>Fabio Anselmi</name>
    </author>
    <author>
      <name>Lorenzo Rosasco</name>
    </author>
    <author>
      <name>Tomaso Poggio</name>
    </author>
    <link href="http://arxiv.org/abs/1503.05938v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.05938v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.07211v1</id>
    <updated>2015-03-24T21:38:59Z</updated>
    <published>2015-03-24T21:38:59Z</published>
    <title>Universal Approximation of Markov Kernels by Shallow Stochastic
  Feedforward Networks</title>
    <summary>  We establish upper bounds for the minimal number of hidden units for which a
binary stochastic feedforward network with sigmoid activation probabilities and
a single hidden layer is a universal approximator of Markov kernels. We show
that each possible probabilistic assignment of the states of $n$ output units,
given the states of $k\geq1$ input units, can be approximated arbitrarily well
by a network with $2^{k-1}(2^{n-1}-1)$ hidden units.
</summary>
    <author>
      <name>Guido Montufar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1503.07211v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.07211v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="82C32" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.06798v1</id>
    <updated>2015-04-26T10:18:09Z</updated>
    <published>2015-04-26T10:18:09Z</published>
    <title>Overlapping Community Detection by Online Cluster Aggregation</title>
    <summary>  We present a new online algorithm for detecting overlapping communities. The
main ingredients are a modification of an online k-means algorithm and a new
approach to modelling overlap in communities. An evaluation on large benchmark
graphs shows that the quality of discovered communities compares favorably to
several methods in the recent literature, while the running time is
significantly improved.
</summary>
    <author>
      <name>Mark Kozdoba</name>
    </author>
    <author>
      <name>Shie Mannor</name>
    </author>
    <link href="http://arxiv.org/abs/1504.06798v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.06798v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.08215v1</id>
    <updated>2015-04-30T13:26:46Z</updated>
    <published>2015-04-30T13:26:46Z</published>
    <title>Lateral Connections in Denoising Autoencoders Support Supervised
  Learning</title>
    <summary>  We show how a deep denoising autoencoder with lateral connections can be used
as an auxiliary unsupervised learning task to support supervised learning. The
proposed model is trained to minimize simultaneously the sum of supervised and
unsupervised cost functions by back-propagation, avoiding the need for
layer-wise pretraining. It improves the state of the art significantly in the
permutation-invariant MNIST classification task.
</summary>
    <author>
      <name>Antti Rasmus</name>
    </author>
    <author>
      <name>Harri Valpola</name>
    </author>
    <author>
      <name>Tapani Raiko</name>
    </author>
    <link href="http://arxiv.org/abs/1504.08215v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.08215v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.02510v1</id>
    <updated>2015-06-08T14:00:32Z</updated>
    <published>2015-06-08T14:00:32Z</published>
    <title>Learning Mixtures of Ising Models using Pseudolikelihood</title>
    <summary>  Maximum pseudolikelihood method has been among the most important methods for
learning parameters of statistical physics models, such as Ising models. In
this paper, we study how pseudolikelihood can be derived for learning
parameters of a mixture of Ising models. The performance of the proposed
approach is demonstrated for Ising and Potts models on both synthetic and real
data.
</summary>
    <author>
      <name>Onur Dikmen</name>
    </author>
    <link href="http://arxiv.org/abs/1506.02510v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.02510v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.04217v2</id>
    <updated>2015-06-22T03:28:45Z</updated>
    <published>2015-06-13T03:52:44Z</published>
    <title>On the Equivalence of CoCoA+ and DisDCA</title>
    <summary>  In this document, we show that the algorithm CoCoA+ (Ma et al., ICML, 2015)
under the setting used in their experiments, which is also the best setting
suggested by the authors that proposed this algorithm, is equivalent to the
practical variant of DisDCA (Yang, NIPS, 2013).
</summary>
    <author>
      <name>Ching-pei Lee</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This article is withdrawn by the author because this is actually a
  known fact</arxiv:comment>
    <link href="http://arxiv.org/abs/1506.04217v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.04217v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.05790v2</id>
    <updated>2015-11-11T01:06:07Z</updated>
    <published>2015-06-18T19:53:12Z</published>
    <title>Scalable Semi-Supervised Aggregation of Classifiers</title>
    <summary>  We present and empirically evaluate an efficient algorithm that learns to
aggregate the predictions of an ensemble of binary classifiers. The algorithm
uses the structure of the ensemble predictions on unlabeled data to yield
significant performance improvements. It does this without making assumptions
on the structure or origin of the ensemble, without parameters, and as scalably
as linear learning. We empirically demonstrate these performance gains with
random forests.
</summary>
    <author>
      <name>Akshay Balsubramani</name>
    </author>
    <author>
      <name>Yoav Freund</name>
    </author>
    <link href="http://arxiv.org/abs/1506.05790v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.05790v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.06573v1</id>
    <updated>2015-06-22T12:47:07Z</updated>
    <published>2015-06-22T12:47:07Z</published>
    <title>PAC-Bayes Iterated Logarithm Bounds for Martingale Mixtures</title>
    <summary>  We give tight concentration bounds for mixtures of martingales that are
simultaneously uniform over (a) mixture distributions, in a PAC-Bayes sense;
and (b) all finite times. These bounds are proved in terms of the martingale
variance, extending classical Bernstein inequalities, and sharpening and
simplifying prior work.
</summary>
    <author>
      <name>Akshay Balsubramani</name>
    </author>
    <link href="http://arxiv.org/abs/1506.06573v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.06573v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.01563v1</id>
    <updated>2015-07-06T18:53:09Z</updated>
    <published>2015-07-06T18:53:09Z</published>
    <title>A Simple Algorithm for Maximum Margin Classification, Revisited</title>
    <summary>  In this note, we revisit the algorithm of Har-Peled et. al. [HRZ07] for
computing a linear maximum margin classifier. Our presentation is self
contained, and the algorithm itself is slightly simpler than the original
algorithm. The algorithm itself is a simple Perceptron like iterative
algorithm. For more details and background, the reader is referred to the
original paper.
</summary>
    <author>
      <name>Sariel Har-Peled</name>
    </author>
    <link href="http://arxiv.org/abs/1507.01563v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.01563v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.02084v1</id>
    <updated>2015-07-08T09:58:06Z</updated>
    <published>2015-07-08T09:58:06Z</published>
    <title>Shedding Light on the Asymmetric Learning Capability of AdaBoost</title>
    <summary>  In this paper, we propose a different insight to analyze AdaBoost. This
analysis reveals that, beyond some preconceptions, AdaBoost can be directly
used as an asymmetric learning algorithm, preserving all its theoretical
properties. A novel class-conditional description of AdaBoost, which models the
actual asymmetric behavior of the algorithm, is presented.
</summary>
    <author>
      <name>Iago Landesa-Vázquez</name>
    </author>
    <author>
      <name>José Luis Alba-Castro</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.patrec.2011.10.022</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.patrec.2011.10.022" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Pattern Recognition Letters 33 (2012) 247-255</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1507.02084v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.02084v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.04910v1</id>
    <updated>2015-07-17T10:39:52Z</updated>
    <published>2015-07-17T10:39:52Z</published>
    <title>Lower Bounds for Multi-armed Bandit with Non-equivalent Multiple Plays</title>
    <summary>  We study the stochastic multi-armed bandit problem with non-equivalent
multiple plays where, at each step, an agent chooses not only a set of arms,
but also their order, which influences reward distribution. In several problem
formulations with different assumptions, we provide lower bounds for regret
with standard asymptotics $O(\log{t})$ but novel coefficients and provide
optimal algorithms, thus proving that these bounds cannot be improved.
</summary>
    <author>
      <name>Aleksandr Vorobev</name>
    </author>
    <author>
      <name>Gleb Gusev</name>
    </author>
    <link href="http://arxiv.org/abs/1507.04910v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.04910v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.07147v1</id>
    <updated>2015-07-25T22:56:29Z</updated>
    <published>2015-07-25T22:56:29Z</published>
    <title>True Online Emphatic TD($λ$): Quick Reference and Implementation
  Guide</title>
    <summary>  This document is a guide to the implementation of true online emphatic
TD($\lambda$), a model-free temporal-difference algorithm for learning to make
long-term predictions which combines the emphasis idea (Sutton, Mahmood &amp; White
2015) and the true-online idea (van Seijen &amp; Sutton 2014). The setting used
here includes linear function approximation, the possibility of off-policy
training, and all the generality of general value functions, as well as the
emphasis algorithm's notion of "interest".
</summary>
    <author>
      <name>Richard S. Sutton</name>
    </author>
    <link href="http://arxiv.org/abs/1507.07147v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.07147v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.07374v1</id>
    <updated>2015-07-27T11:50:44Z</updated>
    <published>2015-07-27T11:50:44Z</published>
    <title>A genetic algorithm for autonomous navigation in partially observable
  domain</title>
    <summary>  The problem of autonomous navigation is one of the basic problems for
robotics. Although, in general, it may be challenging when an autonomous
vehicle is placed into partially observable domain. In this paper we consider
simplistic environment model and introduce a navigation algorithm based on
Learning Classifier System.
</summary>
    <author>
      <name>Maxim Borisyak</name>
    </author>
    <author>
      <name>Andrey Ustyuzhanin</name>
    </author>
    <link href="http://arxiv.org/abs/1507.07374v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.07374v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T05" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.08322v1</id>
    <updated>2015-07-29T21:15:31Z</updated>
    <published>2015-07-29T21:15:31Z</published>
    <title>Distributed Mini-Batch SDCA</title>
    <summary>  We present an improved analysis of mini-batched stochastic dual coordinate
ascent for regularized empirical loss minimization (i.e. SVM and SVM-type
objectives). Our analysis allows for flexible sampling schemes, including where
data is distribute across machines, and combines a dependence on the smoothness
of the loss and/or the data spread (measured through the spectral norm).
</summary>
    <author>
      <name>Martin Takáč</name>
    </author>
    <author>
      <name>Peter Richtárik</name>
    </author>
    <author>
      <name>Nathan Srebro</name>
    </author>
    <link href="http://arxiv.org/abs/1507.08322v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.08322v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.04826v2</id>
    <updated>2015-08-26T12:59:38Z</updated>
    <published>2015-08-19T23:02:37Z</published>
    <title>Dither is Better than Dropout for Regularising Deep Neural Networks</title>
    <summary>  Regularisation of deep neural networks (DNN) during training is critical to
performance. By far the most popular method is known as dropout. Here, cast
through the prism of signal processing theory, we compare and contrast the
regularisation effects of dropout with those of dither. We illustrate some
serious inherent limitations of dropout and demonstrate that dither provides a
more effective regulariser.
</summary>
    <author>
      <name>Andrew J. R. Simpson</name>
    </author>
    <link href="http://arxiv.org/abs/1508.04826v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.04826v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68Txx" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1509.06095v1</id>
    <updated>2015-09-21T02:28:44Z</updated>
    <published>2015-09-21T02:28:44Z</published>
    <title>Multilayer bootstrap network for unsupervised speaker recognition</title>
    <summary>  We apply multilayer bootstrap network (MBN), a recent proposed unsupervised
learning method, to unsupervised speaker recognition. The proposed method first
extracts supervectors from an unsupervised universal background model, then
reduces the dimension of the high-dimensional supervectors by multilayer
bootstrap network, and finally conducts unsupervised speaker recognition by
clustering the low-dimensional data. The comparison results with 2 unsupervised
and 1 supervised speaker recognition techniques demonstrate the effectiveness
and robustness of the proposed method.
</summary>
    <author>
      <name>Xiao-Lei Zhang</name>
    </author>
    <link href="http://arxiv.org/abs/1509.06095v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1509.06095v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.03370v1</id>
    <updated>2015-10-12T17:14:44Z</updated>
    <published>2015-10-12T17:14:44Z</published>
    <title>Asymptotic Logical Uncertainty and The Benford Test</title>
    <summary>  We give an algorithm A which assigns probabilities to logical sentences. For
any simple infinite sequence of sentences whose truth-values appear
indistinguishable from a biased coin that outputs "true" with probability p, we
have that the sequence of probabilities that A assigns to these sentences
converges to p.
</summary>
    <author>
      <name>Scott Garrabrant</name>
    </author>
    <author>
      <name>Siddharth Bhaskar</name>
    </author>
    <author>
      <name>Abram Demski</name>
    </author>
    <author>
      <name>Joanna Garrabrant</name>
    </author>
    <author>
      <name>George Koleszarik</name>
    </author>
    <author>
      <name>Evan Lloyd</name>
    </author>
    <link href="http://arxiv.org/abs/1510.03370v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.03370v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.4.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.06567v1</id>
    <updated>2015-10-22T10:19:52Z</updated>
    <published>2015-10-22T10:19:52Z</published>
    <title>Generalized conditional gradient: analysis of convergence and
  applications</title>
    <summary>  The objectives of this technical report is to provide additional results on
the generalized conditional gradient methods introduced by Bredies et al.
[BLM05]. Indeed , when the objective function is smooth, we provide a novel
certificate of optimality and we show that the algorithm has a linear
convergence rate. Applications of this algorithm are also discussed.
</summary>
    <author>
      <name>Alain Rakotomamonjy</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LITIS</arxiv:affiliation>
    </author>
    <author>
      <name>Rémi Flamary</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LAGRANGE, OCA</arxiv:affiliation>
    </author>
    <author>
      <name>Nicolas Courty</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">OBELIX</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/1510.06567v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.06567v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.07303v1</id>
    <updated>2015-10-25T21:04:12Z</updated>
    <published>2015-10-25T21:04:12Z</published>
    <title>A Framework for Distributed Deep Learning Layer Design in Python</title>
    <summary>  In this paper, a framework for testing Deep Neural Network (DNN) design in
Python is presented. First, big data, machine learning (ML), and Artificial
Neural Networks (ANNs) are discussed to familiarize the reader with the
importance of such a system. Next, the benefits and detriments of implementing
such a system in Python are presented. Lastly, the specifics of the system are
explained, and some experimental results are presented to prove the
effectiveness of the system.
</summary>
    <author>
      <name>Clay McLeod</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1510.07303v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.07303v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.07641v2</id>
    <updated>2017-03-21T21:28:55Z</updated>
    <published>2015-10-26T20:18:56Z</published>
    <title>Phenotyping of Clinical Time Series with LSTM Recurrent Neural Networks</title>
    <summary>  We present a novel application of LSTM recurrent neural networks to
multilabel classification of diagnoses given variable-length time series of
clinical measurements. Our method outperforms a strong baseline on a variety of
metrics.
</summary>
    <author>
      <name>Zachary C. Lipton</name>
    </author>
    <author>
      <name>David C. Kale</name>
    </author>
    <author>
      <name>Randall C. Wetzel</name>
    </author>
    <link href="http://arxiv.org/abs/1510.07641v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.07641v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.03086v1</id>
    <updated>2015-11-10T12:30:42Z</updated>
    <published>2015-11-10T12:30:42Z</published>
    <title>The CTU Prague Relational Learning Repository</title>
    <summary>  The aim of the CTU Prague Relational Learning Repository is to support
machine learning research with multi-relational data. The repository currently
contains 50 SQL databases hosted on a public MySQL server located at
relational.fit.cvut.cz. A searchable meta-database provides metadata (e.g., the
number of tables in the database, the number of rows and columns in the tables,
the number of foreign key constraints between tables).
</summary>
    <author>
      <name>Jan Motl</name>
    </author>
    <author>
      <name>Oliver Schulte</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1511.03086v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.03086v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.6; H.2.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.05240v1</id>
    <updated>2015-11-17T01:14:51Z</updated>
    <published>2015-11-17T01:14:51Z</published>
    <title>An extension of McDiarmid's inequality</title>
    <summary>  We derive an extension of McDiarmid's inequality for functions $f$ with
bounded differences on a high probability set ${\cal Y}$ (instead of almost
surely). The behavior of $f$ outside ${\cal Y}$ may be arbitrary. The proof is
short and elementary, and relies on an extension argument similar to
Kirszbraun's theorem.
</summary>
    <author>
      <name>Richard Combes</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Note (4 pages)</arxiv:comment>
    <link href="http://arxiv.org/abs/1511.05240v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.05240v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1512.01926v1</id>
    <updated>2015-12-07T06:37:49Z</updated>
    <published>2015-12-07T06:37:49Z</published>
    <title>Thinking Required</title>
    <summary>  There exists a theory of a single general-purpose learning algorithm which
could explain the principles its operation. It assumes the initial rough
architecture, a small library of simple innate circuits which are prewired at
birth. and proposes that all significant mental algorithms are learned. Given
current understanding and observations, this paper reviews and lists the
ingredients of such an algorithm from architectural and functional
perspectives.
</summary>
    <author>
      <name>Kamil Rocki</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1512.01926v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1512.01926v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1512.03375v1</id>
    <updated>2015-12-10T19:32:48Z</updated>
    <published>2015-12-10T19:32:48Z</published>
    <title>Convolutional Monte Carlo Rollouts in Go</title>
    <summary>  In this work, we present a MCTS-based Go-playing program which uses
convolutional networks in all parts. Our method performs MCTS in batches,
explores the Monte Carlo search tree using Thompson sampling and a
convolutional network, and evaluates convnet-based rollouts on the GPU. We
achieve strong win rates against open source Go programs and attain competitive
results against state of the art convolutional net-based Go-playing programs.
</summary>
    <author>
      <name>Peter H. Jin</name>
    </author>
    <author>
      <name>Kurt Keutzer</name>
    </author>
    <link href="http://arxiv.org/abs/1512.03375v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1512.03375v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1512.06927v4</id>
    <updated>2016-04-12T17:34:29Z</updated>
    <published>2015-12-22T01:27:23Z</published>
    <title>A C++ library for Multimodal Deep Learning</title>
    <summary>  MDL, Multimodal Deep Learning Library, is a deep learning framework that
supports multiple models, and this document explains its philosophy and
functionality. MDL runs on Linux, Mac, and Unix platforms. It depends on
OpenCV.
</summary>
    <author>
      <name>Jian Jin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">27 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1512.06927v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1512.06927v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1602.01582v2</id>
    <updated>2016-05-21T12:33:05Z</updated>
    <published>2016-02-04T08:14:06Z</published>
    <title>SDCA without Duality, Regularization, and Individual Convexity</title>
    <summary>  Stochastic Dual Coordinate Ascent is a popular method for solving regularized
loss minimization for the case of convex losses. We describe variants of SDCA
that do not require explicit regularization and do not rely on duality. We
prove linear convergence rates even if individual loss functions are
non-convex, as long as the expected loss is strongly convex.
</summary>
    <author>
      <name>Shai Shalev-Shwartz</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICML 2016</arxiv:comment>
    <link href="http://arxiv.org/abs/1602.01582v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1602.01582v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1602.02350v2</id>
    <updated>2016-05-26T07:42:58Z</updated>
    <published>2016-02-07T08:37:18Z</published>
    <title>Solving Ridge Regression using Sketched Preconditioned SVRG</title>
    <summary>  We develop a novel preconditioning method for ridge regression, based on
recent linear sketching methods. By equipping Stochastic Variance Reduced
Gradient (SVRG) with this preconditioning process, we obtain a significant
speed-up relative to fast stochastic methods such as SVRG, SDCA and SAG.
</summary>
    <author>
      <name>Alon Gonen</name>
    </author>
    <author>
      <name>Francesco Orabona</name>
    </author>
    <author>
      <name>Shai Shalev-Shwartz</name>
    </author>
    <link href="http://arxiv.org/abs/1602.02350v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1602.02350v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1602.06183v1</id>
    <updated>2016-02-19T15:36:38Z</updated>
    <published>2016-02-19T15:36:38Z</published>
    <title>Node-By-Node Greedy Deep Learning for Interpretable Features</title>
    <summary>  Multilayer networks have seen a resurgence under the umbrella of deep
learning. Current deep learning algorithms train the layers of the network
sequentially, improving algorithmic performance as well as providing some
regularization. We present a new training algorithm for deep networks which
trains \emph{each node in the network} sequentially. Our algorithm is orders of
magnitude faster, creates more interpretable internal representations at the
node level, while not sacrificing on the ultimate out-of-sample performance.
</summary>
    <author>
      <name>Ke Wu</name>
    </author>
    <author>
      <name>Malik Magdon-Ismail</name>
    </author>
    <link href="http://arxiv.org/abs/1602.06183v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1602.06183v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.02010v1</id>
    <updated>2016-03-07T11:23:57Z</updated>
    <published>2016-03-07T11:23:57Z</published>
    <title>Differentially Private Policy Evaluation</title>
    <summary>  We present the first differentially private algorithms for reinforcement
learning, which apply to the task of evaluating a fixed policy. We establish
two approaches for achieving differential privacy, provide a theoretical
analysis of the privacy and utility of the two algorithms, and show promising
results on simple empirical examples.
</summary>
    <author>
      <name>Borja Balle</name>
    </author>
    <author>
      <name>Maziar Gomrokchi</name>
    </author>
    <author>
      <name>Doina Precup</name>
    </author>
    <link href="http://arxiv.org/abs/1603.02010v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.02010v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.02185v1</id>
    <updated>2016-03-07T18:11:54Z</updated>
    <published>2016-03-07T18:11:54Z</published>
    <title>Distributed Multi-Task Learning with Shared Representation</title>
    <summary>  We study the problem of distributed multi-task learning with shared
representation, where each machine aims to learn a separate, but related, task
in an unknown shared low-dimensional subspaces, i.e. when the predictor matrix
has low rank. We consider a setting where each task is handled by a different
machine, with samples for the task available locally on the machine, and study
communication-efficient methods for exploiting the shared structure.
</summary>
    <author>
      <name>Jialei Wang</name>
    </author>
    <author>
      <name>Mladen Kolar</name>
    </author>
    <author>
      <name>Nathan Srebro</name>
    </author>
    <link href="http://arxiv.org/abs/1603.02185v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.02185v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.02578v1</id>
    <updated>2016-03-08T16:36:31Z</updated>
    <published>2016-03-08T16:36:31Z</published>
    <title>Batched Lazy Decision Trees</title>
    <summary>  We introduce a batched lazy algorithm for supervised classification using
decision trees. It avoids unnecessary visits to irrelevant nodes when it is
used to make predictions with either eagerly or lazily trained decision trees.
A set of experiments demonstrate that the proposed algorithm can outperform
both the conventional and lazy decision tree algorithms in terms of computation
time as well as memory consumption, without compromising accuracy.
</summary>
    <author>
      <name>Mathieu Guillame-Bert</name>
    </author>
    <author>
      <name>Artur Dubrawski</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 2 figures, 3 tables, 3 algorithms</arxiv:comment>
    <link href="http://arxiv.org/abs/1603.02578v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.02578v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.06653v1</id>
    <updated>2016-03-22T01:05:47Z</updated>
    <published>2016-03-22T01:05:47Z</published>
    <title>Information Theoretic-Learning Auto-Encoder</title>
    <summary>  We propose Information Theoretic-Learning (ITL) divergence measures for
variational regularization of neural networks. We also explore ITL-regularized
autoencoders as an alternative to variational autoencoding bayes, adversarial
autoencoders and generative adversarial networks for randomly generating sample
data without explicitly defining a partition function. This paper also
formalizes, generative moment matching networks under the ITL framework.
</summary>
    <author>
      <name>Eder Santana</name>
    </author>
    <author>
      <name>Matthew Emigh</name>
    </author>
    <author>
      <name>Jose C Principe</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1603.06653v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.06653v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.00772v1</id>
    <updated>2016-04-04T08:16:12Z</updated>
    <published>2016-04-04T08:16:12Z</published>
    <title>The CMA Evolution Strategy: A Tutorial</title>
    <summary>  This tutorial introduces the CMA Evolution Strategy (ES), where CMA stands
for Covariance Matrix Adaptation. The CMA-ES is a stochastic, or randomized,
method for real-parameter (continuous domain) optimization of non-linear,
non-convex functions. We try to motivate and derive the algorithm from
intuitive concepts and from requirements of non-linear, non-convex search in
continuous domain.
</summary>
    <author>
      <name>Nikolaus Hansen</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Inria</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ArXiv e-prints, arXiv:1604.xxxxx</arxiv:comment>
    <link href="http://arxiv.org/abs/1604.00772v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.00772v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.07078v1</id>
    <updated>2016-04-24T20:32:18Z</updated>
    <published>2016-04-24T20:32:18Z</published>
    <title>Unsupervised Representation Learning of Structured Radio Communication
  Signals</title>
    <summary>  We explore unsupervised representation learning of radio communication
signals in raw sampled time series representation. We demonstrate that we can
learn modulation basis functions using convolutional autoencoders and visually
recognize their relationship to the analytic bases used in digital
communications. We also propose and evaluate quantitative met- rics for quality
of encoding using domain relevant performance metrics.
</summary>
    <author>
      <name>Timothy J. O'Shea</name>
    </author>
    <author>
      <name>Johnathan Corgan</name>
    </author>
    <author>
      <name>T. Charles Clancy</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 9 figures, currently under conference submission</arxiv:comment>
    <link href="http://arxiv.org/abs/1604.07078v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.07078v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.00251v1</id>
    <updated>2016-05-01T13:19:57Z</updated>
    <published>2016-05-01T13:19:57Z</published>
    <title>A vector-contraction inequality for Rademacher complexities</title>
    <summary>  The contraction inequality for Rademacher averages is extended to Lipschitz
functions with vector-valued domains, and it is also shown that in the bounding
expression the Rademacher variables can be replaced by arbitrary iid symmetric
and sub-gaussian variables. Example applications are given for multi-category
learning, K-means clustering and learning-to-learn.
</summary>
    <author>
      <name>Andreas Maurer</name>
    </author>
    <link href="http://arxiv.org/abs/1605.00251v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.00251v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.00404v1</id>
    <updated>2016-05-02T09:33:46Z</updated>
    <published>2016-05-02T09:33:46Z</published>
    <title>Simple2Complex: Global Optimization by Gradient Descent</title>
    <summary>  A method named simple2complex for modeling and training deep neural networks
is proposed. Simple2complex train deep neural networks by smoothly adding more
and more layers to the shallow networks, as the learning procedure going on,
the network is just like growing. Compared with learning by end2end,
simple2complex is with less possibility trapping into local minimal, namely,
owning ability for global optimization. Cifar10 is used for verifying the
superiority of simple2complex.
</summary>
    <author>
      <name>Ming Li</name>
    </author>
    <link href="http://arxiv.org/abs/1605.00404v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.00404v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.02099v1</id>
    <updated>2016-05-06T20:52:26Z</updated>
    <published>2016-05-06T20:52:26Z</published>
    <title>Some Simulation Results for Emphatic Temporal-Difference Learning
  Algorithms</title>
    <summary>  This is a companion note to our recent study of the weak convergence
properties of constrained emphatic temporal-difference learning (ETD)
algorithms from a theoretic perspective. It supplements the latter analysis
with simulation results and illustrates the behavior of some of the ETD
algorithms using three example problems.
</summary>
    <author>
      <name>Huizhen Yu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">A companion note to the article arxiv:1511.07471; 30 pages; 34
  figures, best viewed on screen</arxiv:comment>
    <link href="http://arxiv.org/abs/1605.02099v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.02099v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.08497v1</id>
    <updated>2016-05-27T03:11:41Z</updated>
    <published>2016-05-27T03:11:41Z</published>
    <title>Universum Learning for SVM Regression</title>
    <summary>  This paper extends the idea of Universum learning [18, 19] to regression
problems. We propose new Universum-SVM formulation for regression problems that
incorporates a priori knowledge in the form of additional data samples. These
additional data samples or Universum belong to the same application domain as
the training samples, but they follow a different distribution. Several
empirical comparisons are presented to illustrate the utility of the proposed
approach.
</summary>
    <author>
      <name>Sauptik Dhar</name>
    </author>
    <author>
      <name>Vladimir Cherkassky</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages,11 figures, Thesis:
  http://conservancy.umn.edu/handle/11299/162636</arxiv:comment>
    <link href="http://arxiv.org/abs/1605.08497v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.08497v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.08833v1</id>
    <updated>2016-05-28T02:39:24Z</updated>
    <published>2016-05-28T02:39:24Z</published>
    <title>Muffled Semi-Supervised Learning</title>
    <summary>  We explore a novel approach to semi-supervised learning. This approach is
contrary to the common approach in that the unlabeled examples serve to
"muffle," rather than enhance, the guidance provided by the labeled examples.
We provide several variants of the basic algorithm and show experimentally that
they can achieve significantly higher AUC than boosted trees, random forests
and logistic regression when unlabeled examples are available.
</summary>
    <author>
      <name>Akshay Balsubramani</name>
    </author>
    <author>
      <name>Yoav Freund</name>
    </author>
    <link href="http://arxiv.org/abs/1605.08833v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.08833v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.00398v1</id>
    <updated>2016-06-01T18:57:54Z</updated>
    <published>2016-06-01T18:57:54Z</published>
    <title>Short Communication on QUIST: A Quick Clustering Algorithm</title>
    <summary>  In this short communication we introduce the quick clustering algorithm
(QUIST), an efficient hierarchical clustering algorithm based on sorting. QUIST
is a poly-logarithmic divisive clustering algorithm that does not assume the
number of clusters, and/or the cluster size to be known ahead of time. It is
also insensitive to the original ordering of the input.
</summary>
    <author>
      <name>Sherenaz W. Al-Haj Baddar</name>
    </author>
    <link href="http://arxiv.org/abs/1606.00398v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.00398v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T05" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.01540v1</id>
    <updated>2016-06-05T17:54:48Z</updated>
    <published>2016-06-05T17:54:48Z</published>
    <title>OpenAI Gym</title>
    <summary>  OpenAI Gym is a toolkit for reinforcement learning research. It includes a
growing collection of benchmark problems that expose a common interface, and a
website where people can share their results and compare the performance of
algorithms. This whitepaper discusses the components of OpenAI Gym and the
design decisions that went into the software.
</summary>
    <author>
      <name>Greg Brockman</name>
    </author>
    <author>
      <name>Vicki Cheung</name>
    </author>
    <author>
      <name>Ludwig Pettersson</name>
    </author>
    <author>
      <name>Jonas Schneider</name>
    </author>
    <author>
      <name>John Schulman</name>
    </author>
    <author>
      <name>Jie Tang</name>
    </author>
    <author>
      <name>Wojciech Zaremba</name>
    </author>
    <link href="http://arxiv.org/abs/1606.01540v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.01540v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.05664v1</id>
    <updated>2016-05-31T09:54:46Z</updated>
    <published>2016-05-31T09:54:46Z</published>
    <title>Linear Classification of data with Support Vector Machines and
  Generalized Support Vector Machines</title>
    <summary>  In this paper, we study the support vector machine and introduced the notion
of generalized support vector machine for classification of data. We show that
the problem of generalized support vector machine is equivalent to the problem
of generalized variational inequality and establish various results for the
existence of solutions. Moreover, we provide various examples to support our
results.
</summary>
    <author>
      <name>Xiaomin Qi</name>
    </author>
    <author>
      <name>Sergei Silvestrov</name>
    </author>
    <author>
      <name>Talat Nazir</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1063/1.4972718</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1063/1.4972718" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">submitted</arxiv:comment>
    <link href="http://arxiv.org/abs/1606.05664v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.05664v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.00466v1</id>
    <updated>2016-07-02T04:48:59Z</updated>
    <published>2016-07-02T04:48:59Z</published>
    <title>Outlier absorbing based on a Bayesian approach</title>
    <summary>  The presence of outliers is prevalent in machine learning applications and
may produce misleading results. In this paper a new method for dealing with
outliers and anomal samples is proposed. To overcome the outlier issue, the
proposed method combines the global and local views of the samples. By
combination of these views, our algorithm performs in a robust manner. The
experimental results show the capabilities of the proposed method.
</summary>
    <author>
      <name>Parsa Bagherzadeh</name>
    </author>
    <author>
      <name>Hadi Sadoghi Yazdi</name>
    </author>
    <link href="http://arxiv.org/abs/1607.00466v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.00466v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.03626v1</id>
    <updated>2016-07-13T08:03:35Z</updated>
    <published>2016-07-13T08:03:35Z</published>
    <title>San Francisco Crime Classification</title>
    <summary>  San Francisco Crime Classification is an online competition administered by
Kaggle Inc. The competition aims at predicting the future crimes based on a
given set of geographical and time-based features. In this paper, I achieved a
an accuracy that ranks at top %18, as of May 19th, 2016. I will explore the
data, and explain in details the tools I used to achieve that result.
</summary>
    <author>
      <name>Yehya Abouelnaga</name>
    </author>
    <link href="http://arxiv.org/abs/1607.03626v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.03626v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.03849v2</id>
    <updated>2016-08-02T15:34:40Z</updated>
    <published>2016-07-13T18:15:52Z</published>
    <title>Fitting a Simplicial Complex using a Variation of k-means</title>
    <summary>  We give a simple and effective two stage algorithm for approximating a point
cloud $\mathcal{S}\subset\mathbb{R}^m$ by a simplicial complex $K$. The first
stage is an iterative fitting procedure that generalizes k-means clustering,
while the second stage involves deleting redundant simplices. A form of
dimension reduction of $\mathcal{S}$ is obtained as a consequence.
</summary>
    <author>
      <name>Piotr Beben</name>
    </author>
    <link href="http://arxiv.org/abs/1607.03849v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.03849v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.02126v1</id>
    <updated>2016-08-06T16:30:47Z</updated>
    <published>2016-08-06T16:30:47Z</published>
    <title>How Much Did it Rain? Predicting Real Rainfall Totals Based on Radar
  Data</title>
    <summary>  We applied a variety of parametric and non-parametric machine learning models
to predict the probability distribution of rainfall based on 1M training
examples over a single year across several U.S. states. Our top performing
model based on a squared loss objective was a cross-validated parametric
k-nearest-neighbor predictor that took about six days to compute, and was
competitive in a world-wide competition.
</summary>
    <author>
      <name>Adam Lesnikowski</name>
    </author>
    <link href="http://arxiv.org/abs/1608.02126v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.02126v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.03647v2</id>
    <updated>2017-04-23T16:46:17Z</updated>
    <published>2016-08-12T07:24:57Z</published>
    <title>Learning with Value-Ramp</title>
    <summary>  We study a learning principle based on the intuition of forming ramps. The
agent tries to follow an increasing sequence of values until the agent meets a
peak of reward. The resulting Value-Ramp algorithm is natural, easy to
configure, and has a robust implementation with natural numbers.
</summary>
    <author>
      <name>Tom J. Ameloot</name>
    </author>
    <author>
      <name>Jan Van den Bussche</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Version 2: fixed notation in definition of transition + clarified a
  sentence in the Introduction</arxiv:comment>
    <link href="http://arxiv.org/abs/1608.03647v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.03647v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.06664v1</id>
    <updated>2016-08-23T22:44:42Z</updated>
    <published>2016-08-23T22:44:42Z</published>
    <title>Topic Grids for Homogeneous Data Visualization</title>
    <summary>  We propose the topic grids to detect anomaly and analyze the behavior based
on the access log content. Content-based behavioral risk is quantified in the
high dimensional space where the topics are generated from the log. The topics
are being projected homogeneously into a space that is perception- and
interaction-friendly to the human experts.
</summary>
    <author>
      <name>Shih-Chieh Su</name>
    </author>
    <author>
      <name>Joseph Vaughn</name>
    </author>
    <author>
      <name>Jean-Laurent Huynh</name>
    </author>
    <link href="http://arxiv.org/abs/1608.06664v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.06664v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.06146v1</id>
    <updated>2016-09-18T01:08:20Z</updated>
    <published>2016-09-18T01:08:20Z</published>
    <title>mlr Tutorial</title>
    <summary>  This document provides and in-depth introduction to the mlr framework for
machine learning experiments in R.
</summary>
    <author>
      <name>Julia Schiffner</name>
    </author>
    <author>
      <name>Bernd Bischl</name>
    </author>
    <author>
      <name>Michel Lang</name>
    </author>
    <author>
      <name>Jakob Richter</name>
    </author>
    <author>
      <name>Zachary M. Jones</name>
    </author>
    <author>
      <name>Philipp Probst</name>
    </author>
    <author>
      <name>Florian Pfisterer</name>
    </author>
    <author>
      <name>Mason Gallo</name>
    </author>
    <author>
      <name>Dominik Kirchhoff</name>
    </author>
    <author>
      <name>Tobias Kühn</name>
    </author>
    <author>
      <name>Janek Thomas</name>
    </author>
    <author>
      <name>Lars Kotthoff</name>
    </author>
    <link href="http://arxiv.org/abs/1609.06146v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.06146v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.09162v1</id>
    <updated>2016-09-29T00:43:03Z</updated>
    <published>2016-09-29T00:43:03Z</published>
    <title>Universum Learning for Multiclass SVM</title>
    <summary>  We introduce Universum learning for multiclass problems and propose a novel
formulation for multiclass universum SVM (MU-SVM). We also propose a span bound
for MU-SVM that can be used for model selection thereby avoiding resampling.
Empirical results demonstrate the effectiveness of MU-SVM and the proposed
bound.
</summary>
    <author>
      <name>Sauptik Dhar</name>
    </author>
    <author>
      <name>Naveen Ramakrishnan</name>
    </author>
    <author>
      <name>Vladimir Cherkassky</name>
    </author>
    <author>
      <name>Mohak Shah</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 12 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1609.09162v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.09162v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1610.00564v1</id>
    <updated>2016-10-03T14:22:19Z</updated>
    <published>2016-10-03T14:22:19Z</published>
    <title>End-to-End Radio Traffic Sequence Recognition with Deep Recurrent Neural
  Networks</title>
    <summary>  We investigate sequence machine learning techniques on raw radio signal
time-series data. By applying deep recurrent neural networks we learn to
discriminate between several application layer traffic types on top of a
constant envelope modulation without using an expert demodulation algorithm. We
show that complex protocol sequences can be learned and used for both
classification and generation tasks using this approach.
</summary>
    <author>
      <name>Timothy J. O'Shea</name>
    </author>
    <author>
      <name>Seth Hitefield</name>
    </author>
    <author>
      <name>Johnathan Corgan</name>
    </author>
    <link href="http://arxiv.org/abs/1610.00564v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1610.00564v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1610.03793v2</id>
    <updated>2017-09-28T11:28:26Z</updated>
    <published>2016-10-12T17:18:01Z</published>
    <title>Introduction to the "Industrial Benchmark"</title>
    <summary>  A novel reinforcement learning benchmark, called Industrial Benchmark, is
introduced. The Industrial Benchmark aims at being be realistic in the sense,
that it includes a variety of aspects that we found to be vital in industrial
applications. It is not designed to be an approximation of any real system, but
to pose the same hardness and complexity.
</summary>
    <author>
      <name>Daniel Hein</name>
    </author>
    <author>
      <name>Alexander Hentschel</name>
    </author>
    <author>
      <name>Volkmar Sterzing</name>
    </author>
    <author>
      <name>Michel Tokic</name>
    </author>
    <author>
      <name>Steffen Udluft</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1610.03793v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1610.03793v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1611.00862v1</id>
    <updated>2016-11-03T02:28:53Z</updated>
    <published>2016-11-03T02:28:53Z</published>
    <title>Quantile Reinforcement Learning</title>
    <summary>  In reinforcement learning, the standard criterion to evaluate policies in a
state is the expectation of (discounted) sum of rewards. However, this
criterion may not always be suitable, we consider an alternative criterion
based on the notion of quantiles. In the case of episodic reinforcement
learning problems, we propose an algorithm based on stochastic approximation
with two timescales. We evaluate our proposition on a simple model of the TV
show, Who wants to be a millionaire.
</summary>
    <author>
      <name>Hugo Gilbert</name>
    </author>
    <author>
      <name>Paul Weng</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">AWRL 2016</arxiv:comment>
    <link href="http://arxiv.org/abs/1611.00862v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1611.00862v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1611.01964v1</id>
    <updated>2016-11-07T10:10:43Z</updated>
    <published>2016-11-07T10:10:43Z</published>
    <title>Log-time and Log-space Extreme Classification</title>
    <summary>  We present LTLS, a technique for multiclass and multilabel prediction that
can perform training and inference in logarithmic time and space. LTLS embeds
large classification problems into simple structured prediction problems and
relies on efficient dynamic programming algorithms for inference. We train LTLS
with stochastic gradient descent on a number of multiclass and multilabel
datasets and show that despite its small memory footprint it is often
competitive with existing approaches.
</summary>
    <author>
      <name>Kalina Jasinska</name>
    </author>
    <author>
      <name>Nikos Karampatziakis</name>
    </author>
    <link href="http://arxiv.org/abs/1611.01964v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1611.01964v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1611.05955v1</id>
    <updated>2016-11-18T02:33:10Z</updated>
    <published>2016-11-18T02:33:10Z</published>
    <title>A Characterization of Prediction Errors</title>
    <summary>  Understanding prediction errors and determining how to fix them is critical
to building effective predictive systems. In this paper, we delineate four
types of prediction errors and demonstrate that these four types characterize
all prediction errors. In addition, we describe potential remedies and tools
that can be used to reduce the uncertainty when trying to determine the source
of a prediction error and when trying to take action to remove a prediction
errors.
</summary>
    <author>
      <name>Christopher Meek</name>
    </author>
    <link href="http://arxiv.org/abs/1611.05955v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1611.05955v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.09122v1</id>
    <updated>2016-12-29T12:29:20Z</updated>
    <published>2016-12-29T12:29:20Z</published>
    <title>Modeling documents with Generative Adversarial Networks</title>
    <summary>  This paper describes a method for using Generative Adversarial Networks to
learn distributed representations of natural language documents. We propose a
model that is based on the recently proposed Energy-Based GAN, but instead uses
a Denoising Autoencoder as the discriminator network. Document representations
are extracted from the hidden layer of the discriminator and evaluated both
quantitatively and qualitatively.
</summary>
    <author>
      <name>John Glover</name>
    </author>
    <link href="http://arxiv.org/abs/1612.09122v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.09122v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.09147v2</id>
    <updated>2017-01-26T16:44:56Z</updated>
    <published>2016-12-29T14:02:31Z</published>
    <title>Linear Learning with Sparse Data</title>
    <summary>  Linear predictors are especially useful when the data is high-dimensional and
sparse. One of the standard techniques used to train a linear predictor is the
Averaged Stochastic Gradient Descent (ASGD) algorithm. We present an efficient
implementation of ASGD that avoids dense vector operations. We also describe a
translation invariant extension called Centered Averaged Stochastic Gradient
Descent (CASGD).
</summary>
    <author>
      <name>Ofer Dekel</name>
    </author>
    <link href="http://arxiv.org/abs/1612.09147v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.09147v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.02377v1</id>
    <updated>2017-01-09T22:29:08Z</updated>
    <published>2017-01-09T22:29:08Z</published>
    <title>The principle of cognitive action - Preliminary experimental analysis</title>
    <summary>  In this document we shows a first implementation and some preliminary results
of a new theory, facing Machine Learning problems in the frameworks of
Classical Mechanics and Variational Calculus. We give a general formulation of
the problem and then we studies basic behaviors of the model on simple
practical implementations.
</summary>
    <author>
      <name>Marco Gori</name>
    </author>
    <author>
      <name>Marco Maggini</name>
    </author>
    <author>
      <name>Alessandro Rossi</name>
    </author>
    <link href="http://arxiv.org/abs/1701.02377v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.02377v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.05487v1</id>
    <updated>2017-01-19T15:48:11Z</updated>
    <published>2017-01-19T15:48:11Z</published>
    <title>Learning first-order definable concepts over structures of small degree</title>
    <summary>  We consider a declarative framework for machine learning where concepts and
hypotheses are defined by formulas of a logic over some background structure.
We show that within this framework, concepts defined by first-order formulas
over a background structure of at most polylogarithmic degree can be learned in
polylogarithmic time in the "probably approximately correct" learning sense.
</summary>
    <author>
      <name>Martin Grohe</name>
    </author>
    <author>
      <name>Martin Ritzert</name>
    </author>
    <link href="http://arxiv.org/abs/1701.05487v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.05487v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.08305v1</id>
    <updated>2017-01-28T17:45:58Z</updated>
    <published>2017-01-28T17:45:58Z</published>
    <title>Multiclass MinMax Rank Aggregation</title>
    <summary>  We introduce a new family of minmax rank aggregation problems under two
distance measures, the Kendall {\tau} and the Spearman footrule. As the
problems are NP-hard, we proceed to describe a number of constant-approximation
algorithms for solving them. We conclude with illustrative applications of the
aggregation methods on the Mallows model and genomic data.
</summary>
    <author>
      <name>Pan Li</name>
    </author>
    <author>
      <name>Olgica Milenkovic</name>
    </author>
    <link href="http://arxiv.org/abs/1701.08305v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.08305v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.08511v1</id>
    <updated>2017-01-30T08:37:25Z</updated>
    <published>2017-01-30T08:37:25Z</published>
    <title>Binary adaptive embeddings from order statistics of random projections</title>
    <summary>  We use some of the largest order statistics of the random projections of a
reference signal to construct a binary embedding that is adapted to signals
correlated with such signal. The embedding is characterized from the analytical
standpoint and shown to provide improved performance on tasks such as
classification in a reduced-dimensionality space.
</summary>
    <author>
      <name>Diego Valsesia</name>
    </author>
    <author>
      <name>Enrico Magli</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/LSP.2016.2639036</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/LSP.2016.2639036" rel="related"/>
    <link href="http://arxiv.org/abs/1701.08511v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.08511v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1702.06120v1</id>
    <updated>2017-02-20T10:09:02Z</updated>
    <published>2017-02-20T10:09:02Z</published>
    <title>On the Consistency of $k$-means++ algorithm</title>
    <summary>  We prove in this paper that the expected value of the objective function of
the $k$-means++ algorithm for samples converges to population expected value.
As $k$-means++, for samples, provides with constant factor approximation for
$k$-means objectives, such an approximation can be achieved for the population
with increase of the sample size.
  This result is of potential practical relevance when one is considering using
subsampling when clustering large data sets (large data bases).
</summary>
    <author>
      <name>Mieczysław A. Kłopotek</name>
    </author>
    <link href="http://arxiv.org/abs/1702.06120v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1702.06120v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1702.06533v1</id>
    <updated>2017-02-21T04:23:41Z</updated>
    <published>2017-02-21T04:23:41Z</published>
    <title>Stochastic Canonical Correlation Analysis</title>
    <summary>  We tightly analyze the sample complexity of CCA, provide a learning algorithm
that achieves optimal statistical performance in time linear in the required
number of samples (up to log factors), as well as a streaming algorithm with
similar guarantees.
</summary>
    <author>
      <name>Chao Gao</name>
    </author>
    <author>
      <name>Dan Garber</name>
    </author>
    <author>
      <name>Nathan Srebro</name>
    </author>
    <author>
      <name>Jialei Wang</name>
    </author>
    <author>
      <name>Weiran Wang</name>
    </author>
    <link href="http://arxiv.org/abs/1702.06533v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1702.06533v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1702.06818v1</id>
    <updated>2017-02-22T14:45:02Z</updated>
    <published>2017-02-22T14:45:02Z</published>
    <title>Stochastic Approximation for Canonical Correlation Analysis</title>
    <summary>  We study canonical correlation analysis (CCA) as a stochastic optimization
problem. We show that regularized CCA is efficiently PAC-learnable. We give
stochastic approximation (SA) algorithms that are instances of stochastic
mirror descent, which achieve $\epsilon$-suboptimality in the population
objective in time $\operatorname{poly}(\frac{1}{\epsilon},\frac{1}{\delta},d)$
with probability $1-\delta$, where $d$ is the input dimensionality.
</summary>
    <author>
      <name>Raman Arora</name>
    </author>
    <author>
      <name>Teodor V. Marinov</name>
    </author>
    <author>
      <name>Poorya Mianjy</name>
    </author>
    <link href="http://arxiv.org/abs/1702.06818v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1702.06818v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1702.06914v3</id>
    <updated>2017-04-08T00:40:26Z</updated>
    <published>2017-02-22T17:54:03Z</published>
    <title>Training a Subsampling Mechanism in Expectation</title>
    <summary>  We describe a mechanism for subsampling sequences and show how to compute its
expected output so that it can be trained with standard backpropagation. We
test this approach on a simple toy problem and discuss its shortcomings.
</summary>
    <author>
      <name>Colin Raffel</name>
    </author>
    <author>
      <name>Dieterich Lawson</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Camera-ready version. Includes additional figures in an appendix</arxiv:comment>
    <link href="http://arxiv.org/abs/1702.06914v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1702.06914v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1702.08398v2</id>
    <updated>2017-06-08T23:45:25Z</updated>
    <published>2017-02-27T17:46:30Z</published>
    <title>McGan: Mean and Covariance Feature Matching GAN</title>
    <summary>  We introduce new families of Integral Probability Metrics (IPM) for training
Generative Adversarial Networks (GAN). Our IPMs are based on matching
statistics of distributions embedded in a finite dimensional feature space.
Mean and covariance feature matching IPMs allow for stable training of GANs,
which we will call McGan. McGan minimizes a meaningful loss between
distributions.
</summary>
    <author>
      <name>Youssef Mroueh</name>
    </author>
    <author>
      <name>Tom Sercu</name>
    </author>
    <author>
      <name>Vaibhava Goel</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages; published at ICML 2017</arxiv:comment>
    <link href="http://arxiv.org/abs/1702.08398v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1702.08398v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1702.08553v2</id>
    <updated>2017-06-09T00:39:57Z</updated>
    <published>2017-02-27T21:59:24Z</published>
    <title>Diameter-Based Active Learning</title>
    <summary>  To date, the tightest upper and lower-bounds for the active learning of
general concept classes have been in terms of a parameter of the learning
problem called the splitting index. We provide, for the first time, an
efficient algorithm that is able to realize this upper bound, and we
empirically demonstrate its good performance.
</summary>
    <author>
      <name>Christopher Tosh</name>
    </author>
    <author>
      <name>Sanjoy Dasgupta</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1702.08553v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1702.08553v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.01830v1</id>
    <updated>2017-03-06T12:06:58Z</updated>
    <published>2017-03-06T12:06:58Z</published>
    <title>Decomposable Submodular Function Minimization: Discrete and Continuous</title>
    <summary>  This paper investigates connections between discrete and continuous
approaches for decomposable submodular function minimization. We provide
improved running time estimates for the state-of-the-art continuous algorithms
for the problem using combinatorial arguments. We also provide a systematic
experimental comparison of the two types of methods, based on a clear
distinction between level-0 and level-1 algorithms.
</summary>
    <author>
      <name>Alina Ene</name>
    </author>
    <author>
      <name>Huy L. Nguyen</name>
    </author>
    <author>
      <name>László A. Végh</name>
    </author>
    <link href="http://arxiv.org/abs/1703.01830v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.01830v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.06485v1</id>
    <updated>2017-03-19T18:25:52Z</updated>
    <published>2017-03-19T18:25:52Z</published>
    <title>Near Optimal Hamiltonian-Control and Learning via Chattering</title>
    <summary>  Many applications require solving non-linear control problems that are
classically not well behaved. This paper develops a simple and efficient
chattering algorithm that learns near optimal decision policies through an
open-loop feedback strategy. The optimal control problem reduces to a series of
linear optimization programs that can be easily solved to recover a relaxed
optimal trajectory. This algorithm is implemented on a real-time enterprise
scheduling and control process.
</summary>
    <author>
      <name>Peeyush Kumar</name>
    </author>
    <author>
      <name>Wolf Kohn</name>
    </author>
    <author>
      <name>Zelda B. Zabinsky</name>
    </author>
    <link href="http://arxiv.org/abs/1703.06485v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.06485v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1704.05041v1</id>
    <updated>2017-04-17T17:32:05Z</updated>
    <published>2017-04-17T17:32:05Z</published>
    <title>Fast multi-output relevance vector regression</title>
    <summary>  This paper aims to decrease the time complexity of multi-output relevance
vector regression from O(VM^3) to O(V^3+M^3), where V is the number of output
dimensions, M is the number of basis functions, and V&lt;M. The experimental
results demonstrate that the proposed method is more competitive than the
existing method, with regard to computation time. MATLAB codes are available at
http://www.mathworks.com/matlabcentral/fileexchange/49131.
</summary>
    <author>
      <name>Youngmin Ha</name>
    </author>
    <link href="http://arxiv.org/abs/1704.05041v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1704.05041v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1704.07139v1</id>
    <updated>2017-04-24T10:55:41Z</updated>
    <published>2017-04-24T10:55:41Z</published>
    <title>An Aposteriorical Clusterability Criterion for $k$-Means and Simplicity
  of Clustering</title>
    <summary>  We define the notion of a well-clusterable data set from the point of view of
the objective of $k$-means clustering algorithm and common sense. The novelty
introduced here is that one can a posteriori (after running $k$-means) check if
the data set is well-clusterable or not.
</summary>
    <author>
      <name>Mieczysław A. Kłopotek</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">37 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1704.07139v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1704.07139v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.03613v1</id>
    <updated>2017-05-10T06:19:04Z</updated>
    <published>2017-05-10T06:19:04Z</published>
    <title>An initialization method for the k-means using the concept of useful
  nearest centers</title>
    <summary>  The aim of the k-means is to minimize squared sum of Euclidean distance from
the mean (SSEDM) of each cluster. The k-means can effectively optimize this
function, but it is too sensitive for initial centers (seeds). This paper
proposed a method for initialization of the k-means using the concept of useful
nearest center for each data point.
</summary>
    <author>
      <name>Hassan Ismkhan</name>
    </author>
    <link href="http://arxiv.org/abs/1705.03613v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.03613v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.05264v1</id>
    <updated>2017-05-15T14:25:15Z</updated>
    <published>2017-05-15T14:25:15Z</published>
    <title>Extending Defensive Distillation</title>
    <summary>  Machine learning is vulnerable to adversarial examples: inputs carefully
modified to force misclassification. Designing defenses against such inputs
remains largely an open problem. In this work, we revisit defensive
distillation---which is one of the mechanisms proposed to mitigate adversarial
examples---to address its limitations. We view our results not only as an
effective way of addressing some of the recently discovered attacks but also as
reinforcing the importance of improved training techniques.
</summary>
    <author>
      <name>Nicolas Papernot</name>
    </author>
    <author>
      <name>Patrick McDaniel</name>
    </author>
    <link href="http://arxiv.org/abs/1705.05264v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.05264v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.07250v3</id>
    <updated>2017-06-02T14:58:53Z</updated>
    <published>2017-05-20T02:54:52Z</published>
    <title>Speedup from a different parametrization within the Neural Network
  algorithm</title>
    <summary>  A different parametrization of the hyperplanes is used in the neural network
algorithm. As demonstrated on several autoencoder examples it significantly
outperforms the usual parametrization, reaching lower training error values
with only a fraction of the number of epochs. It's argued that it makes it
easier to understand and initialize the parameters.
</summary>
    <author>
      <name>Michael F. Zimmer</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1705.07250v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.07250v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="K.3.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.08076v3</id>
    <updated>2017-05-25T16:50:52Z</updated>
    <published>2017-05-23T05:07:52Z</published>
    <title>Learning from partial correction</title>
    <summary>  We introduce a new model of interactive learning in which an expert examines
the predictions of a learner and partially fixes them if they are wrong.
Although this kind of feedback is not i.i.d., we show statistical
generalization bounds on the quality of the learned model.
</summary>
    <author>
      <name>Sanjoy Dasgupta</name>
    </author>
    <author>
      <name>Michael Luby</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1705.08076v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.08076v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.08947v2</id>
    <updated>2017-07-06T17:10:40Z</updated>
    <published>2017-06-27T17:20:06Z</published>
    <title>Exploring Generalization in Deep Learning</title>
    <summary>  With a goal of understanding what drives generalization in deep networks, we
consider several recently suggested explanations, including norm-based control,
sharpness and robustness. We study how these measures can ensure
generalization, highlighting the importance of scale normalization, and making
a connection between sharpness and PAC-Bayes theory. We then investigate how
well the measures explain different observed phenomena.
</summary>
    <author>
      <name>Behnam Neyshabur</name>
    </author>
    <author>
      <name>Srinadh Bhojanapalli</name>
    </author>
    <author>
      <name>David McAllester</name>
    </author>
    <author>
      <name>Nathan Srebro</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages, 8 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1706.08947v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.08947v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.09916v1</id>
    <updated>2017-06-29T18:33:06Z</updated>
    <published>2017-06-29T18:33:06Z</published>
    <title>Graph Convolutional Networks for Molecules</title>
    <summary>  Representation learning for molecules is important for molecular properties
prediction, material design, drug screening, etc. In this work a graph
convolutional network architecture for learning representations for molecules
is presented. An operation for convolving k-neighbourhood of a specific node in
graph is defined, which is corresponding to kernel size of k in convolutional
neural networks. Besides, A module of adaptive filtering is defined to find the
sampling locations based on graph connections and node features.
</summary>
    <author>
      <name>Zhenpeng Zhou</name>
    </author>
    <link href="http://arxiv.org/abs/1706.09916v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.09916v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.09564v1</id>
    <updated>2017-07-29T22:36:35Z</updated>
    <published>2017-07-29T22:36:35Z</published>
    <title>A PAC-Bayesian Approach to Spectrally-Normalized Margin Bounds for
  Neural Networks</title>
    <summary>  We present a generalization bound for feedforward neural networks in terms of
the product of the spectral norm of the layers and the Frobenius norm of the
weights. The generalization bound is derived using a PAC-Bayes analysis.
</summary>
    <author>
      <name>Behnam Neyshabur</name>
    </author>
    <author>
      <name>Srinadh Bhojanapalli</name>
    </author>
    <author>
      <name>David McAllester</name>
    </author>
    <author>
      <name>Nathan Srebro</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1707.09564v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.09564v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.01509v1</id>
    <updated>2017-09-05T17:55:59Z</updated>
    <published>2017-09-05T17:55:59Z</published>
    <title>Linking Generative Adversarial Learning and Binary Classification</title>
    <summary>  In this note, we point out a basic link between generative adversarial (GA)
training and binary classification -- any powerful discriminator essentially
computes an (f-)divergence between real and generated samples. The result,
repeatedly re-derived in decision theory, has implications for GA Networks
(GANs), providing an alternative perspective on training f-GANs by designing
the discriminator loss function.
</summary>
    <author>
      <name>Akshay Balsubramani</name>
    </author>
    <link href="http://arxiv.org/abs/1709.01509v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.01509v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.03942v1</id>
    <updated>2017-09-12T16:35:09Z</updated>
    <published>2017-09-12T16:35:09Z</published>
    <title>Deep Reinforcement Learning with Surrogate Agent-Environment Interface</title>
    <summary>  In this paper we propose surrogate agent-environment interface (SAEI) in
reinforcement learning. We also state that learning based on probability
surrogate agent-environment interface gives optimal policy of task
agent-environment interface. We introduce surrogate probability action and
develope the probability surrogate action deterministic policy gradient
(PSADPG) algorithm based on SAEI. This algorithm enables continuous control of
discrete action. The experiments show PSADPG achieves the performance of DQN in
the long run for selected tasks.
</summary>
    <author>
      <name>Song Wang</name>
    </author>
    <author>
      <name>Yu Jing</name>
    </author>
    <link href="http://arxiv.org/abs/1709.03942v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.03942v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/nlin/0511015v1</id>
    <updated>2005-11-09T14:41:00Z</updated>
    <published>2005-11-09T14:41:00Z</published>
    <title>Combinatorial Approach to Object Analysis</title>
    <summary>  We present a perceptional mathematical model for image and signal analysis. A
resemblance measure is defined, and submitted to an innovating combinatorial
optimization algorithm. Numerical Simulations are also presented
</summary>
    <author>
      <name>Rami Kanhouche</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CMLA</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/nlin/0511015v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/nlin/0511015v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.5088v1</id>
    <updated>2013-01-22T07:10:34Z</updated>
    <published>2013-01-22T07:10:34Z</published>
    <title>Piecewise Linear Multilayer Perceptrons and Dropout</title>
    <summary>  We propose a new type of hidden layer for a multilayer perceptron, and
demonstrate that it obtains the best reported performance for an MLP on the
MNIST dataset.
</summary>
    <author>
      <name>Ian J. Goodfellow</name>
    </author>
    <link href="http://arxiv.org/abs/1301.5088v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.5088v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.5738v1</id>
    <updated>2013-10-21T22:02:17Z</updated>
    <published>2013-10-21T22:02:17Z</published>
    <title>A Kernel for Hierarchical Parameter Spaces</title>
    <summary>  We define a family of kernels for mixed continuous/discrete hierarchical
parameter spaces and show that they are positive definite.
</summary>
    <author>
      <name>Frank Hutter</name>
    </author>
    <author>
      <name>Michael A. Osborne</name>
    </author>
    <link href="http://arxiv.org/abs/1310.5738v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.5738v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.05549v1</id>
    <updated>2017-01-19T18:43:56Z</updated>
    <published>2017-01-19T18:43:56Z</published>
    <title>Deep Neural Networks - A Brief History</title>
    <summary>  Introduction to deep neural networks and their history.
</summary>
    <author>
      <name>Krzysztof J. Cios</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 14 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1701.05549v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.05549v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9905004v1</id>
    <updated>1999-05-10T20:52:23Z</updated>
    <published>1999-05-10T20:52:23Z</published>
    <title>Using Collective Intelligence to Route Internet Traffic</title>
    <summary>  A COllective INtelligence (COIN) is a set of interacting reinforcement
learning (RL) algorithms designed in an automated fashion so that their
collective behavior optimizes a global utility function. We summarize the
theory of COINs, then present experiments using that theory to design COINs to
control internet traffic routing. These experiments indicate that COINs
outperform all previously investigated RL-based, shortest path routing
algorithms.
</summary>
    <author>
      <name>David H. Wolpert</name>
    </author>
    <author>
      <name>Kagan Tumer</name>
    </author>
    <author>
      <name>Jeremy Frank</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Advances in Information Processing Systems - 11, eds M. Kearns, S.
  Solla, D. Cohn, MIT Press, 1999</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/9905004v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9905004v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="adap-org" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.6; I.2.11" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9905015v1</id>
    <updated>1999-05-21T14:49:39Z</updated>
    <published>1999-05-21T14:49:39Z</published>
    <title>State Abstraction in MAXQ Hierarchical Reinforcement Learning</title>
    <summary>  Many researchers have explored methods for hierarchical reinforcement
learning (RL) with temporal abstractions, in which abstract actions are defined
that can perform many primitive actions before terminating. However, little is
known about learning with state abstractions, in which aspects of the state
space are ignored. In previous work, we developed the MAXQ method for
hierarchical RL. In this paper, we define five conditions under which state
abstraction can be combined with the MAXQ value function decomposition. We
prove that the MAXQ-Q learning algorithm converges under these conditions and
show experimentally that state abstraction is important for the successful
application of MAXQ-Q learning.
</summary>
    <author>
      <name>Thomas G. Dietterich</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/9905015v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9905015v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0001004v1</id>
    <updated>2000-01-07T06:20:53Z</updated>
    <published>2000-01-07T06:20:53Z</published>
    <title>Multiplicative Algorithm for Orthgonal Groups and Independent Component
  Analysis</title>
    <summary>  The multiplicative Newton-like method developed by the author et al. is
extended to the situation where the dynamics is restricted to the orthogonal
group. A general framework is constructed without specifying the cost function.
Though the restriction to the orthogonal groups makes the problem somewhat
complicated, an explicit expression for the amount of individual jumps is
obtained. This algorithm is exactly second-order-convergent. The global
instability inherent in the Newton method is remedied by a
Levenberg-Marquardt-type variation. The method thus constructed can readily be
applied to the independent component analysis. Its remarkable performance is
illustrated by a numerical simulation.
</summary>
    <author>
      <name>Toshinao Akuzawa</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">RIKEN BSI</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0001004v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0001004v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0002006v1</id>
    <updated>2000-02-09T06:44:28Z</updated>
    <published>2000-02-09T06:44:28Z</published>
    <title>Multiplicative Nonholonomic/Newton -like Algorithm</title>
    <summary>  We construct new algorithms from scratch, which use the fourth order cumulant
of stochastic variables for the cost function. The multiplicative updating rule
here constructed is natural from the homogeneous nature of the Lie group and
has numerous merits for the rigorous treatment of the dynamics. As one
consequence, the second order convergence is shown. For the cost function,
functions invariant under the componentwise scaling are choosen. By identifying
points which can be transformed to each other by the scaling, we assume that
the dynamics is in a coset space. In our method, a point can move toward any
direction in this coset. Thus, no prewhitening is required.
</summary>
    <author>
      <name>Toshinao Akuzawa</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">RIKEN BSI</arxiv:affiliation>
    </author>
    <author>
      <name>Noboru Murata</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">RIKEN BSI</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/S0960-0779(00)00077-1</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/S0960-0779(00)00077-1" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0002006v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0002006v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0008022v1</id>
    <updated>2000-08-22T21:37:50Z</updated>
    <published>2000-08-22T21:37:50Z</published>
    <title>A Learning Approach to Shallow Parsing</title>
    <summary>  A SNoW based learning approach to shallow parsing tasks is presented and
studied experimentally. The approach learns to identify syntactic patterns by
combining simple predictors to produce a coherent inference. Two instantiations
of this approach are studied and experimental results for Noun-Phrases (NP) and
Subject-Verb (SV) phrases that compare favorably with the best published
results are presented. In doing that, we compare two ways of modeling the
problem of learning to recognize patterns and suggest that shallow parsing
patterns are better learned using open/close predictors than using
inside/outside predictors.
</summary>
    <author>
      <name>Marcia Muñoz</name>
    </author>
    <author>
      <name>Vasin Punyakanok</name>
    </author>
    <author>
      <name>Dan Roth</name>
    </author>
    <author>
      <name>Dav Zimak</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">LaTex 2e, 11 pages, 2 eps figures, 1 bbl file, uses colacl.sty</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of EMNLP-VLC'99, pages 168-178</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0008022v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0008022v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.6; I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0011032v1</id>
    <updated>2000-11-21T21:51:01Z</updated>
    <published>2000-11-21T21:51:01Z</published>
    <title>Top-down induction of clustering trees</title>
    <summary>  An approach to clustering is presented that adapts the basic top-down
induction of decision trees method towards clustering. To this aim, it employs
the principles of instance based learning. The resulting methodology is
implemented in the TIC (Top down Induction of Clustering trees) system for
first order clustering. The TIC system employs the first order logical decision
tree representation of the inductive logic programming system Tilde. Various
experiments with TIC are presented, in both propositional and relational
domains.
</summary>
    <author>
      <name>Hendrik Blockeel</name>
    </author>
    <author>
      <name>Luc De Raedt</name>
    </author>
    <author>
      <name>Jan Ramon</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 3 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Machine Learning, Proceedings of the 15th International Conference
  (J. Shavlik, ed.), Morgan Kaufmann, 1998, pp. 55-63</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0011032v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0011032v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0107032v1</id>
    <updated>2001-07-23T11:06:45Z</updated>
    <published>2001-07-23T11:06:45Z</published>
    <title>Coupled Clustering: a Method for Detecting Structural Correspondence</title>
    <summary>  This paper proposes a new paradigm and computational framework for
identification of correspondences between sub-structures of distinct composite
systems. For this, we define and investigate a variant of traditional data
clustering, termed coupled clustering, which simultaneously identifies
corresponding clusters within two data sets. The presented method is
demonstrated and evaluated for detecting topical correspondences in textual
corpora.
</summary>
    <author>
      <name>Zvika Marx</name>
    </author>
    <author>
      <name>Ido Dagan</name>
    </author>
    <author>
      <name>Joachim Buhmann</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">html with 5 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">In: C. E. Brodley and A. P. Danyluk (eds.), Proceedings of the
  18th International Conference on Machine Learning (ICML 2001), pp. 353-360</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0107032v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0107032v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3; I.2.6; I.2.7; I.5.3; I.5.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0107033v1</id>
    <updated>2001-07-25T15:50:43Z</updated>
    <published>2001-07-25T15:50:43Z</published>
    <title>Yet another zeta function and learning</title>
    <summary>  We study the convergence speed of the batch learning algorithm, and compare
its speed to that of the memoryless learning algorithm and of learning with
memory (as analyzed in joint work with N. Komarova). We obtain precise results
and show in particular that the batch learning algorithm is never worse than
the memoryless learning algorithm (at least asymptotically). Its performance
vis-a-vis learning with full memory is less clearcut, and depends on
certainprobabilistic assumptions. These results necessitate theintroduction of
the moment zeta function of a probability distribution and the study of some of
its properties.
</summary>
    <author>
      <name>Igor Rivin</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0107033v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0107033v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.6; G.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0111003v1</id>
    <updated>2001-11-01T03:02:19Z</updated>
    <published>2001-11-01T03:02:19Z</published>
    <title>The Use of Classifiers in Sequential Inference</title>
    <summary>  We study the problem of combining the outcomes of several different
classifiers in a way that provides a coherent inference that satisfies some
constraints. In particular, we develop two general approaches for an important
subproblem-identifying phrase structure. The first is a Markovian approach that
extends standard HMMs to allow the use of a rich observation structure and of
general classifiers to model state-observation dependencies. The second is an
extension of constraint satisfaction formalisms. We develop efficient
combination algorithms under both models and study them experimentally in the
context of shallow parsing.
</summary>
    <author>
      <name>Vasin Punyakanok</name>
    </author>
    <author>
      <name>Dan Roth</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 1 figure</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Advances in Neural Information Processing Systems 13</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0111003v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0111003v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.6, I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0201014v1</id>
    <updated>2002-01-17T13:42:23Z</updated>
    <published>2002-01-17T13:42:23Z</published>
    <title>The Dynamics of AdaBoost Weights Tells You What's Hard to Classify</title>
    <summary>  The dynamical evolution of weights in the Adaboost algorithm contains useful
information about the role that the associated data points play in the built of
the Adaboost model. In particular, the dynamics induces a bipartition of the
data set into two (easy/hard) classes. Easy points are ininfluential in the
making of the model, while the varying relevance of hard points can be gauged
in terms of an entropy value associated to their evolution. Smooth
approximations of entropy highlight regions where classification is most
uncertain. Promising results are obtained when methods proposed are applied in
the Optimal Sampling framework.
</summary>
    <author>
      <name>Bruno Caprile</name>
    </author>
    <author>
      <name>Cesare Furlanello</name>
    </author>
    <author>
      <name>Stefano Merler</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, LaTeX, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0201014v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0201014v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.5.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0204052v1</id>
    <updated>2002-04-26T14:33:29Z</updated>
    <published>2002-04-26T14:33:29Z</published>
    <title>Required sample size for learning sparse Bayesian networks with many
  variables</title>
    <summary>  Learning joint probability distributions on n random variables requires
exponential sample size in the generic case. Here we consider the case that a
temporal (or causal) order of the variables is known and that the (unknown)
graph of causal dependencies has bounded in-degree Delta. Then the joint
measure is uniquely determined by the probabilities of all (2 Delta+1)-tuples.
Upper bounds on the sample size required for estimating their probabilities can
be given in terms of the VC-dimension of the set of corresponding cylinder
sets. The sample size grows less than linearly with n.
</summary>
    <author>
      <name>Pawel Wocjan</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Universitaet Karlsruhe</arxiv:affiliation>
    </author>
    <author>
      <name>Dominik Janzing</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Universitaet Karlsruhe</arxiv:affiliation>
    </author>
    <author>
      <name>Thomas Beth</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Universitaet Karlsruhe</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0204052v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0204052v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0211003v1</id>
    <updated>2002-11-01T18:09:56Z</updated>
    <published>2002-11-01T18:09:56Z</published>
    <title>Evaluation of the Performance of the Markov Blanket Bayesian Classifier
  Algorithm</title>
    <summary>  The Markov Blanket Bayesian Classifier is a recently-proposed algorithm for
construction of probabilistic classifiers. This paper presents an empirical
comparison of the MBBC algorithm with three other Bayesian classifiers: Naive
Bayes, Tree-Augmented Naive Bayes and a general Bayesian network. All of these
are implemented using the K2 framework of Cooper and Herskovits. The
classifiers are compared in terms of their performance (using simple accuracy
measures and ROC curves) and speed, on a range of standard benchmark data sets.
It is concluded that MBBC is competitive in terms of speed and accuracy with
the other algorithms considered.
</summary>
    <author>
      <name>Michael G. Madden</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages: Technical Report No. NUIG-IT-011002, Department of
  Information Technology, National University of Ireland, Galway (2002)</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0211003v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0211003v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0212029v1</id>
    <updated>2002-12-11T16:08:36Z</updated>
    <published>2002-12-11T16:08:36Z</published>
    <title>A Theory of Cross-Validation Error</title>
    <summary>  This paper presents a theory of error in cross-validation testing of
algorithms for predicting real-valued attributes. The theory justifies the
claim that predicting real-valued attributes requires balancing the conflicting
demands of simplicity and accuracy. Furthermore, the theory indicates precisely
how these conflicting demands must be balanced, in order to minimize
cross-validation error. A general theory is presented, then it is developed in
detail for linear regression and instance-based learning.
</summary>
    <author>
      <name>Peter D. Turney</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">National Research Council of Canada</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">48 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Experimental and Theoretical Artificial Intelligence,
  (1994), 6, 361-391</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0212029v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0212029v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.6; I.5.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0212037v1</id>
    <updated>2002-12-12T18:14:38Z</updated>
    <published>2002-12-12T18:14:38Z</published>
    <title>The Management of Context-Sensitive Features: A Review of Strategies</title>
    <summary>  In this paper, we review five heuristic strategies for handling
context-sensitive features in supervised machine learning from examples. We
discuss two methods for recovering lost (implicit) contextual information. We
mention some evidence that hybrid strategies can have a synergetic effect. We
then show how the work of several machine learning researchers fits into this
framework. While we do not claim that these strategies exhaust the
possibilities, it appears that the framework includes all of the techniques
that can be found in the published literature on contextsensitive learning.
</summary>
    <author>
      <name>Peter D. Turney</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">National Research Council of Canada</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">13th International Conference on Machine Learning, Workshop on
  Learning in Context-Sensitive Domains, Bari, Italy, (1996), 60-66</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0212037v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0212037v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.6; I.5.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0301007v1</id>
    <updated>2003-01-09T15:08:47Z</updated>
    <published>2003-01-09T15:08:47Z</published>
    <title>Kalman filter control in the reinforcement learning framework</title>
    <summary>  There is a growing interest in using Kalman-filter models in brain modelling.
In turn, it is of considerable importance to make Kalman-filters amenable for
reinforcement learning. In the usual formulation of optimal control it is
computed off-line by solving a backward recursion. In this technical note we
show that slight modification of the linear-quadratic-Gaussian Kalman-filter
model allows the on-line estimation of optimal control and makes the bridge to
reinforcement learning. Moreover, the learning rule for value estimation
assumes a Hebbian form weighted by the error of the value estimation.
</summary>
    <author>
      <name>Istvan Szita</name>
    </author>
    <author>
      <name>Andras Lorincz</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0301007v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0301007v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.6; I.2.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0306120v2</id>
    <updated>2007-03-09T15:14:15Z</updated>
    <published>2003-06-22T08:00:09Z</published>
    <title>Reinforcement Learning with Linear Function Approximation and LQ control
  Converges</title>
    <summary>  Reinforcement learning is commonly used with function approximation. However,
very few positive results are known about the convergence of function
approximation based RL control algorithms. In this paper we show that TD(0) and
Sarsa(0) with linear function approximation is convergent for a simple class of
problems, where the system is linear and the costs are quadratic (the LQ
control problem). Furthermore, we show that for systems with Gaussian noise and
non-completely observable states (the LQG problem), the mentioned RL algorithms
are still convergent, if they are combined with Kalman filtering.
</summary>
    <author>
      <name>Istvan Szita</name>
    </author>
    <author>
      <name>Andras Lorincz</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0306120v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0306120v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.6; I.2.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0408058v1</id>
    <updated>2004-08-25T20:25:43Z</updated>
    <published>2004-08-25T20:25:43Z</published>
    <title>Non-negative matrix factorization with sparseness constraints</title>
    <summary>  Non-negative matrix factorization (NMF) is a recently developed technique for
finding parts-based, linear representations of non-negative data. Although it
has successfully been applied in several applications, it does not always
result in parts-based representations. In this paper, we show how explicitly
incorporating the notion of `sparseness' improves the found decompositions.
Additionally, we provide complete MATLAB code both for standard NMF and for our
extension. Our hope is that this will further the application of these methods
to solving novel data-analysis problems.
</summary>
    <author>
      <name>Patrik O. Hoyer</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0408058v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0408058v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0410015v1</id>
    <updated>2004-10-07T10:57:08Z</updated>
    <published>2004-10-07T10:57:08Z</published>
    <title>L1 regularization is better than L2 for learning and predicting chaotic
  systems</title>
    <summary>  Emergent behaviors are in the focus of recent research interest. It is then
of considerable importance to investigate what optimizations suit the learning
and prediction of chaotic systems, the putative candidates for emergence. We
have compared L1 and L2 regularizations on predicting chaotic time series using
linear recurrent neural networks. The internal representation and the weights
of the networks were optimized in a unifying framework. Computational tests on
different problems indicate considerable advantages for the L1 regularization:
It had considerably better learning time and better interpolating capabilities.
We shall argue that optimization viewed as a maximum likelihood estimation
justifies our results, because L1 regularization fits heavy-tailed
distributions -- an apparently general feature of emergent systems -- better.
</summary>
    <author>
      <name>Z. Szabo</name>
    </author>
    <author>
      <name>A. Lorincz</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0410015v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0410015v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0502004v1</id>
    <updated>2005-02-01T13:42:49Z</updated>
    <published>2005-02-01T13:42:49Z</published>
    <title>Asymptotic Log-loss of Prequential Maximum Likelihood Codes</title>
    <summary>  We analyze the Dawid-Rissanen prequential maximum likelihood codes relative
to one-parameter exponential family models M. If data are i.i.d. according to
an (essentially) arbitrary P, then the redundancy grows at rate c/2 ln n. We
show that c=v1/v2, where v1 is the variance of P, and v2 is the variance of the
distribution m* in M that is closest to P in KL divergence. This shows that
prequential codes behave quite differently from other important universal codes
such as the 2-part MDL, Shtarkov and Bayes codes, for which c=1. This behavior
is undesirable in an MDL model selection setting.
</summary>
    <author>
      <name>Peter Grunwald</name>
    </author>
    <author>
      <name>Steven de Rooij</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">22 pages, an abstract has been submitted to COLT 2005</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0502004v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0502004v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="E.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0505083v1</id>
    <updated>2005-05-30T21:12:00Z</updated>
    <published>2005-05-30T21:12:00Z</published>
    <title>Defensive forecasting</title>
    <summary>  We consider how to make probability forecasts of binary labels. Our main
mathematical result is that for any continuous gambling strategy used for
detecting disagreement between the forecasts and the actual labels, there
exists a forecasting strategy whose forecasts are ideal as far as this gambling
strategy is concerned. A forecasting strategy obtained in this way from a
gambling strategy demonstrating a strong law of large numbers is simplified and
studied empirically.
</summary>
    <author>
      <name>Vladimir Vovk</name>
    </author>
    <author>
      <name>Akimichi Takemura</name>
    </author>
    <author>
      <name>Glenn Shafer</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 2 figures, to appear in the AIStats'2005 electronic
  proceedings</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the Tenth International Workshop on Artificial
  Intelligence and Statistics, 2005, pages 365--372.</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0505083v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0505083v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.6; I.5.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0506004v4</id>
    <updated>2006-07-01T13:46:30Z</updated>
    <published>2005-06-01T14:03:20Z</published>
    <title>Non-asymptotic calibration and resolution</title>
    <summary>  We analyze a new algorithm for probability forecasting of binary observations
on the basis of the available data, without making any assumptions about the
way the observations are generated. The algorithm is shown to be well
calibrated and to have good resolution for long enough sequences of
observations and for a suitable choice of its parameter, a kernel on the
Cartesian product of the forecast space $[0,1]$ and the data space. Our main
results are non-asymptotic: we establish explicit inequalities, shown to be
tight, for the performance of the algorithm.
</summary>
    <author>
      <name>Vladimir Vovk</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0506004v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0506004v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.6; I.5.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0511088v1</id>
    <updated>2005-11-25T15:57:56Z</updated>
    <published>2005-11-25T15:57:56Z</published>
    <title>Bounds on Query Convergence</title>
    <summary>  The problem of finding an optimum using noisy evaluations of a smooth cost
function arises in many contexts, including economics, business, medicine,
experiment design, and foraging theory. We derive an asymptotic bound E[ (x_t -
x*)^2 ] &gt;= O(1/sqrt(t)) on the rate of convergence of a sequence (x_0, x_1,
&gt;...) generated by an unbiased feedback process observing noisy evaluations of
an unknown quadratic function maximised at x*. The bound is tight, as the proof
leads to a simple algorithm which meets it. We further establish a bound on the
total regret, E[ sum_{i=1..t} (x_i - x*)^2 ] &gt;= O(sqrt(t)) These bounds may
impose practical limitations on an agent's performance, as O(eps^-4) queries
are made before the queries converge to x* with eps accuracy.
</summary>
    <author>
      <name>Barak A. Pearlmutter</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0511088v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0511088v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0601089v1</id>
    <updated>2006-01-20T17:46:45Z</updated>
    <published>2006-01-20T17:46:45Z</published>
    <title>Distributed Kernel Regression: An Algorithm for Training Collaboratively</title>
    <summary>  This paper addresses the problem of distributed learning under communication
constraints, motivated by distributed signal processing in wireless sensor
networks and data mining with distributed databases. After formalizing a
general model for distributed learning, an algorithm for collaboratively
training regularized kernel least-squares regression estimators is derived.
Noting that the algorithm can be viewed as an application of successive
orthogonal projection algorithms, its convergence properties are investigated
and the statistical behavior of the estimator is discussed in a simplified
theoretical setting.
</summary>
    <author>
      <name>Joel B. Predd</name>
    </author>
    <author>
      <name>Sanjeev R. Kulkarni</name>
    </author>
    <author>
      <name>H. Vincent Poor</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/ITW.2006.1633840</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/ITW.2006.1633840" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To be presented at the 2006 IEEE Information Theory Workshop, Punta
  del Este, Uruguay, March 13-17, 2006</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0601089v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0601089v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0602093v1</id>
    <updated>2006-02-27T10:08:26Z</updated>
    <published>2006-02-27T10:08:26Z</published>
    <title>Rational stochastic languages</title>
    <summary>  The goal of the present paper is to provide a systematic and comprehensive
study of rational stochastic languages over a semiring K \in {Q, Q +, R, R+}. A
rational stochastic language is a probability distribution over a free monoid
\Sigma^* which is rational over K, that is which can be generated by a
multiplicity automata with parameters in K. We study the relations between the
classes of rational stochastic languages S rat K (\Sigma). We define the notion
of residual of a stochastic language and we use it to investigate properties of
several subclasses of rational stochastic languages. Lastly, we study the
representation of rational stochastic languages by means of multiplicity
automata.
</summary>
    <author>
      <name>François Denis</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIF</arxiv:affiliation>
    </author>
    <author>
      <name>Yann Esposito</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIF</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">35 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0602093v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0602093v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0605036v1</id>
    <updated>2006-05-08T23:38:13Z</updated>
    <published>2006-05-08T23:38:13Z</published>
    <title>Evaluating the Robustness of Learning from Implicit Feedback</title>
    <summary>  This paper evaluates the robustness of learning from implicit feedback in web
search. In particular, we create a model of user behavior by drawing upon user
studies in laboratory and real-world settings. The model is used to understand
the effect of user behavior on the performance of a learning algorithm for
ranked retrieval. We explore a wide range of possible user behaviors and find
that learning from implicit feedback can be surprisingly robust. This
complements previous results that demonstrated our algorithm's effectiveness in
a real-world search engine application.
</summary>
    <author>
      <name>Filip Radlinski</name>
    </author>
    <author>
      <name>Thorsten Joachims</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, Presented at ICML Workshop on Learning In Web Search, 2005</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0605036v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0605036v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0605048v1</id>
    <updated>2006-05-11T03:27:12Z</updated>
    <published>2006-05-11T03:27:12Z</published>
    <title>On Learning Thresholds of Parities and Unions of Rectangles in Random
  Walk Models</title>
    <summary>  In a recent breakthrough, [Bshouty et al., 2005] obtained the first
passive-learning algorithm for DNFs under the uniform distribution. They showed
that DNFs are learnable in the Random Walk and Noise Sensitivity models. We
extend their results in several directions. We first show that thresholds of
parities, a natural class encompassing DNFs, cannot be learned efficiently in
the Noise Sensitivity model using only statistical queries. In contrast, we
show that a cyclic version of the Random Walk model allows to learn efficiently
polynomially weighted thresholds of parities. We also extend the algorithm of
Bshouty et al. to the case of Unions of Rectangles, a natural generalization of
DNFs to $\{0,...,b-1\}^n$.
</summary>
    <author>
      <name>S. Roch</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0605048v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0605048v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0607110v1</id>
    <updated>2006-07-25T15:57:56Z</updated>
    <published>2006-07-25T15:57:56Z</published>
    <title>A Theory of Probabilistic Boosting, Decision Trees and Matryoshki</title>
    <summary>  We present a theory of boosting probabilistic classifiers. We place ourselves
in the situation of a user who only provides a stopping parameter and a
probabilistic weak learner/classifier and compare three types of boosting
algorithms: probabilistic Adaboost, decision tree, and tree of trees of ... of
trees, which we call matryoshka. "Nested tree," "embedded tree" and "recursive
tree" are also appropriate names for this algorithm, which is one of our
contributions. Our other contribution is the theoretical analysis of the
algorithms, in which we give training error bounds. This analysis suggests that
the matryoshka leverages probabilistic weak classifiers more efficiently than
simple decision trees.
</summary>
    <author>
      <name>Etienne Grossmann</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0607110v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0607110v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.5.1; I.2.6; G.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0608033v1</id>
    <updated>2006-08-06T16:10:05Z</updated>
    <published>2006-08-06T16:10:05Z</published>
    <title>A Study on Learnability for Rigid Lambek Grammars</title>
    <summary>  We present basic notions of Gold's "learnability in the limit" paradigm,
first presented in 1967, a formalization of the cognitive process by which a
native speaker gets to grasp the underlying grammar of his/her own native
language by being exposed to well formed sentences generated by that grammar.
Then we present Lambek grammars, a formalism issued from categorial grammars
which, although not as expressive as needed for a full formalization of natural
languages, is particularly suited to easily implement a natural interface
between syntax and semantics. In the last part of this work, we present a
learnability result for Rigid Lambek grammars from structured examples.
</summary>
    <author>
      <name>Roberto Bonato</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Futurs, LaBRI</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/cs/0608033v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0608033v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0609007v1</id>
    <updated>2006-09-03T21:30:03Z</updated>
    <published>2006-09-03T21:30:03Z</published>
    <title>A Massive Local Rules Search Approach to the Classification Problem</title>
    <summary>  An approach to the classification problem of machine learning, based on
building local classification rules, is developed. The local rules are
considered as projections of the global classification rules to the event we
want to classify. A massive global optimization algorithm is used for
optimization of quality criterion. The algorithm, which has polynomial
complexity in typical case, is used to find all high--quality local rules. The
other distinctive feature of the algorithm is the integration of attributes
levels selection (for ordered attributes) with rules searching and original
conflicting rules resolution strategy. The algorithm is practical; it was
tested on a number of data sets from UCI repository, and a comparison with the
other predicting techniques is presented.
</summary>
    <author>
      <name>Vladislav Malyshkin</name>
    </author>
    <author>
      <name>Ray Bakhramov</name>
    </author>
    <author>
      <name>Andrey Gorodetsky</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">24 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0609007v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0609007v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0609045v1</id>
    <updated>2006-09-09T11:31:01Z</updated>
    <published>2006-09-09T11:31:01Z</published>
    <title>Metric entropy in competitive on-line prediction</title>
    <summary>  Competitive on-line prediction (also known as universal prediction of
individual sequences) is a strand of learning theory avoiding making any
stochastic assumptions about the way the observations are generated. The
predictor's goal is to compete with a benchmark class of prediction rules,
which is often a proper Banach function space. Metric entropy provides a
unifying framework for competitive on-line prediction: the numerous known upper
bounds on the metric entropy of various compact sets in function spaces readily
imply bounds on the performance of on-line prediction strategies. This paper
discusses strengths and limitations of the direct approach to competitive
on-line prediction via metric entropy, including comparisons to other
approaches.
</summary>
    <author>
      <name>Vladimir Vovk</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">41 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0609045v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0609045v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0609071v2</id>
    <updated>2007-02-14T06:51:03Z</updated>
    <published>2006-09-13T03:44:08Z</published>
    <title>A kernel method for canonical correlation analysis</title>
    <summary>  Canonical correlation analysis is a technique to extract common features from
a pair of multivariate data. In complex situations, however, it does not
extract useful features because of its linearity. On the other hand, kernel
method used in support vector machine is an efficient approach to improve such
a linear method. In this paper, we investigate the effectiveness of applying
kernel method to canonical correlation analysis.
</summary>
    <author>
      <name>Shotaro Akaho</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Full version of paper presented in IMPS2001 (International Meeting of
  Psychometric Society) 2007-Feb-14: typos in equations (23) and (24) in page 3
  of the first version have been corrected</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0609071v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0609071v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0701052v1</id>
    <updated>2007-01-08T17:03:31Z</updated>
    <published>2007-01-08T17:03:31Z</published>
    <title>Time Series Forecasting: Obtaining Long Term Trends with Self-Organizing
  Maps</title>
    <summary>  Kohonen self-organisation maps are a well know classification tool, commonly
used in a wide variety of problems, but with limited applications in time
series forecasting context. In this paper, we propose a forecasting method
specifically designed for multi-dimensional long-term trends prediction, with a
double application of the Kohonen algorithm. Practical applications of the
method are also presented.
</summary>
    <author>
      <name>Geoffroy Simon</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">DICE-MLG</arxiv:affiliation>
    </author>
    <author>
      <name>Amaury Lendasse</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">DICE-MLG</arxiv:affiliation>
    </author>
    <author>
      <name>Marie Cottrell</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">SAMOS, Matisse</arxiv:affiliation>
    </author>
    <author>
      <name>Jean-Claude Fort</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">SAMOS, Matisse</arxiv:affiliation>
    </author>
    <author>
      <name>Michel Verleysen</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">SAMOS, Matisse, Dice-MLG</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">\`{a} la suite de la conf\'{e}rence ANNPR, Florence 2003</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Pattern Recognition Letter 26 n0; 12 (05/2005) 1795-1808</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0701052v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0701052v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0703138v1</id>
    <updated>2007-03-28T04:41:54Z</updated>
    <published>2007-03-28T04:41:54Z</published>
    <title>Reinforcement Learning for Adaptive Routing</title>
    <summary>  Reinforcement learning means learning a policy--a mapping of observations
into actions--based on feedback from the environment. The learning can be
viewed as browsing a set of policies while evaluating them by trial through
interaction with the environment. We present an application of gradient ascent
algorithm for reinforcement learning to a complex domain of packet routing in
network communication and compare the performance of this algorithm to other
routing methods on a benchmark problem.
</summary>
    <author>
      <name>Leonid Peshkin</name>
    </author>
    <author>
      <name>Virginia Savova</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings of the Intnl Joint Conf on Neural Networks (IJCNN),
  2002</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0703138v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0703138v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="C.2.1; C.2.2; C.2.4; C.2.6; F.1.1; I.2.6; I.2.8; I.2.9" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0704.2668v1</id>
    <updated>2007-04-20T08:26:29Z</updated>
    <published>2007-04-20T08:26:29Z</published>
    <title>Supervised Feature Selection via Dependence Estimation</title>
    <summary>  We introduce a framework for filtering features that employs the
Hilbert-Schmidt Independence Criterion (HSIC) as a measure of dependence
between the features and the labels. The key idea is that good features should
maximise such dependence. Feature selection for various supervised learning
problems (including classification and regression) is unified under this
framework, and the solutions can be approximated using a backward-elimination
algorithm. We demonstrate the usefulness of our method on both artificial and
real world datasets.
</summary>
    <author>
      <name>Le Song</name>
    </author>
    <author>
      <name>Alex Smola</name>
    </author>
    <author>
      <name>Arthur Gretton</name>
    </author>
    <author>
      <name>Karsten Borgwardt</name>
    </author>
    <author>
      <name>Justin Bedo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/0704.2668v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0704.2668v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0705.2765v1</id>
    <updated>2007-05-18T19:44:19Z</updated>
    <published>2007-05-18T19:44:19Z</published>
    <title>On the monotonization of the training set</title>
    <summary>  We consider the problem of minimal correction of the training set to make it
consistent with monotonic constraints. This problem arises during analysis of
data sets via techniques that require monotone data. We show that this problem
is NP-hard in general and is equivalent to finding a maximal independent set in
special orgraphs. Practically important cases of that problem considered in
detail. These are the cases when a partial order given on the replies set is a
total order or has a dimension 2. We show that the second case can be reduced
to maximization of a quadratic convex function on a convex set. For this case
we construct an approximate polynomial algorithm based on convex optimization.
</summary>
    <author>
      <name>Rustem Takhanov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/0705.2765v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0705.2765v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0706.0585v1</id>
    <updated>2007-06-05T05:55:07Z</updated>
    <published>2007-06-05T05:55:07Z</published>
    <title>A Novel Model of Working Set Selection for SMO Decomposition Methods</title>
    <summary>  In the process of training Support Vector Machines (SVMs) by decomposition
methods, working set selection is an important technique, and some exciting
schemes were employed into this field. To improve working set selection, we
propose a new model for working set selection in sequential minimal
optimization (SMO) decomposition methods. In this model, it selects B as
working set without reselection. Some properties are given by simple proof, and
experiments demonstrate that the proposed method is in general faster than
existing methods.
</summary>
    <author>
      <name>Zhendong Zhao</name>
    </author>
    <author>
      <name>Lei Yuan</name>
    </author>
    <author>
      <name>Yuxuan Wang</name>
    </author>
    <author>
      <name>Forrest Sheng Bao</name>
    </author>
    <author>
      <name>Shunyi Zhang Yanfei Sun</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/ICTAI.2007.99</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/ICTAI.2007.99" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 12 figures, it was submitted to IEEE International
  conference of Tools on Artificial Intelligence</arxiv:comment>
    <link href="http://arxiv.org/abs/0706.0585v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0706.0585v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0706.3679v1</id>
    <updated>2007-06-25T17:28:57Z</updated>
    <published>2007-06-25T17:28:57Z</published>
    <title>Scale-sensitive Psi-dimensions: the Capacity Measures for Classifiers
  Taking Values in R^Q</title>
    <summary>  Bounds on the risk play a crucial role in statistical learning theory. They
usually involve as capacity measure of the model studied the VC dimension or
one of its extensions. In classification, such "VC dimensions" exist for models
taking values in {0, 1}, {1,..., Q} and R. We introduce the generalizations
appropriate for the missing case, the one of models with values in R^Q. This
provides us with a new guaranteed risk for M-SVMs which appears superior to the
existing one.
</summary>
    <author>
      <name>Yann Guermeur</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LORIA</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ASMDA 2007 (2007) 1-8</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0706.3679v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0706.3679v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0709.0509v1</id>
    <updated>2007-09-04T19:36:22Z</updated>
    <published>2007-09-04T19:36:22Z</published>
    <title>Filtering Additive Measurement Noise with Maximum Entropy in the Mean</title>
    <summary>  The purpose of this note is to show how the method of maximum entropy in the
mean (MEM) may be used to improve parametric estimation when the measurements
are corrupted by large level of noise. The method is developed in the context
on a concrete example: that of estimation of the parameter in an exponential
distribution. We compare the performance of our method with the bayesian and
maximum likelihood approaches.
</summary>
    <author>
      <name>Henryk Gzyl</name>
    </author>
    <author>
      <name>Enrique ter Horst</name>
    </author>
    <link href="http://arxiv.org/abs/0709.0509v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0709.0509v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0710.0485v2</id>
    <updated>2008-06-27T18:45:01Z</updated>
    <published>2007-10-02T10:08:41Z</published>
    <title>Prediction with expert advice for the Brier game</title>
    <summary>  We show that the Brier game of prediction is mixable and find the optimal
learning rate and substitution function for it. The resulting prediction
algorithm is applied to predict results of football and tennis matches. The
theoretical performance guarantee turns out to be rather tight on these data
sets, especially in the case of the more extensive tennis data.
</summary>
    <author>
      <name>Vladimir Vovk</name>
    </author>
    <author>
      <name>Fedor Zhdanov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">34 pages, 22 figures, 2 tables. The conference version (8 pages) is
  published in the ICML 2008 Proceedings</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Machine Learning Research 10 (2009), 2413 - 2440</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0710.0485v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0710.0485v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0711.3594v1</id>
    <updated>2007-11-22T15:05:35Z</updated>
    <published>2007-11-22T15:05:35Z</published>
    <title>Clustering with Transitive Distance and K-Means Duality</title>
    <summary>  Recent spectral clustering methods are a propular and powerful technique for
data clustering. These methods need to solve the eigenproblem whose
computational complexity is $O(n^3)$, where $n$ is the number of data samples.
In this paper, a non-eigenproblem based clustering method is proposed to deal
with the clustering problem. Its performance is comparable to the spectral
clustering algorithms but it is more efficient with computational complexity
$O(n^2)$. We show that with a transitive distance and an observed property,
called K-means duality, our algorithm can be used to handle data sets with
complex cluster shapes, multi-scale clusters, and noise. Moreover, no
parameters except the number of clusters need to be set in our algorithm.
</summary>
    <author>
      <name>Chunjing Xu</name>
    </author>
    <author>
      <name>Jianzhuang Liu</name>
    </author>
    <author>
      <name>Xiaoou Tang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0711.3594v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0711.3594v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0711.4452v1</id>
    <updated>2007-11-28T12:05:47Z</updated>
    <published>2007-11-28T12:05:47Z</published>
    <title>Covariance and PCA for Categorical Variables</title>
    <summary>  Covariances from categorical variables are defined using a regular simplex
expression for categories. The method follows the variance definition by Gini,
and it gives the covariance as a solution of simultaneous equations. The
calculated results give reasonable values for test data. A method of principal
component analysis (RS-PCA) is also proposed using regular simplex expressions,
which allows easy interpretation of the principal components. The proposed
methods apply to variable selection problem of categorical data USCensus1990
data. The proposed methods give appropriate criterion for the variable
selection problem of categorical
</summary>
    <author>
      <name>Hirotaka Niitsuma</name>
    </author>
    <author>
      <name>Takashi Okada</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0711.4452v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0711.4452v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0712.3402v1</id>
    <updated>2007-12-20T13:06:50Z</updated>
    <published>2007-12-20T13:06:50Z</published>
    <title>Graph kernels between point clouds</title>
    <summary>  Point clouds are sets of points in two or three dimensions. Most kernel
methods for learning on sets of points have not yet dealt with the specific
geometrical invariances and practical constraints associated with point clouds
in computer vision and graphics. In this paper, we present extensions of graph
kernels for point clouds, which allow to use kernel methods for such ob jects
as shapes, line drawings, or any three-dimensional point clouds. In order to
design rich and numerically efficient kernels with as few free parameters as
possible, we use kernels between covariance matrices and their factorizations
on graphical models. We derive polynomial time dynamic programming recursions
and present applications to recognition of handwritten digits and Chinese
characters from few training examples.
</summary>
    <author>
      <name>Francis Bach</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">WILLOW Project - Inria/Ens</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/0712.3402v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0712.3402v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0802.1002v1</id>
    <updated>2008-02-07T15:18:27Z</updated>
    <published>2008-02-07T15:18:27Z</published>
    <title>New Estimation Procedures for PLS Path Modelling</title>
    <summary>  Given R groups of numerical variables X1, ... XR, we assume that each group
is the result of one underlying latent variable, and that all latent variables
are bound together through a linear equation system. Moreover, we assume that
some explanatory latent variables may interact pairwise in one or more
equations. We basically consider PLS Path Modelling's algorithm to estimate
both latent variables and the model's coefficients. New "external" estimation
schemes are proposed that draw latent variables towards strong group structures
in a more flexible way. New "internal" estimation schemes are proposed to
enable PLSPM to make good use of variable group complementarity and to deal
with interactions. Application examples are given.
</summary>
    <author>
      <name>Xavier Bry</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">I3M</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/0802.1002v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0802.1002v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0804.0188v2</id>
    <updated>2009-08-04T11:48:14Z</updated>
    <published>2008-04-01T14:55:33Z</published>
    <title>Support Vector Machine Classification with Indefinite Kernels</title>
    <summary>  We propose a method for support vector machine classification using
indefinite kernels. Instead of directly minimizing or stabilizing a nonconvex
loss function, our algorithm simultaneously computes support vectors and a
proxy kernel matrix used in forming the loss. This can be interpreted as a
penalized kernel learning problem where indefinite kernel matrices are treated
as a noisy observations of a true Mercer kernel. Our formulation keeps the
problem convex and relatively large problems can be solved efficiently using
the projected gradient or analytic center cutting plane methods. We compare the
performance of our technique with other methods on several classic data sets.
</summary>
    <author>
      <name>Ronny Luss</name>
    </author>
    <author>
      <name>Alexandre d'Aspremont</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Final journal version. A few typos fixed</arxiv:comment>
    <link href="http://arxiv.org/abs/0804.0188v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0804.0188v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0804.0924v2</id>
    <updated>2009-07-29T04:25:24Z</updated>
    <published>2008-04-06T18:14:34Z</published>
    <title>A Unified Semi-Supervised Dimensionality Reduction Framework for
  Manifold Learning</title>
    <summary>  We present a general framework of semi-supervised dimensionality reduction
for manifold learning which naturally generalizes existing supervised and
unsupervised learning frameworks which apply the spectral decomposition.
Algorithms derived under our framework are able to employ both labeled and
unlabeled examples and are able to handle complex problems where data form
separate clusters of manifolds. Our framework offers simple views, explains
relationships among existing frameworks and provides further extensions which
can improve existing algorithms. Furthermore, a new semi-supervised
kernelization framework called ``KPCA trick'' is proposed to handle non-linear
problems.
</summary>
    <author>
      <name>Ratthachat Chatpatanasiri</name>
    </author>
    <author>
      <name>Boonserm Kijsirikul</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">22 pages, 9 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0804.0924v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0804.0924v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0804.4682v1</id>
    <updated>2008-04-29T19:25:07Z</updated>
    <published>2008-04-29T19:25:07Z</published>
    <title>Introduction to Relational Networks for Classification</title>
    <summary>  The use of computational intelligence techniques for classification has been
used in numerous applications. This paper compares the use of a Multi Layer
Perceptron Neural Network and a new Relational Network on classifying the HIV
status of women at ante-natal clinics. The paper discusses the architecture of
the relational network and its merits compared to a neural network and most
other computational intelligence classifiers. Results gathered from the study
indicate comparable classification accuracies as well as revealed relationships
between data features in the classification data. Much higher classification
accuracies are recommended for future research in the area of HIV
classification as well as missing data estimation.
</summary>
    <author>
      <name>Vukosi Marivate</name>
    </author>
    <author>
      <name>Tshilidzi Marwala</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/0804.4682v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0804.4682v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0805.0149v1</id>
    <updated>2008-05-01T20:25:27Z</updated>
    <published>2008-05-01T20:25:27Z</published>
    <title>On Recovery of Sparse Signals via $\ell_1$ Minimization</title>
    <summary>  This article considers constrained $\ell_1$ minimization methods for the
recovery of high dimensional sparse signals in three settings: noiseless,
bounded error and Gaussian noise. A unified and elementary treatment is given
in these noise settings for two $\ell_1$ minimization methods: the Dantzig
selector and $\ell_1$ minimization with an $\ell_2$ constraint. The results of
this paper improve the existing results in the literature by weakening the
conditions and tightening the error bounds. The improvement on the conditions
shows that signals with larger support can be recovered accurately. This paper
also establishes connections between restricted isometry property and the
mutual incoherence property. Some results of Candes, Romberg and Tao (2006) and
Donoho, Elad, and Temlyakov (2006) are extended.
</summary>
    <author>
      <name>T. Tony Cai</name>
    </author>
    <author>
      <name>Guangwu Xu</name>
    </author>
    <author>
      <name>Jun Zhang</name>
    </author>
    <link href="http://arxiv.org/abs/0805.0149v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0805.0149v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0805.2752v1</id>
    <updated>2008-05-18T20:07:22Z</updated>
    <published>2008-05-18T20:07:22Z</published>
    <title>The Margitron: A Generalised Perceptron with Margin</title>
    <summary>  We identify the classical Perceptron algorithm with margin as a member of a
broader family of large margin classifiers which we collectively call the
Margitron. The Margitron, (despite its) sharing the same update rule with the
Perceptron, is shown in an incremental setting to converge in a finite number
of updates to solutions possessing any desirable fraction of the maximum
margin. Experiments comparing the Margitron with decomposition SVMs on tasks
involving linear kernels and 2-norm soft margin are also reported.
</summary>
    <author>
      <name>Constantinos Panagiotakopoulos</name>
    </author>
    <author>
      <name>Petroula Tsampouka</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/0805.2752v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0805.2752v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0805.4290v1</id>
    <updated>2008-05-28T09:16:44Z</updated>
    <published>2008-05-28T09:16:44Z</published>
    <title>From Data Topology to a Modular Classifier</title>
    <summary>  This article describes an approach to designing a distributed and modular
neural classifier. This approach introduces a new hierarchical clustering that
enables one to determine reliable regions in the representation space by
exploiting supervised information. A multilayer perceptron is then associated
with each of these detected clusters and charged with recognizing elements of
the associated cluster while rejecting all others. The obtained global
classifier is comprised of a set of cooperating neural networks and completed
by a K-nearest neighbor classifier charged with treating elements rejected by
all the neural networks. Experimental results for the handwritten digit
recognition problem and comparison with neural and statistical nonmodular
classifiers are given.
</summary>
    <author>
      <name>Abdel Ennaji</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LITIS</arxiv:affiliation>
    </author>
    <author>
      <name>Arnaud Ribert</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LITIS</arxiv:affiliation>
    </author>
    <author>
      <name>Yves Lecourtier</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LITIS</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s10032-002-0095-3</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s10032-002-0095-3" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal On Document Analysis and Recognition 6, 1
  (2003) 1-9</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0805.4290v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0805.4290v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0806.4210v1</id>
    <updated>2008-06-25T23:18:44Z</updated>
    <published>2008-06-25T23:18:44Z</published>
    <title>Agnostically Learning Juntas from Random Walks</title>
    <summary>  We prove that the class of functions g:{-1,+1}^n -&gt; {-1,+1} that only depend
on an unknown subset of k&lt;&lt;n variables (so-called k-juntas) is agnostically
learnable from a random walk in time polynomial in n, 2^{k^2}, epsilon^{-k},
and log(1/delta). In other words, there is an algorithm with the claimed
running time that, given epsilon, delta &gt; 0 and access to a random walk on
{-1,+1}^n labeled by an arbitrary function f:{-1,+1}^n -&gt; {-1,+1}, finds with
probability at least 1-delta a k-junta that is (opt(f)+epsilon)-close to f,
where opt(f) denotes the distance of a closest k-junta to f.
</summary>
    <author>
      <name>Jan Arpe</name>
    </author>
    <author>
      <name>Elchanan Mossel</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/0806.4210v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0806.4210v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0806.4391v1</id>
    <updated>2008-06-26T20:21:06Z</updated>
    <published>2008-06-26T20:21:06Z</published>
    <title>Prediction with Expert Advice in Games with Unbounded One-Step Gains</title>
    <summary>  The games of prediction with expert advice are considered in this paper. We
present some modification of Kalai and Vempala algorithm of following the
perturbed leader for the case of unrestrictedly large one-step gains. We show
that in general case the cumulative gain of any probabilistic prediction
algorithm can be much worse than the gain of some expert of the pool.
Nevertheless, we give the lower bound for this cumulative gain in general case
and construct a universal algorithm which has the optimal performance; we also
prove that in case when one-step gains of experts of the pool have ``limited
deviations'' the performance of our algorithm is close to the performance of
the best expert.
</summary>
    <author>
      <name>Vladimir V. V'yugin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/0806.4391v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0806.4391v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0806.4484v2</id>
    <updated>2009-06-25T20:07:47Z</updated>
    <published>2008-06-27T10:49:33Z</published>
    <title>On empirical meaning of randomness with respect to a real parameter</title>
    <summary>  We study the empirical meaning of randomness with respect to a family of
probability distributions $P_\theta$, where $\theta$ is a real parameter, using
algorithmic randomness theory. In the case when for a computable probability
distribution $P_\theta$ an effectively strongly consistent estimate exists, we
show that the Levin's a priory semicomputable semimeasure of the set of all
$P_\theta$-random sequences is positive if and only if the parameter $\theta$
is a computable real number. The different methods for generating
``meaningful'' $P_\theta$-random sequences with noncomputable $\theta$ are
discussed.
</summary>
    <author>
      <name>Vladimir V'yugin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">LNCS 4649, pp. 387-396, 2007</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0806.4484v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0806.4484v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0809.1270v1</id>
    <updated>2008-09-08T04:18:17Z</updated>
    <published>2008-09-08T04:18:17Z</published>
    <title>Predictive Hypothesis Identification</title>
    <summary>  While statistics focusses on hypothesis testing and on estimating (properties
of) the true sampling distribution, in machine learning the performance of
learning algorithms on future data is the primary issue. In this paper we
bridge the gap with a general principle (PHI) that identifies hypotheses with
best predictive performance. This includes predictive point and interval
estimation, simple and composite hypothesis testing, (mixture) model selection,
and others as special cases. For concrete instantiations we will recover
well-known methods, variations thereof, and new ones. PHI nicely justifies,
reconciles, and blends (a reparametrization invariant variation of) MAP, ML,
MDL, and moment estimation. One particular feature of PHI is that it can
genuinely deal with nested hypotheses.
</summary>
    <author>
      <name>Marcus Hutter</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/0809.1270v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0809.1270v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0809.2792v3</id>
    <updated>2009-06-24T17:45:11Z</updated>
    <published>2008-09-16T20:05:00Z</published>
    <title>Predicting Abnormal Returns From News Using Text Classification</title>
    <summary>  We show how text from news articles can be used to predict intraday price
movements of financial assets using support vector machines. Multiple kernel
learning is used to combine equity returns with text as predictive features to
increase classification performance and we develop an analytic center cutting
plane method to solve the kernel learning problem efficiently. We observe that
while the direction of returns is not predictable using either text or returns,
their size is, with text features producing significantly better performance
than historical returns alone.
</summary>
    <author>
      <name>Ronny Luss</name>
    </author>
    <author>
      <name>Alexandre d'Aspremont</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Larger data sets, results on time of day effect, and use of delta
  hedged covered call options to trade on daily predictions</arxiv:comment>
    <link href="http://arxiv.org/abs/0809.2792v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0809.2792v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0809.4086v2</id>
    <updated>2011-01-08T03:16:39Z</updated>
    <published>2008-09-24T05:34:56Z</published>
    <title>Learning Hidden Markov Models using Non-Negative Matrix Factorization</title>
    <summary>  The Baum-Welsh algorithm together with its derivatives and variations has
been the main technique for learning Hidden Markov Models (HMM) from
observational data. We present an HMM learning algorithm based on the
non-negative matrix factorization (NMF) of higher order Markovian statistics
that is structurally different from the Baum-Welsh and its associated
approaches. The described algorithm supports estimation of the number of
recurrent states of an HMM and iterates the non-negative matrix factorization
(NMF) algorithm to improve the learned HMM parameters. Numerical examples are
provided as well.
</summary>
    <author>
      <name>George Cybenko</name>
    </author>
    <author>
      <name>Valentino Crespi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to IEEE Transactions on Information Theory in September
  2008</arxiv:comment>
    <link href="http://arxiv.org/abs/0809.4086v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0809.4086v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0809.4632v1</id>
    <updated>2008-09-26T13:47:36Z</updated>
    <published>2008-09-26T13:47:36Z</published>
    <title>Surrogate Learning - An Approach for Semi-Supervised Classification</title>
    <summary>  We consider the task of learning a classifier from the feature space
$\mathcal{X}$ to the set of classes $\mathcal{Y} = \{0, 1\}$, when the features
can be partitioned into class-conditionally independent feature sets
$\mathcal{X}_1$ and $\mathcal{X}_2$. We show the surprising fact that the
class-conditional independence can be used to represent the original learning
task in terms of 1) learning a classifier from $\mathcal{X}_2$ to
$\mathcal{X}_1$ and 2) learning the class-conditional distribution of the
feature set $\mathcal{X}_1$. This fact can be exploited for semi-supervised
learning because the former task can be accomplished purely from unlabeled
samples. We present experimental evaluation of the idea in two real world
applications.
</summary>
    <author>
      <name>Sriharsha Veeramachaneni</name>
    </author>
    <author>
      <name>Ravikumar Kondadadi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0809.4632v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0809.4632v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0810.3525v1</id>
    <updated>2008-10-20T11:09:15Z</updated>
    <published>2008-10-20T11:09:15Z</published>
    <title>The use of entropy to measure structural diversity</title>
    <summary>  In this paper entropy based methods are compared and used to measure
structural diversity of an ensemble of 21 classifiers. This measure is mostly
applied in ecology, whereby species counts are used as a measure of diversity.
The measures used were Shannon entropy, Simpsons and the Berger Parker
diversity indexes. As the diversity indexes increased so did the accuracy of
the ensemble. An ensemble dominated by classifiers with the same structure
produced poor accuracy. Uncertainty rule from information theory was also used
to further define diversity. Genetic algorithms were used to find the optimal
ensemble by using the diversity indices as the cost function. The method of
voting was used to aggregate the decisions.
</summary>
    <author>
      <name>L. Masisi</name>
    </author>
    <author>
      <name>V. Nelwamondo</name>
    </author>
    <author>
      <name>T. Marwala</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/0810.3525v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0810.3525v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0812.1357v1</id>
    <updated>2008-12-07T15:22:27Z</updated>
    <published>2008-12-07T15:22:27Z</published>
    <title>A Novel Clustering Algorithm Based on Quantum Random Walk</title>
    <summary>  The enormous successes have been made by quantum algorithms during the last
decade. In this paper, we combine the quantum random walk (QRW) with the
problem of data clustering, and develop two clustering algorithms based on the
one dimensional QRW. Then, the probability distributions on the positions
induced by QRW in these algorithms are investigated, which also indicates the
possibility of obtaining better results. Consequently, the experimental results
have demonstrated that data points in datasets are clustered reasonably and
efficiently, and the clustering algorithms are of fast rates of convergence.
Moreover, the comparison with other algorithms also provides an indication of
the effectiveness of the proposed approach.
</summary>
    <author>
      <name>Qiang Li</name>
    </author>
    <author>
      <name>Yan He</name>
    </author>
    <author>
      <name>Jing-ping Jiang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 6 figures, 3 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/0812.1357v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0812.1357v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0812.1869v1</id>
    <updated>2008-12-10T09:00:40Z</updated>
    <published>2008-12-10T09:00:40Z</published>
    <title>Convex Sparse Matrix Factorizations</title>
    <summary>  We present a convex formulation of dictionary learning for sparse signal
decomposition. Convexity is obtained by replacing the usual explicit upper
bound on the dictionary size by a convex rank-reducing term similar to the
trace norm. In particular, our formulation introduces an explicit trade-off
between size and sparsity of the decomposition of rectangular matrices. Using a
large set of synthetic examples, we compare the estimation abilities of the
convex and non-convex approaches, showing that while the convex formulation has
a single local minimum, this may lead in some cases to performance which is
inferior to the local minima of the non-convex formulation.
</summary>
    <author>
      <name>Francis Bach</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rocquencourt</arxiv:affiliation>
    </author>
    <author>
      <name>Julien Mairal</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rocquencourt</arxiv:affiliation>
    </author>
    <author>
      <name>Jean Ponce</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rocquencourt</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/0812.1869v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0812.1869v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0812.3147v1</id>
    <updated>2008-12-16T20:58:24Z</updated>
    <published>2008-12-16T20:58:24Z</published>
    <title>Comparison of Binary Classification Based on Signed Distance Functions
  with Support Vector Machines</title>
    <summary>  We investigate the performance of a simple signed distance function (SDF)
based method by direct comparison with standard SVM packages, as well as
K-nearest neighbor and RBFN methods. We present experimental results comparing
the SDF approach with other classifiers on both synthetic geometric problems
and five benchmark clinical microarray data sets. On both geometric problems
and microarray data sets, the non-optimized SDF based classifiers perform just
as well or slightly better than well-developed, standard SVM methods. These
results demonstrate the potential accuracy of SDF-based methods on some types
of problems.
</summary>
    <author>
      <name>Erik M. Boczko</name>
    </author>
    <author>
      <name>Todd Young</name>
    </author>
    <author>
      <name>Minhui Zie</name>
    </author>
    <author>
      <name>Di Wu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 4 figures. Presented at the Ohio Collaborative Conference on
  Bioinformatics (OCCBIO), June 2006</arxiv:comment>
    <link href="http://arxiv.org/abs/0812.3147v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0812.3147v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0812.4952v4</id>
    <updated>2009-05-20T17:40:23Z</updated>
    <published>2008-12-29T18:29:08Z</published>
    <title>Importance Weighted Active Learning</title>
    <summary>  We present a practical and statistically consistent scheme for actively
learning binary classifiers under general loss functions. Our algorithm uses
importance weighting to correct sampling bias, and by controlling the variance,
we are able to give rigorous label complexity bounds for the learning process.
Experiments on passively labeled data show that this approach reduces the label
complexity required to achieve good predictive performance on many learning
problems.
</summary>
    <author>
      <name>Alina Beygelzimer</name>
    </author>
    <author>
      <name>Sanjoy Dasgupta</name>
    </author>
    <author>
      <name>John Langford</name>
    </author>
    <link href="http://arxiv.org/abs/0812.4952v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0812.4952v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0901.2376v1</id>
    <updated>2009-01-16T01:00:39Z</updated>
    <published>2009-01-16T01:00:39Z</published>
    <title>A Limit Theorem in Singular Regression Problem</title>
    <summary>  In statistical problems, a set of parameterized probability distributions is
used to estimate the true probability distribution. If Fisher information
matrix at the true distribution is singular, then it has been left unknown what
we can estimate about the true distribution from random samples. In this paper,
we study a singular regression problem and prove a limit theorem which shows
the relation between the singular regression problem and two birational
invariants, a real log canonical threshold and a singular fluctuation. The
obtained theorem has an important application to statistics, because it enables
us to estimate the generalization error from the training error without any
knowledge of the true probability distribution.
</summary>
    <author>
      <name>Sumio Watanabe</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/0901.2376v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0901.2376v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0902.3373v1</id>
    <updated>2009-02-19T13:47:53Z</updated>
    <published>2009-02-19T13:47:53Z</published>
    <title>Learning rules from multisource data for cardiac monitoring</title>
    <summary>  This paper formalises the concept of learning symbolic rules from multisource
data in a cardiac monitoring context. Our sources, electrocardiograms and
arterial blood pressure measures, describe cardiac behaviours from different
viewpoints. To learn interpretable rules, we use an Inductive Logic Programming
(ILP) method. We develop an original strategy to cope with the dimensionality
issues caused by using this ILP technique on a rich multisource language. The
results show that our method greatly improves the feasibility and the
efficiency of the process while staying accurate. They also confirm the
benefits of using multiple sources to improve the diagnosis of cardiac
arrhythmias.
</summary>
    <author>
      <name>Marie-Odile Cordier</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA - Irisa</arxiv:affiliation>
    </author>
    <author>
      <name>Elisa Fromont</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LAHC</arxiv:affiliation>
    </author>
    <author>
      <name>René Quiniou</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA - Irisa</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/0902.3373v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0902.3373v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0902.4228v1</id>
    <updated>2009-02-24T20:38:32Z</updated>
    <published>2009-02-24T20:38:32Z</published>
    <title>Multiplicative updates For Non-Negative Kernel SVM</title>
    <summary>  We present multiplicative updates for solving hard and soft margin support
vector machines (SVM) with non-negative kernels. They follow as a natural
extension of the updates for non-negative matrix factorization. No additional
param- eter setting, such as choosing learning, rate is required. Ex- periments
demonstrate rapid convergence to good classifiers. We analyze the rates of
asymptotic convergence of the up- dates and establish tight bounds. We test the
performance on several datasets using various non-negative kernels and report
equivalent generalization errors to that of a standard SVM.
</summary>
    <author>
      <name>Vamsi K. Potluru</name>
    </author>
    <author>
      <name>Sergey M. Plis</name>
    </author>
    <author>
      <name>Morten Morup</name>
    </author>
    <author>
      <name>Vince D. Calhoun</name>
    </author>
    <author>
      <name>Terran Lane</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 1 figure, 1 table</arxiv:comment>
    <link href="http://arxiv.org/abs/0902.4228v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0902.4228v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0903.0064v2</id>
    <updated>2009-04-19T04:18:30Z</updated>
    <published>2009-02-28T11:17:12Z</published>
    <title>Manipulation Robustness of Collaborative Filtering Systems</title>
    <summary>  A collaborative filtering system recommends to users products that similar
users like. Collaborative filtering systems influence purchase decisions, and
hence have become targets of manipulation by unscrupulous vendors. We provide
theoretical and empirical results demonstrating that while common nearest
neighbor algorithms, which are widely used in commercial systems, can be highly
susceptible to manipulation, two classes of collaborative filtering algorithms
which we refer to as linear and asymptotically linear are relatively robust.
These results provide guidance for the design of future collaborative filtering
systems.
</summary>
    <author>
      <name>Xiang Yan</name>
    </author>
    <author>
      <name>Benjamin Van Roy</name>
    </author>
    <link href="http://arxiv.org/abs/0903.0064v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0903.0064v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0903.2870v2</id>
    <updated>2009-06-24T14:10:45Z</updated>
    <published>2009-03-16T22:52:06Z</published>
    <title>On $p$-adic Classification</title>
    <summary>  A $p$-adic modification of the split-LBG classification method is presented
in which first clusterings and then cluster centers are computed which locally
minimise an energy function. The outcome for a fixed dataset is independent of
the prime number $p$ with finitely many exceptions. The methods are applied to
the construction of $p$-adic classifiers in the context of learning.
</summary>
    <author>
      <name>Patrick Erik Bradley</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1134/S2070046609040013</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1134/S2070046609040013" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 7 figures, 1 table; added reference, corrected typos, minor
  content changes</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">p-Adic Numbers, Ultrametric Analysis, and Applications, Vol. 1,
  No. 4 (2009), 271-285</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0903.2870v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0903.2870v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0903.4217v2</id>
    <updated>2009-06-03T21:19:34Z</updated>
    <published>2009-03-25T00:28:44Z</published>
    <title>Conditional Probability Tree Estimation Analysis and Algorithms</title>
    <summary>  We consider the problem of estimating the conditional probability of a label
in time $O(\log n)$, where $n$ is the number of possible labels. We analyze a
natural reduction of this problem to a set of binary regression problems
organized in a tree structure, proving a regret bound that scales with the
depth of the tree. Motivated by this analysis, we propose the first online
algorithm which provably constructs a logarithmic depth tree on the set of
labels to solve this problem. We test the algorithm empirically, showing that
it works succesfully on a dataset with roughly $10^6$ labels.
</summary>
    <author>
      <name>Alina Beygelzimer</name>
    </author>
    <author>
      <name>John Langford</name>
    </author>
    <author>
      <name>Yuri Lifshits</name>
    </author>
    <author>
      <name>Gregory Sorkin</name>
    </author>
    <author>
      <name>Alex Strehl</name>
    </author>
    <link href="http://arxiv.org/abs/0903.4217v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0903.4217v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0904.0648v1</id>
    <updated>2009-04-03T20:30:24Z</updated>
    <published>2009-04-03T20:30:24Z</published>
    <title>Evolvability need not imply learnability</title>
    <summary>  We show that Boolean functions expressible as monotone disjunctive normal
forms are PAC-evolvable under a uniform distribution on the Boolean cube if the
hypothesis size is allowed to remain fixed. We further show that this result is
insufficient to prove the PAC-learnability of monotone Boolean functions,
thereby demonstrating a counter-example to a recent claim to the contrary. We
further discuss scenarios wherein evolvability and learnability will coincide
as well as scenarios under which they differ. The implications of the latter
case on the prospects of learning in complex hypothesis spaces is briefly
examined.
</summary>
    <author>
      <name>Nisheeth Srivastava</name>
    </author>
    <link href="http://arxiv.org/abs/0904.0648v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0904.0648v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0904.0814v1</id>
    <updated>2009-04-05T20:08:44Z</updated>
    <published>2009-04-05T20:08:44Z</published>
    <title>Stability Analysis and Learning Bounds for Transductive Regression
  Algorithms</title>
    <summary>  This paper uses the notion of algorithmic stability to derive novel
generalization bounds for several families of transductive regression
algorithms, both by using convexity and closed-form solutions. Our analysis
helps compare the stability of these algorithms. It also shows that a number of
widely used transductive regression algorithms are in fact unstable. Finally,
it reports the results of experiments with local transductive regression
demonstrating the benefit of our stability bounds for model selection, for one
of the algorithms, in particular for determining the radius of the local
neighborhood used by the algorithm.
</summary>
    <author>
      <name>Corinna Cortes</name>
    </author>
    <author>
      <name>Mehryar Mohri</name>
    </author>
    <author>
      <name>Dmitry Pechyony</name>
    </author>
    <author>
      <name>Ashish Rastogi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">26 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/0904.0814v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0904.0814v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0904.3667v1</id>
    <updated>2009-04-23T11:48:38Z</updated>
    <published>2009-04-23T11:48:38Z</published>
    <title>Considerations upon the Machine Learning Technologies</title>
    <summary>  Artificial intelligence offers superior techniques and methods by which
problems from diverse domains may find an optimal solution. The Machine
Learning technologies refer to the domain of artificial intelligence aiming to
develop the techniques allowing the computers to "learn". Some systems based on
Machine Learning technologies tend to eliminate the necessity of the human
intelligence while the others adopt a man-machine collaborative approach.
</summary>
    <author>
      <name>Alin Munteanu</name>
    </author>
    <author>
      <name>Cristina Ofelia Sofran</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages,exposed on 1st "European Conference on Computer Sciences &amp;
  Applications" - XA2006, Timisoara, Romania</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Ann. Univ. Tibiscus Comp. Sci. Series IV (2006), 133-138</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0904.3667v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0904.3667v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0905.2347v1</id>
    <updated>2009-05-14T14:59:15Z</updated>
    <published>2009-05-14T14:59:15Z</published>
    <title>Combining Supervised and Unsupervised Learning for GIS Classification</title>
    <summary>  This paper presents a new hybrid learning algorithm for unsupervised
classification tasks. We combined Fuzzy c-means learning algorithm and a
supervised version of Minimerror to develop a hybrid incremental strategy
allowing unsupervised classifications. We applied this new approach to a
real-world database in order to know if the information contained in unlabeled
features of a Geographic Information System (GIS), allows to well classify it.
Finally, we compared our results to a classical supervised classification
obtained by a multilayer perceptron.
</summary>
    <author>
      <name>Juan-Manuel Torres-Moreno</name>
    </author>
    <author>
      <name>Laurent Bougrain</name>
    </author>
    <author>
      <name>Frdéric Alexandre</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0905.2347v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0905.2347v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0905.2997v1</id>
    <updated>2009-05-18T23:21:35Z</updated>
    <published>2009-05-18T23:21:35Z</published>
    <title>Average-Case Active Learning with Costs</title>
    <summary>  We analyze the expected cost of a greedy active learning algorithm. Our
analysis extends previous work to a more general setting in which different
queries have different costs. Moreover, queries may have more than two possible
responses and the distribution over hypotheses may be non uniform. Specific
applications include active learning with label costs, active learning for
multiclass and partial label queries, and batch mode active learning. We also
discuss an approximate version of interest when there are very many queries.
</summary>
    <author>
      <name>Andrew Guillory</name>
    </author>
    <author>
      <name>Jeff Bilmes</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0905.2997v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0905.2997v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0906.0470v1</id>
    <updated>2009-06-02T11:52:36Z</updated>
    <published>2009-06-02T11:52:36Z</published>
    <title>An optimal linear separator for the Sonar Signals Classification task</title>
    <summary>  The problem of classifying sonar signals from rocks and mines first studied
by Gorman and Sejnowski has become a benchmark against which many learning
algorithms have been tested. We show that both the training set and the test
set of this benchmark are linearly separable, although with different
hyperplanes. Moreover, the complete set of learning and test patterns together,
is also linearly separable. We give the weights that separate these sets, which
may be used to compare results found by other algorithms.
</summary>
    <author>
      <name>Juan-Manuel Torres-Moreno</name>
    </author>
    <author>
      <name>Mirta B. Gordon</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 6 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/0906.0470v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0906.0470v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0906.0872v1</id>
    <updated>2009-06-04T10:25:08Z</updated>
    <published>2009-06-04T10:25:08Z</published>
    <title>Fast Weak Learner Based on Genetic Algorithm</title>
    <summary>  An approach to the acceleration of parametric weak classifier boosting is
proposed. Weak classifier is called parametric if it has fixed number of
parameters and, so, can be represented as a point into multidimensional space.
Genetic algorithm is used instead of exhaustive search to learn parameters of
such classifier. Proposed approach also takes cases when effective algorithm
for learning some of the classifier parameters exists into account. Experiments
confirm that such an approach can dramatically decrease classifier training
time while keeping both training and test errors small.
</summary>
    <author>
      <name>Boris Yangel</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, acmsiggraph latex style packed with the latex source in the
  single archive</arxiv:comment>
    <link href="http://arxiv.org/abs/0906.0872v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0906.0872v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0906.2027v2</id>
    <updated>2012-04-09T17:37:45Z</updated>
    <published>2009-06-11T00:22:58Z</published>
    <title>Matrix Completion from Noisy Entries</title>
    <summary>  Given a matrix M of low-rank, we consider the problem of reconstructing it
from noisy observations of a small, random subset of its entries. The problem
arises in a variety of applications, from collaborative filtering (the `Netflix
problem') to structure-from-motion and positioning. We study a low complexity
algorithm introduced by Keshavan et al.(2009), based on a combination of
spectral techniques and manifold optimization, that we call here OptSpace. We
prove performance guarantees that are order-optimal in a number of
circumstances.
</summary>
    <author>
      <name>Raghunandan H. Keshavan</name>
    </author>
    <author>
      <name>Andrea Montanari</name>
    </author>
    <author>
      <name>Sewoong Oh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">22 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0906.2027v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0906.2027v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0906.5151v1</id>
    <updated>2009-06-28T17:47:22Z</updated>
    <published>2009-06-28T17:47:22Z</published>
    <title>Unsupervised Search-based Structured Prediction</title>
    <summary>  We describe an adaptation and application of a search-based structured
prediction algorithm "Searn" to unsupervised learning problems. We show that it
is possible to reduce unsupervised learning to supervised learning and
demonstrate a high-quality unsupervised shift-reduce parsing model. We
additionally show a close connection between unsupervised Searn and expectation
maximization. Finally, we demonstrate the efficacy of a semi-supervised
extension. The key idea that enables this is an application of the predict-self
idea for unsupervised learning.
</summary>
    <author>
      <name>Hal Daumé III</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the International Conference on Machine Learning,
  2009</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0906.5151v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0906.5151v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0907.0786v1</id>
    <updated>2009-07-04T18:48:34Z</updated>
    <published>2009-07-04T18:48:34Z</published>
    <title>Search-based Structured Prediction</title>
    <summary>  We present Searn, an algorithm for integrating search and learning to solve
complex structured prediction problems such as those that occur in natural
language, speech, computational biology, and vision. Searn is a meta-algorithm
that transforms these complex problems into simple classification problems to
which any binary classifier may be applied. Unlike current algorithms for
structured learning that require decomposition of both the loss function and
the feature functions over the predicted structure, Searn is able to learn
prediction functions for any loss function and any class of features. Moreover,
Searn comes with a strong, natural theoretical guarantee: good performance on
the derived classification problems implies good performance on the structured
prediction problem.
</summary>
    <author>
      <name>Hal Daumé III</name>
    </author>
    <author>
      <name>John Langford</name>
    </author>
    <author>
      <name>Daniel Marcu</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Machine Learning Journal 2009</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0907.0786v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0907.0786v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0907.0809v1</id>
    <updated>2009-07-04T22:34:25Z</updated>
    <published>2009-07-04T22:34:25Z</published>
    <title>Learning as Search Optimization: Approximate Large Margin Methods for
  Structured Prediction</title>
    <summary>  Mappings to structured output spaces (strings, trees, partitions, etc.) are
typically learned using extensions of classification algorithms to simple
graphical structures (eg., linear chains) in which search and parameter
estimation can be performed exactly. Unfortunately, in many complex problems,
it is rare that exact search or parameter estimation is tractable. Instead of
learning exact models and searching via heuristic means, we embrace this
difficulty and treat the structured output problem in terms of approximate
search. We present a framework for learning as search optimization, and two
parameter updates with convergence theorems and bounds. Empirical evidence
shows that our integrated approach to learning and decoding can outperform
exact models at smaller computational cost.
</summary>
    <author>
      <name>Hal Daumé III</name>
    </author>
    <author>
      <name>Daniel Marcu</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ICML 2005</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0907.0809v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0907.0809v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0907.1812v1</id>
    <updated>2009-07-10T13:23:37Z</updated>
    <published>2009-07-10T13:23:37Z</published>
    <title>Fast search for Dirichlet process mixture models</title>
    <summary>  Dirichlet process (DP) mixture models provide a flexible Bayesian framework
for density estimation. Unfortunately, their flexibility comes at a cost:
inference in DP mixture models is computationally expensive, even when
conjugate distributions are used. In the common case when one seeks only a
maximum a posteriori assignment of data points to clusters, we show that search
algorithms provide a practical alternative to expensive MCMC and variational
techniques. When a true posterior sample is desired, the solution found by
search can serve as a good initializer for MCMC. Experimental results show that
using these techniques is it possible to apply DP mixture models to very large
data sets.
</summary>
    <author>
      <name>Hal Daumé III</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">AIStats 2007</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0907.1812v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0907.1812v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0907.1815v1</id>
    <updated>2009-07-10T13:25:48Z</updated>
    <published>2009-07-10T13:25:48Z</published>
    <title>Frustratingly Easy Domain Adaptation</title>
    <summary>  We describe an approach to domain adaptation that is appropriate exactly in
the case when one has enough ``target'' data to do slightly better than just
using only ``source'' data. Our approach is incredibly simple, easy to
implement as a preprocessing step (10 lines of Perl!) and outperforms
state-of-the-art approaches on a range of datasets. Moreover, it is trivially
extended to a multi-domain adaptation problem, where one has data from a
variety of different domains.
</summary>
    <author>
      <name>Hal Daumé III</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ACL 2007</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0907.1815v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0907.1815v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0908.0939v1</id>
    <updated>2009-08-06T19:48:20Z</updated>
    <published>2009-08-06T19:48:20Z</published>
    <title>Clustering for Improved Learning in Maze Traversal Problem</title>
    <summary>  The maze traversal problem (finding the shortest distance to the goal from
any position in a maze) has been an interesting challenge in computational
intelligence. Recent work has shown that the cellular simultaneous recurrent
neural network (CSRN) can solve this problem for simple mazes. This thesis
focuses on exploiting relevant information about the maze to improve learning
and decrease the training time for the CSRN to solve mazes. Appropriate
variables are identified to create useful clusters using relevant information.
The CSRN was next modified to allow for an additional external input. With this
additional input, several methods were tested and results show that clustering
the mazes improves the overall learning of the traversal problem for the CSRN.
</summary>
    <author>
      <name>Eddie White</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">29 pages, 15 figures, Undergraduate Honors Thesis</arxiv:comment>
    <link href="http://arxiv.org/abs/0908.0939v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0908.0939v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0909.0638v1</id>
    <updated>2009-09-03T12:09:08Z</updated>
    <published>2009-09-03T12:09:08Z</published>
    <title>Median topographic maps for biomedical data sets</title>
    <summary>  Median clustering extends popular neural data analysis methods such as the
self-organizing map or neural gas to general data structures given by a
dissimilarity matrix only. This offers flexible and robust global data
inspection methods which are particularly suited for a variety of data as
occurs in biomedical domains. In this chapter, we give an overview about median
clustering and its properties and extensions, with a particular focus on
efficient implementations adapted to large scale data analysis.
</summary>
    <author>
      <name>Barbara Hammer</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LTCI</arxiv:affiliation>
    </author>
    <author>
      <name>Alexander Hasenfuß</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LTCI</arxiv:affiliation>
    </author>
    <author>
      <name>Fabrice Rossi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LTCI</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-642-01805-3_6</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-642-01805-3_6" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Similarity-Based Clustering, Villmann, Th.; Biehl, M.; Hammer, B.;
  Verleysen, M. (Ed.) (2009) 92-117</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0909.0638v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0909.0638v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0909.3609v1</id>
    <updated>2009-09-19T23:40:10Z</updated>
    <published>2009-09-19T23:40:10Z</published>
    <title>Randomized Algorithms for Large scale SVMs</title>
    <summary>  We propose a randomized algorithm for training Support vector machines(SVMs)
on large datasets. By using ideas from Random projections we show that the
combinatorial dimension of SVMs is $O({log} n)$ with high probability. This
estimate of combinatorial dimension is used to derive an iterative algorithm,
called RandSVM, which at each step calls an existing solver to train SVMs on a
randomly chosen subset of size $O({log} n)$. The algorithm has probabilistic
guarantees and is capable of training SVMs with Kernels for both classification
and regression problems. Experiments done on synthetic and real life data sets
demonstrate that the algorithm scales up existing SVM learners, without loss of
accuracy.
</summary>
    <author>
      <name>Vinay Jethava</name>
    </author>
    <author>
      <name>Krishnan Suresh</name>
    </author>
    <author>
      <name>Chiranjib Bhattacharyya</name>
    </author>
    <author>
      <name>Ramesh Hariharan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages, Submitted to Machine Learning journal (October 2008) -
  under revision</arxiv:comment>
    <link href="http://arxiv.org/abs/0909.3609v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0909.3609v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0910.2540v1</id>
    <updated>2009-10-14T07:43:03Z</updated>
    <published>2009-10-14T07:43:03Z</published>
    <title>Effectiveness and Limitations of Statistical Spam Filters</title>
    <summary>  In this paper we discuss the techniques involved in the design of the famous
statistical spam filters that include Naive Bayes, Term Frequency-Inverse
Document Frequency, K-Nearest Neighbor, Support Vector Machine, and Bayes
Additive Regression Tree. We compare these techniques with each other in terms
of accuracy, recall, precision, etc. Further, we discuss the effectiveness and
limitations of statistical filters in filtering out various types of spam from
legitimate e-mails.
</summary>
    <author>
      <name>M. Tariq Banday</name>
    </author>
    <author>
      <name>Tariq R. Jan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">International Conference on New Trends in Statistics and
  Optimization, Organized by Department of Statistics, University of Kashmir,
  Srinagar, India, from 20th to 23rd October, 2008</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Conference on New Trends in Statistics and
  Optimization, Organized by Department of Statistics, University of Kashmir,
  Srinagar, India, from 20th to 23rd October, 2008</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0910.2540v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0910.2540v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="K.6.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0910.4627v1</id>
    <updated>2009-10-24T07:10:24Z</updated>
    <published>2009-10-24T07:10:24Z</published>
    <title>Self-concordant analysis for logistic regression</title>
    <summary>  Most of the non-asymptotic theoretical work in regression is carried out for
the square loss, where estimators can be obtained through closed-form
expressions. In this paper, we use and extend tools from the convex
optimization literature, namely self-concordant functions, to provide simple
extensions of theoretical results for the square loss to the logistic loss. We
apply the extension techniques to logistic regression with regularization by
the $\ell_2$-norm and regularization by the $\ell_1$-norm, showing that new
results for binary classification through logistic regression can be easily
derived from corresponding results for least-squares regression.
</summary>
    <author>
      <name>Francis Bach</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rocquencourt</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/0910.4627v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0910.4627v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0911.0054v2</id>
    <updated>2015-05-16T22:45:35Z</updated>
    <published>2009-10-31T02:56:18Z</published>
    <title>Learning Exponential Families in High-Dimensions: Strong Convexity and
  Sparsity</title>
    <summary>  The versatility of exponential families, along with their attendant convexity
properties, make them a popular and effective statistical model. A central
issue is learning these models in high-dimensions, such as when there is some
sparsity pattern of the optimal parameter. This work characterizes a certain
strong convexity property of general exponential families, which allow their
generalization ability to be quantified. In particular, we show how this
property can be used to analyze generic exponential families under L_1
regularization.
</summary>
    <author>
      <name>Sham M. Kakade</name>
    </author>
    <author>
      <name>Ohad Shamir</name>
    </author>
    <author>
      <name>Karthik Sridharan</name>
    </author>
    <author>
      <name>Ambuj Tewari</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Errata added. Incorrect claim about cumulants of the Bernoulli
  distribution fixed</arxiv:comment>
    <link href="http://arxiv.org/abs/0911.0054v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0911.0054v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0911.0462v1</id>
    <updated>2009-11-03T00:27:36Z</updated>
    <published>2009-11-03T00:27:36Z</published>
    <title>Strange Bedfellows: Quantum Mechanics and Data Mining</title>
    <summary>  Last year, in 2008, I gave a talk titled {\it Quantum Calisthenics}. This
year I am going to tell you about how the work I described then has spun off
into a most unlikely direction. What I am going to talk about is how one maps
the problem of finding clusters in a given data set into a problem in quantum
mechanics. I will then use the tricks I described to let quantum evolution lets
the clusters come together on their own.
</summary>
    <author>
      <name>Marvin Weinstein</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.nuclphysbps.2010.02.009</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.nuclphysbps.2010.02.009" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 7 figures, Invited Talk at Light Cone 2009</arxiv:comment>
    <link href="http://arxiv.org/abs/0911.0462v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0911.0462v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
    <category term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0911.4863v2</id>
    <updated>2011-05-13T01:52:49Z</updated>
    <published>2009-11-25T14:26:54Z</published>
    <title>Statistical exponential families: A digest with flash cards</title>
    <summary>  This document describes concisely the ubiquitous class of exponential family
distributions met in statistics. The first part recalls definitions and
summarizes main properties and duality with Bregman divergences (all proofs are
skipped). The second part lists decompositions and related formula of common
exponential family distributions. We recall the Fisher-Rao-Riemannian
geometries and the dual affine connection information geometries of statistical
manifolds. It is intended to maintain and update this document and catalog by
adding new distribution items.
</summary>
    <author>
      <name>Frank Nielsen</name>
    </author>
    <author>
      <name>Vincent Garcia</name>
    </author>
    <link href="http://arxiv.org/abs/0911.4863v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0911.4863v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0912.5029v1</id>
    <updated>2009-12-26T16:32:46Z</updated>
    <published>2009-12-26T16:32:46Z</published>
    <title>Complexity of stochastic branch and bound methods for belief tree search
  in Bayesian reinforcement learning</title>
    <summary>  There has been a lot of recent work on Bayesian methods for reinforcement
learning exhibiting near-optimal online performance. The main obstacle facing
such methods is that in most problems of interest, the optimal solution
involves planning in an infinitely large tree. However, it is possible to
obtain stochastic lower and upper bounds on the value of each tree node. This
enables us to use stochastic branch and bound algorithms to search the tree
efficiently. This paper proposes two such algorithms and examines their
complexity in this setting.
</summary>
    <author>
      <name>Christos Dimitrakakis</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 1 figure, ICAART 2010</arxiv:comment>
    <link href="http://arxiv.org/abs/0912.5029v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0912.5029v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1001.0879v1</id>
    <updated>2010-01-06T12:40:13Z</updated>
    <published>2010-01-06T12:40:13Z</published>
    <title>Linear Probability Forecasting</title>
    <summary>  Multi-class classification is one of the most important tasks in machine
learning. In this paper we consider two online multi-class classification
problems: classification by a linear model and by a kernelized model. The
quality of predictions is measured by the Brier loss function. We suggest two
computationally efficient algorithms to work with these problems and prove
theoretical guarantees on their losses. We kernelize one of the algorithms and
prove theoretical guarantees on its loss. We perform experiments and compare
our algorithms with logistic regression.
</summary>
    <author>
      <name>Fedor Zhdanov</name>
    </author>
    <author>
      <name>Yuri Kalnishkan</name>
    </author>
    <link href="http://arxiv.org/abs/1001.0879v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1001.0879v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1001.3478v1</id>
    <updated>2010-01-20T07:30:02Z</updated>
    <published>2010-01-20T07:30:02Z</published>
    <title>Role of Interestingness Measures in CAR Rule Ordering for Associative
  Classifier: An Empirical Approach</title>
    <summary>  Associative Classifier is a novel technique which is the integration of
Association Rule Mining and Classification. The difficult task in building
Associative Classifier model is the selection of relevant rules from a large
number of class association rules (CARs). A very popular method of ordering
rules for selection is based on confidence, support and antecedent size (CSA).
Other methods are based on hybrid orderings in which CSA method is combined
with other measures. In the present work, we study the effect of using
different interestingness measures of Association rules in CAR rule ordering
and selection for associative classifier.
</summary>
    <author>
      <name>S. Kannan</name>
    </author>
    <author>
      <name>R. Bhaskaran</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Computing, Vol. 2, Issue 1, January 2010</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1001.3478v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1001.3478v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1002.0709v1</id>
    <updated>2010-02-03T11:31:24Z</updated>
    <published>2010-02-03T11:31:24Z</published>
    <title>Aggregating Algorithm competing with Banach lattices</title>
    <summary>  The paper deals with on-line regression settings with signals belonging to a
Banach lattice. Our algorithms work in a semi-online setting where all the
inputs are known in advance and outcomes are unknown and given step by step. We
apply the Aggregating Algorithm to construct a prediction method whose
cumulative loss over all the input vectors is comparable with the cumulative
loss of any linear functional on the Banach lattice. As a by-product we get an
algorithm that takes signals from an arbitrary domain. Its cumulative loss is
comparable with the cumulative loss of any predictor function from Besov and
Triebel-Lizorkin spaces. We describe several applications of our setting.
</summary>
    <author>
      <name>Fedor Zhdanov</name>
    </author>
    <author>
      <name>Alexey Chernov</name>
    </author>
    <author>
      <name>Yuri Kalnishkan</name>
    </author>
    <link href="http://arxiv.org/abs/1002.0709v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1002.0709v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1002.2044v1</id>
    <updated>2010-02-10T09:08:56Z</updated>
    <published>2010-02-10T09:08:56Z</published>
    <title>On the Stability of Empirical Risk Minimization in the Presence of
  Multiple Risk Minimizers</title>
    <summary>  Recently Kutin and Niyogi investigated several notions of algorithmic
stability--a property of a learning map conceptually similar to
continuity--showing that training-stability is sufficient for consistency of
Empirical Risk Minimization while distribution-free CV-stability is necessary
and sufficient for having finite VC-dimension. This paper concerns a phase
transition in the training stability of ERM, conjectured by the same authors.
Kutin and Niyogi proved that ERM on finite hypothesis spaces containing a
unique risk minimizer has training stability that scales exponentially with
sample size, and conjectured that the existence of multiple risk minimizers
prevents even super-quadratic convergence. We prove this result for the
strictly weaker notion of CV-stability, positively resolving the conjecture.
</summary>
    <author>
      <name>Benjamin I. P. Rubinstein</name>
    </author>
    <author>
      <name>Aleksandr Simma</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1002.2044v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1002.2044v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1002.3345v2</id>
    <updated>2010-05-20T23:39:23Z</updated>
    <published>2010-02-17T18:43:59Z</published>
    <title>Interactive Submodular Set Cover</title>
    <summary>  We introduce a natural generalization of submodular set cover and exact
active learning with a finite hypothesis class (query learning). We call this
new problem interactive submodular set cover. Applications include advertising
in social networks with hidden information. We give an approximation guarantee
for a novel greedy algorithm and give a hardness of approximation result which
matches up to constant factors. We also discuss negative results for simpler
approaches and present encouraging early experimental results.
</summary>
    <author>
      <name>Andrew Guillory</name>
    </author>
    <author>
      <name>Jeff Bilmes</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1002.3345v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1002.3345v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1002.4862v1</id>
    <updated>2010-02-25T20:31:05Z</updated>
    <published>2010-02-25T20:31:05Z</published>
    <title>Less Regret via Online Conditioning</title>
    <summary>  We analyze and evaluate an online gradient descent algorithm with adaptive
per-coordinate adjustment of learning rates. Our algorithm can be thought of as
an online version of batch gradient descent with a diagonal preconditioner.
This approach leads to regret bounds that are stronger than those of standard
online gradient descent for general online convex optimization problems.
Experimentally, we show that our algorithm is competitive with state-of-the-art
algorithms for large scale machine learning problems.
</summary>
    <author>
      <name>Matthew Streeter</name>
    </author>
    <author>
      <name>H. Brendan McMahan</name>
    </author>
    <link href="http://arxiv.org/abs/1002.4862v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1002.4862v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1003.0024v1</id>
    <updated>2010-02-26T21:59:02Z</updated>
    <published>2010-02-26T21:59:02Z</published>
    <title>Asymptotic Analysis of Generative Semi-Supervised Learning</title>
    <summary>  Semisupervised learning has emerged as a popular framework for improving
modeling accuracy while controlling labeling cost. Based on an extension of
stochastic composite likelihood we quantify the asymptotic accuracy of
generative semi-supervised learning. In doing so, we complement
distribution-free analysis by providing an alternative framework to measure the
value associated with different labeling policies and resolve the fundamental
question of how much data to label and in what manner. We demonstrate our
approach with both simulation studies and real world experiments using naive
Bayes for text classification and MRFs and CRFs for structured prediction in
NLP.
</summary>
    <author>
      <name>Joshua V Dillon</name>
    </author>
    <author>
      <name>Krishnakumar Balasubramanian</name>
    </author>
    <author>
      <name>Guy Lebanon</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 9 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1003.0024v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1003.0024v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1003.0470v2</id>
    <updated>2010-07-21T21:19:35Z</updated>
    <published>2010-03-01T22:32:18Z</published>
    <title>Unsupervised Supervised Learning II: Training Margin Based Classifiers
  without Labels</title>
    <summary>  Many popular linear classifiers, such as logistic regression, boosting, or
SVM, are trained by optimizing a margin-based risk function. Traditionally,
these risk functions are computed based on a labeled dataset. We develop a
novel technique for estimating such risks using only unlabeled data and the
marginal label distribution. We prove that the proposed risk estimator is
consistent on high-dimensional datasets and demonstrate it on synthetic and
real-world data. In particular, we show how the estimate is used for evaluating
classifiers in transfer learning, and for training classifiers with no labeled
data whatsoever.
</summary>
    <author>
      <name>Krishnakumar Balasubramanian</name>
    </author>
    <author>
      <name>Pinar Donmez</name>
    </author>
    <author>
      <name>Guy Lebanon</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">22 pages, 43 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1003.0470v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1003.0470v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1004.1230v1</id>
    <updated>2010-04-08T03:06:24Z</updated>
    <published>2010-04-08T03:06:24Z</published>
    <title>Ontology-supported processing of clinical text using medical knowledge
  integration for multi-label classification of diagnosis coding</title>
    <summary>  This paper discusses the knowledge integration of clinical information
extracted from distributed medical ontology in order to ameliorate a machine
learning-based multi-label coding assignment system. The proposed approach is
implemented using a decision tree based cascade hierarchical technique on the
university hospital data for patients with Coronary Heart Disease (CHD). The
preliminary results obtained show a satisfactory finding.
</summary>
    <author>
      <name>Phanu Waraporn</name>
    </author>
    <author>
      <name>Phayung Meesad</name>
    </author>
    <author>
      <name>Gareth Clayton</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE Publication format, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IJCSIS, Vol. 7 No. 3, March 2010,</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1004.1230v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1004.1230v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1004.1982v1</id>
    <updated>2010-04-09T09:36:28Z</updated>
    <published>2010-04-09T09:36:28Z</published>
    <title>State-Space Dynamics Distance for Clustering Sequential Data</title>
    <summary>  This paper proposes a novel similarity measure for clustering sequential
data. We first construct a common state-space by training a single
probabilistic model with all the sequences in order to get a unified
representation for the dataset. Then, distances are obtained attending to the
transition matrices induced by each sequence in that state-space. This approach
solves some of the usual overfitting and scalability issues of the existing
semi-parametric techniques, that rely on training a model for each sequence.
Empirical studies on both synthetic and real-world datasets illustrate the
advantages of the proposed similarity measure for clustering sequences.
</summary>
    <author>
      <name>Darío García-García</name>
    </author>
    <author>
      <name>Emilio Parrado-Hernández</name>
    </author>
    <author>
      <name>Fernando Díaz-de-María</name>
    </author>
    <link href="http://arxiv.org/abs/1004.1982v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1004.1982v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1004.3814v1</id>
    <updated>2010-04-21T23:09:06Z</updated>
    <published>2010-04-21T23:09:06Z</published>
    <title>Bregman Distance to L1 Regularized Logistic Regression</title>
    <summary>  In this work we investigate the relationship between Bregman distances and
regularized Logistic Regression model. We present a detailed study of Bregman
Distance minimization, a family of generalized entropy measures associated with
convex functions. We convert the L1-regularized logistic regression into this
more general framework and propose a primal-dual method based algorithm for
learning the parameters. We pose L1-regularized logistic regression into
Bregman distance minimization and then apply non-linear constrained
optimization techniques to estimate the parameters of the logistic model.
</summary>
    <author>
      <name>Mithun Das Gupta</name>
    </author>
    <author>
      <name>Thomas S. Huang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 3 images, shorter version published in ICPR 2008 by same
  authors.</arxiv:comment>
    <link href="http://arxiv.org/abs/1004.3814v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1004.3814v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1005.0047v1</id>
    <updated>2010-05-01T06:06:36Z</updated>
    <published>2010-05-01T06:06:36Z</published>
    <title>A Geometric View of Conjugate Priors</title>
    <summary>  In Bayesian machine learning, conjugate priors are popular, mostly due to
mathematical convenience. In this paper, we show that there are deeper reasons
for choosing a conjugate prior. Specifically, we formulate the conjugate prior
in the form of Bregman divergence and show that it is the inherent geometry of
conjugate priors that makes them appropriate and intuitive. This geometric
interpretation allows one to view the hyperparameters of conjugate priors as
the {\it effective} sample points, thus providing additional intuition. We use
this geometric understanding of conjugate priors to derive the hyperparameters
and expression of the prior used to couple the generative and discriminative
components of a hybrid model for semi-supervised learning.
</summary>
    <author>
      <name>Arvind Agarwal</name>
    </author>
    <author>
      <name>Hal Daume III</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 4 Figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1005.0047v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1005.0047v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1005.0125v1</id>
    <updated>2010-05-02T06:40:21Z</updated>
    <published>2010-05-02T06:40:21Z</published>
    <title>Adaptive Bases for Reinforcement Learning</title>
    <summary>  We consider the problem of reinforcement learning using function
approximation, where the approximating basis can change dynamically while
interacting with the environment. A motivation for such an approach is
maximizing the value function fitness to the problem faced. Three errors are
considered: approximation square error, Bellman residual, and projected Bellman
residual. Algorithms under the actor-critic framework are presented, and shown
to converge. The advantage of such an adaptive basis is demonstrated in
simulations.
</summary>
    <author>
      <name>Dotan Di Castro</name>
    </author>
    <author>
      <name>Shie Mannor</name>
    </author>
    <link href="http://arxiv.org/abs/1005.0125v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1005.0125v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1005.5170v1</id>
    <updated>2010-05-25T16:07:25Z</updated>
    <published>2010-05-25T16:07:25Z</published>
    <title>Wirtinger's Calculus in general Hilbert Spaces</title>
    <summary>  The present report, has been inspired by the need of the author and its
colleagues to understand the underlying theory of Wirtinger's Calculus and to
further extend it to include the kernel case. The aim of the present manuscript
is twofold: a) it endeavors to provide a more rigorous presentation of the
related material, focusing on aspects that the author finds more insightful and
b) it extends the notions of Wirtinger's calculus on general Hilbert spaces
(such as Reproducing Hilbert Kernel Spaces).
</summary>
    <author>
      <name>P. Bouboulis</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Report completed for the department of Informatics and
  Telecommunications of the University of Athens</arxiv:comment>
    <link href="http://arxiv.org/abs/1005.5170v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1005.5170v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1005.5462v2</id>
    <updated>2010-06-12T10:40:53Z</updated>
    <published>2010-05-29T15:27:16Z</published>
    <title>On the clustering aspect of nonnegative matrix factorization</title>
    <summary>  This paper provides a theoretical explanation on the clustering aspect of
nonnegative matrix factorization (NMF). We prove that even without imposing
orthogonality nor sparsity constraint on the basis and/or coefficient matrix,
NMF still can give clustering results, thus providing a theoretical support for
many works, e.g., Xu et al. [1] and Kim et al. [2], that show the superiority
of the standard NMF as a clustering method.
</summary>
    <author>
      <name>Andri Mirzal</name>
    </author>
    <author>
      <name>Masashi Furukawa</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, no figure, to appear in ICEIE 2010</arxiv:comment>
    <link href="http://arxiv.org/abs/1005.5462v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1005.5462v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1006.0475v1</id>
    <updated>2010-06-02T19:41:27Z</updated>
    <published>2010-06-02T19:41:27Z</published>
    <title>Prediction with Advice of Unknown Number of Experts</title>
    <summary>  In the framework of prediction with expert advice, we consider a recently
introduced kind of regret bounds: the bounds that depend on the effective
instead of nominal number of experts. In contrast to the NormalHedge bound,
which mainly depends on the effective number of experts and also weakly depends
on the nominal one, we obtain a bound that does not contain the nominal number
of experts at all. We use the defensive forecasting method and introduce an
application of defensive forecasting to multivalued supermartingales.
</summary>
    <author>
      <name>Alexey Chernov</name>
    </author>
    <author>
      <name>Vladimir Vovk</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">22 pages; draft version</arxiv:comment>
    <link href="http://arxiv.org/abs/1006.0475v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1006.0475v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1006.1138v3</id>
    <updated>2014-08-12T16:44:00Z</updated>
    <published>2010-06-06T21:05:27Z</published>
    <title>Online Learning via Sequential Complexities</title>
    <summary>  We consider the problem of sequential prediction and provide tools to study
the minimax value of the associated game. Classical statistical learning theory
provides several useful complexity measures to study learning with i.i.d. data.
Our proposed sequential complexities can be seen as extensions of these
measures to the sequential setting. The developed theory is shown to yield
precise learning guarantees for the problem of sequential prediction. In
particular, we show necessary and sufficient conditions for online learnability
in the setting of supervised learning. Several examples show the utility of our
framework: we can establish learnability without having to exhibit an explicit
online learning algorithm.
</summary>
    <author>
      <name>Alexander Rakhlin</name>
    </author>
    <author>
      <name>Karthik Sridharan</name>
    </author>
    <author>
      <name>Ambuj Tewari</name>
    </author>
    <link href="http://arxiv.org/abs/1006.1138v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1006.1138v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1007.1282v1</id>
    <updated>2010-07-08T03:58:25Z</updated>
    <published>2010-07-08T03:58:25Z</published>
    <title>A note on sample complexity of learning binary output neural networks
  under fixed input distributions</title>
    <summary>  We show that the learning sample complexity of a sigmoidal neural network
constructed by Sontag (1992) required to achieve a given misclassification
error under a fixed purely atomic distribution can grow arbitrarily fast: for
any prescribed rate of growth there is an input distribution having this rate
as the sample complexity, and the bound is asymptotically tight. The rate can
be superexponential, a non-recursive function, etc. We further observe that
Sontag's ANN is not Glivenko-Cantelli under any input distribution having a
non-atomic part.
</summary>
    <author>
      <name>Vladimir Pestov</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/SBRN.2010.10</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/SBRN.2010.10" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, latex in IEEE conference proceedings format</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. 2010 Eleventh Brazilian Symposium on Neural Networks (S\~ao
  Bernardo do Campo, SP, Brazil, 23-28 October 2010), IEEE Computer Society,
  2010, pp. 7-12</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1007.1282v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1007.1282v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T05" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1007.2075v1</id>
    <updated>2010-07-13T10:54:14Z</updated>
    <published>2010-07-13T10:54:14Z</published>
    <title>Consistency of Feature Markov Processes</title>
    <summary>  We are studying long term sequence prediction (forecasting). We approach this
by investigating criteria for choosing a compact useful state representation.
The state is supposed to summarize useful information from the history. We want
a method that is asymptotically consistent in the sense it will provably
eventually only choose between alternatives that satisfy an optimality property
related to the used criterion. We extend our work to the case where there is
side information that one can take advantage of and, furthermore, we briefly
discuss the active setting where an agent takes actions to achieve desirable
outcomes.
</summary>
    <author>
      <name>Peter Sunehag</name>
    </author>
    <author>
      <name>Marcus Hutter</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 LaTeX pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. 21st International Conf. on Algorithmic Learning Theory
  (ALT-2010) pages 360-374</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1007.2075v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1007.2075v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1007.2449v1</id>
    <updated>2010-07-14T22:41:30Z</updated>
    <published>2010-07-14T22:41:30Z</published>
    <title>A Brief Introduction to Temporality and Causality</title>
    <summary>  Causality is a non-obvious concept that is often considered to be related to
temporality. In this paper we present a number of past and present approaches
to the definition of temporality and causality from philosophical, physical,
and computational points of view. We note that time is an important ingredient
in many relationships and phenomena. The topic is then divided into the two
main areas of temporal discovery, which is concerned with finding relations
that are stretched over time, and causal discovery, where a claim is made as to
the causal influence of certain events on others. We present a number of
computational tools used for attempting to automatically discover temporal and
causal relations in data.
</summary>
    <author>
      <name>Kamran Karimi</name>
    </author>
    <link href="http://arxiv.org/abs/1007.2449v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1007.2449v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1008.1398v1</id>
    <updated>2010-08-08T11:25:12Z</updated>
    <published>2010-08-08T11:25:12Z</published>
    <title>Semi-Supervised Kernel PCA</title>
    <summary>  We present three generalisations of Kernel Principal Components Analysis
(KPCA) which incorporate knowledge of the class labels of a subset of the data
points. The first, MV-KPCA, penalises within class variances similar to Fisher
discriminant analysis. The second, LSKPCA is a hybrid of least squares
regression and kernel PCA. The final LR-KPCA is an iteratively reweighted
version of the previous which achieves a sigmoid loss function on the labeled
points. We provide a theoretical risk bound as well as illustrative experiments
on real and toy data sets.
</summary>
    <author>
      <name>Christian Walder</name>
    </author>
    <author>
      <name>Ricardo Henao</name>
    </author>
    <author>
      <name>Morten Mørup</name>
    </author>
    <author>
      <name>Lars Kai Hansen</name>
    </author>
    <link href="http://arxiv.org/abs/1008.1398v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1008.1398v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1008.4232v1</id>
    <updated>2010-08-25T09:09:29Z</updated>
    <published>2010-08-25T09:09:29Z</published>
    <title>Online Learning in Case of Unbounded Losses Using the Follow Perturbed
  Leader Algorithm</title>
    <summary>  In this paper the sequential prediction problem with expert advice is
considered for the case where losses of experts suffered at each step cannot be
bounded in advance. We present some modification of Kalai and Vempala algorithm
of following the perturbed leader where weights depend on past losses of the
experts. New notions of a volume and a scaled fluctuation of a game are
introduced. We present a probabilistic algorithm protected from unrestrictedly
large one-step losses. This algorithm has the optimal performance in the case
when the scaled fluctuations of one-step losses of experts of the pool tend to
zero.
</summary>
    <author>
      <name>Vladimir V. V'yugin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">31 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1008.4232v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1008.4232v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1009.3702v1</id>
    <updated>2010-09-20T06:35:11Z</updated>
    <published>2010-09-20T06:35:11Z</published>
    <title>Totally Corrective Multiclass Boosting with Binary Weak Learners</title>
    <summary>  In this work, we propose a new optimization framework for multiclass boosting
learning. In the literature, AdaBoost.MO and AdaBoost.ECC are the two
successful multiclass boosting algorithms, which can use binary weak learners.
We explicitly derive these two algorithms' Lagrange dual problems based on
their regularized loss functions. We show that the Lagrange dual formulations
enable us to design totally-corrective multiclass algorithms by using the
primal-dual optimization technique. Experiments on benchmark data sets suggest
that our multiclass boosting can achieve a comparable generalization capability
with state-of-the-art, but the convergence speed is much faster than stage-wise
gradient descent boosting. In other words, the new totally corrective
algorithms can maximize the margin more aggressively.
</summary>
    <author>
      <name>Zhihui Hao</name>
    </author>
    <author>
      <name>Chunhua Shen</name>
    </author>
    <author>
      <name>Nick Barnes</name>
    </author>
    <author>
      <name>Bo Wang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1009.3702v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1009.3702v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1009.3896v2</id>
    <updated>2012-11-26T06:42:25Z</updated>
    <published>2010-09-20T17:35:35Z</published>
    <title>Optimistic Rates for Learning with a Smooth Loss</title>
    <summary>  We establish an excess risk bound of O(H R_n^2 + R_n \sqrt{H L*}) for
empirical risk minimization with an H-smooth loss function and a hypothesis
class with Rademacher complexity R_n, where L* is the best risk achievable by
the hypothesis class. For typical hypothesis classes where R_n = \sqrt{R/n},
this translates to a learning rate of O(RH/n) in the separable (L*=0) case and
O(RH/n + \sqrt{L^* RH/n}) more generally. We also provide similar guarantees
for online and stochastic convex optimization with a smooth non-negative
objective.
</summary>
    <author>
      <name>Nathan Srebro</name>
    </author>
    <author>
      <name>Karthik Sridharan</name>
    </author>
    <author>
      <name>Ambuj Tewari</name>
    </author>
    <link href="http://arxiv.org/abs/1009.3896v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1009.3896v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1009.3958v1</id>
    <updated>2010-09-20T21:44:30Z</updated>
    <published>2010-09-20T21:44:30Z</published>
    <title>Approximate Inference and Stochastic Optimal Control</title>
    <summary>  We propose a novel reformulation of the stochastic optimal control problem as
an approximate inference problem, demonstrating, that such a interpretation
leads to new practical methods for the original problem. In particular we
characterise a novel class of iterative solutions to the stochastic optimal
control problem based on a natural relaxation of the exact dual formulation.
These theoretical insights are applied to the Reinforcement Learning problem
where they lead to new model free, off policy methods for discrete and
continuous problems.
</summary>
    <author>
      <name>Konrad Rawlik</name>
    </author>
    <author>
      <name>Marc Toussaint</name>
    </author>
    <author>
      <name>Sethu Vijayakumar</name>
    </author>
    <link href="http://arxiv.org/abs/1009.3958v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1009.3958v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1009.5972v1</id>
    <updated>2010-09-29T18:55:02Z</updated>
    <published>2010-09-29T18:55:02Z</published>
    <title>The Attentive Perceptron</title>
    <summary>  We propose a focus of attention mechanism to speed up the Perceptron
algorithm. Focus of attention speeds up the Perceptron algorithm by lowering
the number of features evaluated throughout training and prediction. Whereas
the traditional Perceptron evaluates all the features of each example, the
Attentive Perceptron evaluates less features for easy to classify examples,
thereby achieving significant speedups and small losses in prediction accuracy.
Focus of attention allows the Attentive Perceptron to stop the evaluation of
features at any interim point and filter the example. This creates an attentive
filter which concentrates computation at examples that are hard to classify,
and quickly filters examples that are easy to classify.
</summary>
    <author>
      <name>Raphael Pelossof</name>
    </author>
    <author>
      <name>Zhiliang Ying</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to New York Academy of Sciences Machine Learning symposium
  2010</arxiv:comment>
    <link href="http://arxiv.org/abs/1009.5972v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1009.5972v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1010.4207v2</id>
    <updated>2010-11-14T17:19:42Z</updated>
    <published>2010-10-20T14:02:21Z</published>
    <title>Convex Analysis and Optimization with Submodular Functions: a Tutorial</title>
    <summary>  Set-functions appear in many areas of computer science and applied
mathematics, such as machine learning, computer vision, operations research or
electrical networks. Among these set-functions, submodular functions play an
important role, similar to convex functions on vector spaces. In this tutorial,
the theory of submodular functions is presented, in a self-contained way, with
all results shown from first principles. A good knowledge of convex analysis is
assumed.
</summary>
    <author>
      <name>Francis Bach</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rocquencourt, LIENS</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/1010.4207v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1010.4207v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1011.0350v1</id>
    <updated>2010-11-01T15:40:31Z</updated>
    <published>2010-11-01T15:40:31Z</published>
    <title>Developing courses with HoloRena, a framework for scenario- and game
  based e-learning environments</title>
    <summary>  However utilizing rich, interactive solutions can make learning more
effective and attractive, scenario- and game-based educational resources on the
web are not widely used. Creating these applications is a complex, expensive
and challenging process. Development frameworks and authoring tools hardly
support reusable components, teamwork and learning management
system-independent courseware architecture. In this article we initiate the
concept of a low-level, thick-client solution addressing these problems. With
some example applications we try to demonstrate, how a framework, based on this
concept can be useful for developing scenario- and game-based e-learning
environments.
</summary>
    <author>
      <name>Laszlo Juracz</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Software Engineering &amp; Applications
  (IJSEA), October 2010, Volume 1, Number 4</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1011.0350v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1011.0350v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1011.1936v1</id>
    <updated>2010-11-08T22:41:14Z</updated>
    <published>2010-11-08T22:41:14Z</published>
    <title>Blackwell Approachability and Low-Regret Learning are Equivalent</title>
    <summary>  We consider the celebrated Blackwell Approachability Theorem for two-player
games with vector payoffs. We show that Blackwell's result is equivalent, via
efficient reductions, to the existence of "no-regret" algorithms for Online
Linear Optimization. Indeed, we show that any algorithm for one such problem
can be efficiently converted into an algorithm for the other. We provide a
useful application of this reduction: the first efficient algorithm for
calibrated forecasting.
</summary>
    <author>
      <name>Jacob Abernethy</name>
    </author>
    <author>
      <name>Peter L. Bartlett</name>
    </author>
    <author>
      <name>Elad Hazan</name>
    </author>
    <link href="http://arxiv.org/abs/1011.1936v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1011.1936v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1012.0498v1</id>
    <updated>2010-12-02T17:04:19Z</updated>
    <published>2010-12-02T17:04:19Z</published>
    <title>Estimating Probabilities in Recommendation Systems</title>
    <summary>  Recommendation systems are emerging as an important business application with
significant economic impact. Currently popular systems include Amazon's book
recommendations, Netflix's movie recommendations, and Pandora's music
recommendations. In this paper we address the problem of estimating
probabilities associated with recommendation system data using non-parametric
kernel smoothing. In our estimation we interpret missing items as randomly
censored observations and obtain efficient computation schemes using
combinatorial properties of generating functions. We demonstrate our approach
with several case studies involving real world movie recommendation data. The
results are comparable with state-of-the-art techniques while also providing
probabilistic preference estimates outside the scope of traditional recommender
systems.
</summary>
    <author>
      <name>Mingxuan Sun</name>
    </author>
    <author>
      <name>Guy Lebanon</name>
    </author>
    <author>
      <name>Paul Kidwell</name>
    </author>
    <link href="http://arxiv.org/abs/1012.0498v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1012.0498v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1102.3923v2</id>
    <updated>2011-05-26T19:26:27Z</updated>
    <published>2011-02-18T21:26:16Z</published>
    <title>Concentration-Based Guarantees for Low-Rank Matrix Reconstruction</title>
    <summary>  We consider the problem of approximately reconstructing a partially-observed,
approximately low-rank matrix. This problem has received much attention lately,
mostly using the trace-norm as a surrogate to the rank. Here we study low-rank
matrix reconstruction using both the trace-norm, as well as the less-studied
max-norm, and present reconstruction guarantees based on existing analysis on
the Rademacher complexity of the unit balls of these norms. We show how these
are superior in several ways to recently published guarantees based on
specialized analysis.
</summary>
    <author>
      <name>Rina Foygel</name>
    </author>
    <author>
      <name>Nathan Srebro</name>
    </author>
    <link href="http://arxiv.org/abs/1102.3923v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1102.3923v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1102.4240v1</id>
    <updated>2011-02-21T14:48:20Z</updated>
    <published>2011-02-21T14:48:20Z</published>
    <title>Sparse neural networks with large learning diversity</title>
    <summary>  Coded recurrent neural networks with three levels of sparsity are introduced.
The first level is related to the size of messages, much smaller than the
number of available neurons. The second one is provided by a particular coding
rule, acting as a local constraint in the neural activity. The third one is a
characteristic of the low final connection density of the network after the
learning phase. Though the proposed network is very simple since it is based on
binary neurons and binary connections, it is able to learn a large number of
messages and recall them, even in presence of strong erasures. The performance
of the network is assessed as a classifier and as an associative memory.
</summary>
    <author>
      <name>Vincent Gripon</name>
    </author>
    <author>
      <name>Claude Berrou</name>
    </author>
    <link href="http://arxiv.org/abs/1102.4240v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1102.4240v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.0398v1</id>
    <updated>2011-03-02T11:34:50Z</updated>
    <published>2011-03-02T11:34:50Z</published>
    <title>Natural Language Processing (almost) from Scratch</title>
    <summary>  We propose a unified neural network architecture and learning algorithm that
can be applied to various natural language processing tasks including:
part-of-speech tagging, chunking, named entity recognition, and semantic role
labeling. This versatility is achieved by trying to avoid task-specific
engineering and therefore disregarding a lot of prior knowledge. Instead of
exploiting man-made input features carefully optimized for each task, our
system learns internal representations on the basis of vast amounts of mostly
unlabeled training data. This work is then used as a basis for building a
freely available tagging system with good performance and minimal computational
requirements.
</summary>
    <author>
      <name>Ronan Collobert</name>
    </author>
    <author>
      <name>Jason Weston</name>
    </author>
    <author>
      <name>Leon Bottou</name>
    </author>
    <author>
      <name>Michael Karlen</name>
    </author>
    <author>
      <name>Koray Kavukcuoglu</name>
    </author>
    <author>
      <name>Pavel Kuksa</name>
    </author>
    <link href="http://arxiv.org/abs/1103.0398v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.0398v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.4204v1</id>
    <updated>2011-03-22T04:54:35Z</updated>
    <published>2011-03-22T04:54:35Z</published>
    <title>Parallel Online Learning</title>
    <summary>  In this work we study parallelization of online learning, a core primitive in
machine learning. In a parallel environment all known approaches for parallel
online learning lead to delayed updates, where the model is updated using
out-of-date information. In the worst case, or when examples are temporally
correlated, delay can have a very adverse effect on the learning algorithm.
Here, we analyze and present preliminary empirical results on a set of learning
architectures based on a feature sharding approach that present various
tradeoffs between delay, degree of parallelism, representation power and
empirical performance.
</summary>
    <author>
      <name>Daniel Hsu</name>
    </author>
    <author>
      <name>Nikos Karampatziakis</name>
    </author>
    <author>
      <name>John Langford</name>
    </author>
    <author>
      <name>Alex Smola</name>
    </author>
    <link href="http://arxiv.org/abs/1103.4204v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.4204v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.4487v1</id>
    <updated>2011-03-23T10:38:50Z</updated>
    <published>2011-03-23T10:38:50Z</published>
    <title>Handwritten Digit Recognition with a Committee of Deep Neural Nets on
  GPUs</title>
    <summary>  The competitive MNIST handwritten digit recognition benchmark has a long
history of broken records since 1998. The most recent substantial improvement
by others dates back 7 years (error rate 0.4%) . Recently we were able to
significantly improve this result, using graphics cards to greatly speed up
training of simple but deep MLPs, which achieved 0.35%, outperforming all the
previous more complex methods. Here we report another substantial improvement:
0.31% obtained using a committee of MLPs.
</summary>
    <author>
      <name>Dan C. Cireşan</name>
    </author>
    <author>
      <name>Ueli Meier</name>
    </author>
    <author>
      <name>Luca M. Gambardella</name>
    </author>
    <author>
      <name>Jürgen Schmidhuber</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 4 figures, 3 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1103.4487v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.4487v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.4896v1</id>
    <updated>2011-03-25T02:33:27Z</updated>
    <published>2011-03-25T02:33:27Z</published>
    <title>Classification of Sets using Restricted Boltzmann Machines</title>
    <summary>  We consider the problem of classification when inputs correspond to sets of
vectors. This setting occurs in many problems such as the classification of
pieces of mail containing several pages, of web sites with several sections or
of images that have been pre-segmented into smaller regions. We propose
generalizations of the restricted Boltzmann machine (RBM) that are appropriate
in this context and explore how to incorporate different assumptions about the
relationship between the input sets and the target class within the RBM. In
experiments on standard multiple-instance learning datasets, we demonstrate the
competitiveness of approaches based on RBMs and apply the proposed variants to
the problem of incoming mail classification.
</summary>
    <author>
      <name>Jérôme Louradour</name>
    </author>
    <author>
      <name>Hugo Larochelle</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1103.4896v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.4896v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1104.5601v1</id>
    <updated>2011-04-29T11:39:40Z</updated>
    <published>2011-04-29T11:39:40Z</published>
    <title>Mean-Variance Optimization in Markov Decision Processes</title>
    <summary>  We consider finite horizon Markov decision processes under performance
measures that involve both the mean and the variance of the cumulative reward.
We show that either randomized or history-based policies can improve
performance. We prove that the complexity of computing a policy that maximizes
the mean reward under a variance constraint is NP-hard for some cases, and
strongly NP-hard for others. We finally offer pseudopolynomial exact and
approximation algorithms.
</summary>
    <author>
      <name>Shie Mannor</name>
    </author>
    <author>
      <name>John Tsitsiklis</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">A full version of an ICML 2011 paper</arxiv:comment>
    <link href="http://arxiv.org/abs/1104.5601v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1104.5601v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1105.2274v1</id>
    <updated>2011-05-11T18:59:13Z</updated>
    <published>2011-05-11T18:59:13Z</published>
    <title>Data-Distributed Weighted Majority and Online Mirror Descent</title>
    <summary>  In this paper, we focus on the question of the extent to which online
learning can benefit from distributed computing. We focus on the setting in
which $N$ agents online-learn cooperatively, where each agent only has access
to its own data. We propose a generic data-distributed online learning
meta-algorithm. We then introduce the Distributed Weighted Majority and
Distributed Online Mirror Descent algorithms, as special cases. We show, using
both theoretical analysis and experiments, that compared to a single agent:
given the same computation time, these distributed algorithms achieve smaller
generalization errors; and given the same generalization errors, they can be
$N$ times faster.
</summary>
    <author>
      <name>Hua Ouyang</name>
    </author>
    <author>
      <name>Alexander Gray</name>
    </author>
    <link href="http://arxiv.org/abs/1105.2274v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1105.2274v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1105.4272v1</id>
    <updated>2011-05-21T17:28:12Z</updated>
    <published>2011-05-21T17:28:12Z</published>
    <title>Calibration with Changing Checking Rules and Its Application to
  Short-Term Trading</title>
    <summary>  We provide a natural learning process in which a financial trader without a
risk receives a gain in case when Stock Market is inefficient. In this process,
the trader rationally choose his gambles using a prediction made by a
randomized calibrated algorithm. Our strategy is based on Dawid's notion of
calibration with more general changing checking rules and on some modification
of Kakade and Foster's randomized algorithm for computing calibrated forecasts.
</summary>
    <author>
      <name>Vladimir Trunov</name>
    </author>
    <author>
      <name>Vladimir V'yugin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1105.4272v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1105.4272v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1105.4585v1</id>
    <updated>2011-05-23T19:10:03Z</updated>
    <published>2011-05-23T19:10:03Z</published>
    <title>PAC-Bayesian Analysis of the Exploration-Exploitation Trade-off</title>
    <summary>  We develop a coherent framework for integrative simultaneous analysis of the
exploration-exploitation and model order selection trade-offs. We improve over
our preceding results on the same subject (Seldin et al., 2011) by combining
PAC-Bayesian analysis with Bernstein-type inequality for martingales. Such a
combination is also of independent interest for studies of multiple
simultaneously evolving martingales.
</summary>
    <author>
      <name>Yevgeny Seldin</name>
    </author>
    <author>
      <name>Nicolò Cesa-Bianchi</name>
    </author>
    <author>
      <name>François Laviolette</name>
    </author>
    <author>
      <name>Peter Auer</name>
    </author>
    <author>
      <name>John Shawe-Taylor</name>
    </author>
    <author>
      <name>Jan Peters</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">On-line Trading of Exploration and Exploitation 2 - ICML-2011
  workshop. http://explo.cs.ucl.ac.uk/workshop/</arxiv:comment>
    <link href="http://arxiv.org/abs/1105.4585v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1105.4585v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1105.4701v3</id>
    <updated>2011-09-08T04:14:53Z</updated>
    <published>2011-05-24T07:58:30Z</published>
    <title>Online Learning, Stability, and Stochastic Gradient Descent</title>
    <summary>  In batch learning, stability together with existence and uniqueness of the
solution corresponds to well-posedness of Empirical Risk Minimization (ERM)
methods; recently, it was proved that CV_loo stability is necessary and
sufficient for generalization and consistency of ERM. In this note, we
introduce CV_on stability, which plays a similar note in online learning. We
show that stochastic gradient descent (SDG) with the usual hypotheses is CVon
stable and we then discuss the implications of CV_on stability for convergence
of SGD.
</summary>
    <author>
      <name>Tomaso Poggio</name>
    </author>
    <author>
      <name>Stephen Voinea</name>
    </author>
    <author>
      <name>Lorenzo Rosasco</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1105.4701v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1105.4701v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1105.5379v1</id>
    <updated>2011-05-26T19:19:30Z</updated>
    <published>2011-05-26T19:19:30Z</published>
    <title>Parallel Coordinate Descent for L1-Regularized Loss Minimization</title>
    <summary>  We propose Shotgun, a parallel coordinate descent algorithm for minimizing
L1-regularized losses. Though coordinate descent seems inherently sequential,
we prove convergence bounds for Shotgun which predict linear speedups, up to a
problem-dependent limit. We present a comprehensive empirical study of Shotgun
for Lasso and sparse logistic regression. Our theoretical predictions on the
potential for parallelism closely match behavior on real data. Shotgun
outperforms other published solvers on a range of large problems, proving to be
one of the most scalable algorithms for L1.
</summary>
    <author>
      <name>Joseph K. Bradley</name>
    </author>
    <author>
      <name>Aapo Kyrola</name>
    </author>
    <author>
      <name>Danny Bickson</name>
    </author>
    <author>
      <name>Carlos Guestrin</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">In the 28th International Conference on Machine Learning, July
  2011, Washington, USA</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1105.5379v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1105.5379v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1105.6041v1</id>
    <updated>2011-05-30T17:02:09Z</updated>
    <published>2011-05-30T17:02:09Z</published>
    <title>The Perceptron with Dynamic Margin</title>
    <summary>  The classical perceptron rule provides a varying upper bound on the maximum
margin, namely the length of the current weight vector divided by the total
number of updates up to that time. Requiring that the perceptron updates its
internal state whenever the normalized margin of a pattern is found not to
exceed a certain fraction of this dynamic upper bound we construct a new
approximate maximum margin classifier called the perceptron with dynamic margin
(PDM). We demonstrate that PDM converges in a finite number of steps and derive
an upper bound on them. We also compare experimentally PDM with other
perceptron-like algorithms and support vector machines on hard margin tasks
involving linear kernels which are equivalent to 2-norm soft margin.
</summary>
    <author>
      <name>Constantinos Panagiotakopoulos</name>
    </author>
    <author>
      <name>Petroula Tsampouka</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1105.6041v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1105.6041v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1106.0221v1</id>
    <updated>2011-06-01T16:16:14Z</updated>
    <published>2011-06-01T16:16:14Z</published>
    <title>Evolutionary Algorithms for Reinforcement Learning</title>
    <summary>  There are two distinct approaches to solving reinforcement learning problems,
namely, searching in value function space and searching in policy space.
Temporal difference methods and evolutionary algorithms are well-known examples
of these approaches. Kaelbling, Littman and Moore recently provided an
informative survey of temporal difference methods. This article focuses on the
application of evolutionary algorithms to the reinforcement learning problem,
emphasizing alternative policy representations, credit assignment methods, and
problem-specific genetic operators. Strengths and weaknesses of the
evolutionary approach to reinforcement learning are presented, along with a
survey of representative applications.
</summary>
    <author>
      <name>J. J. Grefenstette</name>
    </author>
    <author>
      <name>D. E. Moriarty</name>
    </author>
    <author>
      <name>A. C. Schultz</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1613/jair.613</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1613/jair.613" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal Of Artificial Intelligence Research, Volume 11, pages
  241-276, 1999</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1106.0221v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1106.0221v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1106.0357v1</id>
    <updated>2011-06-02T02:31:04Z</updated>
    <published>2011-06-02T02:31:04Z</published>
    <title>Learning Hierarchical Sparse Representations using Iterative Dictionary
  Learning and Dimension Reduction</title>
    <summary>  This paper introduces an elemental building block which combines Dictionary
Learning and Dimension Reduction (DRDL). We show how this foundational element
can be used to iteratively construct a Hierarchical Sparse Representation (HSR)
of a sensory stream. We compare our approach to existing models showing the
generality of our simple prescription. We then perform preliminary experiments
using this framework, illustrating with the example of an object recognition
task using standard datasets. This work introduces the very first steps towards
an integrated framework for designing and analyzing various computational tasks
from learning to attention to action. The ultimate goal is building a
mathematically rigorous, integrated theory of intelligence.
</summary>
    <author>
      <name>Mohamad Tarifi</name>
    </author>
    <author>
      <name>Meera Sitharam</name>
    </author>
    <author>
      <name>Jeffery Ho</name>
    </author>
    <link href="http://arxiv.org/abs/1106.0357v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1106.0357v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1106.0518v2</id>
    <updated>2011-06-13T14:32:55Z</updated>
    <published>2011-06-02T21:30:50Z</published>
    <title>Submodular Functions Are Noise Stable</title>
    <summary>  We show that all non-negative submodular functions have high {\em
noise-stability}. As a consequence, we obtain a polynomial-time learning
algorithm for this class with respect to any product distribution on
$\{-1,1\}^n$ (for any constant accuracy parameter $\epsilon$). Our algorithm
also succeeds in the agnostic setting. Previous work on learning submodular
functions required either query access or strong assumptions about the types of
submodular functions to be learned (and did not hold in the agnostic setting).
</summary>
    <author>
      <name>Mahdi Cheraghchi</name>
    </author>
    <author>
      <name>Adam Klivans</name>
    </author>
    <author>
      <name>Pravesh Kothari</name>
    </author>
    <author>
      <name>Homin K. Lee</name>
    </author>
    <link href="http://arxiv.org/abs/1106.0518v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1106.0518v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1106.0676v1</id>
    <updated>2011-06-03T14:55:23Z</updated>
    <published>2011-06-03T14:55:23Z</published>
    <title>Optimizing Dialogue Management with Reinforcement Learning: Experiments
  with the NJFun System</title>
    <summary>  Designing the dialogue policy of a spoken dialogue system involves many
nontrivial choices. This paper presents a reinforcement learning approach for
automatically optimizing a dialogue policy, which addresses the technical
challenges in applying reinforcement learning to a working dialogue system with
human users. We report on the design, construction and empirical evaluation of
NJFun, an experimental spoken dialogue system that provides users with access
to information about fun things to do in New Jersey. Our results show that by
optimizing its performance via reinforcement learning, NJFun measurably
improves system performance.
</summary>
    <author>
      <name>M. Kearns</name>
    </author>
    <author>
      <name>D. Litman</name>
    </author>
    <author>
      <name>S. Singh</name>
    </author>
    <author>
      <name>M. Walker</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1613/jair.859</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1613/jair.859" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal Of Artificial Intelligence Research, Volume 16, pages
  105-133, 2002</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1106.0676v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1106.0676v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1106.1216v2</id>
    <updated>2011-06-15T01:17:56Z</updated>
    <published>2011-06-06T23:55:00Z</published>
    <title>Using More Data to Speed-up Training Time</title>
    <summary>  In many recent applications, data is plentiful. By now, we have a rather
clear understanding of how more data can be used to improve the accuracy of
learning algorithms. Recently, there has been a growing interest in
understanding how more data can be leveraged to reduce the required training
runtime. In this paper, we study the runtime of learning as a function of the
number of available training examples, and underscore the main high-level
techniques. We provide some initial positive results showing that the runtime
can decrease exponentially while only requiring a polynomial growth of the
number of examples, and spell-out several interesting open problems.
</summary>
    <author>
      <name>Shai Shalev-Shwartz</name>
    </author>
    <author>
      <name>Ohad Shamir</name>
    </author>
    <author>
      <name>Eran Tromer</name>
    </author>
    <link href="http://arxiv.org/abs/1106.1216v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1106.1216v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1106.1622v1</id>
    <updated>2011-06-08T19:07:09Z</updated>
    <published>2011-06-08T19:07:09Z</published>
    <title>Large-Scale Convex Minimization with a Low-Rank Constraint</title>
    <summary>  We address the problem of minimizing a convex function over the space of
large matrices with low rank. While this optimization problem is hard in
general, we propose an efficient greedy algorithm and derive its formal
approximation guarantees. Each iteration of the algorithm involves
(approximately) finding the left and right singular vectors corresponding to
the largest singular value of a certain matrix, which can be calculated in
linear time. This leads to an algorithm which can scale to large matrices
arising in several applications such as matrix completion for collaborative
filtering and robust low rank matrix approximation.
</summary>
    <author>
      <name>Shai Shalev-Shwartz</name>
    </author>
    <author>
      <name>Alon Gonen</name>
    </author>
    <author>
      <name>Ohad Shamir</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICML 2011</arxiv:comment>
    <link href="http://arxiv.org/abs/1106.1622v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1106.1622v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1106.2429v4</id>
    <updated>2013-09-11T10:55:26Z</updated>
    <published>2011-06-13T12:30:05Z</published>
    <title>Efficient Transductive Online Learning via Randomized Rounding</title>
    <summary>  Most traditional online learning algorithms are based on variants of mirror
descent or follow-the-leader. In this paper, we present an online algorithm
based on a completely different approach, tailored for transductive settings,
which combines "random playout" and randomized rounding of loss subgradients.
As an application of our approach, we present the first computationally
efficient online algorithm for collaborative filtering with trace-norm
constrained matrices. As a second application, we solve an open question
linking batch learning and transductive online learning
</summary>
    <author>
      <name>Nicolò Cesa-Bianchi</name>
    </author>
    <author>
      <name>Ohad Shamir</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in a Festschrift in honor of V.N. Vapnik. Preliminary
  version presented in NIPS 2011</arxiv:comment>
    <link href="http://arxiv.org/abs/1106.2429v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1106.2429v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1106.3355v2</id>
    <updated>2012-03-05T21:36:51Z</updated>
    <published>2011-06-16T21:32:26Z</published>
    <title>On epsilon-optimality of the pursuit learning algorithm</title>
    <summary>  Estimator algorithms in learning automata are useful tools for adaptive,
real-time optimization in computer science and engineering applications. This
paper investigates theoretical convergence properties for a special case of
estimator algorithms: the pursuit learning algorithm. In this note, we identify
and fill a gap in existing proofs of probabilistic convergence for pursuit
learning. It is tradition to take the pursuit learning tuning parameter to be
fixed in practical applications, but our proof sheds light on the importance of
a vanishing sequence of tuning parameters in a theoretical convergence
analysis.
</summary>
    <author>
      <name>Ryan Martin</name>
    </author>
    <author>
      <name>Omkar Tilak</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1239/jap/1346955334</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1239/jap/1346955334" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Applied Probability, 49(3), 795-805, 2012</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1106.3355v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1106.3355v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1106.3395v1</id>
    <updated>2011-06-17T06:53:47Z</updated>
    <published>2011-06-17T06:53:47Z</published>
    <title>Decoding finger movements from ECoG signals using switching linear
  models</title>
    <summary>  One of the major challenges of ECoG-based Brain-Machine Interfaces is the
movement prediction of a human subject. Several methods exist to predict an arm
2-D trajectory. The fourth BCI Competition gives a dataset in which the aim is
to predict individual finger movements (5-D trajectory). The difficulty lies in
the fact that there is no simple relation between ECoG signals and finger
movement. We propose in this paper to decode finger flexions using switching
models. This method permits to simplify the system as it is now described as an
ensemble of linear models depending on an internal state. We show that an
interesting accuracy prediction can be obtained by such a model.
</summary>
    <author>
      <name>Rémi Flamary</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LITIS</arxiv:affiliation>
    </author>
    <author>
      <name>Alain Rakotomamonjy</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LITIS</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/1106.3395v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1106.3395v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1106.3396v1</id>
    <updated>2011-06-17T06:54:35Z</updated>
    <published>2011-06-17T06:54:35Z</published>
    <title>Large margin filtering for signal sequence labeling</title>
    <summary>  Signal Sequence Labeling consists in predicting a sequence of labels given an
observed sequence of samples. A naive way is to filter the signal in order to
reduce the noise and to apply a classification algorithm on the filtered
samples. We propose in this paper to jointly learn the filter with the
classifier leading to a large margin filtering for classification. This method
allows to learn the optimal cutoff frequency and phase of the filter that may
be different from zero. Two methods are proposed and tested on a toy dataset
and on a real life BCI dataset from BCI Competition III.
</summary>
    <author>
      <name>Rémi Flamary</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LITIS</arxiv:affiliation>
    </author>
    <author>
      <name>Benjamin Labbé</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LITIS</arxiv:affiliation>
    </author>
    <author>
      <name>Alain Rakotomamonjy</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LITIS</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/ICASSP.2010.5495281</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/ICASSP.2010.5495281" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE International Conference on Acoustics Speech and Signal
  Processing (ICASSP), 2010, Dallas : United States (2010)</arxiv:comment>
    <link href="http://arxiv.org/abs/1106.3396v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1106.3396v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1106.4064v2</id>
    <updated>2011-11-09T19:45:30Z</updated>
    <published>2011-06-21T00:37:23Z</published>
    <title>Algorithmic Programming Language Identification</title>
    <summary>  Motivated by the amount of code that goes unidentified on the web, we
introduce a practical method for algorithmically identifying the programming
language of source code. Our work is based on supervised learning and
intelligent statistical features. We also explored, but abandoned, a
grammatical approach. In testing, our implementation greatly outperforms that
of an existing tool that relies on a Bayesian classifier. Code is written in
Python and available under an MIT license.
</summary>
    <author>
      <name>David Klein</name>
    </author>
    <author>
      <name>Kyle Murray</name>
    </author>
    <author>
      <name>Simon Weber</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages. Code:
  https://github.com/simon-weber/Programming-Language-Identification</arxiv:comment>
    <link href="http://arxiv.org/abs/1106.4064v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1106.4064v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.6; K.3.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1106.4251v1</id>
    <updated>2011-06-21T16:16:24Z</updated>
    <published>2011-06-21T16:16:24Z</published>
    <title>Learning with the Weighted Trace-norm under Arbitrary Sampling
  Distributions</title>
    <summary>  We provide rigorous guarantees on learning with the weighted trace-norm under
arbitrary sampling distributions. We show that the standard weighted trace-norm
might fail when the sampling distribution is not a product distribution (i.e.
when row and column indexes are not selected independently), present a
corrected variant for which we establish strong learning guarantees, and
demonstrate that it works better in practice. We provide guarantees when
weighting by either the true or empirical sampling distribution, and suggest
that even if the true distribution is known (or is uniform), weighting by the
empirical distribution may be beneficial.
</summary>
    <author>
      <name>Rina Foygel</name>
    </author>
    <author>
      <name>Ruslan Salakhutdinov</name>
    </author>
    <author>
      <name>Ohad Shamir</name>
    </author>
    <author>
      <name>Nathan Srebro</name>
    </author>
    <link href="http://arxiv.org/abs/1106.4251v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1106.4251v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1106.4574v1</id>
    <updated>2011-06-22T20:59:20Z</updated>
    <published>2011-06-22T20:59:20Z</published>
    <title>Better Mini-Batch Algorithms via Accelerated Gradient Methods</title>
    <summary>  Mini-batch algorithms have been proposed as a way to speed-up stochastic
convex optimization problems. We study how such algorithms can be improved
using accelerated gradient methods. We provide a novel analysis, which shows
how standard gradient methods may sometimes be insufficient to obtain a
significant speed-up and propose a novel accelerated gradient algorithm, which
deals with this deficiency, enjoys a uniformly superior guarantee and works
well in practice.
</summary>
    <author>
      <name>Andrew Cotter</name>
    </author>
    <author>
      <name>Ohad Shamir</name>
    </author>
    <author>
      <name>Nathan Srebro</name>
    </author>
    <author>
      <name>Karthik Sridharan</name>
    </author>
    <link href="http://arxiv.org/abs/1106.4574v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1106.4574v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1106.6258v2</id>
    <updated>2014-05-12T19:40:40Z</updated>
    <published>2011-06-30T15:03:58Z</published>
    <title>A Note on Improved Loss Bounds for Multiple Kernel Learning</title>
    <summary>  In this paper, we correct an upper bound, presented in~\cite{hs-11}, on the
generalisation error of classifiers learned through multiple kernel learning.
The bound in~\cite{hs-11} uses Rademacher complexity and has an\emph{additive}
dependence on the logarithm of the number of kernels and the margin achieved by
the classifier. However, there are some errors in parts of the proof which are
corrected in this paper. Unfortunately, the final result turns out to be a risk
bound which has a \emph{multiplicative} dependence on the logarithm of the
number of kernels and the margin achieved by the classifier.
</summary>
    <author>
      <name>Zakria Hussain</name>
    </author>
    <author>
      <name>John Shawe-Taylor</name>
    </author>
    <author>
      <name>Mario Marchand</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Extended proof</arxiv:comment>
    <link href="http://arxiv.org/abs/1106.6258v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1106.6258v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1107.3823v1</id>
    <updated>2011-07-19T19:43:10Z</updated>
    <published>2011-07-19T19:43:10Z</published>
    <title>Weakly Supervised Learning of Foreground-Background Segmentation using
  Masked RBMs</title>
    <summary>  We propose an extension of the Restricted Boltzmann Machine (RBM) that allows
the joint shape and appearance of foreground objects in cluttered images to be
modeled independently of the background. We present a learning scheme that
learns this representation directly from cluttered images with only very weak
supervision. The model generates plausible samples and performs
foreground-background segmentation. We demonstrate that representing foreground
objects independently of the background can be beneficial in recognition tasks.
</summary>
    <author>
      <name>Nicolas Heess</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Informatics</arxiv:affiliation>
    </author>
    <author>
      <name>Nicolas Le Roux</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Paris - Rocquencourt</arxiv:affiliation>
    </author>
    <author>
      <name>John Winn</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Conference on Artificial Neural Networks (2011)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1107.3823v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1107.3823v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1108.0017v1</id>
    <updated>2011-07-29T21:07:51Z</updated>
    <published>2011-07-29T21:07:51Z</published>
    <title>Generating a Diverse Set of High-Quality Clusterings</title>
    <summary>  We provide a new framework for generating multiple good quality partitions
(clusterings) of a single data set. Our approach decomposes this problem into
two components, generating many high-quality partitions, and then grouping
these partitions to obtain k representatives. The decomposition makes the
approach extremely modular and allows us to optimize various criteria that
control the choice of representative partitions.
</summary>
    <author>
      <name>Jeff M. Phillips</name>
    </author>
    <author>
      <name>Parasaran Raman</name>
    </author>
    <author>
      <name>Suresh Venkatasubramanian</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 Pages, 5 Figures, 2nd MultiClust Workshop at ECML PKDD 2011</arxiv:comment>
    <link href="http://arxiv.org/abs/1108.0017v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1108.0017v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1108.3476v2</id>
    <updated>2011-09-02T08:47:01Z</updated>
    <published>2011-08-17T13:36:11Z</published>
    <title>Structured Sparsity and Generalization</title>
    <summary>  We present a data dependent generalization bound for a large class of
regularized algorithms which implement structured sparsity constraints. The
bound can be applied to standard squared-norm regularization, the Lasso, the
group Lasso, some versions of the group Lasso with overlapping groups, multiple
kernel learning and other regularization schemes. In all these cases
competitive results are obtained. A novel feature of our bound is that it can
be applied in an infinite dimensional setting such as the Lasso in a separable
Hilbert space or multiple kernel learning with a countable number of kernels.
</summary>
    <author>
      <name>Andreas Maurer</name>
    </author>
    <author>
      <name>Massimiliano Pontil</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Machine Learning Research, 13:671-690, 2012</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1108.3476v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1108.3476v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1108.6088v1</id>
    <updated>2011-08-30T21:48:37Z</updated>
    <published>2011-08-30T21:48:37Z</published>
    <title>No Internal Regret via Neighborhood Watch</title>
    <summary>  We present an algorithm which attains O(\sqrt{T}) internal (and thus
external) regret for finite games with partial monitoring under the local
observability condition. Recently, this condition has been shown by (Bartok,
Pal, and Szepesvari, 2011) to imply the O(\sqrt{T}) rate for partial monitoring
games against an i.i.d. opponent, and the authors conjectured that the same
holds for non-stochastic adversaries. Our result is in the affirmative, and it
completes the characterization of possible rates for finite partial-monitoring
games, an open question stated by (Cesa-Bianchi, Lugosi, and Stoltz, 2006). Our
regret guarantees also hold for the more general model of partial monitoring
with random signals.
</summary>
    <author>
      <name>Dean Foster</name>
    </author>
    <author>
      <name>Alexander Rakhlin</name>
    </author>
    <link href="http://arxiv.org/abs/1108.6088v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1108.6088v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1109.2296v1</id>
    <updated>2011-09-11T09:00:53Z</updated>
    <published>2011-09-11T09:00:53Z</published>
    <title>Bandits with an Edge</title>
    <summary>  We consider a bandit problem over a graph where the rewards are not directly
observed. Instead, the decision maker can compare two nodes and receive
(stochastic) information pertaining to the difference in their value. The graph
structure describes the set of possible comparisons. Consequently, comparing
between two nodes that are relatively far requires estimating the difference
between every pair of nodes on the path between them. We analyze this problem
from the perspective of sample complexity: How many queries are needed to find
an approximately optimal node with probability more than $1-\delta$ in the PAC
setup? We show that the topology of the graph plays a crucial in defining the
sample complexity: graphs with a low diameter have a much better sample
complexity.
</summary>
    <author>
      <name>Dotan Di Castro</name>
    </author>
    <author>
      <name>Claudio Gentile</name>
    </author>
    <author>
      <name>Shie Mannor</name>
    </author>
    <link href="http://arxiv.org/abs/1109.2296v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1109.2296v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1109.5311v1</id>
    <updated>2011-09-24T22:14:46Z</updated>
    <published>2011-09-24T22:14:46Z</published>
    <title>Bias Plus Variance Decomposition for Survival Analysis Problems</title>
    <summary>  Bias - variance decomposition of the expected error defined for regression
and classification problems is an important tool to study and compare different
algorithms, to find the best areas for their application. Here the
decomposition is introduced for the survival analysis problem. In our
experiments, we study bias -variance parts of the expected error for two
algorithms: original Cox proportional hazard regression and CoxPath, path
algorithm for L1-regularized Cox regression, on the series of increased
training sets. The experiments demonstrate that, contrary expectations, CoxPath
does not necessarily have an advantage over Cox regression.
</summary>
    <author>
      <name>Marina Sapir</name>
    </author>
    <link href="http://arxiv.org/abs/1109.5311v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1109.5311v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1109.5664v4</id>
    <updated>2013-06-21T20:52:27Z</updated>
    <published>2011-09-26T18:44:00Z</published>
    <title>Deterministic Feature Selection for $k$-means Clustering</title>
    <summary>  We study feature selection for $k$-means clustering. Although the literature
contains many methods with good empirical performance, algorithms with provable
theoretical behavior have only recently been developed. Unfortunately, these
algorithms are randomized and fail with, say, a constant probability. We
address this issue by presenting a deterministic feature selection algorithm
for k-means with theoretical guarantees. At the heart of our algorithm lies a
deterministic method for decompositions of the identity.
</summary>
    <author>
      <name>Christos Boutsidis</name>
    </author>
    <author>
      <name>Malik Magdon-Ismail</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TIT.2013.2255021</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TIT.2013.2255021" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in IEEE Transactions on Information Theory</arxiv:comment>
    <link href="http://arxiv.org/abs/1109.5664v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1109.5664v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1110.1075v1</id>
    <updated>2011-10-05T19:03:35Z</updated>
    <published>2011-10-05T19:03:35Z</published>
    <title>The Augmented Complex Kernel LMS</title>
    <summary>  Recently, a unified framework for adaptive kernel based signal processing of
complex data was presented by the authors, which, besides offering techniques
to map the input data to complex Reproducing Kernel Hilbert Spaces, developed a
suitable Wirtinger-like Calculus for general Hilbert Spaces. In this short
paper, the extended Wirtinger's calculus is adopted to derive complex
kernel-based widely-linear estimation filters. Furthermore, we illuminate
several important characteristics of the widely linear filters. We show that,
although in many cases the gains from adopting widely linear estimation
filters, as alternatives to ordinary linear ones, are rudimentary, for the case
of kernel based widely linear filters significant performance improvements can
be obtained.
</summary>
    <author>
      <name>Pantelis Bouboulis</name>
    </author>
    <author>
      <name>Sergios Theodoridis</name>
    </author>
    <author>
      <name>Michael Mavroforakis</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TSP.2012.2200479</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TSP.2012.2200479" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">manuscript submitted to IEE Transactions on Signal Processing</arxiv:comment>
    <link href="http://arxiv.org/abs/1110.1075v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1110.1075v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1110.1781v1</id>
    <updated>2011-10-09T02:18:50Z</updated>
    <published>2011-10-09T02:18:50Z</published>
    <title>A Study of Unsupervised Adaptive Crowdsourcing</title>
    <summary>  We consider unsupervised crowdsourcing performance based on the model wherein
the responses of end-users are essentially rated according to how their
responses correlate with the majority of other responses to the same
subtasks/questions. In one setting, we consider an independent sequence of
identically distributed crowdsourcing assignments (meta-tasks), while in the
other we consider a single assignment with a large number of component
subtasks. Both problems yield intuitive results in which the overall
reliability of the crowd is a factor.
</summary>
    <author>
      <name>G. Kesidis</name>
    </author>
    <author>
      <name>A. Kurve</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Technical Report, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1110.1781v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1110.1781v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1110.2211v1</id>
    <updated>2011-10-10T21:58:58Z</updated>
    <published>2011-10-10T21:58:58Z</published>
    <title>Learning Symbolic Models of Stochastic Domains</title>
    <summary>  In this article, we work towards the goal of developing agents that can learn
to act in complex worlds. We develop a probabilistic, relational planning rule
representation that compactly models noisy, nondeterministic action effects,
and show how such rules can be effectively learned. Through experiments in
simple planning domains and a 3D simulated blocks world with realistic physics,
we demonstrate that this learning algorithm allows agents to effectively model
world dynamics.
</summary>
    <author>
      <name>L. P. Kaelbling</name>
    </author>
    <author>
      <name>H. M. Pasula</name>
    </author>
    <author>
      <name>L. S. Zettlemoyer</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1613/jair.2113</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1613/jair.2113" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal Of Artificial Intelligence Research, Volume 29, pages
  309-352, 2007</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1110.2211v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1110.2211v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1110.2626v1</id>
    <updated>2011-10-12T10:56:29Z</updated>
    <published>2011-10-12T10:56:29Z</published>
    <title>Analysis of Heart Diseases Dataset using Neural Network Approach</title>
    <summary>  One of the important techniques of Data mining is Classification. Many real
world problems in various fields such as business, science, industry and
medicine can be solved by using classification approach. Neural Networks have
emerged as an important tool for classification. The advantages of Neural
Networks helps for efficient classification of given data. In this study a
Heart diseases dataset is analyzed using Neural Network approach. To increase
the efficiency of the classification process parallel approach is also adopted
in the training phase.
</summary>
    <author>
      <name>K. Usha Rani</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5121/ijdkp.2011.1501</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5121/ijdkp.2011.1501" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 2 figures, 1 table; International Journal of Data Mining &amp;
  Knowledge Management Process (IJDKP) Vol.1, No.5, September 2011</arxiv:comment>
    <link href="http://arxiv.org/abs/1110.2626v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1110.2626v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1110.4416v1</id>
    <updated>2011-10-20T00:56:53Z</updated>
    <published>2011-10-20T00:56:53Z</published>
    <title>Data-dependent kernels in nearly-linear time</title>
    <summary>  We propose a method to efficiently construct data-dependent kernels which can
make use of large quantities of (unlabeled) data. Our construction makes an
approximation in the standard construction of semi-supervised kernels in
Sindhwani et al. 2005. In typical cases these kernels can be computed in
nearly-linear time (in the amount of data), improving on the cubic time of the
standard construction, enabling large scale semi-supervised learning in a
variety of contexts. The methods are validated on semi-supervised and
unsupervised problems on data sets containing upto 64,000 sample points.
</summary>
    <author>
      <name>Guy Lever</name>
    </author>
    <author>
      <name>Tom Diethe</name>
    </author>
    <author>
      <name>John Shawe-Taylor</name>
    </author>
    <link href="http://arxiv.org/abs/1110.4416v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1110.4416v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1110.5051v1</id>
    <updated>2011-10-23T14:41:21Z</updated>
    <published>2011-10-23T14:41:21Z</published>
    <title>Wikipedia Edit Number Prediction based on Temporal Dynamics Only</title>
    <summary>  In this paper, we describe our approach to the Wikipedia Participation
Challenge which aims to predict the number of edits a Wikipedia editor will
make in the next 5 months. The best submission from our team, "zeditor",
achieved 41.7% improvement over WMF's baseline predictive model and the final
rank of 3rd place among 96 teams. An interesting characteristic of our approach
is that only temporal dynamics features (i.e., how the number of edits changes
in recent periods, etc.) are used in a self-supervised learning framework,
which makes it easy to be generalised to other application domains.
</summary>
    <author>
      <name>Dell Zhang</name>
    </author>
    <link href="http://arxiv.org/abs/1110.5051v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1110.5051v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1110.6287v1</id>
    <updated>2011-10-28T10:20:25Z</updated>
    <published>2011-10-28T10:20:25Z</published>
    <title>Deciding of HMM parameters based on number of critical points for
  gesture recognition from motion capture data</title>
    <summary>  This paper presents a method of choosing number of states of a HMM based on
number of critical points of the motion capture data. The choice of Hidden
Markov Models(HMM) parameters is crucial for recognizer's performance as it is
the first step of the training and cannot be corrected automatically within
HMM. In this article we define predictor of number of states based on number of
critical points of the sequence and test its effectiveness against sample data.
</summary>
    <author>
      <name>Michał Cholewa</name>
    </author>
    <author>
      <name>Przemysław Głomb</name>
    </author>
    <link href="http://arxiv.org/abs/1110.6287v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1110.6287v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.1124v1</id>
    <updated>2011-11-04T13:33:24Z</updated>
    <published>2011-11-04T13:33:24Z</published>
    <title>Tight Bounds on Proper Equivalence Query Learning of DNF</title>
    <summary>  We prove a new structural lemma for partial Boolean functions $f$, which we
call the seed lemma for DNF. Using the lemma, we give the first subexponential
algorithm for proper learning of DNF in Angluin's Equivalence Query (EQ) model.
The algorithm has time and query complexity $2^{(\tilde{O}{\sqrt{n}})}$, which
is optimal. We also give a new result on certificates for DNF-size, a simple
algorithm for properly PAC-learning DNF, and new results on EQ-learning $\log
n$-term DNF and decision trees.
</summary>
    <author>
      <name>Lisa Hellerstein</name>
    </author>
    <author>
      <name>Devorah Kletenik</name>
    </author>
    <author>
      <name>Linda Sellie</name>
    </author>
    <author>
      <name>Rocco Servedio</name>
    </author>
    <link href="http://arxiv.org/abs/1111.1124v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.1124v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.1136v2</id>
    <updated>2011-11-14T21:16:59Z</updated>
    <published>2011-11-04T14:18:31Z</published>
    <title>Universal MMSE Filtering With Logarithmic Adaptive Regret</title>
    <summary>  We consider the problem of online estimation of a real-valued signal
corrupted by oblivious zero-mean noise using linear estimators. The estimator
is required to iteratively predict the underlying signal based on the current
and several last noisy observations, and its performance is measured by the
mean-square-error. We describe and analyze an algorithm for this task which: 1.
Achieves logarithmic adaptive regret against the best linear filter in
hindsight. This bound is assyptotically tight, and resolves the question of
Moon and Weissman [1]. 2. Runs in linear time in terms of the number of filter
coefficients. Previous constructions required at least quadratic time.
</summary>
    <author>
      <name>Dan Garber</name>
    </author>
    <author>
      <name>Elad Hazan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1111.1136v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.1136v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.1422v1</id>
    <updated>2011-11-06T14:01:14Z</updated>
    <published>2011-11-06T14:01:14Z</published>
    <title>Robust Interactive Learning</title>
    <summary>  In this paper we propose and study a generalization of the standard
active-learning model where a more general type of query, class conditional
query, is allowed. Such queries have been quite useful in applications, but
have been lacking theoretical understanding. In this work, we characterize the
power of such queries under two well-known noise models. We give nearly tight
upper and lower bounds on the number of queries needed to learn both for the
general agnostic setting and for the bounded noise model. We further show that
our methods can be made adaptive to the (unknown) noise rate, with only
negligible loss in query complexity.
</summary>
    <author>
      <name>Maria-Florina Balcan</name>
    </author>
    <author>
      <name>Steve Hanneke</name>
    </author>
    <link href="http://arxiv.org/abs/1111.1422v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.1422v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.3735v1</id>
    <updated>2011-11-16T09:26:14Z</updated>
    <published>2011-11-16T09:26:14Z</published>
    <title>A Bayesian Model for Plan Recognition in RTS Games applied to StarCraft</title>
    <summary>  The task of keyhole (unobtrusive) plan recognition is central to adaptive
game AI. "Tech trees" or "build trees" are the core of real-time strategy (RTS)
game strategic (long term) planning. This paper presents a generic and simple
Bayesian model for RTS build tree prediction from noisy observations, which
parameters are learned from replays (game logs). This unsupervised machine
learning approach involves minimal work for the game developers as it leverage
players' data (com- mon in RTS). We applied it to StarCraft1 and showed that it
yields high quality and robust predictions, that can feed an adaptive AI.
</summary>
    <author>
      <name>Gabriel Synnaeve</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIG, LPPA</arxiv:affiliation>
    </author>
    <author>
      <name>Pierre Bessière</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIG, LPPA</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages; Artificial Intelligence and Interactive Digital
  Entertainment Conference (AIIDE 2011), Palo Alto : \'Etats-Unis (2011)</arxiv:comment>
    <link href="http://arxiv.org/abs/1111.3735v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.3735v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.3846v1</id>
    <updated>2011-11-16T16:06:57Z</updated>
    <published>2011-11-16T16:06:57Z</published>
    <title>No Free Lunch versus Occam's Razor in Supervised Learning</title>
    <summary>  The No Free Lunch theorems are often used to argue that domain specific
knowledge is required to design successful algorithms. We use algorithmic
information theory to argue the case for a universal bias allowing an algorithm
to succeed in all interesting problem domains. Additionally, we give a new
algorithm for off-line classification, inspired by Solomonoff induction, with
good performance on all structured problems under reasonable assumptions. This
includes a proof of the efficacy of the well-known heuristic of randomly
selecting training data in the hope of reducing misclassification rates.
</summary>
    <author>
      <name>Tor Lattimore</name>
    </author>
    <author>
      <name>Marcus Hutter</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 LaTeX pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1111.3846v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.3846v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1112.1768v1</id>
    <updated>2011-12-08T05:53:35Z</updated>
    <published>2011-12-08T05:53:35Z</published>
    <title>Extended UCB Policy for Multi-Armed Bandit with Light-Tailed Reward
  Distributions</title>
    <summary>  We consider the multi-armed bandit problems in which a player aims to accrue
reward by sequentially playing a given set of arms with unknown reward
statistics. In the classic work, policies were proposed to achieve the optimal
logarithmic regret order for some special classes of light-tailed reward
distributions, e.g., Auer et al.'s UCB1 index policy for reward distributions
with finite support. In this paper, we extend Auer et al.'s UCB1 index policy
to achieve the optimal logarithmic regret order for all light-tailed (or
equivalently, locally sub-Gaussian) reward distributions defined by the (local)
existence of the moment-generating function.
</summary>
    <author>
      <name>Keqin Liu</name>
    </author>
    <author>
      <name>Qing Zhao</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1112.1768v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1112.1768v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1112.1937v1</id>
    <updated>2011-12-08T20:27:31Z</updated>
    <published>2011-12-08T20:27:31Z</published>
    <title>Bootstrapping Intrinsically Motivated Learning with Human Demonstrations</title>
    <summary>  This paper studies the coupling of internally guided learning and social
interaction, and more specifically the improvement owing to demonstrations of
the learning by intrinsic motivation. We present Socially Guided Intrinsic
Motivation by Demonstration (SGIM-D), an algorithm for learning in continuous,
unbounded and non-preset environments. After introducing social learning and
intrinsic motivation, we describe the design of our algorithm, before showing
through a fishing experiment that SGIM-D efficiently combines the advantages of
social learning and intrinsic motivation to gain a wide repertoire while being
specialised in specific subspaces.
</summary>
    <author>
      <name>Sao Mai Nguyen</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Bordeaux - Sud-Ouest</arxiv:affiliation>
    </author>
    <author>
      <name>Adrien Baranes</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Bordeaux - Sud-Ouest</arxiv:affiliation>
    </author>
    <author>
      <name>Pierre-Yves Oudeyer</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Bordeaux - Sud-Ouest</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE International Conference on Development and Learning, Frankfurt
  : Germany (2011)</arxiv:comment>
    <link href="http://arxiv.org/abs/1112.1937v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1112.1937v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1112.4344v1</id>
    <updated>2011-12-19T14:21:00Z</updated>
    <published>2011-12-19T14:21:00Z</published>
    <title>A Scalable Multiclass Algorithm for Node Classification</title>
    <summary>  We introduce a scalable algorithm, MUCCA, for multiclass node classification
in weighted graphs. Unlike previously proposed methods for the same task, MUCCA
works in time linear in the number of nodes. Our approach is based on a
game-theoretic formulation of the problem in which the test labels are
expressed as a Nash Equilibrium of a certain game. However, in order to achieve
scalability, we find the equilibrium on a spanning tree of the original graph.
Experiments on real-world data reveal that MUCCA is much faster than its
competitors while achieving a similar predictive performance.
</summary>
    <author>
      <name>Giovanni Zappella</name>
    </author>
    <link href="http://arxiv.org/abs/1112.4344v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1112.4344v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1201.2416v1</id>
    <updated>2012-01-11T21:03:55Z</updated>
    <published>2012-01-11T21:03:55Z</published>
    <title>Stochastic Low-Rank Kernel Learning for Regression</title>
    <summary>  We present a novel approach to learn a kernel-based regression function. It
is based on the useof conical combinations of data-based parameterized kernels
and on a new stochastic convex optimization procedure of which we establish
convergence guarantees. The overall learning procedure has the nice properties
that a) the learned conical combination is automatically designed to perform
the regression task at hand and b) the updates implicated by the optimization
procedure are quite inexpensive. In order to shed light on the appositeness of
our learning strategy, we present empirical results from experiments conducted
on various benchmark datasets.
</summary>
    <author>
      <name>Pierre Machart</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIF</arxiv:affiliation>
    </author>
    <author>
      <name>Thomas Peel</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIF, LATP</arxiv:affiliation>
    </author>
    <author>
      <name>Liva Ralaivola</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIF</arxiv:affiliation>
    </author>
    <author>
      <name>Sandrine Anthoine</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LATP</arxiv:affiliation>
    </author>
    <author>
      <name>Hervé Glotin</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LSIS</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">International Conference on Machine Learning (ICML'11), Bellevue
  (Washington) : United States (2011)</arxiv:comment>
    <link href="http://arxiv.org/abs/1201.2416v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1201.2416v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1201.5217v1</id>
    <updated>2012-01-25T09:44:06Z</updated>
    <published>2012-01-25T09:44:06Z</published>
    <title>Unsupervised Classification Using Immune Algorithm</title>
    <summary>  Unsupervised classification algorithm based on clonal selection principle
named Unsupervised Clonal Selection Classification (UCSC) is proposed in this
paper. The new proposed algorithm is data driven and self-adaptive, it adjusts
its parameters to the data to make the classification operation as fast as
possible. The performance of UCSC is evaluated by comparing it with the well
known K-means algorithm using several artificial and real-life data sets. The
experiments show that the proposed UCSC algorithm is more reliable and has high
classification precision comparing to traditional classification methods such
as K-means.
</summary>
    <author>
      <name>M. T. Al-Muallim</name>
    </author>
    <author>
      <name>R. El-Kouatly</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5120/677-952</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5120/677-952" rel="related"/>
    <link href="http://arxiv.org/abs/1201.5217v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1201.5217v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.1121v2</id>
    <updated>2014-11-14T14:39:39Z</updated>
    <published>2012-02-06T12:43:12Z</published>
    <title>rFerns: An Implementation of the Random Ferns Method for General-Purpose
  Machine Learning</title>
    <summary>  In this paper I present an extended implementation of the Random ferns
algorithm contained in the R package rFerns. It differs from the original by
the ability of consuming categorical and numerical attributes instead of only
binary ones. Also, instead of using simple attribute subspace ensemble it
employs bagging and thus produce error approximation and variable importance
measure modelled after Random forest algorithm. I also present benchmarks'
results which show that although Random ferns' accuracy is mostly smaller than
achieved by Random forest, its speed and good quality of importance measure it
provides make rFerns a reasonable choice for a specific applications.
</summary>
    <author>
      <name>Miron B. Kursa</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Statistical Software, 61(10), 1-13</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1202.1121v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.1121v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.3702v1</id>
    <updated>2012-02-14T16:41:17Z</updated>
    <published>2012-02-14T16:41:17Z</published>
    <title>Semi-supervised Learning with Density Based Distances</title>
    <summary>  We present a simple, yet effective, approach to Semi-Supervised Learning. Our
approach is based on estimating density-based distances (DBD) using a shortest
path calculation on a graph. These Graph-DBD estimates can then be used in any
distance-based supervised learning method, such as Nearest Neighbor methods and
SVMs with RBF kernels. In order to apply the method to very large data sets, we
also present a novel algorithm which integrates nearest neighbor computations
into the shortest path search and can find exact shortest paths even in
extremely large dense graphs. Significant runtime improvement over the commonly
used Laplacian regularization method is then shown on a large scale dataset.
</summary>
    <author>
      <name>Avleen S. Bijral</name>
    </author>
    <author>
      <name>Nathan Ratliff</name>
    </author>
    <author>
      <name>Nathan Srebro</name>
    </author>
    <link href="http://arxiv.org/abs/1202.3702v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.3702v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.3716v1</id>
    <updated>2012-02-14T16:41:17Z</updated>
    <published>2012-02-14T16:41:17Z</published>
    <title>Boosting as a Product of Experts</title>
    <summary>  In this paper, we derive a novel probabilistic model of boosting as a Product
of Experts. We re-derive the boosting algorithm as a greedy incremental model
selection procedure which ensures that addition of new experts to the ensemble
does not decrease the likelihood of the data. These learning rules lead to a
generic boosting algorithm - POE- Boost which turns out to be similar to the
AdaBoost algorithm under certain assumptions on the expert probabilities. The
paper then extends the POEBoost algorithm to POEBoost.CS which handles
hypothesis that produce probabilistic predictions. This new algorithm is shown
to have better generalization performance compared to other state of the art
algorithms.
</summary>
    <author>
      <name>Narayanan U. Edakunni</name>
    </author>
    <author>
      <name>Gary Brown</name>
    </author>
    <author>
      <name>Tim Kovacs</name>
    </author>
    <link href="http://arxiv.org/abs/1202.3716v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.3716v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.3727v1</id>
    <updated>2012-02-14T16:41:17Z</updated>
    <published>2012-02-14T16:41:17Z</published>
    <title>Bregman divergence as general framework to estimate unnormalized
  statistical models</title>
    <summary>  We show that the Bregman divergence provides a rich framework to estimate
unnormalized statistical models for continuous or discrete random variables,
that is, models which do not integrate or sum to one, respectively. We prove
that recent estimation methods such as noise-contrastive estimation, ratio
matching, and score matching belong to the proposed framework, and explain
their interconnection based on supervised learning. Further, we discuss the
role of boosting in unsupervised learning.
</summary>
    <author>
      <name>Michael Gutmann</name>
    </author>
    <author>
      <name>Jun-ichiro Hirayama</name>
    </author>
    <link href="http://arxiv.org/abs/1202.3727v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.3727v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.3736v1</id>
    <updated>2012-02-14T16:41:17Z</updated>
    <published>2012-02-14T16:41:17Z</published>
    <title>Discovering causal structures in binary exclusive-or skew acyclic models</title>
    <summary>  Discovering causal relations among observed variables in a given data set is
a main topic in studies of statistics and artificial intelligence. Recently,
some techniques to discover an identifiable causal structure have been explored
based on non-Gaussianity of the observed data distribution. However, most of
these are limited to continuous data. In this paper, we present a novel causal
model for binary data and propose a new approach to derive an identifiable
causal structure governing the data based on skew Bernoulli distributions of
external noise. Experimental evaluation shows excellent performance for both
artificial and real world data sets.
</summary>
    <author>
      <name>Takanori Inazumi</name>
    </author>
    <author>
      <name>Takashi Washio</name>
    </author>
    <author>
      <name>Shohei Shimizu</name>
    </author>
    <author>
      <name>Joe Suzuki</name>
    </author>
    <author>
      <name>Akihiro Yamamoto</name>
    </author>
    <author>
      <name>Yoshinobu Kawahara</name>
    </author>
    <link href="http://arxiv.org/abs/1202.3736v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.3736v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.3742v1</id>
    <updated>2012-02-14T16:41:17Z</updated>
    <published>2012-02-14T16:41:17Z</published>
    <title>Variational Algorithms for Marginal MAP</title>
    <summary>  Marginal MAP problems are notoriously difficult tasks for graphical models.
We derive a general variational framework for solving marginal MAP problems, in
which we apply analogues of the Bethe, tree-reweighted, and mean field
approximations. We then derive a "mixed" message passing algorithm and a
convergent alternative using CCCP to solve the BP-type approximations.
Theoretically, we give conditions under which the decoded solution is a global
or local optimum, and obtain novel upper bounds on solutions. Experimentally we
demonstrate that our algorithms outperform related approaches. We also show
that EM and variational EM comprise a special case of our framework.
</summary>
    <author>
      <name>Qiang Liu</name>
    </author>
    <author>
      <name>Alexander T. Ihler</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">conference version. full journal version is at arXiv:1302.6584</arxiv:comment>
    <link href="http://arxiv.org/abs/1202.3742v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.3742v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.3747v1</id>
    <updated>2012-02-14T16:41:17Z</updated>
    <published>2012-02-14T16:41:17Z</published>
    <title>Reconstructing Pompeian Households</title>
    <summary>  A database of objects discovered in houses in the Roman city of Pompeii
provides a unique view of ordinary life in an ancient city. Experts have used
this collection to study the structure of Roman households, exploring the
distribution and variability of tasks in architectural spaces, but such
approaches are necessarily affected by modern cultural assumptions. In this
study we present a data-driven approach to household archeology, treating it as
an unsupervised labeling problem. This approach scales to large data sets and
provides a more objective complement to human interpretation.
</summary>
    <author>
      <name>David Mimno</name>
    </author>
    <link href="http://arxiv.org/abs/1202.3747v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.3747v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.3750v1</id>
    <updated>2012-02-14T16:41:17Z</updated>
    <published>2012-02-14T16:41:17Z</published>
    <title>Fractional Moments on Bandit Problems</title>
    <summary>  Reinforcement learning addresses the dilemma between exploration to find
profitable actions and exploitation to act according to the best observations
already made. Bandit problems are one such class of problems in stateless
environments that represent this explore/exploit situation. We propose a
learning algorithm for bandit problems based on fractional expectation of
rewards acquired. The algorithm is theoretically shown to converge on an
eta-optimal arm and achieve O(n) sample complexity. Experimental results show
the algorithm incurs substantially lower regrets than parameter-optimized
eta-greedy and SoftMax approaches and other low sample complexity
state-of-the-art techniques.
</summary>
    <author>
      <name>Ananda Narayanan B</name>
    </author>
    <author>
      <name>Balaraman Ravindran</name>
    </author>
    <link href="http://arxiv.org/abs/1202.3750v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.3750v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.3753v1</id>
    <updated>2012-02-14T16:41:17Z</updated>
    <published>2012-02-14T16:41:17Z</published>
    <title>Partial Order MCMC for Structure Discovery in Bayesian Networks</title>
    <summary>  We present a new Markov chain Monte Carlo method for estimating posterior
probabilities of structural features in Bayesian networks. The method draws
samples from the posterior distribution of partial orders on the nodes; for
each sampled partial order, the conditional probabilities of interest are
computed exactly. We give both analytical and empirical results that suggest
the superiority of the new method compared to previous methods, which sample
either directed acyclic graphs or linear orders on the nodes.
</summary>
    <author>
      <name>Teppo Niinimaki</name>
    </author>
    <author>
      <name>Pekka Parviainen</name>
    </author>
    <author>
      <name>Mikko Koivisto</name>
    </author>
    <link href="http://arxiv.org/abs/1202.3753v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.3753v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.3766v1</id>
    <updated>2012-02-14T16:41:17Z</updated>
    <published>2012-02-14T16:41:17Z</published>
    <title>Robust learning Bayesian networks for prior belief</title>
    <summary>  Recent reports have described that learning Bayesian networks are highly
sensitive to the chosen equivalent sample size (ESS) in the Bayesian Dirichlet
equivalence uniform (BDeu). This sensitivity often engenders some unstable or
undesirable results. This paper describes some asymptotic analyses of BDeu to
explain the reasons for the sensitivity and its effects. Furthermore, this
paper presents a proposal for a robust learning score for ESS by eliminating
the sensitive factors from the approximation of log-BDeu.
</summary>
    <author>
      <name>Maomi Ueno</name>
    </author>
    <link href="http://arxiv.org/abs/1202.3766v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.3766v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.3771v1</id>
    <updated>2012-02-14T16:41:17Z</updated>
    <published>2012-02-14T16:41:17Z</published>
    <title>Tightening MRF Relaxations with Planar Subproblems</title>
    <summary>  We describe a new technique for computing lower-bounds on the minimum energy
configuration of a planar Markov Random Field (MRF). Our method successively
adds large numbers of constraints and enforces consistency over binary
projections of the original problem state space. These constraints are
represented in terms of subproblems in a dual-decomposition framework that is
optimized using subgradient techniques. The complete set of constraints we
consider enforces cycle consistency over the original graph. In practice we
find that the method converges quickly on most problems with the addition of a
few subproblems and outperforms existing methods for some interesting classes
of hard potentials.
</summary>
    <author>
      <name>Julian Yarkony</name>
    </author>
    <author>
      <name>Ragib Morshed</name>
    </author>
    <author>
      <name>Alexander T. Ihler</name>
    </author>
    <author>
      <name>Charless C. Fowlkes</name>
    </author>
    <link href="http://arxiv.org/abs/1202.3771v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.3771v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.3775v1</id>
    <updated>2012-02-14T16:41:17Z</updated>
    <published>2012-02-14T16:41:17Z</published>
    <title>Kernel-based Conditional Independence Test and Application in Causal
  Discovery</title>
    <summary>  Conditional independence testing is an important problem, especially in
Bayesian network learning and causal discovery. Due to the curse of
dimensionality, testing for conditional independence of continuous variables is
particularly challenging. We propose a Kernel-based Conditional Independence
test (KCI-test), by constructing an appropriate test statistic and deriving its
asymptotic distribution under the null hypothesis of conditional independence.
The proposed method is computationally efficient and easy to implement.
Experimental results show that it outperforms other methods, especially when
the conditioning set is large or the sample size is not very large, in which
case other methods encounter difficulties.
</summary>
    <author>
      <name>Kun Zhang</name>
    </author>
    <author>
      <name>Jonas Peters</name>
    </author>
    <author>
      <name>Dominik Janzing</name>
    </author>
    <author>
      <name>Bernhard Schoelkopf</name>
    </author>
    <link href="http://arxiv.org/abs/1202.3775v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.3775v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.3778v1</id>
    <updated>2012-02-14T16:41:17Z</updated>
    <published>2012-02-14T16:41:17Z</published>
    <title>Sparse Topical Coding</title>
    <summary>  We present sparse topical coding (STC), a non-probabilistic formulation of
topic models for discovering latent representations of large collections of
data. Unlike probabilistic topic models, STC relaxes the normalization
constraint of admixture proportions and the constraint of defining a normalized
likelihood function. Such relaxations make STC amenable to: 1) directly control
the sparsity of inferred representations by using sparsity-inducing
regularizers; 2) be seamlessly integrated with a convex error function (e.g.,
SVM hinge loss) for supervised learning; and 3) be efficiently learned with a
simply structured coordinate descent algorithm. Our results demonstrate the
advantages of STC and supervised MedSTC on identifying topical meanings of
words and improving classification accuracy and time efficiency.
</summary>
    <author>
      <name>Jun Zhu</name>
    </author>
    <author>
      <name>Eric P. Xing</name>
    </author>
    <link href="http://arxiv.org/abs/1202.3778v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.3778v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.3782v1</id>
    <updated>2012-02-14T16:41:17Z</updated>
    <published>2012-02-14T16:41:17Z</published>
    <title>Graphical Models for Bandit Problems</title>
    <summary>  We introduce a rich class of graphical models for multi-armed bandit problems
that permit both the state or context space and the action space to be very
large, yet succinctly specify the payoffs for any context-action pair. Our main
result is an algorithm for such models whose regret is bounded by the number of
parameters and whose running time depends only on the treewidth of the graph
substructure induced by the action space.
</summary>
    <author>
      <name>Kareem Amin</name>
    </author>
    <author>
      <name>Michael Kearns</name>
    </author>
    <author>
      <name>Umar Syed</name>
    </author>
    <link href="http://arxiv.org/abs/1202.3782v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.3782v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.3890v1</id>
    <updated>2012-02-17T11:59:55Z</updated>
    <published>2012-02-17T11:59:55Z</published>
    <title>PAC Bounds for Discounted MDPs</title>
    <summary>  We study upper and lower bounds on the sample-complexity of learning
near-optimal behaviour in finite-state discounted Markov Decision Processes
(MDPs). For the upper bound we make the assumption that each action leads to at
most two possible next-states and prove a new bound for a UCRL-style algorithm
on the number of time-steps when it is not Probably Approximately Correct
(PAC). The new lower bound strengthens previous work by being both more general
(it applies to all policies) and tighter. The upper and lower bounds match up
to logarithmic factors.
</summary>
    <author>
      <name>Tor Lattimore</name>
    </author>
    <author>
      <name>Marcus Hutter</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">25 LaTeX pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. 23rd International Conf. on Algorithmic Learning Theory (ALT
  2012) pages 320-334</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1202.3890v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.3890v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1203.0298v2</id>
    <updated>2012-03-06T09:01:19Z</updated>
    <published>2012-03-01T14:40:02Z</published>
    <title>Application of Gist SVM in Cancer Detection</title>
    <summary>  In this paper, we study the application of GIST SVM in disease prediction
(detection of cancer). Pattern classification problems can be effectively
solved by Support vector machines. Here we propose a classifier which can
differentiate patients having benign and malignant cancer cells. To improve the
accuracy of classification, we propose to determine the optimal size of the
training set and perform feature selection. To find the optimal size of the
training set, different sizes of training sets are experimented and the one
with highest classification rate is selected. The optimal features are selected
through their F-Scores.
</summary>
    <author>
      <name>S. Aruna</name>
    </author>
    <author>
      <name>S. P. Rajagopalan</name>
    </author>
    <author>
      <name>L. V. Nandakishore</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Ann. Univ. Tibiscus Comp. Sci. Series IX/2 (2011), 39-48</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1203.0298v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1203.0298v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1203.3462v1</id>
    <updated>2012-03-15T11:17:56Z</updated>
    <published>2012-03-15T11:17:56Z</published>
    <title>Gaussian Process Topic Models</title>
    <summary>  We introduce Gaussian Process Topic Models (GPTMs), a new family of topic
models which can leverage a kernel among documents while extracting correlated
topics. GPTMs can be considered a systematic generalization of the Correlated
Topic Models (CTMs) using ideas from Gaussian Process (GP) based embedding.
Since GPTMs work with both a topic covariance matrix and a document kernel
matrix, learning GPTMs involves a novel component-solving a suitable Sylvester
equation capturing both topic and document dependencies. The efficacy of GPTMs
is demonstrated with experiments evaluating the quality of both topic modeling
and embedding.
</summary>
    <author>
      <name>Amrudin Agovic</name>
    </author>
    <author>
      <name>Arindam Banerjee</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty
  in Artificial Intelligence (UAI2010)</arxiv:comment>
    <link href="http://arxiv.org/abs/1203.3462v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1203.3462v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1203.3472v1</id>
    <updated>2012-03-15T11:17:56Z</updated>
    <published>2012-03-15T11:17:56Z</published>
    <title>Super-Samples from Kernel Herding</title>
    <summary>  We extend the herding algorithm to continuous spaces by using the kernel
trick. The resulting "kernel herding" algorithm is an infinite memory
deterministic process that learns to approximate a PDF with a collection of
samples. We show that kernel herding decreases the error of expectations of
functions in the Hilbert space at a rate O(1/T) which is much faster than the
usual O(1/pT) for iid random samples. We illustrate kernel herding by
approximating Bayesian predictive distributions.
</summary>
    <author>
      <name>Yutian Chen</name>
    </author>
    <author>
      <name>Max Welling</name>
    </author>
    <author>
      <name>Alex Smola</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty
  in Artificial Intelligence (UAI2010)</arxiv:comment>
    <link href="http://arxiv.org/abs/1203.3472v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1203.3472v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1203.3483v1</id>
    <updated>2012-03-15T11:17:56Z</updated>
    <published>2012-03-15T11:17:56Z</published>
    <title>Regularized Maximum Likelihood for Intrinsic Dimension Estimation</title>
    <summary>  We propose a new method for estimating the intrinsic dimension of a dataset
by applying the principle of regularized maximum likelihood to the distances
between close neighbors. We propose a regularization scheme which is motivated
by divergence minimization principles. We derive the estimator by a Poisson
process approximation, argue about its convergence properties and apply it to a
number of simulated and real datasets. We also show it has the best overall
performance compared with two other intrinsic dimension estimators.
</summary>
    <author>
      <name>Mithun Das Gupta</name>
    </author>
    <author>
      <name>Thomas S. Huang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty
  in Artificial Intelligence (UAI2010)</arxiv:comment>
    <link href="http://arxiv.org/abs/1203.3483v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1203.3483v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1203.3492v1</id>
    <updated>2012-03-15T11:17:56Z</updated>
    <published>2012-03-15T11:17:56Z</published>
    <title>Approximating Higher-Order Distances Using Random Projections</title>
    <summary>  We provide a simple method and relevant theoretical analysis for efficiently
estimating higher-order lp distances. While the analysis mainly focuses on l4,
our methodology extends naturally to p = 6,8,10..., (i.e., when p is even).
Distance-based methods are popular in machine learning. In large-scale
applications, storing, computing, and retrieving the distances can be both
space and time prohibitive. Efficient algorithms exist for estimating lp
distances if 0 &lt; p &lt;= 2. The task for p &gt; 2 is known to be difficult. Our work
partially fills this gap.
</summary>
    <author>
      <name>Ping Li</name>
    </author>
    <author>
      <name>Michael W. Mahoney</name>
    </author>
    <author>
      <name>Yiyuan She</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty
  in Artificial Intelligence (UAI2010)</arxiv:comment>
    <link href="http://arxiv.org/abs/1203.3492v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1203.3492v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1203.3496v1</id>
    <updated>2012-03-15T11:17:56Z</updated>
    <published>2012-03-15T11:17:56Z</published>
    <title>Dirichlet Process Mixtures of Generalized Mallows Models</title>
    <summary>  We present a Dirichlet process mixture model over discrete incomplete
rankings and study two Gibbs sampling inference techniques for estimating
posterior clusterings. The first approach uses a slice sampling subcomponent
for estimating cluster parameters. The second approach marginalizes out several
cluster parameters by taking advantage of approximations to the conditional
posteriors. We empirically demonstrate (1) the effectiveness of this
approximation for improving convergence, (2) the benefits of the Dirichlet
process model over alternative clustering techniques for ranked data, and (3)
the applicability of the approach to exploring large realworld ranking
datasets.
</summary>
    <author>
      <name>Marina Meila</name>
    </author>
    <author>
      <name>Harr Chen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty
  in Artificial Intelligence (UAI2010)</arxiv:comment>
    <link href="http://arxiv.org/abs/1203.3496v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1203.3496v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1203.3516v1</id>
    <updated>2012-03-15T11:17:56Z</updated>
    <published>2012-03-15T11:17:56Z</published>
    <title>Modeling Events with Cascades of Poisson Processes</title>
    <summary>  We present a probabilistic model of events in continuous time in which each
event triggers a Poisson process of successor events. The ensemble of observed
events is thereby modeled as a superposition of Poisson processes. Efficient
inference is feasible under this model with an EM algorithm. Moreover, the EM
algorithm can be implemented as a distributed algorithm, permitting the model
to be applied to very large datasets. We apply these techniques to the modeling
of Twitter messages and the revision history of Wikipedia.
</summary>
    <author>
      <name>Aleksandr Simma</name>
    </author>
    <author>
      <name>Michael I. Jordan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty
  in Artificial Intelligence (UAI2010)</arxiv:comment>
    <link href="http://arxiv.org/abs/1203.3516v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1203.3516v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1203.3517v1</id>
    <updated>2012-03-15T11:17:56Z</updated>
    <published>2012-03-15T11:17:56Z</published>
    <title>A Bayesian Matrix Factorization Model for Relational Data</title>
    <summary>  Relational learning can be used to augment one data source with other
correlated sources of information, to improve predictive accuracy. We frame a
large class of relational learning problems as matrix factorization problems,
and propose a hierarchical Bayesian model. Training our Bayesian model using
random-walk Metropolis-Hastings is impractically slow, and so we develop a
block Metropolis-Hastings sampler which uses the gradient and Hessian of the
likelihood to dynamically tune the proposal. We demonstrate that a predictive
model of brain response to stimuli can be improved by augmenting it with side
information about the stimuli.
</summary>
    <author>
      <name>Ajit P. Singh</name>
    </author>
    <author>
      <name>Geoffrey Gordon</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty
  in Artificial Intelligence (UAI2010)</arxiv:comment>
    <link href="http://arxiv.org/abs/1203.3517v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1203.3517v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1203.3520v1</id>
    <updated>2012-03-15T11:17:56Z</updated>
    <published>2012-03-15T11:17:56Z</published>
    <title>Bayesian Model Averaging Using the k-best Bayesian Network Structures</title>
    <summary>  We study the problem of learning Bayesian network structures from data. We
develop an algorithm for finding the k-best Bayesian network structures. We
propose to compute the posterior probabilities of hypotheses of interest by
Bayesian model averaging over the k-best Bayesian networks. We present
empirical results on structural discovery over several real and synthetic data
sets and show that the method outperforms the model selection method and the
state of-the-art MCMC methods.
</summary>
    <author>
      <name>Jin Tian</name>
    </author>
    <author>
      <name>Ru He</name>
    </author>
    <author>
      <name>Lavanya Ram</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty
  in Artificial Intelligence (UAI2010)</arxiv:comment>
    <link href="http://arxiv.org/abs/1203.3520v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1203.3520v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1203.3521v1</id>
    <updated>2012-03-15T11:17:56Z</updated>
    <published>2012-03-15T11:17:56Z</published>
    <title>Learning networks determined by the ratio of prior and data</title>
    <summary>  Recent reports have described that the equivalent sample size (ESS) in a
Dirichlet prior plays an important role in learning Bayesian networks. This
paper provides an asymptotic analysis of the marginal likelihood score for a
Bayesian network. Results show that the ratio of the ESS and sample size
determine the penalty of adding arcs in learning Bayesian networks. The number
of arcs increases monotonically as the ESS increases; the number of arcs
monotonically decreases as the ESS decreases. Furthermore, the marginal
likelihood score provides a unified expression of various score metrics by
changing prior knowledge.
</summary>
    <author>
      <name>Maomi Ueno</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty
  in Artificial Intelligence (UAI2010)</arxiv:comment>
    <link href="http://arxiv.org/abs/1203.3521v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1203.3521v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.4521v1</id>
    <updated>2012-04-20T03:01:56Z</updated>
    <published>2012-04-20T03:01:56Z</published>
    <title>A Privacy-Aware Bayesian Approach for Combining Classifier and Cluster
  Ensembles</title>
    <summary>  This paper introduces a privacy-aware Bayesian approach that combines
ensembles of classifiers and clusterers to perform semi-supervised and
transductive learning. We consider scenarios where instances and their
classification/clustering results are distributed across different data sites
and have sharing restrictions. As a special case, the privacy aware computation
of the model when instances of the target data are distributed across different
data sites, is also discussed. Experimental results show that the proposed
approach can provide good classification accuracies while adhering to the
data/model sharing constraints.
</summary>
    <author>
      <name>Ayan Acharya</name>
    </author>
    <author>
      <name>Eduardo R. Hruschka</name>
    </author>
    <author>
      <name>Joydeep Ghosh</name>
    </author>
    <link href="http://arxiv.org/abs/1204.4521v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.4521v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.5.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.4990v1</id>
    <updated>2012-04-23T08:02:19Z</updated>
    <published>2012-04-23T08:02:19Z</published>
    <title>Objective Function Designing Led by User Preferences Acquisition</title>
    <summary>  Many real world problems can be defined as optimisation problems in which the
aim is to maximise an objective function. The quality of obtained solution is
directly linked to the pertinence of the used objective function. However,
designing such function, which has to translate the user needs, is usually
fastidious. In this paper, a method to help user objective functions designing
is proposed. Our approach, which is highly interactive, is based on man machine
dialogue and more particularly on the comparison of problem instance solutions
by the user. We propose an experiment in the domain of cartographic
generalisation that shows promising results.
</summary>
    <author>
      <name>Patrick Taillandier</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">UMMISCO</arxiv:affiliation>
    </author>
    <author>
      <name>Julien Gaffuri</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">COGIT</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">International Conference on Information Technology and Applications,
  Hanoi : Viet Nam (2009)</arxiv:comment>
    <link href="http://arxiv.org/abs/1204.4990v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.4990v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.1828v1</id>
    <updated>2012-05-08T21:12:03Z</updated>
    <published>2012-05-08T21:12:03Z</published>
    <title>The Natural Gradient by Analogy to Signal Whitening, and Recipes and
  Tricks for its Use</title>
    <summary>  The natural gradient allows for more efficient gradient descent by removing
dependencies and biases inherent in a function's parameterization. Several
papers present the topic thoroughly and precisely. It remains a very difficult
idea to get your head around however. The intent of this note is to provide
simple intuition for the natural gradient and its use. We review how an ill
conditioned parameter space can undermine learning, introduce the natural
gradient by analogy to the more widely understood concept of signal whitening,
and present tricks and specific prescriptions for applying the natural gradient
to learning problems.
</summary>
    <author>
      <name>Jascha Sohl-Dickstein</name>
    </author>
    <link href="http://arxiv.org/abs/1205.1828v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.1828v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.1925v1</id>
    <updated>2012-05-09T09:49:37Z</updated>
    <published>2012-05-09T09:49:37Z</published>
    <title>Hamiltonian Annealed Importance Sampling for partition function
  estimation</title>
    <summary>  We introduce an extension to annealed importance sampling that uses
Hamiltonian dynamics to rapidly estimate normalization constants. We
demonstrate this method by computing log likelihoods in directed and undirected
probabilistic image models. We compare the performance of linear generative
models with both Gaussian and Laplace priors, product of experts models with
Laplace and Student's t experts, the mc-RBM, and a bilinear generative model.
We provide code to compare additional models.
</summary>
    <author>
      <name>Jascha Sohl-Dickstein</name>
    </author>
    <author>
      <name>Benjamin J. Culpepper</name>
    </author>
    <link href="http://arxiv.org/abs/1205.1925v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.1925v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.2605v1</id>
    <updated>2012-05-09T18:42:06Z</updated>
    <published>2012-05-09T18:42:06Z</published>
    <title>Herding Dynamic Weights for Partially Observed Random Field Models</title>
    <summary>  Learning the parameters of a (potentially partially observable) random field
model is intractable in general. Instead of focussing on a single optimal
parameter value we propose to treat parameters as dynamical quantities. We
introduce an algorithm to generate complex dynamics for parameters and (both
visible and hidden) state vectors. We show that under certain conditions
averages computed over trajectories of the proposed dynamical system converge
to averages computed over the data. Our "herding dynamics" does not require
expensive operations such as exponentiation and is fully deterministic.
</summary>
    <author>
      <name>Max Welling</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty
  in Artificial Intelligence (UAI2009)</arxiv:comment>
    <link href="http://arxiv.org/abs/1205.2605v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.2605v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.2608v1</id>
    <updated>2012-05-09T18:38:39Z</updated>
    <published>2012-05-09T18:38:39Z</published>
    <title>Temporal-Difference Networks for Dynamical Systems with Continuous
  Observations and Actions</title>
    <summary>  Temporal-difference (TD) networks are a class of predictive state
representations that use well-established TD methods to learn models of
partially observable dynamical systems. Previous research with TD networks has
dealt only with dynamical systems with finite sets of observations and actions.
We present an algorithm for learning TD network representations of dynamical
systems with continuous observations and actions. Our results show that the
algorithm is capable of learning accurate and robust models of several noisy
continuous dynamical systems. The algorithm presented here is the first fully
incremental method for learning a predictive representation of a continuous
dynamical system.
</summary>
    <author>
      <name>Christopher M. Vigorito</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty
  in Artificial Intelligence (UAI2009)</arxiv:comment>
    <link href="http://arxiv.org/abs/1205.2608v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.2608v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.2610v1</id>
    <updated>2012-05-09T18:36:39Z</updated>
    <published>2012-05-09T18:36:39Z</published>
    <title>Probabilistic Structured Predictors</title>
    <summary>  We consider MAP estimators for structured prediction with exponential family
models. In particular, we concentrate on the case that efficient algorithms for
uniform sampling from the output space exist. We show that under this
assumption (i) exact computation of the partition function remains a hard
problem, and (ii) the partition function and the gradient of the log partition
function can be approximated efficiently. Our main result is an approximation
scheme for the partition function based on Markov Chain Monte Carlo theory. We
also show that the efficient uniform sampling assumption holds in several
application settings that are of importance in machine learning.
</summary>
    <author>
      <name>Shankar Vembu</name>
    </author>
    <author>
      <name>Thomas Gartner</name>
    </author>
    <author>
      <name>Mario Boley</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty
  in Artificial Intelligence (UAI2009). arXiv admin note: substantial text
  overlap with arXiv:0912.4473</arxiv:comment>
    <link href="http://arxiv.org/abs/1205.2610v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.2610v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.2627v1</id>
    <updated>2012-05-09T17:17:33Z</updated>
    <published>2012-05-09T17:17:33Z</published>
    <title>Domain Knowledge Uncertainty and Probabilistic Parameter Constraints</title>
    <summary>  Incorporating domain knowledge into the modeling process is an effective way
to improve learning accuracy. However, as it is provided by humans, domain
knowledge can only be specified with some degree of uncertainty. We propose to
explicitly model such uncertainty through probabilistic constraints over the
parameter space. In contrast to hard parameter constraints, our approach is
effective also when the domain knowledge is inaccurate and generally results in
superior modeling accuracy. We focus on generative and conditional modeling
where the parameters are assigned a Dirichlet or Gaussian prior and demonstrate
the framework with experiments on both synthetic and real-world data.
</summary>
    <author>
      <name>Yi Mao</name>
    </author>
    <author>
      <name>Guy Lebanon</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty
  in Artificial Intelligence (UAI2009)</arxiv:comment>
    <link href="http://arxiv.org/abs/1205.2627v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.2627v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.2629v1</id>
    <updated>2012-05-09T17:14:10Z</updated>
    <published>2012-05-09T17:14:10Z</published>
    <title>Interpretation and Generalization of Score Matching</title>
    <summary>  Score matching is a recently developed parameter learning method that is
particularly effective to complicated high dimensional density models with
intractable partition functions. In this paper, we study two issues that have
not been completely resolved for score matching. First, we provide a formal
link between maximum likelihood and score matching. Our analysis shows that
score matching finds model parameters that are more robust with noisy training
data. Second, we develop a generalization of score matching. Based on this
generalization, we further demonstrate an extension of score matching to models
of discrete data.
</summary>
    <author>
      <name>Siwei Lyu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty
  in Artificial Intelligence (UAI2009)</arxiv:comment>
    <link href="http://arxiv.org/abs/1205.2629v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.2629v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.2650v1</id>
    <updated>2012-05-09T15:09:51Z</updated>
    <published>2012-05-09T15:09:51Z</published>
    <title>Correlated Non-Parametric Latent Feature Models</title>
    <summary>  We are often interested in explaining data through a set of hidden factors or
features. When the number of hidden features is unknown, the Indian Buffet
Process (IBP) is a nonparametric latent feature model that does not bound the
number of active features in dataset. However, the IBP assumes that all latent
features are uncorrelated, making it inadequate for many realworld problems. We
introduce a framework for correlated nonparametric feature models, generalising
the IBP. We use this framework to generate several specific models and
demonstrate applications on realworld datasets.
</summary>
    <author>
      <name>Finale Doshi-Velez</name>
    </author>
    <author>
      <name>Zoubin Ghahramani</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty
  in Artificial Intelligence (UAI2009)</arxiv:comment>
    <link href="http://arxiv.org/abs/1205.2650v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.2650v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.2661v1</id>
    <updated>2012-05-09T14:47:06Z</updated>
    <published>2012-05-09T14:47:06Z</published>
    <title>REGAL: A Regularization based Algorithm for Reinforcement Learning in
  Weakly Communicating MDPs</title>
    <summary>  We provide an algorithm that achieves the optimal regret rate in an unknown
weakly communicating Markov Decision Process (MDP). The algorithm proceeds in
episodes where, in each episode, it picks a policy using regularization based
on the span of the optimal bias vector. For an MDP with S states and A actions
whose optimal bias vector has span bounded by H, we show a regret bound of
~O(HSpAT). We also relate the span to various diameter-like quantities
associated with the MDP, demonstrating how our results improve on previous
regret bounds.
</summary>
    <author>
      <name>Peter L. Bartlett</name>
    </author>
    <author>
      <name>Ambuj Tewari</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty
  in Artificial Intelligence (UAI2009)</arxiv:comment>
    <link href="http://arxiv.org/abs/1205.2661v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.2661v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.3181v1</id>
    <updated>2012-05-14T20:10:04Z</updated>
    <published>2012-05-14T20:10:04Z</published>
    <title>Multiple Identifications in Multi-Armed Bandits</title>
    <summary>  We study the problem of identifying the top $m$ arms in a multi-armed bandit
game. Our proposed solution relies on a new algorithm based on successive
rejects of the seemingly bad arms, and successive accepts of the good ones.
This algorithmic contribution allows to tackle other multiple identifications
settings that were previously out of reach. In particular we show that this
idea of successive accepts and rejects applies to the multi-bandit best arm
identification problem.
</summary>
    <author>
      <name>Sébastien Bubeck</name>
    </author>
    <author>
      <name>Tengyao Wang</name>
    </author>
    <author>
      <name>Nitin Viswanathan</name>
    </author>
    <link href="http://arxiv.org/abs/1205.3181v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.3181v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.4349v1</id>
    <updated>2012-05-19T17:16:53Z</updated>
    <published>2012-05-19T17:16:53Z</published>
    <title>From Exact Learning to Computing Boolean Functions and Back Again</title>
    <summary>  The goal of the paper is to relate complexity measures associated with the
evaluation of Boolean functions (certificate complexity, decision tree
complexity) and learning dimensions used to characterize exact learning
(teaching dimension, extended teaching dimension). The high level motivation is
to discover non-trivial relations between exact learning of an unknown concept
and testing whether an unknown concept is part of a concept class or not.
Concretely, the goal is to provide lower and upper bounds of complexity
measures for one problem type in terms of the other.
</summary>
    <author>
      <name>Sergiu Goschin</name>
    </author>
    <link href="http://arxiv.org/abs/1205.4349v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.4349v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.2190v1</id>
    <updated>2012-06-11T13:00:51Z</updated>
    <published>2012-06-11T13:00:51Z</published>
    <title>Communication-Efficient Parallel Belief Propagation for Latent Dirichlet
  Allocation</title>
    <summary>  This paper presents a novel communication-efficient parallel belief
propagation (CE-PBP) algorithm for training latent Dirichlet allocation (LDA).
Based on the synchronous belief propagation (BP) algorithm, we first develop a
parallel belief propagation (PBP) algorithm on the parallel architecture.
Because the extensive communication delay often causes a low efficiency of
parallel topic modeling, we further use Zipf's law to reduce the total
communication cost in PBP. Extensive experiments on different data sets
demonstrate that CE-PBP achieves a higher topic modeling accuracy and reduces
more than 80% communication cost than the state-of-the-art parallel Gibbs
sampling (PGS) algorithm.
</summary>
    <author>
      <name>Jian-feng Yan</name>
    </author>
    <author>
      <name>Zhi-Qiang Liu</name>
    </author>
    <author>
      <name>Yang Gao</name>
    </author>
    <author>
      <name>Jia Zeng</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.2190v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.2190v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.2691v1</id>
    <updated>2012-06-13T00:27:36Z</updated>
    <published>2012-06-13T00:27:36Z</published>
    <title>IDS: An Incremental Learning Algorithm for Finite Automata</title>
    <summary>  We present a new algorithm IDS for incremental learning of deterministic
finite automata (DFA). This algorithm is based on the concept of distinguishing
sequences introduced in (Angluin81). We give a rigorous proof that two versions
of this learning algorithm correctly learn in the limit. Finally we present an
empirical performance analysis that compares these two algorithms, focussing on
learning times and different types of learning queries. We conclude that IDS is
an efficient algorithm for software engineering applications of automata
learning, such as testing and model inference.
</summary>
    <author>
      <name>Muddassar A. Sindhu</name>
    </author>
    <author>
      <name>Karl Meinke</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.2691v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.2691v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.3072v1</id>
    <updated>2012-06-14T11:05:55Z</updated>
    <published>2012-06-14T11:05:55Z</published>
    <title>Statistical Consistency of Finite-dimensional Unregularized Linear
  Classification</title>
    <summary>  This manuscript studies statistical properties of linear classifiers obtained
through minimization of an unregularized convex risk over a finite sample.
Although the results are explicitly finite-dimensional, inputs may be passed
through feature maps; in this way, in addition to treating the consistency of
logistic regression, this analysis also handles boosting over a finite weak
learning class with, for instance, the exponential, logistic, and hinge losses.
In this finite-dimensional setting, it is still possible to fit arbitrary
decision boundaries: scaling the complexity of the weak learning class with the
sample size leads to the optimal classification risk almost surely.
</summary>
    <author>
      <name>Matus Telgarsky</name>
    </author>
    <link href="http://arxiv.org/abs/1206.3072v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.3072v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.3241v1</id>
    <updated>2012-06-13T15:04:13Z</updated>
    <published>2012-06-13T15:04:13Z</published>
    <title>Approximating the Partition Function by Deleting and then Correcting for
  Model Edges</title>
    <summary>  We propose an approach for approximating the partition function which is
based on two steps: (1) computing the partition function of a simplified model
which is obtained by deleting model edges, and (2) rectifying the result by
applying an edge-by-edge correction. The approach leads to an intuitive
framework in which one can trade-off the quality of an approximation with the
complexity of computing it. It also includes the Bethe free energy
approximation as a degenerate case. We develop the approach theoretically in
this paper and provide a number of empirical results that reveal its practical
utility.
</summary>
    <author>
      <name>Arthur Choi</name>
    </author>
    <author>
      <name>Adnan Darwiche</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty
  in Artificial Intelligence (UAI2008)</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.3241v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.3241v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.3242v1</id>
    <updated>2012-06-13T15:04:49Z</updated>
    <published>2012-06-13T15:04:49Z</published>
    <title>Multi-View Learning in the Presence of View Disagreement</title>
    <summary>  Traditional multi-view learning approaches suffer in the presence of view
disagreement,i.e., when samples in each view do not belong to the same class
due to view corruption, occlusion or other noise processes. In this paper we
present a multi-view learning approach that uses a conditional entropy
criterion to detect view disagreement. Once detected, samples with view
disagreement are filtered and standard multi-view learning methods can be
successfully applied to the remaining samples. Experimental evaluation on
synthetic and audio-visual databases demonstrates that the detection and
filtering of view disagreement considerably increases the performance of
traditional multi-view learning approaches.
</summary>
    <author>
      <name>C. Christoudias</name>
    </author>
    <author>
      <name>Raquel Urtasun</name>
    </author>
    <author>
      <name>Trevor Darrell</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty
  in Artificial Intelligence (UAI2008)</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.3242v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.3242v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.3247v1</id>
    <updated>2012-06-13T15:09:01Z</updated>
    <published>2012-06-13T15:09:01Z</published>
    <title>Learning Convex Inference of Marginals</title>
    <summary>  Graphical models trained using maximum likelihood are a common tool for
probabilistic inference of marginal distributions. However, this approach
suffers difficulties when either the inference process or the model is
approximate. In this paper, the inference process is first defined to be the
minimization of a convex function, inspired by free energy approximations.
Learning is then done directly in terms of the performance of the inference
process at univariate marginal prediction. The main novelty is that this is a
direct minimization of emperical risk, where the risk measures the accuracy of
predicted marginals.
</summary>
    <author>
      <name>Justin Domke</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty
  in Artificial Intelligence (UAI2008)</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.3247v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.3247v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.3270v1</id>
    <updated>2012-06-13T15:38:07Z</updated>
    <published>2012-06-13T15:38:07Z</published>
    <title>Estimation and Clustering with Infinite Rankings</title>
    <summary>  This paper presents a natural extension of stagewise ranking to the the case
of infinitely many items. We introduce the infinite generalized Mallows model
(IGM), describe its properties and give procedures to estimate it from data.
For estimation of multimodal distributions we introduce the
Exponential-Blurring-Mean-Shift nonparametric clustering algorithm. The
experiments highlight the properties of the new model and demonstrate that
infinite models can be simple, elegant and practical.
</summary>
    <author>
      <name>Marina Meila</name>
    </author>
    <author>
      <name>Le Bao</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty
  in Artificial Intelligence (UAI2008)</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.3270v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.3270v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.3275v1</id>
    <updated>2012-06-13T15:40:51Z</updated>
    <published>2012-06-13T15:40:51Z</published>
    <title>Learning Hidden Markov Models for Regression using Path Aggregation</title>
    <summary>  We consider the task of learning mappings from sequential data to real-valued
responses. We present and evaluate an approach to learning a type of hidden
Markov model (HMM) for regression. The learning process involves inferring the
structure and parameters of a conventional HMM, while simultaneously learning a
regression model that maps features that characterize paths through the model
to continuous responses. Our results, in both synthetic and biological domains,
demonstrate the value of jointly learning the two components of our approach.
</summary>
    <author>
      <name>Keith Noto</name>
    </author>
    <author>
      <name>Mark Craven</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty
  in Artificial Intelligence (UAI2008)</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.3275v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.3275v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.3721v1</id>
    <updated>2012-06-17T04:40:09Z</updated>
    <published>2012-06-17T04:40:09Z</published>
    <title>Constraint-free Graphical Model with Fast Learning Algorithm</title>
    <summary>  In this paper, we propose a simple, versatile model for learning the
structure and parameters of multivariate distributions from a data set.
Learning a Markov network from a given data set is not a simple problem,
because Markov networks rigorously represent Markov properties, and this rigor
imposes complex constraints on the design of the networks. Our proposed model
removes these constraints, acquiring important aspects from the information
geometry. The proposed parameter- and structure-learning algorithms are simple
to execute as they are based solely on local computation at each node.
Experiments demonstrate that our algorithms work appropriately.
</summary>
    <author>
      <name>Kazuya Takabatake</name>
    </author>
    <author>
      <name>Shotaro Akaho</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 11 figures, submitted to UAI2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.3721v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.3721v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.4110v1</id>
    <updated>2012-06-19T02:24:55Z</updated>
    <published>2012-06-19T02:24:55Z</published>
    <title>ConeRANK: Ranking as Learning Generalized Inequalities</title>
    <summary>  We propose a new data mining approach in ranking documents based on the
concept of cone-based generalized inequalities between vectors. A partial
ordering between two vectors is made with respect to a proper cone and thus
learning the preferences is formulated as learning proper cones. A pairwise
learning-to-rank algorithm (ConeRank) is proposed to learn a non-negative
subspace, formulated as a polyhedral cone, over document-pair differences. The
algorithm is regularized by controlling the `volume' of the cone. The
experimental studies on the latest and largest ranking dataset LETOR 4.0 shows
that ConeRank is competitive against other recent ranking approaches.
</summary>
    <author>
      <name>Truyen T. Tran</name>
    </author>
    <author>
      <name>Duc Son Pham</name>
    </author>
    <link href="http://arxiv.org/abs/1206.4110v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.4110v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.4606v1</id>
    <updated>2012-06-18T14:43:42Z</updated>
    <published>2012-06-18T14:43:42Z</published>
    <title>TrueLabel + Confusions: A Spectrum of Probabilistic Models in Analyzing
  Multiple Ratings</title>
    <summary>  This paper revisits the problem of analyzing multiple ratings given by
different judges. Different from previous work that focuses on distilling the
true labels from noisy crowdsourcing ratings, we emphasize gaining diagnostic
insights into our in-house well-trained judges. We generalize the well-known
DawidSkene model (Dawid &amp; Skene, 1979) to a spectrum of probabilistic models
under the same "TrueLabel + Confusion" paradigm, and show that our proposed
hierarchical Bayesian model, called HybridConfusion, consistently outperforms
DawidSkene on both synthetic and real-world data sets.
</summary>
    <author>
      <name>Chao Liu</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Tencent Inc.</arxiv:affiliation>
    </author>
    <author>
      <name>Yi-Min Wang</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Microsoft Research</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICML2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.4606v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.4606v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.4607v1</id>
    <updated>2012-06-18T14:44:09Z</updated>
    <published>2012-06-18T14:44:09Z</published>
    <title>Distributed Tree Kernels</title>
    <summary>  In this paper, we propose the distributed tree kernels (DTK) as a novel
method to reduce time and space complexity of tree kernels. Using a linear
complexity algorithm to compute vectors for trees, we embed feature spaces of
tree fragments in low-dimensional spaces where the kernel computation is
directly done with dot product. We show that DTKs are faster, correlate with
tree kernels, and obtain a statistically similar performance in two natural
language processing tasks.
</summary>
    <author>
      <name>Fabio Massimo Zanzotto</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Rome-Tor Vergata</arxiv:affiliation>
    </author>
    <author>
      <name>Lorenzo Dell'Arciprete</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Rome-Tor Vergata</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICML2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.4607v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.4607v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.4608v1</id>
    <updated>2012-06-18T14:44:28Z</updated>
    <published>2012-06-18T14:44:28Z</published>
    <title>A Hybrid Algorithm for Convex Semidefinite Optimization</title>
    <summary>  We present a hybrid algorithm for optimizing a convex, smooth function over
the cone of positive semidefinite matrices. Our algorithm converges to the
global optimal solution and can be used to solve general large-scale
semidefinite programs and hence can be readily applied to a variety of machine
learning problems. We show experimental results on three machine learning
problems (matrix completion, metric learning, and sparse PCA) . Our approach
outperforms state-of-the-art algorithms.
</summary>
    <author>
      <name>Soeren Laue</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Friedrich-Schiller-University</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICML2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.4608v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.4608v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.4617v1</id>
    <updated>2012-06-18T15:02:28Z</updated>
    <published>2012-06-18T15:02:28Z</published>
    <title>Continuous Inverse Optimal Control with Locally Optimal Examples</title>
    <summary>  Inverse optimal control, also known as inverse reinforcement learning, is the
problem of recovering an unknown reward function in a Markov decision process
from expert demonstrations of the optimal policy. We introduce a probabilistic
inverse optimal control algorithm that scales gracefully with task
dimensionality, and is suitable for large, continuous domains where even
computing a full policy is impractical. By using a local approximation of the
reward function, our method can also drop the assumption that the
demonstrations are globally optimal, requiring only local optimality. This
allows it to learn from examples that are unsuitable for prior methods.
</summary>
    <author>
      <name>Sergey Levine</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Stanford University</arxiv:affiliation>
    </author>
    <author>
      <name>Vladlen Koltun</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Stanford University</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICML2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.4617v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.4617v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.4620v1</id>
    <updated>2012-06-18T15:04:54Z</updated>
    <published>2012-06-18T15:04:54Z</published>
    <title>Improved Information Gain Estimates for Decision Tree Induction</title>
    <summary>  Ensembles of classification and regression trees remain popular machine
learning methods because they define flexible non-parametric models that
predict well and are computationally efficient both during training and
testing. During induction of decision trees one aims to find predicates that
are maximally informative about the prediction target. To select good
predicates most approaches estimate an information-theoretic scoring function,
the information gain, both for classification and regression problems. We point
out that the common estimation procedures are biased and show that by replacing
them with improved estimators of the discrete and the differential entropy we
can obtain better decision trees. In effect our modifications yield improved
predictive performance and are simple to implement in any decision tree code.
</summary>
    <author>
      <name>Sebastian Nowozin</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Microsoft Research Cambridge</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICML2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.4620v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.4620v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.4623v1</id>
    <updated>2012-06-18T15:06:34Z</updated>
    <published>2012-06-18T15:06:34Z</published>
    <title>On the Size of the Online Kernel Sparsification Dictionary</title>
    <summary>  We analyze the size of the dictionary constructed from online kernel
sparsification, using a novel formula that expresses the expected determinant
of the kernel Gram matrix in terms of the eigenvalues of the covariance
operator. Using this formula, we are able to connect the cardinality of the
dictionary with the eigen-decay of the covariance operator. In particular, we
show that under certain technical conditions, the size of the dictionary will
always grow sub-linearly in the number of data points, and, as a consequence,
the kernel linear regressor constructed from the resulting dictionary is
consistent.
</summary>
    <author>
      <name>Yi Sun</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IDSIA</arxiv:affiliation>
    </author>
    <author>
      <name>Faustino Gomez</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IDSIA,</arxiv:affiliation>
    </author>
    <author>
      <name>Juergen Schmidhuber</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IDSIA</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICML2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.4623v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.4623v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.4628v1</id>
    <updated>2012-06-18T15:07:55Z</updated>
    <published>2012-06-18T15:07:55Z</published>
    <title>Robust PCA in High-dimension: A Deterministic Approach</title>
    <summary>  We consider principal component analysis for contaminated data-set in the
high dimensional regime, where the dimensionality of each observation is
comparable or even more than the number of observations. We propose a
deterministic high-dimensional robust PCA algorithm which inherits all
theoretical properties of its randomized counterpart, i.e., it is tractable,
robust to contaminated points, easily kernelizable, asymptotic consistent and
achieves maximal robustness -- a breakdown point of 50%. More importantly, the
proposed method exhibits significantly better computational efficiency, which
makes it suitable for large-scale real applications.
</summary>
    <author>
      <name>Jiashi Feng</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">NUS</arxiv:affiliation>
    </author>
    <author>
      <name>Huan Xu</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">NUS</arxiv:affiliation>
    </author>
    <author>
      <name>Shuicheng Yan</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">NUS</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICML2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.4628v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.4628v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.4630v1</id>
    <updated>2012-06-18T15:08:38Z</updated>
    <published>2012-06-18T15:08:38Z</published>
    <title>Efficient Decomposed Learning for Structured Prediction</title>
    <summary>  Structured prediction is the cornerstone of several machine learning
applications. Unfortunately, in structured prediction settings with expressive
inter-variable interactions, exact inference-based learning algorithms, e.g.
Structural SVM, are often intractable. We present a new way, Decomposed
Learning (DecL), which performs efficient learning by restricting the inference
step to a limited part of the structured spaces. We provide characterizations
based on the structure, target parameters, and gold labels, under which DecL is
equivalent to exact learning. We then show that in real world settings, where
our theoretical assumptions may not completely hold, DecL-based algorithms are
significantly more efficient and as accurate as exact learning.
</summary>
    <author>
      <name>Rajhans Samdani</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Illinois, U-C</arxiv:affiliation>
    </author>
    <author>
      <name>Dan Roth</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Illinois, U-C</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICML2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.4630v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.4630v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.4634v1</id>
    <updated>2012-06-18T15:14:24Z</updated>
    <published>2012-06-18T15:14:24Z</published>
    <title>Artist Agent: A Reinforcement Learning Approach to Automatic Stroke
  Generation in Oriental Ink Painting</title>
    <summary>  Oriental ink painting, called Sumi-e, is one of the most appealing painting
styles that has attracted artists around the world. Major challenges in
computer-based Sumi-e simulation are to abstract complex scene information and
draw smooth and natural brush strokes. To automatically find such strokes, we
propose to model the brush as a reinforcement learning agent, and learn desired
brush-trajectories by maximizing the sum of rewards in the policy search
framework. We also provide elaborate design of actions, states, and rewards
tailored for a Sumi-e agent. The effectiveness of our proposed approach is
demonstrated through simulated Sumi-e experiments.
</summary>
    <author>
      <name>Ning Xie</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Tokyo Institute of Technology</arxiv:affiliation>
    </author>
    <author>
      <name>Hirotaka Hachiya</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Tokyo Institute of Technology</arxiv:affiliation>
    </author>
    <author>
      <name>Masashi Sugiyama</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Tokyo Institute of Technology</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1587/transinf.E96.D.1134</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1587/transinf.E96.D.1134" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICML2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.4634v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.4634v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.4643v1</id>
    <updated>2012-06-18T15:19:07Z</updated>
    <published>2012-06-18T15:19:07Z</published>
    <title>Lightning Does Not Strike Twice: Robust MDPs with Coupled Uncertainty</title>
    <summary>  We consider Markov decision processes under parameter uncertainty. Previous
studies all restrict to the case that uncertainties among different states are
uncoupled, which leads to conservative solutions. In contrast, we introduce an
intuitive concept, termed "Lightning Does not Strike Twice," to model coupled
uncertain parameters. Specifically, we require that the system can deviate from
its nominal parameters only a bounded number of times. We give probabilistic
guarantees indicating that this model represents real life situations and
devise tractable algorithms for computing optimal control policies using this
concept.
</summary>
    <author>
      <name>Shie Mannor</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Technion</arxiv:affiliation>
    </author>
    <author>
      <name>Ofir Mebel</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Technion</arxiv:affiliation>
    </author>
    <author>
      <name>Huan Xu</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">National University of Singapore</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICML2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.4643v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.4643v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.4645v1</id>
    <updated>2012-06-18T15:19:58Z</updated>
    <published>2012-06-18T15:19:58Z</published>
    <title>Ensemble Methods for Convex Regression with Applications to Geometric
  Programming Based Circuit Design</title>
    <summary>  Convex regression is a promising area for bridging statistical estimation and
deterministic convex optimization. New piecewise linear convex regression
methods are fast and scalable, but can have instability when used to
approximate constraints or objective functions for optimization. Ensemble
methods, like bagging, smearing and random partitioning, can alleviate this
problem and maintain the theoretical properties of the underlying estimator. We
empirically examine the performance of ensemble methods for prediction and
optimization, and then apply them to device modeling and constraint
approximation for geometric programming based circuit design.
</summary>
    <author>
      <name>Lauren Hannah</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Duke University</arxiv:affiliation>
    </author>
    <author>
      <name>David Dunson</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Duke University</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICML2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.4645v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.4645v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.4646v1</id>
    <updated>2012-06-18T15:20:14Z</updated>
    <published>2012-06-18T15:20:14Z</published>
    <title>Partial-Hessian Strategies for Fast Learning of Nonlinear Embeddings</title>
    <summary>  Stochastic neighbor embedding (SNE) and related nonlinear manifold learning
algorithms achieve high-quality low-dimensional representations of similarity
data, but are notoriously slow to train. We propose a generic formulation of
embedding algorithms that includes SNE and other existing algorithms, and study
their relation with spectral methods and graph Laplacians. This allows us to
define several partial-Hessian optimization strategies, characterize their
global and local convergence, and evaluate them empirically. We achieve up to
two orders of magnitude speedup over existing training methods with a strategy
(which we call the spectral direction) that adds nearly no overhead to the
gradient and yet is simple, scalable and applicable to several existing and
future embedding algorithms.
</summary>
    <author>
      <name>Max Vladymyrov</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">UC Merced</arxiv:affiliation>
    </author>
    <author>
      <name>Miguel Carreira-Perpinan</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">UC Merced</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICML2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.4646v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.4646v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.4647v1</id>
    <updated>2012-06-18T15:22:24Z</updated>
    <published>2012-06-18T15:22:24Z</published>
    <title>Active Learning for Matching Problems</title>
    <summary>  Effective learning of user preferences is critical to easing user burden in
various types of matching problems. Equally important is active query selection
to further reduce the amount of preference information users must provide. We
address the problem of active learning of user preferences for matching
problems, introducing a novel method for determining probabilistic matchings,
and developing several new active learning strategies that are sensitive to the
specific matching objective. Experiments with real-world data sets spanning
diverse domains demonstrate that matching-sensitive active learning
</summary>
    <author>
      <name>Laurent Charlin</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Toronto</arxiv:affiliation>
    </author>
    <author>
      <name>Rich Zemel</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Toronto</arxiv:affiliation>
    </author>
    <author>
      <name>Craig Boutilier</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Toronto</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICML2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.4647v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.4647v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.4650v1</id>
    <updated>2012-06-18T15:23:37Z</updated>
    <published>2012-06-18T15:23:37Z</published>
    <title>Analysis of Kernel Mean Matching under Covariate Shift</title>
    <summary>  In real supervised learning scenarios, it is not uncommon that the training
and test sample follow different probability distributions, thus rendering the
necessity to correct the sampling bias. Focusing on a particular covariate
shift problem, we derive high probability confidence bounds for the kernel mean
matching (KMM) estimator, whose convergence rate turns out to depend on some
regularity measure of the regression function and also on some capacity measure
of the kernel. By comparing KMM with the natural plug-in estimator, we
establish the superiority of the former hence provide concrete
evidence/understanding to the effectiveness of KMM under covariate shift.
</summary>
    <author>
      <name>Yaoliang Yu</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Alberta</arxiv:affiliation>
    </author>
    <author>
      <name>Csaba Szepesvari</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Alberta</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICML2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.4650v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.4650v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.4651v1</id>
    <updated>2012-06-18T15:24:01Z</updated>
    <published>2012-06-18T15:24:01Z</published>
    <title>Is margin preserved after random projection?</title>
    <summary>  Random projections have been applied in many machine learning algorithms.
However, whether margin is preserved after random projection is non-trivial and
not well studied. In this paper we analyse margin distortion after random
projection, and give the conditions of margin preservation for binary
classification problems. We also extend our analysis to margin for multiclass
problems, and provide theoretical bounds on multiclass margin on the projected
data.
</summary>
    <author>
      <name>Qinfeng Shi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">The University of Adelaide</arxiv:affiliation>
    </author>
    <author>
      <name>Chunhua Shen</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">The University of Adelaide</arxiv:affiliation>
    </author>
    <author>
      <name>Rhys Hill</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">The University of Adelaide</arxiv:affiliation>
    </author>
    <author>
      <name>Anton van den Hengel</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">the University of Adelaide</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICML2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.4651v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.4651v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.4656v1</id>
    <updated>2012-06-18T15:26:13Z</updated>
    <published>2012-06-18T15:26:13Z</published>
    <title>Machine Learning that Matters</title>
    <summary>  Much of current machine learning (ML) research has lost its connection to
problems of import to the larger world of science and society. From this
perspective, there exist glaring limitations in the data sets we investigate,
the metrics we employ for evaluation, and the degree to which results are
communicated back to their originating domains. What changes are needed to how
we conduct research to increase the impact that ML has? We present six Impact
Challenges to explicitly focus the field?s energy and attention, and we discuss
existing obstacles that must be addressed. We aim to inspire ongoing discussion
and focus on ML that matters.
</summary>
    <author>
      <name>Kiri Wagstaff</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Jet Propulsion Laboratory</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICML2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.4656v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.4656v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.4657v1</id>
    <updated>2012-06-18T15:26:34Z</updated>
    <published>2012-06-18T15:26:34Z</published>
    <title>Projection-free Online Learning</title>
    <summary>  The computational bottleneck in applying online learning to massive data sets
is usually the projection step. We present efficient online learning algorithms
that eschew projections in favor of much more efficient linear optimization
steps using the Frank-Wolfe technique. We obtain a range of regret bounds for
online convex optimization, with better bounds for specific cases such as
stochastic online smooth convex optimization.
  Besides the computational advantage, other desirable features of our
algorithms are that they are parameter-free in the stochastic case and produce
sparse decisions. We apply our algorithms to computationally intensive
applications of collaborative filtering, and show the theoretical improvements
to be clearly visible on standard datasets.
</summary>
    <author>
      <name>Elad Hazan</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Technion</arxiv:affiliation>
    </author>
    <author>
      <name>Satyen Kale</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IBM T.J. Watson Research Center</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICML2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.4657v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.4657v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.4659v1</id>
    <updated>2012-06-18T15:27:56Z</updated>
    <published>2012-06-18T15:27:56Z</published>
    <title>Max-Margin Nonparametric Latent Feature Models for Link Prediction</title>
    <summary>  We present a max-margin nonparametric latent feature model, which unites the
ideas of max-margin learning and Bayesian nonparametrics to discover
discriminative latent features for link prediction and automatically infer the
unknown latent social dimension. By minimizing a hinge-loss using the linear
expectation operator, we can perform posterior inference efficiently without
dealing with a highly nonlinear link likelihood function; by using a
fully-Bayesian formulation, we can avoid tuning regularization constants.
Experimental results on real datasets appear to demonstrate the benefits
inherited from max-margin learning and fully-Bayesian nonparametric inference.
</summary>
    <author>
      <name>Jun Zhu</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Tsinghua University</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICML2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.4659v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.4659v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.4661v1</id>
    <updated>2012-06-18T15:30:13Z</updated>
    <published>2012-06-18T15:30:13Z</published>
    <title>Predicting accurate probabilities with a ranking loss</title>
    <summary>  In many real-world applications of machine learning classifiers, it is
essential to predict the probability of an example belonging to a particular
class. This paper proposes a simple technique for predicting probabilities
based on optimizing a ranking loss, followed by isotonic regression. This
semi-parametric technique offers both good ranking and regression performance,
and models a richer set of probability distributions than statistical
workhorses such as logistic regression. We provide experimental results that
show the effectiveness of this technique on real-world applications of
probability prediction.
</summary>
    <author>
      <name>Aditya Menon</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">UC San Diego</arxiv:affiliation>
    </author>
    <author>
      <name>Xiaoqian Jiang</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">UC San Diego</arxiv:affiliation>
    </author>
    <author>
      <name>Shankar Vembu</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Toronto</arxiv:affiliation>
    </author>
    <author>
      <name>Charles Elkan</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">UC San Diego</arxiv:affiliation>
    </author>
    <author>
      <name>Lucila Ohno-Machado</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">UC San Diego</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICML2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.4661v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.4661v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.4663v1</id>
    <updated>2012-06-18T15:30:52Z</updated>
    <published>2012-06-18T15:30:52Z</published>
    <title>The Convexity and Design of Composite Multiclass Losses</title>
    <summary>  We consider composite loss functions for multiclass prediction comprising a
proper (i.e., Fisher-consistent) loss over probability distributions and an
inverse link function. We establish conditions for their (strong) convexity and
explore the implications. We also show how the separation of concerns afforded
by using this composite representation allows for the design of families of
losses with the same Bayes risk.
</summary>
    <author>
      <name>Mark Reid</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">The Australian National University and NICTA</arxiv:affiliation>
    </author>
    <author>
      <name>Robert Williamson</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">The Australian National University and NICTA</arxiv:affiliation>
    </author>
    <author>
      <name>Peng Sun</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Tsinghua University</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICML2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.4663v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.4663v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.4664v1</id>
    <updated>2012-06-18T15:31:13Z</updated>
    <published>2012-06-18T15:31:13Z</published>
    <title>Tighter Variational Representations of f-Divergences via Restriction to
  Probability Measures</title>
    <summary>  We show that the variational representations for f-divergences currently used
in the literature can be tightened. This has implications to a number of
methods recently proposed based on this representation. As an example
application we use our tighter representation to derive a general f-divergence
estimator based on two i.i.d. samples and derive the dual program for this
estimator that performs well empirically. We also point out a connection
between our estimator and MMD.
</summary>
    <author>
      <name>Avraham Ruderman</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Australian National University and NICTA</arxiv:affiliation>
    </author>
    <author>
      <name>Mark Reid</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Australian National University and NICTA</arxiv:affiliation>
    </author>
    <author>
      <name>Dario Garcia-Garcia</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Australian National University and NICTA</arxiv:affiliation>
    </author>
    <author>
      <name>James Petterson</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">NICTA</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICML2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.4664v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.4664v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.4671v1</id>
    <updated>2012-06-18T15:35:02Z</updated>
    <published>2012-06-18T15:35:02Z</published>
    <title>Dependent Hierarchical Normalized Random Measures for Dynamic Topic
  Modeling</title>
    <summary>  We develop dependent hierarchical normalized random measures and apply them
to dynamic topic modeling. The dependency arises via superposition, subsampling
and point transition on the underlying Poisson processes of these measures. The
measures used include normalised generalised Gamma processes that demonstrate
power law properties, unlike Dirichlet processes used previously in dynamic
topic modeling. Inference for the model includes adapting a recently developed
slice sampler to directly manipulate the underlying Poisson process.
Experiments performed on news, blogs, academic and Twitter collections
demonstrate the technique gives superior perplexity over a number of previous
models.
</summary>
    <author>
      <name>Changyou Chen</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">ANU &amp; NICTA</arxiv:affiliation>
    </author>
    <author>
      <name>Nan Ding</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Purdue University</arxiv:affiliation>
    </author>
    <author>
      <name>Wray Buntine</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">NICTA</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICML2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.4671v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.4671v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.4674v1</id>
    <updated>2012-06-18T15:36:16Z</updated>
    <published>2012-06-18T15:36:16Z</published>
    <title>Comparison-Based Learning with Rank Nets</title>
    <summary>  We consider the problem of search through comparisons, where a user is
presented with two candidate objects and reveals which is closer to her
intended target. We study adaptive strategies for finding the target, that
require knowledge of rank relationships but not actual distances between
objects. We propose a new strategy based on rank nets, and show that for target
distributions with a bounded doubling constant, it finds the target in a number
of comparisons close to the entropy of the target distribution and, hence, of
the optimum. We extend these results to the case of noisy oracles, and compare
this strategy to prior art over multiple datasets.
</summary>
    <author>
      <name>Amin Karbasi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">EPFL</arxiv:affiliation>
    </author>
    <author>
      <name>Stratis Ioannidis</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Technicolor</arxiv:affiliation>
    </author>
    <author>
      <name>laurent Massoulie</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Technicolor</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICML2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.4674v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.4674v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.4677v1</id>
    <updated>2012-06-18T15:37:07Z</updated>
    <published>2012-06-18T15:37:07Z</published>
    <title>Semi-Supervised Learning of Class Balance under Class-Prior Change by
  Distribution Matching</title>
    <summary>  In real-world classification problems, the class balance in the training
dataset does not necessarily reflect that of the test dataset, which can cause
significant estimation bias. If the class ratio of the test dataset is known,
instance re-weighting or resampling allows systematical bias correction.
However, learning the class ratio of the test dataset is challenging when no
labeled data is available from the test domain. In this paper, we propose to
estimate the class ratio in the test dataset by matching probability
distributions of training and test input data. We demonstrate the utility of
the proposed approach through experiments.
</summary>
    <author>
      <name>Marthinus Du Plessis</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Tokyo Institute of Technology</arxiv:affiliation>
    </author>
    <author>
      <name>Masashi Sugiyama</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Tokyo Institute of Technology</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICML2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.4677v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.4677v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.4678v1</id>
    <updated>2012-06-18T15:37:23Z</updated>
    <published>2012-06-18T15:37:23Z</published>
    <title>Linear Regression with Limited Observation</title>
    <summary>  We consider the most common variants of linear regression, including Ridge,
Lasso and Support-vector regression, in a setting where the learner is allowed
to observe only a fixed number of attributes of each example at training time.
We present simple and efficient algorithms for these problems: for Lasso and
Ridge regression they need the same total number of attributes (up to
constants) as do full-information algorithms, for reaching a certain accuracy.
For Support-vector regression, we require exponentially less attributes
compared to the state of the art. By that, we resolve an open problem recently
posed by Cesa-Bianchi et al. (2010). Experiments show the theoretical bounds to
be justified by superior performance compared to the state of the art.
</summary>
    <author>
      <name>Elad Hazan</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Technion</arxiv:affiliation>
    </author>
    <author>
      <name>Tomer Koren</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Technion</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICML2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.4678v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.4678v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.4681v1</id>
    <updated>2012-06-18T15:40:11Z</updated>
    <published>2012-06-18T15:40:11Z</published>
    <title>LPQP for MAP: Putting LP Solvers to Better Use</title>
    <summary>  MAP inference for general energy functions remains a challenging problem.
While most efforts are channeled towards improving the linear programming (LP)
based relaxation, this work is motivated by the quadratic programming (QP)
relaxation. We propose a novel MAP relaxation that penalizes the
Kullback-Leibler divergence between the LP pairwise auxiliary variables, and QP
equivalent terms given by the product of the unaries. We develop two efficient
algorithms based on variants of this relaxation. The algorithms minimize the
non-convex objective using belief propagation and dual decomposition as
building blocks. Experiments on synthetic and real-world data show that the
solutions returned by our algorithms substantially improve over the LP
relaxation.
</summary>
    <author>
      <name>Patrick Pletscher</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">ETH Zurich</arxiv:affiliation>
    </author>
    <author>
      <name>Sharon Wulff</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">ETH Zurich</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICML2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.4681v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.4681v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.5162v2</id>
    <updated>2012-12-04T19:35:34Z</updated>
    <published>2012-06-22T14:36:15Z</published>
    <title>Fast Variational Inference in the Conjugate Exponential Family</title>
    <summary>  We present a general method for deriving collapsed variational inference
algo- rithms for probabilistic models in the conjugate exponential family. Our
method unifies many existing approaches to collapsed variational inference. Our
collapsed variational inference leads to a new lower bound on the marginal
likelihood. We exploit the information geometry of the bound to derive much
faster optimization methods based on conjugate gradients for these models. Our
approach is very general and is easily applied to any model where the mean
field update equations have been derived. Empirically we show significant
speed-ups for probabilistic models optimized using our bound.
</summary>
    <author>
      <name>James Hensman</name>
    </author>
    <author>
      <name>Magnus Rattray</name>
    </author>
    <author>
      <name>Neil D. Lawrence</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at NIPS 2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.5162v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.5162v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.5248v1</id>
    <updated>2012-06-20T14:55:04Z</updated>
    <published>2012-06-20T14:55:04Z</published>
    <title>Statistical Translation, Heat Kernels and Expected Distances</title>
    <summary>  High dimensional structured data such as text and images is often poorly
understood and misrepresented in statistical modeling. The standard histogram
representation suffers from high variance and performs poorly in general. We
explore novel connections between statistical translation, heat kernels on
manifolds and graphs, and expected distances. These connections provide a new
framework for unsupervised metric learning for text documents. Experiments
indicate that the resulting distances are generally superior to their more
standard counterparts.
</summary>
    <author>
      <name>Joshua Dillon</name>
    </author>
    <author>
      <name>Yi Mao</name>
    </author>
    <author>
      <name>Guy Lebanon</name>
    </author>
    <author>
      <name>Jian Zhang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the Twenty-Third Conference on Uncertainty
  in Artificial Intelligence (UAI2007)</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.5248v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.5248v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.5274v1</id>
    <updated>2012-06-20T15:06:08Z</updated>
    <published>2012-06-20T15:06:08Z</published>
    <title>On Discarding, Caching, and Recalling Samples in Active Learning</title>
    <summary>  We address challenges of active learning under scarce informational resources
in non-stationary environments. In real-world settings, data labeled and
integrated into a predictive model may become invalid over time. However, the
data can become informative again with switches in context and such changes may
indicate unmodeled cyclic or other temporal dynamics. We explore principles for
discarding, caching, and recalling labeled data points in active learning based
on computations of value of information. We review key concepts and study the
value of the methods via investigations of predictive performance and costs of
acquiring data for simulated and real-world data sets.
</summary>
    <author>
      <name>Ashish Kapoor</name>
    </author>
    <author>
      <name>Eric J. Horvitz</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the Twenty-Third Conference on Uncertainty
  in Artificial Intelligence (UAI2007)</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.5274v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.5274v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.5533v2</id>
    <updated>2012-09-16T17:49:12Z</updated>
    <published>2012-06-24T19:17:35Z</published>
    <title>Practical recommendations for gradient-based training of deep
  architectures</title>
    <summary>  Learning algorithms related to artificial neural networks and in particular
for Deep Learning may seem to involve many bells and whistles, called
hyper-parameters. This chapter is meant as a practical guide with
recommendations for some of the most commonly used hyper-parameters, in
particular in the context of learning algorithms based on back-propagated
gradient and gradient-based optimization. It also discusses how to deal with
the fact that more interesting results can be obtained when allowing one to
adjust many hyper-parameters. Overall, it describes elements of the practice
used to successfully and efficiently train and debug large-scale and often deep
multi-layer neural networks. It closes with open questions about the training
difficulties observed with deeper architectures.
</summary>
    <author>
      <name>Yoshua Bengio</name>
    </author>
    <link href="http://arxiv.org/abs/1206.5533v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.5533v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.5766v4</id>
    <updated>2012-10-28T07:03:15Z</updated>
    <published>2012-06-25T18:49:44Z</published>
    <title>Learning mixtures of spherical Gaussians: moment methods and spectral
  decompositions</title>
    <summary>  This work provides a computationally efficient and statistically consistent
moment-based estimator for mixtures of spherical Gaussians. Under the condition
that component means are in general position, a simple spectral decomposition
technique yields consistent parameter estimates from low-order observable
moments, without additional minimum separation assumptions needed by previous
computationally efficient estimation procedures. Thus computational and
information-theoretic barriers to efficient estimation in mixture models are
precluded when the mixture components have means in general position and
spherical covariances. Some connections are made to estimation problems related
to independent component analysis.
</summary>
    <author>
      <name>Daniel Hsu</name>
    </author>
    <author>
      <name>Sham M. Kakade</name>
    </author>
    <link href="http://arxiv.org/abs/1206.5766v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.5766v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.5882v1</id>
    <updated>2012-06-26T05:10:36Z</updated>
    <published>2012-06-26T05:10:36Z</published>
    <title>Exact Recovery of Sparsely-Used Dictionaries</title>
    <summary>  We consider the problem of learning sparsely used dictionaries with an
arbitrary square dictionary and a random, sparse coefficient matrix. We prove
that $O (n \log n)$ samples are sufficient to uniquely determine the
coefficient matrix. Based on this proof, we design a polynomial-time algorithm,
called Exact Recovery of Sparsely-Used Dictionaries (ER-SpUD), and prove that
it probably recovers the dictionary and coefficient matrix when the coefficient
matrix is sufficiently sparse. Simulation results show that ER-SpUD reveals the
true dictionary as well as the coefficients with probability higher than many
state-of-the-art algorithms.
</summary>
    <author>
      <name>Daniel A. Spielman</name>
    </author>
    <author>
      <name>Huan Wang</name>
    </author>
    <author>
      <name>John Wright</name>
    </author>
    <link href="http://arxiv.org/abs/1206.5882v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.5882v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.6015v1</id>
    <updated>2012-06-26T14:56:33Z</updated>
    <published>2012-06-26T14:56:33Z</published>
    <title>Transductive Classification Methods for Mixed Graphs</title>
    <summary>  In this paper we provide a principled approach to solve a transductive
classification problem involving a similar graph (edges tend to connect nodes
with same labels) and a dissimilar graph (edges tend to connect nodes with
opposing labels). Most of the existing methods, e.g., Information
Regularization (IR), Weighted vote Relational Neighbor classifier (WvRN) etc,
assume that the given graph is only a similar graph. We extend the IR and WvRN
methods to deal with mixed graphs. We evaluate the proposed extensions on
several benchmark datasets as well as two real world datasets and demonstrate
the usefulness of our ideas.
</summary>
    <author>
      <name>Sundararajan Sellamanickam</name>
    </author>
    <author>
      <name>Sathiya Keerthi Selvaraj</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 Pages, 2 Tables, 2 Figures, KDD Workshop - MLG'11 San Diego, CA,
  USA</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.6015v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.6015v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.6141v1</id>
    <updated>2012-06-26T23:39:00Z</updated>
    <published>2012-06-26T23:39:00Z</published>
    <title>Directed Time Series Regression for Control</title>
    <summary>  We propose directed time series regression, a new approach to estimating
parameters of time-series models for use in certainty equivalent model
predictive control. The approach combines merits of least squares regression
and empirical optimization. Through a computational study involving a
stochastic version of a well known inverted pendulum balancing problem, we
demonstrate that directed time series regression can generate significant
improvements in controller performance over either of the aforementioned
alternatives.
</summary>
    <author>
      <name>Yi-Hao Kao</name>
    </author>
    <author>
      <name>Benjamin Van Roy</name>
    </author>
    <link href="http://arxiv.org/abs/1206.6141v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.6141v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.6381v2</id>
    <updated>2012-07-09T08:36:42Z</updated>
    <published>2012-06-27T19:59:59Z</published>
    <title>Shortest path distance in random k-nearest neighbor graphs</title>
    <summary>  Consider a weighted or unweighted k-nearest neighbor graph that has been
built on n data points drawn randomly according to some density p on R^d. We
study the convergence of the shortest path distance in such graphs as the
sample size tends to infinity. We prove that for unweighted kNN graphs, this
distance converges to an unpleasant distance function on the underlying space
whose properties are detrimental to machine learning. We also study the
behavior of the shortest path distance in weighted kNN graphs.
</summary>
    <author>
      <name>Morteza Alamgir</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Max Planck Institute for Intelligent Systems</arxiv:affiliation>
    </author>
    <author>
      <name>Ulrike von Luxburg</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Max Planck Institute for Intelligent Systems and University of Hamburg</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.6381v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.6381v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.6383v1</id>
    <updated>2012-06-27T19:59:59Z</updated>
    <published>2012-06-27T19:59:59Z</published>
    <title>Feature Selection via Probabilistic Outputs</title>
    <summary>  This paper investigates two feature-scoring criteria that make use of
estimated class probabilities: one method proposed by \citet{shen} and a
complementary approach proposed below. We develop a theoretical framework to
analyze each criterion and show that both estimate the spread (across all
values of a given feature) of the probability that an example belongs to the
positive class. Based on our analysis, we predict when each scoring technique
will be advantageous over the other and give empirical results validating our
predictions.
</summary>
    <author>
      <name>Andrea Danyluk</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Williams College</arxiv:affiliation>
    </author>
    <author>
      <name>Nicholas Arnosti</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Stanford University</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.6383v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.6383v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.6392v1</id>
    <updated>2012-06-27T19:59:59Z</updated>
    <published>2012-06-27T19:59:59Z</published>
    <title>Modeling Temporal Dependencies in High-Dimensional Sequences:
  Application to Polyphonic Music Generation and Transcription</title>
    <summary>  We investigate the problem of modeling symbolic sequences of polyphonic music
in a completely general piano-roll representation. We introduce a probabilistic
model based on distribution estimators conditioned on a recurrent neural
network that is able to discover temporal dependencies in high-dimensional
sequences. Our approach outperforms many traditional models of polyphonic music
on a variety of realistic datasets. We show how our musical language model can
serve as a symbolic prior to improve the accuracy of polyphonic transcription.
</summary>
    <author>
      <name>Nicolas Boulanger-Lewandowski</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Universite de Montreal</arxiv:affiliation>
    </author>
    <author>
      <name>Yoshua Bengio</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Universite de Montreal</arxiv:affiliation>
    </author>
    <author>
      <name>Pascal Vincent</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Universite de Montreal</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.6392v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.6392v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.6405v1</id>
    <updated>2012-06-27T19:59:59Z</updated>
    <published>2012-06-27T19:59:59Z</published>
    <title>Bounded Planning in Passive POMDPs</title>
    <summary>  In Passive POMDPs actions do not affect the world state, but still incur
costs. When the agent is bounded by information-processing constraints, it can
only keep an approximation of the belief. We present a variational principle
for the problem of maintaining the information which is most useful for
minimizing the cost, and introduce an efficient and simple algorithm for
finding an optimum.
</summary>
    <author>
      <name>Roy Fox</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Hebrew University</arxiv:affiliation>
    </author>
    <author>
      <name>Naftali Tishby</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Hebrew University</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.6405v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.6405v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.6409v1</id>
    <updated>2012-06-27T19:59:59Z</updated>
    <published>2012-06-27T19:59:59Z</published>
    <title>Scaling Up Coordinate Descent Algorithms for Large $\ell_1$
  Regularization Problems</title>
    <summary>  We present a generic framework for parallel coordinate descent (CD)
algorithms that includes, as special cases, the original sequential algorithms
Cyclic CD and Stochastic CD, as well as the recent parallel Shotgun algorithm.
We introduce two novel parallel algorithms that are also special
cases---Thread-Greedy CD and Coloring-Based CD---and give performance
measurements for an OpenMP implementation of these.
</summary>
    <author>
      <name>Chad Scherrer</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Pacific Northwest National Lab</arxiv:affiliation>
    </author>
    <author>
      <name>Mahantesh Halappanavar</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Pacific Northwest National Lab</arxiv:affiliation>
    </author>
    <author>
      <name>Ambuj Tewari</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Texas</arxiv:affiliation>
    </author>
    <author>
      <name>David Haglin</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Pacific Northwest National Lab</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.6409v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.6409v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.6410v1</id>
    <updated>2012-06-27T19:59:59Z</updated>
    <published>2012-06-27T19:59:59Z</published>
    <title>On the Partition Function and Random Maximum A-Posteriori Perturbations</title>
    <summary>  In this paper we relate the partition function to the max-statistics of
random variables. In particular, we provide a novel framework for approximating
and bounding the partition function using MAP inference on randomly perturbed
models. As a result, we can use efficient MAP solvers such as graph-cuts to
evaluate the corresponding partition function. We show that our method excels
in the typical "high signal - high coupling" regime that results in ragged
energy landscapes difficult for alternative approaches.
</summary>
    <author>
      <name>Tamir Hazan</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">TTIC</arxiv:affiliation>
    </author>
    <author>
      <name>Tommi Jaakkola</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">MIT</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.6410v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.6410v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.6412v1</id>
    <updated>2012-06-27T19:59:59Z</updated>
    <published>2012-06-27T19:59:59Z</published>
    <title>A Simple Algorithm for Semi-supervised Learning with Improved
  Generalization Error Bound</title>
    <summary>  In this work, we develop a simple algorithm for semi-supervised regression.
The key idea is to use the top eigenfunctions of integral operator derived from
both labeled and unlabeled examples as the basis functions and learn the
prediction function by a simple linear regression. We show that under
appropriate assumptions about the integral operator, this approach is able to
achieve an improved regression error bound better than existing bounds of
supervised learning. We also verify the effectiveness of the proposed algorithm
by an empirical study.
</summary>
    <author>
      <name>Ming Ji</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">UIUC</arxiv:affiliation>
    </author>
    <author>
      <name>Tianbao Yang</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Michigan State University</arxiv:affiliation>
    </author>
    <author>
      <name>Binbin Lin</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Zhejiang University</arxiv:affiliation>
    </author>
    <author>
      <name>Rong Jin</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Michigan State University</arxiv:affiliation>
    </author>
    <author>
      <name>Jiawei Han</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">UIUC</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.6412v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.6412v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.6413v1</id>
    <updated>2012-06-27T19:59:59Z</updated>
    <published>2012-06-27T19:59:59Z</published>
    <title>A Convex Relaxation for Weakly Supervised Classifiers</title>
    <summary>  This paper introduces a general multi-class approach to weakly supervised
classification. Inferring the labels and learning the parameters of the model
is usually done jointly through a block-coordinate descent algorithm such as
expectation-maximization (EM), which may lead to local minima. To avoid this
problem, we propose a cost function based on a convex relaxation of the
soft-max loss. We then propose an algorithm specifically designed to
efficiently solve the corresponding semidefinite program (SDP). Empirically,
our method compares favorably to standard ones on different datasets for
multiple instance learning and semi-supervised learning as well as on
clustering tasks.
</summary>
    <author>
      <name>Armand Joulin</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA - Ecole Normale Superieure</arxiv:affiliation>
    </author>
    <author>
      <name>Francis Bach</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA - Ecole Normale Superieure</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.6413v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.6413v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.6420v1</id>
    <updated>2012-06-27T19:59:59Z</updated>
    <published>2012-06-27T19:59:59Z</published>
    <title>Distributed Parameter Estimation via Pseudo-likelihood</title>
    <summary>  Estimating statistical models within sensor networks requires distributed
algorithms, in which both data and computation are distributed across the nodes
of the network. We propose a general approach for distributed learning based on
combining local estimators defined by pseudo-likelihood components,
encompassing a number of combination methods, and provide both theoretical and
experimental analysis. We show that simple linear combination or max-voting
methods, when combined with second-order information, are statistically
competitive with more advanced and costly joint optimization. Our algorithms
have many attractive properties including low communication and computational
cost and "any-time" behavior.
</summary>
    <author>
      <name>Qiang Liu</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">UC Irvine</arxiv:affiliation>
    </author>
    <author>
      <name>Alexander Ihler</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">UC Irvine</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.6420v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.6420v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.6425v1</id>
    <updated>2012-06-27T19:59:59Z</updated>
    <published>2012-06-27T19:59:59Z</published>
    <title>Sparse Stochastic Inference for Latent Dirichlet allocation</title>
    <summary>  We present a hybrid algorithm for Bayesian topic models that combines the
efficiency of sparse Gibbs sampling with the scalability of online stochastic
inference. We used our algorithm to analyze a corpus of 1.2 million books (33
billion words) with thousands of topics. Our approach reduces the bias of
variational inference and generalizes to many Bayesian hidden-variable models.
</summary>
    <author>
      <name>David Mimno</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Princeton University</arxiv:affiliation>
    </author>
    <author>
      <name>Matt Hoffman</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Columbia University</arxiv:affiliation>
    </author>
    <author>
      <name>David Blei</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Princeton University</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.6425v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.6425v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.6435v1</id>
    <updated>2012-06-27T19:59:59Z</updated>
    <published>2012-06-27T19:59:59Z</published>
    <title>Rethinking Collapsed Variational Bayes Inference for LDA</title>
    <summary>  We propose a novel interpretation of the collapsed variational Bayes
inference with a zero-order Taylor expansion approximation, called CVB0
inference, for latent Dirichlet allocation (LDA). We clarify the properties of
the CVB0 inference by using the alpha-divergence. We show that the CVB0
inference is composed of two different divergence projections: alpha=1 and -1.
This interpretation will help shed light on CVB0 works.
</summary>
    <author>
      <name>Issei Sato</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">The University of Tokyo</arxiv:affiliation>
    </author>
    <author>
      <name>Hiroshi Nakagawa</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">The University of Tokyo</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.6435v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.6435v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.6436v1</id>
    <updated>2012-06-27T19:59:59Z</updated>
    <published>2012-06-27T19:59:59Z</published>
    <title>Efficient Structured Prediction with Latent Variables for General
  Graphical Models</title>
    <summary>  In this paper we propose a unified framework for structured prediction with
latent variables which includes hidden conditional random fields and latent
structured support vector machines as special cases. We describe a local
entropy approximation for this general formulation using duality, and derive an
efficient message passing algorithm that is guaranteed to converge. We
demonstrate its effectiveness in the tasks of image segmentation as well as 3D
indoor scene understanding from single images, showing that our approach is
superior to latent structured support vector machines and hidden conditional
random fields.
</summary>
    <author>
      <name>Alexander Schwing</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">ETH Zurich</arxiv:affiliation>
    </author>
    <author>
      <name>Tamir Hazan</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">TTIC</arxiv:affiliation>
    </author>
    <author>
      <name>Marc Pollefeys</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">ETH Zurich</arxiv:affiliation>
    </author>
    <author>
      <name>Raquel Urtasun</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">TTIC</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.6436v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.6436v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.6442v1</id>
    <updated>2012-06-27T19:59:59Z</updated>
    <published>2012-06-27T19:59:59Z</published>
    <title>Minimizing The Misclassification Error Rate Using a Surrogate Convex
  Loss</title>
    <summary>  We carefully study how well minimizing convex surrogate loss functions,
corresponds to minimizing the misclassification error rate for the problem of
binary classification with linear predictors. In particular, we show that
amongst all convex surrogate losses, the hinge loss gives essentially the best
possible bound, of all convex loss functions, for the misclassification error
rate of the resulting linear predictor in terms of the best possible margin
error rate. We also provide lower bounds for specific convex surrogates that
show how different commonly used losses qualitatively differ from each other.
</summary>
    <author>
      <name>Shai Ben-David</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Waterloo</arxiv:affiliation>
    </author>
    <author>
      <name>David Loker</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Waterloo</arxiv:affiliation>
    </author>
    <author>
      <name>Nathan Srebro</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">TTIC</arxiv:affiliation>
    </author>
    <author>
      <name>Karthik Sridharan</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Pennsylvania</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.6442v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.6442v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.6453v1</id>
    <updated>2012-06-27T19:59:59Z</updated>
    <published>2012-06-27T19:59:59Z</published>
    <title>Adaptive Canonical Correlation Analysis Based On Matrix Manifolds</title>
    <summary>  In this paper, we formulate the Canonical Correlation Analysis (CCA) problem
on matrix manifolds. This framework provides a natural way for dealing with
matrix constraints and tools for building efficient algorithms even in an
adaptive setting. Finally, an adaptive CCA algorithm is proposed and applied to
a change detection problem in EEG signals.
</summary>
    <author>
      <name>Florian Yger</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LITIS</arxiv:affiliation>
    </author>
    <author>
      <name>Maxime Berar</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LITIS</arxiv:affiliation>
    </author>
    <author>
      <name>Gilles Gasso</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INSA de Rouen</arxiv:affiliation>
    </author>
    <author>
      <name>Alain Rakotomamonjy</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INSA de Rouen</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.6453v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.6453v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.6470v1</id>
    <updated>2012-06-27T19:59:59Z</updated>
    <published>2012-06-27T19:59:59Z</published>
    <title>A Combinatorial Algebraic Approach for the Identifiability of Low-Rank
  Matrix Completion</title>
    <summary>  In this paper, we review the problem of matrix completion and expose its
intimate relations with algebraic geometry, combinatorics and graph theory. We
present the first necessary and sufficient combinatorial conditions for
matrices of arbitrary rank to be identifiable from a set of matrix entries,
yielding theoretical constraints and new algorithms for the problem of matrix
completion. We conclude by algorithmically evaluating the tightness of the
given conditions and algorithms for practically relevant matrix sizes, showing
that the algebraic-combinatoric approach can lead to improvements over
state-of-the-art matrix completion methods.
</summary>
    <author>
      <name>Franz Kiraly</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">TU Berlin</arxiv:affiliation>
    </author>
    <author>
      <name>Ryota Tomioka</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Tokyo</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.6470v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.6470v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.6813v1</id>
    <updated>2012-06-27T15:36:47Z</updated>
    <published>2012-06-27T15:36:47Z</published>
    <title>A concentration theorem for projections</title>
    <summary>  X in R^D has mean zero and finite second moments. We show that there is a
precise sense in which almost all linear projections of X into R^d (for d &lt; D)
look like a scale-mixture of spherical Gaussians -- specifically, a mixture of
distributions N(0, sigma^2 I_d) where the weight of the particular sigma
component is P (| X |^2 = sigma^2 D). The extent of this effect depends upon
the ratio of d to D, and upon a particular coefficient of eccentricity of X's
distribution. We explore this result in a variety of experiments.
</summary>
    <author>
      <name>Sanjoy Dasgupta</name>
    </author>
    <author>
      <name>Daniel Hsu</name>
    </author>
    <author>
      <name>Nakul Verma</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.6813v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.6813v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.6846v1</id>
    <updated>2012-06-27T16:23:17Z</updated>
    <published>2012-06-27T16:23:17Z</published>
    <title>Approximate Separability for Weak Interaction in Dynamic Systems</title>
    <summary>  One approach to monitoring a dynamic system relies on decomposition of the
system into weakly interacting subsystems. An earlier paper introduced a notion
of weak interaction called separability, and showed that it leads to exact
propagation of marginals for prediction. This paper addresses two questions
left open by the earlier paper: can we define a notion of approximate
separability that occurs naturally in practice, and do separability and
approximate separability lead to accurate monitoring? The answer to both
questions is afirmative. The paper also analyzes the structure of approximately
separable decompositions, and provides some explanation as to why these models
perform well.
</summary>
    <author>
      <name>Avi Pfeffer</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.6846v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.6846v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.6847v1</id>
    <updated>2012-06-27T16:23:41Z</updated>
    <published>2012-06-27T16:23:41Z</published>
    <title>Identifying the Relevant Nodes Without Learning the Model</title>
    <summary>  We propose a method to identify all the nodes that are relevant to compute
all the conditional probability distributions for a given set of nodes. Our
method is simple, effcient, consistent, and does not require learning a
Bayesian network first. Therefore, our method can be applied to
high-dimensional databases, e.g. gene expression databases.
</summary>
    <author>
      <name>Jose M. Pena</name>
    </author>
    <author>
      <name>Roland Nilsson</name>
    </author>
    <author>
      <name>Johan Björkegren</name>
    </author>
    <author>
      <name>Jesper Tegnér</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.6847v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.6847v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.6860v1</id>
    <updated>2012-06-27T16:27:25Z</updated>
    <published>2012-06-27T16:27:25Z</published>
    <title>Predicting Conditional Quantiles via Reduction to Classification</title>
    <summary>  We show how to reduce the process of predicting general order statistics (and
the median in particular) to solving classification. The accompanying
theoretical statement shows that the regret of the classifier bounds the regret
of the quantile regression under a quantile loss. We also test this reduction
empirically against existing quantile regression methods on large real-world
datasets and discover that it provides state-of-the-art performance.
</summary>
    <author>
      <name>John Langford</name>
    </author>
    <author>
      <name>Roberto Oliveira</name>
    </author>
    <author>
      <name>Bianca Zadrozny</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.6860v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.6860v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.6863v1</id>
    <updated>2012-06-27T16:28:18Z</updated>
    <published>2012-06-27T16:28:18Z</published>
    <title>Bayesian Multicategory Support Vector Machines</title>
    <summary>  We show that the multi-class support vector machine (MSVM) proposed by Lee
et. al. (2004), can be viewed as a MAP estimation procedure under an
appropriate probabilistic interpretation of the classifier. We also show that
this interpretation can be extended to a hierarchical Bayesian architecture and
to a fully-Bayesian inference procedure for multi-class classification based on
data augmentation. We present empirical results that show that the advantages
of the Bayesian formalism are obtained without a loss in classification
accuracy.
</summary>
    <author>
      <name>Zhihua Zhang</name>
    </author>
    <author>
      <name>Michael I. Jordan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.6863v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.6863v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.0166v3</id>
    <updated>2013-01-16T19:19:34Z</updated>
    <published>2012-06-30T23:07:03Z</published>
    <title>On Multilabel Classification and Ranking with Partial Feedback</title>
    <summary>  We present a novel multilabel/ranking algorithm working in partial
information settings. The algorithm is based on 2nd-order descent methods, and
relies on upper-confidence bounds to trade-off exploration and exploitation. We
analyze this algorithm in a partial adversarial setting, where covariates can
be adversarial, but multilabel probabilities are ruled by (generalized) linear
models. We show O(T^{1/2} log T) regret bounds, which improve in several ways
on the existing results. We test the effectiveness of our upper-confidence
scheme by contrasting against full-information baselines on real-world
multilabel datasets, often obtaining comparable performance.
</summary>
    <author>
      <name>Claudio Gentile</name>
    </author>
    <author>
      <name>Francesco Orabona</name>
    </author>
    <link href="http://arxiv.org/abs/1207.0166v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.0166v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.1358v1</id>
    <updated>2012-07-04T12:14:50Z</updated>
    <published>2012-07-04T12:14:50Z</published>
    <title>Unsupervised spectral learning</title>
    <summary>  In spectral clustering and spectral image segmentation, the data is partioned
starting from a given matrix of pairwise similarities S. the matrix S is
constructed by hand, or learned on a separate training set. In this paper we
show how to achieve spectral clustering in unsupervised mode. Our algorithm
starts with a set of observed pairwise features, which are possible components
of an unknown, parametric similarity function. This function is learned
iteratively, at the same time as the clustering of the data. The algorithm
shows promosing results on synthetic and real data.
</summary>
    <author>
      <name>Susan Shortreed</name>
    </author>
    <author>
      <name>Marina Meila</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</arxiv:comment>
    <link href="http://arxiv.org/abs/1207.1358v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.1358v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.3790v1</id>
    <updated>2012-07-16T08:49:34Z</updated>
    <published>2012-07-16T08:49:34Z</published>
    <title>Accuracy Measures for the Comparison of Classifiers</title>
    <summary>  The selection of the best classification algorithm for a given dataset is a
very widespread problem. It is also a complex one, in the sense it requires to
make several important methodological choices. Among them, in this work we
focus on the measure used to assess the classification performance and rank the
algorithms. We present the most popular measures and discuss their properties.
Despite the numerous measures proposed over the years, many of them turn out to
be equivalent in this specific case, to have interpretation problems, or to be
unsuitable for our purpose. Consequently, classic overall success rate or
marginal rates should be preferred for this specific task.
</summary>
    <author>
      <name>Vincent Labatut</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">BIT Lab</arxiv:affiliation>
    </author>
    <author>
      <name>Hocine Cherifi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Le2i</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The 5th International Conference on Information Technology, amman :
  Jordanie (2011)</arxiv:comment>
    <link href="http://arxiv.org/abs/1207.3790v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.3790v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.4112v1</id>
    <updated>2012-07-11T14:42:26Z</updated>
    <published>2012-07-11T14:42:26Z</published>
    <title>Algebraic Statistics in Model Selection</title>
    <summary>  We develop the necessary theory in computational algebraic geometry to place
Bayesian networks into the realm of algebraic statistics. We present an
algebra{statistics dictionary focused on statistical modeling. In particular,
we link the notion of effiective dimension of a Bayesian network with the
notion of algebraic dimension of a variety. We also obtain the independence and
non{independence constraints on the distributions over the observable variables
implied by a Bayesian network with hidden variables, via a generating set of an
ideal of polynomials associated to the network. These results extend previous
work on the subject. Finally, the relevance of these results for model
selection is discussed.
</summary>
    <author>
      <name>Luis David Garcia</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</arxiv:comment>
    <link href="http://arxiv.org/abs/1207.4112v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.4112v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
