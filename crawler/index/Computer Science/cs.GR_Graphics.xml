<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3Dall%3Acs.GR%26id_list%3D%26start%3D0%26max_results%3D500" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=all:cs.GR&amp;id_list=&amp;start=0&amp;max_results=500</title>
  <id>http://arxiv.org/api/dMlT+VWhZ9/qXcaXKDFTT1zVRiI</id>
  <updated>2017-10-08T00:00:00-04:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">937</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">500</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/cs/9301112v1</id>
    <updated>1990-04-01T00:00:00Z</updated>
    <published>1990-04-01T00:00:00Z</published>
    <title>A note on digitized angles</title>
    <summary>  We study the configurations of pixels that occur when two digitized straight
lines meet each other.
</summary>
    <author>
      <name>Donald E. Knuth</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Electronic Publishing 3 (1990), no. 2, 99--104</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/9301112v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9301112v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0302013v1</id>
    <updated>2003-02-12T05:16:12Z</updated>
    <published>2003-02-12T05:16:12Z</published>
    <title>Cg in Two Pages</title>
    <summary>  Cg is a language for programming GPUs. This paper describes Cg briefly.
</summary>
    <author>
      <name>Mark J. Kilgard</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0302013v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0302013v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.6; C.1.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1303.2824v1</id>
    <updated>2013-03-12T10:20:34Z</updated>
    <published>2013-03-12T10:20:34Z</published>
    <title>Fourth-order flows in surface modelling</title>
    <summary>  This short article is a brief account of the usage of fourth-order curvature
flow in surface modelling.
</summary>
    <author>
      <name>Ty Kang</name>
    </author>
    <link href="http://arxiv.org/abs/1303.2824v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1303.2824v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1406.6786v2</id>
    <updated>2014-06-27T07:51:43Z</updated>
    <published>2014-06-26T07:02:33Z</published>
    <title>3D Texture Coordinates on Polygon Mesh Sequences</title>
    <summary>  A method for creating 3D texture coordinates for a sequence of polygon meshes
with changing topology and vertex motion vectors.
</summary>
    <author>
      <name>Eric Mootz</name>
    </author>
    <link href="http://arxiv.org/abs/1406.6786v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1406.6786v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.03898v1</id>
    <updated>2016-07-22T12:52:09Z</updated>
    <published>2016-07-22T12:52:09Z</published>
    <title>Curvature transformation</title>
    <summary>  A transformation based on mean curvature is introduced which morphs
triangulated surfaces into round spheres.
</summary>
    <author>
      <name>Dimitris Vartziotis</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 13 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1608.03898v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.03898v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="53C44" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.05773v1</id>
    <updated>2016-08-20T03:25:50Z</updated>
    <published>2016-08-20T03:25:50Z</published>
    <title>Extending Scatterplots to Scalar Fields</title>
    <summary>  Embedding high-dimensional data into a 2D canvas is a popular strategy for
their visualization.
</summary>
    <author>
      <name>Shenghui Cheng</name>
    </author>
    <author>
      <name>Pengcheng Cui</name>
    </author>
    <author>
      <name>Klaus Mueller</name>
    </author>
    <link href="http://arxiv.org/abs/1608.05773v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.05773v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.0600v1</id>
    <updated>2013-04-02T11:55:33Z</updated>
    <published>2013-04-02T11:55:33Z</published>
    <title>Software for creating pictures in the LaTeX environment</title>
    <summary>  To create a text with graphic instructions for output pictures into LATEX
document, we offer software that allows us to build a picture in WIZIWIG mode
and for setting the text with these graphical instructions.
</summary>
    <author>
      <name>Bezhentcev Roman Vadimovich</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 1 figure, 2 formulas, sourcecode</arxiv:comment>
    <link href="http://arxiv.org/abs/1304.0600v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.0600v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68U05" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.07953v1</id>
    <updated>2016-01-29T00:08:24Z</updated>
    <published>2016-01-29T00:08:24Z</published>
    <title>Boolean Operations using Generalized Winding Numbers</title>
    <summary>  The generalized winding number function measures insideness for arbitrary
oriented triangle meshes. Exploiting this, I similarly generalize binary
boolean operations to act on such meshes. The resulting operations for union,
intersection, difference, etc. avoid volumetric discretization or
pre-processing.
</summary>
    <author>
      <name>Alec Jacobson</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">1 page, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1601.07953v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.07953v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0304011v1</id>
    <updated>2003-04-08T14:17:53Z</updated>
    <published>2003-04-08T14:17:53Z</published>
    <title>Embedded Reflection Mapping</title>
    <summary>  Environment maps are used to simulate reflections off curved objects. We
present a technique to reflect a user, or a group of users, in a real
environment, onto a virtual object, in a virtual reality application, using the
live video feeds from a set of cameras, in real-time. Our setup can be used in
a variety of environments ranging from outdoor or indoor scenes.
</summary>
    <author>
      <name>Paul Anderson</name>
    </author>
    <author>
      <name>Goncalo Carvalho</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0304011v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0304011v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0503054v1</id>
    <updated>2005-03-22T16:59:56Z</updated>
    <published>2005-03-22T16:59:56Z</published>
    <title>Analytic Definition of Curves and Surfaces by Parabolic Blending</title>
    <summary>  A procedure for interpolating between specified points of a curve or surface
is described. The method guarantees slope continuity at all junctions. A
surface panel divided into p x q contiguous patches is completely specified by
the coordinates of (p+1) x (q+1) points. Each individual patch, however,
depends parametrically on the coordinates of 16 points, allowing shape
flexibility and global conformity.
</summary>
    <author>
      <name>A. W. Overhauser</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 4 figures, technical report</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0503054v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0503054v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0510087v1</id>
    <updated>2005-10-31T09:40:00Z</updated>
    <published>2005-10-31T09:40:00Z</published>
    <title>MathPSfrag: Creating Publication-Quality Labels in Mathematica Plots</title>
    <summary>  This article introduces a Mathematica package providing a graphics export
function that automatically replaces Mathematica expressions in a graphic by
the corresponding LaTeX constructs and positions them correctly. It thus
facilitates the creation of publication-quality Enscapulated PostScript (EPS)
graphics.
</summary>
    <author>
      <name>J. Grosse</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 8 figures, for associated Mathematica package, see
  http://wwwth.mppmu.mpg.de/members/jgrosse/mathpsfrag/MathPSfrag-1.0.tar.gz</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0510087v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0510087v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0512098v1</id>
    <updated>2005-12-26T14:45:32Z</updated>
    <published>2005-12-26T14:45:32Z</published>
    <title>Mathematical models of the complex surfaces in simulation and
  visualization systems</title>
    <summary>  Modeling, simulation and visualization of three-dimension complex bodies
widely use mathematical model of curves and surfaces. The most important curves
and surfaces for these purposes are curves and surfaces in Hermite and Bezier
forms, splines and NURBS. Article is devoted to survey this way to use
geometrical data in various computer graphics systems and adjacent fields.
</summary>
    <author>
      <name>Dmitry P. Paukov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0512098v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0512098v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0712.0121v1</id>
    <updated>2007-12-02T07:25:59Z</updated>
    <published>2007-12-02T07:25:59Z</published>
    <title>Efficient Binary and Run Length Morphology and its Application to
  Document Image Processing</title>
    <summary>  This paper describes the implementation and evaluation of an open source
library for mathematical morphology based on packed binary and run-length
compressed images for document imaging applications. Abstractions and patterns
useful in the implementation of the interval operations are described. A number
of benchmarks and comparisons to bit-blit based implementations on standard
document images are provided.
</summary>
    <author>
      <name>Thomas M. Breuel</name>
    </author>
    <link href="http://arxiv.org/abs/0712.0121v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0712.0121v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.4; I.4.10; I.7.4; I.7.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0801.2175v1</id>
    <updated>2008-01-15T18:34:44Z</updated>
    <published>2008-01-15T18:34:44Z</published>
    <title>MathPSfrag 2: Convenient LaTeX Labels in Mathematica</title>
    <summary>  This article introduces the next version of MathPSfrag. MathPSfrag is a
Mathematica package that during export automatically replaces all expressions
in a plot by corresponding LaTeX commands. The new version can also produce
LaTeX independent images; e.g., PDF files for inclusion in pdfLaTeX. Moreover
from these files a preview is generated and shown within Mathematica.
</summary>
    <author>
      <name>Johannes Große</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, package can be found at
  http://wwwth.mppmu.mpg.de/members/jgrosse/mathpsfrag/</arxiv:comment>
    <link href="http://arxiv.org/abs/0801.2175v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0801.2175v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0910.4854v1</id>
    <updated>2009-10-26T10:55:16Z</updated>
    <published>2009-10-26T10:55:16Z</published>
    <title>Yet Another Pacman 3D Adventures</title>
    <summary>  This game is meant to be extension of the overly-beaten pacman-style game
(code-named "Yet Another Pacman 3D Adventures", or YAP3DAD) from the proposed
ideas and other projects with advance visual and computer graphics features,
including a-game-in-a-game approach. The project is an open-source project
published on SourceForge.net for possible future development and extension.
</summary>
    <author>
      <name>Serguei A. Mokhov</name>
    </author>
    <author>
      <name>Yingying She</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">31 pages, 8 figures. A 2006 report, corresponding to the open source
  project here: http://sourceforge.net/projects/yap3dad/</arxiv:comment>
    <link href="http://arxiv.org/abs/0910.4854v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0910.4854v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1001.3481v2</id>
    <updated>2010-02-03T16:35:49Z</updated>
    <published>2010-01-20T07:35:21Z</published>
    <title>Resolution scalability improvement for JPEG2000 standard color image</title>
    <summary>  Removed by arXiv administration. This article was plagiarised from
http://www.dmi.unict.it/~battiato/download/NSIP_2003_VQ.pdf and other
locations.
</summary>
    <author>
      <name>U. Vijayasankar</name>
    </author>
    <author>
      <name>S. Prasadh.</name>
    </author>
    <author>
      <name>A. Arul Lawrence Selvakumar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Removed by arXiv administration. This article was plagiarised from
  http://www.dmi.unict.it/~battiato/download/NSIP_2003_VQ.pdf and other
  locations</arxiv:comment>
    <link href="http://arxiv.org/abs/1001.3481v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1001.3481v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1101.0243v1</id>
    <updated>2010-12-31T12:30:34Z</updated>
    <published>2010-12-31T12:30:34Z</published>
    <title>Across Browsers SVG Implementation</title>
    <summary>  In this work SVG will be translated into VML or HTML by using Javascript
based on Backbase Client Framework. The target of this project is to implement
SVG to be viewed in Internet Explorer without any plug-in and work together
with other Backbase Client Framework languages. The result of this project will
be added as an extension to the current Backbase Client Framework.
</summary>
    <author>
      <name>Liang Wang</name>
    </author>
    <author>
      <name>Nies Huijsmans</name>
    </author>
    <author>
      <name>Michael S. Lew</name>
    </author>
    <author>
      <name>Dan Tsymbala</name>
    </author>
    <link href="http://arxiv.org/abs/1101.0243v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1101.0243v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1101.0301v1</id>
    <updated>2010-12-31T21:23:11Z</updated>
    <published>2010-12-31T21:23:11Z</published>
    <title>Specular holography</title>
    <summary>  By tooling an spot-illuminated surface to control the flow of specular glints
under motion, one can produce holographic view-dependent imagery. This paper
presents the differential equation that governs the shape of the specular
surfaces, and illustrates how solutions can be constructed for different kinds
of motion, lighting, host surface geometries, and fabrication constraints,
leading to some novel forms of holography.
</summary>
    <author>
      <name>Matthew Brand</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1364/AO.50.005042</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1364/AO.50.005042" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1101.0301v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1101.0301v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.optics" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1107.3013v1</id>
    <updated>2011-07-15T08:58:09Z</updated>
    <published>2011-07-15T08:58:09Z</published>
    <title>Linear-Time Poisson-Disk Patterns</title>
    <summary>  We present an algorithm for generating Poisson-disc patterns taking O(N) time
to generate $N$ points. The method is based on a grid of regions which can
contain no more than one point in the final pattern, and uses an explicit model
of point arrival times under a uniform Poisson process.
</summary>
    <author>
      <name>Thouis R. Jones</name>
    </author>
    <author>
      <name>David R. Karger</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1080/2151237X.2011.617173</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1080/2151237X.2011.617173" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1107.3013v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1107.3013v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1109.1914v2</id>
    <updated>2011-10-24T05:56:49Z</updated>
    <published>2011-09-09T06:49:52Z</published>
    <title>Jacobians and Hessians of Mean Value Coordinates for Closed Triangular
  Meshes</title>
    <summary>  In this technical note, we present the formulae of the derivatives of the
Mean Value Coordinates based transformations, using an enclosing triangle mesh,
acting as a cage for the deformation of an interior object.
</summary>
    <author>
      <name>Jean-Marc Thiery</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LTCI</arxiv:affiliation>
    </author>
    <author>
      <name>Julien Tierny</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LTCI</arxiv:affiliation>
    </author>
    <author>
      <name>Tamy Boubekeur</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LTCI</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/1109.1914v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1109.1914v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.6007v1</id>
    <updated>2013-01-25T11:03:18Z</updated>
    <published>2013-01-25T11:03:18Z</published>
    <title>Immersive VR Visualizations by VFIVE. Part 1: Development</title>
    <summary>  We have been developing a visualization application for CAVE-type virtual
reality (VR) systems for more than a decade. This application, VFIVE, is
currently used in several CAVE systems in Japan for routine visualizations. It
is also used as a base system of further developments of advanced
visualizations. The development of VFIVE is summarized.
</summary>
    <author>
      <name>Akira Kageyama</name>
    </author>
    <author>
      <name>Nobuaki Ohno</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1301.6007v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.6007v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.1240v1</id>
    <updated>2013-10-04T12:27:46Z</updated>
    <published>2013-10-04T12:27:46Z</published>
    <title>Compression of animated 3D models using HO-SVD</title>
    <summary>  This work presents an analysis of Higher Order Singular Value Decomposition
(HO-SVD) applied to lossy compression of 3D mesh animations. We describe
strategies for choosing a number of preserved spatial and temporal components
after tensor decomposition. Compression error is measured using three metrics
(MSE, Hausdorff, MSDM). Results are compared with a method based on Principal
Component Analysis (PCA) and presented on a set of animations with typical mesh
deformations.
</summary>
    <author>
      <name>Michał Romaszewski</name>
    </author>
    <author>
      <name>Piotr Gawron</name>
    </author>
    <author>
      <name>Sebastian Opozda</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 11 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1310.1240v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.1240v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1312.6935v1</id>
    <updated>2013-12-25T06:56:35Z</updated>
    <published>2013-12-25T06:56:35Z</published>
    <title>Application of polynomial texture mapping in process of digitalization
  of cultural heritage</title>
    <summary>  In this paper we present modern texture mapping techniques and several
applications of polynomial texture mapping in cultural heritage programs. We
also consider some well-known and some new methods for mathematical procedure
that is involved in generation of polynomial texture maps.
</summary>
    <author>
      <name>Branko Malesevic</name>
    </author>
    <author>
      <name>Ratko Obradovic</name>
    </author>
    <author>
      <name>Bojan Banjac</name>
    </author>
    <author>
      <name>Ivana Jovovic</name>
    </author>
    <author>
      <name>Milica Makragic</name>
    </author>
    <link href="http://arxiv.org/abs/1312.6935v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1312.6935v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.1902v1</id>
    <updated>2014-05-08T12:15:59Z</updated>
    <published>2014-05-08T12:15:59Z</published>
    <title>Proofs of two Theorems concerning Sparse Spacetime Constraints</title>
    <summary>  In the SIGGRAPH 2014 paper [SvTSH14] an approach for animating deformable
objects using sparse spacetime constraints is introduced. This report contains
the proofs of two theorems presented in the paper.
</summary>
    <author>
      <name>Christian Schulz</name>
    </author>
    <author>
      <name>Christoph von Tycowicz</name>
    </author>
    <author>
      <name>Hans-Peter Seidel</name>
    </author>
    <author>
      <name>Klaus Hildebrandt</name>
    </author>
    <link href="http://arxiv.org/abs/1405.1902v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.1902v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.07515v1</id>
    <updated>2015-06-24T19:56:56Z</updated>
    <published>2015-06-24T19:56:56Z</published>
    <title>The Vector Space of Convex Curves: How to Mix Shapes</title>
    <summary>  We present a novel, log-radius profile representation for convex curves and
define a new operation for combining the shape features of curves. Unlike the
standard, angle profile-based methods, this operation accurately combines the
shape features in a visually intuitive manner. This method have implications in
shape analysis as well as in investigating how the brain perceives and
generates curved shapes and motions.
</summary>
    <author>
      <name>Dongsung Huh</name>
    </author>
    <link href="http://arxiv.org/abs/1506.07515v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.07515v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.06821v1</id>
    <updated>2016-03-22T15:14:21Z</updated>
    <published>2016-03-22T15:14:21Z</published>
    <title>A Report on Shape Deformation with a Stretching and Bending Energy</title>
    <summary>  In this report we describe a mesh editing system that we implemented that
uses a natural stretching and bending energy defined over smooth surfaces. As
such, this energy behaves uniformly under various mesh resolutions. All of the
elements of our approach already exist in the literature. We hope that our
discussions of these energies helps to shed light on the behaviors of these
methods and provides a unified discussion of these methods.
</summary>
    <author>
      <name>Hui Zhao</name>
    </author>
    <author>
      <name>Steven J. Gortler</name>
    </author>
    <link href="http://arxiv.org/abs/1603.06821v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.06821v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.01396v1</id>
    <updated>2016-05-04T19:45:32Z</updated>
    <published>2016-05-04T19:45:32Z</published>
    <title>Squares that Look Round: Transforming Spherical Images</title>
    <summary>  We propose M\"obius transformations as the natural rotation and scaling tools
for editing spherical images. As an application we produce spherical Droste
images. We obtain other self-similar visual effects using rational functions,
elliptic functions, and Schwarz-Christoffel maps.
</summary>
    <author>
      <name>Saul Schleimer</name>
    </author>
    <author>
      <name>Henry Segerman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 9 figures with many subfigures</arxiv:comment>
    <link href="http://arxiv.org/abs/1605.01396v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.01396v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.HO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="00A66, 33C75, 30F10" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.09737v1</id>
    <updated>2016-05-31T17:39:49Z</updated>
    <published>2016-05-31T17:39:49Z</published>
    <title>3D Printed Stencils for Texturing Flat Surfaces</title>
    <summary>  We address the problem of texturing flat surfaces by spray-painting through
3D printed stencils. We propose a system that (1) decomposes an image into
alpha-blended layers; (2) computes a stippling given a transparency channel;
(3) generates a 3D printed stencil given a stippling and (4) simulates the
effects of spray-painting through the stencil.
</summary>
    <author>
      <name>Vaibhav Vavilala</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1605.09737v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.09737v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.01933v1</id>
    <updated>2016-08-05T16:39:27Z</updated>
    <published>2016-08-05T16:39:27Z</published>
    <title>Geoplotlib: a Python Toolbox for Visualizing Geographical Data</title>
    <summary>  We introduce geoplotlib, an open-source python toolbox for visualizing
geographical data. geoplotlib supports the development of hardware-accelerated
interactive visualizations in pure python, and provides implementations of dot
maps, kernel density estimation, spatial graphs, Voronoi tesselation,
shapefiles and many more common spatial visualizations. We describe geoplotlib
design, functionalities and use cases.
</summary>
    <author>
      <name>Andrea Cuttone</name>
    </author>
    <author>
      <name>Sune Lehmann</name>
    </author>
    <author>
      <name>Jakob Eg Larsen</name>
    </author>
    <link href="http://arxiv.org/abs/1608.01933v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.01933v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1704.02897v1</id>
    <updated>2017-04-10T15:13:40Z</updated>
    <published>2017-04-10T15:13:40Z</published>
    <title>Projection Mapping Technologies for AR</title>
    <summary>  This invited talk will present recent projection mapping technologies for
augmented reality. First, fundamental technologies are briefly explained, which
have been proposed to overcome the technical limitations of ordinary
projectors. Second, augmented reality (AR) applications using projection
mapping technologies are introduced.
</summary>
    <author>
      <name>Daisuke Iwai</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3 pages, 1 figure, 23rd International Display Workshops in
  conjunction with Asia Display 2016. arXiv admin note: substantial text
  overlap with arXiv:1510.02710</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of International Display Workshops (IDW), pp.
  1076-1078, 2016</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1704.02897v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1704.02897v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.07559v1</id>
    <updated>2017-08-24T21:12:51Z</updated>
    <published>2017-08-24T21:12:51Z</published>
    <title>Efficient barycentric point sampling on meshes</title>
    <summary>  We present an easy-to-implement and efficient analytical inversion algorithm
for the unbiased random sampling of a set of points on a triangle mesh whose
surface density is specified by barycentric interpolation of non-negative
per-vertex weights. The correctness of the inversion algorithm is verified via
statistical tests, and we show that it is faster on average than rejection
sampling.
</summary>
    <author>
      <name>Jamie Portsmouth</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1708.07559v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.07559v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.02721v2</id>
    <updated>2017-09-21T03:48:18Z</updated>
    <published>2017-08-16T07:02:54Z</published>
    <title>On the correlation between a level of structure order and properties of
  composites. In Memory of Yu.L. Klimontovich</title>
    <summary>  Proposed the computerized method for calculating the relative level of order
composites. Correlation between a level of structure order and properties of
solids is shown. Discussed the possibility of clarifying the terminology used
in describing the structure.
</summary>
    <author>
      <name>Alexander Herega</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">in Russian</arxiv:comment>
    <link href="http://arxiv.org/abs/1709.02721v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.02721v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.mtrl-sci" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9810020v1</id>
    <updated>1998-10-22T20:44:35Z</updated>
    <published>1998-10-22T20:44:35Z</published>
    <title>Computational Geometry Column 33</title>
    <summary>  Several recent SIGGRAPH papers on surface simplification are described.
</summary>
    <author>
      <name>Joseph O'Rourke</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Internat. J. Comput. Geom. Appl., 8(3) 381-384, 1998. Also in
  SIGACT News, 29(2) (Issue 107) 14-16, 1998</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/9810020v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9810020v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.2.2;I.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9810021v1</id>
    <updated>1998-10-22T21:01:36Z</updated>
    <published>1998-10-22T21:01:36Z</published>
    <title>Computational Geometry Column 32</title>
    <summary>  The proof of Dey's new k-set bound is illustrated.
</summary>
    <author>
      <name>Joseph O'Rourke</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Internat. J. Comput. Geom. Appl.,7(5) 509-513, 1997. Also in
  SIGACT News, 29(2) (Issue 107) 14-16, 1998</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/9810021v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9810021v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.2.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0206029v1</id>
    <updated>2002-06-20T06:21:15Z</updated>
    <published>2002-06-20T06:21:15Z</published>
    <title>Computer-Generated Photorealistic Hair</title>
    <summary>  This paper presents an efficient method for generating and rendering
photorealistic hair in two dimensional pictures. The method consists of three
major steps. Simulating an artist drawing is used to design the rough hair
shape. A convolution based filter is then used to generate photorealistic hair
patches. A refine procedure is finally used to blend the boundaries of the
patches with surrounding areas. This method can be used to create all types of
photorealistic human hair (head hair, facial hair and body hair). It is also
suitable for fur and grass generation. Applications of this method include:
hairstyle designing/editing, damaged hair image restoration, human hair
animation, virtual makeover of a human, and landscape creation.
</summary>
    <author>
      <name>Alice J. Lin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0206029v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0206029v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0212043v1</id>
    <updated>2002-12-13T05:33:10Z</updated>
    <published>2002-12-13T05:33:10Z</published>
    <title>Computing Conformal Structure of Surfaces</title>
    <summary>  This paper solves the problem of computing conformal structures of general
2-manifolds represented as triangle meshes. We compute conformal structures in
the following way: first compute homology bases from simplicial complex
structures, then construct dual cohomology bases and diffuse them to harmonic
1-forms. Next, we construct bases of holomorphic differentials. We then obtain
period matrices by integrating holomorphic differentials along homology bases.
We also study the global conformal mapping between genus zero surfaces and
spheres, and between general meshes and planes. Our method of computing
conformal structures can be applied to tackle fundamental problems in computer
aid design and computer graphics, such as geometry classification and
identification, and surface global parametrization.
</summary>
    <author>
      <name>Xianfeng Gu</name>
    </author>
    <author>
      <name>Shing-Tung Yau</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 3 figures, simplified version, full version upon request</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0212043v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0212043v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.5;F.2.2;G.2.m" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0306031v1</id>
    <updated>2003-06-06T12:34:53Z</updated>
    <published>2003-06-06T12:34:53Z</published>
    <title>The FRED Event Display: an Extensible HepRep Client for GLAST</title>
    <summary>  A new graphics client prototype for the HepRep protocol is presented. Based
on modern toolkits and high level languages (C++ and Ruby), Fred is an
experiment to test applicability of scripting facilities to the high energy
physics event display domain. Its flexible structure, extensibility and the use
of the HepRep protocol are key features for its use in the astroparticle
experiment GLAST.
</summary>
    <author>
      <name>Marco Frailis</name>
    </author>
    <author>
      <name>Riccardo Giannitrapani</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Talk from the 2003 Computing in High Energy and Nuclear Physics
  (CHEP03), La Jolla, Ca, USA, March 2003, 5 pages, LaTeX, 3 eps figures. PSN
  MOLT010</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ECONFC0303241:MOLT010,2003</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0306031v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0306031v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.2,I.3.3,I.3.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0404022v1</id>
    <updated>2004-04-08T14:07:05Z</updated>
    <published>2004-04-08T14:07:05Z</published>
    <title>An Algorithm for Transforming Color Images into Tactile Graphics</title>
    <summary>  This paper presents an algorithm that transforms color visual images, like
photographs or paintings, into tactile graphics. In the algorithm, the edges of
objects are detected and colors of the objects are estimated. Then, the edges
and the colors are encoded into lines and textures in the output tactile image.
Design of the method is substantiated by various qualities of haptic
recognizing of images. Also, means of presentation of the tactile images in
printouts are discussed. Example translated images are shown.
</summary>
    <author>
      <name>Artur Rataj</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0404022v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0404022v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.4.0" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0603132v1</id>
    <updated>2006-03-31T19:58:30Z</updated>
    <published>2006-03-31T19:58:30Z</published>
    <title>Graphics Turing Test</title>
    <summary>  We define a Graphics Turing Test to measure graphics performance in a similar
manner to the definition of the traditional Turing Test. To pass the test one
needs to reach a computational scale, the Graphics Turing Scale, for which
Computer Generated Imagery becomes comparatively indistinguishable from real
images while also being interactive. We derive an estimate for this
computational scale which, although large, is within reach of todays
supercomputers. We consider advantages and disadvantages of various computer
systems designed to pass the Graphics Turing Test. Finally we discuss
commercial applications from the creation of such a system, in particular
Interactive Cinema.
</summary>
    <author>
      <name>Michael McGuigan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0603132v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0603132v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0607050v2</id>
    <updated>2008-03-25T15:53:37Z</updated>
    <published>2006-07-11T19:01:41Z</published>
    <title>Interactive Hatching and Stippling by Example</title>
    <summary>  We describe a system that lets a designer interactively draw patterns of
strokes in the picture plane, then guide the synthesis of similar patterns over
new picture regions. Synthesis is based on an initial user-assisted analysis
phase in which the system recognizes distinct types of strokes (hatching and
stippling) and organizes them according to perceptual grouping criteria. The
synthesized strokes are produced by combining properties (eg. length,
orientation, parallelism, proximity) of the stroke groups extracted from the
input examples. We illustrate our technique with a drawing application that
allows the control of attributes and scale-dependent reproduction of the
synthesized patterns.
</summary>
    <author>
      <name>Pascal Barla</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rhône-Alpes / GRAVIR-IMAG</arxiv:affiliation>
    </author>
    <author>
      <name>Simon Breslav</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">EECS</arxiv:affiliation>
    </author>
    <author>
      <name>Lee Markosian</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">EECS</arxiv:affiliation>
    </author>
    <author>
      <name>Joëlle Thollot</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rhône-Alpes / GRAVIR-IMAG</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/cs/0607050v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0607050v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0608003v2</id>
    <updated>2006-08-01T22:08:19Z</updated>
    <published>2006-08-01T19:25:17Z</published>
    <title>On a solution to display non-filled-in quaternionic Julia sets</title>
    <summary>  During early 1980s, the so-called `escape time' method, developed to display
the Julia sets for complex dynamical systems, was exported to quaternions in
order to draw analogous pictures in this wider numerical field. Despite of the
fine results in the complex plane, where all topological configurations of
Julia sets have been successfully displayed, the `escape time' method fails to
render properly the non-filled-in variety of quaternionic Julia sets. So their
digital visualisation remained an open problem for several years. Both the
solution for extending this old method to non-filled-in quaternionic Julia sets
and its implementation into a program are explained here.
</summary>
    <author>
      <name>Alessandro Rosa</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 28 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0608003v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0608003v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0609084v1</id>
    <updated>2006-09-15T07:21:11Z</updated>
    <published>2006-09-15T07:21:11Z</published>
    <title>Non-photorealistic image rendering with a labyrinthine tiling</title>
    <summary>  The paper describes a new image processing for a non-photorealistic
rendering. The algorithm is based on a random generation of gray tones and
competing statistical requirements. The gray tone value of each pixel in the
starting image is replaced selecting among randomly generated tone values,
according to the statistics of nearest-neighbor and next-nearest-neighbor
pixels. Two competing conditions for replacing the tone values - one position
on the local mean value the other on the local variance - produce a peculiar
pattern on the image. This pattern has a labyrinthine tiling aspect. For
certain subjects, the pattern enhances the look of the image.
</summary>
    <author>
      <name>A. Sparavigna</name>
    </author>
    <author>
      <name>B. Montrucchio</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0609084v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0609084v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0610088v1</id>
    <updated>2006-10-14T09:25:52Z</updated>
    <published>2006-10-14T09:25:52Z</published>
    <title>Vector field visualization with streamlines</title>
    <summary>  We have recently developed an algorithm for vector field visualization with
oriented streamlines, able to depict the flow directions everywhere in a dense
vector field and the sense of the local orientations. The algorithm has useful
applications in the visualization of the director field in nematic liquid
crystals. Here we propose an improvement of the algorithm able to enhance the
visualization of the local magnitude of the field. This new approach of the
algorithm is compared with the same procedure applied to the Line Integral
Convolution (LIC) visualization.
</summary>
    <author>
      <name>A. Sparavigna</name>
    </author>
    <author>
      <name>B. Montrucchio</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pges, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0610088v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0610088v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0712.1549v1</id>
    <updated>2007-12-10T17:42:48Z</updated>
    <published>2007-12-10T17:42:48Z</published>
    <title>Dynamic Multilevel Graph Visualization</title>
    <summary>  We adapt multilevel, force-directed graph layout techniques to visualizing
dynamic graphs in which vertices and edges are added and removed in an online
fashion (i.e., unpredictably). We maintain multiple levels of coarseness using
a dynamic, randomized coarsening algorithm. To ensure the vertices follow
smooth trajectories, we employ dynamics simulation techniques, treating the
vertices as point particles. We simulate fine and coarse levels of the graph
simultaneously, coupling the dynamics of adjacent levels. Projection from
coarser to finer levels is adaptive, with the projection determined by an
affine transformation that evolves alongside the graph layouts. The result is a
dynamic graph visualizer that quickly and smoothly adapts to changes in a
graph.
</summary>
    <author>
      <name>Todd L. Veldhuizen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/0712.1549v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0712.1549v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.0; G.2.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0801.1500v1</id>
    <updated>2008-01-09T20:51:02Z</updated>
    <published>2008-01-09T20:51:02Z</published>
    <title>Toward the Graphics Turing Scale on a Blue Gene Supercomputer</title>
    <summary>  We investigate raytracing performance that can be achieved on a class of Blue
Gene supercomputers. We measure a 822 times speedup over a Pentium IV on a 6144
processor Blue Gene/L. We measure the computational performance as a function
of number of processors and problem size to determine the scaling performance
of the raytracing calculation on the Blue Gene. We find nontrivial scaling
behavior at large number of processors. We discuss applications of this
technology to scientific visualization with advanced lighting and high
resolution. We utilize three racks of a Blue Gene/L in our calculations which
is less than three percent of the the capacity of the worlds largest Blue Gene
computer.
</summary>
    <author>
      <name>Michael McGuigan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 4 figures, 6 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/0801.1500v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0801.1500v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0801.3249v1</id>
    <updated>2008-01-21T18:27:09Z</updated>
    <published>2008-01-21T18:27:09Z</published>
    <title>Complex Eigenvalues for Binary Subdivision Schemes</title>
    <summary>  Convergence properties of binary stationary subdivision schemes for curves
have been analyzed using the techniques of z-transforms and eigenanalysis.
Eigenanalysis provides a way to determine derivative continuity at specific
points based on the eigenvalues of a finite matrix. None of the well-known
subdivision schemes for curves have complex eigenvalues. We prove when a
convergent scheme with palindromic mask can have complex eigenvalues and that a
lower limit for the size of the mask exists in this case. We find a scheme with
complex eigenvalues achieving this lower bound. Furthermore we investigate this
scheme numerically and explain from a geometric viewpoint why such a scheme has
not yet been used in computer-aided geometric design.
</summary>
    <author>
      <name>Christian Kuehn</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0801.3249v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0801.3249v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0804.3103v1</id>
    <updated>2008-04-18T21:02:19Z</updated>
    <published>2008-04-18T21:02:19Z</published>
    <title>Size matters: performance declines if your pixels are too big or too
  small</title>
    <summary>  We present a conceptual model that describes the effect of pixel size on
target acquisition. We demonstrate the use of our conceptual model by applying
it to predict and explain the results of an experiment to evaluate users'
performance in a target acquisition task involving three distinct display
sizes: standard desktop, small and large displays. The results indicate that
users are fastest on standard desktop displays, undershoots are the most common
error on small displays and overshoots are the most common error on large
displays. We propose heuristics to maintain usability when changing displays.
Finally, we contribute to the growing body of evidence that amplitude does
affect performance in a display-based pointing task.
</summary>
    <author>
      <name>Vassilis Kostakos</name>
    </author>
    <author>
      <name>Eamonn O'Neill</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 13 figures, 7 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/0804.3103v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0804.3103v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0807.1667v1</id>
    <updated>2008-07-10T14:40:35Z</updated>
    <published>2008-07-10T14:40:35Z</published>
    <title>Quasi-Mandelbrot sets for perturbed complex analytic maps: visual
  patterns</title>
    <summary>  We consider perturbations of the complex quadratic map $ z \to z^2 +c$ and
corresponding changes in their quasi-Mandelbrot sets. Depending on particular
perturbation, visual forms of quasi-Mandelbrot set changes either sharply (when
the perturbation reaches some critical value) or continuously. In the latter
case we have a smooth transition from the classical form of the set to some
forms, constructed from mostly linear structures, as it is typical for
two-dimensional real number dynamics. Two examples of continuous evolution of
the quasi-Mandelbrot set are described.
</summary>
    <author>
      <name>A. V. Toporensky</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages with 10 JPEG pictures</arxiv:comment>
    <link href="http://arxiv.org/abs/0807.1667v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0807.1667v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0811.4121v1</id>
    <updated>2008-11-25T17:12:22Z</updated>
    <published>2008-11-25T17:12:22Z</published>
    <title>String Art: Circle Drawing Using Straight Lines</title>
    <summary>  An algorithm to generate the locus of a circle using the intersection points
of straight lines is proposed. The pixels on the circle are plotted independent
of one another and the operations involved in finding the locus of the circle
from the intersection of straight lines are parallelizable. Integer only
arithmetic and algorithmic optimizations are used for speedup. The proposed
algorithm makes use of an envelope to form a parabolic arc which is consequent
transformed into a circle. The use of parabolic arcs for the transformation
results in higher pixel errors as the radius of the circle to be drawn
increases. At its current state, the algorithm presented may be suitable only
for generating circles for string art.
</summary>
    <author>
      <name>Sankar K</name>
    </author>
    <author>
      <name>Sarad AV</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, code included</arxiv:comment>
    <link href="http://arxiv.org/abs/0811.4121v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0811.4121v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OH" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0811.4681v1</id>
    <updated>2008-11-28T16:31:12Z</updated>
    <published>2008-11-28T16:31:12Z</published>
    <title>The Good, the Bad, and the Ugly: three different approaches to break
  their watermarking system</title>
    <summary>  The Good is Blondie, a wandering gunman with a strong personal sense of
honor. The Bad is Angel Eyes, a sadistic hitman who always hits his mark. The
Ugly is Tuco, a Mexican bandit who's always only looking out for himself.
Against the backdrop of the BOWS contest, they search for a watermark in gold
buried in three images. Each knows only a portion of the gold's exact location,
so for the moment they're dependent on each other. However, none are
particularly inclined to share...
</summary>
    <author>
      <name>Gaëtan Le Guelvouit</name>
    </author>
    <author>
      <name>Teddy Furon</name>
    </author>
    <author>
      <name>François Cayre</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1117/12.703968</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1117/12.703968" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 8 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. IS&amp;T/SPIE Electronic Imaging, vol. 6505, San Jose, CA, Jan.
  2007</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0811.4681v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0811.4681v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1003.1401v1</id>
    <updated>2010-03-06T16:42:53Z</updated>
    <published>2010-03-06T16:42:53Z</published>
    <title>Macro and micro view on steady states in state space</title>
    <summary>  This paper describes visualization of chaotic attractor and elements of the
singularities in 3D space. 3D view of these effects enables to create a
demonstrative projection about relations of chaos generated by physical
circuit, the Chua's circuit. Via macro views on chaotic attractor is obtained
not only visual space illustration of representative point motion in state
space, but also its relation to planes of singularity elements. Our created
program enables view on chaotic attractor both in 2D and 3D space together with
plane objects visualization -- elements of singularities.
</summary>
    <author>
      <name>Branislav Sobota</name>
    </author>
    <author>
      <name>Milan Guzan</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Acta Univ. Sapientiae, Informatica, 2,1 (2010) 90-98</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1003.1401v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1003.1401v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="94C99, 68U05" scheme="http://arxiv.org/schemas/atom"/>
    <category term="B.7.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1003.1410v2</id>
    <updated>2013-08-08T18:05:00Z</updated>
    <published>2010-03-06T18:08:12Z</published>
    <title>Local Space-Time Smoothing for Version Controlled Documents</title>
    <summary>  Unlike static documents, version controlled documents are continuously edited
by one or more authors. Such collaborative revision process makes traditional
modeling and visualization techniques inappropriate. In this paper we propose a
new representation based on local space-time smoothing that captures important
revision patterns. We demonstrate the applicability of our framework using
experiments on synthetic and real-world data.
</summary>
    <author>
      <name>Seungyeon Kim</name>
    </author>
    <author>
      <name>Guy Lebanon</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 6 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 23rd International Conference on Computational
  Linguistics (Coling 2010); 2010 Aug 23-27; Beijing, CN</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1003.1410v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1003.1410v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1005.3163v1</id>
    <updated>2010-05-18T11:54:39Z</updated>
    <published>2010-05-18T11:54:39Z</published>
    <title>Virtual Texturing</title>
    <summary>  In this thesis a rendering system and an accompanying tool chain for Virtual
Texturing is presented. Our tools allow to automatically retexture existing
geometry in order to apply unique texturing on each face. Furthermore we
investigate several techniques that try to minimize visual artifacts in the
case that only a small amount of pages can be streamed per frame. We analyze
the influence of different heuristics that are responsible for the page
selection. Alongside these results we present a measurement method to allow the
comparison of our heuristics.
</summary>
    <author>
      <name>Andreas Neu</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">RWTH Aachen University, Computer Graphics &amp; Multimedia</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/1005.3163v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1005.3163v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1005.3190v1</id>
    <updated>2010-05-18T13:10:28Z</updated>
    <published>2010-05-18T13:10:28Z</published>
    <title>From granular avalanches to fluid turbulences through oozing pastes. A
  mesoscopic physically-based particle model</title>
    <summary>  In this paper, we describe how we can precisely produce complex and various
dynamic morphological features such as structured and chaotic features which
occur in sand pilings (piles, avalanches, internal collapses, arches) , in
flowing fluids (laminar flowing, Kelvin-Helmholtz and Von Karmann eddies), and
in cohesive pastes (twist-and-turn oozing and packing) using only a single
unified model, called "mesoscopic model". This model is a physically-based
particle model whose behavior depends on only four simple, but easy to
understand, physically-based parameters : elasticity, viscosity and their local
areas of influence. It is fast to compute and easy to understand by
non-physicist users.
</summary>
    <author>
      <name>Annie Luciani</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">ACROE</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Graphicon 2000, Moscou : Russian Federation (2000)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1005.3190v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1005.3190v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1006.4903v2</id>
    <updated>2010-12-30T05:17:12Z</updated>
    <published>2010-06-25T03:11:37Z</published>
    <title>Toric degenerations of Bezier patches</title>
    <summary>  The control polygon of a Bezier curve is well-defined and has geometric
significance---there is a sequence of weights under which the limiting position
of the curve is the control polygon. For a Bezier surface patch, there are many
possible polyhedral control structures, and none are canonical. We propose a
not necessarily polyhedral control structure for surface patches, regular
control surfaces, which are certain C^0 spline surfaces. While not unique,
regular control surfaces are exactly the possible limiting positions of a
Bezier patch when the weights are allowed to vary.
</summary>
    <author>
      <name>Luis David Garcia-Puente</name>
    </author>
    <author>
      <name>Frank Sottile</name>
    </author>
    <author>
      <name>Chungang Zhu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages, many .eps figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1006.4903v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1006.4903v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.AG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65D17, 14M25" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1007.2204v1</id>
    <updated>2010-07-13T21:09:11Z</updated>
    <published>2010-07-13T21:09:11Z</published>
    <title>What's wrong with Phong - Designers' appraisal of shading in CAD-systems</title>
    <summary>  The Phong illumination model is still widely used in realtime 3D
visualization systems. The aim of this article is to document problems with the
Phong illumination model that are encountered by an important professional user
group, namely digital designers. This leads to a visual evaluation of Phong
illumination, which at least in this condensed form seems still to be missing
in the literature. It is hoped that by explicating these flaws, awareness about
the limitations and interdependencies of the model will increase, both among
fellow users, and among researchers and developers.
</summary>
    <author>
      <name>Jörg M. Hahn</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages, 8 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1007.2204v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1007.2204v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.7; J.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1008.0208v2</id>
    <updated>2010-08-03T08:15:53Z</updated>
    <published>2010-08-01T22:58:04Z</published>
    <title>Parametric polynomial minimal surfaces of arbitrary degree</title>
    <summary>  Weierstrass representation is a classical parameterization of minimal
surfaces. However, two functions should be specified to construct the
parametric form in Weierestrass representation. In this paper, we propose an
explicit parametric form for a class of parametric polynomial minimal surfaces
of arbitrary degree. It includes the classical Enneper surface for cubic case.
The proposed minimal surfaces also have some interesting properties such as
symmetry, containing straight lines and self-intersections. According to the
shape properties, the proposed minimal surface can be classified into four
categories with respect to $n=4k-1$ $n=4k+1$, $n=4k$ and $n=4k+2$. The explicit
parametric form of corresponding conjugate minimal surfaces is given and the
isometric deformation is also implemented.
</summary>
    <author>
      <name>Gang Xu</name>
    </author>
    <author>
      <name>Guozhao Wang</name>
    </author>
    <link href="http://arxiv.org/abs/1008.0208v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1008.0208v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1008.1664v1</id>
    <updated>2010-08-10T08:34:46Z</updated>
    <published>2010-08-10T08:34:46Z</published>
    <title>L-systems in Geometric Modeling</title>
    <summary>  We show that parametric context-sensitive L-systems with affine geometry
interpretation provide a succinct description of some of the most fundamental
algorithms of geometric modeling of curves. Examples include the
Lane-Riesenfeld algorithm for generating B-splines, the de Casteljau algorithm
for generating Bezier curves, and their extensions to rational curves. Our
results generalize the previously reported geometric-modeling applications of
L-systems, which were limited to subdivision curves.
</summary>
    <author>
      <name>Przemyslaw Prusinkiewicz</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Calgary</arxiv:affiliation>
    </author>
    <author>
      <name>Mitra Shirmohammadi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Calgary</arxiv:affiliation>
    </author>
    <author>
      <name>Faramarz Samavati</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Calgary</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.31.3</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.31.3" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings DCFS 2010, arXiv:1008.1270</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 31, 2010, pp. 3-14</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1008.1664v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1008.1664v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1009.4602v1</id>
    <updated>2010-09-23T13:08:32Z</updated>
    <published>2010-09-23T13:08:32Z</published>
    <title>Geoglyphs of Titicaca as an ancient example of graphic design</title>
    <summary>  The paper proposes an ancient landscape design as an example of graphic
design for an age and place where no written documents existed. It is created
by a network of earthworks, which constitute the remains of an extensive
ancient agricultural system. It can be seen by means of the Google satellite
imagery on the Peruvian region near the Titicaca Lake, as a texture
superimposed to the background landform. In this texture, many drawings
(geoglyphs) can be observed.
</summary>
    <author>
      <name>Amelia Carolina Sparavigna</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Keywords: Geoglyphs, History of Graphics, Image processing, Satellite
  maps, Archaeology</arxiv:comment>
    <link href="http://arxiv.org/abs/1009.4602v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1009.4602v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1010.2623v2</id>
    <updated>2010-11-15T10:47:24Z</updated>
    <published>2010-10-13T10:35:23Z</published>
    <title>Surface Curvature Effects on Reflectance from Translucent Materials</title>
    <summary>  Most of the physically based techniques for rendering translucent objects use
the diffusion theory of light scattering in turbid media. The widely used
dipole diffusion model (Jensen et al. 2001) applies the diffusion-theory
formula derived for a planar interface to objects of arbitrary shapes. This
paper presents first results of our investigation of how surface curvature
affects the diffuse reflectance from translucent materials.
</summary>
    <author>
      <name>Konstantin Kolchin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 2 figures. The first version of this paper was published in
  the Communication Papers Proceedings of 18th International Conference on
  Computer Graphics, Visualization and Computer Vision 2010 - WSCG2010</arxiv:comment>
    <link href="http://arxiv.org/abs/1010.2623v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1010.2623v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.optics" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.4.1; I.4.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1101.0262v1</id>
    <updated>2010-12-31T14:34:06Z</updated>
    <published>2010-12-31T14:34:06Z</published>
    <title>High Speed and Area Efficient 2D DWT Processor based Image Compression"
  Signal &amp; Image Processing</title>
    <summary>  This paper presents a high speed and area efficient DWT processor based
design for Image Compression applications. In this proposed design, pipelined
partially serial architecture has been used to enhance the speed along with
optimal utilization and resources available on target FPGA. The proposed model
has been designed and simulated using Simulink and System Generator blocks,
synthesized with Xilinx Synthesis tool (XST) and implemented on Spartan 2 and 3
based XC2S100-5tq144 and XC3S500E-4fg320 target device. The results show that
proposed design can operate at maximum frequency 231 MHz in case of Spartan 3
by consuming power of 117mW at 28 degree/c junction temperature. The result
comparison has shown an improvement of 15% in speed.
</summary>
    <author>
      <name>Sugreev Kaur</name>
    </author>
    <author>
      <name>Rajesh Mehra</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 Pages, 9 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1101.0262v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1101.0262v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1107.0690v1</id>
    <updated>2011-07-04T17:51:00Z</updated>
    <published>2011-07-04T17:51:00Z</published>
    <title>A Framework for Designing 3D Virtual Environments</title>
    <summary>  The process of design and development of virtual environments can be
supported by tools and frameworks, to save time in technical aspects and
focusing on the content. In this paper we present an academic framework which
provides several levels of abstraction to ease this work. It includes
state-of-the-art components we devised or integrated adopting open-source
solutions in order to face specific problems. Its architecture is modular and
customizable, the code is open-source.
</summary>
    <author>
      <name>Salvatore Catanese</name>
    </author>
    <author>
      <name>Emilio Ferrara</name>
    </author>
    <author>
      <name>Giacomo Fiumara</name>
    </author>
    <author>
      <name>Francesco Pagano</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-642-30214-5_23</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-642-30214-5_23" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 1 figure, Proceedings of the 4th International ICST
  Conference On Intelligent Technologies For Interactive Entertainment, 2011</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Lecture Notes of the Institute for Computer Sciences, Social
  Informatics and Telecommunications Engineering Volume 78, 2012, pp 209-218</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1107.0690v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1107.0690v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1112.3110v1</id>
    <updated>2011-12-14T03:46:46Z</updated>
    <published>2011-12-14T03:46:46Z</published>
    <title>GPU-based Image Analysis on Mobile Devices</title>
    <summary>  With the rapid advances in mobile technology many mobile devices are capable
of capturing high quality images and video with their embedded camera. This
paper investigates techniques for real-time processing of the resulting images,
particularly on-device utilizing a graphical processing unit. Issues and
limitations of image processing on mobile devices are discussed, and the
performance of graphical processing units on a range of devices measured
through a programmable shader implementation of Canny edge detection.
</summary>
    <author>
      <name>Andrew Ensor</name>
    </author>
    <author>
      <name>Seth Hall</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of Image and Vision Computing New Zealand 2011</arxiv:comment>
    <link href="http://arxiv.org/abs/1112.3110v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1112.3110v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.1; I.4.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1201.0070v1</id>
    <updated>2011-12-30T06:23:54Z</updated>
    <published>2011-12-30T06:23:54Z</published>
    <title>Fast B-spline Curve Fitting by L-BFGS</title>
    <summary>  We propose a novel method for fitting planar B-spline curves to unorganized
data points. In traditional methods, optimization of control points and foot
points are performed in two very time-consuming steps in each iteration: 1)
control points are updated by setting up and solving a linear system of
equations; and 2) foot points are computed by projecting each data point onto a
B-spline curve. Our method uses the L-BFGS optimization method to optimize
control points and foot points simultaneously and therefore it does not need to
perform either matrix computation or foot point projection in every iteration.
As a result, our method is much faster than existing methods.
</summary>
    <author>
      <name>Wenni Zheng</name>
    </author>
    <author>
      <name>Pengbo Bo</name>
    </author>
    <author>
      <name>Yang Liu</name>
    </author>
    <author>
      <name>Wenping Wang</name>
    </author>
    <link href="http://arxiv.org/abs/1201.0070v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1201.0070v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.1461v1</id>
    <updated>2012-04-06T12:03:45Z</updated>
    <published>2012-04-06T12:03:45Z</published>
    <title>Efficient computational noise in GLSL</title>
    <summary>  We present GLSL implementations of Perlin noise and Perlin simplex noise that
run fast enough for practical consideration on current generation GPU hardware.
The key benefits are that the functions are purely computational, i.e. they use
neither textures nor lookup tables, and that they are implemented in GLSL
version 1.20, which means they are compatible with all current GLSL-capable
platforms, including OpenGL ES 2.0 and WebGL 1.0. Their performance is on par
with previously presented GPU implementations of noise, they are very
convenient to use, and they scale well with increasing parallelism in present
and upcoming GPU architectures.
</summary>
    <author>
      <name>Ian McEwan</name>
    </author>
    <author>
      <name>David Sheets</name>
    </author>
    <author>
      <name>Stefan Gustavson</name>
    </author>
    <author>
      <name>Mark Richardson</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1080/2151237X.2012.649621</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1080/2151237X.2012.649621" rel="related"/>
    <link href="http://arxiv.org/abs/1204.1461v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.1461v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.3899v1</id>
    <updated>2012-07-17T07:17:27Z</updated>
    <published>2012-07-17T07:17:27Z</published>
    <title>Fast View Frustum Culling of Spatial Object by Analytical Bounding Bin</title>
    <summary>  It is a common sense to apply the VFC (view frustum culling) of spatial
object to bounding cube of the object in 3D graphics. The accuracy of VFC can
not be guaranteed even in cube rotated three-dimensionally. In this paper is
proposed a method which is able to carry out more precise and fast VFC of any
spatial object in the image domain of cube by an analytic mapping, and is
demonstrated the effect of the method for terrain block on global surface.
</summary>
    <author>
      <name>Munsu Ju</name>
    </author>
    <author>
      <name>Yunchol Jong</name>
    </author>
    <link href="http://arxiv.org/abs/1207.3899v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.3899v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.1768v1</id>
    <updated>2012-11-08T06:50:44Z</updated>
    <published>2012-11-08T06:50:44Z</published>
    <title>Nearest Neighbor Value Interpolation</title>
    <summary>  This paper presents the nearest neighbor value (NNV) algorithm for high
resolution (H.R.) image interpolation. The difference between the proposed
algorithm and conventional nearest neighbor algorithm is that the concept
applied, to estimate the missing pixel value, is guided by the nearest value
rather than the distance. In other words, the proposed concept selects one
pixel, among four directly surrounding the empty location, whose value is
almost equal to the value generated by the conventional bilinear interpolation
algorithm. The proposed method demonstrated higher performances in terms of
H.R. when compared to the conventional interpolation algorithms mentioned.
</summary>
    <author>
      <name>Rukundo Olivier</name>
    </author>
    <author>
      <name>Cao Hanqiang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 11 figures, 2 tables</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Advanced Computer Science and
  Applications(IJACSA),Vol. 3, No. 4, 2012</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1211.1768v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.1768v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.3297v2</id>
    <updated>2013-08-01T14:12:08Z</updated>
    <published>2012-11-14T13:21:03Z</published>
    <title>Gap Processing for Adaptive Maximal Poisson-Disk Sampling</title>
    <summary>  In this paper, we study the generation of maximal Poisson-disk sets with
varying radii. First, we present a geometric analysis of gaps in such disk
sets. This analysis is the basis for maximal and adaptive sampling in Euclidean
space and on manifolds. Second, we propose efficient algorithms and data
structures to detect gaps and update gaps when disks are inserted, deleted,
moved, or have their radius changed. We build on the concepts of the regular
triangulation and the power diagram. Third, we will show how our analysis can
make a contribution to the state-of-the-art in surface remeshing.
</summary>
    <author>
      <name>Dong-Ming Yan</name>
    </author>
    <author>
      <name>Peter Wonka</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages. ACM Transactions on Graphics, 2013</arxiv:comment>
    <link href="http://arxiv.org/abs/1211.3297v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.3297v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.3659v1</id>
    <updated>2012-11-15T17:08:58Z</updated>
    <published>2012-11-15T17:08:58Z</published>
    <title>Color scales that are effective in both color and grayscale</title>
    <summary>  We consider the problem of finding a color scale which performs well when
converted to a grayscale. We assume that each color is converted to a shade of
gray with the same intensity as the color. We also assume that the color scales
have a linear variation of intensity and hue, and find scales which maximize
the average chroma (or "colorfulness") of the colors. We find two classes of
solutions, which traverse the color wheel in opposite directions. The two
classes of scales start with hues near cyan and red. The average chroma of the
scales are 65-77% those of the pure colors.
</summary>
    <author>
      <name>Silas Alben</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1211.3659v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.3659v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.5669v1</id>
    <updated>2012-11-24T12:56:58Z</updated>
    <published>2012-11-24T12:56:58Z</published>
    <title>Analysis-suitable T-splines: characterization, refineability, and
  approximation</title>
    <summary>  We establish several fundamental properties of analysis-suitable T-splines
which are important for design and analysis. First, we characterize T-spline
spaces and prove that the space of smooth bicubic polynomials, defined over the
extended T-mesh of an analysis-suitable T-spline, is contained in the
corresponding analysis-suitable T-spline space. This is accomplished through
the theory of perturbed analysis-suitable T-spline spaces and a simple
topological dimension formula. Second, we establish the theory of
analysis-suitable local refinement and describe the conditions under which two
analysis-suitable T-spline spaces are nested. Last, we demonstrate that these
results can be used to establish basic approximation results which are critical
for analysis.
</summary>
    <author>
      <name>Xin Li</name>
    </author>
    <author>
      <name>M. A. Scott</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Mathematical Models and Methods in Applied Sciences,Vol. 24, No.
  06, pp. 1141-1164 (2014)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1211.5669v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.5669v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.5842v1</id>
    <updated>2012-11-26T02:13:52Z</updated>
    <published>2012-11-26T02:13:52Z</published>
    <title>A Novel Algorithm for Real-time Procedural Generation of Building Floor
  Plans</title>
    <summary>  Real-time generation of natural-looking floor plans is vital in games with
dynamic environments. This paper presents an algorithm to generate suburban
house floor plans in real-time. The algorithm is based on the work presented in
[1]. However, the corridor placement is redesigned to produce floor plans
similar to real houses. Moreover, an optimization stage is added to find a
corridor placement with the minimum used space, an approach that is designed to
mimic the real-life practices to minimize the wasted spaces in the design. The
results show very similar floor plans to the ones designed by an architect.
</summary>
    <author>
      <name>Maysam Mirahmadi</name>
    </author>
    <author>
      <name>Abdallah Shami</name>
    </author>
    <link href="http://arxiv.org/abs/1211.5842v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.5842v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.0289v1</id>
    <updated>2012-12-24T17:10:28Z</updated>
    <published>2012-12-24T17:10:28Z</published>
    <title>Reconstructing Self Organizing Maps as Spider Graphs for better visual
  interpretation of large unstructured datasets</title>
    <summary>  Self-Organizing Maps (SOM) are popular unsupervised artificial neural network
used to reduce dimensions and visualize data. Visual interpretation from
Self-Organizing Maps (SOM) has been limited due to grid approach of data
representation, which makes inter-scenario analysis impossible. The paper
proposes a new way to structure SOM. This model reconstructs SOM to show
strength between variables as the threads of a cobweb and illuminate
inter-scenario analysis. While Radar Graphs are very crude representation of
spider web, this model uses more lively and realistic cobweb representation to
take into account the difference in strength and length of threads. This model
allows for visualization of highly unstructured dataset with large number of
dimensions, common in Bigdata sources.
</summary>
    <author>
      <name>Aaditya Prakash</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 8 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1301.0289v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.0289v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.6008v1</id>
    <updated>2013-01-25T11:07:37Z</updated>
    <published>2013-01-25T11:07:37Z</published>
    <title>Immersive VR Visualizations by VFIVE. Part 2: Applications</title>
    <summary>  VFIVE is a scientific visualization application for CAVE-type immersive
virtual reality systems. The source codes are freely available. VFIVE is used
as a research tool in various VR systems. It also lays the groundwork for
developments of new visualization software for CAVEs. In this paper, we pick up
five CAVE systems in four different institutions in Japan. Applications of
VFIVE in each CAVE system are summarized. Special emphases will be placed on
scientific and technical achievements made possible by VFIVE.
</summary>
    <author>
      <name>Akira Kageyama</name>
    </author>
    <author>
      <name>Nobuaki Ohno</name>
    </author>
    <author>
      <name>Shintaro Kawahara</name>
    </author>
    <author>
      <name>Kazuo Kashiyama</name>
    </author>
    <author>
      <name>Hiroaki Ohtani</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 14 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1301.6008v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.6008v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.4974v1</id>
    <updated>2013-04-17T21:32:37Z</updated>
    <published>2013-04-17T21:32:37Z</published>
    <title>Fast exact digital differential analyzer for circle generation</title>
    <summary>  In the first part of the paper we present a short review of applications of
digital differential analyzers (DDA) to generation of circles showing that they
can be treated as one-step numerical schemes. In the second part we present and
discuss a novel fast algorithm based on a two-step numerical scheme (explicit
midpoint rule). Although our algorithm is as cheap as the simplest one-step DDA
algoritm (and can be represented in terms of shifts and additions), it
generates circles with maximal accuracy, i.e., it is exact up to round-off
errors.
</summary>
    <author>
      <name>Jan L. Cieśliński</name>
    </author>
    <author>
      <name>Leonid V. Moroz</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1304.4974v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.4974v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65D17, 68U07, 65L12" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.3; G.1.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.7842v1</id>
    <updated>2013-04-30T03:10:31Z</updated>
    <published>2013-04-30T03:10:31Z</published>
    <title>The Logarithmic Curvature Graphs of Generalised Cornu Spirals</title>
    <summary>  The Generalized Cornu Spiral (GCS) was first proposed by Ali et al. in 1995
[9]. Due to the monotonocity of its curvature function, the surface generated
with GCS segments has been considered as a high quality surface and it has
potential applications in surface design [2]. In this paper, the analysis of
GCS segment is carried out by determining its aesthetic value using the log
curvature Graph (LCG) as proposed by Kanaya et al.[10]. The analysis of LCG
supports the claim that GCS is indeed a generalized aesthetic curve.
</summary>
    <author>
      <name>R. U. Gobithaasan</name>
    </author>
    <author>
      <name>J. M. Ali</name>
    </author>
    <author>
      <name>Kenjiro T. Miura</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">2012 Punjab University Journal of Mathematics, 44, Pg.1-8</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1304.7842v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.7842v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.7848v1</id>
    <updated>2013-04-30T03:33:43Z</updated>
    <published>2013-04-30T03:33:43Z</published>
    <title>Characterization of Planar Cubic Alternative curve</title>
    <summary>  In this paper, we analyze the planar cubic Alternative curve to determine the
conditions for convex, loops, cusps and inflection points. Thus cubic curve is
represented by linear combination of three control points and basis function
that consist of two shape parameters. By using algebraic manipulation, we can
determine the constraint of shape parameters and sufficient conditions are
derived which ensure that the curve is a strictly convex, loops, cusps and
inflection point. We conclude the result in a shape diagram of parameters. The
simplicity of this form makes characterization more intuitive and efficient to
compute.
</summary>
    <author>
      <name>Azhar Ahmad</name>
    </author>
    <author>
      <name>R. Gobithasan</name>
    </author>
    <author>
      <name>Jamaluddin Md. Ali</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">2009 Journal of Mathematika, Vol. 25, Nu.2, Pg. 125-134</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1304.7848v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.7848v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.7881v1</id>
    <updated>2013-04-30T05:25:31Z</updated>
    <published>2013-04-30T05:25:31Z</published>
    <title>Various Types of Aesthetic Curves</title>
    <summary>  The research on developing planar curves to produce visually pleasing
products (ranges from electric appliances to car body design) and
indentifying/modifying planar curves for special purposes namely for railway
design, highway design and robot trajectories have been progressing since
1970s. The pattern of research in this field of study has branched to five
major groups namely curve synthesis, fairing process, improvement in control of
natural spiral, construction of new type of planar curves and, natural spiral
fitting &amp; approximation techniques. The purpose of is this paper is to briefly
review recent progresses in Computer Aided Geometric Design (CAGD) focusing on
the topics states above.
</summary>
    <author>
      <name>R. U. Gobithaasan</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">2011 The Proceedings of Seminar Bidang Kepakaran Jabatan Matematik
  2010, Cherating, Pahang. Disember 27th- 30th 2010, Pg.9-22</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1304.7881v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.7881v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.7883v1</id>
    <updated>2013-04-30T05:30:00Z</updated>
    <published>2013-04-30T05:30:00Z</published>
    <title>An Improvised Algorithm to Identify The Beauty of A Planar Curve</title>
    <summary>  An improvised algorithm is proposed based on the work of Yoshimoto and
Harada. The improvised algorithm results a graph which is called LDGC or
Logarithmic Distribution Graph of Curvature. This graph has the capability to
identify the beauty of monotonic planar curves with less effort as compared to
LDDC by Yoshimoto and Harada.
</summary>
    <author>
      <name>R. U. Gobithaasan</name>
    </author>
    <author>
      <name>Jamaludin Md. Ali</name>
    </author>
    <author>
      <name>Kenjiro T. Miura</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">2008 The Proceedings of Simposium Kebangsaan Sains Matematik ke-16
  (SKSM16), Kota Bharu, Kelantan. June 3rd-5th 2008, Pg.223-228</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1304.7883v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.7883v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1305.0001v1</id>
    <updated>2013-04-30T05:12:05Z</updated>
    <published>2013-04-30T05:12:05Z</published>
    <title>Perfectly normal type-2 fuzzy interpolation B-spline curve</title>
    <summary>  In this paper, we proposed another new form of type-2 fuzzy data
points(T2FDPs) that is perfectly normal type-2 data points(PNT2FDPs). These
kinds of brand-new data were defined by using the existing type-2 fuzzy set
theory(T2FST) and type-2 fuzzy number(T2FN) concept since we dealt with the
problem of defining complex uncertainty data. Along with this restructuring, we
included the fuzzification(alpha-cut operation), type-reduction and
defuzzification processes against PNT2FDPs. In addition, we used interpolation
B-soline curve function to demonstrate the PNT2FDPs.
</summary>
    <author>
      <name>Rozaimi Zakaria</name>
    </author>
    <author>
      <name>Abd. Fatah Wahab</name>
    </author>
    <author>
      <name>R. U. Gobithaasan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: substantial text overlap with arXiv:1304.7868</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">2013 Applied Mathematical Sciences 7 (21-24), Pg.1043-1055</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1305.0001v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1305.0001v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1305.1473v1</id>
    <updated>2013-05-07T11:35:49Z</updated>
    <published>2013-05-07T11:35:49Z</published>
    <title>On the variety of planar spirals and their applications in computer
  aided design</title>
    <summary>  In this paper we discuss the variety of planar spiral segments and their
applications in objects in both the real and artificial world. The discussed
curves with monotonic curvature function are well-known in geometric modelling
and computer aided geometric design as fair curves, and they are very
significant in aesthetic shape modelling. Fair curve segments are used for
two-point G1 and G2 Hermite interpolation, as well as for generating aesthetic
splines.
</summary>
    <author>
      <name>Rushan Ziatdinov</name>
    </author>
    <author>
      <name>Kenjiro T. Miura</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">European Researcher 27(8-2), 1227-1232, 2012</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1305.1473v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1305.1473v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1305.1737v1</id>
    <updated>2013-05-08T07:59:52Z</updated>
    <published>2013-05-08T07:59:52Z</published>
    <title>MC-curves and aesthetic measurements for pseudospiral curve segments</title>
    <summary>  This article studies families of curves with monotonic curvature function
(MC-curves) and their applications in geometric modelling and aesthetic design.
Aesthetic analysis and assessment of the structure and plastic qualities of
pseudospirals, which are curves with monotonic curvature function, are
conducted for the first time in the field of geometric modelling from the
position of technical aesthetics laws. The example of car body surface
modelling with the use of aesthetics splines is given.
</summary>
    <author>
      <name>Rushan Ziatdinov</name>
    </author>
    <author>
      <name>Rifkat I. Nabiyev</name>
    </author>
    <author>
      <name>Kenjiro T. Miura</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Mathematical Design &amp; Technical Aesthetics 1(1), 6-17, 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1305.1737v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1305.1737v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1308.0419v2</id>
    <updated>2014-05-08T18:34:09Z</updated>
    <published>2013-08-02T07:10:47Z</published>
    <title>Inverse Procedural Modeling of Facade Layouts</title>
    <summary>  In this paper, we address the following research problem: How can we generate
a meaningful split grammar that explains a given facade layout? To evaluate if
a grammar is meaningful, we propose a cost function based on the description
length and minimize this cost using an approximate dynamic programming
framework. Our evaluation indicates that our framework extracts meaningful
split grammars that are competitive with those of expert users, while some
users and all competing automatic solutions are less successful.
</summary>
    <author>
      <name>Fuzhang Wu</name>
    </author>
    <author>
      <name>Dong-Ming Yan</name>
    </author>
    <author>
      <name>Weiming Dong</name>
    </author>
    <author>
      <name>Xiaopeng Zhang</name>
    </author>
    <author>
      <name>Peter Wonka</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10</arxiv:comment>
    <link href="http://arxiv.org/abs/1308.0419v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1308.0419v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1308.0869v1</id>
    <updated>2013-08-05T01:56:59Z</updated>
    <published>2013-08-05T01:56:59Z</published>
    <title>A Spline-based Volumetric Data Modeling Framework and Its Applications</title>
    <summary>  In this dissertation, we concentrate on the challenging research issue of
developing a spline-based modeling framework, which converts the conventional
data (e.g., surface meshes) to tensor-product trivariate splines. This
methodology can represent both boundary/volumetric geometry and real volumetric
physical attributes in a compact and continuous fashion. The regular
tensor-product structure enables our new developed methods to be embedded into
the industry standard seamlessly. These properties make our techniques highly
preferable in many physically-based applications including mechanical analysis,
shape deformation and editing, virtual surgery training, etc.
</summary>
    <author>
      <name>Bo Li</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Ph.D thesis, Computer Science Department, Stony Brook University</arxiv:comment>
    <link href="http://arxiv.org/abs/1308.0869v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1308.0869v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1308.1279v9</id>
    <updated>2014-10-30T05:07:47Z</updated>
    <published>2013-08-06T14:15:42Z</published>
    <title>Barycentric Coordinates as Interpolants</title>
    <summary>  Barycentric coordinates are frequently used as interpolants to shade computer
graphics images. A simple equation transforms barycentric coordinates from
screen space into eye space in order to undo the perspective transformation and
permit accurate interpolative shading of texture maps. This technique is
amenable to computation using a block-normalized integer representation.
</summary>
    <author>
      <name>Russell A. Brown</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1308.1279v9" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1308.1279v9" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1309.1917v1</id>
    <updated>2013-09-07T23:21:31Z</updated>
    <published>2013-09-07T23:21:31Z</published>
    <title>Zahir: a Object-Oriented Framework for Computer Graphics</title>
    <summary>  In this article we present Zahir, a framework for experimentation in Computer
Graphics that provides a group of object-oriented base components that take
care of common tasks in rendering techniques and algorithms, specially those of
Non Photo-realistic Rendering (NPR). These components allow developers to
implement rendering techniques and algorithms over static and animated meshes.
Currently, Zahir is being used in a Master's Thesis and as support material in
the undergraduate Computer Graphics course in University of Chile.
</summary>
    <author>
      <name>Eduardo Graells-Garrido</name>
    </author>
    <author>
      <name>María Cecilia Rivara</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Tech report, 2009, Santiago, Chile</arxiv:comment>
    <link href="http://arxiv.org/abs/1309.1917v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1309.1917v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1309.3314v1</id>
    <updated>2013-09-12T21:47:37Z</updated>
    <published>2013-09-12T21:47:37Z</published>
    <title>Progressive Compression of 3D Objects with an Adaptive Quantization</title>
    <summary>  This paper presents a new progressive compression method for triangular
meshes. This method, in fact, is based on a schema of irregular
multi-resolution analysis and is centered on the optimization of the
rate-distortion trade-off. The quantization precision is adapted to each vertex
during the encoding / decoding process to optimize the rate-distortion
compromise. The Optimization of the treated mesh geometry improves the
approximation quality and the compression ratio at each level of resolution.
The experimental results show that the proposed algorithm gives competitive
results compared to the previous works dealing with the rate-distortion
compromise.
</summary>
    <author>
      <name>Zeineb Abderrahim</name>
    </author>
    <author>
      <name>Elhem Techini</name>
    </author>
    <author>
      <name>Mohamed Salim Bouhlel</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 5 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IJCSI Volume 10, Issue 2,No 1, March 2013 , Pages 504-511</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1309.3314v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1309.3314v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1311.7430v1</id>
    <updated>2013-11-28T21:45:10Z</updated>
    <published>2013-11-28T21:45:10Z</published>
    <title>A local Gaussian filter and adaptive morphology as tools for completing
  partially discontinuous curves</title>
    <summary>  This paper presents a method for extraction and analysis of curve--type
structures which consist of disconnected components. Such structures are found
in electron--microscopy (EM) images of metal nanograins, which are widely used
in the field of nanosensor technology.
  The topography of metal nanograins in compound nanomaterials is crucial to
nanosensor characteristics. The method of completing such templates consists of
three steps. In the first step, a local Gaussian filter is used with different
weights for each neighborhood. In the second step, an adaptive morphology
operation is applied to detect the endpoints of curve segments and connect
them. In the last step, pruning is employed to extract a curve which optimally
fits the template.
</summary>
    <author>
      <name>P. Spurek</name>
    </author>
    <author>
      <name>A. Chaikouskaya</name>
    </author>
    <author>
      <name>J. Tabor</name>
    </author>
    <author>
      <name>E. Zając</name>
    </author>
    <link href="http://arxiv.org/abs/1311.7430v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1311.7430v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1406.5431v2</id>
    <updated>2014-06-23T12:03:12Z</updated>
    <published>2014-06-20T15:34:06Z</published>
    <title>Consistently Orienting Facets in Polygon Meshes by Minimizing the
  Dirichlet Energy of Generalized Winding Numbers</title>
    <summary>  Jacobson et al. [JKSH13] hypothesized that the local coherency of the
generalized winding number function could be used to correctly determine
consistent facet orientations in polygon meshes. We report on an approach to
consistently orienting facets in polygon meshes by minimizing the Dirichlet
energy of generalized winding numbers. While the energy can be concisely
formulated and efficiently computed, we found that this approach is
fundamentally flawed and is unfortunately not applicable for most handmade
meshes shared on popular mesh repositories such as Google 3D Warehouse.
</summary>
    <author>
      <name>Kenshi Takayama</name>
    </author>
    <author>
      <name>Alec Jacobson</name>
    </author>
    <author>
      <name>Ladislav Kavan</name>
    </author>
    <author>
      <name>Olga Sorkine-Hornung</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1406.5431v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1406.5431v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1406.7025v1</id>
    <updated>2014-06-26T20:50:34Z</updated>
    <published>2014-06-26T20:50:34Z</published>
    <title>DASS: Detail Aware Sketch-Based Surface Modeling</title>
    <summary>  We present a sketch-based modeling system suitable for detail editing, based
on a multilevel representation for surfaces. The main advantage of this
representation allowing for the control of local (details) and global changes
of the model. We used an adaptive mesh (4-8 mesh) and developed a label theory
to construct a manifold structure, which is responsible for controlling local
editing of the model. The overall shape and global modifications are defined by
a variational implicit surface (Hermite RBF). Our system assembles the manifold
structures to allow the user to add details without changing the overall shape,
as well as edit the overall shape while repositioning details coherently.
</summary>
    <author>
      <name>Emilio Vital Brazil</name>
    </author>
    <link href="http://arxiv.org/abs/1406.7025v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1406.7025v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1409.5024v1</id>
    <updated>2014-09-01T00:46:26Z</updated>
    <published>2014-09-01T00:46:26Z</published>
    <title>Comparative Study of Geometric and Image Based Modelling and Rendering
  Techniques</title>
    <summary>  This is a comparative study of the traditional 3D computer graphics technique
of geometric modelling and image-based rendering techniques that were surveyed
and implemented.We have discussed the classifications and representative
methods of both the techniques. The study has shown that there is a strong
continuum between both the techniques and a hybrid of the two is most suitable
for further implementations.This hybridisation study is underway to create
models of real life situations and provide disaster management training.
</summary>
    <author>
      <name>Agrima Seth</name>
    </author>
    <author>
      <name>Deepak Mishra</name>
    </author>
    <link href="http://arxiv.org/abs/1409.5024v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1409.5024v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1501.03605v1</id>
    <updated>2015-01-15T09:16:26Z</updated>
    <published>2015-01-15T09:16:26Z</published>
    <title>Feature Lines for Illustrating Medical Surface Models: Mathematical
  Background and Survey</title>
    <summary>  This paper provides a tutorial and survey for a specific kind of illustrative
visualization technique: feature lines. We examine different feature line
methods. For this, we provide the differential geometry behind these concepts
and adapt this mathematical field to the discrete differential geometry. All
discrete differential geometry terms are explained for triangulated surface
meshes. These utilities serve as basis for the feature line methods. We provide
the reader with all knowledge to re-implement every feature line method.
Furthermore, we summarize the methods and suggest a guideline for which kind of
surface which feature line algorithm is best suited. Our work is motivated by,
but not restricted to, medical and biological surface models.
</summary>
    <author>
      <name>Kai Lawonn</name>
    </author>
    <author>
      <name>Bernhard Preim</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">33 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1501.03605v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1501.03605v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1501.06364v1</id>
    <updated>2015-01-26T12:38:21Z</updated>
    <published>2015-01-26T12:38:21Z</published>
    <title>GPU Programming - Speeding Up the 3D Surface Generator VESTA</title>
    <summary>  The novel "Volume-Enclosing Surface exTraction Algorithm" (VESTA) generates
triangular isosurfaces from computed tomography volumetric images and/or
three-dimensional (3D) simulation data. Here, we present various benchmarks for
GPU-based code implementations of both VESTA and the current state-of-the-art
Marching Cubes Algorithm (MCA). One major result of this study is that VESTA
runs significantly faster than the MCA.
</summary>
    <author>
      <name>B. R. Schlei</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.15120/GR-2015-1-FG-GENERAL-42</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.15120/GR-2015-1-FG-GENERAL-42" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">1 page, 1 figure, submitted contribution to the GSI Scientific Report
  2014</arxiv:comment>
    <link href="http://arxiv.org/abs/1501.06364v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1501.06364v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.04232v1</id>
    <updated>2015-02-14T17:42:02Z</updated>
    <published>2015-02-14T17:42:02Z</published>
    <title>Sketch-based Shape Retrieval using Pyramid-of-Parts</title>
    <summary>  We present a multi-scale approach to sketch-based shape retrieval. It is
based on a novel multi-scale shape descriptor called Pyramidof- Parts, which
encodes the features and spatial relationship of the semantic parts of query
sketches. The same descriptor can also be used to represent 2D projected views
of 3D shapes, allowing effective matching of query sketches with 3D shapes
across multiple scales. Experimental results show that the proposed method
outperforms the state-of-the-art method, whether the sketch segmentation
information is obtained manually or automatically by considering each stroke as
a semantic part.
</summary>
    <author>
      <name>Changqing Zou</name>
    </author>
    <author>
      <name>Zhe Huang</name>
    </author>
    <author>
      <name>Rynson W. H. Lau</name>
    </author>
    <author>
      <name>Jianzhuang Liu</name>
    </author>
    <author>
      <name>Hongbo Fu</name>
    </author>
    <link href="http://arxiv.org/abs/1502.04232v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.04232v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.06995v1</id>
    <updated>2015-03-24T11:42:43Z</updated>
    <published>2015-03-24T11:42:43Z</published>
    <title>Interpolation of a spline developable surface between a curve and two
  rulings</title>
    <summary>  In this paper we address the problem of interpolating a spline developable
patch bounded by a given spline curve and the first and the last rulings of the
developable surface. In order to complete the boundary of the patch a second
spline curve is to be given. Up to now this interpolation problem could be
solved, but without the possibility of choosing both endpoints for the rulings.
We circumvent such difficulty here by resorting to degree elevation of the
developable surface. This is useful not only to solve this problem, but also
other problems dealing with triangular developable patches.
</summary>
    <author>
      <name>A. Cantón</name>
    </author>
    <author>
      <name>L. Fernández-Jambrina</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1631/FITEE.14a0210</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1631/FITEE.14a0210" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Frontiers of Information Technology &amp; Electronic Engineering 16,
  173-190 (2015)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1503.06995v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.06995v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65D17, 68U07" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.01379v2</id>
    <updated>2015-07-29T20:57:06Z</updated>
    <published>2015-04-06T15:53:09Z</published>
    <title>Preprint Big City 3D Visual Analysis</title>
    <summary>  This is the preprint version of our paper on EUROGRAPHICS 2015. A big city
visual analysis platform based on Web Virtual Reality Geographical Information
System (WEBVRGIS) is presented. Extensive model editing functions and spatial
analysis functions are available, including terrain analysis, spatial analysis,
sunlight analysis, traffic analysis, population analysis and community
analysis.
</summary>
    <author>
      <name>Zhihan Lv</name>
    </author>
    <author>
      <name>Xiaoming Li</name>
    </author>
    <author>
      <name>Baoyun Zhang</name>
    </author>
    <author>
      <name>Weixi Wang</name>
    </author>
    <author>
      <name>Shengzhong Feng</name>
    </author>
    <author>
      <name>Jinxing Hu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This is the preprint version of our paper on EUROGRAPHICS 2015</arxiv:comment>
    <link href="http://arxiv.org/abs/1504.01379v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.01379v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.02744v1</id>
    <updated>2015-04-10T17:42:14Z</updated>
    <published>2015-04-10T17:42:14Z</published>
    <title>Real-time Tool for Affine Transformations of Two Dimensional IFS
  Fractals</title>
    <summary>  This work introduces a novel tool for interactive, real-time transformations
of two dimensional IFS fractals. We assign barycentric coordinates (relative to
an arbitrary affine basis of $\mathbb{R}^2$) to the points that constitute the
image of a fractal. The tool uses some of the nice properties of the
barycentric coordinates, enabling any affine transformation of the basis, done
by click-and-drag, to be immediately followed by the same affine transformation
of the IFS fractal attractor. In order to have a better control over the
fractal, as affine basis we use a kind of minimal simplex that contains the
attractor. We give theoretical grounds of the tool and then the software
application.
</summary>
    <author>
      <name>Elena Hadzieva</name>
    </author>
    <author>
      <name>Marija Shuminoska</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1504.02744v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.02744v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="28A80, 65D17" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.03151v1</id>
    <updated>2015-04-13T12:39:50Z</updated>
    <published>2015-04-13T12:39:50Z</published>
    <title>Massively Parallel Ray Tracing Algorithm Using GPU</title>
    <summary>  Ray tracing is a technique for generating an image by tracing the path of
light through pixels in an image plane and simulating the effects of
high-quality global illumination at a heavy computational cost. Because of the
high computation complexity, it can't reach the requirement of real-time
rendering. The emergence of many-core architectures, makes it possible to
reduce significantly the running time of ray tracing algorithm by employing the
powerful ability of floating point computation. In this paper, a new GPU
implementation and optimization of the ray tracing to accelerate the rendering
process is presented.
</summary>
    <author>
      <name>Yutong Qin</name>
    </author>
    <author>
      <name>Jianbiao Lin</name>
    </author>
    <author>
      <name>Xiang Huang</name>
    </author>
    <link href="http://arxiv.org/abs/1504.03151v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.03151v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.00021v1</id>
    <updated>2015-05-29T20:27:11Z</updated>
    <published>2015-05-29T20:27:11Z</published>
    <title>Variance Analysis for Monte Carlo Integration: A
  Representation-Theoretic Perspective</title>
    <summary>  In this report, we revisit the work of Pilleboue et al. [2015], providing a
representation-theoretic derivation of the closed-form expression for the
expected value and variance in homogeneous Monte Carlo integration. We show
that the results obtained for the variance estimation of Monte Carlo
integration on the torus, the sphere, and Euclidean space can be formulated as
specific instances of a more general theory. We review the related
representation theory and show how it can be used to derive a closed-form
solution.
</summary>
    <author>
      <name>Michael Kazhdan</name>
    </author>
    <author>
      <name>Gurprit Singh</name>
    </author>
    <author>
      <name>Adrien Pilleboue</name>
    </author>
    <author>
      <name>David Coeurjolly</name>
    </author>
    <author>
      <name>Victor Ostromoukhov</name>
    </author>
    <link href="http://arxiv.org/abs/1506.00021v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.00021v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.06968v1</id>
    <updated>2015-06-23T12:22:32Z</updated>
    <published>2015-06-23T12:22:32Z</published>
    <title>A Survey on Distributed Visualization Techniques over Clusters of
  Personal Computers</title>
    <summary>  In the last years, Distributed Visualization over Personal Computer (PC)
clusters has become important for research and industrial communities. They
have made large-scale visualizations practical and more accessible. In this
work we survey Distributed Visualization techniques aiming at compiling last
decade's literature on the use of PC clusters as suitable alternatives to
high-end workstations. We review the topic by defining basic concepts,
enumerating system requirements and implementation challenges, and presenting
up-to-date methodologies. Our work fulfills the needs of newcomers and seasoned
professionals as an introductory compilation at the same time that it can help
experienced personnel by organizing ideas.
</summary>
    <author>
      <name>Jose Rodrigues</name>
    </author>
    <author>
      <name>Andre Balan</name>
    </author>
    <author>
      <name>Luciana Zaina</name>
    </author>
    <author>
      <name>Agma Traina</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">INFOCOMP Journal of Computer Science, 2009, ISSN: 1807-4545, vol
  8: 4. 79-90</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1506.06968v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.06968v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.05290v2</id>
    <updated>2016-07-06T01:24:42Z</updated>
    <published>2015-07-19T13:53:47Z</published>
    <title>A concise parametrisation of affine transformation</title>
    <summary>  Good parametrisations of affine transformations are essential to
interpolation, deformation, and analysis of shape, motion, and animation. It
has been one of the central research topics in computer graphics. However,
there is no single perfect method and each one has both advantages and
disadvantages. In this paper, we propose a novel parametrisation of affine
transformations, which is a generalisation to or an improvement of existing
methods. Our method adds yet another choice to the existing toolbox and shows
better performance in some applications. A C++ implementation is available to
make our framework ready to use in various applications.
</summary>
    <author>
      <name>Shizuo Kaji</name>
    </author>
    <author>
      <name>Hiroyuki Ochiai</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">errors corrected, a section on Frechet mean removed</arxiv:comment>
    <link href="http://arxiv.org/abs/1507.05290v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.05290v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68U05, 65D18, 65F60, 15A16" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.5; I.3.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.07593v1</id>
    <updated>2015-08-30T16:12:59Z</updated>
    <published>2015-08-30T16:12:59Z</published>
    <title>The Prose Storyboard Language: A Tool for Annotating and Directing
  Movies</title>
    <summary>  The prose storyboard language is a formal language for describing movies shot
by shot, where each shot is described with a unique sentence. The language uses
a simple syntax and limited vocabulary borrowed from working practices in
traditional movie-making, and is intended to be readable both by machines and
humans. The language is designed to serve as a high-level user interface for
intelligent cinematography and editing systems.
</summary>
    <author>
      <name>Remi Ronfard</name>
    </author>
    <author>
      <name>Vineet Gandhi</name>
    </author>
    <author>
      <name>Laurent Boiron</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, presented at Workshop on Intelligent Cinematography and
  Editing (WICED'2013)</arxiv:comment>
    <link href="http://arxiv.org/abs/1508.07593v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.07593v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.07932v1</id>
    <updated>2015-11-25T01:41:08Z</updated>
    <published>2015-11-25T01:41:08Z</published>
    <title>Embedding of Hypercube into Cylinder</title>
    <summary>  Task mapping in modern high performance parallel computers can be modeled as
a graph embedding problem, which simulates the mapping as embedding one graph
into another and try to find the minimum wirelength for the mapping. Though
embedding problems have been considered for several regular graphs, such as
hypercubes into grids, binary trees into grids, et al, it is still an open
problem for hypercubes into cylinders. In this paper, we consider the problem
of embedding hypercubes into cylinders to minimize the wirelength. We obtain
the exact wirelength formula of embedding hypercube $Q^r$ into cylinder
$C_{2^3}\times P_{2^{r-3}}$ with $r\ge3$.
</summary>
    <author>
      <name>Weixing Ji</name>
    </author>
    <author>
      <name>Qinghui Liu</name>
    </author>
    <author>
      <name>Guizhen Wang</name>
    </author>
    <author>
      <name>ZhuoJia Shen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1511.07932v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.07932v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.08118v1</id>
    <updated>2015-11-25T17:02:20Z</updated>
    <published>2015-11-25T17:02:20Z</published>
    <title>SlicerPET: A workflow based software module for PET/CT guided needle
  biopsy</title>
    <summary>  Biopsy is commonly used to confirm cancer diagnosis when radiologically
indicated. Given the ability of PET to localize malignancies in heterogeneous
tumors and tumors that do not have a CT correlate, PET/CT guided biopsy may
improve the diagnostic yield of biopsies. To facilitate PET/CT guided needle
biopsy, we developed a workflow that allows us to bring PET image guidance into
the interventional CT suite. In this abstract, we present SlicerPET, a
user-friendly workflow based module developed using open source software
libraries to guide needle biopsy in the interventional suite.
</summary>
    <author>
      <name>Dženan Zukić</name>
    </author>
    <author>
      <name>Julien Finet</name>
    </author>
    <author>
      <name>Emmanuel Wilson</name>
    </author>
    <author>
      <name>Filip Banovac</name>
    </author>
    <author>
      <name>Giuseppe Esposito</name>
    </author>
    <author>
      <name>Kevin Cleary</name>
    </author>
    <author>
      <name>Andinet Enquobahrie</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s11548-015-1213-2</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s11548-015-1213-2" rel="related"/>
    <link href="http://arxiv.org/abs/1511.08118v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.08118v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.4.9" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.01754v1</id>
    <updated>2016-01-08T02:56:57Z</updated>
    <published>2016-01-08T02:56:57Z</published>
    <title>Anti-commutative Dual Complex Numbers and 2D Rigid Transformation</title>
    <summary>  We introduce a new presentation of the two dimensional rigid transformation
which is more concise and efficient than the standard matrix presentation. By
modifying the ordinary dual number construction for the complex numbers, we
define the ring of the anti-commutative dual complex numbers, which
parametrizes two dimensional rotation and translation all together. With this
presentation, one can easily interpolate or blend two or more rigid
transformations at a low computational cost. We developed a library for C++
with the MIT-licensed source code and demonstrate its facility by an
interactive deformation tool developed for iPad.
</summary>
    <author>
      <name>Genki Matsuda</name>
    </author>
    <author>
      <name>Shizuo Kaji</name>
    </author>
    <author>
      <name>Hiroyuki Ochiai</name>
    </author>
    <link href="http://arxiv.org/abs/1601.01754v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.01754v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.5; I.3.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.04816v1</id>
    <updated>2016-01-19T07:48:57Z</updated>
    <published>2016-01-19T07:48:57Z</published>
    <title>Tetrisation of triangular meshes and its application in shape blending</title>
    <summary>  The As-Rigid-As-Possible (ARAP) shape deformation framework is a versatile
technique for morphing, surface modelling, and mesh editing. We discuss an
improvement of the ARAP framework in a few aspects: 1. Given a triangular mesh
in 3D space, we introduce a method to associate a tetrahedral structure, which
encodes the geometry of the original mesh. 2. We use a Lie algebra based method
to interpolate local transformation, which provides better handling of rotation
with large angle. 3. We propose a new error function to compile local
transformations into a global piecewise linear map, which is rotation invariant
and easy to minimise. We implemented a shape blender based on our algorithm and
its MIT licensed source code is available online.
</summary>
    <author>
      <name>Shizuo Kaji</name>
    </author>
    <link href="http://arxiv.org/abs/1601.04816v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.04816v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.5; I.3.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1602.01224v2</id>
    <updated>2016-09-16T10:41:05Z</updated>
    <published>2016-02-03T08:24:21Z</published>
    <title>Smooth surface interpolation using patches with rational offsets</title>
    <summary>  We present a new method for the interpolation of given data points and
associated normals with surface parametric patches with rational normal fields.
We give some arguments why a dual approach is the most convenient for these
surfaces, which are traditionally called Pythagorean normal vector (PN)
surfaces. Our construction is based on the isotropic model of the dual space to
which the original data are pushed. Then the bicubic Coons patches are
constructed in the isotropic space and then pulled back to the standard three
dimensional space. As a result we obtain the patch construction which is
completely local and produces surfaces with the global G1~continuity.
</summary>
    <author>
      <name>Miroslav Lávička</name>
    </author>
    <author>
      <name>Zbyněk Šír</name>
    </author>
    <author>
      <name>Jan Vršek</name>
    </author>
    <link href="http://arxiv.org/abs/1602.01224v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1602.01224v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1602.06239v1</id>
    <updated>2016-02-04T15:54:02Z</updated>
    <published>2016-02-04T15:54:02Z</published>
    <title>On a recursive construction of circular paths and the search for $π$
  on the integer lattice $\mathbb{Z}^2$</title>
    <summary>  Digital circles not only play an important role in various technological
settings, but also provide a lively playground for more fundamental
number-theoretical questions. In this paper, we present a new recursive
algorithm for the construction of digital circles on the integer lattice
$\mathbb{Z}^2$, which makes sole use of the signum function. By briefly
elaborating on the nature of discretization of circular paths, we then find
that this algorithm recovers, in a space endowed with $\ell^1$-norm, the
defining constant $\pi$ of a circle in $\mathbb{R}^2$.
</summary>
    <author>
      <name>Michelle Rudolph-Lilith</name>
    </author>
    <link href="http://arxiv.org/abs/1602.06239v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1602.06239v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="97N70, 68R10, 52C05, 11H06" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.02013v1</id>
    <updated>2016-04-06T05:20:04Z</updated>
    <published>2016-04-06T05:20:04Z</published>
    <title>Keyboard Based Control of Four Dimensional Rotations</title>
    <summary>  Aiming at applications to the scientific visualization of three dimensional
simulations with time evolution, a keyboard based control method to specify
rotations in four dimensions is proposed. It is known that four dimensional
rotations are generally so-called double rotations, and a double rotation is a
combination of simultaneously applied two simple rotations. The proposed method
can specify both the simple and double rotations by single key typings of the
keyboard. The method is tested in visualizations of a regular pentachoron in
four dimensional space by a hyperplane slicing.
</summary>
    <author>
      <name>Akira Kageyama</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted for publication in Journal of Visualization</arxiv:comment>
    <link href="http://arxiv.org/abs/1604.02013v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.02013v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.02483v2</id>
    <updated>2016-04-13T00:16:24Z</updated>
    <published>2016-04-08T20:59:46Z</published>
    <title>On the Hessian of Shape Matching Energy</title>
    <summary>  In this technical report we derive the analytic form of the Hessian matrix
for shape matching energy. Shape matching is a useful technique for meshless
deformation, which can be easily combined with multiple techniques in real-time
dynamics. Nevertheless, it has been rarely applied in scenarios where implicit
integrators are required, and hence strong viscous damping effect, though
popular in simulation systems nowadays, is forbidden for shape matching. The
reason lies in the difficulty to derive the Hessian matrix of the shape
matching energy. Computing the Hessian matrix correctly, and stably, is the key
to more broadly application of shape matching in implicitly-integrated systems.
</summary>
    <author>
      <name>Yun Fei</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 1 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1604.02483v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.02483v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.08848v1</id>
    <updated>2016-04-29T14:26:55Z</updated>
    <published>2016-04-29T14:26:55Z</published>
    <title>Augmented Reality Oculus Rift</title>
    <summary>  This paper covers the whole process of developing an Augmented Reality
Stereoscopig Render Engine for the Oculus Rift. To capture the real world in
form of a camera stream, two cameras with fish-eye lenses had to be installed
on the Oculus Rift DK1 hardware. The idea was inspired by Steptoe
\cite{steptoe2014presence}. After the introduction, a theoretical part covers
all the most neccessary elements to achieve an AR System for the Oculus Rift,
following the implementation part where the code from the AR Stereo Engine is
explained in more detail. A short conclusion section shows some results,
reflects some experiences and in the final chapter some future works will be
discussed. The project can be accessed via the git repository
https://github.com/MaXvanHeLL/ARift.git.
</summary>
    <author>
      <name>Markus Höll</name>
    </author>
    <author>
      <name>Nikolaus Heran</name>
    </author>
    <author>
      <name>Vincent Lepetit</name>
    </author>
    <link href="http://arxiv.org/abs/1604.08848v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.08848v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.09451v1</id>
    <updated>2016-05-31T00:33:04Z</updated>
    <published>2016-05-31T00:33:04Z</published>
    <title>Quantitative Analysis of Saliency Models</title>
    <summary>  Previous saliency detection research required the reader to evaluate
performance qualitatively, based on renderings of saliency maps on a few
shapes. This qualitative approach meant it was unclear which saliency models
were better, or how well they compared to human perception. This paper provides
a quantitative evaluation framework that addresses this issue. In the first
quantitative analysis of 3D computational saliency models, we evaluate four
computational saliency models and two baseline models against ground-truth
saliency collected in previous work.
</summary>
    <author>
      <name>Flora Ponjou Tasse</name>
    </author>
    <author>
      <name>Jiří Kosinka</name>
    </author>
    <author>
      <name>Neil Anthony Dodgson</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1605.09451v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.09451v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.04953v1</id>
    <updated>2016-08-17T13:07:27Z</updated>
    <published>2016-08-17T13:07:27Z</published>
    <title>A Perceptual Aesthetics Measure for 3D Shapes</title>
    <summary>  While the problem of image aesthetics has been well explored, the study of 3D
shape aesthetics has focused on specific manually defined features. In this
paper, we learn an aesthetics measure for 3D shapes autonomously from raw voxel
data and without manually-crafted features by leveraging the strength of deep
learning. We collect data from humans on their aesthetics preferences for
various 3D shape classes. We take a deep convolutional 3D shape ranking
approach to compute a measure that gives an aesthetics score for a 3D shape. We
demonstrate our approach with various types of shapes and for applications such
as aesthetics-based visualization, search, and scene composition.
</summary>
    <author>
      <name>Kapil Dev</name>
    </author>
    <author>
      <name>Manfred Lau</name>
    </author>
    <author>
      <name>Ligang Liu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 Pages, 8 Figures, Conference</arxiv:comment>
    <link href="http://arxiv.org/abs/1608.04953v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.04953v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.05344v1</id>
    <updated>2016-09-17T14:43:17Z</updated>
    <published>2016-09-17T14:43:17Z</published>
    <title>Optimisations for Real-Time Volumetric Cloudscapes</title>
    <summary>  Volumetric cloudscapes are prohibitively expensive to render in real time
without extensive optimisations. Previous approaches render the clouds to an
offscreen buffer at one quarter resolution and update a fraction of the pixels
per frame, drawing the remaining pixels by temporal reprojection. We present an
alternative approach, reducing the number of raymarching steps and adding a
randomly jittered offset to the raymarch. We use an analytical integration
technique to make results consistent with a lower number of raymarching steps.
To remove noise from the resulting image we apply a temporal anti-aliasing
implementation. The result is a technique producing visually similar results
with 1/16 the number of steps.
</summary>
    <author>
      <name>Alastair Toft</name>
    </author>
    <author>
      <name>Huw Bowles</name>
    </author>
    <author>
      <name>Daniel Zimmermann</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1609.05344v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.05344v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1610.02769v1</id>
    <updated>2016-10-10T03:57:40Z</updated>
    <published>2016-10-10T03:57:40Z</published>
    <title>Inverse Diffusion Curves using Shape Optimization</title>
    <summary>  The inverse diffusion curve problem focuses on automatic creation of
diffusion curve images that resemble user provided color fields. This problem
is challenging since the 1D curves have a nonlinear and global impact on
resulting color fields via a partial differential equation (PDE). We introduce
a new approach complementary to previous methods by optimizing curve geometry.
In particular, we propose a novel iterative algorithm based on the theory of
shape derivatives. The resulting diffusion curves are clean and well-shaped,
and the final image closely approximates the input. Our method provides a
user-controlled parameter to regularize curve complexity, and generalizes to
handle input color fields represented in a variety of formats.
</summary>
    <author>
      <name>Shuang Zhao</name>
    </author>
    <author>
      <name>Fredo Durand</name>
    </author>
    <author>
      <name>Changxi Zheng</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1610.02769v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1610.02769v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1610.03525v2</id>
    <updated>2016-11-02T13:47:38Z</updated>
    <published>2016-10-11T20:51:48Z</published>
    <title>Polynomial method for Procedural Terrain Generation</title>
    <summary>  A systematic fractal brownian motion approach is proposed for generating
coherent noise, aiming at procedurally generating realistic terrain and
textures. Two models are tested and compared to Perlin noise method for
two-dimensional height map generation. A fractal analysis is performed in order
to compare fractal behaviour of generated data to real terrain coastlines from
the point of view of fractal dimension. Performance analysis show that one of
the described schemes requires half as many primitive operations than Perlin
noise while producing data of equivalent quality.
</summary>
    <author>
      <name>Yann Thorimbert</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 9 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1610.03525v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1610.03525v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1610.04281v1</id>
    <updated>2016-10-13T22:32:08Z</updated>
    <published>2016-10-13T22:32:08Z</published>
    <title>Augmented Reality with Hololens: Experiential Architectures Embedded in
  the Real World</title>
    <summary>  Early hands-on experiences with the Microsoft Hololens augmented/mixed
reality device are reported and discussed, with a general aim of exploring
basic 3D visualization. A range of usage cases are tested, including data
visualization and immersive data spaces, in-situ visualization of 3D models and
full scale architectural form visualization. Ultimately, the Hololens is found
to provide a remarkable tool for moving from traditional visualization of 3D
objects on a 2D screen, to fully experiential 3D visualizations embedded in the
real world.
</summary>
    <author>
      <name>Paul Hockett</name>
    </author>
    <author>
      <name>Tim Ingleby</name>
    </author>
    <link href="http://arxiv.org/abs/1610.04281v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1610.04281v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1610.09988v1</id>
    <updated>2016-10-31T15:56:30Z</updated>
    <published>2016-10-31T15:56:30Z</published>
    <title>Selecting the Best Quadrilateral Mesh for Given Planar Shape</title>
    <summary>  The problem of mesh matching is addressed in this work. For a given n-sided
planar region bounded by one loop of n polylines we are selecting optimal
quadrilateral mesh from existing catalogue of meshes. The formulation of
matching between planar shape and quadrilateral mesh from the catalogue is
based on the problem of finding longest common subsequence (LCS). Theoretical
foundation of mesh matching method is provided. Suggested method represents a
viable technique for selecting best mesh for planar region and stepping stone
for further parametrization of the region.
</summary>
    <author>
      <name>Petra Surynkova</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1610.09988v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1610.09988v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.01944v2</id>
    <updated>2017-01-23T22:00:34Z</updated>
    <published>2016-12-06T18:42:44Z</published>
    <title>Porous Structure Design in Tissue Engineering Using Anisotropic Radial
  Basis Function</title>
    <summary>  Development of additive manufacturing in last decade greatly improves tissue
engineering. During the manufacturing of porous scaffold, simplified but
functionally equivalent models are getting focused for practically reasons.
Scaffolds can be classified into regular porous scaffolds and irregular porous
scaffolds. Several methodologies are developed to design these scaffolds. A
novel method is proposed in this paper using anisotropic radial basis function
(ARBF) interpolation. This is method uses geometric models such as volumetric
meshes as input and proves to be flexible because geometric models are able to
capture the characteristics of complex tissues easily. Moreover, this method is
straightforward and easy to implement.
</summary>
    <author>
      <name>Ke Liu</name>
    </author>
    <author>
      <name>Ye Guo</name>
    </author>
    <author>
      <name>Zeyun Yu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Computer Science, University of Wisconsin Milwaukee</arxiv:comment>
    <link href="http://arxiv.org/abs/1612.01944v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.01944v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.05064v1</id>
    <updated>2016-12-15T13:52:30Z</updated>
    <published>2016-12-15T13:52:30Z</published>
    <title>Orthogonal Edge Routing for the EditLens</title>
    <summary>  The EditLens is an interactive lens technique that supports the editing of
graphs. The user can insert, update, or delete nodes and edges while
maintaining an already existing layout of the graph. For the nodes and edges
that are affected by an edit operation, the EditLens suggests suitable
locations and routes, which the user can accept or adjust. For this purpose,
the EditLens requires an efficient routing algorithm that can compute results
at interactive framerates. Existing algorithms cannot fully satisfy the needs
of the EditLens. This paper describes a novel algorithm that can compute
orthogonal edge routes for incremental edit operations of graphs. Tests
indicate that, in general, the algorithm is better than alternative solutions.
</summary>
    <author>
      <name>Stefan Gladisch</name>
    </author>
    <author>
      <name>Valerius Weigandt</name>
    </author>
    <author>
      <name>Heidrun Schumann</name>
    </author>
    <author>
      <name>Christian Tominski</name>
    </author>
    <link href="http://arxiv.org/abs/1612.05064v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.05064v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.07353v1</id>
    <updated>2016-11-17T02:11:59Z</updated>
    <published>2016-11-17T02:11:59Z</published>
    <title>Data-driven Shoulder Inverse Kinematics</title>
    <summary>  This paper proposes a shoulder inverse kinematics (IK) technique. Shoulder
complex is comprised of the sternum, clavicle, ribs, scapula, humerus, and four
joints. The shoulder complex shows specific motion pattern, such as Scapulo
humeral rhythm. As a result, if a motion of the shoulder isgenerated without
the knowledge of kinesiology, it will be seen as un-natural. The proposed
technique generates motion of the shoulder complex about the orientation of the
upper arm by interpolating the measurement data. The shoulder IK method allows
novice animators to generate natural shoulder motions easily. As a result, this
technique improves the quality of character animation.
</summary>
    <author>
      <name>YoungBeom Kim</name>
    </author>
    <author>
      <name>Byung-Ha Park</name>
    </author>
    <author>
      <name>Kwang-Mo Jung</name>
    </author>
    <author>
      <name>JungHyun Han</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 14 figures, IJCGA</arxiv:comment>
    <link href="http://arxiv.org/abs/1612.07353v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.07353v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.04383v1</id>
    <updated>2017-01-16T18:20:32Z</updated>
    <published>2017-01-16T18:20:32Z</published>
    <title>Automatic Knot Adjustment Using Dolphin Echolocation Algorithm for
  B-Spline Curve Approximation</title>
    <summary>  In this paper, a new approach to solve the cubic B-spline curve fitting
problem is presented based on a meta-heuristic algorithm called " dolphin
echolocation ". The method minimizes the proximity error value of the selected
nodes that measured using the least squares method and the Euclidean distance
method of the new curve generated by the reverse engineering. The results of
the proposed method are compared with the genetic algorithm. As a result, this
new method seems to be successful.
</summary>
    <author>
      <name>Hasan Ali Akyürek</name>
    </author>
    <author>
      <name>Erkan Ülker</name>
    </author>
    <author>
      <name>Barış Koçer</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The Journal of MacroTrends in Technology and Innovation, Vol 4. Issue
  1. 2016</arxiv:comment>
    <link href="http://arxiv.org/abs/1701.04383v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.04383v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.05754v1</id>
    <updated>2017-01-20T10:58:20Z</updated>
    <published>2017-01-20T10:58:20Z</published>
    <title>User-guided free-form asset modelling</title>
    <summary>  In this paper a new system for piecewise primitive surface recovery on point
clouds is presented, which allows a novice user to sketch areas of interest in
order to guide the fitting process. The algorithm is demonstrated against a
benchmark technique for autonomous surface fitting, and, contrasted against
existing literature in user guided surface recovery, with empirical evidence.
It is concluded that the system is an improvement to the current documented
literature for its visual quality when modelling objects which are composed of
piecewise primitive shapes, and, in its ability to fill large holes on occluded
surfaces using free-form input.
</summary>
    <author>
      <name>Daniel Beale</name>
    </author>
    <link href="http://arxiv.org/abs/1701.05754v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.05754v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1702.01537v1</id>
    <updated>2017-02-06T09:24:02Z</updated>
    <published>2017-02-06T09:24:02Z</published>
    <title>Conceptual and algorithmic development of Pseudo 3D Graphics and Video
  Content Visualization</title>
    <summary>  The article presents a general concept of the organization of pseudo three
dimension visualization of graphics and video content for three dimension
visualization systems. The steps of algorithms for solving the problem of
synthesis of three dimension stereo images based on two dimension images are
introduced. The features of synthesis organization of standard format of three
dimension stereo frame are presented. Moreover, the performed experimental
simulation for generating complete stereoframes and the results of its time
complexity are shown. Keywords:Three dimension visualization, pseudo three
dimension stereo, a stereo pair, three dimension stereo format, algorithm,
modeling, time complexity.
</summary>
    <author>
      <name>Aladdein M. Amro</name>
    </author>
    <author>
      <name>S. A. Zori</name>
    </author>
    <author>
      <name>Anas M. Al-Oraiqat</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 10 Figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Publisher for Advanced Scientific Journals 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1702.01537v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1702.01537v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1702.02878v1</id>
    <updated>2017-02-09T16:23:36Z</updated>
    <published>2017-02-09T16:23:36Z</published>
    <title>Bezier developable surfaces</title>
    <summary>  In this paper we address the issue of designing developable surfaces with
Bezier patches. We show that developable surfaces with a polynomial edge of
regression are the set of developable surfaces which can be constructed with
Aumann's algorithm. We also obtain the set of polynomial developable surfaces
which can be constructed using general polynomial curves. The conclusions can
be extended to spline surfaces as well.
</summary>
    <author>
      <name>L. Fernández-Jambrina</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.cagd.2017.02.001</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.cagd.2017.02.001" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">26 pages, 10 figures, Computer Aided Geometric Design special number
  in memoriam Professor Gerald Farin</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Computer Aided Geometric Design 55, 15-28 (2017)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1702.02878v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1702.02878v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65D17" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1704.04038v1</id>
    <updated>2017-04-13T09:03:28Z</updated>
    <published>2017-04-13T09:03:28Z</published>
    <title>Denoising a Point Cloud for Surface Reconstruction</title>
    <summary>  Surface reconstruction from an unorganized point cloud is an important
problem due to its widespread applications. White noise, possibly clustered
outliers, and noisy perturbation may be generated when a point cloud is sampled
from a surface. Most existing methods handle limited amount of noise. We
develop a method to denoise a point cloud so that the users can run their
surface reconstruction codes or perform other analyses afterwards. Our
experiments demonstrate that our method is computationally efficient and it has
significantly better noise handling ability than several existing surface
reconstruction codes.
</summary>
    <author>
      <name>Siu-Wing Cheng</name>
    </author>
    <author>
      <name>Man-Kit Lau</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1704.04038v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1704.04038v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1704.04456v1</id>
    <updated>2017-04-14T15:28:37Z</updated>
    <published>2017-04-14T15:28:37Z</published>
    <title>Liquid Splash Modeling with Neural Networks</title>
    <summary>  This paper proposes a new data-driven approach for modeling detailed splashes
for liquid simulations with neural networks. Our model learns to generate
small-scale splash detail for fluid-implicit-particle methods using training
data acquired from physically accurate, high-resolution simulations. We use
neural networks to model the regression of splash formation using a classifier
together with a velocity modification term. More specifically, we employ a
heteroscedastic model for the velocity updates. Our simulation results
demonstrate that our model significantly improves visual fidelity with a large
amount of realistic droplet formation and yields splash detail much more
efficiently than finer discretizations. We show this for two different spatial
scales and simulation setups.
</summary>
    <author>
      <name>Kiwon Um</name>
    </author>
    <author>
      <name>Xiangyu Hu</name>
    </author>
    <author>
      <name>Nils Thuerey</name>
    </author>
    <link href="http://arxiv.org/abs/1704.04456v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1704.04456v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.02422v1</id>
    <updated>2017-05-06T00:25:31Z</updated>
    <published>2017-05-06T00:25:31Z</published>
    <title>On Discrete Conformal Seamless Similarity Maps</title>
    <summary>  An algorithm for the computation of global discrete conformal
parametrizations with prescribed global holonomy signatures for triangle meshes
was recently described in [Campen and Zorin 2017]. In this paper we provide a
detailed analysis of convergence and correctness of this algorithm. We
generalize and extend ideas of [Springborn et al. 2008] to show a connection of
the algorithm to Newton's algorithm applied to solving the system of
constraints on angles in the parametric domain, and demonstrate that this
system can be obtained as a gradient of a convex energy.
</summary>
    <author>
      <name>Marcel Campen</name>
    </author>
    <author>
      <name>Denis Zorin</name>
    </author>
    <link href="http://arxiv.org/abs/1705.02422v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.02422v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.05508v1</id>
    <updated>2017-05-16T02:58:44Z</updated>
    <published>2017-05-16T02:58:44Z</published>
    <title>Automated Body Structure Extraction from Arbitrary 3D Mesh</title>
    <summary>  This paper presents an automated method for 3D character skeleton extraction
that can be applied for generic 3D shapes. Our work is motivated by the
skeleton-based prior work on automatic rigging focused on skeleton extraction
and can automatically aligns the extracted structure to fit the 3D shape of the
given 3D mesh. The body mesh can be subsequently skinned based on the extracted
skeleton and thus enables rigging process. In the experiment, we apply public
dataset to drive the estimated skeleton from different body shapes, as well as
the real data obtained from 3D scanning systems. Satisfactory results are
obtained compared to the existing approaches.
</summary>
    <author>
      <name>Yong Khoo</name>
    </author>
    <author>
      <name>Sang Chung</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Imaging and Graphics, 2017</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1705.05508v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.05508v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.00267v1</id>
    <updated>2017-05-30T20:29:05Z</updated>
    <published>2017-05-30T20:29:05Z</published>
    <title>On the Design and Invariants of a Ruled Surface</title>
    <summary>  This paper deals with a kind of design of a ruled surface. It combines
concepts from the fields of computer aided geometric design and kinematics. A
dual unit spherical B\'ezier-like curve on the dual unit sphere (DUS) is
obtained with respect the control points by a new method. So, with the aid of
Study [1] transference principle, a dual unit spherical B\'ezier-like curve
corresponds to a ruled surface. Furthermore, closed ruled surfaces are
determined via control points and integral invariants of these surfaces are
investigated. The results are illustrated by examples.
</summary>
    <author>
      <name>Ferhat Taş</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">27 pages, 4 figures, 1 figure list</arxiv:comment>
    <link href="http://arxiv.org/abs/1706.00267v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.00267v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="53A17, 53A25" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.08262v1</id>
    <updated>2017-06-26T07:40:55Z</updated>
    <published>2017-06-26T07:40:55Z</published>
    <title>Degenerations of NURBS curves while all of weights approaching infinity</title>
    <summary>  NURBS curve is widely used in Computer Aided Design and Computer Aided
Geometric Design. When a single weight approaches infinity, the limit of a
NURBS curve tends to the corresponding control point. In this paper, a kind of
control structure of a NURBS curve, called regular control curve, is defined.
We prove that the limit of the NURBS curve is exactly its regular control curve
when all of weights approach infinity, where each weight is multiplied by a
certain one-parameter function tending to infinity, different for each control
point. Moreover, some representative examples are presented to show this
property and indicate its application for shape deformation.
</summary>
    <author>
      <name>Yue Zhang</name>
    </author>
    <author>
      <name>Chun-Gang Zhu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">23 pages, 47 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1706.08262v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.08262v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65D17" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.09123v1</id>
    <updated>2017-07-28T07:03:29Z</updated>
    <published>2017-07-28T07:03:29Z</published>
    <title>Research on Shape Mapping of 3D Mesh Models based on Hidden Markov
  Random Field and EM Algorithm</title>
    <summary>  How to establish the matching (or corresponding) between two different 3D
shapes is a classical problem. This paper focused on the research on shape
mapping of 3D mesh models, and proposed a shape mapping algorithm based on
Hidden Markov Random Field and EM algorithm, as introducing a hidden state
random variable associated with the adjacent blocks of shape matching when
establishing HMRF. This algorithm provides a new theory and method to ensure
the consistency of the edge data of adjacent blocks, and the experimental
results show that the algorithm in this paper has a great improvement on the
shape mapping of 3D mesh models.
</summary>
    <author>
      <name>Yong Wang</name>
    </author>
    <author>
      <name>Huai-yu Wu</name>
    </author>
    <link href="http://arxiv.org/abs/1707.09123v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.09123v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.09629v1</id>
    <updated>2017-07-30T15:12:52Z</updated>
    <published>2017-07-30T15:12:52Z</published>
    <title>Kernel Projection of Latent Structures Regression for Facial Animation
  Retargeting</title>
    <summary>  Inspired by kernel methods that have been used extensively in achieving
efficient facial animation retargeting, this paper presents a solution to
retargeting facial animation in virtual character's face model based on the
kernel projection of latent structure (KPLS) regression between semantically
similar facial expressions. Specifically, a given number of corresponding
semantically similar facial expressions are projected into the latent space. By
using the Nonlinear Iterative Partial Least Square method, decomposition of the
latent variables is achieved. Finally, the KPLS is achieved by solving a
kernalized version of the eigenvalue problem. By evaluating our methodology
with other kernel-based solutions, the efficiency of the presented methodology
in transferring facial animation to face models with different morphological
variations is demonstrated.
</summary>
    <author>
      <name>Christos Ouzounis</name>
    </author>
    <author>
      <name>Alex Kilias</name>
    </author>
    <author>
      <name>Christos Mousas</name>
    </author>
    <link href="http://arxiv.org/abs/1707.09629v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.09629v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.09839v1</id>
    <updated>2017-07-13T18:16:06Z</updated>
    <published>2017-07-13T18:16:06Z</published>
    <title>Superposition de calques monochromes d'opacités variables</title>
    <summary>  For a monochrome layer $x$ of opacity $0\le o_x\le1 $ placed on another
monochrome layer of opacity 1, the result given by the standard formula is
$$\small\Pi\left({\bf
C}_\varphi\right)=1+\sum_{n=1}^2\left(2-n-(-1)^no_{\chi(\varphi+1)}\right)\left(\chi(n+\varphi-1)-o_{\chi(n+\varphi-1)}\right),$$
the formula being of course explained in detail in this paper. We will
eventually deduce a very simple theorem, generalize it and then see its
validity with alternative formulas to this standard containing the same main
properties here exposed.
</summary>
    <author>
      <name>Alexandre Bali</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">WARNING : Paper written entirely in french. 3 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1707.09839v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.09839v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.04233v1</id>
    <updated>2017-08-13T23:02:34Z</updated>
    <published>2017-08-13T23:02:34Z</published>
    <title>Fast, large-scale hologram calculation in wavelet domain</title>
    <summary>  We propose a large-scale hologram calculation using WAvelet ShrinkAge-Based
superpositIon (WASABI), a wavelet transform-based algorithm. An image-type
hologram calculated using the WASABI method is printed on a glass substrate
with the resolution of $65,536 \times 65,536$ pixels and a pixel pitch of $1
\mu$m. The hologram calculation time amounts to approximately 354 s on a
commercial CPU, which is approximately 30 times faster than conventional
methods.
</summary>
    <author>
      <name>Tomoyoshi Shimobaba</name>
    </author>
    <author>
      <name>Kyoji Matsushima</name>
    </author>
    <author>
      <name>Takayuki Takahashi</name>
    </author>
    <author>
      <name>Yuki Nagahama</name>
    </author>
    <author>
      <name>Satoki Hasegawa</name>
    </author>
    <author>
      <name>Marie Sano</name>
    </author>
    <author>
      <name>Ryuji Hirayama</name>
    </author>
    <author>
      <name>Takashi Kakue</name>
    </author>
    <author>
      <name>Tomoyoshi Ito</name>
    </author>
    <link href="http://arxiv.org/abs/1708.04233v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.04233v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.optics" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.06684v1</id>
    <updated>2017-07-28T10:52:52Z</updated>
    <published>2017-07-28T10:52:52Z</published>
    <title>Fractions, Projective Representation, Duality, Linear Algebra and
  Geometry</title>
    <summary>  This contribution describes relationship between fractions, projective
representation, duality, linear algebra and geometry. Many problems lead to a
system of linear equations. This paper presents equivalence of the
Cross-product operation and solution of a system of linear equations Ax=0 or
Ax=b using projective space representation and homogeneous coordinates. It
leads to conclusion that division operation is not required for a solution of a
system of linear equations, if the projective representation and homogeneous
coordinates are used. An efficient solution on CPU and GPU based architectures
is presented with an application to barycentric coordinates computation as
well.
</summary>
    <author>
      <name>Vaclav Skala</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">CZECH-SLOVAK CONFERENCE ON GEOMETRY AND GRAPHICS 2016, ISBN
  978-80-7464-874-8</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1708.06684v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.06684v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.04752v1</id>
    <updated>2017-09-10T11:24:08Z</updated>
    <published>2017-09-10T11:24:08Z</published>
    <title>The wave method of building color palette and its application in
  computer graphics</title>
    <summary>  This article describes a method of getting a harmonious combination of
colors, developed by us on the basis of the relationship of color and acoustic
waves. Presents a parallel between harmoniously matched colors and the concept
of harmony in music theory (consonance). Describes the physical assumption of
the essence of the phenomenon of harmony (consonance). The article also
provides algorithm of implementation wave method for the sRGB color model.
</summary>
    <author>
      <name>I. I. Sabo</name>
    </author>
    <author>
      <name>H. R. Lagoda</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1709.04752v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.04752v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1008.2819v1</id>
    <updated>2010-08-17T05:04:20Z</updated>
    <published>2010-08-17T05:04:20Z</published>
    <title>A symmetric motion picture of the twist-spun trefoil</title>
    <summary>  With the aid of a computer, we provide a motion picture of the twist-spun
trefoil which exhibits the periodicity well.
</summary>
    <author>
      <name>Ayumu Inoue</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 21 figures, and 5 movies</arxiv:comment>
    <link href="http://arxiv.org/abs/1008.2819v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1008.2819v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.GT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.GT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="Primary 57Q45, Secondary 68U05, 68U07" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1407.5211v1</id>
    <updated>2014-07-19T18:14:20Z</updated>
    <published>2014-07-19T18:14:20Z</published>
    <title>Development &amp; Implementation of a PyMOL 'putty' Representation</title>
    <summary>  The PyMOL molecular graphics program has been modified to introduce a new
'putty' cartoon representation, akin to the 'sausage'-style representation of
the MOLMOL molecular visualization (MolVis) software package. This document
outlines the development and implementation of the putty representation.
</summary>
    <author>
      <name>Cameron Mura</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1407.5211v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1407.5211v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.BM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.BM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.6649v1</id>
    <updated>2014-12-20T12:51:24Z</updated>
    <published>2014-12-20T12:51:24Z</published>
    <title>Qualitative shape representation based on the qualitative relative
  direction and distance calculus eOPRAm</title>
    <summary>  This document serves as a brief technical report, detailing the processes
used to represent and reconstruct simplified polygons using qualitative spatial
descriptions, as defined by the eOPRAm qualitative spatial calculus.
</summary>
    <author>
      <name>Christopher H. Dorr</name>
    </author>
    <author>
      <name>Reinhard Moratz</name>
    </author>
    <link href="http://arxiv.org/abs/1412.6649v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.6649v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1001.3974v2</id>
    <updated>2010-01-23T00:51:58Z</updated>
    <published>2010-01-22T12:57:59Z</published>
    <title>Modelacion y Visualizacion Tridimensional Interactiva de Variables
  Electricas en Celdas de Electro-Obtencion con Electrodos Bipolares</title>
    <summary>  The use of floating bipolar electrodes in electrowinning cells of copper
constitutes a nonconventional technology that promises economic and operational
impacts. This paper presents a computational tool for the simulation and
analysis of such electrochemical cells. A new model is developed for floating
electrodes and a method of finite difference is used to obtain the
threedimensional distribution of the potential and the field of current density
inside the cell. The analysis of the results is based on a technique for the
interactive visualization of three-dimensional vectorial fields as lines of
flow.
</summary>
    <author>
      <name>César Mena Labraña</name>
    </author>
    <author>
      <name>Ricardo Sánchez Schulz</name>
    </author>
    <author>
      <name>Lautaro Salazar Silva</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 3 figures, in Spanish. See also arXiv:1001.4002v1 [cs.GR].
  The only change in V2 is the updating of a reference</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Anales del XIV Congreso de la Asociacion Chilena de Control
  Automatico, ACCA, 2000, pp. 362-367</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1001.3974v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1001.3974v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1001.4002v1</id>
    <updated>2010-01-22T18:23:27Z</updated>
    <published>2010-01-22T18:23:27Z</published>
    <title>Aplicacion Grafica para el estudio de un Modelo de Celda Electrolitica
  usando Tecnicas de Visualizacion de Campos Vectoriales</title>
    <summary>  The use of floating bipolar electrodes in electrowinning cells of copper
constitutes a nonconventional technology that promises economic and operational
impacts. This thesis presents a computational tool for the simulation and
analysis of such electrochemical cells. A new model is developed for floating
electrodes and a method of finite difference is used to obtain the
threedimensional distribution of the potential and the field of current density
inside the cell. The analysis of the results is based on a technique for the
interactive visualization of three-dimensional vectorial fields as lines of
flow.
</summary>
    <author>
      <name>César Mena Labraña</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.13140/RG.2.1.1291.4082</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.13140/RG.2.1.1291.4082" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Electronic Engineer Thesis, Universidad de Concepcion, 2000, 105
  pages, 22 figures, in Spanish. The main results are also available in
  arXiv:1001.3974v1 [cs.GR]</arxiv:comment>
    <link href="http://arxiv.org/abs/1001.4002v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1001.4002v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0001017v1</id>
    <updated>2000-01-21T10:02:49Z</updated>
    <published>2000-01-21T10:02:49Z</published>
    <title>Bezier Curves Intersection Using Relief Perspective</title>
    <summary>  Presented paper describes the method for finding the intersection of class
space rational Bezier curves. The problem curve/curve intersection belongs
among basic geometric problems and the aim of this article is to describe the
new technique to solve the problem using relief perspective and Bezier
clipping.
</summary>
    <author>
      <name>Radoslav Hlusek</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 2 figures, to appear in Proceedings of WSCG'2000 in Plzen,
  Czech Republic</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0001017v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0001017v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.2.2; I.3.5; J.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0708.0660v1</id>
    <updated>2007-08-05T05:25:45Z</updated>
    <published>2007-08-05T05:25:45Z</published>
    <title>Network synchronizability analysis: the theory of subgraphs and
  complementary graphs</title>
    <summary>  In this paper, subgraphs and complementary graphs are used to analyze the
network synchronizability. Some sharp and attainable bounds are provided for
the eigenratio of the network structural matrix, which characterizes the
network synchronizability, especially when the network's corresponding graph
has cycles, chains, bipartite graphs or product graphs as its subgraphs.
</summary>
    <author>
      <name>Zhisheng Duan</name>
    </author>
    <author>
      <name>Chao Liu</name>
    </author>
    <author>
      <name>Guanrong Chen</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.physd.2007.12.003</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.physd.2007.12.003" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0708.0660v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0708.0660v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1006.2368v1</id>
    <updated>2010-06-11T19:05:05Z</updated>
    <published>2010-06-11T19:05:05Z</published>
    <title>L2-optimal image interpolation and its applications to medical imaging</title>
    <summary>  Digital medical images are always displayed scaled to fit particular view.
Interpolation is responsible for this scaling, and if not done properly, can
significantly degrade diagnostic image quality. However, theoretically-optimal
interpolation algorithms may also be the most time-consuming and impractical.
We propose a new approach, adapted to the needs of digital medical imaging, to
combine high interpolation speed and superior L2-optimal image quality.
</summary>
    <author>
      <name>Oleg Pianykh</name>
    </author>
    <link href="http://arxiv.org/abs/1006.2368v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1006.2368v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1006.3661v1</id>
    <updated>2010-06-18T10:40:23Z</updated>
    <published>2010-06-18T10:40:23Z</published>
    <title>Fractal Basins and Boundaries in 2D Maps inspired in Discrete Population
  Models</title>
    <summary>  Two-dimensional maps can model interactions between populations. Despite
their simplicity, these dynamical systems can show some complex situations, as
multistability or fractal boundaries between basins that lead to remarkable
pictures. Some of them are shown and explained here for three different 2D
discrete models.
</summary>
    <author>
      <name>Daniele Fournier-Prunaret</name>
    </author>
    <author>
      <name>Ricardo Lopez-Ruiz</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 12 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1006.3661v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1006.3661v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="nlin.CD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.CD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.6336v1</id>
    <updated>2013-01-27T09:35:33Z</updated>
    <published>2013-01-27T09:35:33Z</published>
    <title>Approximation of Polyhedral Surface Uniformization</title>
    <summary>  We present a constructive approach for approximating the conformal map
(uniformization) of a polyhedral surface to a canonical domain in the plane.
The main tool is a characterization of convex spaces of quasiconformal
simplicial maps and their approximation properties. As far as we are aware,
this is the first algorithm proved to approximate the uniformization of general
polyhedral surfaces.
</summary>
    <author>
      <name>Yaron Lipman</name>
    </author>
    <link href="http://arxiv.org/abs/1301.6336v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.6336v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1305.2276v1</id>
    <updated>2013-05-10T07:58:06Z</updated>
    <published>2013-05-10T07:58:06Z</published>
    <title>The effects of computer assisted and distance learning of geometric
  modelling</title>
    <summary>  The effects of computer-assisted and distance learning of geometric modeling
and computer aided geometric design are studied. It was shown that computer
algebra systems and dynamic geometric environments can be considered as
excellent tools for teaching mathematical concepts of mentioned areas, and
distance education technologies would be indispensable for consolidation of
successfully passed topics.
</summary>
    <author>
      <name>Omer Faruk Sozcu</name>
    </author>
    <author>
      <name>Rushan Ziatdinov</name>
    </author>
    <author>
      <name>Ismail Ipek</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">European Researcher 39(1-2), 175-181, 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1305.2276v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1305.2276v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.00754v1</id>
    <updated>2016-09-02T21:47:47Z</updated>
    <published>2016-09-02T21:47:47Z</published>
    <title>A heuristic extending the Squarified treemapping algorithm</title>
    <summary>  A heuristic extending the Squarified Treemap technique for the representation
of hierarchical information as treemaps is presented. The original technique
gives high quality treemap views, since items are laid out with rectangles that
approximate squares, allowing easy comparison and selection operations. New key
steps, with a low computational impact, have been introduced to yield treemaps
with even better aspect ratios and higher homogeneity among items.
</summary>
    <author>
      <name>Antonio Cesarano</name>
    </author>
    <author>
      <name>FIlomena Ferrucci</name>
    </author>
    <author>
      <name>Mario Torre</name>
    </author>
    <link href="http://arxiv.org/abs/1609.00754v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.00754v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.01499v2</id>
    <updated>2017-03-15T14:55:52Z</updated>
    <published>2017-03-04T17:37:32Z</published>
    <title>A Machine-Learning Framework for Design for Manufacturability</title>
    <summary>  this is a duplicate submission(original is arXiv:1612.02141). Hence want to
withdraw it
</summary>
    <author>
      <name>Aditya Balu</name>
    </author>
    <author>
      <name>Sambit Ghadai</name>
    </author>
    <author>
      <name>Gavin Young</name>
    </author>
    <author>
      <name>Soumik Sarkar</name>
    </author>
    <author>
      <name>Adarsh Krishnamurthy</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">this is a duplicate submission. Hence want to withdraw it</arxiv:comment>
    <link href="http://arxiv.org/abs/1703.01499v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.01499v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.03497v1</id>
    <updated>2017-06-12T08:04:42Z</updated>
    <published>2017-06-12T08:04:42Z</published>
    <title>A filter based approach for inbetweening</title>
    <summary>  We present a filter based approach for inbetweening. We train a convolutional
neural network to generate intermediate frames. This network aim to generate
smooth animation of line drawings. Our method can process scanned images
directly. Our method does not need to compute correspondence of lines and
topological changes explicitly. We experiment our method with real animation
production data. The results show that our method can generate intermediate
frames partially.
</summary>
    <author>
      <name>Yuichi Yagi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, in Japanese</arxiv:comment>
    <link href="http://arxiv.org/abs/1706.03497v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.03497v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.01597v1</id>
    <updated>2017-08-20T19:24:17Z</updated>
    <published>2017-08-20T19:24:17Z</published>
    <title>Multi-color image compression-encryption algorithm based on chaotic
  system and fuzzy transform</title>
    <summary>  In this paper an algorithm for multi-color image compression-encryption is
introduced. For compression step fuzzy transform based on exponential b-spline
function is used. In encryption step, a novel combination chaotic system based
on Sine and Tent systems is proposed. Also in the encryption algorithm, 3D
shift based on chaotic system is introduced. The simulation results and
security analysis show that the proposed algorithm is secure and efficient.
</summary>
    <author>
      <name>M. Zarebnia</name>
    </author>
    <author>
      <name>R. Kianfar</name>
    </author>
    <author>
      <name>R. Parvaz</name>
    </author>
    <link href="http://arxiv.org/abs/1709.01597v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.01597v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0301002v1</id>
    <updated>2003-01-06T20:57:51Z</updated>
    <published>2003-01-06T20:57:51Z</published>
    <title>Practical and Robust Stenciled Shadow Volumes for Hardware-Accelerated
  Rendering</title>
    <summary>  Twenty-five years ago, Crow published the shadow volume approach for
determining shadowed regions in a scene. A decade ago, Heidmann described a
hardware-accelerated stencil buffer-based shadow volume algorithm.
  Unfortunately hardware-accelerated stenciled shadow volume techniques have
not been widely adopted by 3D games and applications due in large part to the
lack of robustness of described techniques. This situation persists despite
widely available hardware support. Specifically what has been lacking is a
technique that robustly handles various "hard" situations created by near or
far plane clipping of shadow volumes.
  We describe a robust, artifact-free technique for hardware-accelerated
rendering of stenciled shadow volumes. Assuming existing hardware, we resolve
the issues otherwise caused by shadow volume near and far plane clipping
through a combination of (1) placing the conventional far clip plane "at
infinity", (2) rasterization with infinite shadow volume polygons via
homogeneous coordinates, and (3) adopting a zfail stencil-testing scheme. Depth
clamping, a new rasterization feature provided by NVIDIA's GeForce3, preserves
existing depth precision by not requiring the far plane to be placed at
infinity. We also propose two-sided stencil testing to improve the efficiency
of rendering stenciled shadow volumes.
</summary>
    <author>
      <name>Cass Everitt</name>
    </author>
    <author>
      <name>Mark J. Kilgard</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0301002v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0301002v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.6; I.3.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0305057v1</id>
    <updated>2003-05-29T22:06:27Z</updated>
    <published>2003-05-29T22:06:27Z</published>
    <title>The Persint visualization program for the ATLAS experiment</title>
    <summary>  The Persint program is designed for the three-dimensional representation of
objects and for the interfacing and access to a variety of independent
applications, in a fully interactive way. Facilities are provided for the
spatial navigation and the definition of the visualization properties, in order
to interactively set the viewing and viewed points, and to obtain the desired
perspective. In parallel, applications may be launched through the use of
dedicated interfaces, such as the interactive reconstruction and display of
physics events. Recent developments have focalized on the interfacing to the
XML ATLAS General Detector Description AGDD, making it a widely used tool for
XML developers. The graphics capabilities of this program were exploited in the
context of the ATLAS 2002 Muon Testbeam where it was used as an online event
display, integrated in the online software framework and participating in the
commissioning and debug of the detector system.
</summary>
    <author>
      <name>D. Pomarede</name>
    </author>
    <author>
      <name>M. Virchaux</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 10 figures, proceedings of CHEP2003</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ECONFC0303241:MOLT009,2003</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0305057v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0305057v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.0" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0307065v1</id>
    <updated>2003-07-29T13:40:12Z</updated>
    <published>2003-07-29T13:40:12Z</published>
    <title>Application of interactive parallel visualization for commodity-based
  clusters using visualization APIs</title>
    <summary>  We present an efficient and inexpensive to develop application for
interactive high-performance parallel visualization. We extend popular APIs
such as Open Inventor and VTK to support commodity-based cluster visualization.
Our implementation follows a standard master/slave concept: the general idea is
to have a ``Master'' node, which will intercept a sequential graphical user
interface (GUI) and broadcast it to the ``Slave'' nodes. The interactions
between the nodes are implemented using MPI. The parallel remote rendering uses
Chromium. This paper is mainly the report of our implementation experiences. We
present in detail the proposed model and key aspects of its implementation.
Also, we present performance measurements, we benchmark and quantitatively
demonstrate the dependence of the visualization speed on the data size and the
network bandwidth, and we identify the singularities and draw conclusions on
Chromium's sort-first rendering architecture. The most original part of this
work is the combined use of Open Inventor and Chromium.
</summary>
    <author>
      <name>Stanimire Tomov</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Brookhaven National Laboratory</arxiv:affiliation>
    </author>
    <author>
      <name>Robert Bennett</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Brookhaven National Laboratory</arxiv:affiliation>
    </author>
    <author>
      <name>Michael McGuigan</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Brookhaven National Laboratory</arxiv:affiliation>
    </author>
    <author>
      <name>Arnold Peskin</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Brookhaven National Laboratory</arxiv:affiliation>
    </author>
    <author>
      <name>Gordon Smith</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Brookhaven National Laboratory</arxiv:affiliation>
    </author>
    <author>
      <name>John Spiletic</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Brookhaven National Laboratory</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0307065v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0307065v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.6; I.3.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0310002v2</id>
    <updated>2003-10-07T18:36:30Z</updated>
    <published>2003-10-05T06:30:56Z</published>
    <title>The Graphics Card as a Streaming Computer</title>
    <summary>  Massive data sets have radically changed our understanding of how to design
efficient algorithms; the streaming paradigm, whether it in terms of number of
passes of an external memory algorithm, or the single pass and limited memory
of a stream algorithm, appears to be the dominant method for coping with large
data.
  A very different kind of massive computation has had the same effect at the
level of the CPU. The most prominent example is that of the computations
performed by a graphics card. The operations themselves are very simple, and
require very little memory, but require the ability to perform many
computations extremely fast and in parallel to whatever degree possible. What
has resulted is a stream processor that is highly optimized for stream
computations. An intriguing side effect of this is the growing use of a
graphics card as a general purpose stream processing engine. In an
ever-increasing array of applications, researchers are discovering that
performing a computation on a graphics card is far faster than performing it on
a CPU, and so are using a GPU as a stream co-processor.
</summary>
    <author>
      <name>Suresh Venkatasubramanian</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2 pages: corrected missing bibliographic references</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">In SIGMOD Workshop on Management and Processing of Massive Data
  (June 2003)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0310002v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0310002v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="C.1.2;F.1.1;I.3.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0311034v1</id>
    <updated>2003-11-22T18:17:26Z</updated>
    <published>2003-11-22T18:17:26Z</published>
    <title>Visualization of variations in human brain morphology using
  differentiating reflection functions</title>
    <summary>  Conventional visualization media such as MRI prints and computer screens are
inherently two dimensional, making them incapable of displaying true 3D volume
data sets. By applying only transparency or intensity projection, and ignoring
light-matter interaction, results will likely fail to give optimal results.
Little research has been done on using reflectance functions to visually
separate the various segments of a MRI volume. We will explore if applying
specific reflectance functions to individual anatomical structures can help in
building an intuitive 2D image from a 3D dataset. We will test our hypothesis
by visualizing a statistical analysis of the genetic influences on variations
in human brain morphology because it inherently contains complex and many
different types of data making it a good candidate for our approach
</summary>
    <author>
      <name>Gibby Koldenhof</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, keywords: MRI, Medical Visualization, Volume rendering,
  BRDF, Specular reflection overlap</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0311034v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0311034v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.4.7;I.4.8;I.4.10;I.3.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0312006v1</id>
    <updated>2003-12-02T15:47:19Z</updated>
    <published>2003-12-02T15:47:19Z</published>
    <title>Benchmarking and Implementation of Probability-Based Simulations on
  Programmable Graphics Cards</title>
    <summary>  The latest Graphics Processing Units (GPUs) are reported to reach up to
  200 billion floating point operations per second (200 Gflops) and to have
price performance of 0.1 cents per M flop. These facts raise great interest in
the plausibility of extending the GPUs' use to non-graphics applications, in
particular numerical simulations on structured grids (lattice).
  We review previous work on using GPUs for non-graphics applications,
implement probability-based simulations on the GPU, namely the
  Ising and percolation models, implement vector operation benchmarks for the
GPU, and finally compare the CPU's and GPU's performance.
  A general conclusion from the results obtained is that moving computations
from the CPU to the GPU is feasible, yielding good time and price performance,
for certain lattice computations.
  Preliminary results also show that it is feasible to use them in parallel
</summary>
    <author>
      <name>S. Tomov</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Brookhaven National Laboratory, Data Analysis and Visualization, Upton, NY</arxiv:affiliation>
    </author>
    <author>
      <name>M. McGuigan</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Brookhaven National Laboratory, Data Analysis and Visualization, Upton, NY</arxiv:affiliation>
    </author>
    <author>
      <name>R. Bennett</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Brookhaven National Laboratory, Data Analysis and Visualization, Upton, NY</arxiv:affiliation>
    </author>
    <author>
      <name>G. Smith</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Brookhaven National Laboratory, Data Analysis and Visualization, Upton, NY</arxiv:affiliation>
    </author>
    <author>
      <name>J. Spiletic</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Brookhaven National Laboratory, Data Analysis and Visualization, Upton, NY</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0312006v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0312006v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.6.3; I.3.1; B.8.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0401023v1</id>
    <updated>2004-01-26T21:51:04Z</updated>
    <published>2004-01-26T21:51:04Z</published>
    <title>Surface Triangulation -- The Metric Approach</title>
    <summary>  We embark in a program of studying the problem of better approximating
surfaces by triangulations(triangular meshes) by considering the approximating
triangulations as finite metric spaces and the target smooth surface as their
Haussdorff-Gromov limit. This allows us to define in a more natural way the
relevant elements, constants and invariants s.a. principal directions and
principal values, Gaussian and Mean curvature, etc. By a "natural way" we mean
an intrinsic, discrete, metric definitions as opposed to approximating or
paraphrasing the differentiable notions. In this way we hope to circumvent
computational errors and, indeed, conceptual ones, that are often inherent to
the classical, "numerical" approach. In this first study we consider the
problem of determining the Gaussian curvature of a polyhedral surface, by using
the {\em embedding curvature} in the sense of Wald (and Menger). We present two
modalities of employing these definitions for the computation of Gaussian
curvature.
</summary>
    <author>
      <name>Emil Saucan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">29 pages, 13 figures Preliminary version</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0401023v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0401023v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.MG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.2; I.4.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0405048v1</id>
    <updated>2004-05-14T18:18:04Z</updated>
    <published>2004-05-14T18:18:04Z</published>
    <title>Interactive visualization of higher dimensional data in a multiview
  environment</title>
    <summary>  We develop multiple view visualization of higher dimensional data. Our work
was chiefly motivated by the need to extract insight from four dimensional
Quantum Chromodynamic (QCD) data. We develop visualization where multiple
views, generally views of 3D projections or slices of a higher dimensional
data, are tightly coupled not only by their specific order but also by a view
synchronizing interaction style, and an internally defined interaction
language. The tight coupling of the different views allows a fast and
well-coordinated exploration of the data. In particular, the visualization
allowed us to easily make consistency checks of the 4D QCD data and to infer
the correctness of particle properties calculations. The software developed was
also successfully applied in material studies, in particular studies of
meteorite properties. Our implementation uses the VTK API. To handle a large
number of views (slices/projections) and to still maintain good resolution, we
use IBM T221 display (3840 X 2400 pixels).
</summary>
    <author>
      <name>Stanimire Tomov</name>
    </author>
    <author>
      <name>Michael McGuigan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0405048v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0405048v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.6; I.3.8; H.5.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0505043v2</id>
    <updated>2012-06-27T11:49:17Z</updated>
    <published>2005-05-16T02:20:19Z</published>
    <title>Estimacao Temporal da Deformacao entre Objectos utilizando uma
  Metodologia Fisica</title>
    <summary>  In this paper, it is presented a methodology to estimate the deformation
involved between two objects attending to its physical properties. This
methodology can be used, for example, in Computational Vision or Computer
Graphics applications, and consists in physically modeling the objects, by
means of the Finite Elements Method, establishing correspondences between some
of its data points, by using Modal Matching, and finally, determining the
displacement field, that is the intermediate shapes, through the resolution of
the Lagrange Dynamic Equilibrium Equation. As in many of the possible
applications of the methodology to present, it is necessary to quantify the
existing deformation, as well as to estimate only the non rigid component of
the involved global deformation. The solutions adopted to satisfy such
intentions will be also presented.
</summary>
    <author>
      <name>Joao Manuel R. S. Tavares</name>
    </author>
    <author>
      <name>Raquel R. Pinho</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">INFOCOMP Journal of Computer Science. This paper has been withdrawn
  due to journal politics</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">INFOCOMP Journal of Computer Science, 4(1), 2005</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0505043v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0505043v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0507012v1</id>
    <updated>2005-07-05T19:48:09Z</updated>
    <published>2005-07-05T19:48:09Z</published>
    <title>Lattice Gas Cellular Automata for Computational Fluid Animation</title>
    <summary>  The past two decades showed a rapid growing of physically-based modeling of
fluids for computer graphics applications. In this area, a common top down
approach is to model the fluid dynamics by Navier-Stokes equations and apply a
numerical techniques such as Finite Differences or Finite Elements for the
simulation. In this paper we focus on fluid modeling through Lattice Gas
Cellular Automata (LGCA) for computer graphics applications. LGCA are discrete
models based on point particles that move on a lattice, according to suitable
and simple rules in order to mimic a fully molecular dynamics. By
Chapman-Enskog expansion, a known multiscale technique in this area, it can be
demonstrated that the Navier-Stokes model can be reproduced by the LGCA
technique. Thus, with LGCA we get a fluid model that does not require solution
of complicated equations. Therefore, we combine the advantage of the low
computational cost of LGCA and its ability to mimic the realistic fluid
dynamics to develop a new animating framework for computer graphics
applications. In this work, we discuss the theoretical elements of our proposal
and show experimental results.
</summary>
    <author>
      <name>Gilson A. Giraldi</name>
    </author>
    <author>
      <name>Adilson V. Xavier</name>
    </author>
    <author>
      <name>Antonio L. Apolinario Jr</name>
    </author>
    <author>
      <name>Paulo S. Rodrigues</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0507012v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0507012v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0511032v1</id>
    <updated>2005-11-08T14:40:47Z</updated>
    <published>2005-11-08T14:40:47Z</published>
    <title>Spatiotemporal sensistivity and visual attention for efficient rendering
  of dynamic environments</title>
    <summary>  We present a method to accelerate global illumination computation in dynamic
environments by taking advantage of limitations of the human visual system. A
model of visual attention is used to locate regions of interest in a scene and
to modulate spatiotemporal sensitivity. The method is applied in the form of a
spatiotemporal error tolerance map. Perceptual acceleration combined with good
sampling protocols provide a global illumination solution feasible for use in
animation. Results indicate an order of magnitude improvement in computational
speed. The method is adaptable and can also be used in image-based rendering,
geometry level of detail selection, realistic image synthesis, video telephony
and video compression.
</summary>
    <author>
      <name>Yang Li Hector Yee</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Cornell University</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ACM Transactions on Graphics, 20(1), January 2001</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0511032v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0511032v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0606098v1</id>
    <updated>2006-06-22T15:35:56Z</updated>
    <published>2006-06-22T15:35:56Z</published>
    <title>Outlier Robust ICP for Minimizing Fractional RMSD</title>
    <summary>  We describe a variation of the iterative closest point (ICP) algorithm for
aligning two point sets under a set of transformations. Our algorithm is
superior to previous algorithms because (1) in determining the optimal
alignment, it identifies and discards likely outliers in a statistically robust
manner, and (2) it is guaranteed to converge to a locally optimal solution. To
this end, we formalize a new distance measure, fractional root mean squared
distance (frmsd), which incorporates the fraction of inliers into the distance
function. We lay out a specific implementation, but our framework can easily
incorporate most techniques and heuristics from modern registration algorithms.
We experimentally validate our algorithm against previous techniques on 2 and 3
dimensional data exposed to a variety of outlier types.
</summary>
    <author>
      <name>Jeff M. Phillips</name>
    </author>
    <author>
      <name>Ran Liu</name>
    </author>
    <author>
      <name>Carlo Tomasi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">22 pages, 7 Figures, 9 Tables</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0606098v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0606098v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0702026v1</id>
    <updated>2007-02-05T10:11:58Z</updated>
    <published>2007-02-05T10:11:58Z</published>
    <title>Shape preservation behavior of spline curves</title>
    <summary>  Shape preservation behavior of a spline consists of criterial conditions for
preserving convexity, inflection, collinearity, torsion and coplanarity shapes
of data polgonal arc. We present our results which acts as an improvement in
the definitions of and provide geometrical insight into each of the above shape
preservation criteria. We also investigate the effect of various results from
the literature on various shape preservation criteria. These results have not
been earlier refered in the context of shape preservation behaviour of splines.
We point out that each curve segment need to satisfy more than one shape
preservation criteria. We investigate the conflict between different shape
preservation criteria 1)on each curve segment and 2)of adjacent curve segments.
We derive simplified formula for shape preservation criteria for cubic curve
segments. We study the shape preservation behavior of cubic Catmull-Rom splines
and see that, though being very simple spline curve, it indeed satisfy all the
shape preservation criteria.
</summary>
    <author>
      <name>Ravi Shankar Gautam</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">54 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0702026v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0702026v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0706.4224v1</id>
    <updated>2007-06-28T13:19:04Z</updated>
    <published>2007-06-28T13:19:04Z</published>
    <title>User driven applications - new design paradigm</title>
    <summary>  Programs for complicated engineering and scientific tasks always have to deal
with a problem of showing numerous graphical results. The limits of the screen
space and often opposite requirements from different users are the cause of the
infinite discussions between designers and users, but the source of this
ongoing conflict is not in the level of interface design, but in the basic
principle of current graphical output: user may change some views and details,
but in general the output view is absolutely defined and fixed by the
developer. Author was working for several years on the algorithm that will
allow eliminating this problem thus allowing stepping from designer-driven
applications to user-driven. Such type of applications in which user is
deciding what, when and how to show on the screen, is the dream of scientists
and engineers working on the analysis of the most complicated tasks. The new
paradigm is based on movable and resizable graphics, and such type of graphics
can be widely used not only for scientific and engineering applications.
</summary>
    <author>
      <name>Sergey Andreyev</name>
    </author>
    <link href="http://arxiv.org/abs/0706.4224v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0706.4224v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0708.0712v1</id>
    <updated>2007-08-06T07:42:56Z</updated>
    <published>2007-08-06T07:42:56Z</published>
    <title>Virtual Environments for Training: From Individual Learning to
  Collaboration with Humanoids</title>
    <summary>  The next generation of virtual environments for training is oriented towards
collaborative aspects. Therefore, we have decided to enhance our platform for
virtual training environments, adding collaboration opportunities and
integrating humanoids. In this paper we put forward a model of humanoid that
suits both virtual humans and representations of real users, according to
collaborative training activities. We suggest adaptations to the scenario model
of our platform making it possible to write collaborative procedures. We
introduce a mechanism of action selection made up of a global repartition and
an individual choice. These models are currently being integrated and validated
in GVT, a virtual training tool for maintenance of military equipments,
developed in collaboration with the French company NEXTER-Group.
</summary>
    <author>
      <name>Stéphanie Gerbaud</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IRISA</arxiv:affiliation>
    </author>
    <author>
      <name>Nicolas Mollet</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IRISA</arxiv:affiliation>
    </author>
    <author>
      <name>Bruno Arnaldi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IRISA</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Dans Edutainment (2007)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0708.0712v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0708.0712v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0709.3553v1</id>
    <updated>2007-09-22T00:21:08Z</updated>
    <published>2007-09-22T00:21:08Z</published>
    <title>Design of moveable and resizable graphics</title>
    <summary>  We are communicating with computers on two different levels. On upper level
we have a very flexible system of windows: we can move them, resize, overlap or
put side by side. At any moment we decide what would be the best view and
reorganize the whole view easily. Then we start any application, go to the
inner level, and everything changes. Here we are stripped of all the
flexibility and can work only inside the scenario, developed by the designer of
the program. Interface will allow us to change some tiny details, but in
general everything is fixed: graphics is neither moveable, nor resizable, and
the same with controls. Author designed an extremely powerful mechanism of
turning graphical objects and controls into moveable and resizable. This can
not only significantly improve the existing applications, but this will bring
the applications to another level. (To estimate the possible difference, try to
imagine the Windows system without its flexibility and compare it with the
current one.) This article explains in details the construction and use of
moveable and resizable graphical objects.
</summary>
    <author>
      <name>Sergey Andreyev</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0709.3553v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0709.3553v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0809.4093v2</id>
    <updated>2011-07-27T23:29:19Z</updated>
    <published>2008-09-24T05:50:56Z</published>
    <title>Perspective Drawing of Surfaces with Line Hidden Line Elimination,
  Dibujando Superficies En Perspectiva Con Eliminacion De Lineas Ocultas</title>
    <summary>  An efficient computer algorithm is described for the perspective drawing of a
wide class of surfaces. The class includes surfaces corresponding lo
single-valued, continuous functions which are defined over rectangular domains.
The algorithm automatically computes and eliminates hidden lines. The number of
computations in the algorithm grows linearly with the number of sample points
on the surface to be drawn. An analysis of the algorithm is presented, and
extensions lo certain multi-valued functions are indicated. The algorithm is
implemented and tested on .Net 2.0 platform that left interactive use. Running
times are found lo be exceedingly efficient for visualization, where
interaction on-line and view-point control, enables effective and rapid
examination of a surfaces from many perspectives.
</summary>
    <author>
      <name>Ignacio Vega-Paez</name>
    </author>
    <author>
      <name>Jose Angel Ortega</name>
    </author>
    <author>
      <name>Georgina G. Pulido</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings in Technical Memory, XI Congreso Nacional de
  Ingenieria Electromecanica y de Sistemas, pp. 136-144, Mexico, DF., Nov 2009</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0809.4093v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0809.4093v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0810.2021v1</id>
    <updated>2008-10-13T12:53:57Z</updated>
    <published>2008-10-13T12:53:57Z</published>
    <title>Visualization Optimization : Application to the RoboCup Rescue Domain</title>
    <summary>  In this paper we demonstrate the use of intelligent optimization
methodologies on the visualization optimization of virtual / simulated
environments. The problem of automatic selection of an optimized set of views,
which better describes an on-going simulation over a virtual environment is
addressed in the context of the RoboCup Rescue Simulation domain. A generic
architecture for optimization is proposed and described. We outline the
possible extensions of this architecture and argue on how several problems
within the fields of Interactive Rendering and Visualization can benefit from
it.
</summary>
    <author>
      <name>Pedro Miguel Moreira</name>
    </author>
    <author>
      <name>Luís Paulo Reis</name>
    </author>
    <author>
      <name>António Augusto de Sousa</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">1+4 pages, 3 Figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings SIACG 2006 - Ibero American Symposyum in Computer
  Graphics, Santiago de Compostela, Spain, 5-7 July 2006</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0810.2021v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0810.2021v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.7; I.2.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0811.2055v2</id>
    <updated>2008-11-18T20:31:15Z</updated>
    <published>2008-11-13T09:34:42Z</published>
    <title>GPU-Based Interactive Visualization of Billion Point Cosmological
  Simulations</title>
    <summary>  Despite the recent advances in graphics hardware capabilities, a brute force
approach is incapable of interactively displaying terabytes of data. We have
implemented a system that uses hierarchical level-of-detailing for the results
of cosmological simulations, in order to display visually accurate results
without loading in the full dataset (containing over 10 billion points). The
guiding principle of the program is that the user should not be able to
distinguish what they are seeing from a full rendering of the original data.
Furthermore, by using a tree-based system for levels of detail, the size of the
underlying data is limited only by the capacity of the IO system containing it.
</summary>
    <author>
      <name>Tamas Szalay</name>
    </author>
    <author>
      <name>Volker Springel</name>
    </author>
    <author>
      <name>Gerard Lemson</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2008 Microsoft eScience conference</arxiv:comment>
    <link href="http://arxiv.org/abs/0811.2055v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0811.2055v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0812.1119v1</id>
    <updated>2008-12-05T12:16:53Z</updated>
    <published>2008-12-05T12:16:53Z</published>
    <title>An analysis of a random algorithm for estimating all the matchings</title>
    <summary>  Counting the number of all the matchings on a bipartite graph has been
transformed into calculating the permanent of a matrix obtained from the
extended bipartite graph by Yan Huo, and Rasmussen presents a simple approach
(RM) to approximate the permanent, which just yields a critical ratio
O($n\omega(n)$) for almost all the 0-1 matrices, provided it's a simple
promising practical way to compute this #P-complete problem. In this paper, the
performance of this method will be shown when it's applied to compute all the
matchings based on that transformation. The critical ratio will be proved to be
very large with a certain probability, owning an increasing factor larger than
any polynomial of $n$ even in the sense for almost all the 0-1 matrices. Hence,
RM fails to work well when counting all the matchings via computing the
permanent of the matrix. In other words, we must carefully utilize the known
methods of estimating the permanent to count all the matchings through that
transformation.
</summary>
    <author>
      <name>Jinshan Zhang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/0812.1119v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0812.1119v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.2.0" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0812.1647v1</id>
    <updated>2008-12-09T10:12:36Z</updated>
    <published>2008-12-09T10:12:36Z</published>
    <title>Polyomino-Based Digital Halftoning</title>
    <summary>  In this work, we present a new method for generating a threshold structure.
This kind of structure can be advantageously used in various halftoning
algorithms such as clustered-dot or dispersed-dot dithering, error diffusion
with threshold modulation, etc. The proposed method is based on rectifiable
polyominoes -- a non-periodic hierarchical structure, which tiles the Euclidean
plane with no gaps. Each polyomino contains a fixed number of discrete
threshold values. Thanks to its inherent non-periodic nature combined with
off-line optimization of threshold values, our polyomino-based threshold
structure shows blue-noise spectral properties. The halftone images produced
with this threshold structure have high visual quality. Although the proposed
method is general, and can be applied on any polyomino tiling, we consider one
particular case: tiling with G-hexominoes. We compare our polyomino-based
threshold structure with the best known state-of-the-art methods for generation
threshold matrices, and conclude considerable improvement achieved with our
method.
</summary>
    <author>
      <name>David Vanderhaeghe</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rhône-Alpes / LJK Laboratoire Jean Kuntzmann, LJK</arxiv:affiliation>
    </author>
    <author>
      <name>Victor Ostromoukhov</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">DIRO</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">http://artis.imag.fr/Publications/2008/VO08/</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IADIS International Conference on Computer Graphics and
  Visualization 2008 (2008)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0812.1647v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0812.1647v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0906.1226v1</id>
    <updated>2009-06-05T22:57:04Z</updated>
    <published>2009-06-05T22:57:04Z</published>
    <title>On the Complexity of Smooth Spline Surfaces from Quad Meshes</title>
    <summary>  This paper derives strong relations that boundary curves of a smooth complex
of patches have to obey when the patches are computed by local averaging. These
relations restrict the choice of reparameterizations for geometric continuity.
In particular, when one bicubic tensor-product B-spline patch is associated
with each facet of a quadrilateral mesh with n-valent vertices and we do not
want segments of the boundary curves forced to be linear, then the relations
dictate the minimal number and multiplicity of knots: For general data, the
tensor-product spline patches must have at least two internal double knots per
edge to be able to model a G^1-conneced complex of C^1 splines. This lower
bound on the complexity of any construction is proven to be sharp by suitably
interpreting an existing surface construction. That is, we have a tight bound
on the complexity of smoothing quad meshes with bicubic tensor-product B-spline
patches.
</summary>
    <author>
      <name>Jorg Peters</name>
    </author>
    <author>
      <name>Jianhua Fan</name>
    </author>
    <link href="http://arxiv.org/abs/0906.1226v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0906.1226v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0911.0902v1</id>
    <updated>2009-11-04T18:11:30Z</updated>
    <published>2009-11-04T18:11:30Z</published>
    <title>Digital Image Watermarking for Arbitrarily Shaped Objects Based On
  SA-DWT</title>
    <summary>  Many image watermarking schemes have been proposed in recent years, but they
usually involve embedding a watermark to the entire image without considering
only a particular object in the image, which the image owner may be interested
in. This paper proposes a watermarking scheme that can embed a watermark to an
arbitrarily shaped object in an image. Before embedding, the image owner
specifies an object of arbitrary shape that is of a concern to him. Then the
object is transformed into the wavelet domain using in place lifting shape
adaptive DWT(SADWT) and a watermark is embedded by modifying the wavelet
coefficients. In order to make the watermark robust and transparent, the
watermark is embedded in the average of wavelet blocks using the visual model
based on the human visual system. Wavelet coefficients n least significant bits
(LSBs) are adjusted in concert with the average. Simulation results shows that
the proposed watermarking scheme is perceptually invisible and robust against
many attacks such as lossy compression (e.g.JPEG, JPEG2000), scaling, adding
noise, filtering, etc.
</summary>
    <author>
      <name>A. Essaouabi</name>
    </author>
    <author>
      <name>E. Ibnelhaj</name>
    </author>
    <author>
      <name>F. Fegragui</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Science Issues, Volume 5, pp1-8,
  October 2009</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">A.Essaouabi, E.Ibnelhaj and F.regragui, "Digital Image
  Watermarking for Arbitrarily Shaped Objects Based On SA-DWT", International
  Journal of Computer Science Issues, Volume 5, pp1-8, October 2009</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0911.0902v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0911.0902v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0911.5157v3</id>
    <updated>2011-04-27T16:54:22Z</updated>
    <published>2009-11-26T22:47:37Z</published>
    <title>Analyzing Midpoint Subdivision</title>
    <summary>  Midpoint subdivision generalizes the Lane-Riesenfeld algorithm for uniform
tensor product splines and can also be applied to non regular meshes. For
example, midpoint subdivision of degree 2 is a specific Doo-Sabin algorithm and
midpoint subdivision of degree 3 is a specific Catmull-Clark algorithm. In
2001, Zorin and Schroeder were able to prove C1-continuity for midpoint
subdivision surfaces analytically up to degree 9. Here, we develop general
analysis tools to show that the limiting surfaces under midpoint subdivision of
any degree &gt;= 2 are C1-continuous at their extraordinary points.
</summary>
    <author>
      <name>Hartmut Prautzsch</name>
    </author>
    <author>
      <name>Qi Chen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The paper was improved by adding more explanations and by adding an
  illustration of how the statements depend on each other. We combined a few
  theorems to simplify the structure of the paper and better described the
  meaning of the statements and how they fit into the overall proof. 24 pages,
  10 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0911.5157v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0911.5157v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0912.3923v1</id>
    <updated>2009-12-19T18:47:39Z</updated>
    <published>2009-12-19T18:47:39Z</published>
    <title>Secure Watermarking Scheme for Color Image Using Intensity of Pixel and
  LSB Substitution</title>
    <summary>  In this paper a novel spatial domain LSB based watermarking scheme for color
Images is proposed. The proposed scheme is of type blind and invisible
watermarking. Our scheme introduces the concept of storing variable number of
bits in each pixel based on the actual color value of pixel. Equal or higher
the color value of channels with respect to intensity of pixel stores higher
number of watermark bits. The Red, Green and Blue channel of the color image
has been used for watermark embedding. The watermark is embedded into selected
channels of pixel. The proposed method supports high watermark embedding
capacity, which is equivalent to the size of cover image. The security of
watermark is preserved by permuting the watermark bits using secret key. The
proposed scheme is found robust to various image processing operations such as
image compression, blurring, salt and pepper noise, filtering and cropping.
</summary>
    <author>
      <name>Nagaraj V. Dharwadkar</name>
    </author>
    <author>
      <name>B. B. Amberker</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Computing, Volume 1, Issue 1, pp 1-6, December 2009</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0912.3923v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0912.3923v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0912.5380v1</id>
    <updated>2009-12-30T18:07:56Z</updated>
    <published>2009-12-30T18:07:56Z</published>
    <title>Computing Principal Components Dynamically</title>
    <summary>  In this paper we present closed-form solutions for efficiently updating the
principal components of a set of $n$ points, when $m$ points are added or
deleted from the point set. For both operations performed on a discrete point
set in $\mathbb{R}^d$, we can compute the new principal components in $O(m)$
time for fixed $d$. This is a significant improvement over the commonly used
approach of recomputing the principal components from scratch, which takes
$O(n+m)$ time. An important application of the above result is the dynamical
computation of bounding boxes based on principal component analysis. PCA
bounding boxes are very often used in many fields, among others in computer
graphics for collision detection and fast rendering. We have implemented and
evaluated few algorithms for computing dynamically PCA bounding boxes in
$\mathbb{R}^3$. In addition, we present closed-form solutions for computing
dynamically principal components of continuous point sets in $\mathbb{R}^2$ and
$\mathbb{R}^3$. In both cases, discrete and continuous, to compute the new
principal components, no additional data structures or storage are needed.
</summary>
    <author>
      <name>Darko Dimitrov</name>
    </author>
    <author>
      <name>Mathias Holst</name>
    </author>
    <author>
      <name>Christian Knauer</name>
    </author>
    <author>
      <name>Klaus Kriegel</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">32 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0912.5380v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0912.5380v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0912.5494v1</id>
    <updated>2009-12-30T17:53:18Z</updated>
    <published>2009-12-30T17:53:18Z</published>
    <title>Teaching Physical Based Animation via OpenGL Slides</title>
    <summary>  This work expands further our earlier poster presentation and integration of
the OpenGL Slides Framework (OGLSF) - to make presentations with real-time
animated graphics where each slide is a scene with tidgets - and physical based
animation of elastic two-, three-layer softbody objects. The whole project is
very interactive, and serves dual purpose - delivering the teaching material in
a classroom setting with real running animated examples as well as releasing
the source code to the students to show how the actual working things are made.
</summary>
    <author>
      <name>Miao Song</name>
    </author>
    <author>
      <name>Serguei A. Mokhov</name>
    </author>
    <author>
      <name>Peter Grogono</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-90-481-9112-3_82 10.1145/1557626.1557647</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-90-481-9112-3_82" rel="related"/>
    <link title="doi" href="http://dx.doi.org/10.1145/1557626.1557647" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages; 7 figures; the poster is presented at C32SE'09 and the
  paper at CISSE'09 at http://conference.cisse2009.org/proceedings.aspx ; there
  are an executable demo and its source code</arxiv:comment>
    <link href="http://arxiv.org/abs/0912.5494v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0912.5494v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.7; I.3.6; I.4.9; H.5.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1002.4006v1</id>
    <updated>2010-02-21T19:46:12Z</updated>
    <published>2010-02-21T19:46:12Z</published>
    <title>Text/Graphics Separation and Skew Correction of Text Regions of Business
  Card Images for Mobile Devices</title>
    <summary>  Separation of the text regions from background texture and graphics is an
important step of any optical character recognition system for the images
containing both texts and graphics. In this paper, we have presented a novel
text/graphics separation technique and a method for skew correction of text
regions extracted from business card images captured with a cell-phone camera.
At first, the background is eliminated at a coarse level based on intensity
variance. This makes the foreground components distinct from each other. Then
the non-text components are removed using various characteristic features of
text and graphics. Finally, the text regions are skew corrected for further
processing. Experimenting with business card images of various resolutions, we
have found an optimum performance of 98.25% (recall) with 0.75 MP images, that
takes 0.17 seconds processing time and 1.1 MB peak memory on a moderately
powerful computer (DualCore 1.73 GHz Processor, 1 GB RAM, 1 MB L2 Cache). The
developed technique is computationally efficient and consumes low memory so as
to be applicable on mobile devices.
</summary>
    <author>
      <name>Ayatullah Faruk Mollah</name>
    </author>
    <author>
      <name>Subhadip Basu</name>
    </author>
    <author>
      <name>Mita Nasipuri</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Computing, Volume 2, Issue 2, February 2010,
  https://sites.google.com/site/journalofcomputing/</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1002.4006v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1002.4006v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1003.4036v1</id>
    <updated>2010-03-21T23:32:56Z</updated>
    <published>2010-03-21T23:32:56Z</published>
    <title>A Very Simple Approach for 3-D to 2-D Mapping</title>
    <summary>  Many times we need to plot 3-D functions e.g., in many scientificc
experiments. To plot this 3-D functions on 2-D screen it requires some kind of
mapping. Though OpenGL, DirectX etc 3-D rendering libraries have made this job
very simple, still these libraries come with many complex pre- operations that
are simply not intended, also to integrate these libraries with any kind of
system is often a tough trial. This article presents a very simple method of
mapping from 3D to 2D, that is free from any complex pre-operation, also it
will work with any graphics system where we have some primitive 2-D graphics
function. Also we discuss the inverse transform and how to do basic computer
graphics transformations using our coordinate mapping system.
</summary>
    <author>
      <name>Sandipan Dey</name>
    </author>
    <author>
      <name>Ajith Abraham</name>
    </author>
    <author>
      <name>Sugata Sanyal</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 Pages, 5 Figures,</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal on Image Processing and Communications ,
  Poland, Editor-in-Chief: R. S. Choras; Volume 11, No. 2, pp. 75 - 82, 2007.</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1003.4036v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1003.4036v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1004.0766v1</id>
    <updated>2010-04-06T03:54:27Z</updated>
    <published>2010-04-06T03:54:27Z</published>
    <title>Text/Graphics Separation for Business Card Images for Mobile Devices</title>
    <summary>  Separation of the text regions from background texture and graphics is an
important step of any optical character recognition sytem for the images
containg both texts and graphics. In this paper, we have presented a novel
text/graphics separation technique for business card images captured with a
cell-phone camera. At first, the background is eliminated at a coarse level
based on intensity variance. This makes the foreground components distinct from
each other. Then the non-text components are removed using various
characteristic features of text and graphics. Finally, the text regions are
skew corrected and binarized for further processing. Experimenting with
business card images of various resolutions, we have found an optimum
performance of 98.54% with 0.75 MP images, that takes 0.17 seconds processing
time and 1.1 MB peak memory on a moderately powerful computer (DualCore 1.73
GHz Processor, 1 GB RAM, 1 MB L2 Cache). The developed technique is
computationally efficient and consumes low memory so as to be applicable on
mobile devices.
</summary>
    <author>
      <name>Ayatullah Faruk Mollah</name>
    </author>
    <author>
      <name>Subhadip Basu</name>
    </author>
    <author>
      <name>Mita Nasipuri</name>
    </author>
    <author>
      <name>Dipak Kumar Basu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. IAPR International Workshop on Graphics Recognition (2009)
  263-270</arxiv:comment>
    <link href="http://arxiv.org/abs/1004.0766v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1004.0766v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1004.2447v1</id>
    <updated>2010-04-14T16:40:41Z</updated>
    <published>2010-04-14T16:40:41Z</published>
    <title>Autoplot: A browser for scientific data on the web</title>
    <summary>  Autoplot is software developed for the Virtual Observatories in Heliophysics
to provide intelligent and automated plotting capabilities for many typical
data products that are stored in a variety of file formats or databases.
Autoplot has proven to be a flexible tool for exploring, accessing, and viewing
data resources as typically found on the web, usually in the form of a
directory containing data files with multiple parameters contained in each
file. Data from a data source is abstracted into a common internal data model
called QDataSet. Autoplot is built from individually useful components, and can
be extended and reused to create specialized data handling and analysis
applications and is being used in a variety of science visualization and
analysis applications. Although originally developed for viewing
heliophysics-related time series and spectrograms, its flexible and generic
data representation model makes it potentially useful for the Earth sciences.
</summary>
    <author>
      <name>J. Faden</name>
    </author>
    <author>
      <name>R. S. Weigel</name>
    </author>
    <author>
      <name>J. Merka</name>
    </author>
    <author>
      <name>R. H. W. Friedel</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s12145-010-0049-0</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s12145-010-0049-0" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1004.2447v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1004.2447v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.space-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1005.3181v1</id>
    <updated>2010-05-18T13:01:46Z</updated>
    <published>2010-05-18T13:01:46Z</published>
    <title>Multi-sensorial interaction with a nano-scale phenomenon : the force
  curve</title>
    <summary>  Using Atomic Force Microscopes (AFM) to manipulate nano-objects is an actual
challenge for surface scientists. Basic haptic interfacesbetween the AFM and
experimentalists have already been implemented. Themulti-sensory renderings
(seeing, hearing and feeling) studied from acognitive point of view increase
the efficiency of the actual interfaces. Toallow the experimentalist to feel
and touch the nano-world, we add mixedrealities between an AFM and a force
feedback device, enriching thus thedirect connection by a modeling engine. We
present in this paper the firstresults from a real-time remote-control handling
of an AFM by our ForceFeedback Gestural Device through the example of the
approach-retract curve.
</summary>
    <author>
      <name>Sylvain Marliere</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LEPES</arxiv:affiliation>
    </author>
    <author>
      <name>Daniela Urma</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">ICA</arxiv:affiliation>
    </author>
    <author>
      <name>Jean-Loup Florens</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">ACROE</arxiv:affiliation>
    </author>
    <author>
      <name>Florence Marchi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LEPES</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EuroHaptics 2004, Munich : Germany (2004)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1005.3181v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1005.3181v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1005.4563v1</id>
    <updated>2010-05-25T13:14:11Z</updated>
    <published>2010-05-25T13:14:11Z</published>
    <title>Physically-based particle simulation and visualization of pastes and
  gels</title>
    <summary>  This paper is focused on the question of simulation and visualiza- tion of 3D
gel and paste dynamic effects. In a first part, we introduce a 3D physically
based particle (or mass-interaction) model, with a small number of masses and
few powerful interaction parameters, which is able to generate the dynamic
features of both gels and pastes. This model proves that the 3D
mass-interaction method is relevant for the simulation of such phenomena,
without an explicit knowledge of their underly- ing physics. In a second part,
we expose an original rendering process, the Flow Structuring Method that
enhances the dynamic properties of the simulation and offers a realistic
visualization. This process ignores all the properties of the underlying
physical model. It leads to a reconstruction of the spatial structure of the
gel (or paste) flow only through an analysis of the output of the simula- tion
which is a set of unorganized points moving in a 3D space. Finally, the paper
presents realistic renderings obtained by using implicit surfaces and
ray-tracing techniques on the Structured Flow previously obtained.
</summary>
    <author>
      <name>Claire Guilbaud</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">ICA</arxiv:affiliation>
    </author>
    <author>
      <name>Annie Luciani</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">ACROE</arxiv:affiliation>
    </author>
    <author>
      <name>Nicolas Castagné</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">ACROE</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Graphicon 2003, Moscou : Russie, F\'ed\'eration De (2003)</arxiv:comment>
    <link href="http://arxiv.org/abs/1005.4563v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1005.4563v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1009.5183v1</id>
    <updated>2010-09-27T08:16:36Z</updated>
    <published>2010-09-27T08:16:36Z</published>
    <title>A Framework for an Ego-centered and Time-aware Visualization of
  Relations in Arbitrary Data Repositories</title>
    <summary>  Understanding constellations in large data collections has become a common
task. One obstacle a user has to overcome is the internal complexity of these
repositories. For example, extracting connected data from a normalized
relational database requires knowledge of the table structure which might not
be available for the casual user. In this paper we present a visualization
framework which presents the collection as a set of entities and relations (on
the data level). Using rating functions, we divide large relation networks into
small graphs which resemble ego-centered networks. These graphs are connected
so the user can browse from one to another. To further assist the user, we
present two views which embed information on the evolution of the relations
into the graphs. Each view emphasizes another aspect of temporal development.
The framework can be adapted to any repository by a flexible data interface and
a graph configuration file. We present some first web-based applications
including a visualization of the DBLP data set. We use the DBLP visualization
to evaluate our approach.
</summary>
    <author>
      <name>Florian Reitz</name>
    </author>
    <link href="http://arxiv.org/abs/1009.5183v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1009.5183v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1101.0395v1</id>
    <updated>2011-01-02T10:09:11Z</updated>
    <published>2011-01-02T10:09:11Z</published>
    <title>Improving the Performance of K-Means for Color Quantization</title>
    <summary>  Color quantization is an important operation with many applications in
graphics and image processing. Most quantization methods are essentially based
on data clustering algorithms. However, despite its popularity as a general
purpose clustering algorithm, k-means has not received much respect in the
color quantization literature because of its high computational requirements
and sensitivity to initialization. In this paper, we investigate the
performance of k-means as a color quantizer. We implement fast and exact
variants of k-means with several initialization schemes and then compare the
resulting quantizers to some of the most popular quantizers in the literature.
Experiments on a diverse set of images demonstrate that an efficient
implementation of k-means with an appropriate initialization strategy can in
fact serve as a very effective color quantizer.
</summary>
    <author>
      <name>M. Emre Celebi</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.imavis.2010.10.002</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.imavis.2010.10.002" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">26 pages, 4 figures, 13 tables</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Image and Vision Computing 29 (2011) 260-271</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1101.0395v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1101.0395v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.4.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1101.0663v1</id>
    <updated>2011-01-04T06:53:36Z</updated>
    <published>2011-01-04T06:53:36Z</published>
    <title>The Role of Computer Graphics in Documentary Film Production</title>
    <summary>  We discuss a topic on the role of computer graphics in the production of
documentaries, which is often ignored in favor of other topics. Typically,
except for some rare occasions, documentary producers and computer scientists
or digital artists that do computer graphics are relatively far apart in their
domains and rarely intercommunicate to have a joint production; yet it happens,
and perhaps more so in the present and the future.
  We attempt to classify the documentaries on the amount and techniques of
computer graphics used for documentaries. We come up with the initial
categories such as "plain" (no graphics), "in-between", "all-out" -- nearly
100% of the documentary consisting of computer-generated imagery. Computer
graphics can be used to enhance the scenery, fill in the gaps in the missing
storyline pieces, or animate between scenes. It can incorporate stereoscopic
effects for higher viewer impression as well as interactivity aspects. It can
also be used simply in old archived image and film restoration.
</summary>
    <author>
      <name>Miao Song</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">35 pages; 7 figures; an April 2009 research paper</arxiv:comment>
    <link href="http://arxiv.org/abs/1101.0663v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1101.0663v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1101.1240v1</id>
    <updated>2010-12-13T18:45:13Z</updated>
    <published>2010-12-13T18:45:13Z</published>
    <title>Chameleon: A Color-Adaptive Web Browser for Mobile OLED Displays</title>
    <summary>  Displays based on organic light-emitting diode (OLED) technology are
appearing on many mobile devices. Unlike liquid crystal displays (LCD), OLED
displays consume dramatically different power for showing different colors. In
particular, OLED displays are inefficient for showing bright colors. This has
made them undesirable for mobile devices because much of the web content is of
bright colors.
  To tackle this problem, we present the motivational studies, design, and
realization of Chameleon, a color adaptive web browser that renders web pages
with power-optimized color schemes under user-supplied constraints. Driven by
the findings from our motivational studies, Chameleon provides end users with
important options, offloads tasks that are not absolutely needed in real-time,
and accomplishes real-time tasks by carefully enhancing the codebase of a
browser engine. According to measure-ments with OLED smartphones, Chameleon is
able to re-duce average system power consumption for web browsing by 41% and
reduce display power consumption by 64% without introducing any noticeable
delay.
</summary>
    <author>
      <name>Mian Dong</name>
    </author>
    <author>
      <name>Lin Zhong</name>
    </author>
    <link href="http://arxiv.org/abs/1101.1240v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1101.1240v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1101.5490v1</id>
    <updated>2011-01-28T09:41:43Z</updated>
    <published>2011-01-28T09:41:43Z</published>
    <title>Ray-Based Reflectance Model for Diffraction</title>
    <summary>  We present a novel method of simulating wave effects in graphics using
ray--based renderers with a new function: the Wave BSDF (Bidirectional
Scattering Distribution Function). Reflections from neighboring surface patches
represented by local BSDFs are mutually independent. However, in many surfaces
with wavelength-scale microstructures, interference and diffraction requires a
joint analysis of reflected wavefronts from neighboring patches. We demonstrate
a simple method to compute the BSDF for the entire microstructure, which can be
used independently for each patch. This allows us to use traditional ray--based
rendering pipelines to synthesize wave effects of light and sound. We exploit
the Wigner Distribution Function (WDF) to create transmissive, reflective, and
emissive BSDFs for various diffraction phenomena in a physically accurate way.
In contrast to previous methods for computing interference, we circumvent the
need to explicitly keep track of the phase of the wave by using BSDFs that
include positive as well as negative coefficients. We describe and compare the
theory in relation to well understood concepts in rendering and demonstrate a
straightforward implementation. In conjunction with standard raytracers, such
as PBRT, we demonstrate wave effects for a range of scenarios such as
multi--bounce diffraction materials, holograms and reflection of high frequency
surfaces.
</summary>
    <author>
      <name>Tom Cuypers</name>
    </author>
    <author>
      <name>Se Baek Oh</name>
    </author>
    <author>
      <name>Tom Haber</name>
    </author>
    <author>
      <name>Philippe Bekaert</name>
    </author>
    <author>
      <name>Ramesh Raskar</name>
    </author>
    <link href="http://arxiv.org/abs/1101.5490v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1101.5490v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1102.0634v1</id>
    <updated>2011-02-03T10:00:15Z</updated>
    <published>2011-02-03T10:00:15Z</published>
    <title>Glioblastoma Multiforme Segmentation in MRI Data with a Balloon
  Inflation Approach</title>
    <summary>  Gliomas are the most common primary brain tumors, evolving from the cerebral
supportive cells. For clinical follow-up, the evaluation of the preoperative
tumor volume is essential. Volumetric assessment of tumor volume with manual
segmentation of its outlines is a time-consuming process that can be overcome
with the help of computer-assisted segmentation methods. In this paper, a
semi-automatic approach for World Health Organization (WHO) grade IV glioma
segmentation is introduced that uses balloon inflation forces, and relies on
the detection of high-intensity tumor boundaries that are coupled by using
contrast agent gadolinium. The presented method is evaluated on 27 magnetic
resonance imaging (MRI) data sets and the ground truth data of the tumor
boundaries - for evaluation of the results - are manually extracted by
neurosurgeons.
</summary>
    <author>
      <name>Dženan Zukić</name>
    </author>
    <author>
      <name>Jan Egger</name>
    </author>
    <author>
      <name>Miriam H. A. Bauer</name>
    </author>
    <author>
      <name>Daniela Kuhnt</name>
    </author>
    <author>
      <name>Barbara Carl</name>
    </author>
    <author>
      <name>Bernd Freisleben</name>
    </author>
    <author>
      <name>Andreas Kolb</name>
    </author>
    <author>
      <name>Christopher Nimsky</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 4 figures, Proc. of the 6th Russian-Bavarian Conference on
  Bio-Medical Engineering</arxiv:comment>
    <link href="http://arxiv.org/abs/1102.0634v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1102.0634v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1102.2652v1</id>
    <updated>2011-02-14T01:09:24Z</updated>
    <published>2011-02-14T01:09:24Z</published>
    <title>Rule-based transformations for geometric modelling</title>
    <summary>  The context of this paper is the use of formal methods for topology-based
geometric modelling. Topology-based geometric modelling deals with objects of
various dimensions and shapes. Usually, objects are defined by a graph-based
topological data structure and by an embedding that associates each topological
element (vertex, edge, face, etc.) with relevant data as their geometric shape
(position, curve, surface, etc.) or application dedicated data (e.g. molecule
concentration level in a biological context). We propose to define
topology-based geometric objects as labelled graphs. The arc labelling defines
the topological structure of the object whose topological consistency is then
ensured by labelling constraints. Nodes have as many labels as there are
different data kinds in the embedding. Labelling constraints ensure then that
the embedding is consistent with the topological structure. Thus,
topology-based geometric objects constitute a particular subclass of a category
of labelled graphs in which nodes have multiple labels.
</summary>
    <author>
      <name>Thomas Bellet</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Poitiers</arxiv:affiliation>
    </author>
    <author>
      <name>Agnès Arnould</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Poitiers</arxiv:affiliation>
    </author>
    <author>
      <name>Pascale Le Gall</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Ecole Centrale Paris</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.48.5</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.48.5" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings TERMGRAPH 2011, arXiv:1102.2268</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 48, 2011, pp. 20-37</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1102.2652v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1102.2652v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.5; G.2.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1102.3328v1</id>
    <updated>2011-02-16T13:04:18Z</updated>
    <published>2011-02-16T13:04:18Z</published>
    <title>An Efficient and Integrated Algorithm for Video Enhancement in
  Challenging Lighting Conditions</title>
    <summary>  We describe a novel integrated algorithm for real-time enhancement of video
acquired under challenging lighting conditions. Such conditions include low
lighting, haze, and high dynamic range situations. The algorithm automatically
detects the dominate source of impairment, then depending on whether it is low
lighting, haze or others, a corresponding pre-processing is applied to the
input video, followed by the core enhancement algorithm. Temporal and spatial
redundancies in the video input are utilized to facilitate real-time processing
and to improve temporal and spatial consistency of the output. The proposed
algorithm can be used as an independent module, or be integrated in either a
video encoder or a video decoder for further optimizations.
</summary>
    <author>
      <name>Xuan Dong</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Gene</arxiv:affiliation>
    </author>
    <author>
      <name> Jiangtao</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Gene</arxiv:affiliation>
    </author>
    <author>
      <name> Wen</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Amy</arxiv:affiliation>
    </author>
    <author>
      <name>Weixin Li</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Amy</arxiv:affiliation>
    </author>
    <author>
      <name> Yi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Amy</arxiv:affiliation>
    </author>
    <author>
      <name> Pang</name>
    </author>
    <author>
      <name>Guan Wang</name>
    </author>
    <author>
      <name>Yao Lu</name>
    </author>
    <author>
      <name>Wei Meng</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 23 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1102.3328v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1102.3328v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1102.4992v1</id>
    <updated>2011-02-24T13:54:29Z</updated>
    <published>2011-02-24T13:54:29Z</published>
    <title>Mathematics of Human Motion: from Animation towards Simulation (A View
  form the Outside)</title>
    <summary>  Simulation of human motion is the subject of study in a number of
disciplines: Biomechanics, Robotics, Computer Animation, Control Theory,
Neurophysiology, Medicine, Ergonomics. Since the author has never visited any
of these fields, this review is indeed a passer-by's impression. On the other
hand, he happens to be a human (who occasionally is moving) and, as everybody
else, rates himself an expert in Applied Common Sense. Thus the author hopes
that this view from the {\em outside} will be of some interest not only for the
strangers like himself, but for those who are {\em inside} as well.
  Two flaws of the text that follows are inevitable. First, some essential
issues that are too familar to the specialists to discuss them may be missing.
Second, the author probably failed to provide the uniform "level-of-detail" for
this wide range of topics.
</summary>
    <author>
      <name>A. I. Zhmakin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appendix: "The Animator's Eleven Commandments"</arxiv:comment>
    <link href="http://arxiv.org/abs/1102.4992v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1102.4992v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.4271v2</id>
    <updated>2011-06-02T18:11:55Z</updated>
    <published>2011-03-22T14:16:07Z</published>
    <title>Rendering of 3D Dynamic Virtual Environments</title>
    <summary>  In this paper we present a framework for the rendering of dynamic 3D virtual
environments which can be integrated in the development of videogames. It
includes methods to manage sounds and particle effects, paged static
geometries, the support of a physics engine and various input systems. It has
been designed with a modular structure to allow future expansions. We exploited
some open-source state-of-the-art components such as OGRE, PhysX,
ParticleUniverse, etc.; all of them have been properly integrated to obtain
peculiar physical and environmental effects. The stand-alone version of the
application is fully compatible with Direct3D and OpenGL APIs and adopts OpenAL
APIs to manage audio cards. Concluding, we devised a showcase demo which
reproduces a dynamic 3D environment, including some particular effects: the
alternation of day and night infuencing the lighting of the scene, the
rendering of terrain, water and vegetation, the reproduction of sounds and
atmospheric agents.
</summary>
    <author>
      <name>Salvatore Catanese</name>
    </author>
    <author>
      <name>Emilio Ferrara</name>
    </author>
    <author>
      <name>Giacomo Fiumara</name>
    </author>
    <author>
      <name>Francesco Pagano</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4108/icst.simutools.2011.245524</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4108/icst.simutools.2011.245524" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 11 figures, Proceedings of the 4th International ICST
  Conference on Simulation Tools and Techniques (2011)</arxiv:comment>
    <link href="http://arxiv.org/abs/1103.4271v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.4271v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.1; I.2.1; I.3.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1105.5678v1</id>
    <updated>2011-05-28T02:28:19Z</updated>
    <published>2011-05-28T02:28:19Z</published>
    <title>Time-Dependent 2-D Vector Field Topology: An Approach Inspired by
  Lagrangian Coherent Structures</title>
    <summary>  This paper presents an approach to a time-dependent variant of the concept of
vector field topology for 2-D vector fields. Vector field topology is defined
for steady vector fields and aims at discriminating the domain of a vector
field into regions of qualitatively different behaviour. The presented approach
represents a generalization for saddle-type critical points and their
separatrices to unsteady vector fields based on generalized streak lines, with
the classical vector field topology as its special case for steady vector
fields. The concept is closely related to that of Lagrangian coherent
structures obtained as ridges in the finite-time Lyapunov exponent field. The
proposed approach is evaluated on both 2-D time-dependent synthetic and vector
fields from computational fluid dynamics.
</summary>
    <author>
      <name>Filip Sadlo</name>
    </author>
    <author>
      <name>Daniel Weiskopf</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1111/j.1467-8659.2009.01546.x</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1111/j.1467-8659.2009.01546.x" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Computer Graphics Forum, Volume 29, Issue 1, pages 88-100, March
  2010</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1105.5678v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1105.5678v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.CD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.flu-dyn" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.8; J.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1106.2877v1</id>
    <updated>2011-06-15T05:35:51Z</updated>
    <published>2011-06-15T05:35:51Z</published>
    <title>Injectivity of 2D Toric Bézier Patches</title>
    <summary>  Rational B\'{e}zier functions are widely used as mapping functions in surface
reparameterization, finite element analysis, image warping and morphing. The
injectivity (one-to-one property) of a mapping function is typically necessary
for these applications. Toric B\'{e}zier patches are generalizations of
classical patches (triangular, tensor product) which are defined on the convex
hull of a set of integer lattice points. We give a geometric condition on the
control points that we show is equivalent to the injectivity of every 2D toric
B\'{e}zier patch with those control points for all possible choices of weights.
This condition refines that of Craciun, et al., which only implied injectivity
on the interior of a patch.
</summary>
    <author>
      <name>Frank Sottile</name>
    </author>
    <author>
      <name>Chungang Zhu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, extended abstract, to be publised in Proceedings of
  CAD/Graphis 2011</arxiv:comment>
    <link href="http://arxiv.org/abs/1106.2877v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1106.2877v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.AG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65D17, 14M25" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1109.6073v1</id>
    <updated>2011-09-28T01:44:43Z</updated>
    <published>2011-09-28T01:44:43Z</published>
    <title>Evaluation of a Bundling Technique for Parallel Coordinates</title>
    <summary>  We describe a technique for bundled curve representations in
parallel-coordinates plots and present a controlled user study evaluating their
effectiveness. Replacing the traditional C^0 polygonal lines by C^1 continuous
piecewise Bezier curves makes it easier to visually trace data points through
each coordinate axis. The resulting Bezier curves can then be bundled to
visualize data with given cluster structures. Curve bundles are efficient to
compute, provide visual separation between data clusters, reduce visual
clutter, and present a clearer overview of the dataset. A controlled user study
with 14 participants confirmed the effectiveness of curve bundling for
parallel-coordinates visualization: 1) compared to polygonal lines, it is
equally capable of revealing correlations between neighboring data attributes;
2) its geometric cues can be effective in displaying cluster information. For
some datasets curve bundling allows the color perceptual channel to be applied
to other data attributes, while for complex cluster patterns, bundling and
color can represent clustering far more clearly than either alone.
</summary>
    <author>
      <name>Julian Heinrich</name>
    </author>
    <author>
      <name>Yuan Luo</name>
    </author>
    <author>
      <name>Arthur E. Kirkpatrick</name>
    </author>
    <author>
      <name>Hao Zhang</name>
    </author>
    <author>
      <name>Daniel Weiskopf</name>
    </author>
    <link href="http://arxiv.org/abs/1109.6073v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1109.6073v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1109.6494v1</id>
    <updated>2011-09-29T11:50:29Z</updated>
    <published>2011-09-29T11:50:29Z</published>
    <title>A Survey of Ocean Simulation and Rendering Techniques in Computer
  Graphics</title>
    <summary>  This paper presents a survey of ocean simulation and rendering methods in
computer graphics. To model and animate the ocean's surface, these methods
mainly rely on two main approaches: on the one hand, those which approximate
ocean dynamics with parametric, spectral or hybrid models and use empirical
laws from oceanographic research. We will see that this type of methods
essentially allows the simulation of ocean scenes in the deep water domain,
without breaking waves. On the other hand, physically-based methods use
Navier-Stokes Equations (NSE) to represent breaking waves and more generally
ocean surface near the shore. We also describe ocean rendering methods in
computer graphics, with a special interest in the simulation of phenomena such
as foam and spray, and light's interaction with the ocean surface.
</summary>
    <author>
      <name>Emmanuelle Darles</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">XLIM</arxiv:affiliation>
    </author>
    <author>
      <name>Benoît Crespin</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">XLIM</arxiv:affiliation>
    </author>
    <author>
      <name>Djamchid Ghazanfarpour</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">XLIM</arxiv:affiliation>
    </author>
    <author>
      <name>Jean-Christophe Gonzato</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Bordeaux - Sud-Ouest, LaBRI</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1111/j.1467-8659.2010.01828.x</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1111/j.1467-8659.2010.01828.x" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Computer Graphics Forum 30, 1 (2011) 43-60</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1109.6494v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1109.6494v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1112.6032v1</id>
    <updated>2011-12-27T23:40:12Z</updated>
    <published>2011-12-27T23:40:12Z</published>
    <title>A self-rendering digital image encoding</title>
    <summary>  Without careful long-term preservation digital data may be lost to a number
of factors, including physical media decay, lack of suitable decoding
equipment, and the absence of software. When raw data can be read but lack
suitable annotations as to provenance, the ability to interpret them is more
straightforward if they can be assessed through simple visual techniques. In
this regard digital images are a special case since their data have a natural
representation on two-dimensional media surfaces. This paper presents a novel
binary image pixel encoding that produces an approximate analog rendering of
encoded images when the image bits are arranged spatially in an appropriate
manner. This simultaneous digital and analog representation acts to inseparably
annotate bits as image data, which may contribute to the longevity of
so-encoded images.
</summary>
    <author>
      <name>Daniel L. Ruderman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1112.6032v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1112.6032v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.4734v1</id>
    <updated>2012-04-20T20:05:46Z</updated>
    <published>2012-04-20T20:05:46Z</published>
    <title>Numerical Analysis of Diagonal-Preserving, Ripple-Minimizing and
  Low-Pass Image Resampling Methods</title>
    <summary>  Image resampling is a necessary component of any operation that changes the
size of an image or its geometry.
  Methods tuned for natural image upsampling (roughly speaking, image
enlargement) are analyzed and developed with a focus on their ability to
preserve diagonal features and suppress overshoots. Monotone, locally bounded
and almost monotone "direct" interpolation and filtering methods, as well as
face split and vertex split surface subdivision methods, alone or in
combination, are studied. Key properties are established by way of proofs and
counterexamples as well as numerical experiments involving 1D curve and 2D
diagonal data resampling.
  In addition, the Remez minimax method for the computation of low-cost
polynomial approximations of low-pass filter kernels tuned for natural image
downsampling (roughly speaking, image reduction) is refactored for relative
error minimization in the presence of roots in the interior of the interval of
approximation and so that even and odd functions are approximated with like
polynomials. The accuracy and frequency response of the approximations are
tabulated and plotted against the original, establishing their rapid
convergence.
</summary>
    <author>
      <name>Chantal Racette</name>
    </author>
    <link href="http://arxiv.org/abs/1204.4734v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.4734v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.6216v2</id>
    <updated>2012-09-12T16:53:47Z</updated>
    <published>2012-04-24T20:26:58Z</published>
    <title>Geodesics in Heat</title>
    <summary>  We introduce the heat method for computing the shortest geodesic distance to
a specified subset (e.g., point or curve) of a given domain. The heat method is
robust, efficient, and simple to implement since it is based on solving a pair
of standard linear elliptic problems. The method represents a significant
breakthrough in the practical computation of distance on a wide variety of
geometric domains, since the resulting linear systems can be prefactored once
and subsequently solved in near-linear time. In practice, distance can be
updated via the heat method an order of magnitude faster than with
state-of-the-art methods while maintaining a comparable level of accuracy. We
provide numerical evidence that the method converges to the exact geodesic
distance in the limit of refinement; we also explore smoothed approximations of
distance suitable for applications where more regularity is required.
</summary>
    <author>
      <name>Keenan Crane</name>
    </author>
    <author>
      <name>Clarisse Weischedel</name>
    </author>
    <author>
      <name>Max Wardetzky</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/2516971.2516977</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/2516971.2516977" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ACM Trans. Graph. 32 (5), 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1204.6216v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.6216v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.5204v1</id>
    <updated>2012-05-23T15:29:16Z</updated>
    <published>2012-05-23T15:29:16Z</published>
    <title>Visualizing 2D Flows with Animated Arrow Plots</title>
    <summary>  Flow fields are often represented by a set of static arrows to illustrate
scientific vulgarization, documentary film, meteorology, etc. This simple
schematic representation lets an observer intuitively interpret the main
properties of a flow: its orientation and velocity magnitude. We propose to
generate dynamic versions of such representations for 2D unsteady flow fields.
Our algorithm smoothly animates arrows along the flow while controlling their
density in the domain over time. Several strategies have been combined to lower
the unavoidable popping artifacts arising when arrows appear and disappear and
to achieve visually pleasing animations. Disturbing arrow rotations in low
velocity regions are also handled by continuously morphing arrow glyphs to
semi-transparent discs. To substantiate our method, we provide results for
synthetic and real velocity field datasets.
</summary>
    <author>
      <name>Bruno Jobard</name>
    </author>
    <author>
      <name>Nicolas Ray</name>
    </author>
    <author>
      <name>Dmitry Sokolov</name>
    </author>
    <link href="http://arxiv.org/abs/1205.5204v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.5204v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.1148v2</id>
    <updated>2012-08-07T12:40:29Z</updated>
    <published>2012-06-06T08:38:27Z</published>
    <title>From individual to population: Challenges in Medical Visualization</title>
    <summary>  In this paper, we first give a high-level overview of medical visualization
development over the past 30 years, focusing on key developments and the trends
that they represent. During this discussion, we will refer to a number of key
papers that we have also arranged on the medical visualization research
timeline. Based on the overview and our observations of the field, we then
identify and discuss the medical visualization research challenges that we
foresee for the coming decade.
</summary>
    <author>
      <name>Charl P. Botha</name>
    </author>
    <author>
      <name>Bernhard Preim</name>
    </author>
    <author>
      <name>Arie Kaufman</name>
    </author>
    <author>
      <name>Shigeo Takahashi</name>
    </author>
    <author>
      <name>Anders Ynnerman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Improvements based on comments by reviewers: Typos and layout issues
  fixed. Added two more multi-modal volume rendering references to 2.1. Added
  more detail on Virtual Colonoscopy to 2.2</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.1148v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.1148v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.med-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.1428v2</id>
    <updated>2012-08-07T12:19:28Z</updated>
    <published>2012-06-07T09:17:34Z</published>
    <title>Visualization in Connectomics</title>
    <summary>  Connectomics is a field of neuroscience that analyzes neuronal connections. A
connectome is a complete map of a neuronal system, comprising all neuronal
connections between its structures. The term "connectome" is close to the word
"genome" and implies completeness of all neuronal connections, in the same way
as a genome is a complete listing of all nucleotide sequences. The goal of
connectomics is to create a complete representation of the brain's wiring. Such
a representation is believed to increase our understanding of how functional
brain states emerge from their underlying anatomical structure. Furthermore, it
can provide important information for the cure of neuronal dysfunctions like
schizophrenia or autism. In this paper, we review the current state-of-the-art
of visualization and image processing techniques in the field of connectomics
and describe some remaining challenges.
</summary>
    <author>
      <name>Hanspeter Pfister</name>
    </author>
    <author>
      <name>Verena Kaynig</name>
    </author>
    <author>
      <name>Charl P. Botha</name>
    </author>
    <author>
      <name>Stefan Bruckner</name>
    </author>
    <author>
      <name>Vincent J. Dercksen</name>
    </author>
    <author>
      <name>Hans-Christian Hege</name>
    </author>
    <author>
      <name>Jos B. T. M. Roerdink</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Improved definition of diffusion PDF. Integrated reviewer comments:
  Added figures showing DTI tractography and glyphs, fMRI connectivity vis, EM
  reconstruction of neuronal structures, Brainbow image. Typos and grammar
  errors fixed. Description of connectivity matrix added</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.1428v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.1428v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.3975v1</id>
    <updated>2012-06-18T16:05:47Z</updated>
    <published>2012-06-18T16:05:47Z</published>
    <title>The Ultrasound Visualization Pipeline - A Survey</title>
    <summary>  Ultrasound is one of the most frequently used imaging modality in medicine.
The high spatial resolution, its interactive nature and non-invasiveness makes
it the first choice in many examinations. Image interpretation is one of
ultrasound's main challenges. Much training is required to obtain a confident
skill level in ultrasound-based diagnostics. State-of-the-art graphics
techniques is needed to provide meaningful visualizations of ultrasound in
real-time. In this paper we present the process-pipeline for ultrasound
visualization, including an overview of the tasks performed in the specific
steps. To provide an insight into the trends of ultrasound visualization
research, we have selected a set of significant publications and divided them
into a technique-based taxonomy covering the topics pre-processing,
segmentation, registration, rendering and augmented reality. For the different
technique types we discuss the difference between ultrasound-based techniques
and techniques for other modalities.
</summary>
    <author>
      <name>Åsmund Birkeland</name>
    </author>
    <author>
      <name>Veronika Solteszova</name>
    </author>
    <author>
      <name>Dieter Hönigmann</name>
    </author>
    <author>
      <name>Odd Helge Gilja</name>
    </author>
    <author>
      <name>Svein Brekke</name>
    </author>
    <author>
      <name>Timo Ropinski</name>
    </author>
    <author>
      <name>Ivan Viola</name>
    </author>
    <link href="http://arxiv.org/abs/1206.3975v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.3975v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.6850v1</id>
    <updated>2012-06-27T16:24:29Z</updated>
    <published>2012-06-27T16:24:29Z</published>
    <title>Visualization of Collaborative Data</title>
    <summary>  Collaborative data consist of ratings relating two distinct sets of objects:
users and items. Much of the work with such data focuses on filtering:
predicting unknown ratings for pairs of users and items. In this paper we focus
on the problem of visualizing the information. Given all of the ratings, our
task is to embed all of the users and items as points in the same Euclidean
space. We would like to place users near items that they have rated (or would
rate) high, and far away from those they would give a low rating. We pose this
problem as a real-valued non-linear Bayesian network and employ Markov chain
Monte Carlo and expectation maximization to find an embedding. We present a
metric by which to judge the quality of a visualization and compare our results
to local linear embedding and Eigentaste on three real-world datasets.
</summary>
    <author>
      <name>Guobiao Mei</name>
    </author>
    <author>
      <name>Christian R. Shelton</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.6850v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.6850v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.3351v1</id>
    <updated>2012-07-13T13:13:27Z</updated>
    <published>2012-07-13T13:13:27Z</published>
    <title>Combining Brain-Computer Interfaces and Haptics: Detecting Mental
  Workload to Adapt Haptic Assistance</title>
    <summary>  In this paper we introduce the combined use of Brain-Computer Interfaces
(BCI) and Haptic interfaces. We propose to adapt haptic guides based on the
mental activity measured by a BCI system. This novel approach is illustrated
within a proof-of-concept system: haptic guides are toggled during a
path-following task thanks to a mental workload index provided by a BCI. The
aim of this system is to provide haptic assistance only when the user's brain
activity reflects a high mental workload. A user study conducted with 8
participants shows that our proof-of-concept is operational and exploitable.
Results show that activation of haptic guides occurs in the most difficult part
of the path-following task. Moreover it allows to increase task performance by
53% by activating assistance only 59% of the time. Taken together, these
results suggest that BCI could be used to determine when the user needs
assistance during haptic interaction and to enable haptic guides accordingly.
</summary>
    <author>
      <name>Laurent George</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA - IRISA</arxiv:affiliation>
    </author>
    <author>
      <name>Maud Marchal</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA - IRISA</arxiv:affiliation>
    </author>
    <author>
      <name>Loeïz Glondu</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA - IRISA</arxiv:affiliation>
    </author>
    <author>
      <name>Anatole Lécuyer</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA - IRISA</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-642-31401-8_12</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-642-31401-8_12" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">EuroHaptics (2012)</arxiv:comment>
    <link href="http://arxiv.org/abs/1207.3351v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.3351v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1208.3794v1</id>
    <updated>2012-08-18T23:40:24Z</updated>
    <published>2012-08-18T23:40:24Z</published>
    <title>General Midpoint Subdivision</title>
    <summary>  In this paper, we introduce two generalizations of midpoint subdivision and
analyze the smoothness of the resulting subdivision surfaces at regular and
extraordinary points.
  The smoothing operators used in midpoint and mid-edge subdivision connect the
midpoints of adjacent faces or of adjacent edges, respectively. An arbitrary
combination of these two operators and the refinement operator that splits each
face with m vertices into m quadrilateral subfaces forms a general midpoint
subdivision operator. We analyze the smoothness of the resulting subdivision
surfaces by estimating the norm of a special second order difference scheme and
by using established methods for analyzing midpoint subdivision. The surfaces
are smooth at their regular points and they are also smooth at extraordinary
points for a certain subclass of general midpoint subdivision schemes.
  Generalizing the smoothing rules of non general midpoint subdivision schemes
around extraordinary and regular vertices or faces results in a class of
subdivision schemes, which includes the Catmull-Clark algorithm with restricted
parameters. We call these subdivision schemes generalized Catmull-Clark schemes
and we analyze their smoothness properties.
</summary>
    <author>
      <name>Qi Chen</name>
    </author>
    <author>
      <name>Hartmut Prautzsch</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages, 13 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1208.3794v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1208.3794v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65D18, 65D17, 68U07, 68U05" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.6560v1</id>
    <updated>2012-09-28T16:05:37Z</updated>
    <published>2012-09-28T16:05:37Z</published>
    <title>Sparse Modeling of Intrinsic Correspondences</title>
    <summary>  We present a novel sparse modeling approach to non-rigid shape matching using
only the ability to detect repeatable regions. As the input to our algorithm,
we are given only two sets of regions in two shapes; no descriptors are
provided so the correspondence between the regions is not know, nor we know how
many regions correspond in the two shapes. We show that even with such scarce
information, it is possible to establish very accurate correspondence between
the shapes by using methods from the field of sparse modeling, being this, the
first non-trivial use of sparse models in shape correspondence. We formulate
the problem of permuted sparse coding, in which we solve simultaneously for an
unknown permutation ordering the regions on two shapes and for an unknown
correspondence in functional representation. We also propose a robust variant
capable of handling incomplete matches. Numerically, the problem is solved
efficiently by alternating the solution of a linear assignment and a sparse
coding problem. The proposed methods are evaluated qualitatively and
quantitatively on standard benchmarks containing both synthetic and scanned
objects.
</summary>
    <author>
      <name>J. Pokrass</name>
    </author>
    <author>
      <name>A. M. Bronstein</name>
    </author>
    <author>
      <name>M. M. Bronstein</name>
    </author>
    <author>
      <name>P. Sprechmann</name>
    </author>
    <author>
      <name>G. Sapiro</name>
    </author>
    <link href="http://arxiv.org/abs/1209.6560v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.6560v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.4490v1</id>
    <updated>2012-12-18T12:52:26Z</updated>
    <published>2012-12-18T12:52:26Z</published>
    <title>Sketch-to-Design: Context-based Part Assembly</title>
    <summary>  Designing 3D objects from scratch is difficult, especially when the user
intent is fuzzy without a clear target form. In the spirit of
modeling-by-example, we facilitate design by providing reference and
inspiration from existing model contexts. We rethink model design as navigating
through different possible combinations of part assemblies based on a large
collection of pre-segmented 3D models. We propose an interactive
sketch-to-design system, where the user sketches prominent features of parts to
combine. The sketched strokes are analyzed individually and in context with the
other parts to generate relevant shape suggestions via a design gallery
interface. As the session progresses and more parts get selected, contextual
cues becomes increasingly dominant and the system quickly converges to a final
design. As a key enabler, we use pre-learned part-based contextual information
to allow the user to quickly explore different combinations of parts. Our
experiments demonstrate the effectiveness of our approach for efficiently
designing new variations from existing shapes.
</summary>
    <author>
      <name>Xiaohua Xie</name>
    </author>
    <author>
      <name>Kai Xu</name>
    </author>
    <author>
      <name>Niloy J. Mitra</name>
    </author>
    <author>
      <name>Daniel Cohen-Or</name>
    </author>
    <author>
      <name>Baoquan Chen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages; Executable: see project webpage</arxiv:comment>
    <link href="http://arxiv.org/abs/1212.4490v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.4490v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.6048v1</id>
    <updated>2012-12-25T13:23:32Z</updated>
    <published>2012-12-25T13:23:32Z</published>
    <title>Discrete Surface Modeling Based on Google Earth: A Case Study</title>
    <summary>  Google Earth (GE) has become a powerful tool for geological, geophysical and
geographical modeling; yet GE can be accepted to acquire elevation data of
terrain. In this paper, we present a real study case of building the discrete
surface model (DSM) at Haut-Barr Castle in France based on the elevation data
of terrain points extracted from GE using the COM API. We first locate the
position of Haut-Barr Castle and determine the region of the study area, then
extract elevation data of terrain at Haut-Barr, and thirdly create a planar
triangular mesh that covers the study area and finally generate the desired DSM
by calculating the elevation of vertices in the planar mesh via interpolating
with Universal Kriging (UK) and Inverse Distance Weighting (IDW). The generated
DSM can reflect the features of the ground surface at Haut-Barr well, and can
be used for constructingthe Sealed Engineering Geological Model (SEGM) in
further step.
</summary>
    <author>
      <name>Gang Mei</name>
    </author>
    <author>
      <name>John C. Tipper</name>
    </author>
    <author>
      <name>Nengxiong Xu</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/ICCSNT.2012.6526125</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/ICCSNT.2012.6526125" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of IEEE Conference, ICCSNT 2012, in Press</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">2012 2nd International Conference on , vol., no., pp.1137,1141,
  29-31 Dec. 2012</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1212.6048v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.6048v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.6923v1</id>
    <updated>2012-12-31T16:41:07Z</updated>
    <published>2012-12-31T16:41:07Z</published>
    <title>The Geant4 Visualisation System - a multi-driver graphics system</title>
    <summary>  From the beginning the Geant4 Visualisation System was designed to support
several simultaneous graphics systems written to common abstract interfaces.
Today it has matured into a powerful diagnostic and presentational tool. It
comes with a library of models that may be added to the current scene and which
include the representation of the Geant4 geometry hierarchy, simulated
trajectories and user-written hits and digitisations. The workhorse is the
OpenGL suite of drivers for X, Xm, Qt and Win32. There is an Open Inventor
driver. Scenes can be exported in special graphics formats for offline viewing
in the DAWN, VRML, HepRApp and gMocren browsers. PostScript can be generated
through OpenGL, Open Inventor, DAWN and HepRApp. Geant4's own tracking
algorithms are used by the Ray Tracer. Not all drivers support all features but
all drivers bring added functionality of some sort. This paper describes the
interfaces and details the individual drivers.
</summary>
    <author>
      <name>John Allison</name>
    </author>
    <author>
      <name>Laurent Garnier</name>
    </author>
    <author>
      <name>Akinori Kimura</name>
    </author>
    <author>
      <name>Joseph Perl</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">22 pages, 15 figures. Submitted to the International Journal of
  Modeling, Simulation, and Scientific Computing</arxiv:comment>
    <link href="http://arxiv.org/abs/1212.6923v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.6923v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="hep-ex" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.3455v1</id>
    <updated>2013-01-15T19:14:06Z</updated>
    <published>2013-01-15T19:14:06Z</published>
    <title>3D Geological Modeling and Visualization of Rock Masses Based on Google
  Earth: A Case Study</title>
    <summary>  Google Earth (GE) has become a powerful tool for geological modeling and
visualization. An interesting and useful feature of GE, Google Street View, can
allow the GE users to view geological structure such as layers of rock masses
at a field site. In this paper, we introduce a practical solution for building
3D geological models for rock masses based on the data acquired by use with GE.
A real study case at Haut-Barr, France is presented to demonstrate our
solution. We first locate the position of Haut-Barr in GE, and then determine
the shape and scale of the rock masses in the study area, and thirdly acquire
the layout of layers of rock masses in the Google Street View, and finally
create the approximate 3D geological models by extruding and intersecting. The
generated 3D geological models can simply reflect the basic structure of the
rock masses at Haut-Barr, and can be used for visualizing the rock bodies
interactively.
</summary>
    <author>
      <name>Gang Mei</name>
    </author>
    <author>
      <name>John C. Tipper</name>
    </author>
    <author>
      <name>Nengxiong Xu</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/CSIT.2013.6588781</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/CSIT.2013.6588781" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">to appear in the Proceeding of IEEE Conference CSIT2013, in press</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Computer Science and Information Technology (CSIT), 2013 5th
  International Conference on, 2013, pp. 210-213</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1301.3455v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.3455v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.6809v2</id>
    <updated>2014-06-25T14:49:18Z</updated>
    <published>2013-01-29T00:18:00Z</published>
    <title>Skeletal Representations and Applications</title>
    <summary>  When representing a solid object there are alternatives to the use of
traditional explicit (surface meshes) or implicit (zero crossing of implicit
functions) methods. Skeletal representations encode shape information in a
mixed fashion: they are composed of a set of explicit primitives, yet they are
able to efficiently encode the shape's volume as well as its topology. I will
discuss, in two dimensions, how symmetry can be used to reduce the
dimensionality of the data (from a 2D solid to a 1D curve), and how this
relates to the classical definition of skeletons by Medial Axis Transform.
While the medial axis of a 2D shape is composed of a set of curves, in 3D it
results in a set of sheets connected in a complex fashion. Because of this
complexity, medial skeletons are difficult to use in practical applications.
Curve skeletons address this problem by strictly requiring their geometry to be
one dimensional, resulting in an intuitive yet powerful shape representation.
In this report I will define both medial and curve skeletons and discuss their
mutual relationship. I will also present several algorithms for their
computation and a variety of scenarios where skeletons are employed, with a
special focus on geometry processing and shape analysis.
</summary>
    <author>
      <name>Andrea Tagliasacchi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">42 pages, SFU Depth Exam</arxiv:comment>
    <link href="http://arxiv.org/abs/1301.6809v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.6809v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1302.2024v1</id>
    <updated>2013-02-08T13:11:39Z</updated>
    <published>2013-02-08T13:11:39Z</published>
    <title>User Interface for Volume Rendering in Virtual Reality Environments</title>
    <summary>  Volume Rendering applications require sophisticated user interaction for the
definition and refinement of transfer functions. Traditional 2D desktop user
interface elements have been developed to solve this task, but such concepts do
not map well to the interaction devices available in Virtual Reality
environments.
  In this paper, we propose an intuitive user interface for Volume Rendering
specifically designed for Virtual Reality environments. The proposed interface
allows transfer function design and refinement based on intuitive two-handed
operation of Wand-like controllers. Additional interaction modes such as
navigation and clip plane manipulation are supported as well.
  The system is implemented using the Sony PlayStation Move controller system.
This choice is based on controller device capabilities as well as application
and environment constraints.
  Initial results document the potential of our approach.
</summary>
    <author>
      <name>Jonathan Klein</name>
    </author>
    <author>
      <name>Dennis Reuling</name>
    </author>
    <author>
      <name>Jan Grimm</name>
    </author>
    <author>
      <name>Andreas Pfau</name>
    </author>
    <author>
      <name>Damien Lefloch</name>
    </author>
    <author>
      <name>Martin Lambers</name>
    </author>
    <author>
      <name>Andreas Kolb</name>
    </author>
    <link href="http://arxiv.org/abs/1302.2024v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1302.2024v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1303.4110v1</id>
    <updated>2013-03-17T22:00:15Z</updated>
    <published>2013-03-17T22:00:15Z</published>
    <title>On Linear Spaces of Polyhedral Meshes</title>
    <summary>  Polyhedral meshes (PM) - meshes having planar faces - have enjoyed a rise in
popularity in recent years due to their importance in architectural and
industrial design. However, they are also notoriously difficult to generate and
manipulate. Previous methods start with a smooth surface and then apply
elaborate meshing schemes to create polyhedral meshes approximating the
surface. In this paper, we describe a reverse approach: given the topology of a
mesh, we explore the space of possible planar meshes with that topology.
  Our approach is based on a complete characterization of the maximal linear
spaces of polyhedral meshes contained in the curved manifold of polyhedral
meshes with a given topology. We show that these linear spaces can be described
as nullspaces of differential operators, much like harmonic functions are
nullspaces of the Laplacian operator. An analysis of this operator provides
tools for global and local design of a polyhedral mesh, which fully expose the
geometric possibilities and limitations of the given topology.
</summary>
    <author>
      <name>Roi Poranne</name>
    </author>
    <author>
      <name>Renjie Chen</name>
    </author>
    <author>
      <name>Craig Gotsman</name>
    </author>
    <link href="http://arxiv.org/abs/1303.4110v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1303.4110v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.7845v1</id>
    <updated>2013-04-30T03:28:07Z</updated>
    <published>2013-04-30T03:28:07Z</published>
    <title>G2 Transition curve using Quartic Bezier Curve</title>
    <summary>  A method to construct transition curves using a family of the quartic Bezier
spiral is described. The transition curves discussed are S-shape and C-shape of
contact, between two separated circles. A spiral is a curve of monotone
increasing or monotone decreasing curvature of one sign. Thus, a spiral cannot
have an inflection point or curvature extreme. The family of quartic Bezier
spiral form which is introduced has more degrees of freedom and will give a
better approximation. It is proved that the methods of constructing transition
curves can be simplified by the transformation process and the ratio of two
radii has no restriction, which extends the application area, and it gives a
family of transition curves that allow more flexible curve designs.
</summary>
    <author>
      <name>Azhar Ahmad</name>
    </author>
    <author>
      <name>R. Gobithasan</name>
    </author>
    <author>
      <name>Jamaluddin Md. Ali</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">2007 Computer Graphics, Imaging and Visualization CGIV 2007, Pg.
  223-228</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1304.7845v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.7845v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.7852v1</id>
    <updated>2013-04-30T03:41:31Z</updated>
    <published>2013-04-30T03:41:31Z</published>
    <title>Variational Formulation of the Log-Aesthetic Surface and Development of
  Discrete Surface Filters</title>
    <summary>  The log-aesthetic curves include the logarithmic (equiangular) spiral,
clothoid, and involute curves. Although most of them are expressed only by an
integral form of the tangent vector, it is possible to interactively generate
and deform them and they are expected to be utilized for practical use of
industrial and graphical design. The discrete log-aesthetic filter based on the
formulation of the log-aesthetic curve has successfully been introduced not to
impose strong constraints on the designer's activity, to let him/her design
freely and to embed the properties of the log-aesthetic curves for complicated
ones with both increasing and decreasing curvature. In this paper, in order to
define the log-aesthetic surface and develop surface filters based on its
formulation, at first we reformulate the log-aesthetic curve with variational
principle. Then we propose several new functionals to be minimized for
free-form surfaces and define the log-aesthetic surface. Furthermore we propose
new discrete surface filters based on the log-aesthetic surface formulation
</summary>
    <author>
      <name>K. T. Miura</name>
    </author>
    <author>
      <name>R. Shirahata</name>
    </author>
    <author>
      <name>S. Agari</name>
    </author>
    <author>
      <name>S. Usuki</name>
    </author>
    <author>
      <name>R. U. Gobithaasan</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">2012 Computer Aided Design &amp; Application, Vol.9 (6), Pg.901-914</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1304.7852v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.7852v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.7868v1</id>
    <updated>2013-04-30T04:27:35Z</updated>
    <published>2013-04-30T04:27:35Z</published>
    <title>Normal type-2 Fuzzy Rational B-Spline Curve</title>
    <summary>  In this paper, we proposed a new form of type-2 fuzzy data points(T2FDPs)
that is normal type-2 data points(NT2FDPs). These brand-new forms of data were
defined by using the definition of normal type-2 triangular fuzzy
number(NT2TFN). Then, we applied fuzzification(alpha-cut) and type-reduction
processes towards NT2FDPs after they had been redefined based on the situation
of NT2FDPs. Furthermore, we redefine the defuzzification definition along with
the new definitions of fuzzification process and type-reduction method to
obtain crisp type-2 fuzzy solution data points. For all these processes from
the defining the NT2FDPs to defuzzification of NT2FDPs, we demonstrate through
curve representation by using the rational B-spline curve function as the
example form modeling these NT2FDPs.
</summary>
    <author>
      <name>Rozaimi Zakaria</name>
    </author>
    <author>
      <name>Abd. Fatah Wahab</name>
    </author>
    <author>
      <name>R. U. Gobithaasan</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">2013 Int. Journal of Math. Analysis, 7(16), Pg.789-806</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1304.7868v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.7868v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1305.3971v1</id>
    <updated>2013-05-17T03:13:28Z</updated>
    <published>2013-05-17T03:13:28Z</published>
    <title>Sparse Norm Filtering</title>
    <summary>  Optimization-based filtering smoothes an image by minimizing a fidelity
function and simultaneously preserves edges by exploiting a sparse norm penalty
over gradients. It has obtained promising performance in practical problems,
such as detail manipulation, HDR compression and deblurring, and thus has
received increasing attentions in fields of graphics, computer vision and image
processing. This paper derives a new type of image filter called sparse norm
filter (SNF) from optimization-based filtering. SNF has a very simple form,
introduces a general class of filtering techniques, and explains several
classic filters as special implementations of SNF, e.g. the averaging filter
and the median filter. It has advantages of being halo free, easy to implement,
and low time and memory costs (comparable to those of the bilateral filter).
Thus, it is more generic than a smoothing operator and can better adapt to
different tasks. We validate the proposed SNF by a wide variety of applications
including edge-preserving smoothing, outlier tolerant filtering, detail
manipulation, HDR compression, non-blind deconvolution, image segmentation, and
colorization.
</summary>
    <author>
      <name>Chengxi Ye</name>
    </author>
    <author>
      <name>Dacheng Tao</name>
    </author>
    <author>
      <name>Mingli Song</name>
    </author>
    <author>
      <name>David W. Jacobs</name>
    </author>
    <author>
      <name>Min Wu</name>
    </author>
    <link href="http://arxiv.org/abs/1305.3971v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1305.3971v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1305.4583v2</id>
    <updated>2013-11-03T21:39:13Z</updated>
    <published>2013-05-20T17:27:29Z</published>
    <title>Parallel Coordinates Guided High Dimensional Transfer Function Design</title>
    <summary>  High-dimensional transfer function design is widely used to provide
appropriate data classification for direct volume rendering of various
datasets. However, its design is a complicated task. Parallel coordinate plot
(PCP), as a powerful visualization tool, can efficiently display
high-dimensional geometry and accurately analyze multivariate data. In this
paper, we propose to combine parallel coordinates with dimensional reduction
methods to guide high-dimensional transfer function design. Our pipeline has
two major advantages: (1) combine and display extracted high-dimensional
features in parameter space; and (2) select appropriate high-dimensional
parameters, with the help of dimensional reduction methods, to obtain
sophisticated data classification as transfer function for volume rendering. In
order to efficiently design high-dimensional transfer functions, the
combination of both parallel coordinate components and dimension reduction
results is necessary to generate final visualization results. We demonstrate
the capability of our method for direct volume rendering using various CT and
MRI datasets.
</summary>
    <author>
      <name>Xin Zhao</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 5 figures. This paper has been withdrawn by the author due
  to publication</arxiv:comment>
    <link href="http://arxiv.org/abs/1305.4583v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1305.4583v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1306.1959v2</id>
    <updated>2013-11-03T21:38:56Z</updated>
    <published>2013-06-08T21:18:43Z</published>
    <title>Pattern Recognition and Revealing using Parallel Coordinates Plot</title>
    <summary>  Parallel coordinates plot (PCP) is an excellent tool for multivariate
visualization and analysis, but it may fail to reveal inherent structures for
datasets with a large number of items. In this paper, we propose a suite of
novel clustering, dimension ordering and visualization techniques based on PCP,
to reveal and highlight hidden structures. First, we propose a continuous
spline based polycurves design to extract and classify different cluster
aspects of the data. Then, we provide an efficient and optimal correlation
based sorting technique to reorder coordinates, as a helpful visualization tool
for data analysis. Various results generated by our framework visually
represent much structure, trend and correlation information to guide the user,
and improve the efficacy of analysis, especially for complex and noisy
datasets.
</summary>
    <author>
      <name>Xin Zhao</name>
    </author>
    <author>
      <name>Bo Li</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages and 6 figures. This paper has been withdrawn by the author
  due to publication</arxiv:comment>
    <link href="http://arxiv.org/abs/1306.1959v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1306.1959v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1306.2081v1</id>
    <updated>2013-06-10T01:38:09Z</updated>
    <published>2013-06-10T01:38:09Z</published>
    <title>3D model retrieval using global and local radial distances</title>
    <summary>  3D model retrieval techniques can be classified as histogram-based,
view-based and graph-based approaches. We propose a hybrid shape descriptor
which combines the global and local radial distance features by utilizing the
histogram-based and view-based approaches respectively. We define an
area-weighted global radial distance with respect to the center of the bounding
sphere of the model and encode its distribution into a 2D histogram as the
global radial distance shape descriptor. We then uniformly divide the bounding
cube of a 3D model into a set of small cubes and define their centers as local
centers. Then, we compute the local radial distance of a point based on the
nearest local center. By sparsely sampling a set of views and encoding the
local radial distance feature on the rendered views by color coding, we extract
the local radial distance shape descriptor. Based on these two shape
descriptors, we develop a hybrid radial distance shape descriptor for 3D model
retrieval. Experiment results show that our hybrid shape descriptor outperforms
several typical histogram-based and view-based approaches.
</summary>
    <author>
      <name>Bo Li</name>
    </author>
    <author>
      <name>Henry Johan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">The International Workshop on Advanced Image Technology
  (IWAIT2010), 2010</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1306.2081v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1306.2081v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1306.3113v2</id>
    <updated>2014-01-21T04:02:59Z</updated>
    <published>2013-06-13T14:11:28Z</published>
    <title>Multimaterial Front Tracking</title>
    <summary>  We present the first triangle mesh-based technique for tracking the evolution
of general three-dimensional multimaterial interfaces undergoing complex
topology changes induced by deformations and collisions. Our core
representation is a non-manifold triangle surface mesh with material labels
assigned to each half-face to distinguish volumetric regions. We advect the
vertices of the mesh in a Lagrangian manner, and employ a complete set of
collision-safe mesh improvement and topological operations that track and
update material labels. In particular, we develop a unified, collision-safe
strategy for handling complex topological operations acting on evolving triple-
and higher-valence junctions, and a flexible method to merge colliding
multimaterial meshes. We demonstrate our approach with a number of challenging
geometric flows, including passive advection, normal flow, and mean curvature
flow.
</summary>
    <author>
      <name>Fang Da</name>
    </author>
    <author>
      <name>Christopher Batty</name>
    </author>
    <author>
      <name>Eitan Grinspun</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The paper has been drastically revised and submitted to a journal
  that requires author anonymity; while this cannot be achieved under arXiv.org
  policy, we have nevertheless decided to withdraw the paper to reflect our
  attempt to satisfy anonymity</arxiv:comment>
    <link href="http://arxiv.org/abs/1306.3113v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1306.3113v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.0118v3</id>
    <updated>2014-05-10T19:56:31Z</updated>
    <published>2013-06-29T15:32:23Z</published>
    <title>Computing a Compact Spline Representation of the Medial Axis Transform
  of a 2D Shape</title>
    <summary>  We present a full pipeline for computing the medial axis transform of an
arbitrary 2D shape. The instability of the medial axis transform is overcome by
a pruning algorithm guided by a user-defined Hausdorff distance threshold. The
stable medial axis transform is then approximated by spline curves in 3D to
produce a smooth and compact representation. These spline curves are computed
by minimizing the approximation error between the input shape and the shape
represented by the medial axis transform. Our results on various 2D shapes
suggest that our method is practical and effective, and yields faithful and
compact representations of medial axis transforms of 2D shapes.
</summary>
    <author>
      <name>Yanshu Zhu</name>
    </author>
    <author>
      <name>Feng Sun</name>
    </author>
    <author>
      <name>Yi-King Choi</name>
    </author>
    <author>
      <name>Bert Jüttler</name>
    </author>
    <author>
      <name>Wenping Wang</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.gmod.2014.03.007</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.gmod.2014.03.007" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">GMP14 (Geometric Modeling and Processing)</arxiv:comment>
    <link href="http://arxiv.org/abs/1307.0118v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.0118v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.0247v1</id>
    <updated>2013-06-30T21:54:33Z</updated>
    <published>2013-06-30T21:54:33Z</published>
    <title>Progressive Blue Surfels</title>
    <summary>  In this paper we describe a new technique to generate and use surfels for
rendering of highly complex, polygonal 3D scenes in real time. The basic idea
is to approximate complex parts of the scene by rendering a set of points
(surfels). The points are computed in a preprocessing step and offer two
important properties: They are placed only on the visible surface of the
scene's geometry and they are distributed and sorted in such a way, that every
prefix of points is a good visual representation of the approximated part of
the scene. An early evaluation of the method shows that it is capable of
rendering scenes consisting of several billions of triangles with high image
quality.
</summary>
    <author>
      <name>Claudius Jähn</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Please note that this paper represents an early working draft, which
  will be subsequently replaced by refined versions! 3 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1307.0247v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.0247v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.6360v1</id>
    <updated>2013-07-24T09:54:22Z</updated>
    <published>2013-07-24T09:54:22Z</published>
    <title>Electronic Visualisation in Chemistry: From Alchemy to Art</title>
    <summary>  Chemists now routinely use software as part of their work. For example,
virtual chemistry allows chemical reactions to be simulated. In particular, a
selection of software is available for the visualisation of complex
3-dimensional molecular structures. Many of these are very beautiful in their
own right. As well as being included as illustrations in academic papers, such
visualisations are often used on the covers of chemistry journals as
artistically decorative and attractive motifs. Chemical images have also been
used as the basis of artworks in exhibitions. This paper explores the
development of the relationship of chemistry, art, and IT. It covers some of
the increasingly sophisticated software used to generate these projections
(e.g., UCSF Chimera) and their progressive use as a visual art form.
</summary>
    <author>
      <name>Karl Harrison</name>
    </author>
    <author>
      <name>Jonathan P. Bowen</name>
    </author>
    <author>
      <name>Alice M. Bowen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 27 figures, EVA London 2013</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EVA London 2013 Conference Proceedings, Electronic Workshops in
  Computing (eWiC), British Computer Society, 29-31 July 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1307.6360v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.6360v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.chem-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.m; J.3; J.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1308.0375v1</id>
    <updated>2013-08-01T23:08:03Z</updated>
    <published>2013-08-01T23:08:03Z</published>
    <title>A New 3D Geometric Approach to Focus and Context Lens Effect Simulation</title>
    <summary>  We present a novel methodology based on geometric approach to simulate
magnification lens effects. Our aim is to promote new applications of powerful
geometric modeling techniques in visual computing. Conventional image
processing/visualization methods are computed in two dimensional space (2D). We
examine this conventional 2D manipulation from a completely innovative
perspective of 3D geometric processing. Compared with conventional optical lens
design, 3D geometric method are much more capable of preserving shape features
and minimizing distortion. We magnify an area of interest to better visualize
the interior details, while keeping the rest of area without perceivable
distortion. We flatten the mesh back into 2D space for viewing, and further
applications in the screen space. In both steps, we devise an iterative
deformation scheme to minimize distortion around both focus and context region,
while avoiding the noncontinuous transition region between the focus and
context areas. Particularly, our method allows the user to flexibly modify the
ROI shapes to accommodate complex feature. The user can also easily specify a
spectrum of metrics for different visual effects. Various experimental results
demonstrate the effectiveness, robustness, and efficiency of our framework.
</summary>
    <author>
      <name>Bo Li</name>
    </author>
    <author>
      <name>Xin Zhao</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Poster for I3D</arxiv:comment>
    <link href="http://arxiv.org/abs/1308.0375v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1308.0375v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1308.0867v1</id>
    <updated>2013-08-05T01:27:36Z</updated>
    <published>2013-08-05T01:27:36Z</published>
    <title>A Survey of Spline-based Volumetric Data Modeling Framework and Its
  Applications</title>
    <summary>  The rapid advances in 3D scanning and acquisition techniques have given rise
to the explosive increase of volumetric digital models in recent years. This
dissertation systematically trailblazes a novel volumetric modeling framework
to represent 3D solids. The need to explore more efficient and robust 3D
modeling framework has gained the prominence. Although the traditional surface
representation (e.g., triangle mesh) has many attractive properties, it is
incapable of expressing the interior space and materials. Such a serious
drawback overshadows many potential modeling and analysis applications.
Consequently volumetric modeling techniques become the well-known solution to
this problem. Nevertheless, many unsolved research issues remain when
developing an efficient modeling paradigm for existing 3D models: complex
geometry (fine details and extreme concaveness), arbitrary topology,
heterogenous materials, large-scale data storage and processing, etc.
</summary>
    <author>
      <name>Bo Li</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Master Thesis, Computer Science Department, Stony Brook University</arxiv:comment>
    <link href="http://arxiv.org/abs/1308.0867v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1308.0867v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1308.3917v1</id>
    <updated>2013-08-19T03:34:21Z</updated>
    <published>2013-08-19T03:34:21Z</published>
    <title>Medial Meshes for Volume Approximation</title>
    <summary>  Volume approximation is an important problem found in many applications of
computer graphics, vision, and image processing. The problem is about computing
an accurate and compact approximate representation of 3D volumes using some
simple primitives. In this study, we propose a new volume representation,
called medial meshes, and present an efficient method for its computation.
Specifically, we use the union of a novel type of simple volume primitives,
which are spheres and the convex hulls of two or three spheres, to approximate
a given 3D shape. We compute such a volume approximation based on a new method
for medial axis simplification guided by Hausdorff errors. We further
demonstrate the superior efficiency and accuracy of our method over existing
methods for medial axis simplification.
</summary>
    <author>
      <name>Feng Sun</name>
    </author>
    <author>
      <name>Yi-King Choi</name>
    </author>
    <author>
      <name>Yizhou Yu</name>
    </author>
    <author>
      <name>Wenping Wang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 14 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1308.3917v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1308.3917v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1308.5843v1</id>
    <updated>2013-08-27T12:44:54Z</updated>
    <published>2013-08-27T12:44:54Z</published>
    <title>Affordable Virtual Reality System Architecture for Representation of
  Implicit Object Properties</title>
    <summary>  A flexible, scalable and affordable virtual reality software system
architecture is proposed. This solution can be easily implemented on different
hardware configurations: on a single computer or on a computer cluster. The
architecture is aimed to be integrated in the workflow for solving engineering
tasks and oriented towards presenting implicit object properties through
multiple sensorial channels (visual, audio and haptic). Implicit properties
represent hidden object features (i.e. magnetization, radiation, humidity,
toxicity, etc.) which cannot be perceived by the observer through his or her
senses but require specialized equipment in order to expand the sensory ability
of the observer. Our approach extends the underlying general scene graph
structure incorporating additional effects nodes for implicit properties
representation.
</summary>
    <author>
      <name>Stoyan Maleshkov</name>
    </author>
    <author>
      <name>Dimo Chotrov</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IJCSI International Journal of Computer Science Issues, Vol. 9,
  Issue 4, No 2, July 2012</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1308.5843v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1308.5843v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1308.5847v1</id>
    <updated>2013-08-27T12:47:34Z</updated>
    <published>2013-08-27T12:47:34Z</published>
    <title>Post-processing of Engineering Analysis Results for Visualization in VR
  Systems</title>
    <summary>  The applicability of Virtual Reality for evaluating engineering analysis
results is beginning to receive increased appreciation in the last years. The
problem many engineers are still facing is how to import their model together
with the analysis results in a virtual reality environment for exploration and
results validation. In this paper we propose an algorithm for transforming
model data and results from finite element analysis (FEA) solving application
to a format easily interpretable by a virtual reality application. The
algorithm includes also steps for reducing the face-count of the resulting mesh
by eliminating faces from the inner part of the model in the cases when only
the surfaces of the model is analyzed. We also describe a possibility for
simultaneously assessing multiple analysis results relying on multimodal
results presentation by stimulating different senses of the operator.
</summary>
    <author>
      <name>Stoyan Maleshkov</name>
    </author>
    <author>
      <name>Dimo Chotrov</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IJCSI International Journal of Computer Science Issues, Vol. 10,
  Issue 2, March 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1308.5847v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1308.5847v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1309.4413v2</id>
    <updated>2013-09-18T03:49:02Z</updated>
    <published>2013-09-17T18:13:01Z</published>
    <title>Mobile augmented reality survey: a bottom-up approach</title>
    <summary>  Augmented Reality (AR) is becoming mobile. Mobile devices have many
constraints but also rich new features that traditional desktop computers do
not have. There are several survey papers on AR, but none is dedicated to
Mobile Augmented Reality (MAR). Our work serves the purpose of closing this
gap. The contents are organized with a bottom-up approach. We first present the
state-of-the-art in system components including hardware platforms, software
frameworks and display devices, follows with enabling technologies such as
tracking and data management. We then survey the latest technologies and
methods to improve run-time performance and energy efficiency for practical
implementation. On top of these, we further introduce the application fields
and several typical MAR applications. Finally we conclude the survey with
several challenge problems, which are under exploration and require great
research efforts in the future.
</summary>
    <author>
      <name>Zhanpeng Huang</name>
    </author>
    <author>
      <name>Pan Hui</name>
    </author>
    <author>
      <name>Christoph Peylo</name>
    </author>
    <author>
      <name>Dimitris Chatzopoulos</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">35 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1309.4413v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1309.4413v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.0041v1</id>
    <updated>2013-09-30T20:31:10Z</updated>
    <published>2013-09-30T20:31:10Z</published>
    <title>Gradient-Domain Processing for Large EM Image Stacks</title>
    <summary>  We propose a new gradient-domain technique for processing registered EM image
stacks to remove the inter-image discontinuities while preserving intra-image
detail. To this end, we process the image stack by first performing anisotropic
diffusion to smooth the data along the slice axis and then solving a
screened-Poisson equation within each slice to re-introduce the detail. The
final image stack is both continuous across the slice axis (facilitating the
tracking of information between slices) and maintains sharp details within each
slice (supporting automatic feature detection). To support this editing, we
describe the implementation of the first multigrid solver designed for
efficient gradient domain processing of large, out-of-core, voxel grids.
</summary>
    <author>
      <name>Michael Kazhdan</name>
    </author>
    <author>
      <name>Randal Burns</name>
    </author>
    <author>
      <name>Bobby Kasthuri</name>
    </author>
    <author>
      <name>Jeff Lichtman</name>
    </author>
    <author>
      <name>Jacob Vogelstein</name>
    </author>
    <author>
      <name>Joshua Vogelstein</name>
    </author>
    <link href="http://arxiv.org/abs/1310.0041v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.0041v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.4459v1</id>
    <updated>2013-10-16T17:39:34Z</updated>
    <published>2013-10-16T17:39:34Z</published>
    <title>Matching LBO eigenspace of non-rigid shapes via high order statistics</title>
    <summary>  A fundamental tool in shape analysis is the virtual embedding of the
Riemannian manifold describing the geometry of a shape into Euclidean space.
Several methods have been proposed to embed isometric shapes in flat domains
while preserving distances measured on the manifold. Recently, attention has
been given to embedding shapes into the eigenspace of the Lapalce-Beltrami
operator. The Laplace-Beltrami eigenspace preserves the diffusion distance, and
is invariant under isometric transformations. However, Laplace-Beltrami
eigenfunctions computed independently for different shapes are often
incompatible with each other. Applications involving multiple shapes, such as
pointwise correspondence, would greatly benefit if their respective
eigenfunctions were somehow matched. Here, we introduce a statistical approach
for matching eigenfunctions. We consider the values of the eigenfunctions over
the manifold as sampling of random variables, and try to match their
multivariate distributions. Comparing distributions is done indirectly, using
high order statistics. We show that the permutation and sign ambiguities of low
order eigenfunctions, can be inferred by minimizing the difference of their
third order moments. The sign ambiguities of antisymmetric eigenfunctions can
be resolved by exploiting isometric invariant relations between the gradients
of the eigenfunctions and the surface normal. We present experiments
demonstrating the success of the proposed method applied to feature point
correspondence.
</summary>
    <author>
      <name>Alon Shtern</name>
    </author>
    <author>
      <name>Ron Kimmel</name>
    </author>
    <link href="http://arxiv.org/abs/1310.4459v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.4459v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1311.0955v2</id>
    <updated>2013-12-07T04:17:37Z</updated>
    <published>2013-11-05T03:25:38Z</published>
    <title>A Dual-Beam Method-of-Images 3D Searchlight BSSRDF</title>
    <summary>  We present a novel BSSRDF for rendering translucent materials. Angular
effects lacking in previous BSSRDF models are incorporated by using a dual-beam
formulation. We employ a Placzek's Lemma interpretation of the method of images
and discard diffusion theory. Instead, we derive a plane-parallel
transformation of the BSSRDF to form the associated BRDF and optimize the image
confiurations such that the BRDF is close to the known analytic solutions for
the associated albedo problem. This ensures reciprocity, accurate colors, and
provides an automatic level-of-detail transition for translucent objects that
appear at various distances in an image. Despite optimizing the subsurface
fluence in a plane-parallel setting, we find that this also leads to fairly
accurate fluence distributions throughout the volume in the original 3D
searchlight problem. Our method-of-images modifications can also improve the
accuracy of previous BSSRDFs.
</summary>
    <author>
      <name>Eugene d'Eon</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">added clarifying text and 1 figure to illustrate the method</arxiv:comment>
    <link href="http://arxiv.org/abs/1311.0955v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1311.0955v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1311.5018v1</id>
    <updated>2013-11-20T11:30:03Z</updated>
    <published>2013-11-20T11:30:03Z</published>
    <title>On the impact of explicit or semi-implicit integration methods over the
  stability of real-time numerical simulations</title>
    <summary>  Physics-based animation of soft or rigid bodies for real-time applications
often suffers from numerical instabilities. We analyse one of the most common
sources of unwanted behaviour: the numerical integration strategy. To assess
the impact of popular integration methods, we consider a scenario where soft
and hard constraints are added to a custom designed deformable linear object.
Since the goal for this class of simulation methods is to attain interactive
frame-rates, we present the drawbacks of using explicit integration methods
over inherently stable, implicit integrators. To help numerical solver
designers better understand the impact of an integrator on a certain simulated
world, we have conceived a method of benchmarking the efficiency of an
integrator with respect to its speed, stability and symplecticity.
</summary>
    <author>
      <name>Teodor Cioaca</name>
    </author>
    <author>
      <name>Horea Caramizaru</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to the ROMAI Journal of Applied Mathematics. Presented at
  the CAIM 2013 Conference on Applied and Industrial Mathematics</arxiv:comment>
    <link href="http://arxiv.org/abs/1311.5018v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1311.5018v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65D18" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.7; I.6.8; G.1.0" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1311.6811v1</id>
    <updated>2013-11-26T18:41:48Z</updated>
    <published>2013-11-26T18:41:48Z</published>
    <title>Digitize Your Body and Action in 3-D at Over 10 FPS: Real Time Dense
  Voxel Reconstruction and Marker-less Motion Tracking via GPU Acceleration</title>
    <summary>  In this paper, we present an approach to reconstruct 3-D human motion from
multi-cameras and track human skeleton using the reconstructed human 3-D point
(voxel) cloud. We use an improved and more robust algorithm, probabilistic
shape from silhouette to reconstruct human voxel. In addition, the annealed
particle filter is applied for tracking, where the measurement is computed
using the reprojection of reconstructed voxel. We use two different ways to
accelerate the approach. For the CPU only acceleration, we leverage Intel TBB
to speed up the hot spot of the computational overhead and reached an
accelerating ratio of 3.5 on a 4-core CPU. Moreover, we implement an
intensively paralleled version via GPU acceleration without TBB. Taking account
all data transfer and computing time, the GPU version is about 400 times faster
than the original CPU implementation, leading the approach to run at a
real-time speed.
</summary>
    <author>
      <name>Jian Song</name>
    </author>
    <author>
      <name>Yatao Bian</name>
    </author>
    <author>
      <name>Junchi Yan</name>
    </author>
    <author>
      <name>Xu Zhao</name>
    </author>
    <author>
      <name>Yuncai Liu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">23 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1311.6811v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1311.6811v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1311.7194v1</id>
    <updated>2013-11-28T03:17:03Z</updated>
    <published>2013-11-28T03:17:03Z</published>
    <title>Real-time High Resolution Fusion of Depth Maps on GPU</title>
    <summary>  A system for live high quality surface reconstruction using a single moving
depth camera on a commodity hardware is presented. High accuracy and real-time
frame rate is achieved by utilizing graphics hardware computing capabilities
via OpenCL and by using sparse data structure for volumetric surface
representation. Depth sensor pose is estimated by combining serial texture
registration algorithm with iterative closest points algorithm (ICP) aligning
obtained depth map to the estimated scene model. Aligned surface is then fused
into the scene. Kalman filter is used to improve fusion quality. Truncated
signed distance function (TSDF) stored as block-based sparse buffer is used to
represent surface. Use of sparse data structure greatly increases accuracy of
scanned surfaces and maximum scanning area. Traditional GPU implementation of
volumetric rendering and fusion algorithms were modified to exploit sparsity to
achieve desired performance. Incorporation of texture registration for sensor
pose estimation and Kalman filter for measurement integration improved accuracy
and robustness of scanning process.
</summary>
    <author>
      <name>Dmitry Trifonov</name>
    </author>
    <link href="http://arxiv.org/abs/1311.7194v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1311.7194v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1311.7462v1</id>
    <updated>2013-11-29T03:08:37Z</updated>
    <published>2013-11-29T03:08:37Z</published>
    <title>Continuous Collision Detection for Composite Quadric Models</title>
    <summary>  A composite quadric model (CQM) is an object modeled by piecewise linear or
quadric patches. We study the continuous detection problem of a special type of
CQM objects which are commonly used in CAD/CAM, that is, the boundary surfaces
of such a CQM intersect only in straight line segments or conic curve segments.
We present a framework for continuous collision detection (CCD) of this special
type of CQM (which we also call CQM for brevity) in motion. We derive algebraic
formulations and compute numerically the first contact time instants and the
contact points of two moving CQMs in $\mathbb R^3$. Since it is difficult to
process CCD of two CQMs in a direct manner because they are composed of
semi-algebraic varieties, we break down the problem into subproblems of solving
CCD of pairs of boundary elements of the CQMs. We present procedures to solve
CCD of different types of boundary element pairs in different dimensions. Some
CCD problems are reduced to their equivalents in a lower dimensional setting,
where they can be solved more efficiently.
</summary>
    <author>
      <name>Yi-King Choi</name>
    </author>
    <author>
      <name>Wenping Wang</name>
    </author>
    <author>
      <name>Bernard Mourrain</name>
    </author>
    <author>
      <name>Changhe Tu</name>
    </author>
    <author>
      <name>Xiaohong Jia</name>
    </author>
    <author>
      <name>Feng Sun</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">23 pages, 13 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1311.7462v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1311.7462v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1311.7535v1</id>
    <updated>2013-11-29T12:03:00Z</updated>
    <published>2013-11-29T12:03:00Z</published>
    <title>Compact Part-Based Shape Spaces for Dense Correspondences</title>
    <summary>  We consider the problem of establishing dense correspondences within a set of
related shapes of strongly varying geometry. For such input, traditional shape
matching approaches often produce unsatisfactory results. We propose an
ensemble optimization method that improves given coarse correspondences to
obtain dense correspondences. Following ideas from minimum description length
approaches, it maximizes the compactness of the induced shape space to obtain
high-quality correspondences. We make a number of improvements that are
important for computer graphics applications: Our approach handles meshes of
general topology and handles partial matching between input of varying
topology. To this end we introduce a novel part-based generative statistical
shape model. We develop a novel analysis algorithm that learns such models from
training shapes of varying topology. We also provide a novel synthesis method
that can generate new instances with varying part layouts and subject to
generic variational constraints. In practical experiments, we obtain a
substantial improvement in correspondence quality over state-of-the-art
methods. As example application, we demonstrate a system that learns shape
families as assemblies of deformable parts and permits real-time editing with
continuous and discrete variability.
</summary>
    <author>
      <name>Oliver Burghard</name>
    </author>
    <author>
      <name>Alexander Berner</name>
    </author>
    <author>
      <name>Michael Wand</name>
    </author>
    <author>
      <name>Niloy Mitra</name>
    </author>
    <author>
      <name>Hans-Peter Seidel</name>
    </author>
    <author>
      <name>Reinhard Klein</name>
    </author>
    <link href="http://arxiv.org/abs/1311.7535v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1311.7535v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.5; I.2.10" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1312.7034v2</id>
    <updated>2014-06-28T20:57:37Z</updated>
    <published>2013-12-26T00:22:31Z</published>
    <title>A Topologically-informed Hyperstreamline Seeding Method for Alignment
  Tensor Fields</title>
    <summary>  A topologically-informed method is presented for seeding of hyperstreamlines
for visualization of alignment tensor fields. The method is inspired by and
applied to visualization of nematic liquid crystal (LC) reorientation dynamics
simulations. The method distributes hyperstreamlines along domain boundaries
and edges of a nearest-neighbor graph whose vertices are degenerate regions of
the alignment tensor field, which correspond to orientational defects in a
nematic LC domain. This is accomplished without iteration while conforming to a
user-specified spacing between hyperstreamlines and avoids possible failure
modes associated with hyperstreamline integration in the vicinity of
degeneracies of alignment (orientational defects). It is shown that the
presented seeding method enables automated hyperstreamline-based visualization
of a broad range of alignment tensor fields which enhances the ability of
researchers to interpret these fields and provides an alternative to using
glyph-based techniques.
</summary>
    <author>
      <name>Fred Fu</name>
    </author>
    <author>
      <name>Nasser Mohieddin Abukhdeir</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TVCG.2014.2363828</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TVCG.2014.2363828" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 9 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1312.7034v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1312.7034v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.soft" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1401.0113v3</id>
    <updated>2014-06-17T14:31:06Z</updated>
    <published>2013-12-31T08:50:03Z</published>
    <title>Connectivity-preserving Geometry Images</title>
    <summary>  We propose connectivity-preserving geometry images (CGIMs), which map a
three-dimensional mesh onto a rectangular regular array of an image, such that
the reconstructed mesh produces no sampling errors, but merely round-off
errors. We obtain a V-matrix with respect to the original mesh, whose elements
are vertices of the mesh, which intrinsically preserves the vertex-set and the
connectivity of the original mesh in the sense of allowing round-off errors. We
generate a CGIM array by using the Cartesian coordinates of corresponding
vertices of the V-matrix. To reconstruct a mesh, we obtain a vertex-set and an
edge-set by collecting all the elements with different pixels, and all
different pairwise adjacent elements from the CGIM array respectively. Compared
with traditional geometry images, CGIMs achieve minimum reconstruction errors
with an efficient parametrization-free algorithm via elementary permutation
techniques. We apply CGIMs to lossy compression of meshes, and the experimental
results show that CGIMs perform well in reconstruction precision and detail
preservation.
</summary>
    <author>
      <name>Shaofan Wang</name>
    </author>
    <author>
      <name>Dehui Kong</name>
    </author>
    <author>
      <name>Juan Xue</name>
    </author>
    <author>
      <name>Weijia Zhu</name>
    </author>
    <author>
      <name>Min Xu</name>
    </author>
    <author>
      <name>Baocai Yin</name>
    </author>
    <author>
      <name>Hubert Roth</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 10 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1401.0113v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1401.0113v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1401.1488v1</id>
    <updated>2014-01-07T20:14:55Z</updated>
    <published>2014-01-07T20:14:55Z</published>
    <title>Forward and Inverse Kinematics Seamless Matching Using Jacobian</title>
    <summary>  In this paper the problem of matching Forward Kinematics (FK) motion of a 3
Dimensional (3D) joint chain to the Inverse Kinematics (IK) movement and vice
versa has been addressed. The problem lies at the heart of animating a 3D
character having controller and manipulator based rig for animation within any
3D modeling and animation software. The seamless matching has been achieved
through the use of pseudo-inverse of Jacobian Matrix. The Jacobian Matrix is
used to determine the rotation values of each joint of character body part such
as arms, between the inverse kinematics and forward kinematics motion. Then
moving the corresponding kinematic joint system to the desired place,
automatically eliminating the jumping or popping effect which would reduce the
complexity of the system.
</summary>
    <author>
      <name>Zeeshan Bhatti</name>
    </author>
    <author>
      <name>Asadullah Shah</name>
    </author>
    <author>
      <name>Farruh Shahidi</name>
    </author>
    <author>
      <name>Mostafa Karbasi</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Sindh University Research Journal (SURJ) Volume 45 (2), 8/2013,
  pp:387-392, Sindh University Press</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1401.1488v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1401.1488v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1402.2363v1</id>
    <updated>2014-02-11T04:05:12Z</updated>
    <published>2014-02-11T04:05:12Z</published>
    <title>Animation of 3D Human Model Using Markerless Motion Capture Applied To
  Sports</title>
    <summary>  Markerless motion capture is an active research in 3D virtualization. In
proposed work we presented a system for markerless motion capture for 3D human
character animation, paper presents a survey on motion and skeleton tracking
techniques which are developed or are under development. The paper proposed a
method to transform the motion of a performer to a 3D human character (model),
the 3D human character performs similar movements as that of a performer in
real time. In the proposed work, human model data will be captured by Kinect
camera, processed data will be applied on 3D human model for animation. 3D
human model is created using open source software (MakeHuman). Anticipated
dataset for sport activity is considered as input which can be applied to any
HCI application.
</summary>
    <author>
      <name>Ashish Shingade</name>
    </author>
    <author>
      <name>Archana Ghotkar</name>
    </author>
    <link href="http://arxiv.org/abs/1402.2363v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1402.2363v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1402.5440v1</id>
    <updated>2014-02-21T22:31:26Z</updated>
    <published>2014-02-21T22:31:26Z</published>
    <title>Ergonomic-driven Geometric Exploration and Reshaping</title>
    <summary>  The paper addresses the following problem: given a set of man-made shapes,
e.g., chairs, can we quickly rank and explore the set of shapes with respect to
a given avatar pose? Answering this question requires identifying which shapes
are more suitable for the defined avatar and pose; and moreover, to provide
fast preview of how to alter the input geometry to better fit the deformed
shapes to the given avatar pose? The problem naturally links physical
proportions of human body and its interaction with object shapes in an attempt
to connect ergonomics with shape geometry. We designed an interaction system
that allows users to explore shape collections using the deformation of human
characters while at the same time providing interactive previews of how to
alter the shapes to better fit the user-specified character. We achieve this by
first mapping ergonomics guidelines into a set of simultaneous multi-part
constraints based on target contacts; and then, proposing a novel contact-based
deformation model to realize multi-contact constraints. We evaluate our
framework on various chair models and validate the results via a small user
study.
</summary>
    <author>
      <name>Youyi Zheng</name>
    </author>
    <author>
      <name>Julie Dorsey</name>
    </author>
    <author>
      <name>Niloy Mitra</name>
    </author>
    <link href="http://arxiv.org/abs/1402.5440v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1402.5440v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1403.0917v1</id>
    <updated>2014-03-04T19:50:00Z</updated>
    <published>2014-03-04T19:50:00Z</published>
    <title>An Extension Of Weiler-Atherton Algorithm To Cope With The
  Self-intersecting Polygon</title>
    <summary>  In this paper a new algorithm has been proposed which can fix the problem of
Weiler Atherton algorithm. The problem of Weiler Atherton algorithm lies in
clipping self intersecting polygon. Clipping self intersecting polygon is not
considered in Weiler Atherton algorithm and hence it is also a main
disadvantage of this algorithm. In our new algorithm a self intersecting
polygon has been divided into non self intersecting contours and then perform
the Weiler Atherton clipping algorithm on those sub polygons. For holes we have
to store the edges that is not own boundary of hole contour from recently
clipped polygon. Thus if both contour is hole then we have to store all the
edges of the recently clipped polygon. Finally the resultant polygon has been
produced by eliminating all the stored edges.
</summary>
    <author>
      <name>Anurag Chakraborty</name>
    </author>
    <link href="http://arxiv.org/abs/1403.0917v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1403.0917v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1403.6566v2</id>
    <updated>2014-08-21T06:16:01Z</updated>
    <published>2014-03-26T03:29:25Z</published>
    <title>Image Retargeting by Content-Aware Synthesis</title>
    <summary>  Real-world images usually contain vivid contents and rich textural details,
which will complicate the manipulation on them. In this paper, we design a new
framework based on content-aware synthesis to enhance content-aware image
retargeting. By detecting the textural regions in an image, the textural image
content can be synthesized rather than simply distorted or cropped. This method
enables the manipulation of textural &amp; non-textural regions with different
strategy since they have different natures. We propose to retarget the textural
regions by content-aware synthesis and non-textural regions by fast
multi-operators. To achieve practical retargeting applications for general
images, we develop an automatic and fast texture detection method that can
detect multiple disjoint textural regions. We adjust the saliency of the image
according to the features of the textural regions. To validate the proposed
method, comparisons with state-of-the-art image targeting techniques and a user
study were conducted. Convincing visual results are shown to demonstrate the
effectiveness of the proposed method.
</summary>
    <author>
      <name>Weiming Dong</name>
    </author>
    <author>
      <name>Fuzhang Wu</name>
    </author>
    <author>
      <name>Yan Kong</name>
    </author>
    <author>
      <name>Xing Mei</name>
    </author>
    <author>
      <name>Tong-Yee Lee</name>
    </author>
    <author>
      <name>Xiaopeng Zhang</name>
    </author>
    <link href="http://arxiv.org/abs/1403.6566v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1403.6566v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1403.8105v1</id>
    <updated>2014-03-31T17:54:34Z</updated>
    <published>2014-03-31T17:54:34Z</published>
    <title>Flux-Limited Diffusion for Multiple Scattering in Participating Media</title>
    <summary>  For the rendering of multiple scattering effects in participating media,
methods based on the diffusion approximation are an extremely efficient
alternative to Monte Carlo path tracing. However, in sufficiently transparent
regions, classical diffusion approximation suffers from non-physical radiative
fluxes which leads to a poor match to correct light transport. In particular,
this prevents the application of classical diffusion approximation to
heterogeneous media, where opaque material is embedded within transparent
regions. To address this limitation, we introduce flux-limited diffusion, a
technique from the astrophysics domain. This method provides a better
approximation to light transport than classical diffusion approximation,
particularly when applied to heterogeneous media, and hence broadens the
applicability of diffusion-based techniques. We provide an algorithm for
flux-limited diffusion, which is validated using the transport theory for a
point light source in an infinite homogeneous medium. We further demonstrate
that our implementation of flux-limited diffusion produces more accurate
renderings of multiple scattering in various heterogeneous datasets than
classical diffusion approximation, by comparing both methods to ground truth
renderings obtained via volumetric path tracing.
</summary>
    <author>
      <name>David Koerner</name>
    </author>
    <author>
      <name>Jamie Portsmouth</name>
    </author>
    <author>
      <name>Filip Sadlo</name>
    </author>
    <author>
      <name>Thomas Ertl</name>
    </author>
    <author>
      <name>Bernd Eberhardt</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1111/cgf.12342</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1111/cgf.12342" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted in Computer Graphics Forum</arxiv:comment>
    <link href="http://arxiv.org/abs/1403.8105v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1403.8105v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.0981v1</id>
    <updated>2014-04-03T15:48:55Z</updated>
    <published>2014-04-03T15:48:55Z</published>
    <title>New Julia and Mandelbrot Sets for Jungck Ishikawa Iterates</title>
    <summary>  The generation of fractals and study of the dynamics of polynomials is one of
the emerging and interesting field of research nowadays. We introduce in this
paper the dynamics of polynomials z^ n - z + c = 0 for n&gt;=2 and applied Jungck
Ishikawa Iteration to generate new Relative Superior Mandelbrot sets and
Relative Superior Julia sets. In order to solve this function by Jungck type
iterative schemes, we write it in the form of Sz = Tz, where the function T, S
are defined as Tz = z^ n + c and Sz = z. Only mathematical explanations are
derived by applying Jungck Ishikawa Iteration for polynomials in the literature
but in this paper we have generated Relative Mandelbrot sets and Relative Julia
sets.
</summary>
    <author>
      <name>Suman Joshi</name>
    </author>
    <author>
      <name>Dr. Yashwant Singh Chauhan</name>
    </author>
    <author>
      <name>Dr. Ashish Negi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages,18 tables,18 charts,18 figures Published with International
  Journal of Computer Trends and Technology (IJCTT)</arxiv:comment>
    <link href="http://arxiv.org/abs/1404.0981v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.0981v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.2053v1</id>
    <updated>2014-04-08T09:23:05Z</updated>
    <published>2014-04-08T09:23:05Z</published>
    <title>Expression driven Trignometric based Procedural Animation of Quadrupeds</title>
    <summary>  This research paper addresses the problem of generating involuntary and
precise animation of quadrupeds with automatic rigging system of various
character types. The technique proposed through this research is based on a two
tier animation control curve with base simulation being driven through dynamic
mathematical model using procedural algorithm and the top layer with a custom
user controlled animation provided with intuitive Graphical User Interface
(GUI). The character rig is based on forward and inverse kinematics driven
through trigonometric based motion equations. The User is provided with various
manipulators and attributes to control and handle the locomotion gaits of the
characters and choose between various types of simulated motions from walking,
running, trotting, ambling and galloping with complete custom controls to
easily extend the base simulation as per requirements.
</summary>
    <author>
      <name>Zeeshan Bhatti</name>
    </author>
    <author>
      <name>Asadullah Shah</name>
    </author>
    <author>
      <name>Mustafa Karabasi</name>
    </author>
    <author>
      <name>Waheed Mahesar</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/ICICM.2013.25</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/ICICM.2013.25" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 8 figures, Conference paper</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings of the International Conference on Informatics and
  Creative Multimedia 2103 (ICICM'13), pp.104,109, 4-6 Sept. 2013 IEEEXplore.
  UTM, KUALA LUMPUR (3-6 Sept)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1404.2053v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.2053v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.2728v2</id>
    <updated>2014-04-22T02:26:25Z</updated>
    <published>2014-04-10T08:25:20Z</published>
    <title>Real-time Decolorization using Dominant Colors</title>
    <summary>  Decolorization is the process to convert a color image or video to its
grayscale version, and it has received great attention in recent years. An
ideal decolorization algorithm should preserve the original color contrast as
much as possible. Meanwhile, it should provide the final decolorized result as
fast as possible. However, most of the current methods are suffering from
either unsatisfied color information preservation or high computational cost,
limiting their application value. In this paper, a simple but effective
technique is proposed for real-time decolorization. Based on the typical
rgb2gray() color conversion model, which produces a grayscale image by linearly
combining R, G, and B channels, we propose a dominant color hypothesis and a
corresponding distance measurement metric to evaluate the quality of grayscale
conversion. The local optimum scheme provides several "good" candidates in a
confidence interval, from which the "best" result can be extracted.
Experimental results demonstrate that remarkable simplicity of the proposed
method facilitates the process of high resolution images and videos in
real-time using a common CPU.
</summary>
    <author>
      <name>Wei Hu</name>
    </author>
    <author>
      <name>Wei Li</name>
    </author>
    <author>
      <name>Fan Zhang</name>
    </author>
    <author>
      <name>Qian Du</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper has been withdrawn by the author due to some errors in
  equation 9 related descriptions</arxiv:comment>
    <link href="http://arxiv.org/abs/1404.2728v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.2728v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.3363v3</id>
    <updated>2015-05-07T13:37:13Z</updated>
    <published>2014-04-13T09:52:15Z</published>
    <title>Interactive Isogeometric Volume Visualization with Pixel-Accurate
  Geometry</title>
    <summary>  A recent development, called isogeometric analysis, provides a unified
approach for design, analysis and optimization of functional products in
industry. Traditional volume rendering methods for inspecting the results from
the numerical simulations cannot be applied directly to isogeometric models. We
present a novel approach for interactive visualization of isogeometric analysis
results, ensuring correct, i.e., pixel-accurate geometry of the volume
including its bounding surfaces. The entire OpenGL pipeline is used in a
multi-stage algorithm leveraging techniques from surface rendering,
order-independent transparency, as well as theory and numerical methods for
ordinary differential equations. We showcase the efficiency of our approach on
different models relevant to industry, ranging from quality inspection of the
parametrization of the geometry, to stress analysis in linear elasticity, to
visualization of computational fluid dynamics results.
</summary>
    <author>
      <name>Franz G. Fuchs</name>
    </author>
    <author>
      <name>Jon M. Hjelmervik</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TVCG.2015.2430337</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TVCG.2015.2430337" rel="related"/>
    <link href="http://arxiv.org/abs/1404.3363v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.3363v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.6.9.h; G.1.1.e; G.1.5; G.1.7; G.1.0.g" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.6293v2</id>
    <updated>2015-01-30T00:13:07Z</updated>
    <published>2014-04-25T00:04:20Z</published>
    <title>Piko: A Design Framework for Programmable Graphics Pipelines</title>
    <summary>  We present Piko, a framework for designing, optimizing, and retargeting
implementations of graphics pipelines on multiple architectures. Piko
programmers express a graphics pipeline by organizing the computation within
each stage into spatial bins and specifying a scheduling preference for these
bins. Our compiler, Pikoc, compiles this input into an optimized implementation
targeted to a massively-parallel GPU or a multicore CPU.
  Piko manages work granularity in a programmable and flexible manner, allowing
programmers to build load-balanced parallel pipeline implementations, to
exploit spatial and producer-consumer locality in a pipeline implementation,
and to explore tradeoffs between these considerations. We demonstrate that Piko
can implement a wide range of pipelines, including rasterization, Reyes, ray
tracing, rasterization/ray tracing hybrid, and deferred rendering. Piko allows
us to implement efficient graphics pipelines with relative ease and to quickly
explore design alternatives by modifying the spatial binning configurations and
scheduling preferences for individual stages, all while delivering real-time
performance that is within a factor six of state-of-the-art rendering systems.
</summary>
    <author>
      <name>Anjul Patney</name>
    </author>
    <author>
      <name>Stanley Tzeng</name>
    </author>
    <author>
      <name>Kerry A. Seitz Jr.</name>
    </author>
    <author>
      <name>John D. Owens</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, updated for 2015</arxiv:comment>
    <link href="http://arxiv.org/abs/1404.6293v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.6293v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.1; I.3.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.4734v1</id>
    <updated>2014-04-30T22:05:15Z</updated>
    <published>2014-04-30T22:05:15Z</published>
    <title>A General Framework for Bilateral and Mean Shift Filtering</title>
    <summary>  We present a generalization of the bilateral filter that can be applied to
feature-preserving smoothing of signals on images, meshes, and other domains
within a single unified framework. Our discretization is competitive with
state-of-the-art smoothing techniques in terms of both accuracy and speed, is
easy to implement, and has parameters that are straightforward to understand.
Unlike previous bilateral filters developed for meshes and other irregular
domains, our construction reduces exactly to the image bilateral on rectangular
domains and comes with a rigorous foundation in both the smooth and discrete
settings. These guarantees allow us to construct unconditionally convergent
mean-shift schemes that handle a variety of extremely noisy signals. We also
apply our framework to geometric edge-preserving effects like feature
enhancement and show how it is related to local histogram techniques.
</summary>
    <author>
      <name>Justin Solomon</name>
    </author>
    <author>
      <name>Keenan Crane</name>
    </author>
    <author>
      <name>Adrian Butscher</name>
    </author>
    <author>
      <name>Chris Wojtan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 11 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1405.4734v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.4734v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1406.7338v1</id>
    <updated>2014-06-28T00:47:30Z</updated>
    <published>2014-06-28T00:47:30Z</published>
    <title>Order-Independent Texture Synthesis</title>
    <summary>  Search-based texture synthesis algorithms are sensitive to the order in which
texture samples are generated; different synthesis orders yield different
textures. Unfortunately, most polygon rasterizers and ray tracers do not
guarantee the order with which surfaces are sampled. To circumvent this
problem, textures are synthesized beforehand at some maximum resolution and
rendered using texture mapping.
  We describe a search-based texture synthesis algorithm in which samples can
be generated in arbitrary order, yet the resulting texture remains identical.
The key to our algorithm is a pyramidal representation in which each texture
sample depends only on a fixed number of neighboring samples at each level of
the pyramid. The bottom (coarsest) level of the pyramid consists of a noise
image, which is small and predetermined. When a sample is requested by the
renderer, all samples on which it depends are generated at once. Using this
approach, samples can be generated in any order. To make the algorithm
efficient, we propose storing texture samples and their dependents in a
pyramidal cache. Although the first few samples are expensive to generate,
there is substantial reuse, so subsequent samples cost less. Fortunately, most
rendering algorithms exhibit good coherence, so cache reuse is high.
</summary>
    <author>
      <name>Li-Yi Wei</name>
    </author>
    <author>
      <name>Marc Levoy</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This is a combination of Stanford Computer Science Department
  Technical Report 2002-01 and a subsequent submission to SIGGRAPH 2003</arxiv:comment>
    <link href="http://arxiv.org/abs/1406.7338v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1406.7338v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1407.3145v1</id>
    <updated>2014-07-11T13:14:16Z</updated>
    <published>2014-07-11T13:14:16Z</published>
    <title>SketchBio: A Scientist's 3D Interface for Molecular Modeling and
  Animation</title>
    <summary>  Background: Because of the difficulties involved in learning and using 3D
modeling and rendering software, many scientists hire programmers or animators
to create models and animations. This both slows the discovery process and
provides opportunities for miscommunication. Working with multiple
collaborators, we developed a set of design goals for a tool that would enable
them to directly construct models and animations. Results: We present
SketchBio, a tool that incorporates state-of-the-art bimanual interaction and
drop shadows to enable rapid construction of molecular structures and
animations. It includes three novel features: crystal by example, pose-mode
physics, and spring-based layout that accelerate operations common in the
formation of molecular models. We present design decisions and their
consequences, including cases where iterative design was required to produce
effective approaches. Conclusions: The design decisions, novel features, and
inclusion of state-of-the-art techniques enabled SketchBio to meet all of its
design goals. These features and decisions can be incorporated into existing
and new tools to improve their effectiveness
</summary>
    <author>
      <name>Shawn M. Waldon</name>
    </author>
    <author>
      <name>Peter M. Thompson</name>
    </author>
    <author>
      <name>Patrick J. Hahn</name>
    </author>
    <author>
      <name>Russell M. Taylor II</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">BioVis 2014 conference</arxiv:comment>
    <link href="http://arxiv.org/abs/1407.3145v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1407.3145v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1408.0677v1</id>
    <updated>2014-08-04T13:27:17Z</updated>
    <published>2014-08-04T13:27:17Z</published>
    <title>A Moving Least Squares Based Approach for Contour Visualization of
  Multi-Dimensional Data</title>
    <summary>  Analysis of high dimensional data is a common task. Often, small multiples
are used to visualize 1 or 2 dimensions at a time, such as in a scatterplot
matrix. Associating data points between different views can be difficult
though, as the points are not fixed. Other times, dimensional reduction
techniques are employed to summarize the whole dataset in one image, but
individual dimensions are lost in this view. In this paper, we present a means
of augmenting a dimensional reduction plot with isocontours to reintroduce the
original dimensions. By applying this to each dimension in the original data,
we create multiple views where the points are consistent, which facilitates
their comparison. Our approach employs a combination of a novel, graph-based
projection technique with a GPU accelerated implementation of moving least
squares to interpolate space between the points. We also present evaluations of
this approach both with a case study and with a user study.
</summary>
    <author>
      <name>Chris W. Muelder</name>
    </author>
    <author>
      <name>Nick Leaf</name>
    </author>
    <author>
      <name>Carmen Sigovan</name>
    </author>
    <author>
      <name>Kwan-Liu Ma</name>
    </author>
    <link href="http://arxiv.org/abs/1408.0677v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1408.0677v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1408.3326v1</id>
    <updated>2014-08-14T16:05:29Z</updated>
    <published>2014-08-14T16:05:29Z</published>
    <title>Regularized Harmonic Surface Deformation</title>
    <summary>  Harmonic surface deformation is a well-known geometric modeling method that
creates plausible deformations in an interactive manner. However, this method
is susceptible to artifacts, in particular close to the deformation handles.
These artifacts often correlate with strong gradients of the deformation
energy.In this work, we propose a novel formulation of harmonic surface
deformation, which incorporates a regularization of the deformation energy. To
do so, we build on and extend a recently introduced generic linear
regularization approach. It can be expressed as a change of norm for the linear
optimization problem, i.e., the regularization is baked into the optimization.
This minimizes the implementation complexity and has only a small impact on
runtime. Our results show that a moderate use of regularization suppresses many
deformation artifacts common to the well-known harmonic surface deformation
method, without introducing new artifacts.
</summary>
    <author>
      <name>Yeara Kozlov</name>
    </author>
    <author>
      <name>Janick Martinez Esturo</name>
    </author>
    <author>
      <name>Hans-Peter Seidel</name>
    </author>
    <author>
      <name>Tino Weinkauf</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1408.3326v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1408.3326v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1408.6591v1</id>
    <updated>2014-08-26T14:23:57Z</updated>
    <published>2014-08-26T14:23:57Z</published>
    <title>Voronoi Grid-Shell Structures</title>
    <summary>  We introduce a framework for the generation of grid-shell structures that is
based on Voronoi diagrams and allows us to design tessellations that achieve
excellent static performances. We start from an analysis of stress on the input
surface and we use the resulting tensor field to induce an anisotropic
non-Euclidean metric over it. Then we compute a Centroidal Voronoi Tessellation
under the same metric. The resulting mesh is hex-dominant and made of cells
with a variable density, which depends on the amount of stress, and anisotropic
shape, which depends on the direction of maximum stress. This mesh is further
optimized taking into account symmetry and regularity of cells to improve
aesthetics. We demonstrate that our grid-shells achieve better static
performances with respect to quad-based grid shells, while offering an
innovative and aesthetically pleasing look.
</summary>
    <author>
      <name>Nico Pietroni</name>
    </author>
    <author>
      <name>Davide Tonelli</name>
    </author>
    <author>
      <name>Enrico Puppo</name>
    </author>
    <author>
      <name>Maurizio Froli</name>
    </author>
    <author>
      <name>Roberto Scopigno</name>
    </author>
    <author>
      <name>Paolo Cignoni</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1408.6591v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1408.6591v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68U05" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1409.2081v1</id>
    <updated>2014-09-07T04:34:11Z</updated>
    <published>2014-09-07T04:34:11Z</published>
    <title>History-free Collision Response for Deformable Surfaces</title>
    <summary>  Continuous collision detection (CCD) and response methods are widely adopted
in dynamics simulation of deformable models. They are history-based, as their
success is strictly based on an assumption of a collision-free state at the
start of each time interval. On the other hand, in many applications surfaces
have normals defined to designate their orientation (i.e. front- and
back-face), yet CCD methods are totally blind to such orientation
identification (thus are orientation-free). We notice that if such information
is utilized, many penetrations can be untangled. In this paper we present a
history-free method for separation of two penetrating meshes, where at least
one of them has clarified surface orientation. This method first computes all
edge-face (E-F) intersections with discrete collision detection (DCD), and then
builds a number of penetration stencils. On response, the stencil vertices are
relocated into a penetration-free state, via a global displacement minimizer.
Our method is very effective for handling penetration between two meshes, being
it an initial configuration or in the middle of physics simulation. The major
limitation is that it is not applicable to self-collision within one mesh at
the time being.
</summary>
    <author>
      <name>Juntao Ye</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">originally 4 pages, submitted as Technical Brief to Siggraph Asia
  2014</arxiv:comment>
    <link href="http://arxiv.org/abs/1409.2081v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1409.2081v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1409.2235v3</id>
    <updated>2014-09-13T23:59:10Z</updated>
    <published>2014-09-08T08:19:21Z</published>
    <title>Tracing Analytic Ray Curves for Light and Sound Propagation in
  Non-linear Media</title>
    <summary>  The physical world consists of spatially varying media, such as the
atmosphere and the ocean, in which light and sound propagates along non-linear
trajectories. This presents a challenge to existing ray-tracing based methods,
which are widely adopted to simulate propagation due to their efficiency and
flexibility, but assume linear rays. We present a novel algorithm that traces
analytic ray curves computed from local media gradients, and utilizes the
closed-form solutions of both the intersections of the ray curves with planar
surfaces, and the travel distance. By constructing an adaptive unstructured
mesh, our algorithm is able to model general media profiles that vary in three
dimensions with complex boundaries consisting of terrains and other scene
objects such as buildings. We trace the analytic ray curves using the adaptive
unstructured mesh, which considerably improves the efficiency over prior
methods. We highlight the algorithm's application on simulation of sound and
visual propagation in outdoor scenes.
</summary>
    <author>
      <name>Qi Mo</name>
    </author>
    <author>
      <name>Hengchin Yeh</name>
    </author>
    <author>
      <name>Dinesh Manocha</name>
    </author>
    <link href="http://arxiv.org/abs/1409.2235v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1409.2235v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1409.7256v1</id>
    <updated>2014-09-09T10:39:46Z</updated>
    <published>2014-09-09T10:39:46Z</published>
    <title>Reactive Programming for Interactive Graphics</title>
    <summary>  One of the big challenges of developing interactive statistical applications
is the management of the data pipeline, which controls transformations from
data to plot. The user's interactions needs to be propagated through these
modules and reflected in the output representation at a fast pace. Each
individual module may be easy to develop and manage, but the dependency
structure can be quite challenging. The MVC (Model/View/Controller) pattern is
an attempt to solve the problem by separating the user's interaction from the
representation of the data. In this paper we discuss the paradigm of reactive
programming in the framework of the MVC architecture and show its applicability
to interactive graphics. Under this paradigm, developers benefit from the
separation of user interaction from the graphical representation, which makes
it easier for users and developers to extend interactive applications. We show
the central role of reactive data objects in an interactive graphics system,
implemented as the R package cranvas, which is freely available on GitHub and
the main developers include the authors of this paper.
</summary>
    <author>
      <name>Yihui Xie</name>
    </author>
    <author>
      <name>Heike Hofmann</name>
    </author>
    <author>
      <name>Xiaoyue Cheng</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1214/14-STS477</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1214/14-STS477" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published in at http://dx.doi.org/10.1214/14-STS477 the Statistical
  Science (http://www.imstat.org/sts/) by the Institute of Mathematical
  Statistics (http://www.imstat.org)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Statistical Science 2014, Vol. 29, No. 2, 201-213</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1409.7256v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1409.7256v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1409.7724v1</id>
    <updated>2014-07-23T19:17:11Z</updated>
    <published>2014-07-23T19:17:11Z</published>
    <title>Using 3D Printing to Visualize Social Media Big Data</title>
    <summary>  Big data volume continues to grow at unprecedented rates. One of the key
features that makes big data valuable is the promise to find unknown patterns
or correlations that may be able to improve the quality of processes or
systems. Unfortunately, with the exponential growth in data, users often have
difficulty in visualizing the often-unstructured, non-homogeneous data coming
from a variety of sources. The recent growth in popularity of 3D printing has
ushered in a revolutionary way to interact with big data. Using a 3D printed
mockup up a physical or notional environment, one can display data on the
mockup to show real-time data patterns. In this poster and demonstration, we
describe the process of 3D printing and demonstrate an application of
displaying Twitter data on a 3D mockup of the Massachusetts Institute of
Technology (MIT) campus, known as LuminoCity.
</summary>
    <author>
      <name>Zachary Weber</name>
    </author>
    <author>
      <name>Vijay Gadepally</name>
    </author>
    <link href="http://arxiv.org/abs/1409.7724v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1409.7724v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.1130v1</id>
    <updated>2014-10-05T07:26:44Z</updated>
    <published>2014-10-05T07:26:44Z</published>
    <title>Real-time animation of human characters with fuzzy controllers</title>
    <summary>  The production of animation is a resource intensive process in game
companies. Therefore, techniques to synthesize animations have been developed.
However, these procedural techniques offer limited adaptability by animation
artists. In order to solve this, a fuzzy neural network model of the animation
is proposed, where the parameters can be tuned either by machine learning
techniques that use motion capture data as training data or by the animation
artist himself. This paper illustrates how this real time procedural animation
system can be developed, taking the human gait on flat terrain and inclined
surfaces as example. Currently, the parametric model is capable of synthesizing
animations for various limb sizes and step sizes.
</summary>
    <author>
      <name>Koen Samyn</name>
    </author>
    <author>
      <name>Sofie Van Hoecke</name>
    </author>
    <author>
      <name>Bart Pieters</name>
    </author>
    <author>
      <name>Charles Hollemeersch</name>
    </author>
    <author>
      <name>Aljosha Demeulemeester</name>
    </author>
    <author>
      <name>Rik van de Walle</name>
    </author>
    <link href="http://arxiv.org/abs/1410.1130v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.1130v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.2259v1</id>
    <updated>2014-09-14T11:10:06Z</updated>
    <published>2014-09-14T11:10:06Z</published>
    <title>Image compression overview</title>
    <summary>  Compression plays a significant role in a data storage and a transmission. If
we speak about a generall data compression, it has to be a lossless one. It
means, we are able to recover the original data 1:1 from the compressed file.
Multimedia data (images, video, sound...), are a special case. In this area, we
can use something called a lossy compression. Our main goal is not to recover
data 1:1, but only keep them visually similar. This article is about an image
compression, so we will be interested only in image compression. For a human
eye, it is not a huge difference, if we recover RGB color with values
[150,140,138] instead of original [151,140,137]. The magnitude of a difference
determines the loss rate of the compression. The bigger difference usually
means a smaller file, but also worse image quality and noticable differences
from the original image. We want to cover compression techniques mainly from
the last decade. Many of them are variations of existing ones, only some of
them uses new principes.
</summary>
    <author>
      <name>Martin Prantl</name>
    </author>
    <link href="http://arxiv.org/abs/1410.2259v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.2259v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.3018v1</id>
    <updated>2014-10-11T18:21:05Z</updated>
    <published>2014-10-11T18:21:05Z</published>
    <title>A mathematical design and evaluation of Bernstein-Bezier curves' shape
  features using the laws of technical aesthetics</title>
    <summary>  We present some notes on the definition of mathematical design as well as on
the methods of mathematical modeling which are used in the process of the
artistic design of the environment and its components. For the first time in
the field of geometric modeling, we perform an aesthetic analysis of planar
Bernstein-Bezier curves from the standpoint of the laws of technical
aesthetics. The shape features of the curve segments' geometry were evaluated
using the following criteria: conciseness-integrity, expressiveness,
proportional consistency, compositional balance, structural organization,
imagery, rationality, dynamism, scale, flexibility and harmony. In the
non-Russian literature, Bernstein-Bezier curves using a monotonic curvature
function (i.e., a class A Bezier curve) are considered to be fair (i.e.,
beautiful) curves, but their aesthetic analysis has never been performed. The
aesthetic analysis performed by the authors of this work means that this is no
longer the case. To confirm the conclusions of the authors' research, a survey
of the "aesthetic appropriateness" of certain Bernstein-Bezier curve segments
was conducted among 240 children, aged 14-17. The results of this survey have
shown themselves to be in full accordance with the authors' results.
</summary>
    <author>
      <name>Rifkat I. Nabiyev</name>
    </author>
    <author>
      <name>Rushan Ziatdinov</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.13187/md.2014.2.6</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.13187/md.2014.2.6" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Mathematical Design &amp; Technical Aesthetics, 2014, Vol. 2, No. 1,
  pp. 6-13</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1410.3018v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.3018v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1411.1906v1</id>
    <updated>2014-11-07T13:29:06Z</updated>
    <published>2014-11-07T13:29:06Z</published>
    <title>Footprint-Driven Locomotion Composition</title>
    <summary>  One of the most efficient ways of generating goal-directed walking motions is
synthesising the final motion based on footprints. Nevertheless, current
implementations have not examined the generation of continuous motion based on
footprints, where different behaviours can be generated automatically.
Therefore, in this paper a flexible approach for footprint-driven locomotion
composition is presented. The presented solution is based on the ability to
generate footprint-driven locomotion, with flexible features like jumping,
running, and stair stepping. In addition, the presented system examines the
ability of generating the desired motion of the character based on predefined
footprint patterns that determine which behaviour should be performed. Finally,
it is examined the generation of transition patterns based on the velocity of
the root and the number of footsteps required to achieve the target behaviour
smoothly and naturally.
</summary>
    <author>
      <name>Christos Mousas</name>
    </author>
    <author>
      <name>Paul Newbury</name>
    </author>
    <author>
      <name>Christos-Nikolaos Anagnostopoulos</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5121/ijcga.2014.4403</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5121/ijcga.2014.4403" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Graphics &amp; Animation (IJCGA)
  Vol.4, No.4, pp. 27-42, October 2014</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1411.1906v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1411.1906v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1411.3632v1</id>
    <updated>2014-11-13T17:50:51Z</updated>
    <published>2014-11-13T17:50:51Z</published>
    <title>Mesh2Fab: Reforming Shapes for Material-specific Fabrication</title>
    <summary>  As humans, we regularly associate shape of an object with its built material.
In the context of geometric modeling, however, this interrelation between form
and material is rarely explored. In this work, we propose a novel data-driven
reforming (i.e., reshaping) algorithm that adapts an input multi-component
model for a target fabrication material. The algorithm adapts both the part
geometry and the inter-part topology of the input shape to better align with
material specific fabrication requirements. As output, we produce the reshaped
model along with respective part dimensions and inter-part junction
specifications. We evaluate our algorithm on a range of man-made models and
demonstrate non-trivial model reshaping examples focusing only on metal and
wooden materials. We also appraise the output of our algorithm using a user
study.
</summary>
    <author>
      <name>Yong-Liang Yang</name>
    </author>
    <author>
      <name>Jun Wang</name>
    </author>
    <author>
      <name>Niloy J. Mitra</name>
    </author>
    <link href="http://arxiv.org/abs/1411.3632v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1411.3632v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1411.5993v1</id>
    <updated>2014-11-21T19:37:27Z</updated>
    <published>2014-11-21T19:37:27Z</published>
    <title>Reverse Engineering Point Clouds to Fit Tensor Product B-Spline Surfaces
  by Blending Local Fits</title>
    <summary>  Being able to reverse engineer from point cloud data to obtain 3D models is
important in modeling. As our main contribution, we present a new method to
obtain a tensor product B-spline representation from point cloud data by
fitting surfaces to appropriately segmented data. By blending multiple local
fits our method is more efficient than existing techniques, with the ability to
deal with more detail by efficiently introducing a high number of knots.
Further point cloud data obtained by digitizing 3D data, typically presents
many associated complications like noise and missing data. As our second
contribution, we propose an end-to-end framework for smoothing, hole filling,
parameterization, knot selection and B-spline fitting that addresses these
issues, works robustly with large irregularly shaped data containing holes and
is straightforward to implement.
</summary>
    <author>
      <name>Lavanya Sita Tekumalla</name>
    </author>
    <author>
      <name>Elaine Cohen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Masters Thesis, Lavanya Sita Tekumalla, School of Computing,
  University of Utah</arxiv:comment>
    <link href="http://arxiv.org/abs/1411.5993v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1411.5993v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.3841v6</id>
    <updated>2015-10-18T20:50:07Z</updated>
    <published>2014-12-11T22:11:44Z</published>
    <title>Merging of Bézier curves with box constraints</title>
    <summary>  In this paper, we present a novel approach to the problem of merging of
B\'ezier curves with respect to the $L_2$-norm. We give illustrative examples
to show that the solution of the conventional merging problem may not be
suitable for further modification and applications. As in the case of the
degree reduction problem, we apply the so-called restricted area approach --
proposed recently in (P. Gospodarczyk, Computer-Aided Design 62 (2015),
143--151) -- to avoid certain defects and make the resulting curve more useful.
A method of solving the new problem is based on box-constrained quadratic
programming approach.
</summary>
    <author>
      <name>Przemysław Gospodarczyk</name>
    </author>
    <author>
      <name>Paweł Woźny</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.cam.2015.10.005</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.cam.2015.10.005" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Computational and Applied Mathematics 296, 265-274
  (2016)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1412.3841v6" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.3841v6" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.4246v1</id>
    <updated>2014-12-13T15:24:38Z</updated>
    <published>2014-12-13T15:24:38Z</published>
    <title>A Canonical Representation of Data-Linear Visualization Algorithms</title>
    <summary>  We introduce linear-state dataflows, a canonical model for a large set of
visualization algorithms that we call data-linear visualizations. Our model
defines a fixed dataflow architecture: partitioning and subpartitioning of
input data, ordering, graphic primitives, and graphic attributes generation.
Local variables and accumulators are specific concepts that extend the
expressiveness of the dataflow to support features of visualization algorithms
that require state handling. We first show the flexibility of our model: it
enables the declarative construction of many common algorithms with just a few
mappings. Furthermore, the model enables easy mixing of visual mappings, such
as creating treemaps of histograms and 2D plots, plots of histograms...
Finally, we introduce our model in a more formal way and present some of its
important properties. We have implemented this model in a visualization
framework built around the concept of linear-state dataflows.
</summary>
    <author>
      <name>Thomas Baudel</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, extended version of the original technical report</arxiv:comment>
    <link href="http://arxiv.org/abs/1412.4246v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.4246v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.7780v1</id>
    <updated>2014-12-25T03:20:34Z</updated>
    <published>2014-12-25T03:20:34Z</published>
    <title>Interactive Visual Exploration of Halos in Large Scale Cosmology
  Simulation</title>
    <summary>  Halo is one of the most important basic elements in cosmology simulation,
which merges from small clumps to ever larger objects. The processes of the
birth and merging of the halos play a fundamental role in studying the
evolution of large scale cosmological structures. In this paper, a visual
analysis system is developed to interactively identify and explore the
evolution histories of thousands of halos. In this system, an intelligent
structure-aware selection method in What You See Is What You Get manner is
designed to efficiently define the interesting region in 3D space with 2D
hand-drawn lasso input. Then the exact information of halos within this 3D
region is identified by data mining in the merger tree files. To avoid visual
clutter, all the halos are projected in 2D space with a MDS method. Through the
linked view of 3D View and 2D graph, Users can interactively explore these
halos, including the tracing path and evolution history tree.
</summary>
    <author>
      <name>Guihua Shan</name>
    </author>
    <author>
      <name>Maojin Xie</name>
    </author>
    <author>
      <name>FengAn Li</name>
    </author>
    <author>
      <name>Yang Gao</name>
    </author>
    <author>
      <name>Xuebin Chi</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s12650-014-0206-5</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s12650-014-0206-5" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9pages, 14figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">J. Visualization 17(3):145-156(2014)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1412.7780v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.7780v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1501.03032v3</id>
    <updated>2015-03-09T09:42:07Z</updated>
    <published>2015-01-13T15:13:35Z</published>
    <title>$G^{k,l}$-constrained multi-degree reduction of Bézier curves</title>
    <summary>  We present a new approach to the problem of $G^{k,l}$-constrained ($k,l \leq
3$) multi-degree reduction of B\'{e}zier curves with respect to the least
squares norm. First, to minimize the least squares error, we consider two
methods of determining the values of geometric continuity parameters. One of
them is based on quadratic and nonlinear programming, while the other uses some
simplifying assumptions and solves a system of linear equations. Next, for
prescribed values of these parameters, we obtain control points of the
multi-degree reduced curve, using the properties of constrained dual Bernstein
basis polynomials. Assuming that the input and output curves are of degree $n$
and $m$, respectively, we determine these points with the complexity $O(mn)$,
which is significantly less than the cost of other known methods. Finally, we
give several examples to demonstrate the effectiveness of our algorithms.
</summary>
    <author>
      <name>Przemysław Gospodarczyk</name>
    </author>
    <author>
      <name>Stanisław Lewanowicz</name>
    </author>
    <author>
      <name>Paweł Woźny</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s11075-015-9988-3</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s11075-015-9988-3" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Numerical Algorithms 71, 121-137 (2016)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1501.03032v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1501.03032v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.01954v1</id>
    <updated>2015-02-06T16:59:20Z</updated>
    <published>2015-02-06T16:59:20Z</published>
    <title>Interactive 3D Face Stylization Using Sculptural Abstraction</title>
    <summary>  Sculptors often deviate from geometric accuracy in order to enhance the
appearance of their sculpture. These subtle stylizations may emphasize anatomy,
draw the viewer's focus to characteristic features of the subject, or symbolize
textures that might not be accurately reproduced in a particular sculptural
medium, while still retaining fidelity to the unique proportions of an
individual. In this work we demonstrate an interactive system for enhancing
face geometry using a class of stylizations based on visual decomposition into
abstract semantic regions, which we call sculptural abstraction. We propose an
interactive two-scale optimization framework for stylization based on
sculptural abstraction, allowing real-time adjustment of both global and local
parameters. We demonstrate this system's effectiveness in enhancing physical 3D
prints of scans from various sources.
</summary>
    <author>
      <name>Jan Jachnik</name>
    </author>
    <author>
      <name>Dan B Goldman</name>
    </author>
    <author>
      <name>Linjie Luo</name>
    </author>
    <author>
      <name>Andrew J. Davison</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 16 figures. For associated video and to download some of the
  results, see the project webpage at
  http://wp.doc.ic.ac.uk/robotvision/project/face-stylization/</arxiv:comment>
    <link href="http://arxiv.org/abs/1502.01954v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.01954v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.02139v1</id>
    <updated>2015-02-07T13:13:51Z</updated>
    <published>2015-02-07T13:13:51Z</published>
    <title>Marching Surfaces: Isosurface Approximation using G$^1$ Multi-Sided
  Surfaces</title>
    <summary>  Marching surfaces is a method for isosurface extraction and approximation
based on a $G^1$ multi-sided patch interpolation scheme. Given a 3D grid of
scalar values, an underlying curve network is formed using second order
information and cubic Hermite splines. Circular arc fitting defines the tangent
vectors for the Hermite curves at specified isovalues. Once the boundary curve
network is formed, a loop of curves is determined for each grid cell and then
interpolated with multi-sided surface patches, which are $G^1$ continuous at
the joins. The data economy of the method and its continuity preserving
properties provide an effective compression scheme, ideal for indirect volume
rendering on mobile devices, or collaborating on the Internet, while enhancing
visual fidelity. The use of multi-sided patches enables a more natural way to
approximate the isosurfaces than using a fixed number of sides or polygons as
is proposed in the literature. This assertion is supported with comparisons to
the traditional Marching Cubes algorithm and other $G^1$ methods.
</summary>
    <author>
      <name>Gustavo Chávez</name>
    </author>
    <author>
      <name>Alyn Rockwood</name>
    </author>
    <link href="http://arxiv.org/abs/1502.02139v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.02139v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.02961v1</id>
    <updated>2015-02-10T16:03:37Z</updated>
    <published>2015-02-10T16:03:37Z</published>
    <title>Avatar-independent scripting for real-time gesture animation</title>
    <summary>  When animation of a humanoid figure is to be generated at run-time, instead
of by replaying pre-composed motion clips, some method is required of
specifying the avatar's movements in a form from which the required motion data
can be automatically generated. This form must be of a more abstract nature
than raw motion data: ideally, it should be independent of the particular
avatar's proportions, and both writable by hand and suitable for automatic
generation from higher-level descriptions of the required actions.
  We describe here the development and implementation of such a scripting
language for the particular area of sign languages of the deaf, called SiGML
(Signing Gesture Markup Language), based on the existing HamNoSys notation for
sign languages.
  We conclude by suggesting how this work may be extended to more general
animation for interactive virtual reality applications.
</summary>
    <author>
      <name>Richard Kennaway</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">23 pages, 12 figures. Last revised November 2006</arxiv:comment>
    <link href="http://arxiv.org/abs/1502.02961v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.02961v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.06419v1</id>
    <updated>2015-02-14T11:29:26Z</updated>
    <published>2015-02-14T11:29:26Z</published>
    <title>Analysis of Design Principles and Requirements for Procedural Rigging of
  Bipeds and Quadrupeds Characters with Custom Manipulators for Animation</title>
    <summary>  Character rigging is a process of endowing a character with a set of custom
manipulators and controls making it easy to animate by the animators. These
controls consist of simple joints, handles, or even separate character
selection windows.This research paper present an automated rigging system for
quadruped characters with custom controls and manipulators for animation.The
full character rigging mechanism is procedurally driven based on various
principles and requirements used by the riggers and animators. The automation
is achieved initially by creating widgets according to the character type.
These widgets then can be customized by the rigger according to the character
shape, height and proportion. Then joint locations for each body parts are
calculated and widgets are replaced programmatically.Finally a complete and
fully operational procedurally generated character control rig is created and
attached with the underlying skeletal joints. The functionality and feasibility
of the rig was analyzed from various source of actual character motion and a
requirements criterion was met. The final rigged character provides an
efficient and easy to manipulate control rig with no lagging and at high frame
rate.
</summary>
    <author>
      <name>Zeeshan Bhatti</name>
    </author>
    <author>
      <name>Asadullah Shah</name>
    </author>
    <author>
      <name>Ahmad Waqas</name>
    </author>
    <author>
      <name>Nadeem Mahmood</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5121/ijcga.2015.5104</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5121/ijcga.2015.5104" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages, 24 figures, 4 Algorithms, Journal Paper</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Graphics &amp; Animation (IJCGA)
  Vol.5, No.1, January 2015</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1502.06419v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.06419v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.06686v1</id>
    <updated>2015-02-24T04:30:43Z</updated>
    <published>2015-02-24T04:30:43Z</published>
    <title>Data-Driven Shape Analysis and Processing</title>
    <summary>  Data-driven methods play an increasingly important role in discovering
geometric, structural, and semantic relationships between 3D shapes in
collections, and applying this analysis to support intelligent modeling,
editing, and visualization of geometric data. In contrast to traditional
approaches, a key feature of data-driven approaches is that they aggregate
information from a collection of shapes to improve the analysis and processing
of individual shapes. In addition, they are able to learn models that reason
about properties and relationships of shapes without relying on hard-coded
rules or explicitly programmed instructions. We provide an overview of the main
concepts and components of these techniques, and discuss their application to
shape classification, segmentation, matching, reconstruction, modeling and
exploration, as well as scene analysis and synthesis, through reviewing the
literature and relating the existing works with both qualitative and numerical
comparisons. We conclude our report with ideas that can inspire future research
in data-driven shape analysis and processing.
</summary>
    <author>
      <name>Kai Xu</name>
    </author>
    <author>
      <name>Vladimir G. Kim</name>
    </author>
    <author>
      <name>Qixing Huang</name>
    </author>
    <author>
      <name>Evangelos Kalogerakis</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 19 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1502.06686v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.06686v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.00088v1</id>
    <updated>2015-02-28T07:23:08Z</updated>
    <published>2015-02-28T07:23:08Z</published>
    <title>Facial Expression Cloning with Elastic and Muscle Models</title>
    <summary>  Expression cloning plays an important role in facial expression synthesis. In
this paper, a novel algorithm is proposed for facial expression cloning. The
proposed algorithm first introduces a new elastic model to balance the global
and local warping effects, such that the impacts from facial feature diversity
among people can be minimized, and thus more effective geometric warping
results can be achieved. Furthermore, a muscle-distribution-based (MD) model is
proposed, which utilizes the muscle distribution of the human face and results
in more accurate facial illumination details. In addition, we also propose a
new distance-based metric to automatically select the optimal parameters such
that the global and local warping effects in the elastic model can be suitably
balanced. Experimental results show that our proposed algorithm outperforms the
existing methods.
</summary>
    <author>
      <name>Yihao Zhang</name>
    </author>
    <author>
      <name>Weiyao Lin</name>
    </author>
    <author>
      <name>Bing Zhou</name>
    </author>
    <author>
      <name>Zhenzhong Chen</name>
    </author>
    <author>
      <name>Bin Sheng</name>
    </author>
    <author>
      <name>Jianxin Wu</name>
    </author>
    <author>
      <name>Wenjun Zhang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This manuscript is the accepted version for JVCI (Journal of Visual
  Communication and Image Representation)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Visual Communication and Image Representation, vol. 25,
  no. 5, pp. 916-927, 2014</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1503.00088v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.00088v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.00202v1</id>
    <updated>2015-03-01T01:10:03Z</updated>
    <published>2015-03-01T01:10:03Z</published>
    <title>On Integrating Information Visualization Techniques into Data Mining: A
  Review</title>
    <summary>  The exploding growth of digital data in the information era and its
immeasurable potential value has called for different types of data-driven
techniques to exploit its value for further applications. Information
visualization and data mining are two research field with such goal. While the
two communities advocates different approaches of problem solving, the vision
of combining the sophisticated algorithmic techniques from data mining as well
as the intuitivity and interactivity of information visualization is tempting.
In this paper, we attempt to survey recent researches and real world systems
integrating the wisdom in two fields towards more effective and efficient data
analytics. More specifically, we study the intersection from a data mining
point of view, explore how information visualization can be used to complement
and improve different stages of data mining through established theories for
optimized visual presentation as well as practical toolsets for rapid
development. We organize the survey by identifying three main stages of typical
process of data mining, the preliminary analysis of data, the model
construction, as well as the model evaluation, and study how each stage can
benefit from information visualization.
</summary>
    <author>
      <name>Keqian Li</name>
    </author>
    <link href="http://arxiv.org/abs/1503.00202v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.00202v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.05787v2</id>
    <updated>2015-04-17T14:01:50Z</updated>
    <published>2015-03-19T14:53:55Z</published>
    <title>Interactive Illustrative Line Styles and Line Style Transfer Functions
  for Flow Visualization</title>
    <summary>  We present a flexible illustrative line style model for the visualization of
streamline data. Our model partitions view-oriented line strips into parallel
bands whose basic visual properties can be controlled independently. We thus
extend previous line stylization techniques specifically for visualization
purposes by allowing the parametrization of these bands based on the local line
data attributes. Moreover, our approach supports emphasis and abstraction by
introducing line style transfer functions that map local line attribute values
to complete line styles. With a flexible GPU implementation of this line style
model we enable the interactive exploration of visual representations of
streamlines. We demonstrate the effectiveness of our model by applying it to 3D
flow field datasets.
</summary>
    <author>
      <name>Maarten H. Everts</name>
    </author>
    <author>
      <name>Henk Bekker</name>
    </author>
    <author>
      <name>Jos B. T. M. Roerdink</name>
    </author>
    <author>
      <name>Tobias Isenberg</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Extended version of a short paper at Pacific Graphics 2011
  (http://dx.doi.org/10.2312/PE/PG/PG2011short/105-110)</arxiv:comment>
    <link href="http://arxiv.org/abs/1503.05787v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.05787v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.02687v1</id>
    <updated>2015-04-10T14:13:39Z</updated>
    <published>2015-04-10T14:13:39Z</published>
    <title>3D Density Histograms for Criteria-driven Edge Bundling</title>
    <summary>  This paper presents a graph bundling algorithm that agglomerates edges taking
into account both spatial proximity as well as user-defined criteria in order
to reveal patterns that were not perceivable with previous bundling techniques.
Each edge belongs to a group that may either be an input of the problem or
found by clustering one or more edge properties such as origin, destination,
orientation, length or domain-specific properties. Bundling is driven by a
stack of density maps, with each map capturing both the edge density of a given
group as well as interactions with edges from other groups. Density maps are
efficiently calculated by smoothing 2D histograms of edge occurrence using
repeated averaging filters based on integral images.
  A CPU implementation of the algorithm is tested on several graphs, and
different grouping criteria are used to illustrate how the proposed technique
can render different visualizations of the same data. Bundling performance is
much higher than on previous approaches, being particularly noticeable on large
graphs, with millions of edges being bundled in seconds.
</summary>
    <author>
      <name>Daniel C. Moura</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to a conference (under review)</arxiv:comment>
    <link href="http://arxiv.org/abs/1504.02687v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.02687v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68U05" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.3; E.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.04565v1</id>
    <updated>2015-04-17T16:45:35Z</updated>
    <published>2015-04-17T16:45:35Z</published>
    <title>Real-time correction of panoramic images using hyperbolic Möbius
  transformations</title>
    <summary>  Wide-angle images gained a huge popularity in the last years due to the
development of computational photography and imaging technological advances.
They present the information of a scene in a way which is more natural for the
human eye but, on the other hand, they introduce artifacts such as bent lines.
These artifacts become more and more unnatural as the field of view increases.
  In this work, we present a technique aimed to improve the perceptual quality
of panorama visualization. The main ingredients of our approach are, on one
hand, considering the viewing sphere as a Riemann sphere, what makes natural
the application of M\"obius (complex) transformations to the input image, and,
on the other hand, a projection scheme which changes in function of the field
of view used.
  We also introduce an implementation of our method, compare it against images
produced with other methods and show that the transformations can be done in
real-time, which makes our technique very appealing for new settings, as well
as for existing interactive panorama applications.
</summary>
    <author>
      <name>Luis Peñaranda</name>
    </author>
    <author>
      <name>Luiz Velho</name>
    </author>
    <author>
      <name>Leonardo Sacht</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s11554-015-0502-x</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s11554-015-0502-x" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">25 pages, 13 figures, 1 table, 1 algorithm. In "Real-time Image
  Processing"</arxiv:comment>
    <link href="http://arxiv.org/abs/1504.04565v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.04565v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.00073v1</id>
    <updated>2015-05-01T02:47:12Z</updated>
    <published>2015-05-01T02:47:12Z</published>
    <title>Bijective Deformations in $\mathbb{R}^n$ via Integral Curve Coordinates</title>
    <summary>  We introduce Integral Curve Coordinates, which identify each point in a
bounded domain with a parameter along an integral curve of the gradient of a
function $f$ on that domain; suitable functions have exactly one critical
point, a maximum, in the domain, and the gradient of the function on the
boundary points inward. Because every integral curve intersects the boundary
exactly once, Integral Curve Coordinates provide a natural bijective mapping
from one domain to another given a bijection of the boundary. Our approach can
be applied to shapes in any dimension, provided that the boundary of the shape
(or cage) is topologically equivalent to an $n$-sphere. We present a simple
algorithm for generating a suitable function space for $f$ in any dimension. We
demonstrate our approach in 2D and describe a practical (simple and robust)
algorithm for tracing integral curves on a (piecewise-linear) triangulated
regular grid.
</summary>
    <author>
      <name>Lisa Huynh</name>
    </author>
    <author>
      <name>Yotam Gingold</name>
    </author>
    <link href="http://arxiv.org/abs/1505.00073v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.00073v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="37E30" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.01214v1</id>
    <updated>2015-05-05T22:59:32Z</updated>
    <published>2015-05-05T22:59:32Z</published>
    <title>Learning Style Similarity for Searching Infographics</title>
    <summary>  Infographics are complex graphic designs integrating text, images, charts and
sketches. Despite the increasing popularity of infographics and the rapid
growth of online design portfolios, little research investigates how we can
take advantage of these design resources. In this paper we present a method for
measuring the style similarity between infographics. Based on human perception
data collected from crowdsourced experiments, we use computer vision and
machine learning algorithms to learn a style similarity metric for infographic
designs. We evaluate different visual features and learning algorithms and find
that a combination of color histograms and Histograms-of-Gradients (HoG)
features is most effective in characterizing the style of infographics. We
demonstrate our similarity metric on a preliminary image retrieval test.
</summary>
    <author>
      <name>Babak Saleh</name>
    </author>
    <author>
      <name>Mira Dontcheva</name>
    </author>
    <author>
      <name>Aaron Hertzmann</name>
    </author>
    <author>
      <name>Zhicheng Liu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, to appear in the 41st annual conference on Graphics
  Interface (GI) 2015,</arxiv:comment>
    <link href="http://arxiv.org/abs/1505.01214v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.01214v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.03615v1</id>
    <updated>2015-05-14T04:08:53Z</updated>
    <published>2015-05-14T04:08:53Z</published>
    <title>A Connectivity-Aware Multi-level Finite-Element System for Solving
  Laplace-Beltrami Equations</title>
    <summary>  Recent work on octree-based finite-element systems has developed a multigrid
solver for Poisson equations on meshes. While the idea of defining a regularly
indexed function space has been successfully used in a number of applications,
it has also been noted that the richness of the function space is limited
because the function values can be coupled across locally disconnected regions.
In this work, we show how to enrich the function space by introducing functions
that resolve the coupling while still preserving the nesting hierarchy that
supports multigrid. A spectral analysis reveals the superior quality of the
resulting Laplace-Beltrami operator and applications to surface flow
demonstrate that our new solver more efficiently converges to the correct
solution.
</summary>
    <author>
      <name>Ming Chuang</name>
    </author>
    <author>
      <name>Michael Kazhdan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This work was done when the first author was a PhD student at Johns
  Hopkins University</arxiv:comment>
    <link href="http://arxiv.org/abs/1505.03615v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.03615v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.03977v2</id>
    <updated>2016-01-27T16:50:48Z</updated>
    <published>2015-05-15T07:38:46Z</published>
    <title>A wide diversity of 3D surfaces Generator using a new implicit function</title>
    <summary>  We present in this paper a new family of implicit function for synthesizing a
wide variety of 3D surfaces. The basis of this family consists of the usual
functions that are: the function rectangular pulses, the function saw-tooth
pulses, the function of triangular pulses, the staircase function and the power
function. By combining these common functions, named constituent functions, in
one implicit function and by varying some parameters of this function we can
synthesize a wide variety of 3D surfaces with the possibility to set their
deformations.
</summary>
    <author>
      <name>Jelloul Elmesbahi</name>
    </author>
    <author>
      <name>Ahmed Errami</name>
    </author>
    <author>
      <name>Mohammed Khaldoun</name>
    </author>
    <author>
      <name>Omar Bouattane</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This second submission replaces the first following submission at:
  arXiv:1505.03977 It completes this later by adding a second model to complete
  the first one. It corresponds to particular surfaces (Lego cubes) and the
  other remained results (about 500 3D surfaces). This is to avoid huge file
  size for our submission and to proof the effectiveness of our model</arxiv:comment>
    <link href="http://arxiv.org/abs/1505.03977v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.03977v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.06022v1</id>
    <updated>2015-05-22T10:41:45Z</updated>
    <published>2015-05-22T10:41:45Z</published>
    <title>Implementing a Photorealistic Rendering System using GLSL</title>
    <summary>  Ray tracing on GPUs is becoming quite common these days. There are many
publicly available documents on how to implement basic ray tracing on GPUs for
spheres and implicit surfaces. We even have some general frameworks for ray
tracing on GPUs. We however hardly find details on how to implement more
complex ray tracing algorithms themselves that are commonly used for
photorealistic rendering. This paper explains an implementation of a
stand-alone rendering system on GPUs which supports the bounding volume
hierarchy and stochastic progressive photon mapping. The key characteristic of
the system is that it uses only GLSL shaders without relying on any platform
dependent feature. The system can thus run on many platforms that support
OpenGL, making photorealistic rendering on GPUs widely accessible. This paper
also sketches practical ideas for stackless traversal and pseudorandom number
generation which both fit well with the limited system configuration.
</summary>
    <author>
      <name>Toshiya Hachisuka</name>
    </author>
    <link href="http://arxiv.org/abs/1505.06022v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.06022v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.07079v2</id>
    <updated>2016-05-13T12:25:30Z</updated>
    <published>2015-05-26T19:03:54Z</published>
    <title>A survey on Information Visualization in light of Vision and Cognitive
  sciences</title>
    <summary>  Information Visualization techniques are built on a context with many factors
related to both vision and cognition, making it difficult to draw a clear
picture of how data visually turns into comprehension. In the intent of
promoting a better picture, here, we survey concepts on vision, cognition, and
Information Visualization organized in a theorization named Visual Expression
Process. Our theorization organizes the basis of visualization techniques with
a reduced level of complexity; still, it is complete enough to foster
discussions related to design and analytical tasks. Our work introduces the
following contributions: (1) a Theoretical compilation of vision, cognition,
and Information Visualization; (2) Discussions supported by vast literature;
and (3) Reflections on visual-cognitive aspects concerning use and design. We
expect our contributions will provide further clarification about how users and
designers think about InfoVis, leveraging the potential of systems and
techniques.
</summary>
    <author>
      <name>Jose Rodrigues-Jr</name>
    </author>
    <author>
      <name>Luciana Zaina</name>
    </author>
    <author>
      <name>Maria Oliveira</name>
    </author>
    <author>
      <name>Bruno Brandoli</name>
    </author>
    <author>
      <name>Agma Traina</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">29 pages, Elsevier Journal preprint</arxiv:comment>
    <link href="http://arxiv.org/abs/1505.07079v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.07079v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.07804v1</id>
    <updated>2015-05-28T19:14:44Z</updated>
    <published>2015-05-28T19:14:44Z</published>
    <title>The Spatial-Perceptual Design Space: a new comprehension for Data
  Visualization</title>
    <summary>  We revisit the design space of visualizations aiming at identifying and
relating its components. In this sense, we establish a model to examine the
process through which visualizations become expressive for users. This model
has leaded us to a taxonomy oriented to the human visual perception, a
conceptualization that provides natural criteria in order to delineate a novel
understanding for the visualization design space. The new organization of
concepts that we introduce is our main contribution: a grammar for the
visualization design based on the review of former works and of classical and
state-of-the-art techniques. Like so, the paper is presented as a survey whose
structure introduces a new conceptualization for the space of techniques
concerning visual analysis.
</summary>
    <author>
      <name>Jose F. Rodrigues Jr</name>
    </author>
    <author>
      <name>Agma J. M. Traina</name>
    </author>
    <author>
      <name>Maria C. F. Oliveira</name>
    </author>
    <author>
      <name>Caetano Traina Jr</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1057/palgrave.ivs.9500161</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1057/palgrave.ivs.9500161" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Information Visualization 6: 4. 261-279 (2007)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1505.07804v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.07804v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.00967v2</id>
    <updated>2016-01-06T11:07:51Z</updated>
    <published>2015-06-02T17:35:47Z</published>
    <title>Geometric elements and classification of quadrics in rational Bézier
  form</title>
    <summary>  In this paper we classify and derive closed formulas for geometric elements
of quadrics in rational B\'ezier triangular form (such as the center, the conic
at infinity, the vertex and the axis of paraboloids and the principal planes),
using just the control vertices and the weights for the quadric patch. The
results are extended also to quadric tensor product patches. Our results rely
on using techniques from projective algebraic geometry to find suitable
bilinear forms for the quadric in a coordinate-free fashion, considering a
pencil of quadrics that are tangent to the given quadric along a conic. Most of
the information about the quadric is encoded in one coefficient, involving the
weights of the patch, which allows us to tell apart oval from ruled quadrics.
This coefficient is also relevant to determine the affine type of the quadric.
Spheres and quadrics of revolution are characterised within this framework.
</summary>
    <author>
      <name>A. Cantón</name>
    </author>
    <author>
      <name>L. Fernández-Jambrina</name>
    </author>
    <author>
      <name>M. E. Rosado María</name>
    </author>
    <author>
      <name>M. J. Vázquez-Gallo</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.cam.2016.01.006</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.cam.2016.01.006" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 12 figures. Minor changes from previous version. To appear
  in Journal of Computational and Applied Mathematics</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Computational and Applied Mathematics 300, 400-419
  (2016)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1506.00967v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.00967v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65D17" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.02079v1</id>
    <updated>2015-06-05T22:35:31Z</updated>
    <published>2015-06-05T22:35:31Z</published>
    <title>Gradient-Domain Fusion for Color Correction in Large EM Image Stacks</title>
    <summary>  We propose a new gradient-domain technique for processing registered EM image
stacks to remove inter-image discontinuities while preserving intra-image
detail. To this end, we process the image stack by first performing anisotropic
smoothing along the slice axis and then solving a Poisson equation within each
slice to re-introduce the detail. The final image stack is continuous across
the slice axis and maintains sharp details within each slice. Adapting existing
out-of-core techniques for solving the linear system, we describe a parallel
algorithm with time complexity that is linear in the size of the data and space
complexity that is sub-linear, allowing us to process datasets as large as five
teravoxels with a 600 MB memory footprint.
</summary>
    <author>
      <name>Michael Kazhdan</name>
    </author>
    <author>
      <name>Kunal Lillaney</name>
    </author>
    <author>
      <name>William Roncal</name>
    </author>
    <author>
      <name>Davi Bock</name>
    </author>
    <author>
      <name>Joshua Vogelstein</name>
    </author>
    <author>
      <name>Randal Burns</name>
    </author>
    <link href="http://arxiv.org/abs/1506.02079v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.02079v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.02400v2</id>
    <updated>2016-01-15T15:09:27Z</updated>
    <published>2015-06-08T08:47:52Z</published>
    <title>Pushing the Limits of 3D Color Printing: Error Diffusion with
  Translucent Materials</title>
    <summary>  Accurate color reproduction is important in many applications of 3D printing,
from design prototypes to 3D color copies or portraits. Although full color is
available via other technologies, multi-jet printers have greater potential for
graphical 3D printing, in terms of reproducing complex appearance properties.
However, to date these printers cannot produce full color, and doing so poses
substantial technical challenges, from the shear amount of data to the
translucency of the available color materials. In this paper, we propose an
error diffusion halftoning approach to achieve full color with multi-jet
printers, which operates on multiple isosurfaces or layers within the object.
We propose a novel traversal algorithm for voxel surfaces, which allows the
transfer of existing error diffusion algorithms from 2D printing. The resulting
prints faithfully reproduce colors, color gradients and fine-scale details.
</summary>
    <author>
      <name>Alan Brunton</name>
    </author>
    <author>
      <name>Can Ates Arikan</name>
    </author>
    <author>
      <name>Philipp Urban</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/2832905</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/2832905" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 14 figures; includes supplemental figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ACM Transactions on Graphics, 35(1), Article 4, December 2015</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1506.02400v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.02400v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.02976v1</id>
    <updated>2015-06-09T16:08:19Z</updated>
    <published>2015-06-09T16:08:19Z</published>
    <title>Reviewing Data Visualization: an Analytical Taxonomical Study</title>
    <summary>  This paper presents an analytical taxonomy that can suitably describe, rather
than simply classify, techniques for data presentation. Unlike previous works,
we do not consider particular aspects of visualization techniques, but their
mechanisms and foundational vision perception. Instead of just adjusting
visualization research to a classification system, our aim is to better
understand its process. For doing so, we depart from elementary concepts to
reach a model that can describe how visualization techniques work and how they
convey meaning.
</summary>
    <author>
      <name>Jose F. Rodrigues Jr.</name>
    </author>
    <author>
      <name>Agma J. M. Traina</name>
    </author>
    <author>
      <name>Maria Cristina F. de Oliveira</name>
    </author>
    <author>
      <name>Caetano Traina Jr</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published in the Proceedings of the Information Visualization
  Conference as Jose Rodrigues, Agma Traina, Maria Oliveira, Caetano Traina,
  Reviewing Data Visualization: an Analytical Taxonomical Study In: 10th
  International Conference on Information Visualization, 2006, 713-720 IEEE
  Press</arxiv:comment>
    <link href="http://arxiv.org/abs/1506.02976v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.02976v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.04480v2</id>
    <updated>2015-10-29T07:27:16Z</updated>
    <published>2015-06-15T05:29:06Z</published>
    <title>A Clustering Based Approach for Realistic and Efficient Data-Driven
  Crowd Simulation</title>
    <summary>  In this paper, we present a data-driven approach to generate realistic
steering behaviors for virtual crowds in crowd simulation. We take advantage of
both rule-based models and data-driven models by applying the interaction
patterns discovered from crowd videos. Unlike existing example-based models in
which current states are matched to states extracted from crowd videos
directly, our approach adopts a hierarchical mechanism to generate the steering
behaviors of agents. First, each agent is classified into one of the
interaction patterns that are automatically discovered from crowd video before
simulation. Then the most matched action is selected from the associated
interaction pattern to generate the steering behaviors of the agent. By doing
so, agents can avoid performing a simple state matching as in the traditional
example-based approaches, and can perform a wider variety of steering behaviors
as well as mimic the cognitive process of pedestrians. Simulation results on
scenarios with different crowd densities and main motion directions demonstrate
that our approach performs better than two state-of-the-art simulation models,
in terms of prediction accuracy. Besides, our approach is efficient enough to
run at interactive rates in real time simulation.
</summary>
    <author>
      <name>Mingbi Zhao</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper has been withdrawn by the author due to a crucial error in
  equation 6</arxiv:comment>
    <link href="http://arxiv.org/abs/1506.04480v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.04480v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.06636v2</id>
    <updated>2015-06-23T12:11:32Z</updated>
    <published>2015-06-22T14:46:58Z</published>
    <title>3D Geometric Analysis of Tubular Objects based on Surface Normal
  Accumulation</title>
    <summary>  This paper proposes a simple and efficient method for the reconstruction and
extraction of geometric parameters from 3D tubular objects. Our method
constructs an image that accumulates surface normal information, then peaks
within this image are located by tracking. Finally, the positions of these are
optimized to lie precisely on the tubular shape centerline. This method is very
versatile, and is able to process various input data types like full or partial
mesh acquired from 3D laser scans, 3D height map or discrete volumetric images.
The proposed algorithm is simple to implement, contains few parameters and can
be computed in linear time with respect to the number of surface faces. Since
the extracted tube centerline is accurate, we are able to decompose the tube
into rectilinear parts and torus-like parts. This is done with a new linear
time 3D torus detection algorithm, which follows the same principle of a
previous work on 2D arc circle recognition. Detailed experiments show the
versatility, accuracy and robustness of our new method.
</summary>
    <author>
      <name>Bertrand Kerautret</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LORIA</arxiv:affiliation>
    </author>
    <author>
      <name>Adrien Krähenbühl</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LORIA</arxiv:affiliation>
    </author>
    <author>
      <name>Isabelle Debled-Rennesson</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LORIA</arxiv:affiliation>
    </author>
    <author>
      <name>Jacques-Olivier Lachaud</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">in 18th International Conference on Image Analysis and Processing,
  Sep 2015, Genova, Italy. 2015</arxiv:comment>
    <link href="http://arxiv.org/abs/1506.06636v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.06636v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.06855v1</id>
    <updated>2015-06-23T04:40:30Z</updated>
    <published>2015-06-23T04:40:30Z</published>
    <title>Modeling and Correspondence of Topologically Complex 3D Shapes</title>
    <summary>  3D shape creation and modeling remains a challenging task especially for
novice users. Many methods in the field of computer graphics have been proposed
to automate the often repetitive and precise operations needed during the
modeling of detailed shapes. This report surveys different approaches of shape
modeling and correspondence especially for shapes exhibiting topological
complexity. We focus on methods designed to help generate or process shapes
with large number of interconnected components often found in man-made shapes.
We first discuss a variety of modeling techniques, that leverage existing
shapes, in easy to use creative modeling systems. We then discuss possible
correspondence strategies for topologically different shapes as it is a
requirement for such systems. Finally, we look at different shape
representations and tools that facilitate the modification of shape topology
and we focus on those particularly useful in free-form 3D modeling.
</summary>
    <author>
      <name>Ibraheem Alhashim</name>
    </author>
    <link href="http://arxiv.org/abs/1506.06855v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.06855v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.08459v1</id>
    <updated>2015-06-28T22:08:10Z</updated>
    <published>2015-06-28T22:08:10Z</published>
    <title>On the Approximation Theory of Linear Variational Subspace Design</title>
    <summary>  Solving large-scale optimization on-the-fly is often a difficult task for
real-time computer graphics applications. To tackle this challenge, model
reduction is a well-adopted technique. Despite its usefulness, model reduction
often requires a handcrafted subspace that spans a domain that hypothetically
embodies desirable solutions. For many applications, obtaining such subspaces
case-by-case either is impossible or requires extensive human labors, hence
does not readily have a scalable solution for growing number of tasks. We
propose linear variational subspace design for large-scale constrained
quadratic programming, which can be computed automatically without any human
interventions. We provide meaningful approximation error bound that
substantiates the quality of calculated subspace, and demonstrate its empirical
success in interactive deformable modeling for triangular and tetrahedral
meshes.
</summary>
    <author>
      <name>Jianbo Ye</name>
    </author>
    <author>
      <name>Zhixin Yan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 10 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1506.08459v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.08459v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.08956v2</id>
    <updated>2015-07-16T23:30:45Z</updated>
    <published>2015-06-30T06:39:19Z</published>
    <title>Lens Factory: Automatic Lens Generation Using Off-the-shelf Components</title>
    <summary>  Custom optics is a necessity for many imaging applications. Unfortunately,
custom lens design is costly (thousands to tens of thousands of dollars), time
consuming (10-12 weeks typical lead time), and requires specialized optics
design expertise. By using only inexpensive, off-the-shelf lens components the
Lens Factory automatic design system greatly reduces cost and time. Design,
ordering of parts, delivery, and assembly can be completed in a few days, at a
cost in the low hundreds of dollars. Lens design constraints, such as focal
length and field of view, are specified in terms familiar to the graphics
community so no optics expertise is necessary. Unlike conventional lens design
systems, which only use continuous optimization methods, Lens Factory adds a
discrete optimization stage. This stage searches the combinatorial space of
possible combinations of lens elements to find novel designs, evolving simple
canonical lens designs into more complex, better designs. Intelligent pruning
rules make the combinatorial search feasible. We have designed and built
several high performance optical systems which demonstrate the practicality of
the system.
</summary>
    <author>
      <name>Libin Sun</name>
    </author>
    <author>
      <name>Brian Guenter</name>
    </author>
    <author>
      <name>Neel Joshi</name>
    </author>
    <author>
      <name>Patrick Therien</name>
    </author>
    <author>
      <name>James Hays</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 18 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1506.08956v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.08956v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.02766v1</id>
    <updated>2015-07-10T02:24:41Z</updated>
    <published>2015-07-10T02:24:41Z</published>
    <title>A Hybrid Graph-drawing Algorithm for Large, Naturally-clustered,
  Disconnected Graphs</title>
    <summary>  In this paper, we present a hybrid graph-drawing algorithm (GDA) for
layouting large, naturally-clustered, disconnected graphs. We called it a
hybrid algorithm because it is an implementation of a series of already known
graph-drawing and graph-theoretic procedures. We remedy in this hybrid the
problematic nature of the current force-based GDA which has the inability to
scale to large, naturally-clustered, and disconnected graphs. These kinds of
graph usually model the complex inter-relationships among entities in social,
biological, natural, and artificial networks. Obviously, the hybrid runs longer
than the current GDAs. By using two extreme cases of graphs as inputs, we
present in this paper the derivation of the time complexity of the hybrid which
we found to be $O(|\V|^3)$.
</summary>
    <author>
      <name>Toni-Jan Keith P. Monserrat</name>
    </author>
    <author>
      <name>Jaderick P. Pabico</name>
    </author>
    <author>
      <name>Eliezer A. Albacea</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 2 figures, originally appeared in H.N. Adorna and J.M.
  Samaniego (eds.) Proceedings of the 5th National Symposium on Mathematical
  Aspects of Computer Science (SMACS 2010), University of the Philippines Los
  Ba\~nos, College, Laguna, 3-4 December 2010, pp. 32-38</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Asia Pacific Journal of Multidisciplinary Research 2(4):119-126</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1507.02766v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.02766v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.02800v1</id>
    <updated>2015-07-10T08:12:22Z</updated>
    <published>2015-07-10T08:12:22Z</published>
    <title>Meshfree C^2-Weighting for Shape Deformation</title>
    <summary>  Handle-driven deformation based on linear blending is widely used in many
applications because of its merits in intuitiveness, efficiency and easiness of
implementation. We provide a meshfree method to compute the smooth weights of
linear blending for shape deformation. The C2-continuity of weighting is
guaranteed by the carefully formulated basis functions, with which the
computation of weights is in a closed-form. Criteria to ensure the quality of
deformation are preserved by the basis functions after decomposing the shape
domain according to the Voronoi diagram of handles. The cost of inserting a new
handle is only the time to evaluate the distances from the new handle to all
sample points in the space of deformation. Moreover, a virtual handle insertion
algorithm has been developed to allow users freely placing handles while
preserving the criteria on weights. Experimental examples for real-time 2D/3D
deformations are shown to demonstrate the effectiveness of this method.
</summary>
    <author>
      <name>Chuhua Xian</name>
    </author>
    <author>
      <name>Shuo Jin</name>
    </author>
    <author>
      <name>Charlie C. L. Wang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 14 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1507.02800v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.02800v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.02860v1</id>
    <updated>2015-07-10T11:41:04Z</updated>
    <published>2015-07-10T11:41:04Z</published>
    <title>A Closed-Form Formulation of HRBF-Based Surface Reconstruction</title>
    <summary>  The Hermite radial basis functions (HRBFs) implicits have been used to
reconstruct surfaces from scattered Hermite data points. In this work, we
propose a closed-form formulation to construct HRBF-based implicits by a
quasi-solution approximating the exact solution. A scheme is developed to
automatically adjust the support sizes of basis functions to hold the error
bound of a quasi-solution. Our method can generate an implicit function from
positions and normals of scattered points without taking any global operation.
Working together with an adaptive sampling algorithm, the HRBF-based implicits
can also reconstruct surfaces from point clouds with non-uniformity and noises.
Robust and efficient reconstruction has been observed in our experimental tests
on real data captured from a variety of scenes.
</summary>
    <author>
      <name>Shengjun Liu</name>
    </author>
    <author>
      <name>Charlie C. L. Wang</name>
    </author>
    <author>
      <name>Guido Brunnett</name>
    </author>
    <author>
      <name>Jun Wang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages with 10 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1507.02860v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.02860v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.03351v1</id>
    <updated>2015-07-13T08:07:19Z</updated>
    <published>2015-07-13T08:07:19Z</published>
    <title>On Smooth 3D Frame Field Design</title>
    <summary>  We analyze actual methods that generate smooth frame fields both in 2D and in
3D. We formalize the 2D problem by representing frames as functions (as it was
done in 3D), and show that the derived optimization problem is the one that
previous work obtain via "representation vectors." We show (in 2D) why this non
linear optimization problem is easier to solve than directly minimizing the
rotation angle of the field, and observe that the 2D algorithm is able to find
good fields.
  Now, the 2D and the 3D optimization problems are derived from the same
formulation (based on representing frames by functions). Their energies share
some similarities from an optimization point of view (smoothness, local minima,
bounds of partial derivatives, etc.), so we applied the 2D resolution mechanism
to the 3D problem. Our evaluation of all existing 3D methods suggests to
initialize the field by this new algorithm, but possibly use another method for
further smoothing.
</summary>
    <author>
      <name>Nicolas Ray</name>
    </author>
    <author>
      <name>Dmitry Sokolov</name>
    </author>
    <link href="http://arxiv.org/abs/1507.03351v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.03351v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.04110v4</id>
    <updated>2015-11-23T10:30:39Z</updated>
    <published>2015-07-15T07:57:26Z</published>
    <title>A de Casteljau Algorithm for Bernstein type Polynomials based on
  (p,q)-integers</title>
    <summary>  In this paper, a de Casteljau algorithm to compute (p,q)-Bernstein Bezier
curves based on (p,q)-integers is introduced. We study the nature of degree
elevation and degree reduction for (p,q)-Bezier Bernstein functions. The new
curves have some properties similar to q-Bezier curves. Moreover, we construct
the corresponding tensor product surfaces over the rectangular domain (u, v)
\in [0, 1] \times [0, 1] depending on four parameters. We also study the de
Casteljau algorithm and degree evaluation properties of the surfaces for these
generalization over the rectangular domain. Furthermore, some fundamental
properties for (p,q)-Bernstein Bezier curves are discussed. We get q-Bezier
curves and surfaces for (u, v) \in [0, 1] \times [0, 1] when we set the
parameter p1 = p2 = 1.
</summary>
    <author>
      <name>Khalid Khan</name>
    </author>
    <author>
      <name>D. K. Lobiyal</name>
    </author>
    <author>
      <name>Adem Kilicman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 7 figures, basis function revised. arXiv admin note:
  substantial text overlap with arXiv:1505.01810</arxiv:comment>
    <link href="http://arxiv.org/abs/1507.04110v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.04110v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65D17, 41A10, 41A25, 41A36" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.04571v3</id>
    <updated>2015-11-10T08:36:25Z</updated>
    <published>2015-07-16T13:45:36Z</published>
    <title>GPU-based visualization of domain-coloured algebraic Riemann surfaces</title>
    <summary>  We examine an algorithm for the visualization of domain-coloured Riemann
surfaces of plane algebraic curves. The approach faithfully reproduces the
topology and the holomorphic structure of the Riemann surface. We discuss how
the algorithm can be implemented efficiently in OpenGL with geometry shaders,
and (less efficiently) even in WebGL with multiple render targets and floating
point textures. While the generation of the surface takes noticeable time in
both implementations, the visualization of a cached Riemann surface mesh is
possible with interactive performance. This allows us to visually explore
otherwise almost unimaginable mathematical objects. As examples, we look at the
complex square root and the folium of Descartes. For the folium of Descartes,
the visualization reveals features of the algebraic curve which are not obvious
from its equation.
</summary>
    <author>
      <name>Stefan Kranich</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">revised version; 21 pages, 12 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1507.04571v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.04571v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.AG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.02826v1</id>
    <updated>2015-08-12T07:02:19Z</updated>
    <published>2015-08-12T07:02:19Z</published>
    <title>Inappropriate use of L-BFGS, Illustrated on frame field design</title>
    <summary>  L-BFGS is a hill climbing method that is guarantied to converge only for
convex problems. In computer graphics, it is often used as a black box solver
for a more general class of non linear problems, including problems having many
local minima. Some works obtain very nice results by solving such difficult
problems with L-BFGS. Surprisingly, the method is able to escape local minima:
our interpretation is that the approximation of the Hessian is smoother than
the real Hessian, making it possible to evade the local minima. We analyse the
behavior of L-BFGS on the design of 2D frame fields. It involves an energy
function that is infinitly continuous, strongly non linear and having many
local minima. Moreover, the local minima have a clear visual interpretation:
they corresponds to differents frame field topologies. We observe that the
performances of LBFGS are almost unpredictables: they are very competitive when
the field is sampled on the primal graph, but really poor when they are sampled
on the dual graph.
</summary>
    <author>
      <name>Nicolas Ray</name>
    </author>
    <author>
      <name>Dmitry Sokolov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1508.02826v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.02826v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.03590v2</id>
    <updated>2015-12-07T09:12:02Z</updated>
    <published>2015-05-04T12:17:09Z</published>
    <title>Light-field Microscopy with a Consumer Light-field Camera</title>
    <summary>  We explore the use of inexpensive consumer light- field camera technology for
the purpose of light-field mi- croscopy. Our experiments are based on the Lytro
(first gen- eration) camera. Unfortunately, the optical systems of the Lytro
and those of microscopes are not compatible, lead- ing to a loss of light-field
information due to angular and spatial vignetting when directly recording
microscopic pic- tures. We therefore consider an adaptation of the Lytro op-
tical system. We demonstrate that using the Lytro directly as an oc- ular
replacement, leads to unacceptable spatial vignetting. However, we also found a
setting that allows the use of the Lytro camera in a virtual imaging mode which
prevents the information loss to a large extent. We analyze the new vir- tual
imaging mode and use it in two different setups for im- plementing light-field
microscopy using a Lytro camera. As a practical result, we show that the camera
can be used for low magnification work, as e.g. common in quality control,
surface characterization, etc. We achieve a maximum spa- tial resolution of
about 6.25{\mu}m, albeit at a limited SNR for the side views.
</summary>
    <author>
      <name>Lois Mignard-Debise</name>
    </author>
    <author>
      <name>Ivo Ihrke</name>
    </author>
    <link href="http://arxiv.org/abs/1508.03590v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.03590v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.06181v1</id>
    <updated>2015-08-25T15:01:47Z</updated>
    <published>2015-08-25T15:01:47Z</published>
    <title>PolyDepth: Real-time Penetration Depth Computation using Iterative
  Contact-Space Projection</title>
    <summary>  We present a real-time algorithm that finds the Penetration Depth (PD)
between general polygonal models based on iterative and local optimization
techniques. Given an in-collision configuration of an object in configuration
space, we find an initial collision-free configuration using several methods
such as centroid difference, maximally clear configuration, motion coherence,
random configuration, and sampling-based search. We project this configuration
on to a local contact space using a variant of continuous collision detection
algorithm and construct a linear convex cone around the projected
configuration. We then formulate a new projection of the in-collision
configuration onto the convex cone as a Linear Complementarity Problem (LCP),
which we solve using a type of Gauss-Seidel iterative algorithm. We repeat this
procedure until a locally optimal PD is obtained. Our algorithm can process
complicated models consisting of tens of thousands triangles at interactive
rates.
</summary>
    <author>
      <name>Changsoo Je</name>
    </author>
    <author>
      <name>Min Tang</name>
    </author>
    <author>
      <name>Youngeun Lee</name>
    </author>
    <author>
      <name>Minkyoung Lee</name>
    </author>
    <author>
      <name>Young J. Kim</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/2077341.2077346</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/2077341.2077346" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented in ACM SIGGRAPH 2012. 15 pages, 23 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ACM Transactions on Graphics (ToG 2012), Volume 31, Issue 1,
  Article 5, pp. 1-14, January 1, 2012</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1508.06181v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.06181v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.9; I.3.5; I.3.7; I.6.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1509.01220v1</id>
    <updated>2015-08-23T00:37:47Z</updated>
    <published>2015-08-23T00:37:47Z</published>
    <title>Light Efficient Flutter Shutter</title>
    <summary>  Flutter shutter is a technique in which the exposure is chopped into segments
and light is only integrated part of the time. By carefully selecting the
chopping sequence it is possible to better condition the data for
reconstruction problems such as motion deblurring, focal sweeping, and
compressed sensing. The partial exposure trades better conditioning for less
energy. In problems such as motion deblurring the available energy is what
caused the problem in the first place (as strong illumination allows short
exposure thus eliminates motion blur). It is still beneficial because the
benefit from the better conditioning outweighs the cost in energy.
  This documents is focused on light efficient flutter shutter that provides
better conditioning and better energy utilization than conventional flutter
shutter.
</summary>
    <author>
      <name>Moshe Ben-Ezra</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This documnet and the code listing in it are submitted under the
  permissive MIT License in hope it will be useful. In case anyone is
  interesting in 2012 date confirmation - the documnet was notarized at MIT on
  5 Dec 2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1509.01220v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1509.01220v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1509.03335v1</id>
    <updated>2015-09-10T20:58:36Z</updated>
    <published>2015-09-10T20:58:36Z</published>
    <title>Decomposing Digital Paintings into Layers via RGB-space Geometry</title>
    <summary>  In digital painting software, layers organize paintings. However, layers are
not explicitly represented, transmitted, or published with the final digital
painting. We propose a technique to decompose a digital painting into layers.
In our decomposition, each layer represents a coat of paint of a single paint
color applied with varying opacity throughout the image. Our decomposition is
based on the painting's RGB-space geometry. In RGB-space, a geometric structure
is revealed due to the linear nature of the standard Porter-Duff "over" pixel
compositing operation. The vertices of the convex hull of pixels in RGB-space
suggest paint colors. Users choose the degree of simplification to perform on
the convex hull, as well as a layer order for the colors. We solve a
constrained optimization problem to find maximally translucent, spatially
coherent opacity for each layer, such that the composition of the layers
reproduces the original image. We demonstrate the utility of the resulting
decompositions for re-editing.
</summary>
    <author>
      <name>Jianchao Tan</name>
    </author>
    <author>
      <name>Jyh-Ming Lien</name>
    </author>
    <author>
      <name>Yotam Gingold</name>
    </author>
    <link href="http://arxiv.org/abs/1509.03335v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1509.03335v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65D18" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.7; I.4.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1509.03700v1</id>
    <updated>2015-09-12T03:35:20Z</updated>
    <published>2015-09-12T03:35:20Z</published>
    <title>Good Colour Maps: How to Design Them</title>
    <summary>  Many colour maps provided by vendors have highly uneven perceptual contrast
over their range. It is not uncommon for colour maps to have perceptual flat
spots that can hide a feature as large as one tenth of the total data range.
Colour maps may also have perceptual discontinuities that induce the appearance
of false features. Previous work in the design of perceptually uniform colour
maps has mostly failed to recognise that CIELAB space is only designed to be
perceptually uniform at very low spatial frequencies. The most important factor
in designing a colour map is to ensure that the magnitude of the incremental
change in perceptual lightness of the colours is uniform. The specific
requirements for linear, diverging, rainbow and cyclic colour maps are
developed in detail. To support this work two test images for evaluating colour
maps are presented. The use of colour maps in combination with relief shading
is considered and the conditions under which colour can enhance or disrupt
relief shading are identified. Finally, a set of new basis colours for the
construction of ternary images are presented. Unlike the RGB primaries these
basis colours produce images whereby the salience of structures are consistent
irrespective of the assignment of basis colours to data channels.
</summary>
    <author>
      <name>Peter Kovesi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">42 pages, 25 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1509.03700v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1509.03700v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1509.05301v1</id>
    <updated>2015-09-17T15:47:25Z</updated>
    <published>2015-09-17T15:47:25Z</published>
    <title>Humans Are Easily Fooled by Digital Images</title>
    <summary>  Digital images are ubiquitous in our modern lives, with uses ranging from
social media to news, and even scientific papers. For this reason, it is
crucial evaluate how accurate people are when performing the task of identify
doctored images. In this paper, we performed an extensive user study evaluating
subjects capacity to detect fake images. After observing an image, users have
been asked if it had been altered or not. If the user answered the image has
been altered, he had to provide evidence in the form of a click on the image.
We collected 17,208 individual answers from 383 users, using 177 images
selected from public forensic databases. Different from other previously
studies, our method propose different ways to avoid lucky guess when evaluating
users answers. Our results indicate that people show inaccurate skills at
differentiating between altered and non-altered images, with an accuracy of
58%, and only identifying the modified images 46.5% of the time. We also track
user features such as age, answering time, confidence, providing deep analysis
of how such variables influence on the users' performance.
</summary>
    <author>
      <name>Victor Schetinger</name>
    </author>
    <author>
      <name>Manuel M. Oliveira</name>
    </author>
    <author>
      <name>Roberto da Silva</name>
    </author>
    <author>
      <name>Tiago J. Carvalho</name>
    </author>
    <link href="http://arxiv.org/abs/1509.05301v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1509.05301v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1509.05330v1</id>
    <updated>2015-09-15T09:32:17Z</updated>
    <published>2015-09-15T09:32:17Z</published>
    <title>Elements of Validation of Artificial Lighting through the Software
  CODYRUN: Application to a Test Case of the International Commission on
  Illumination (CIE)</title>
    <summary>  CODYRUN is a software for computational aeraulic and thermal simulation in
buildings developed by the Laboratory of Building Physics and Systems
(L.P.B.S). Numerical simulation codes of artificial lighting have been
introduced to extend the tool capacity. These calculation codes are able to
predict the amount of light received by any point of a given working plane and
from one or more sources installed on the ceiling of the room. The model used
for these calculations is original and semi-detailed (simplified). The test
case references of the task-3 TC-33 International Commission on Illumination
(CIE) were applied to the software to ensure reliability to properly handle
this photometric aspect. This allowed having a precise idea about the
reliability of the results of numerical simulations.
</summary>
    <author>
      <name>Ali Hamada Fakra</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PIMENT</arxiv:affiliation>
    </author>
    <author>
      <name>Frédéric Miranville</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PIMENT</arxiv:affiliation>
    </author>
    <author>
      <name>Dimitri Bigot</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PIMENT</arxiv:affiliation>
    </author>
    <author>
      <name>Harry Boyer</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PIMENT</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">IASTED Power and Energy Systems 2010, Sep 2010, Gaborone, Botswana.
  2010</arxiv:comment>
    <link href="http://arxiv.org/abs/1509.05330v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1509.05330v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1509.08834v1</id>
    <updated>2015-09-29T16:31:57Z</updated>
    <published>2015-09-29T16:31:57Z</published>
    <title>Visualization techniques for the developing chicken heart</title>
    <summary>  We present a geometric surface parameterization algorithm and several
visualization techniques adapted to the problem of understanding the 4D
peristaltic-like motion of the outflow tract (OFT) in an embryonic chick heart.
We illustrated the techniques using data from hearts under normal conditions
(four embryos), and hearts in which blood flow conditions are altered through
OFT banding (four embryos). The overall goal is to create quantitative measures
of the temporal heart-shape change both within a single subject and between
multiple subjects. These measures will help elucidate how altering hemodynamic
conditions changes the shape and motion of the OFT walls, which in turn
influence the stresses and strains on the developing heart, causing it to
develop differently. We take advantage of the tubular shape and periodic motion
of the OFT to produce successively lower dimensional visualizations of the
cardiac motion (e.g. curvature, volume, and cross-section) over time, and
quantifications of such visualizations.
</summary>
    <author>
      <name>Ly Phan</name>
    </author>
    <author>
      <name>Sandra Rugonyi</name>
    </author>
    <author>
      <name>Cindy Grimm</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Longer version of conference paper published in 11th International
  Symposium on Visual Computing (December 2015)</arxiv:comment>
    <link href="http://arxiv.org/abs/1509.08834v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1509.08834v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.TO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.5, J.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.01113v2</id>
    <updated>2015-10-06T12:54:01Z</updated>
    <published>2015-10-05T11:58:12Z</published>
    <title>RAID: A Relation-Augmented Image Descriptor</title>
    <summary>  As humans, we regularly interpret images based on the relations between image
regions. For example, a person riding object X, or a plank bridging two
objects. Current methods provide limited support to search for images based on
such relations. We present RAID, a relation-augmented image descriptor that
supports queries based on inter-region relations. The key idea of our
descriptor is to capture the spatial distribution of simple point-to-region
relationships to describe more complex relationships between two image regions.
We evaluate the proposed descriptor by querying into a large subset of the
Microsoft COCO database and successfully extract nontrivial images
demonstrating complex inter-region relations, which are easily missed or
erroneously classified by existing methods.
</summary>
    <author>
      <name>Paul Guerrero</name>
    </author>
    <author>
      <name>Niloy J. Mitra</name>
    </author>
    <author>
      <name>Peter Wonka</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Fixed affiliation and email address of first author</arxiv:comment>
    <link href="http://arxiv.org/abs/1510.01113v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.01113v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.4.8; I.4.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.03935v1</id>
    <updated>2015-10-14T00:24:22Z</updated>
    <published>2015-10-14T00:24:22Z</published>
    <title>Curvature-Metric-Free Surface Remeshing via Principle Component Analysis</title>
    <summary>  In this paper, we present a surface remeshing method with high approximation
quality based on Principal Component Analysis. Given a triangular mesh and a
user assigned polygon/vertex budget, traditional methods usually require the
extra curvature metric field for the desired anisotropy to best approximate the
surface, even though the estimated curvature metric is known to be imperfect
and already self-contained in the surface. In our approach, this anisotropic
control is achieved through the optimal geometry partition without this
explicit metric field. The minimization of our proposed partition energy has
the following properties: Firstly, on a C2 surface, it is theoretically
guaranteed to have the optimal aspect ratio and cluster size as specified in
approximation theory for L1 piecewise linear approximation. Secondly, it
captures sharp features on practical models without any pre-tagging. We develop
an effective merging-swapping framework to seek the optimal partition and
construct polygonal/triangular mesh afterwards. The effectiveness and
efficiency of our method are demonstrated through the comparison with other
state-of-the-art remeshing methods.
</summary>
    <author>
      <name>Yiqi Cai</name>
    </author>
    <author>
      <name>Xiaohu Guo</name>
    </author>
    <author>
      <name>Yang Liu</name>
    </author>
    <author>
      <name>Wenping Wang</name>
    </author>
    <author>
      <name>Weihua Mao</name>
    </author>
    <author>
      <name>Zichun Zhong</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 20 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1510.03935v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.03935v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.04224v2</id>
    <updated>2015-11-17T08:14:34Z</updated>
    <published>2015-11-13T10:19:41Z</published>
    <title>Procedural wood textures</title>
    <summary>  Existing bidirectional reflectance distribution function (BRDF) models are
capable of capturing the distinctive highlights produced by the fibrous nature
of wood. However, capturing parameter textures for even a single specimen
remains a laborious process requiring specialized equipment. In this paper we
take a procedural approach to generating parameters for the wood BSDF. We
characterize the elements of trees that are important for the appearance of
wood, discuss techniques appropriate for representing those features, and
present a complete procedural wood shader capable of reproducing the growth
patterns responsible for the distinctive appearance of highly prized
``figured'' wood. Our procedural wood shader is random-access, 3D, modular, and
is fast enough to generate a preview for design.
</summary>
    <author>
      <name>Albert J. Liu</name>
    </author>
    <author>
      <name>Stephen R. Marschner</name>
    </author>
    <author>
      <name>Victoria E. Dye</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This version: Increased resolution of images and added YouTube link
  to video</arxiv:comment>
    <link href="http://arxiv.org/abs/1511.04224v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.04224v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.06594v1</id>
    <updated>2015-11-20T13:52:39Z</updated>
    <published>2015-11-20T13:52:39Z</published>
    <title>Bezier curves and surfaces based on modified Bernstein polynomials</title>
    <summary>  In this paper, we use the blending functions of Bernstein polynomials with
shifted knots for construction of Bezier curves and surfaces. We study the
nature of degree elevation and degree reduction for Bezier Bernstein functions
with shifted knots.
  Parametric curves are represented using these modified Bernstein basis and
the concept of total positivity is applied to investigate the shape properties
of the curve. We get Bezier curve defined on [0, 1] when we set the parameter
\alpha=\beta to the value 0. We also present a de Casteljau algorithm to
compute Bernstein Bezier curves and surfaces with shifted knots. The new curves
have some properties similar to Bezier curves. Furthermore, some fundamental
properties for Bernstein Bezier curves and surfaces are discussed.
</summary>
    <author>
      <name>Khalid Khan</name>
    </author>
    <author>
      <name>D. K. Lobiyal</name>
    </author>
    <author>
      <name>Adem Kilicman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 2 figures. arXiv admin note: substantial text overlap with
  arXiv:1507.04110</arxiv:comment>
    <link href="http://arxiv.org/abs/1511.06594v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.06594v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65D17, 41A10, 41A25, 41A36" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1512.03012v1</id>
    <updated>2015-12-09T19:42:48Z</updated>
    <published>2015-12-09T19:42:48Z</published>
    <title>ShapeNet: An Information-Rich 3D Model Repository</title>
    <summary>  We present ShapeNet: a richly-annotated, large-scale repository of shapes
represented by 3D CAD models of objects. ShapeNet contains 3D models from a
multitude of semantic categories and organizes them under the WordNet taxonomy.
It is a collection of datasets providing many semantic annotations for each 3D
model such as consistent rigid alignments, parts and bilateral symmetry planes,
physical sizes, keywords, as well as other planned annotations. Annotations are
made available through a public web-based interface to enable data
visualization of object attributes, promote data-driven geometric analysis, and
provide a large-scale quantitative benchmark for research in computer graphics
and vision. At the time of this technical report, ShapeNet has indexed more
than 3,000,000 models, 220,000 models out of which are classified into 3,135
categories (WordNet synsets). In this report we describe the ShapeNet effort as
a whole, provide details for all currently available datasets, and summarize
future plans.
</summary>
    <author>
      <name>Angel X. Chang</name>
    </author>
    <author>
      <name>Thomas Funkhouser</name>
    </author>
    <author>
      <name>Leonidas Guibas</name>
    </author>
    <author>
      <name>Pat Hanrahan</name>
    </author>
    <author>
      <name>Qixing Huang</name>
    </author>
    <author>
      <name>Zimo Li</name>
    </author>
    <author>
      <name>Silvio Savarese</name>
    </author>
    <author>
      <name>Manolis Savva</name>
    </author>
    <author>
      <name>Shuran Song</name>
    </author>
    <author>
      <name>Hao Su</name>
    </author>
    <author>
      <name>Jianxiong Xiao</name>
    </author>
    <author>
      <name>Li Yi</name>
    </author>
    <author>
      <name>Fisher Yu</name>
    </author>
    <link href="http://arxiv.org/abs/1512.03012v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1512.03012v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1512.08826v1</id>
    <updated>2015-12-30T02:26:46Z</updated>
    <published>2015-12-30T02:26:46Z</published>
    <title>Improving Style Similarity Metrics of 3D Shapes</title>
    <summary>  The idea of style similarity metrics has been recently developed for various
media types such as 2D clip art and 3D shapes. We explore this style metric
problem and improve existing style similarity metrics of 3D shapes in four
novel ways. First, we consider the color and texture of 3D shapes which are
important properties that have not been previously considered. Second, we
explore the effect of clustering a dataset of 3D models by comparing between
style metrics for a single object type and style metrics that combine clusters
of object types. Third, we explore the idea of user-guided learning for this
problem. Fourth, we introduce an iterative approach that can learn a metric
from a general set of 3D models. We demonstrate these contributions with
various classes of 3D shapes and with applications such as style-based
similarity search and scene composition.
</summary>
    <author>
      <name>Kapil Dev</name>
    </author>
    <author>
      <name>Manfred Lau</name>
    </author>
    <link href="http://arxiv.org/abs/1512.08826v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1512.08826v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.03224v1</id>
    <updated>2016-01-13T13:11:42Z</updated>
    <published>2016-01-13T13:11:42Z</published>
    <title>Implicit equations of non-degenerate rational Bezier quadric triangles</title>
    <summary>  In this paper we review the derivation of implicit equations for
non-degenerate quadric patches in rational Bezier triangular form. These are
the case of Steiner surfaces of degree two. We derive the bilinear forms for
such quadrics in a coordinate-free fashion in terms of their control net and
their list of weights in a suitable form. Our construction relies on projective
geometry and is grounded on the pencil of quadrics circumscribed to a
tetrahedron formed by vertices of the control net and an additional point which
is required for the Steiner surface to be a non-degenerate quadric.
</summary>
    <author>
      <name>A. Canton</name>
    </author>
    <author>
      <name>L. Fernandez-Jambrina</name>
    </author>
    <author>
      <name>E. Rosado Maria</name>
    </author>
    <author>
      <name>M. J. Vazquez-Gallo</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-319-22804-4_6</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-319-22804-4_6" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 8th International Conference Curves and Surfaces, Paris,
  France, June 12-18, 2014</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Lecture Notes in Computer Science 9213, 70-79 (2015)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1601.03224v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.03224v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65D17" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.04450v1</id>
    <updated>2016-01-18T10:11:26Z</updated>
    <published>2016-01-18T10:11:26Z</published>
    <title>Which tone-mapping operator is the best? A comparative study of
  perceptual quality</title>
    <summary>  Tone-mapping operators (TMO) are designed to generate perceptually similar
low-dynamic range images from high-dynamic range ones. We studied the
performance of fifteen TMOs in two psychophysical experiments where observers
compared the digitally generated tone-mapped images to their corresponding
physical scenes. All experiments were performed in a controlled environment and
the setups were designed to emphasise different image properties: in the first
experiment we evaluated the local relationships among intensity-levels, and in
the second one we evaluated global visual appearance among physical scenes and
tone-mapped images, which were presented side by side. We ranked the TMOs
according to how well they reproduce the results obtained in the physical
scene. Our results show that ranking position clearly depends on the adopted
evaluation criteria, which implies that, in general, these tone-mapping
algorithms consider either local or global image attributes but rarely both. We
conclude that a more thorough and standardized evaluation criteria are needed
to study all the characteristics of TMOs, as there is ample room for
improvement in future developments.
</summary>
    <author>
      <name>Xim Cerdá-Company</name>
    </author>
    <author>
      <name>C. Alejandro Párraga</name>
    </author>
    <author>
      <name>Xavier Otazu</name>
    </author>
    <link href="http://arxiv.org/abs/1601.04450v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.04450v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68U10" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.3; I.4.0; H.1.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.05824v1</id>
    <updated>2016-01-21T21:46:22Z</updated>
    <published>2016-01-21T21:46:22Z</published>
    <title>3D digital reassembling of archaeological ceramic pottery fragments
  based on their thickness profile</title>
    <summary>  The reassembly of a broken archaeological ceramic pottery is an open and
complex problem, which remains a scientific process of extreme interest for the
archaeological community. Usually, the solutions suggested by various research
groups and universities depend on various aspects such as the matching process
of the broken surfaces, the outline of sherds or their colors and geometric
characteris-tics, their axis of symmetry, the corners of their contour, the
theme portrayed on the surface, the concentric circular rills that are left
during the base construction in the inner pottery side by the fingers of the
potter artist etc. In this work the reassembly process is based on a different
and more secure idea, since it is based on the thick-ness profile, which is
appropriately identified in every fragment. Specifically, our approach is based
on information encapsulated in the inner part of the sherd (i.e. thickness),
which is not -or at least not heavily- affected by the presence of harsh
environmental conditions, but is safely kept within the sherd itself. Our
method is verified in various use case experiments, using cutting edge
technologies such as 3D representations and precise measurements on surfaces
from the acquired 3D models.
</summary>
    <author>
      <name>Michail I. Stamatopoulos</name>
    </author>
    <author>
      <name>Christos-Nikolaos Anagnostopoulos</name>
    </author>
    <link href="http://arxiv.org/abs/1601.05824v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.05824v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1602.01644v1</id>
    <updated>2016-02-04T11:33:22Z</updated>
    <published>2016-02-04T11:33:22Z</published>
    <title>A semi-automatic computer-aided method for surgical template design</title>
    <summary>  This paper presents a generalized integrated framework of semi-automatic
surgical template design. Several algorithms were implemented including the
mesh segmentation, offset surface generation, collision detection, ruled
surface generation, etc., and a special software named TemDesigner was
developed. With a simple user interface, a customized template can be semi-
automatically designed according to the preoperative plan. Firstly, mesh
segmentation with signed scalar of vertex is utilized to partition the inner
surface from the input surface mesh based on the indicated point loop. Then,
the offset surface of the inner surface is obtained through contouring the
distance field of the inner surface, and segmented to generate the outer
surface. Ruled surface is employed to connect inner and outer surfaces.
Finally, drilling tubes are generated according to the preoperative plan
through collision detection and merging. It has been applied to the template
design for various kinds of surgeries, including oral implantology, cervical
pedicle screw insertion, iliosacral screw insertion and osteotomy,
demonstrating the efficiency, functionality and generality of our method.
</summary>
    <author>
      <name>Xiaojun Chen</name>
    </author>
    <author>
      <name>Lu Xu</name>
    </author>
    <author>
      <name>Yue Yang</name>
    </author>
    <author>
      <name>Jan Egger</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1038/srep20280</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1038/srep20280" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, 16 figures, 2 tables, 36 references</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Scientific Reports 6, Article number: 20280, 2016</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1602.01644v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1602.01644v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1602.02139v2</id>
    <updated>2016-08-05T12:27:51Z</updated>
    <published>2016-02-03T23:43:26Z</published>
    <title>A simple method for estimating the fractal dimension from digital
  images: The compression dimension</title>
    <summary>  The fractal structure of real world objects is often analyzed using digital
images. In this context, the compression fractal dimension is put forward. It
provides a simple method for the direct estimation of the dimension of fractals
stored as digital image files. The computational scheme can be implemented
using readily available free software. Its simplicity also makes it very
interesting for introductory elaborations of basic concepts of fractal
geometry, complexity, and information theory. A test of the computational
scheme using limited-quality images of well-defined fractal sets obtained from
the Internet and free software has been performed. Also, a systematic
evaluation of the proposed method using computer generated images of the
Weierstrass cosine function shows an accuracy comparable to those of the
methods most commonly used to estimate the dimension of fractal data sequences
applied to the same test problem.
</summary>
    <author>
      <name>P. Chamorro-Posada</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.chaos.2016.08.002</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.chaos.2016.08.002" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Chaos Solitons Fract 91 (2016) 562-572</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1602.02139v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1602.02139v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1602.03206v2</id>
    <updated>2016-03-31T19:22:26Z</updated>
    <published>2016-02-06T17:35:21Z</published>
    <title>Design of false color palettes for grayscale reproduction</title>
    <summary>  Design of false color palette is quite easy but some effort has to be done to
achieve good dynamic range, contrast and overall appearance of the palette.
Such palettes, for instance, are commonly used in scientific papers for
presenting the data. However, to lower the cost of the paper most scientists
decide to let the data to be printed in grayscale. The same applies to e-book
readers based on e-ink where most of them are still grayscale. For majority of
false color palettes reproducing them in grayscale results in ambiguous mapping
of the colors and may be misleading for the reader. In this article design of
false color palettes suitable for grayscale reproduction is described. Due to
the monotonic change of luminance of these palettes grayscale representation is
very similar to the data directly presented with a grayscale palette. Some
suggestions and examples how to design such palettes are provided.
</summary>
    <author>
      <name>Filip A. Sala</name>
    </author>
    <link href="http://arxiv.org/abs/1602.03206v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1602.03206v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1602.06645v1</id>
    <updated>2016-02-22T04:45:43Z</updated>
    <published>2016-02-22T04:45:43Z</published>
    <title>Creating Simplified 3D Models with High Quality Textures</title>
    <summary>  This paper presents an extension to the KinectFusion algorithm which allows
creating simplified 3D models with high quality RGB textures. This is achieved
through (i) creating model textures using images from an HD RGB camera that is
calibrated with Kinect depth camera, (ii) using a modified scheme to update
model textures in an asymmetrical colour volume that contains a higher number
of voxels than that of the geometry volume, (iii) simplifying dense polygon
mesh model using quadric-based mesh decimation algorithm, and (iv) creating and
mapping 2D textures to every polygon in the output 3D model. The proposed
method is implemented in real-time by means of GPU parallel processing.
Visualization via ray casting of both geometry and colour volumes provides
users with a real-time feedback of the currently scanned 3D model. Experimental
results show that the proposed method is capable of keeping the model texture
quality even for a heavily decimated model and that, when reconstructing small
objects, photorealistic RGB textures can still be reconstructed.
</summary>
    <author>
      <name>Song Liu</name>
    </author>
    <author>
      <name>Wanqing Li</name>
    </author>
    <author>
      <name>Philip Ogunbona</name>
    </author>
    <author>
      <name>Yang-Wai Chow</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/DICTA.2015.7371249</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/DICTA.2015.7371249" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2015 International Conference on Digital Image Computing: Techniques
  and Applications (DICTA), Page 1 - 8</arxiv:comment>
    <link href="http://arxiv.org/abs/1602.06645v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1602.06645v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1602.07038v2</id>
    <updated>2016-07-06T23:24:19Z</updated>
    <published>2016-02-23T04:47:28Z</published>
    <title>Computer Aided Restoration of Handwritten Character Strokes</title>
    <summary>  This work suggests a new variational approach to the task of computer aided
restoration of incomplete characters, residing in a highly noisy document. We
model character strokes as the movement of a pen with a varying radius.
Following this model, a cubic spline representation is being utilized to
perform gradient descent steps, while maintaining interpolation at some initial
(manually sampled) points. The proposed algorithm was utilized in the process
of restoring approximately 1000 ancient Hebrew characters (dating to ca.
8th-7th century BCE), some of which are presented herein and show that the
algorithm yields plausible results when applied on deteriorated documents.
</summary>
    <author>
      <name>Barak Sober</name>
    </author>
    <author>
      <name>David Levin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 17 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1602.07038v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1602.07038v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68U07, 68U10, 65D18, 94A08" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.7.5; I.5.4; I.4.5; J.6; I.3.3; I.3.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.04060v1</id>
    <updated>2016-03-13T18:38:15Z</updated>
    <published>2016-03-13T18:38:15Z</published>
    <title>Modelling Developable Ribbons Using Ruling Bending Coordinates</title>
    <summary>  This paper presents a new method for modelling the dynamic behaviour of
developable ribbons, two dimensional strips with much smaller width than
length. Instead of approximating such surface with a general triangle mesh, we
characterize it by a set of creases and bending angles across them. This
representation allows the developability to be satisfied everywhere while still
leaves enough degree of freedom to represent salient global deformation. We
show how the potential and kinetic energies can be properly discretized in this
configuration space and time integrated in a fully implicit manner. The result
is a dynamic simulator with several desirable features: We can model
non-trivial deformation using much fewer elements than conventional FEM method.
It is stable under extreme deformation, external force or large timestep size.
And we can readily handle various user constraints in Euclidean space.
</summary>
    <author>
      <name>Zherong Pan</name>
    </author>
    <author>
      <name>Jin Huang</name>
    </author>
    <author>
      <name>Hujun Bao</name>
    </author>
    <link href="http://arxiv.org/abs/1603.04060v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.04060v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.05433v2</id>
    <updated>2016-03-18T09:34:34Z</updated>
    <published>2016-03-17T11:30:01Z</published>
    <title>Degree reduction of composite Bézier curves</title>
    <summary>  This paper deals with the problem of multi-degree reduction of a composite
B\'ezier curve with the parametric continuity constraints at the endpoints of
the segments. We present a novel method which is based on the idea of using
constrained dual Bernstein polynomials to compute the control points of the
reduced composite curve. In contrast to other methods, ours minimizes the
$L_2$-error for the whole composite curve instead of minimizing the
$L_2$-errors for each segment separately. As a result, an additional
optimization is possible. Examples show that the new method gives much better
results than multiple application of the degree reduction of a single B\'ezier
curve.
</summary>
    <author>
      <name>Przemysław Gospodarczyk</name>
    </author>
    <author>
      <name>Stanisław Lewanowicz</name>
    </author>
    <author>
      <name>Paweł Woźny</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.amc.2016.08.004</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.amc.2016.08.004" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Applied Mathematics and Computation 293, p. 40-48 (2017)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1603.05433v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.05433v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.06078v2</id>
    <updated>2016-08-03T11:11:55Z</updated>
    <published>2016-03-19T10:29:57Z</published>
    <title>Deep Shading: Convolutional Neural Networks for Screen-Space Shading</title>
    <summary>  In computer vision, convolutional neural networks (CNNs) have recently
achieved new levels of performance for several inverse problems where RGB pixel
appearance is mapped to attributes such as positions, normals or reflectance.
In computer graphics, screen-space shading has recently increased the visual
quality in interactive image synthesis, where per-pixel attributes such as
positions, normals or reflectance of a virtual 3D scene are converted into RGB
pixel appearance, enabling effects like ambient occlusion, indirect light,
scattering, depth-of-field, motion blur, or anti-aliasing. In this paper we
consider the diagonal problem: synthesizing appearance from given per-pixel
attributes using a CNN. The resulting Deep Shading simulates various
screen-space effects at competitive quality and speed while not being
programmed by human experts but learned from example images.
</summary>
    <author>
      <name>Oliver Nalbach</name>
    </author>
    <author>
      <name>Elena Arabadzhiyska</name>
    </author>
    <author>
      <name>Dushyant Mehta</name>
    </author>
    <author>
      <name>Hans-Peter Seidel</name>
    </author>
    <author>
      <name>Tobias Ritschel</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1111/cgf.13225</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1111/cgf.13225" rel="related"/>
    <link href="http://arxiv.org/abs/1603.06078v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.06078v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.7; I.2.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.06143v2</id>
    <updated>2016-10-13T20:10:09Z</updated>
    <published>2016-03-19T20:58:47Z</published>
    <title>Neurally-Guided Procedural Models: Amortized Inference for Procedural
  Graphics Programs using Neural Networks</title>
    <summary>  Probabilistic inference algorithms such as Sequential Monte Carlo (SMC)
provide powerful tools for constraining procedural models in computer graphics,
but they require many samples to produce desirable results. In this paper, we
show how to create procedural models which learn how to satisfy constraints. We
augment procedural models with neural networks which control how the model
makes random choices based on the output it has generated thus far. We call
such models neurally-guided procedural models. As a pre-computation, we train
these models to maximize the likelihood of example outputs generated via SMC.
They are then used as efficient SMC importance samplers, generating
high-quality results with very few samples. We evaluate our method on
L-system-like models with image-based constraints. Given a desired quality
threshold, neurally-guided models can generate satisfactory results up to 10x
faster than unguided models.
</summary>
    <author>
      <name>Daniel Ritchie</name>
    </author>
    <author>
      <name>Anna Thomas</name>
    </author>
    <author>
      <name>Pat Hanrahan</name>
    </author>
    <author>
      <name>Noah D. Goodman</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Neural Information Processing Systems (NIPS 2016)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1603.06143v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.06143v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.07011v1</id>
    <updated>2016-03-22T22:14:01Z</updated>
    <published>2016-03-22T22:14:01Z</published>
    <title>Graphs Drawing through Fuzzy Clustering</title>
    <summary>  Many problems can be presented in an abstract form through a wide range of
binary objects and relations which are defined over problem domain. In these
problems, graphical demonstration of defined binary objects and solutions is
the most suitable representation approach. In this regard, graph drawing
problem discusses the methods for transforming combinatorial graphs to
geometrical drawings in order to visualize them. This paper studies the
force-directed algorithms and multi-surface techniques for drawing general
undirected graphs. Particularly, this research describes force-directed
approach to model the drawing of a general graph as a numerical optimization
problem. So, it can use rich knowledge which is presented as an established
system by the numerical optimization. Moreover, this research proposes the
multi-surface approach as an efficient tool for overcoming local minimums in
standard force-directed algorithms. Next, we introduce a new method for
multi-surface approach based on fuzzy clustering algorithms.
</summary>
    <author>
      <name>Mohammadreza Ashouri</name>
    </author>
    <author>
      <name>Ali Golshani</name>
    </author>
    <author>
      <name>Dara Moazzmi</name>
    </author>
    <author>
      <name>Mandana Ghasemi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">26 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1603.07011v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.07011v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.08753v1</id>
    <updated>2016-03-29T13:02:50Z</updated>
    <published>2016-03-29T13:02:50Z</published>
    <title>Curve Networks for Surface Reconstruction</title>
    <summary>  Man-made objects usually exhibit descriptive curved features (i.e., curve
networks). The curve network of an object conveys its high-level geometric and
topological structure. We present a framework for extracting feature curve
networks from unstructured point cloud data. Our framework first generates a
set of initial curved segments fitting highly curved regions. We then optimize
these curved segments to respect both data fitting and structural regularities.
Finally, the optimized curved segments are extended and connected into curve
networks using a clustering method. To facilitate effectiveness in case of
severe missing data and to resolve ambiguities, we develop a user interface for
completing the curve networks. Experiments on various imperfect point cloud
data validate the effectiveness of our curve network extraction framework. We
demonstrate the usefulness of the extracted curve networks for surface
reconstruction from incomplete point clouds.
</summary>
    <author>
      <name>Yuanhao Cao</name>
    </author>
    <author>
      <name>Liangliang Nan</name>
    </author>
    <author>
      <name>Peter Wonka</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1603.08753v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.08753v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.08984v2</id>
    <updated>2017-04-10T11:09:34Z</updated>
    <published>2016-03-29T22:18:29Z</published>
    <title>SMASH: Physics-guided Reconstruction of Collisions from Videos</title>
    <summary>  Collision sequences are commonly used in games and entertainment to add drama
and excitement. Authoring even two body collisions in the real world can be
difficult, as one has to get timing and the object trajectories to be correctly
synchronized. After tedious trial-and-error iterations, when objects can
actually be made to collide, then they are difficult to capture in 3D. In
contrast, synthetically generating plausible collisions is difficult as it
requires adjusting different collision parameters (e.g., object mass ratio,
coefficient of restitution, etc.) and appropriate initial parameters. We
present SMASH to directly read off appropriate collision parameters directly
from raw input video recordings. Technically we enable this by utilizing laws
of rigid body collision to regularize the problem of lifting 2D trajectories to
a physically valid 3D reconstruction of the collision. The reconstructed
sequences can then be modified and combined to easily author novel and
plausible collisions. We evaluate our system on a range of synthetic scenes and
demonstrate the effectiveness of our method by accurately reconstructing
several complex real world collision events.
</summary>
    <author>
      <name>Aron Monszpart</name>
    </author>
    <author>
      <name>Nils Thuerey</name>
    </author>
    <author>
      <name>Niloy J. Mitra</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/2980179.2982421</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/2980179.2982421" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">SIGGRAPH Asia 2016</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ACM Trans. Graph. 35, 6, Article 199 (November 2016), 14 pages
  (2016)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1603.08984v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.08984v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.00047v1</id>
    <updated>2016-03-31T20:40:14Z</updated>
    <published>2016-03-31T20:40:14Z</published>
    <title>Towards Zero-Waste Furniture Design</title>
    <summary>  In traditional design, shapes are first conceived, and then fabricated. While
this decoupling simplifies the design process, it can result in inefficient
material usage, especially where off-cut pieces are hard to reuse. The
designer, in absence of explicit feedback on material usage remains helpless to
effectively adapt the design -- even though design variabilities exist. In this
paper, we investigate {\em waste minimizing furniture design} wherein based on
the current design, the user is presented with design variations that result in
more effective usage of materials. Technically, we dynamically analyze material
space layout to determine {\em which} parts to change and {\em how}, while
maintaining original design intent specified in the form of design constraints.
We evaluate the approach on simple and complex furniture design scenarios, and
demonstrate effective material usage that is difficult, if not impossible, to
achieve without computational support.
</summary>
    <author>
      <name>Bongjin Koo</name>
    </author>
    <author>
      <name>Jean Hergel</name>
    </author>
    <author>
      <name>Sylvain Lefebvre</name>
    </author>
    <author>
      <name>Niloy J. Mitra</name>
    </author>
    <link href="http://arxiv.org/abs/1604.00047v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.00047v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.03220v1</id>
    <updated>2016-04-09T16:47:06Z</updated>
    <published>2016-04-09T16:47:06Z</published>
    <title>Algorithms and identities for $(p,q)$-B$\acute{e}$zier curves via
  $(p,q)$-Blossom</title>
    <summary>  In this paper, a new variant of the blossom, the $(p,q)$-blossom, is
introduced, by altering the diagonal property of the standard blossom. This
$(p,q)$-blossom has been adapted for developing identities and algorithms for
$(p,q)$-Bernstein bases and $(p,q)$-B$\acute{e}$zier curves. We generate
several new identities including an explicit formula representing the monomials
in terms of the $(p,q)$-Bernstein basis functions and a $(p,q)$-variant of
Marsden's identity by applying the $(p,q)$-blossom. We also derive for each
$(p,q)$-B$\acute{e}$zier curve of degree $n,$ a collection of $n!$ new, affine
invariant, recursive evaluation algorithms. Using two of these new recursive
evaluation algorithms, we construct a recursive subdivision algorithm for
$(p,q)$-B$\acute{e}$zier curves.
</summary>
    <author>
      <name>Khalid Khan</name>
    </author>
    <author>
      <name>D. K. Lobiyal</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1604.03220v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.03220v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.07378v1</id>
    <updated>2016-04-25T19:42:37Z</updated>
    <published>2016-04-25T19:42:37Z</published>
    <title>Towards Real-time Simulation of Hyperelastic Materials</title>
    <summary>  We present a new method for real-time physics-based simulation supporting
many different types of hyperelastic materials. Previous methods such as
Position Based or Projective Dynamics are fast, but support only limited
selection of materials; even classical materials such as the Neo-Hookean
elasticity are not supported. Recently, Xu et al. [2015] introduced new
"spline-based materials" which can be easily controlled by artists to achieve
desired animation effects. Simulation of these types of materials currently
relies on Newton's method, which is slow, even with only one iteration per
timestep. In this paper, we show that Projective Dynamics can be interpreted as
a quasi-Newton method. This insight enables very efficient simulation of a
large class of hyperelastic materials, including the Neo-Hookean, spline-based
materials, and others. The quasi-Newton interpretation also allows us to
leverage ideas from numerical optimization. In particular, we show that our
solver can be further accelerated using L-BFGS updates (Limited-memory
Broyden-Fletcher-Goldfarb-Shanno algorithm). Our final method is typically more
than 10 times faster than one iteration of Newton's method without compromising
quality. In fact, our result is often more accurate than the result obtained
with one iteration of Newton's method. Our method is also easier to implement,
implying reduced software development costs.
</summary>
    <author>
      <name>Tiantian Liu</name>
    </author>
    <author>
      <name>Sofien Bouaziz</name>
    </author>
    <author>
      <name>Ladislav Kavan</name>
    </author>
    <link href="http://arxiv.org/abs/1604.07378v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.07378v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.01760v1</id>
    <updated>2016-05-05T21:25:54Z</updated>
    <published>2016-05-05T21:25:54Z</published>
    <title>Adaptive Mesh Booleans</title>
    <summary>  We present a new method for performing Boolean operations on volumes
represented as triangle meshes. In contrast to existing methods which treat
meshes as 3D polyhedra and try to partition the faces at their exact
intersection curves, we treat meshes as adaptive surfaces which can be
arbitrarily refined. Rather than depending on computing precise face
intersections, our approach refines the input meshes in the intersection
regions, then discards intersecting triangles and fills the resulting holes
with high-quality triangles. The original intersection curves are approximated
to a user-definable precision, and our method can identify and preserve creases
and sharp features. Advantages of our approach include the ability to trade
speed for accuracy, support for open meshes, and the ability to incorporate
tolerances to handle cases where large numbers of faces are slightly
inter-penetrating or near-coincident.
</summary>
    <author>
      <name>Ryan Schmidt</name>
    </author>
    <author>
      <name>Tyson Brochu</name>
    </author>
    <link href="http://arxiv.org/abs/1605.01760v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.01760v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68U05, 68U07" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.01816v3</id>
    <updated>2016-05-24T05:44:40Z</updated>
    <published>2016-05-06T04:17:12Z</published>
    <title>Sufficient Conditions for Tuza's Conjecture on Packing and Covering
  Triangles</title>
    <summary>  Given a simple graph $G=(V,E)$, a subset of $E$ is called a triangle cover if
it intersects each triangle of $G$. Let $\nu_t(G)$ and $\tau_t(G)$ denote the
maximum number of pairwise edge-disjoint triangles in $G$ and the minimum
cardinality of a triangle cover of $G$, respectively. Tuza conjectured in 1981
that $\tau_t(G)/\nu_t(G)\le2$ holds for every graph $G$. In this paper, using a
hypergraph approach, we design polynomial-time combinatorial algorithms for
finding small triangle covers. These algorithms imply new sufficient conditions
for Tuza's conjecture on covering and packing triangles. More precisely,
suppose that the set $\mathscr T_G$ of triangles covers all edges in $G$. We
show that a triangle cover of $G$ with cardinality at most $2\nu_t(G)$ can be
found in polynomial time if one of the following conditions is satisfied: (i)
$\nu_t(G)/|\mathscr T_G|\ge\frac13$, (ii) $\nu_t(G)/|E|\ge\frac14$, (iii)
$|E|/|\mathscr T_G|\ge2$.
  Keywords: Triangle cover, Triangle packing, Linear 3-uniform hypergraphs,
Combinatorial algorithms
</summary>
    <author>
      <name>Xujin Chen</name>
    </author>
    <author>
      <name>Zhuo Diao</name>
    </author>
    <author>
      <name>Xiaodong Hu</name>
    </author>
    <author>
      <name>Zhongzheng Tang</name>
    </author>
    <link href="http://arxiv.org/abs/1605.01816v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.01816v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.04797v2</id>
    <updated>2016-07-02T03:15:10Z</updated>
    <published>2016-05-16T15:09:19Z</published>
    <title>Thingi10K: A Dataset of 10,000 3D-Printing Models</title>
    <summary>  Empirically validating new 3D-printing related algorithms and implementations
requires testing data representative of inputs encountered \emph{in the wild}.
An ideal benchmarking dataset should not only draw from the same distribution
of shapes people print in terms of class (e.g., toys, mechanisms, jewelry),
representation type (e.g., triangle soup meshes) and complexity (e.g., number
of facets), but should also capture problems and artifacts endemic to 3D
printing models (e.g., self-intersections, non-manifoldness). We observe that
the contextual and geometric characteristics of 3D printing models differ
significantly from those used for computer graphics applications, not to
mention standard models (e.g., Stanford bunny, Armadillo, Fertility). We
present a new dataset of 10,000 models collected from an online 3D printing
model-sharing database. Via analysis of both geometric (e.g., triangle aspect
ratios, manifoldness) and contextual (e.g., licenses, tags, classes)
characteristics, we demonstrate that this dataset represents a more concise
summary of real-world models used for 3D printing compared to existing
datasets. To facilitate future research endeavors, we also present an online
query interface to select subsets of the dataset according to project-specific
characteristics. The complete dataset and per-model statistical data are freely
available to the public.
</summary>
    <author>
      <name>Qingnan Zhou</name>
    </author>
    <author>
      <name>Alec Jacobson</name>
    </author>
    <link href="http://arxiv.org/abs/1605.04797v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.04797v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.06215v1</id>
    <updated>2016-05-20T05:42:12Z</updated>
    <published>2016-05-20T05:42:12Z</published>
    <title>TRIM: Triangulating Images for Efficient Registration</title>
    <summary>  With the advancement in the digital camera technology, the use of high
resolution images and videos has been widespread in the modern society. In
particular, image and video frame registration is frequently applied in
computer graphics and film production. However, the conventional registration
approaches usually require long computational time for high quality images and
video frames. This hinders the applications of the registration approaches in
the modern industries. In this work, we propose a novel approach called {\em
TRIM} to accelerate the computations of the registration by triangulating the
images. More specifically, given a high resolution image or video frame, we
compute an optimal coarse triangulation which captures the important features
of the image. Then, the computation of the registration can be simplified with
the aid of the coarse triangulation. Experimental results suggest that the
computational time of the registration is significantly reduced using our
triangulation-based approach, meanwhile the accuracy of the registration is
well retained when compared with the conventional grid-based approach.
</summary>
    <author>
      <name>Chun Pang Yung</name>
    </author>
    <author>
      <name>Gary Pui-Tung Choi</name>
    </author>
    <author>
      <name>Ke Chen</name>
    </author>
    <author>
      <name>Lok Ming Lui</name>
    </author>
    <link href="http://arxiv.org/abs/1605.06215v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.06215v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.07829v2</id>
    <updated>2016-06-21T11:53:20Z</updated>
    <published>2016-05-25T11:16:00Z</published>
    <title>As-exact-as-possible repair of unprintable STL files</title>
    <summary>  The class of models that can be represented by STL files is larger than the
class of models that can be printed using additive manufacturing technologies.
In this paper such a gap is formalized while providing an unambiguous
description of all the mathematical entities involved in the modeling-printing
pipeline. Possible defects of an STL file are formally defined and classified,
and a fully automatic procedure is described to turn "any" such file into a
printable model. The procedure is as exact as possible, meaning that no visible
distortion is introduced unless it is strictly imposed by limitations of the
printing device. Thanks to such an unprecedented flexibility and accuracy, this
algorithm is expected to significantly simplify the modeling-printing process,
in particular within the continuously emerging non-professional "maker"
communities.
</summary>
    <author>
      <name>Marco Attene</name>
    </author>
    <link href="http://arxiv.org/abs/1605.07829v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.07829v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.07104v2</id>
    <updated>2016-09-08T19:21:46Z</updated>
    <published>2016-06-22T20:59:12Z</published>
    <title>Manifolds' Projective Approximation Using The Moving Least-Squares
  (MMLS)</title>
    <summary>  In order to avoid the curse of dimensionality, frequently encountered in Big
Data analysis, there was a vast development in the field of linear and
non-linear dimension reduction techniques in recent years. These techniques
(sometimes referred to as manifold learning) assume that the scattered input
data is lying on a lower dimensional manifold, thus the high dimensionality
problem can be overcome by learning the lower dimensionality behavior. However,
in real life applications, data is often very noisy. In this work, we propose a
method to approximate a $d$-dimensional $C^{m+1}$ smooth submanifold
$\mathcal{M}$ residing in $\mathbb{R}^n$ ($d &lt;&lt; n$) based upon scattered data
points (i.e., a data cloud). We assume that the data points are located "near"
the noisy lower dimensional manifold and perform a non-linear moving
least-squares projection on an approximating manifold. Under some mild
assumptions, the resulting approximant is shown to be infinitely smooth and of
high approximation order (i.e., $O(h^{m+1})$, where $h$ is the fill distance
and $m$ is the degree of the local polynomial approximation). Furthermore, the
method presented here assumes no analytic knowledge of the approximated
manifold and the approximation algorithm is linear in the large dimension $n$.
</summary>
    <author>
      <name>Barak Sober</name>
    </author>
    <author>
      <name>David Levin</name>
    </author>
    <link href="http://arxiv.org/abs/1606.07104v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.07104v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.09540v1</id>
    <updated>2016-06-30T15:37:53Z</updated>
    <published>2016-06-30T15:37:53Z</published>
    <title>SurfCuit: Surface Mounted Circuits on 3D Prints</title>
    <summary>  We present, SurfCuit, a novel approach to design and construction of electric
circuits on the surface of 3D prints. Our surface mounting technique allows
durable construction of circuits on the surface of 3D prints. SurfCuit does not
require tedious circuit casing design or expensive set-ups, thus we can
expedite the process of circuit construction for 3D models. Our technique
allows the user to construct complex circuits for consumer-level desktop fused
decomposition modeling (FDM) 3D printers. The key idea behind our technique is
that FDM plastic forms a strong bond with metal when it is melted. This
observation enables construction of a robust circuit traces using copper tape
and soldering. We also present an interactive tool to design such circuits on
arbitrary 3D geometry. We demonstrate the effectiveness of our approach through
various actual construction examples.
</summary>
    <author>
      <name>Nobuyuki Umetani</name>
    </author>
    <author>
      <name>Ryan Schmidt</name>
    </author>
    <link href="http://arxiv.org/abs/1606.09540v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.09540v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.01102v1</id>
    <updated>2016-07-05T03:22:40Z</updated>
    <published>2016-07-05T03:22:40Z</published>
    <title>A Visualization Method of Four Dimensional Polytopes by Oval Display of
  Parallel Hyperplane Slices</title>
    <summary>  A method to visualize polytopes in a four dimensional euclidian space
$(x,y,z,w)$ is proposed. A polytope is sliced by multiple hyperplanes that are
parallel each other and separated by uniform intervals. Since the hyperplanes
are perpendicular to the $w$ axis, the resulting multiple slices appear in the
three-dimensional $(x,y,z)$ space and they are shown by the standard computer
graphics. The polytope is rotated extrinsically in the four dimensional space
by means of a simple input method based on keyboard typings. The multiple
slices are placed on a parabola curve in the three-dimensional world
coordinates. The slices in a view window form an oval appearance. Both the
simple and the double rotations in the four dimensional space are applied to
the polytope. All slices synchronously change their shapes when a rotation is
applied to the polytope. The compact display in the oval of many slices with
the help of quick rotations facilitate a grasp of the four dimensional
configuration of the polytope.
</summary>
    <author>
      <name>Akira Kageyama</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1607.01102v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.01102v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.05812v1</id>
    <updated>2016-07-20T04:00:44Z</updated>
    <published>2016-07-20T04:00:44Z</published>
    <title>HoloMed: A Low-Cost Gesture-Based Holographic</title>
    <summary>  During medicine studies, visualization of certain elements is common and
indispensable in order to get more information about the way they work.
Currently, we resort to the use of photographs -which are insufficient due to
being static- or tests in patients, which can be invasive or even risky.
Therefore, a low-cost approach is proposed by using a 3D visualization. This
paper presents a holographic system built with low-cost materials for teaching
obstetrics, where student interaction is performed by using voice and gestures.
Our solution, which we called HoloMed, is focused on the projection of a
euthocic normal delivery under a web-based infrastructure which also employs a
Kinect. HoloMed is divided in three (3) essential modules: a gesture analyzer,
a data server, and a holographic projection architecture, which can be executed
in several interconnected computers using different network protocols. Tests
used for determining the user's position, illumination factors, and response
times, demonstrate HoloMed's effectiveness as a low-cost system for teaching,
using a natural user interface and 3D images.
</summary>
    <author>
      <name>Juan Perozo</name>
    </author>
    <author>
      <name>Mimia Lo Leung</name>
    </author>
    <author>
      <name>Esmitt Ramírez</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">English version of an accepted paper in the Proceedings of the 4th
  Simposio Cient\'ifico y Tecnol\'ogico en Computaci\'on, 160-168. May 2016.
  Original version in spanish
  http://ccg.ciens.ucv.ve/~esmitt/publications/2016/SCTC2016.pdf</arxiv:comment>
    <link href="http://arxiv.org/abs/1607.05812v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.05812v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.00936v4</id>
    <updated>2016-09-01T14:51:28Z</updated>
    <published>2016-08-02T19:02:40Z</published>
    <title>Multimodal Brain Visualization</title>
    <summary>  Current connectivity diagrams of human brain image data are either overly
complex or overly simplistic. In this work we introduce simple yet accurate
interactive visual representations of multiple brain image structures and the
connectivity among them. We map cortical surfaces extracted from human brain
magnetic resonance imaging (MRI) data onto 2D surfaces that preserve shape
(angle), extent (area), and spatial (neighborhood) information for 2D (circular
disk) and 3D (spherical) mapping, split these surfaces into separate patches,
and cluster functional and diffusion tractography MRI connections between pairs
of these patches. The resulting visualizations are easier to compute on and
more visually intuitive to interact with than the original data, and facilitate
simultaneous exploration of multiple data sets, modalities, and statistical
maps.
</summary>
    <author>
      <name>Saad Nadeem</name>
    </author>
    <author>
      <name>Arie Kaufman</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1117/12.2217003</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1117/12.2217003" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">SPIE Medical Imaging 2016, Proc. SPIE Medical Imaging: Biomedical
  Applications in Molecular, Structural, and Functional Imaging, 2016</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">SPIE Medical Imaging, pp. 97881Y-97881Y. 2016</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1608.00936v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.00936v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.01102v1</id>
    <updated>2016-08-03T08:04:24Z</updated>
    <published>2016-08-03T08:04:24Z</published>
    <title>Efficient Optimal Control of Smoke using Spacetime Multigrid</title>
    <summary>  We present a novel algorithm to control the physically-based animation of
smoke. Given a set of keyframe smoke shapes, we compute a dense sequence of
control force fields that can drive the smoke shape to match several keyframes
at certain time instances. Our approach formulates this control problem as a
PDE constrained spacetime optimization and computes locally optimal control
forces as the stationary point of the Karush-Kuhn-Tucker conditions. In order
to reduce the high complexity of multiple passes of fluid resimulation, we
utilize the coherence between consecutive fluid simulation passes and update
our solution using a novel spacetime full approximation scheme (STFAS). We
demonstrate the benefits of our approach by computing accurate solutions on 2D
and 3D benchmarks. In practice, we observe more than an order of magnitude
improvement over prior methods.
</summary>
    <author>
      <name>Zherong Pan</name>
    </author>
    <author>
      <name>Dinesh Manocha</name>
    </author>
    <link href="http://arxiv.org/abs/1608.01102v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.01102v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.04082v1</id>
    <updated>2016-08-14T09:55:34Z</updated>
    <published>2016-08-14T09:55:34Z</published>
    <title>A weighted binary average of point-normal pairs with application to
  subdivision schemes</title>
    <summary>  Subdivision is a well-known and established method for generating smooth
curves and surfaces from discrete data by repeated refinements. The typical
input for such a process is a mesh of vertices. In this work we propose to
refine 2D data consisting of vertices of a polygon and a normal at each vertex.
Our core refinement procedure is based on a circle average, which is a new
non-linear weighted average of two points and their corresponding normals. The
ability to locally approximate curves by the circle average is demonstrated.
With this ability, the circle average is a candidate for modifying linear
subdivision schemes refining points, to schemes refining point-normal pairs.
This is done by replacing the weighted binary arithmetic means in a linear
subdivision scheme, expressed in terms of repeated binary averages, by circle
averages with the same weights. Here we investigate the modified
Lane-Riesenfeld algorithm and the 4-point scheme. For the case that the initial
data consists of a control polygon only, a naive method for choosing initial
normals is proposed. An example demonstrates the superiority of the above two
modified schemes, with the naive choice of initial normals over the
corresponding linear schemes, when applied to a control polygon with edges of
significantly different lengths.
</summary>
    <author>
      <name>Evgeny Lipovetsky</name>
    </author>
    <author>
      <name>Nira Dyn</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.cagd.2016.07.004</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.cagd.2016.07.004" rel="related"/>
    <link href="http://arxiv.org/abs/1608.04082v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.04082v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.04366v2</id>
    <updated>2016-11-19T16:24:27Z</updated>
    <published>2016-08-15T19:02:30Z</published>
    <title>Infill Optimization for Additive Manufacturing -- Approaching Bone-like
  Porous Structures</title>
    <summary>  Porous structures such as trabecular bone are widely seen in nature. These
structures exhibit superior mechanical properties whilst being lightweight. In
this paper, we present a method to generate bone-like porous structures as
lightweight infill for additive manufacturing. Our method builds upon and
extends voxel-wise topology optimization. In particular, for the purpose of
generating sparse yet stable structures distributed in the interior of a given
shape, we propose upper bounds on the localized material volume in the
proximity of each voxel in the design domain. We then aggregate the local
per-voxel constraints by their p-norm into an equivalent global constraint, in
order to facilitate an efficient optimization process. Implemented on a
high-resolution topology optimization framework, our results demonstrate
mechanically optimized, detailed porous structures which mimic those found in
nature. We further show variants of the optimized structures subject to
different design specifications, and analyze the optimality and robustness of
the obtained structures.
</summary>
    <author>
      <name>Jun Wu</name>
    </author>
    <author>
      <name>Niels Aage</name>
    </author>
    <author>
      <name>Ruediger Westermann</name>
    </author>
    <author>
      <name>Ole Sigmund</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">TVCG Revision 1</arxiv:comment>
    <link href="http://arxiv.org/abs/1608.04366v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.04366v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.04721v1</id>
    <updated>2016-08-16T19:38:16Z</updated>
    <published>2016-08-16T19:38:16Z</published>
    <title>Adaptive Position-Based Fluids: Improving Performance of Fluid
  Simulations for Real-Time Applications</title>
    <summary>  The Position Based Fluids (PBF) method is a state-of-the-art approach for
fluid simulations in the context of real-time applications like games. It uses
an iterative solver concept that tries to maintain a constant fluid density
(incompressibility) to realize incompressible fluids like water. However,
larger fluid volumes that consist of several hundred thousand particles (e.g.
for the simulation of oceans) require many iterations and a lot of simulation
power. We present a lightweight and easy-to-integrate extension to PBF that
adaptively adjusts the number of solver iterations on a fine-grained basis.
Using a novel adaptive-simulation approach, we are able to achieve significant
improvements in performance on our evaluation scenarios while maintaining
high-quality results in terms of visualization quality, which makes it a
perfect choice for game developers. Furthermore, our method does not weaken the
advantages of prior work and seamlessly integrates into other position-based
methods for physically-based simulations.
</summary>
    <author>
      <name>Marcel Köster</name>
    </author>
    <author>
      <name>Antonio Krüger</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5121/ijcga.2016.6301</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5121/ijcga.2016.6301" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, International Journal of Computer Graphics &amp; Animation
  Vol.6, No.3, July 2016</arxiv:comment>
    <link href="http://arxiv.org/abs/1608.04721v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.04721v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.5; I.3.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.05231v2</id>
    <updated>2016-08-27T12:07:01Z</updated>
    <published>2016-08-18T10:34:54Z</published>
    <title>Design and Implementation of a Procedural Content Generation Web
  Application for Vertex Shaders</title>
    <summary>  We present a web application for the procedural generation of transformations
of 3D models. We generate the transformations by algorithmically generating the
vertex shaders of the 3D models. The vertex shaders are created with an
interactive genetic algorithm, which displays to the user the visual effect
caused by each vertex shader, allows the user to select the visual effect the
user likes best, and produces a new generation of vertex shaders using the user
feedback as the fitness measure of the genetic algorithm. We use genetic
programming to represent each vertex shader as a computer program. This paper
presents details of requirements specification, software architecture, high and
low-level design, and prototype user interface. We discuss the project's
current status and development challenges.
</summary>
    <author>
      <name>Juan C. Quiroz</name>
    </author>
    <author>
      <name>Sergiu M. Dascalu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">25th International Conference on Software Engineering and Data
  Engineering (SEDE 2016), September 26-28, Denver, CO</arxiv:comment>
    <link href="http://arxiv.org/abs/1608.05231v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.05231v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.05772v1</id>
    <updated>2016-08-20T03:18:57Z</updated>
    <published>2016-08-20T03:18:57Z</published>
    <title>A Data-Driven Approach for Mapping Multivariate Data to Color</title>
    <summary>  A wide variety of color schemes have been devised for mapping scalar data to
color. Some use the data value to index a color scale. Others assign colors to
different, usually blended disjoint materials, to handle areas where materials
overlap. A number of methods can map low-dimensional data to color, however,
these methods do not scale to higher dimensional data. Likewise, schemes that
take a more artistic approach through color mixing and the like also face
limits when it comes to the number of variables they can encode. We address the
challenge of mapping multivariate data to color and avoid these limitations at
the same time. It is a data driven method, which first gauges the similarity of
the attributes and then arranges them according to the periphery of a convex 2D
color space, such as HSL. The color of a multivariate data sample is then
obtained via generalized barycentric coordinate (GBC) interpolation.
</summary>
    <author>
      <name>Shenghui Cheng</name>
    </author>
    <author>
      <name>Wei Xu</name>
    </author>
    <author>
      <name>Wen Zhong</name>
    </author>
    <author>
      <name>Klaus Mueller</name>
    </author>
    <link href="http://arxiv.org/abs/1608.05772v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.05772v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.06368v3</id>
    <updated>2016-09-09T14:10:41Z</updated>
    <published>2016-08-23T03:14:13Z</published>
    <title>Segmenting a Surface Mesh into Pants Using Morse Theory</title>
    <summary>  A pair of pants is a genus zero orientable surface with three boundary
components. A pants decomposition of a surface is a finite collection of
unordered pairwise disjoint simple closed curves embedded in the surface that
decompose the surface into pants. In this paper we present two Morse theory
based algorithms for pants decomposition of a surface mesh. Both algorithms
operates on a choice of an appropriate Morse function on the surface. The first
algorithm uses this Morse function to identify handles that are glued
systematically to obtain a pant decomposition. The second algorithm uses the
Reeb graph of the Morse function to obtain a pant decomposition. Both
algorithms work for surfaces with or without boundaries. Our preliminary
implementation of the two algorithms shows that both algorithms run in much
less time than an existing state-of-the-art method, and the Reeb graph based
algorithm achieves the best time efficiency. Finally, we demonstrate the
robustness of our algorithms against noise.
</summary>
    <author>
      <name>Mustafa Hajij</name>
    </author>
    <author>
      <name>Tamal Dey</name>
    </author>
    <author>
      <name>Xin Li</name>
    </author>
    <link href="http://arxiv.org/abs/1608.06368v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.06368v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.GT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.08570v1</id>
    <updated>2016-08-30T17:31:36Z</updated>
    <published>2016-08-30T17:31:36Z</published>
    <title>Interpolations of Smoke and Liquid Simulations</title>
    <summary>  We present a novel method to interpolate smoke and liquid simulations in
order to perform data-driven fluid simulations. Our approach calculates a dense
space-time deformation using grid-based signed-distance functions of the
inputs. A key advantage of this implicit Eulerian representation is that it
allows us to use powerful techniques from the optical flow area. We employ a
five-dimensional optical flow solve. In combination with a projection
algorithm, and residual iterations, we achieve a robust matching of the inputs.
Once the match is computed, arbitrary in between variants can be created very
efficiently. To concatenate multiple long-range deformations, we propose a
novel alignment technique. Our approach has numerous advantages, including
automatic matches without user input, volumetric deformations that can be
applied to details around the surface, and the inherent handling of topology
changes. As a result, we can interpolate swirling smoke clouds, and splashing
liquid simulations. We can even match and interpolate phenomena with
fundamentally different physics: a drop of liquid, and a blob of heavy smoke.
</summary>
    <author>
      <name>Nils Thuerey</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/2956233</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/2956233" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ACM Transactions on Graphics, 36(1), 2017</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1608.08570v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.08570v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.6.8; I.3.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.02072v1</id>
    <updated>2016-09-07T17:03:19Z</updated>
    <published>2016-09-07T17:03:19Z</published>
    <title>Sampling BSSRDFs with non-perpendicular incidence</title>
    <summary>  Sub-surface scattering is key to our perception of translucent materials.
Models based on diffusion theory are used to render such materials in a
realistic manner by evaluating an approximation of the material BSSRDF at any
two points of the surface. Under the assumption of perpendicular incidence,
this BSSRDF approximation can be tabulated over 2 dimensions to provide fast
evaluation and importance sampling. However, accounting for non-perpendicular
incidence with the same approach would require to tabulate over 4 dimensions,
making the model too large for practical applications. In this report, we
present a method to efficiently evaluate and importance sample the
multi-scattering component of diffusion based BSSRDFs for non-perpendicular
incidence. Our approach is based on tabulating a compressed angular model of
Photon Beam Diffusion. We explain how to generate, evaluate and sample our
model. We show that 1 MiB is enough to store a model of the multi-scattering
BSSRDF that is within $0.5\%$ relative error of Photon Beam Diffusion. Finally,
we present a method to use our model in a Monte Carlo particle tracer and show
results of our implementation in PBRT.
</summary>
    <author>
      <name>Etienne Ferrier</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Supervised by Prof. Wenzel Jakob (EPFL). Contains 9 pages, 13
  figures, 4 tables, 3 algorithms</arxiv:comment>
    <link href="http://arxiv.org/abs/1609.02072v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.02072v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.05328v1</id>
    <updated>2016-09-17T12:54:41Z</updated>
    <published>2016-09-17T12:54:41Z</published>
    <title>Hermite interpolation by piecewise polynomial surfaces with polynomial
  area element</title>
    <summary>  This paper is devoted to the construction of polynomial 2-surfaces which
possess a polynomial area element. In particular we study these surfaces in the
Euclidean space $\mathbb R^3$ (where they are equivalent to the PN surfaces)
and in the Minkowski space $\mathbb R^{3,1}$ (where they provide the MOS
surfaces). We show generally in real vector spaces of any dimension and any
metric that the Gram determinant of a parametric set of subspaces is a perfect
square if and only if the Gram determinant of its orthogonal complement is a
perfect square. Consequently the polynomial surfaces of a given degree with
polynomial area element can be constructed from the prescribed normal fields
solving a system of linear equations. The degree of the constructed surface
depending on the degree and the quality of the prescribed normal field is
investigated and discussed. We use the presented approach to interpolate a
network of points and associated normals with piecewise polynomial surfaces
with polynomial area element and demonstrate our method on a number of examples
(constructions of quadrilateral as well as triangular patches
</summary>
    <author>
      <name>Michal Bizzarri</name>
    </author>
    <author>
      <name>Miroslav Lávička</name>
    </author>
    <author>
      <name>Zbyňek Šír</name>
    </author>
    <author>
      <name>Jan Vršek</name>
    </author>
    <link href="http://arxiv.org/abs/1609.05328v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.05328v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.AG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.07049v1</id>
    <updated>2016-09-22T16:11:57Z</updated>
    <published>2016-09-22T16:11:57Z</published>
    <title>Customized Facial Constant Positive Air Pressure (CPAP) Masks</title>
    <summary>  Sleep apnea is a syndrome that is characterized by sudden breathing halts
while sleeping. One of the common treatments involves wearing a mask that
delivers continuous air flow into the nostrils so as to maintain a steady air
pressure. These masks are designed for an average facial model and are often
difficult to adjust due to poor fit to the actual patient. The incompatibility
is characterized by gaps between the mask and the face, which deteriorates the
impermeability of the mask and leads to air leakage. We suggest a fully
automatic approach for designing a personalized nasal mask interface using a
facial depth scan. The interfaces generated by the proposed method accurately
fit the geometry of the scanned face, and are easy to manufacture. The proposed
method utilizes cheap commodity depth sensors and 3D printing technologies to
efficiently design and manufacture customized masks for patients suffering from
sleep apnea.
</summary>
    <author>
      <name>Matan Sela</name>
    </author>
    <author>
      <name>Nadav Toledo</name>
    </author>
    <author>
      <name>Yaron Honen</name>
    </author>
    <author>
      <name>Ron Kimmel</name>
    </author>
    <link href="http://arxiv.org/abs/1609.07049v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.07049v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.07738v1</id>
    <updated>2016-09-25T13:20:58Z</updated>
    <published>2016-09-25T13:20:58Z</published>
    <title>Fast Blended Transformations for Partial Shape Registration</title>
    <summary>  Automatic estimation of skinning transformations is a popular way to deform a
single reference shape into a new pose by providing a small number of control
parameters. We generalize this approach by efficiently enabling the use of
multiple exemplar shapes. Using a small set of representative natural poses, we
propose to express an unseen appearance by a low-dimensional linear subspace,
specified by a redundant dictionary of weighted vertex positions. Minimizing a
nonlinear functional that regulates the example manifold, the suggested
approach supports local-rigid deformations of articulated objects, as well as
nearly isometric embeddings of smooth shapes. A real-time non-rigid deformation
system is demonstrated, and a shape completion and partial registration
framework is introduced. These applications can recover a target pose and
implicit inverse kinematics from a small number of examples and just a few
vertex positions. The result reconstruction is more accurate compared to
state-of-the-art reduced deformable models.
</summary>
    <author>
      <name>Alon Shtern</name>
    </author>
    <author>
      <name>Matan Sela</name>
    </author>
    <author>
      <name>Ron Kimmel</name>
    </author>
    <link href="http://arxiv.org/abs/1609.07738v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.07738v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.08313v1</id>
    <updated>2016-09-27T08:35:14Z</updated>
    <published>2016-09-27T08:35:14Z</published>
    <title>Unsupervised Co-segmentation of 3D Shapes via Functional Maps</title>
    <summary>  We present an unsupervised method for co-segmentation of a set of 3D shapes
from the same class with the aim of segmenting the input shapes into consistent
semantic parts and establishing their correspondence across the set. Starting
from meaningful pre-segmentation of all given shapes individually, we construct
the correspondence between same candidate parts and obtain the labels via
functional maps. And then, we use these labels to mark the input shapes and
obtain results of co-segmentation. The core of our algorithm is to seek for an
optimal correspondence between semantically similar parts through functional
maps and mark such shape parts. Experimental results on the benchmark datasets
show the efficiency of this method and comparable accuracy to the
state-of-the-art algorithms.
</summary>
    <author>
      <name>Jun Yang</name>
    </author>
    <author>
      <name>Zhenhua Tian</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 8figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1609.08313v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.08313v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="B.7.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.08685v2</id>
    <updated>2016-11-08T20:13:56Z</updated>
    <published>2016-09-27T22:00:56Z</published>
    <title>Understanding and Exploiting Object Interaction Landscapes</title>
    <summary>  Interactions play a key role in understanding objects and scenes, for both
virtual and real world agents. We introduce a new general representation for
proximal interactions among physical objects that is agnostic to the type of
objects or interaction involved. The representation is based on tracking
particles on one of the participating objects and then observing them with
sensors appropriately placed in the interaction volume or on the interaction
surfaces. We show how to factorize these interaction descriptors and project
them into a particular participating object so as to obtain a new functional
descriptor for that object, its interaction landscape, capturing its observed
use in a spatio-temporal framework. Interaction landscapes are independent of
the particular interaction and capture subtle dynamic effects in how objects
move and behave when in functional use. Our method relates objects based on
their function, establishes correspondences between shapes based on functional
key points and regions, and retrieves peer and partner objects with respect to
an interaction.
</summary>
    <author>
      <name>Sören Pirk</name>
    </author>
    <author>
      <name>Vojtech Krs</name>
    </author>
    <author>
      <name>Kaimo Hu</name>
    </author>
    <author>
      <name>Suren Deepak Rajasekaran</name>
    </author>
    <author>
      <name>Hao Kang</name>
    </author>
    <author>
      <name>Bedrich Benes</name>
    </author>
    <author>
      <name>Yusuke Yoshiyasu</name>
    </author>
    <author>
      <name>Leonidas J. Guibas</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 19 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1609.08685v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.08685v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1610.01691v1</id>
    <updated>2016-10-05T23:49:21Z</updated>
    <published>2016-10-05T23:49:21Z</published>
    <title>Towards a Drone Cinematographer: Guiding Quadrotor Cameras using Visual
  Composition Principles</title>
    <summary>  We present a system to capture video footage of human subjects in the real
world. Our system leverages a quadrotor camera to automatically capture
well-composed video of two subjects. Subjects are tracked in a large-scale
outdoor environment using RTK GPS and IMU sensors. Then, given the tracked
state of our subjects, our system automatically computes static shots based on
well-established visual composition principles and canonical shots from
cinematography literature. To transition between these static shots, we
calculate feasible, safe, and visually pleasing transitions using a novel
real-time trajectory planning algorithm. We evaluate the performance of our
tracking system, and experimentally show that RTK GPS significantly outperforms
conventional GPS in capturing a variety of canonical shots. Lastly, we
demonstrate our system guiding a consumer quadrotor camera autonomously
capturing footage of two subjects in a variety of use cases. This is the first
end-to-end system that enables people to leverage the mobility of quadrotors,
as well as the knowledge of expert filmmakers, to autonomously capture
high-quality footage of people in the real world.
</summary>
    <author>
      <name>Niels Joubert</name>
    </author>
    <author>
      <name>Jane L. E</name>
    </author>
    <author>
      <name>Dan B Goldman</name>
    </author>
    <author>
      <name>Floraine Berthouzoz</name>
    </author>
    <author>
      <name>Mike Roberts</name>
    </author>
    <author>
      <name>James A. Landay</name>
    </author>
    <author>
      <name>Pat Hanrahan</name>
    </author>
    <link href="http://arxiv.org/abs/1610.01691v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1610.01691v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1610.07368v2</id>
    <updated>2016-10-31T17:36:37Z</updated>
    <published>2016-10-24T11:34:13Z</published>
    <title>Simplification of Multi-Scale Geometry using Adaptive Curvature Fields</title>
    <summary>  We present a novel algorithm to compute multi-scale curvature fields on
triangle meshes. Our algorithm is based on finding robust mean curvatures using
the ball neighborhood, where the radius of a ball corresponds to the scale of
the features. The essential problem is to find a good radius for each ball to
obtain a reliable curvature estimation. We propose an algorithm that finds
suitable radii in an automatic way. In particular, our algorithm is applicable
to meshes produced by image-based reconstruction systems. These meshes often
contain geometric features at various scales, for example if certain regions
have been captured in greater detail. We also show how such a multi-scale
curvature field can be converted to a density field and used to guide
applications like mesh simplification.
</summary>
    <author>
      <name>Patrick Seemann</name>
    </author>
    <author>
      <name>Simon Fuhrmann</name>
    </author>
    <author>
      <name>Stefan Guthe</name>
    </author>
    <author>
      <name>Fabian Langguth</name>
    </author>
    <author>
      <name>Michael Goesele</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1610.07368v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1610.07368v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65D18" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1610.09992v1</id>
    <updated>2016-10-31T16:08:42Z</updated>
    <published>2016-10-31T16:08:42Z</published>
    <title>Deconfliction and Surface Generation from Bathymetry Data Using LR
  B-splines</title>
    <summary>  A set of bathymetry point clouds acquired by different measurement techniques
at different times, having different accuracy and varying patterns of points,
are approximated by an LR B-spline surface. The aim is to represent the sea
bottom with good accuracy and at the same time reduce the data size
considerably. In this process the point clouds must be cleaned by selecting the
"best" points for surface generation. This cleaning process is called
deconfliction, and we use a rough approximation of the combined point clouds as
a reference surface to select a consistent set of points. The reference surface
is updated with the selected points to create an accurate approximation. LR
B-splines is the selected surface format due to its suitability for adaptive
refinement and approximation, and its ability to represent local detail without
a global increase in the data size of the surface
</summary>
    <author>
      <name>Vibeke Skytt</name>
    </author>
    <author>
      <name>Quillon Harpham</name>
    </author>
    <author>
      <name>Tor Dokken</name>
    </author>
    <author>
      <name>Heidi E. I. Dahl</name>
    </author>
    <link href="http://arxiv.org/abs/1610.09992v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1610.09992v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1611.01765v1</id>
    <updated>2016-11-06T12:26:37Z</updated>
    <published>2016-11-06T12:26:37Z</published>
    <title>A Survey on 3D CAD model quality assurance and testing tools</title>
    <summary>  A new taxonomy of issues related to CAD model quality is presented, which
distinguishes between explicit and procedural models. For each type of model,
morphologic, syntactic, and semantic errors are characterized. The taxonomy was
validated successfully when used to classify quality testing tools, which are
aimed at detecting and repairing data errors that may affect the
simplification, interoperability, and reusability of CAD models. The study
shows that low semantic level errors that hamper simplification are reasonably
covered in explicit representations, although many CAD quality testers are
still unaffordable for Small and Medium Enterprises, both in terms of cost and
training time. Interoperability has been reasonably solved by standards like
STEP AP 203 and AP214, but model reusability is not feasible in explicit
representations. Procedural representations are promising, as interactive
modeling editors automatically prevent most morphologic errors derived from
unsuitable modeling strategies. Interoperability problems between procedural
representations are expected to decrease dramatically with STEP AP242. Higher
semantic aspects of quality such as assurance of design intent, however, are
hardly supported by current CAD quality testers.
</summary>
    <author>
      <name>C. González-Lluch</name>
    </author>
    <author>
      <name>P. Company</name>
    </author>
    <author>
      <name>M. Contero</name>
    </author>
    <author>
      <name>J. D. Camba</name>
    </author>
    <author>
      <name>R. Plumed</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.cad.2016.10.003</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.cad.2016.10.003" rel="related"/>
    <link href="http://arxiv.org/abs/1611.01765v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1611.01765v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1611.01990v2</id>
    <updated>2017-06-25T17:45:00Z</updated>
    <published>2016-11-07T11:11:10Z</published>
    <title>Hamiltonian operator for spectral shape analysis</title>
    <summary>  Many shape analysis methods treat the geometry of an object as a metric space
that can be captured by the Laplace-Beltrami operator. In this paper, we
propose to adapt the classical Hamiltonian operator from quantum mechanics to
the field of shape analysis. To this end we study the addition of a potential
function to the Laplacian as a generator for dual spaces in which shape
processing is performed. We present a general optimization approach for solving
variational problems involving the basis defined by the Hamiltonian using
perturbation theory for its eigenvectors. The suggested operator is shown to
produce better functional spaces to operate with, as demonstrated on different
shape analysis tasks.
</summary>
    <author>
      <name>Yoni Choukroun</name>
    </author>
    <author>
      <name>Alon Shtern</name>
    </author>
    <author>
      <name>Alex Bronstein</name>
    </author>
    <author>
      <name>Ron Kimmel</name>
    </author>
    <link href="http://arxiv.org/abs/1611.01990v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1611.01990v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1611.03079v1</id>
    <updated>2016-11-08T23:22:59Z</updated>
    <published>2016-11-08T23:22:59Z</published>
    <title>Fractal Art Generation using GPUs</title>
    <summary>  Fractal image generation algorithms exhibit extreme parallelizability. Using
general purpose graphics processing unit (GPU) programming to implement
escape-time algorithms for Julia sets of functions,parallel methods generate
visually attractive fractal images much faster than traditional methods. Vastly
improved speeds are achieved using this method of computation, which allow
real-time generation and display of images. A comparison is made between
sequential and parallel implementations of the algorithm. An application
created by the authors demonstrates using the increased speed to create dynamic
imaging of fractals where the user may explore paths of parameter values
corresponding to a given function's Mandelbrot set. Examples are given of
artistic and mathematical insights gained by experiencing fractals
interactively and from the ability to sample the parameter space quickly and
comprehensively.
</summary>
    <author>
      <name>Will. D. Mayfield</name>
    </author>
    <author>
      <name>Justin. C. Eiland</name>
    </author>
    <author>
      <name>Taylor. J. Hutyra</name>
    </author>
    <author>
      <name>Matt. C. Paulsen</name>
    </author>
    <author>
      <name>Bryant. M. Wyatt</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1611.03079v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1611.03079v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1611.03677v2</id>
    <updated>2017-04-07T08:48:44Z</updated>
    <published>2016-11-11T12:20:43Z</published>
    <title>Primal-Dual Optimization for Fluids</title>
    <summary>  We apply a novel optimization scheme from the image processing and machine
learning areas, a fast Primal-Dual method, to achieve controllable and
realistic fluid simulations. While our method is generally applicable to many
problems in fluid simulations, we focus on the two topics of fluid guiding and
separating solid-wall boundary conditions. Each problem is posed as an
optimization problem and solved using our method, which contains acceleration
schemes tailored to each problem. In fluid guiding, we are interested in
partially guiding fluid motion to exert control while preserving fluid
characteristics. With our method, we achieve explicit control over both
large-scale motions and small-scale details which is valuable for many
applications, such as level-of-detail adjustment (after running the coarse
simulation), spatially varying guiding strength, domain modification, and
resimulation with different fluid parameters. For the separating solid-wall
boundary conditions problem, our method effectively eliminates unrealistic
artifacts of fluid crawling up solid walls and sticking to ceilings, requiring
few changes to existing implementations. We demonstrate the fast convergence of
our Primal-Dual method with a variety of test cases for both model problems.
</summary>
    <author>
      <name>Tiffany Inglis</name>
    </author>
    <author>
      <name>Marie-Lena Eckert</name>
    </author>
    <author>
      <name>James Gregson</name>
    </author>
    <author>
      <name>Nils Thuerey</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1111/cgf.13084</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1111/cgf.13084" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 18 figures, supplemental video
  https://www.youtube.com/watch?v=Pgbat5MXo8Q</arxiv:comment>
    <link href="http://arxiv.org/abs/1611.03677v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1611.03677v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.6.8; I.3.7; G.1.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1611.08947v1</id>
    <updated>2016-11-28T01:03:57Z</updated>
    <published>2016-11-28T01:03:57Z</published>
    <title>Navigable videos for presenting scientific data on head-mounted displays</title>
    <summary>  Immersive, stereoscopic viewing enables scientists to better analyze the
spatial structures of visualized physical phenomena. However, their findings
cannot be properly presented in traditional media, which lack these core
attributes. Creating a presentation tool that captures this environment poses
unique challenges, namely related to poor viewing accessibility. Immersive
scientific renderings often require high-end equipment, which can be
impractical to obtain. We address these challenges with our authoring tool and
navigational interface, which is designed for affordable head-mounted displays.
With the authoring tool, scientists can show salient data features as connected
360{\deg} video paths, resulting in a "choose-your-own-adventure" experience.
Our navigational interface features bidirectional video playback for added
viewing control when users traverse the tailor-made content. We evaluate our
system's benefits by authoring case studies on several data sets and conducting
a usability study on the navigational interface's design. In summary, our
approach provides scientists an immersive medium to visually present their
research to the intended audience--spanning from students to colleagues--on
affordable virtual reality headsets.
</summary>
    <author>
      <name>Jacqueline Chu</name>
    </author>
    <author>
      <name>Leonardo Ferrer</name>
    </author>
    <author>
      <name>Min Shih</name>
    </author>
    <author>
      <name>Kwan-Liu Ma</name>
    </author>
    <link href="http://arxiv.org/abs/1611.08947v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1611.08947v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.04336v1</id>
    <updated>2016-12-13T20:03:36Z</updated>
    <published>2016-12-13T20:03:36Z</published>
    <title>A Qualitative and Quantitative Evaluation of 8 Clear Sky Models</title>
    <summary>  We provide a qualitative and quantitative evaluation of 8 clear sky models
used in Computer Graphics. We compare the models with each other as well as
with measurements and with a reference model from the physics community. After
a short summary of the physics of the problem, we present the measurements and
the reference model, and how we "invert" it to get the model parameters. We
then give an overview of each CG model, and detail its scope, its algorithmic
complexity, and its results using the same parameters as in the reference
model. We also compare the models with a perceptual study. Our quantitative
results confirm that the less simplifications and approximations are used to
solve the physical equations, the more accurate are the results. We conclude
with a discussion of the advantages and drawbacks of each model, and how to
further improve their accuracy.
</summary>
    <author>
      <name>Eric Bruneton</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TVCG.2016.2622272</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TVCG.2016.2622272" rel="related"/>
    <link href="http://arxiv.org/abs/1612.04336v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.04336v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.05395v7</id>
    <updated>2017-04-28T06:43:30Z</updated>
    <published>2016-12-16T08:41:06Z</published>
    <title>Charted Metropolis Light Transport</title>
    <summary>  In this manuscript, inspired by a simpler reformulation of primary sample
space Metropolis light transport, we derive a novel family of general Markov
chain Monte Carlo algorithms called charted Metropolis-Hastings, that
introduces the notion of sampling charts to extend a given sampling domain and
making it easier to sample the desired target distribution and escape from
local maxima through coordinate changes. We further apply the novel algorithms
to light transport simulation, obtaining a new type of algorithm called charted
Metropolis light transport, that can be seen as a bridge between primary sample
space and path space Metropolis light transport. The new algorithms require to
provide only right inverses of the sampling functions, a property that we
believe crucial to make them practical in the context of light transport
simulation. We further propose a method to integrate density estimation into
this framework through a novel scheme that uses it as an independence sampler.
</summary>
    <author>
      <name>Jacopo Pantaleoni</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3072959.3073677</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3072959.3073677" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 6 figures - to be published in the SIGGRAPH 2017
  proceedings</arxiv:comment>
    <link href="http://arxiv.org/abs/1612.05395v7" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.05395v7" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.08731v4</id>
    <updated>2017-07-23T08:17:44Z</updated>
    <published>2016-12-20T14:06:20Z</published>
    <title>Quantum Optimal Transport for Tensor Field Processing</title>
    <summary>  This article introduces a new notion of optimal transport (OT) between tensor
fields, which are measures whose values are positive semidefinite (PSD)
matrices. This "quantum" formulation of OT (Q-OT) corresponds to a relaxed
version of the classical Kantorovich transport problem, where the fidelity
between the input PSD-valued measures is captured using the geometry of the
Von-Neumann quantum entropy. We propose a quantum-entropic regularization of
the resulting convex optimization problem, which can be solved efficiently
using an iterative scaling algorithm. This method is a generalization of the
celebrated Sinkhorn algorithm to the quantum setting of PSD matrices. We extend
this formulation and the quantum Sinkhorn algorithm to compute barycenters
within a collection of input tensor fields. We illustrate the usefulness of the
proposed approach on applications to procedural noise generation, anisotropic
meshing, diffusion tensor imaging and spectral texture synthesis.
</summary>
    <author>
      <name>Gabriel Peyré</name>
    </author>
    <author>
      <name>Lenaïc Chizat</name>
    </author>
    <author>
      <name>François-Xavier Vialard</name>
    </author>
    <author>
      <name>Justin Solomon</name>
    </author>
    <link href="http://arxiv.org/abs/1612.08731v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.08731v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.03754v2</id>
    <updated>2017-01-16T23:13:01Z</updated>
    <published>2017-01-13T17:48:44Z</published>
    <title>LayerBuilder: Layer Decomposition for Interactive Image and Video Color
  Editing</title>
    <summary>  Exploring and editing colors in images is a common task in graphic design and
photography. However, allowing for interactive recoloring while preserving
smooth color blends in the image remains a challenging problem. We present
LayerBuilder, an algorithm that decomposes an image or video into a linear
combination of colored layers to facilitate color-editing applications. These
layers provide an interactive and intuitive means for manipulating individual
colors. Our approach reduces color layer extraction to a fast iterative linear
system. Layer Builder uses locally linear embedding, which represents pixels as
linear combinations of their neighbors, to reduce the number of variables in
the linear solve and extract layers that can better preserve color blending
effects. We demonstrate our algorithm on recoloring a variety of images and
videos, and show its overall effectiveness in recoloring quality and time
complexity compared to previous approaches. We also show how this
representation can benefit other applications, such as automatic recoloring
suggestion, texture synthesis, and color-based filtering.
</summary>
    <author>
      <name>Sharon Lin</name>
    </author>
    <author>
      <name>Matthew Fisher</name>
    </author>
    <author>
      <name>Angela Dai</name>
    </author>
    <author>
      <name>Pat Hanrahan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages; added reference to Tan et al. 2016 and more image
  attribution</arxiv:comment>
    <link href="http://arxiv.org/abs/1701.03754v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.03754v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.4.9" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.06507v2</id>
    <updated>2017-02-02T17:59:10Z</updated>
    <published>2017-01-23T17:05:22Z</published>
    <title>Plausible Shading Decomposition For Layered Photo Retouching</title>
    <summary>  Photographers routinely compose multiple manipulated photos of the same scene
(layers) into a single image, which is better than any individual photo could
be alone. Similarly, 3D artists set up rendering systems to produce layered
images to contain only individual aspects of the light transport, which are
composed into the final result in post-production. Regrettably, both approaches
either take considerable time to capture, or remain limited to synthetic
scenes. In this paper, we suggest a system to allow decomposing a single image
into a plausible shading decomposition (PSD) that approximates effects such as
shadow, diffuse illumination, albedo, and specular shading. This decomposition
can then be manipulated in any off-the-shelf image manipulation software and
recomposited back. We perform such a decomposition by learning a convolutional
neural network trained using synthetic data. We demonstrate the effectiveness
of our decomposition on synthetic (i.e., rendered) and real data (i.e.,
photographs), and use them for common photo manipulation, which are nearly
impossible to perform otherwise from single images.
</summary>
    <author>
      <name>Carlo Innamorati</name>
    </author>
    <author>
      <name>Tobias Ritschel</name>
    </author>
    <author>
      <name>Tim Weyrich</name>
    </author>
    <author>
      <name>Niloy J. Mitra</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 9 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1701.06507v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.06507v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.0; I.4.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.07110v1</id>
    <updated>2017-01-24T23:35:09Z</updated>
    <published>2017-01-24T23:35:09Z</published>
    <title>By chance is not enough: Preserving relative density through non uniform
  sampling</title>
    <summary>  Dealing with visualizations containing large data set is a challenging issue
and, in the field of Information Visualization, almost every visual technique
reveals its drawback when visualizing large number of items. To deal with this
problem we introduce a formal environment, modeling in a virtual space the
image features we are interested in (e.g, absolute and relative density,
clusters, etc.) and we define some metrics able to characterize the image
decay. Such metrics drive our automatic techniques (i.e., not uniform sampling)
rescuing the image features and making them visible to the user. In this paper
we focus on 2D scatter-plots, devising a novel non uniform data sampling
strategy able to preserve in an effective way relative densities.
</summary>
    <author>
      <name>Enrico Bertini</name>
    </author>
    <author>
      <name>Giuseppe Santucci</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Keywords: visual clutter, visual quality metrics, non-uniform
  sampling</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings - Eighth International Conference on Information
  Visualisation, IV 2004; London; United Kingdom; 14 July 2004 through 16 July
  2004; Category numberPR02177; Code 63599</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1701.07110v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.07110v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.08893v2</id>
    <updated>2017-02-01T23:30:20Z</updated>
    <published>2017-01-31T02:37:19Z</published>
    <title>Stable and Controllable Neural Texture Synthesis and Style Transfer
  Using Histogram Losses</title>
    <summary>  Recently, methods have been proposed that perform texture synthesis and style
transfer by using convolutional neural networks (e.g. Gatys et al.
[2015,2016]). These methods are exciting because they can in some cases create
results with state-of-the-art quality. However, in this paper, we show these
methods also have limitations in texture quality, stability, requisite
parameter tuning, and lack of user controls. This paper presents a multiscale
synthesis pipeline based on convolutional neural networks that ameliorates
these issues. We first give a mathematical explanation of the source of
instabilities in many previous approaches. We then improve these instabilities
by using histogram losses to synthesize textures that better statistically
match the exemplar. We also show how to integrate localized style losses in our
multiscale framework. These losses can improve the quality of large features,
improve the separation of content and style, and offer artistic controls such
as paint by numbers. We demonstrate that our approach offers improved quality,
convergence in fewer iterations, and more stability over the optimization.
</summary>
    <author>
      <name>Eric Risser</name>
    </author>
    <author>
      <name>Pierre Wilmot</name>
    </author>
    <author>
      <name>Connelly Barnes</name>
    </author>
    <link href="http://arxiv.org/abs/1701.08893v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.08893v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1702.01530v1</id>
    <updated>2017-02-06T08:36:10Z</updated>
    <published>2017-02-06T08:36:10Z</published>
    <title>Three dimension visualization by ray-tracing image synthesis on GPU</title>
    <summary>  This paper presents a realization of the approach to spatial three Dimension
stereo of visualization of three Dimension images with use parallel Graphics
processing unit (GPU). The experiments of realization of synthesis of images of
a 3D stage by a method of trace of beams on GPU with Compute Unified Device
Architecture have shown that 60 % of the time is spent for the decision of a
computing problem approximately, the major part of time (40 %) is spent for
transfer of data between the central processing unit and GPU for calculations
and the organization process of visualization. The study of the influence of
increase in the size of the GPU network at the speed of calculations showed
importance of the correct task of structure of formation of the parallel
computer network and general mechanism of parallelization.
  Keywords: Volumetric three Dimension visualization, stereo three Dimension
visualization, Ray tracing, parallel computing on GPU, Compute Unified Device
Architecture.
</summary>
    <author>
      <name>Anas M. Al-Oraiqat</name>
    </author>
    <author>
      <name>S. A. Zori</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 8 Figures, International Journal of Engineering Science and
  Technology 2009</arxiv:comment>
    <link href="http://arxiv.org/abs/1702.01530v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1702.01530v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1702.01540v1</id>
    <updated>2017-02-06T09:38:20Z</updated>
    <published>2017-02-06T09:38:20Z</published>
    <title>Generalized 3D Voxel Image Synthesis Architecture for Volumetric Spatial
  Visualization</title>
    <summary>  A general concept of 3D volumetric visualization systems is described based
on 3D discrete voxel scenes (worlds) representation. Definitions of 3D discrete
voxel scene (world) basic elements and main steps of the image synthesis
algorithm are formulated. An algorithm for solving the problem of the voxelized
world 3D image synthesis, intended for the systems of volumetric spatial
visualization, is proposed. A computer-based architecture for 3D volumetric
visualization of 3D discrete voxel world is presented. On the basis of the
proposed overall concept of discrete voxel representation, the proposed
architecture successfully adapts the ray tracing technique for the synthesis of
3D volumetric images. Since it is algorithmically simple and effectively
supports parallelism, it can efficiently be implemented.
  Key words:Volumetric spatial visualization, 3D volumetric imagesynthesis,
discrete voxel world, ray tracing.
</summary>
    <author>
      <name>Anas M. Al-Oraiqat</name>
    </author>
    <author>
      <name>E. A. Bashkov</name>
    </author>
    <author>
      <name>S. A. Zori</name>
    </author>
    <author>
      <name>Aladdein M. Amro</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 4 Figures, International Publisher for Advanced Scientific
  Journals 2013</arxiv:comment>
    <link href="http://arxiv.org/abs/1702.01540v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1702.01540v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1702.03246v1</id>
    <updated>2017-02-10T16:37:55Z</updated>
    <published>2017-02-10T16:37:55Z</published>
    <title>Towards Developing an Easy-To-Use Scripting Environment for Animating
  Virtual Characters</title>
    <summary>  This paper presents the three scripting commands and main functionalities of
a novel character animation environment called CHASE. CHASE was developed for
enabling inexperienced programmers, animators, artists, and students to animate
in meaningful ways virtual reality characters. This is achieved by scripting
simple commands within CHASE. The commands identified, which are associated
with simple parameters, are responsible for generating a number of predefined
motions and actions of a character. Hence, the virtual character is able to
animate within a virtual environment and to interact with tasks located within
it. An additional functionality of CHASE is supplied. It provides the ability
to generate multiple tasks of a character, such as providing the user the
ability to generate scenario-related animated sequences. However, since
multiple characters may require simultaneous animation, the ability to script
actions of different characters at the same time is also provided.
</summary>
    <author>
      <name>Christos Mousas</name>
    </author>
    <link href="http://arxiv.org/abs/1702.03246v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1702.03246v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1702.04852v1</id>
    <updated>2017-02-16T03:49:46Z</updated>
    <published>2017-02-16T03:49:46Z</published>
    <title>Visualization and Analysis of Large-Scale, Tree-Based, Adaptive Mesh
  Refinement Simulations with Arbitrary Rectilinear Geometry</title>
    <summary>  We present here the first systematic treatment of the problems posed by the
visualization and analysis of large-scale, parallel adaptive mesh refinement
(AMR) simulations on an Eulerian grid. When compared to those obtained by
constructing an intermediate unstructured mesh with fully described
connectivity, our primary results indicate a gain of at least 80\% in terms of
memory footprint, with a better rendering while retaining similar execution
speed. In this article, we describe the key concepts that allow us to obtain
these results, together with the methodology that facilitates the design,
implementation, and optimization of algorithms operating directly on such
refined meshes. This native support for AMR meshes has been contributed to the
open source Visualization Toolkit (VTK). This work pertains to a broader
long-term vision, with the dual goal to both improve interactivity when
exploring such data sets in 2 and 3 dimensions, and optimize resource
utilization.
</summary>
    <author>
      <name>Guénolé Harel</name>
    </author>
    <author>
      <name>Jacques-Bernard Lekien</name>
    </author>
    <author>
      <name>Philippe P. Pébaÿ</name>
    </author>
    <link href="http://arxiv.org/abs/1702.04852v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1702.04852v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1702.08680v1</id>
    <updated>2017-02-28T07:54:21Z</updated>
    <published>2017-02-28T07:54:21Z</published>
    <title>A Data-driven Approach for Furniture and Indoor Scene Colorization</title>
    <summary>  We present a data-driven approach that colorizes 3D furniture models and
indoor scenes by leveraging indoor images on the internet. Our approach is able
to colorize the furniture automatically according to an example image. The core
is to learn image-guided mesh segmentation to segment the model into different
parts according to the image object. Given an indoor scene, the system supports
colorization-by-example, and has the ability to recommend the colorization
scheme that is consistent with a user-desired color theme. The latter is
realized by formulating the problem as a Markov random field model that imposes
user input as an additional constraint. We contribute to the community a
hierarchically organized image-model database with correspondences between each
image and the corresponding model at the part-level. Our experiments and a user
study show that our system produces perceptually convincing results comparable
to those generated by interior designers.
</summary>
    <author>
      <name>Jie Zhu</name>
    </author>
    <author>
      <name>Yanwen Guo</name>
    </author>
    <author>
      <name>Han Ma</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 16 figures, submission to IEEE TVCG</arxiv:comment>
    <link href="http://arxiv.org/abs/1702.08680v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1702.08680v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65D18" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.7; I.3.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.00050v1</id>
    <updated>2017-02-28T20:47:47Z</updated>
    <published>2017-02-28T20:47:47Z</published>
    <title>SceneSeer: 3D Scene Design with Natural Language</title>
    <summary>  Designing 3D scenes is currently a creative task that requires significant
expertise and effort in using complex 3D design interfaces. This effortful
design process starts in stark contrast to the easiness with which people can
use language to describe real and imaginary environments. We present SceneSeer:
an interactive text to 3D scene generation system that allows a user to design
3D scenes using natural language. A user provides input text from which we
extract explicit constraints on the objects that should appear in the scene.
Given these explicit constraints, the system then uses a spatial knowledge base
learned from an existing database of 3D scenes and 3D object models to infer an
arrangement of the objects forming a natural scene matching the input
description. Using textual commands the user can then iteratively refine the
created scene by adding, removing, replacing, and manipulating objects. We
evaluate the quality of 3D scenes generated by SceneSeer in a perceptual
evaluation experiment where we compare against manually designed scenes and
simpler baselines for 3D scene generation. We demonstrate how the generated
scenes can be iteratively refined through simple natural language commands.
</summary>
    <author>
      <name>Angel X. Chang</name>
    </author>
    <author>
      <name>Mihail Eric</name>
    </author>
    <author>
      <name>Manolis Savva</name>
    </author>
    <author>
      <name>Christopher D. Manning</name>
    </author>
    <link href="http://arxiv.org/abs/1703.00050v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.00050v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.00061v1</id>
    <updated>2017-02-28T21:21:03Z</updated>
    <published>2017-02-28T21:21:03Z</published>
    <title>SceneSuggest: Context-driven 3D Scene Design</title>
    <summary>  We present SceneSuggest: an interactive 3D scene design system providing
context-driven suggestions for 3D model retrieval and placement. Using a
point-and-click metaphor we specify regions in a scene in which to
automatically place and orient relevant 3D models. Candidate models are ranked
using a set of static support, position, and orientation priors learned from 3D
scenes. We show that our suggestions enable rapid assembly of indoor scenes. We
perform a user study comparing suggestions to manual search and selection, as
well as to suggestions with no automatic orientation. We find that suggestions
reduce total modeling time by 32%, that orientation priors reduce time spent
re-orienting objects by 27%, and that context-driven suggestions reduce the
number of text queries by 50%.
</summary>
    <author>
      <name>Manolis Savva</name>
    </author>
    <author>
      <name>Angel X. Chang</name>
    </author>
    <author>
      <name>Maneesh Agrawala</name>
    </author>
    <link href="http://arxiv.org/abs/1703.00061v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.00061v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.00521v1</id>
    <updated>2017-03-01T21:40:16Z</updated>
    <published>2017-03-01T21:40:16Z</published>
    <title>The Signals and Systems Approach to Animation</title>
    <summary>  Animation is ubiquitous in visualization systems, and a common technique for
creating these animations is the transition. In the transition approach,
animations are created by smoothly interpolating a visual attribute between a
start and end value, reaching the end value after a specified duration. This
approach works well when each transition for an attribute is allowed to finish
before the next is triggered, but performs poorly when a new transition is
triggered before the current transition has finished. In particular,
interruptions introduce velocity discontinuities, and frequent interruptions
can slow down the resulting animation. To solve these problems, we model the
problem of animation as a signal processing problem. In our technique,
animations are produced by transformations of signals, or functions over time.
In particular, an animation is produced by transforming an input signal, a
function from time to target attribute value, into an output signal, a function
from time to displayed attribute value. We show that well-known
signal-processing techniques can be applied to produce animations that are free
from velocity discontinuities even when interrupted.
</summary>
    <author>
      <name>Andrew McCaleb Reach</name>
    </author>
    <author>
      <name>Chris North</name>
    </author>
    <link href="http://arxiv.org/abs/1703.00521v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.00521v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.07167v1</id>
    <updated>2017-03-17T10:28:00Z</updated>
    <published>2017-03-17T10:28:00Z</published>
    <title>Volumetric parametrization from a level set boundary representation with
  PHT Splines</title>
    <summary>  A challenge in isogeometric analysis is constructing analysis-suitable
volumetric meshes which can accurately represent the geometry of a given
physical domain. In this paper, we propose a method to derive a spline-based
representation of a domain of interest from voxel-based data. We show an
efficient way to obtain a boundary representation of the domain by a level-set
function. Then, we use the geometric information from the boundary (the normal
vectors and curvature) to construct a matching C1 representation with
hierarchical cubic splines. The approximation is done by a single template and
linear transformations (scaling, translations and rotations) without the need
for solving an optimization problem. We illustrate our method with several
examples in two and three dimensions, and show good performance on some
standard benchmark test problems.
</summary>
    <author>
      <name>Chiu Ling Chan</name>
    </author>
    <author>
      <name>Cosmin Anitescu</name>
    </author>
    <author>
      <name>Timon Rabczuk</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.cad.2016.08.008</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.cad.2016.08.008" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Computer-Aided Design, Volume 82, January 2017, Pages 29-41</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1703.07167v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.07167v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.10405v1</id>
    <updated>2017-03-30T11:06:02Z</updated>
    <published>2017-03-30T11:06:02Z</published>
    <title>Autocomplete 3D Sculpting</title>
    <summary>  Digital sculpting is a popular means to create 3D models but remains a
challenging task for many users. This can be alleviated by recent advances in
data-driven and procedural modeling, albeit bounded by the underlying data and
procedures. We propose a 3D sculpting system that assists users in freely
creating models without predefined scope. With a brushing interface similar to
common sculpting tools, our system silently records and analyzes users'
workflows, and predicts what they might or should do in the future to reduce
input labor or enhance output quality. Users can accept, ignore, or modify the
suggestions and thus maintain full control and individual style. They can also
explicitly select and clone past workflows over output model regions. Our key
idea is to consider how a model is authored via dynamic workflows in addition
to what it is shaped in static geometry, for more accurate analysis of user
intentions and more general synthesis of shape structures. The workflows
contain potential repetitions for analysis and synthesis, including user inputs
(e.g. pen strokes on a pressure sensing tablet), model outputs (e.g. extrusions
on an object surface), and camera viewpoints. We evaluate our method via user
feedbacks and authored models.
</summary>
    <author>
      <name>Mengqi Peng</name>
    </author>
    <author>
      <name>Jun Xing</name>
    </author>
    <author>
      <name>Li-Yi Wei</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1703.10405v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.10405v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.5; H.5.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1704.04610v1</id>
    <updated>2017-04-15T09:21:57Z</updated>
    <published>2017-04-15T09:21:57Z</published>
    <title>A learning-based approach for automatic image and video colorization</title>
    <summary>  In this paper, we present a color transfer algorithm to colorize a broad
range of gray images without any user intervention. The algorithm uses a
machine learning-based approach to automatically colorize grayscale images. The
algorithm uses the superpixel representation of the reference color images to
learn the relationship between different image features and their corresponding
color values. We use this learned information to predict the color value of
each grayscale image superpixel. As compared to processing individual image
pixels, our use of superpixels helps us to achieve a much higher degree of
spatial consistency as well as speeds up the colorization process. The
predicted color values of the gray-scale image superpixels are used to provide
a 'micro-scribble' at the centroid of the superpixels. These color scribbles
are refined by using a voting based approach. To generate the final
colorization result, we use an optimization-based approach to smoothly spread
the color scribble across all pixels within a superpixel. Experimental results
on a broad range of images and the comparison with existing state-of-the-art
colorization methods demonstrate the greater effectiveness of the proposed
algorithm.
</summary>
    <author>
      <name>Raj Kumar Gupta</name>
    </author>
    <author>
      <name>Alex Yong-Sang Chia</name>
    </author>
    <author>
      <name>Deepu Rajan</name>
    </author>
    <author>
      <name>Huang Zhiyong</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Computer Graphics International - 2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1704.04610v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1704.04610v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1704.07854v1</id>
    <updated>2017-04-25T18:21:42Z</updated>
    <published>2017-04-25T18:21:42Z</published>
    <title>Pre-computed Liquid Spaces with Generative Neural Networks and Optical
  Flow</title>
    <summary>  Liquids exhibit highly complex, non-linear behavior under changing simulation
conditions such as user interactions. We propose a method to map this complex
behavior over a parameter range onto a reduced representation based on
space-time deformations. In order to represent the complexity of the full space
of inputs, we use aligned deformations from optical flow solves, and we
leverage the power of generative neural networks to synthesize additional
deformations for refinement. We introduce a novel deformation-aware loss
function, which enables optimization in the highly non-linear space of multiple
deformations. To demonstrate the effectiveness of our approach, we showcase the
method with several complex examples in two and four dimensions. Our
representation makes it possible to generate implicit surfaces of liquids very
efficiently, which allows us to very efficiently display the scene from any
angle, and to add secondary effects such as particle systems. We have
implemented a mobile application with our full pipeline to demonstrate that
real-time interaction is possible with our approach.
</summary>
    <author>
      <name>Boris Bonev</name>
    </author>
    <author>
      <name>Lukas Prantl</name>
    </author>
    <author>
      <name>Nils Thuerey</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Supplemental Android app:
  https://play.google.com/store/apps/details?id=fluidsim.de.interactivedrop</arxiv:comment>
    <link href="http://arxiv.org/abs/1704.07854v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1704.07854v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.00274v2</id>
    <updated>2017-05-12T21:48:29Z</updated>
    <published>2017-04-30T06:40:18Z</published>
    <title>Topologically Robust 3D Shape Matching via Gradual Deflation and
  Inflation</title>
    <summary>  Despite being vastly ignored in the literature, coping with topological noise
is an issue of increasing importance, especially as a consequence of the
increasing number and diversity of 3D polygonal models that are captured by
devices of different qualities or synthesized by algorithms of different
stabilities. One approach for matching 3D shapes under topological noise is to
replace the topology-sensitive geodesic distance with distances that are less
sensitive to topological changes. We propose an alternative approach utilising
gradual deflation (or inflation) of the shape volume, of which purpose is to
bring the pair of shapes to be matched to a \emph{comparable} topology before
the search for correspondences. Illustrative experiments using different
datasets demonstrate that as the level of topological noise increases, our
approach outperforms the other methods in the literature.
</summary>
    <author>
      <name>Asli Genctav</name>
    </author>
    <author>
      <name>Yusuf Sahillioglu</name>
    </author>
    <author>
      <name>Sibel Tari</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Section 2 replaced</arxiv:comment>
    <link href="http://arxiv.org/abs/1705.00274v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.00274v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.01263v1</id>
    <updated>2017-05-03T06:03:08Z</updated>
    <published>2017-05-03T06:03:08Z</published>
    <title>The Iray Light Transport Simulation and Rendering System</title>
    <summary>  While ray tracing has become increasingly common and path tracing is well
understood by now, a major challenge lies in crafting an easy-to-use and
efficient system implementing these technologies. Following a purely
physically-based paradigm while still allowing for artistic workflows, the Iray
light transport simulation and rendering system allows for rendering complex
scenes by the push of a button and thus makes accurate light transport
simulation widely available. In this document we discuss the challenges and
implementation choices that follow from our primary design decisions,
demonstrating that such a rendering system can be made a practical, scalable,
and efficient real-world application that has been adopted by various companies
across many fields and is in use by many industry professionals today.
</summary>
    <author>
      <name>Alexander Keller</name>
    </author>
    <author>
      <name>Carsten Wächter</name>
    </author>
    <author>
      <name>Matthias Raab</name>
    </author>
    <author>
      <name>Daniel Seibert</name>
    </author>
    <author>
      <name>Dietger van Antwerpen</name>
    </author>
    <author>
      <name>Johann Korndörfer</name>
    </author>
    <author>
      <name>Lutz Kettner</name>
    </author>
    <link href="http://arxiv.org/abs/1705.01263v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.01263v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.01425v2</id>
    <updated>2017-07-25T14:35:49Z</updated>
    <published>2017-05-03T13:41:49Z</published>
    <title>Data-Driven Synthesis of Smoke Flows with CNN-based Feature Descriptors</title>
    <summary>  We present a novel data-driven algorithm to synthesize high-resolution flow
simulations with reusable repositories of space-time flow data. In our work, we
employ a descriptor learning approach to encode the similarity between fluid
regions with differences in resolution and numerical viscosity. We use
convolutional neural networks to generate the descriptors from fluid data such
as smoke density and flow velocity. At the same time, we present a deformation
limiting patch advection method which allows us to robustly track deformable
fluid regions. With the help of this patch advection, we generate stable
space-time data sets from detailed fluids for our repositories. We can then use
our learned descriptors to quickly localize a suitable data set when running a
new simulation. This makes our approach very efficient, and resolution
independent. We will demonstrate with several examples that our method yields
volumes with very high effective resolutions, and non-dissipative small scale
details that naturally integrate into the motions of the underlying flow.
</summary>
    <author>
      <name>Mengyu Chu</name>
    </author>
    <author>
      <name>Nils Thuerey</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3072959.3073643</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3072959.3073643" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 17 figures, to appear at SIGGRAPH 2017, v2 only fixes small
  typos</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ACM Trans. Graph.36, 4 (2017), 69:1-69:13</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1705.01425v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.01425v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.01661v1</id>
    <updated>2017-05-04T00:11:16Z</updated>
    <published>2017-05-04T00:11:16Z</published>
    <title>Learning Hierarchical Shape Segmentation and Labeling from Online
  Repositories</title>
    <summary>  We propose a method for converting geometric shapes into hierarchically
segmented parts with part labels. Our key idea is to train category-specific
models from the scene graphs and part names that accompany 3D shapes in public
repositories. These freely-available annotations represent an enormous,
untapped source of information on geometry. However, because the models and
corresponding scene graphs are created by a wide range of modelers with
different levels of expertise, modeling tools, and objectives, these models
have very inconsistent segmentations and hierarchies with sparse and noisy
textual tags. Our method involves two analysis steps. First, we perform a joint
optimization to simultaneously cluster and label parts in the database while
also inferring a canonical tag dictionary and part hierarchy. We then use this
labeled data to train a method for hierarchical segmentation and labeling of
new 3D shapes. We demonstrate that our method can mine complex information,
detecting hierarchies in man-made objects and their constituent parts,
obtaining finer scale details than existing alternatives. We also show that, by
performing domain transfer using a few supervised examples, our technique
outperforms fully-supervised techniques that require hundreds of
manually-labeled models.
</summary>
    <author>
      <name>Li Yi</name>
    </author>
    <author>
      <name>Leonidas Guibas</name>
    </author>
    <author>
      <name>Aaron Hertzmann</name>
    </author>
    <author>
      <name>Vladimir G. Kim</name>
    </author>
    <author>
      <name>Hao Su</name>
    </author>
    <author>
      <name>Ersin Yumer</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3072959.3073652</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3072959.3073652" rel="related"/>
    <link href="http://arxiv.org/abs/1705.01661v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.01661v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.03811v2</id>
    <updated>2017-09-21T09:35:30Z</updated>
    <published>2017-05-10T15:12:14Z</published>
    <title>From 3D Models to 3D Prints: an Overview of the Processing Pipeline</title>
    <summary>  Due to the wide diffusion of 3D printing technologies, geometric algorithms
for Additive Manufacturing are being invented at an impressive speed. Each
single step, in particular along the Process Planning pipeline, can now count
on dozens of methods that prepare the 3D model for fabrication, while analysing
and optimizing geometry and machine instructions for various objectives. This
report provides a classification of this huge state of the art, and elicits the
relation between each single algorithm and a list of desirable objectives
during Process Planning. The objectives themselves are listed and discussed,
along with possible needs for tradeoffs. Additive Manufacturing technologies
are broadly categorized to explicitly relate classes of devices and supported
features. Finally, this report offers an analysis of the state of the art while
discussing open and challenging problems from both an academic and an
industrial perspective.
</summary>
    <author>
      <name>Marco Livesu</name>
    </author>
    <author>
      <name>Stefano Ellero</name>
    </author>
    <author>
      <name>Jonás Martìnez</name>
    </author>
    <author>
      <name>Sylvain Lefebvre</name>
    </author>
    <author>
      <name>Marco Attene</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1111/cgf.13147</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1111/cgf.13147" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">European Union (EU); Horizon 2020; H2020-FoF-2015; RIA - Research and
  Innovation action; Grant agreement N. 680448</arxiv:comment>
    <link href="http://arxiv.org/abs/1705.03811v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.03811v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.06250v1</id>
    <updated>2017-05-12T01:23:55Z</updated>
    <published>2017-05-12T01:23:55Z</published>
    <title>Shape Classification using Spectral Graph Wavelets</title>
    <summary>  Spectral shape descriptors have been used extensively in a broad spectrum of
geometry processing applications ranging from shape retrieval and segmentation
to classification. In this pa- per, we propose a spectral graph wavelet
approach for 3D shape classification using the bag-of-features paradigm. In an
effort to capture both the local and global geometry of a 3D shape, we present
a three-step feature description framework. First, local descriptors are
extracted via the spectral graph wavelet transform having the Mexican hat
wavelet as a generating ker- nel. Second, mid-level features are obtained by
embedding lo- cal descriptors into the visual vocabulary space using the soft-
assignment coding step of the bag-of-features model. Third, a global descriptor
is constructed by aggregating mid-level fea- tures weighted by a geodesic
exponential kernel, resulting in a matrix representation that describes the
frequency of appearance of nearby codewords in the vocabulary. Experimental
results on two standard 3D shape benchmarks demonstrate the effective- ness of
the proposed classification approach in comparison with state-of-the-art
methods.
</summary>
    <author>
      <name>Majid Masoumi</name>
    </author>
    <author>
      <name>A. Ben Hamza</name>
    </author>
    <link href="http://arxiv.org/abs/1705.06250v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.06250v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.01558v1</id>
    <updated>2017-06-05T23:20:20Z</updated>
    <published>2017-06-05T23:20:20Z</published>
    <title>QuickCSG: Fast Arbitrary Boolean Combinations of N Solids</title>
    <summary>  QuickCSG computes the result for general N-polyhedron boolean expressions
without an intermediate tree of solids. We propose a vertex-centric view of the
problem, which simplifies the identification of final geometric contributions,
and facilitates its spatial decomposition. The problem is then cast in a single
KD-tree exploration, geared toward the result by early pruning of any region of
space not contributing to the final surface. We assume strong regularity
properties on the input meshes and that they are in general position. This
simplifying assumption, in combination with our vertex-centric approach,
improves the speed of the approach. Complemented with a task-stealing
parallelization, the algorithm achieves breakthrough performance, one to two
orders of magnitude speedups with respect to state-of-the-art CPU algorithms,
on boolean operations over two to dozens of polyhedra. The algorithm also
outperforms GPU implementations with approximate discretizations, while
producing an output without redundant facets. Despite the restrictive
assumptions on the input, we show the usefulness of QuickCSG for applications
with large CSG problems and strong temporal constraints, e.g. modeling for 3D
printers, reconstruction from visual hulls and collision detection.
</summary>
    <author>
      <name>Matthijs Douze</name>
    </author>
    <author>
      <name>Jean-Sébastien Franco</name>
    </author>
    <author>
      <name>Bruno Raffin</name>
    </author>
    <link href="http://arxiv.org/abs/1706.01558v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.01558v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.03024v2</id>
    <updated>2017-06-12T08:18:21Z</updated>
    <published>2017-06-09T16:32:33Z</published>
    <title>A Physically Plausible Model for Rendering Highly Scattering Fluorescent
  Participating Media</title>
    <summary>  We present a novel extension of the path tracing algorithm that is capable of
treating highly scattering participating media in the presence of fluorescent
structures. The extension is based on the formulation of the full radiative
transfer equation when solved on a per-wavelength-basis, resulting in accurate
model and unbiased algorithm for rendering highly scattering fluorescent
participating media. The model accounts for the intrinsic properties of
fluorescent dyes including their absorption and emission spectra, molar
absorptivity and quantum yield and also their concentration. Our algorithm is
applied to render highly scattering isotropic fluorescent solutions under
different illumination conditions. The spectral performance of the model is
validated against emission spectra of different fluorescent dyes that are of
significance in spectroscopy.
</summary>
    <author>
      <name>Marwan Abdellah</name>
    </author>
    <author>
      <name>Ahmet Bilgili</name>
    </author>
    <author>
      <name>Stefan Eilemann</name>
    </author>
    <author>
      <name>Henry Markram</name>
    </author>
    <author>
      <name>Felix Schürmann</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, 7 figures, conference</arxiv:comment>
    <link href="http://arxiv.org/abs/1706.03024v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.03024v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.03950v1</id>
    <updated>2017-06-13T08:21:02Z</updated>
    <published>2017-06-13T08:21:02Z</published>
    <title>Procedural Wang Tile Algorithm for Stochastic Wall Patterns</title>
    <summary>  The game and movie industries always face the challenge of reproducing
materials. This problem is tackled by combining illumination models and various
textures (painted or procedural patterns). Gnerating stochastic wall patterns
is crucial in the creation of a wide range of backgrounds (castles, temples,
ruins...). A specific Wang tile set was introduced previously to tackle this
problem, in a non-procedural fashion. Long lines may appear as visual
artifacts. We use this tile set in a new procedural algorithm to generate
stochastic wall patterns. For this purpose, we introduce specific hash
functions implementing a constrained Wang tiling. This technique makes possible
the generation of boundless textures while giving control over the maximum line
length. The algorithm is simple and easy to implement, and the wall structure
we get from the tiles allows to achieve visuals that reproduce all the small
details of artist painted walls.
</summary>
    <author>
      <name>Alexandre Derouet-Jourdan</name>
    </author>
    <author>
      <name>Marc Salvati</name>
    </author>
    <author>
      <name>Theo Jonchier</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to ACM Transactions on Graphics</arxiv:comment>
    <link href="http://arxiv.org/abs/1706.03950v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.03950v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.04077v1</id>
    <updated>2017-06-12T05:17:18Z</updated>
    <published>2017-06-12T05:17:18Z</published>
    <title>Interactive Shape Perturbation</title>
    <summary>  We present a web application for the procedural generation of perturbations
of 3D models. We generate the perturbations by generating vertex shaders that
change the positions of vertices that make up the 3D model. The vertex shaders
are created with an interactive genetic algorithm, which displays to the user
the visual effect caused by each vertex shader, allows the user to select the
visual effect the user likes best, and produces a new generation of vertex
shaders using the user feedback as the fitness measure of the genetic
algorithm. We use genetic programming to represent each vertex shader as a
computer program. This paper presents details of requirements specification,
software architecture, high and low-level design, and prototype user interface.
We discuss the project's current status and development challenges.
</summary>
    <author>
      <name>Juan C. Quiroz</name>
    </author>
    <author>
      <name>Sergiu M. Dascalu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Preprint. arXiv admin note: substantial text overlap with
  arXiv:1608.05231</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computers and Their Applications, IJCA,
  Vol. 24, No. 1, March 2017, 8 pages</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1706.04077v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.04077v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.06918v1</id>
    <updated>2017-06-21T14:11:32Z</updated>
    <published>2017-06-21T14:11:32Z</published>
    <title>cGAN-based Manga Colorization Using a Single Training Image</title>
    <summary>  The Japanese comic format known as Manga is popular all over the world. It is
traditionally produced in black and white, and colorization is time consuming
and costly. Automatic colorization methods generally rely on greyscale values,
which are not present in manga. Furthermore, due to copyright protection,
colorized manga available for training is scarce. We propose a manga
colorization method based on conditional Generative Adversarial Networks
(cGAN). Unlike previous cGAN approaches that use many hundreds or thousands of
training images, our method requires only a single colorized reference image
for training, avoiding the need of a large dataset. Colorizing manga using
cGANs can produce blurry results with artifacts, and the resolution is limited.
We therefore also propose a method of segmentation and color-correction to
mitigate these issues. The final results are sharp, clear, and in high
resolution, and stay true to the character's original color scheme.
</summary>
    <author>
      <name>Paulina Hensman</name>
    </author>
    <author>
      <name>Kiyoharu Aizawa</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 13 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1706.06918v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.06918v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68U10, 68U05" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.10098v1</id>
    <updated>2017-06-30T10:08:11Z</updated>
    <published>2017-06-30T10:08:11Z</published>
    <title>From Big Data to Big Displays: High-Performance Visualization at Blue
  Brain</title>
    <summary>  Blue Brain has pushed high-performance visualization (HPV) to complement its
HPC strategy since its inception in 2007. In 2011, this strategy has been
accelerated to develop innovative visualization solutions through increased
funding and strategic partnerships with other research institutions.
  We present the key elements of this HPV ecosystem, which integrates C++
visualization applications with novel collaborative display systems. We
motivate how our strategy of transforming visualization engines into services
enables a variety of use cases, not only for the integration with high-fidelity
displays, but also to build service oriented architectures, to link into web
applications and to provide remote services to Python applications.
</summary>
    <author>
      <name>Stefan Eilemann</name>
    </author>
    <author>
      <name>Marwan Abdellah</name>
    </author>
    <author>
      <name>Nicolas Antille</name>
    </author>
    <author>
      <name>Ahmet Bilgili</name>
    </author>
    <author>
      <name>Grigory Chevtchenko</name>
    </author>
    <author>
      <name>Raphael Dumusc</name>
    </author>
    <author>
      <name>Cyrille Favreau</name>
    </author>
    <author>
      <name>Juan Hernando</name>
    </author>
    <author>
      <name>Daniel Nachbaur</name>
    </author>
    <author>
      <name>Pawel Podhajski</name>
    </author>
    <author>
      <name>Jafet Villafranca</name>
    </author>
    <author>
      <name>Felix Schürmann</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ISC 2017 Visualization at Scale workshop</arxiv:comment>
    <link href="http://arxiv.org/abs/1706.10098v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.10098v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.00648v1</id>
    <updated>2017-06-01T11:51:37Z</updated>
    <published>2017-06-01T11:51:37Z</published>
    <title>Examplar-Based Face Colorization Using Image Morphing</title>
    <summary>  Colorization of gray-scale images relies on prior color information.
Examplar-based methods use a color image as source of such information. Then
the colors of the source image are transferred to the gray-scale image. In the
literature, this transfer is mainly guided by texture descriptors. Face images
usually contain few texture so that the common approaches frequently fail. In
this paper we propose a new method based on image morphing. This technique is
able to compute a correspondence map between images with similar shapes. It is
based on the geometric structure of the images rather than textures which is
more reliable for faces. Our numerical experiments show that our morphing based
approach clearly outperforms state-of-the-art methods.
</summary>
    <author>
      <name>Johannes Persch</name>
    </author>
    <author>
      <name>Fabien Pierre</name>
    </author>
    <author>
      <name>Gabriele Steidl</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 6 figures, preprint</arxiv:comment>
    <link href="http://arxiv.org/abs/1707.00648v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.00648v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68U10" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.01732v1</id>
    <updated>2017-07-06T11:18:42Z</updated>
    <published>2017-07-06T11:18:42Z</published>
    <title>Nonlinear dance motion analysis and motion editing using Hilbert-Huang
  transform</title>
    <summary>  Human motions (especially dance motions) are very noisy, and it is hard to
analyze and edit the motions. To resolve this problem, we propose a new method
to decompose and modify the motions using the Hilbert-Huang transform (HHT).
First, HHT decomposes a chromatic signal into "monochromatic" signals that are
the so-called Intrinsic Mode Functions (IMFs) using an Empirical Mode
Decomposition (EMD) [6]. After applying the Hilbert Transform to each IMF, the
instantaneous frequencies of the "monochromatic" signals can be obtained. The
HHT has the advantage to analyze non-stationary and nonlinear signals such as
human-joint-motions over FFT or Wavelet transform.
  In the present paper, we propose a new framework to analyze and extract some
new features from a famous Japanese threesome pop singer group called
"Perfume", and compare it with Waltz and Salsa dance. Using the EMD, their
dance motions can be decomposed into motion (choreographic) primitives or IMFs.
Therefore we can scale, combine, subtract, exchange, and modify those IMFs, and
can blend them into new dance motions self-consistently. Our analysis and
framework can lead to a motion editing and blending method to create a new
dance motion from different dance motions.
</summary>
    <author>
      <name>Ran Dong</name>
    </author>
    <author>
      <name>Dongsheng Cai</name>
    </author>
    <author>
      <name>Nobuyoshi Asai</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3095140.3095175</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3095140.3095175" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 10 figures, Computer Graphics International 2017, Conference
  short paper</arxiv:comment>
    <link href="http://arxiv.org/abs/1707.01732v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.01732v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.02596v1</id>
    <updated>2017-07-09T16:03:30Z</updated>
    <published>2017-07-09T16:03:30Z</published>
    <title>Localized Manifold Harmonics for Spectral Shape Analysis</title>
    <summary>  The use of Laplacian eigenfunctions is ubiquitous in a wide range of computer
graphics and geometry processing applications. In particular, Laplacian
eigenbases allow generalizing the classical Fourier analysis to manifolds. A
key drawback of such bases is their inherently global nature, as the Laplacian
eigenfunctions carry geometric and topological structure of the entire
manifold. In this paper, we introduce a new framework for local spectral shape
analysis. We show how to efficiently construct localized orthogonal bases by
solving an optimization problem that in turn can be posed as the
eigendecomposition of a new operator obtained by a modification of the standard
Laplacian. We study the theoretical and computational aspects of the proposed
framework and showcase our new construction on the classical problems of shape
approximation and correspondence. We obtain significant improvement compared to
classical Laplacian eigenbases as well as other alternatives for constructing
localized bases.
</summary>
    <author>
      <name>Simone Melzi</name>
    </author>
    <author>
      <name>Emanuele Rodolà</name>
    </author>
    <author>
      <name>Umberto Castellani</name>
    </author>
    <author>
      <name>Michael M. Bronstein</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to Computer Graphics Forum</arxiv:comment>
    <link href="http://arxiv.org/abs/1707.02596v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.02596v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.04348v1</id>
    <updated>2017-07-13T22:56:46Z</updated>
    <published>2017-07-13T22:56:46Z</published>
    <title>Natural Boundary Conditions for Smoothing in Geometry Processing</title>
    <summary>  In geometry processing, smoothness energies are commonly used to model
scattered data interpolation, dense data denoising, and regularization during
shape optimization. The squared Laplacian energy is a popular choice of energy
and has a corresponding standard implementation: squaring the discrete
Laplacian matrix. For compact domains, when values along the boundary are not
known in advance, this construction bakes in low-order boundary conditions.
This causes the geometric shape of the boundary to strongly bias the solution.
For many applications, this is undesirable. Instead, we propose using the
squared Frobenious norm of the Hessian as a smoothness energy. Unlike the
squared Laplacian energy, this energy's natural boundary conditions (those that
best minimize the energy) correspond to meaningful high-order boundary
conditions. These boundary conditions model free boundaries where the shape of
the boundary should not bias the solution locally. Our analysis begins in the
smooth setting and concludes with discretizations using finite-differences on
2D grids or mixed finite elements for triangle meshes. We demonstrate the core
behavior of the squared Hessian as a smoothness energy for various tasks.
</summary>
    <author>
      <name>Oded Stein</name>
    </author>
    <author>
      <name>Eitan Grinspun</name>
    </author>
    <author>
      <name>Max Wardetzky</name>
    </author>
    <author>
      <name>Alec Jacobson</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 16 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1707.04348v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.04348v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.04805v1</id>
    <updated>2017-07-16T01:42:41Z</updated>
    <published>2017-07-16T01:42:41Z</published>
    <title>A Streamline Selection Technique Overlaying with Isosurfaces</title>
    <summary>  Integration of scalar and vector visualization has been an interesting topic.
This paper presents a technique to appropriately select and display multiple
streamlines while overlaying with isosurfaces, aiming an integrated scalar and
vector field visualization. The technique visualizes a scalar field by multiple
semitransparent isosurfaces, and a vector field by multiple streamlines, while
the technique adequately selects the streamlines considering reduction of
cluttering among the isosurfaces and streamlines. The technique first selects
and renders isosurfaces, and then generates large number of streamlines from
randomly selected seed points. The technique evaluates each of the streamlines
according to their shapes on a 2D display space, distances to critical points
of the given vector fields, and occlusion by isosurfaces. It then selects the
specified number of highly evaluated streamlines. As a result, we can visualize
both scalar and vector fields as a set of view-independently selected
isosurfaces and view-dependently selected streamlines.
</summary>
    <author>
      <name>Shiho Furuya</name>
    </author>
    <author>
      <name>Takayuki Itoh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">TopoInVis2017</arxiv:comment>
    <link href="http://arxiv.org/abs/1707.04805v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.04805v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.06683v2</id>
    <updated>2017-10-03T03:30:17Z</updated>
    <published>2017-07-20T19:13:55Z</published>
    <title>Visual Detection of Structural Changes in Time-Varying Graphs Using
  Persistent Homology</title>
    <summary>  Topological data analysis is an emerging area in exploratory data analysis
and data mining. Its main tool, persistent homology, has become a popular
technique to study the structure of complex, high-dimensional data. In this
paper, we propose a novel method using persistent homology to quantify
structural changes in time-varying graphs. Specifically, we transform each
instance of the time-varying graph into metric spaces, extract topological
features using persistent homology, and compare those features over time. We
provide a visualization that assists in time-varying graph exploration and
helps to identify patterns of behavior within the data. To validate our
approach, we conduct several case studies on real world data sets and show how
our method can find cyclic patterns, deviations from those patterns, and
one-time events in time-varying graphs. We also examine whether
persistence-based similarity measure as a graph metric satisfies a set of
well-established, desirable properties for graph metrics.
</summary>
    <author>
      <name>Mustafa Hajij</name>
    </author>
    <author>
      <name>Bei Wang</name>
    </author>
    <author>
      <name>Carlos Scheidegger</name>
    </author>
    <author>
      <name>Paul Rosen</name>
    </author>
    <link href="http://arxiv.org/abs/1707.06683v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.06683v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.07070v1</id>
    <updated>2017-07-21T23:28:53Z</updated>
    <published>2017-07-21T23:28:53Z</published>
    <title>Steklov Geometry Processing: An Extrinsic Approach to Spectral Shape
  Analysis</title>
    <summary>  We propose Steklov geometry processing, an extrinsic approach to spectral
geometry processing and shape analysis. Intrinsic approaches, usually based on
the Laplace-Beltrami operator, cannot capture the spatial embedding of a shape
up to rigid motion, while many previous extrinsic methods lack theoretical
justification. Instead, we propose a systematic approach by considering the
Steklov eigenvalue problem, computing the spectrum of the Dirichlet-to-Neumann
operator of a surface bounding a volume. A remarkable property of this operator
is that it encodes the volumetric geometry. We use the boundary element method
(BEM) to discretize the operator, accelerated by hierarchical numerical schemes
and preconditioning; this pipeline allows us to solve eigenvalue and linear
problems on large-scale meshes despite the density of the Dirichlet-to-Neumann
discretization. We further demonstrate that our operators naturally fit into
existing frameworks for geometry processing, making a shift from intrinsic to
extrinsic geometry as simple as substituting the Laplace-Beltrami operator with
the Dirichlet-to-Neumann operator.
</summary>
    <author>
      <name>Yu Wang</name>
    </author>
    <author>
      <name>Mirela Ben-Chen</name>
    </author>
    <author>
      <name>Iosif Polterovich</name>
    </author>
    <author>
      <name>Justin Solomon</name>
    </author>
    <link href="http://arxiv.org/abs/1707.07070v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.07070v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.08323v1</id>
    <updated>2017-07-26T08:50:14Z</updated>
    <published>2017-07-26T08:50:14Z</published>
    <title>Pigmento: Pigment-Based Image Analysis and Editing</title>
    <summary>  The colorful appearance of a physical painting is determined by the
distribution of paint pigments across the canvas, which we model as a per-pixel
mixture of a small number of pigments with multispectral absorption and
scattering coefficients. We present an algorithm to efficiently recover this
structure from an RGB image, yielding a plausible set of pigments and a low RGB
reconstruction error. We show that under certain circumstances we are able to
recover pigments that are close to ground truth, while in all cases our results
are always plausible. Using our decomposition, we repose standard digital image
editing operations as operations in pigment space rather than RGB, with
interestingly novel results. We demonstrate tonal adjustments, selection
masking, cut-copy-paste, recoloring, palette summarization, and edge
enhancement.
</summary>
    <author>
      <name>Jianchao Tan</name>
    </author>
    <author>
      <name>Stephen DiVerdi</name>
    </author>
    <author>
      <name>Jingwan Lu</name>
    </author>
    <author>
      <name>Yotam Gingold</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1707.08323v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.08323v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.08358v2</id>
    <updated>2017-07-28T10:57:27Z</updated>
    <published>2017-07-26T10:26:08Z</published>
    <title>Notes on optimal approximations for importance sampling</title>
    <summary>  In this manuscript, we derive optimal conditions for building function
approximations that minimize variance when used as importance sampling
estimators for Monte Carlo integration problems. Particularly, we study the
problem of finding the optimal projection $g$ of an integrand $f$ onto certain
classes of piecewise constant functions, in order to minimize the variance of
the unbiased importance sampling estimator $E_g[f/g]$, as well as the related
problem of finding optimal mixture weights to approximate and importance sample
a target mixture distribution $f = \sum_i \alpha_i f_i$ with components $f_i$
in a family $\mathcal{F}$, through a corresponding mixture of importance
sampling densities $g_i$ that are only approximately proportional to $f_i$. We
further show that in both cases the optimal projection is different from the
commonly used $\ell_1$ projection, and provide an intuitive explanation for the
difference.
</summary>
    <author>
      <name>Jacopo Pantaleoni</name>
    </author>
    <author>
      <name>Eric Heitz</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1707.08358v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.08358v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.08360v1</id>
    <updated>2017-07-26T10:30:34Z</updated>
    <published>2017-07-26T10:30:34Z</published>
    <title>Discrete Geodesic Nets for Modeling Developable Surfaces</title>
    <summary>  We present a discrete theory for modeling developable surfaces as
quadrilateral meshes satisfying simple angle constraints. The basis of our
model is a lesser known characterization of developable surfaces as manifolds
that can be parameterized through orthogonal geodesics. Our model is simple,
local, and, unlike previous works, it does not directly encode the surface
rulings. This allows us to model continuous deformations of discrete
developable surfaces independently of their decomposition into torsal and
planar patches or the surface topology. We prove and experimentally demonstrate
strong ties to smooth developable surfaces, including a theorem stating that
every sampling of the smooth counterpart satisfies our constraints up to second
order. We further present an extension of our model that enables a local
definition of discrete isometry. We demonstrate the effectiveness of our
discrete model in a developable surface editing system, as well as computation
of an isometric interpolation between isometric discrete developable shapes.
</summary>
    <author>
      <name>Michael Rabinovich</name>
    </author>
    <author>
      <name>Tim Hoffmann</name>
    </author>
    <author>
      <name>Olga Sorkine-Hornung</name>
    </author>
    <link href="http://arxiv.org/abs/1707.08360v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.08360v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.09366v1</id>
    <updated>2017-07-28T08:45:37Z</updated>
    <published>2017-07-28T08:45:37Z</published>
    <title>Continuous Global Optimization in Surface Reconstruction from an
  Oriented Point Cloud</title>
    <summary>  We introduce a continuous global optimization method to the field of surface
reconstruction from discrete noisy cloud of points with weak information on
orientation. The proposed method uses an energy functional combining flux-based
data-fit measures and a regularization term. A continuous convex relaxation
scheme assures the global minima of the geometric surface functional. The
reconstructed surface is implicitly represented by the binary segmentation of
vertices of a 3D uniform grid and a triangulated surface can be obtained by
extracting an appropriate isosurface. Unlike the discrete graph-cut solution,
the continuous global optimization entails advantages like memory requirements,
reduction of metrication errors for geometric quantities, allowing globally
optimal surface reconstruction at higher grid resolutions. We demonstrate the
performance of the proposed method on several oriented point clouds captured by
laser scanners. Experimental results confirm that our approach is robust to
noise, large holes and non-uniform sampling density under the condition of very
coarse orientation information.
</summary>
    <author>
      <name>Rongjiang Pan</name>
    </author>
    <author>
      <name>Vaclav Skala</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.cad.2011.03.005</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.cad.2011.03.005" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Computer Aided Design, Vol.43, No.8, pp.896-901, Elsevier, ISSN
  0010-4485, 2011</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1707.09366v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.09366v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.09432v1</id>
    <updated>2017-07-28T22:33:01Z</updated>
    <published>2017-07-28T22:33:01Z</published>
    <title>Generation of concept-representative symbols</title>
    <summary>  The visual representation of concepts or ideas through the use of simple
shapes has always been explored in the history of Humanity, and it is believed
to be the origin of writing. We focus on computational generation of visual
symbols to represent concepts. We aim to develop a system that uses background
knowledge about the world to find connections among concepts, with the goal of
generating symbols for a given concept. We are also interested in exploring the
system as an approach to visual dissociation and visual conceptual blending.
This has a great potential in the area of Graphic Design as a tool to both
stimulate creativity and aid in brainstorming in projects such as logo,
pictogram or signage design.
</summary>
    <author>
      <name>João Miguel Cunha</name>
    </author>
    <author>
      <name>Pedro Martins</name>
    </author>
    <author>
      <name>Amílcar Cardoso</name>
    </author>
    <author>
      <name>Penousal Machado</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">cite as "Cunha, J. M., Martins, P., Cardoso, A., &amp; Machado, P.
  (2015). Generation of Concept-Representative Symbols. In ICCBR (Workshops).",
  Computational creativity, Computational generation, Concept representation,
  Visual representation</arxiv:comment>
    <link href="http://arxiv.org/abs/1707.09432v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.09432v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.03686v1</id>
    <updated>2017-08-11T19:58:46Z</updated>
    <published>2017-08-11T19:58:46Z</published>
    <title>Visualizing Time-Varying Particle Flows with Diffusion Geometry</title>
    <summary>  The tasks of identifying separation structures and clusters in flow data are
fundamental to flow visualization. Significant work has been devoted to these
tasks in flow represented by vector fields, but there are unique challenges in
addressing these tasks for time-varying particle data. The unstructured nature
of particle data, nonuniform and sparse sampling, and the inability to access
arbitrary particles in space-time make it difficult to define separation and
clustering for particle data. We observe that weaker notions of separation and
clustering through continuous measures of these structures are meaningful when
coupled with user exploration. We achieve this goal by defining a measure of
particle similarity between pairs of particles. More specifically, separation
occurs when spatially-localized particles are dissimilar, while clustering is
characterized by sets of particles that are similar to one another. To be
robust to imperfections in sampling we use diffusion geometry to compute
particle similarity. Diffusion geometry is parameterized by a scale that allows
a user to explore separation and clustering in a continuous manner. We
illustrate the benefits of our technique on a variety of 2D and 3D flow
datasets, from particles integrated in fluid simulations based on time-varying
vector fields, to particle-based simulations in astrophysics.
</summary>
    <author>
      <name>Matthew Berger</name>
    </author>
    <author>
      <name>Joshua A. Levine</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 16 figures, under review</arxiv:comment>
    <link href="http://arxiv.org/abs/1708.03686v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.03686v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.03748v1</id>
    <updated>2017-08-12T07:40:39Z</updated>
    <published>2017-08-12T07:40:39Z</published>
    <title>Calipso: Physics-based Image and Video Editing through CAD Model Proxies</title>
    <summary>  We present Calipso, an interactive method for editing images and videos in a
physically-coherent manner. Our main idea is to realize physics-based
manipulations by running a full physics simulation on proxy geometries given by
non-rigidly aligned CAD models. Running these simulations allows us to apply
new, unseen forces to move or deform selected objects, change physical
parameters such as mass or elasticity, or even add entire new objects that
interact with the rest of the underlying scene. In Calipso, the user makes
edits directly in 3D; these edits are processed by the simulation and then
transfered to the target 2D content using shape-to-image correspondences in a
photo-realistic rendering process. To align the CAD models, we introduce an
efficient CAD-to-image alignment procedure that jointly minimizes for rigid and
non-rigid alignment while preserving the high-level structure of the input
shape. Moreover, the user can choose to exploit image flow to estimate scene
motion, producing coherent physical behavior with ambient dynamics. We
demonstrate Calipso's physics-based editing on a wide range of examples
producing myriad physical behavior while preserving geometric and visual
consistency.
</summary>
    <author>
      <name>Nazim Haouchine</name>
    </author>
    <author>
      <name>Frederick Roy</name>
    </author>
    <author>
      <name>Hadrien Courtecuisse</name>
    </author>
    <author>
      <name>Matthias Nießner</name>
    </author>
    <author>
      <name>Stephane Cotin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1708.03748v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.03748v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.03760v1</id>
    <updated>2017-08-12T09:52:16Z</updated>
    <published>2017-08-12T09:52:16Z</published>
    <title>Temporal Upsampling of Depth Maps Using a Hybrid Camera</title>
    <summary>  In recent years consumer-level depth sensors have been adopted in various
applications. However, they often produce depth maps at a not very fast frame
rate (around 30 frames per second), preventing them from being used for
applications like digitizing human performance involving fast motion. On the
other hand there are available low-cost faster-rate video cameras. This
motivates us to develop a hybrid camera that consists of a high-rate video
camera and a low-rate depth camera, and to allow temporal interpolation of
depth maps with the help of auxiliary color images. To achieve this we develop
a novel algorithm that reconstructs intermediate depth frames and estimates
scene flow simultaneously. We have tested our algorithm on various examples
involving fast, non-rigid motions of single or multiple objects. Our
experiments show that our scene flow estimation method is more precise than
purely tracking based method and the state-of-the-art techniques.
</summary>
    <author>
      <name>Mingze Yuan</name>
    </author>
    <author>
      <name>Lin Gao</name>
    </author>
    <author>
      <name>Hongbo Fu</name>
    </author>
    <author>
      <name>Shihong Xia</name>
    </author>
    <link href="http://arxiv.org/abs/1708.03760v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.03760v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.04820v1</id>
    <updated>2017-08-16T09:06:51Z</updated>
    <published>2017-08-16T09:06:51Z</published>
    <title>Light in Power: A General and Parameter-free Algorithm for Caustic
  Design</title>
    <summary>  We present in this paper a generic and parameter-free algorithm to
efficiently build a wide variety of optical components, such as mirrors or
lenses, that satisfy some light energy constraints. In all of our problems, one
is given a collimated or point light source and a desired illumination after
reflection or refraction and the goal is to design the geometry of a mirror or
lens which transports exactly the light emitted by the source onto the target.
We first propose a general framework and show that eight different optical
component design problems amount to solving a Light Energy Conservation
equation that involves the computation of Visibility diagrams. We show that
these diagrams all have the same structure and can be obtained by intersecting
a 3D Power Diagram with a planar or spherical domain. This allows us to propose
an efficient and fully generic algorithm capable to solve the eight optical
component design problems. Our solutions can satisfy design constraints such as
convexity or concavity and are always graphs over the plane or the sphere. We
show the effectiveness of our algorithm on numerous simulated examples.
</summary>
    <author>
      <name>Quentin Mérigot</name>
    </author>
    <author>
      <name>Jocelyn Meyron</name>
    </author>
    <author>
      <name>Boris Thibert</name>
    </author>
    <link href="http://arxiv.org/abs/1708.04820v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.04820v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.06034v1</id>
    <updated>2017-08-20T23:38:41Z</updated>
    <published>2017-08-20T23:38:41Z</published>
    <title>Perceptual Studies for Foveated Light Field Displays</title>
    <summary>  The human visual system can resolve higher spatial frequencies in the fovea
than in the periphery. This property has been harnessed by recent 2D foveated
rendering methods to reduce computation cost while maintaining perceptual
quality. Inspired by this, we have conducted psycho-physical experiments to
study foveation of human visual systems for 4D light fields and evaluate our
prototype system described in [Sun et al. 2017].
  We measure, for the first time, the blur detection/discrimination and light
field depth perception thresholds in up to 15 degree of visual eccentricity,
and reject the idea of replacing the peripheral rendering with 2D billboards -
4D light fields are still required. The psycho-physical data can also guide
other foveated rendering approaches.
</summary>
    <author>
      <name>Joohwan Kim</name>
    </author>
    <author>
      <name>Qi Sun</name>
    </author>
    <author>
      <name>Fu-Chung Huang</name>
    </author>
    <author>
      <name>Li-Yi Wei</name>
    </author>
    <author>
      <name>David Luebke</name>
    </author>
    <author>
      <name>Arie Kaufman</name>
    </author>
    <link href="http://arxiv.org/abs/1708.06034v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.06034v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.06695v1</id>
    <updated>2017-07-28T08:33:02Z</updated>
    <published>2017-07-28T08:33:02Z</published>
    <title>A two-level approach to implicit surface modeling with compactly
  supported radial basis functions</title>
    <summary>  We describe a two-level method for computing a function whose zero-level set
is the surface reconstructed from given points scattered over the surface and
associated with surface normal vectors. The function is defined as a linear
combination of compactly supported radial basis functions (CSRBFs). The method
preserves the simplicity and efficiency of implicit surface interpolation with
CSRBFs and the reconstructed implicit surface owns the attributes, which are
previously only associated with globally supported or globally regularized
radial basis functions, such as exhibiting less extra zero-level sets, suitable
for inside and outside tests. First, in the coarse scale approximation, we
choose basis function centers on a grid that covers the enlarged bounding box
of the given point set and compute their signed distances to the underlying
surface using local quadratic approximations of the nearest surface points.
Then a fitting to the residual errors on the surface points and additional
off-surface points is performed with fine scale basis functions. The final
function is the sum of the two intermediate functions and is a good
approximation of the signed distance field to the surface in the bounding box.
Examples of surface reconstruction and set operations between shapes are
provided.
</summary>
    <author>
      <name>Rongjiang Pan</name>
    </author>
    <author>
      <name>Vaclav Skala</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Engineering with Computers 2011 27:299-307</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1708.06695v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.06695v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.07391v1</id>
    <updated>2017-08-05T09:43:59Z</updated>
    <published>2017-08-05T09:43:59Z</published>
    <title>A Novel Stretch Energy Minimization Algorithm for Equiareal
  Parameterizations</title>
    <summary>  Surface parameterizations have been widely applied to computer graphics and
digital geometry processing. In this paper, we propose a novel stretch energy
minimization (SEM) algorithm for the computation of equiareal parameterizations
of simply connected open surfaces with a very small area distortion and a
highly improved computational efficiency. In addition, the existence of
nontrivial limit points of the SEM algorithm is guaranteed under some mild
assumptions of the mesh quality. Numerical experiments indicate that the
efficiency, accuracy, and robustness of the proposed SEM algorithm outperform
other state-of-the-art algorithms. Applications of the SEM on surface remeshing
and surface registration for simply connected open surfaces are demonstrated
thereafter. Thanks to the SEM algorithm, the computations for these
applications can be carried out efficiently and robustly.
</summary>
    <author>
      <name>Mei-Heng Yueh</name>
    </author>
    <author>
      <name>Wen-Wei Lin</name>
    </author>
    <author>
      <name>Chin-Tien Wu</name>
    </author>
    <author>
      <name>Shing-Tung Yau</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">29 pages, 15 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1708.07391v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.07391v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.08188v2</id>
    <updated>2017-09-07T23:37:31Z</updated>
    <published>2017-08-28T04:36:03Z</published>
    <title>Active Animations of Reduced Deformable Models with Environment
  Interactions</title>
    <summary>  We present an efficient spacetime optimization method to automatically
generate animations for a general volumetric, elastically deformable body. Our
approach can model the interactions between the body and the environment and
automatically generate active animations. We model the frictional contact
forces using contact invariant optimization and the fluid drag forces using a
simplified model. To handle complex objects, we use a reduced deformable model
and present a novel hybrid optimizer to search for the local minima
efficiently. This allows us to use long-horizon motion planning to
automatically generate animations such as walking, jumping, swimming, and
rolling. We evaluate the approach on different shapes and animations, including
deformable body navigation and combining with an open-loop controller for
realtime forward simulation.
</summary>
    <author>
      <name>Zherong Pan</name>
    </author>
    <author>
      <name>Dinesh Manocha</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1708.08188v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.08188v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.01221v2</id>
    <updated>2017-09-07T21:26:02Z</updated>
    <published>2017-09-05T03:08:01Z</published>
    <title>MLSEB: Edge Bundling using Moving Least Squares Approximation</title>
    <summary>  Edge bundling methods can effectively alleviate visual clutter and reveal
high-level graph structures in large graph visualization. Researchers have
devoted significant efforts to improve edge bundling according to different
metrics. As the edge bundling family evolve rapidly, the quality of edge
bundles receives increasing attention in the literature accordingly. In this
paper, we present MLSEB, a novel method to generate edge bundles based on
moving least squares (MLS) approximation. In comparison with previous edge
bundling methods, we argue that our MLSEB approach can generate better results
based on a quantitative metric of quality, and also ensure scalability and the
efficiency for visualizing large graphs.
</summary>
    <author>
      <name>Jieting Wu</name>
    </author>
    <author>
      <name>Jianping Zeng</name>
    </author>
    <author>
      <name>Feiyu Zhu</name>
    </author>
    <author>
      <name>Hongfeng Yu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in the Proceedings of the 25th International Symposium on
  Graph Drawing and Network Visualization (GD 2017)</arxiv:comment>
    <link href="http://arxiv.org/abs/1709.01221v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.01221v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.01250v1</id>
    <updated>2017-09-05T06:24:02Z</updated>
    <published>2017-09-05T06:24:02Z</published>
    <title>Sparse Data Driven Mesh Deformation</title>
    <summary>  Example-based mesh deformation methods are powerful tools for realistic shape
editing. However, existing techniques typically combine all the example
deformation modes, which can lead to overfitting, i.e. using a overly
complicated model to explain the user-specified deformation. This leads to
implausible or unstable deformation results, including unexpected global
changes outside the region of interest. To address this fundamental limitation,
we propose a sparse blending method that automatically selects a smaller number
of deformation modes to compactly describe the desired deformation. This along
with a suitably chosen deformation basis including spatially localized
deformation modes leads to significant advantages, including more meaningful,
reliable, and efficient deformations because fewer and localized deformation
modes are applied. To cope with large rotations, we develop a simple but
effective representation based on polar decomposition of deformation gradients,
which resolves the ambiguity of large global rotations using an
as-consistent-as-possible global optimization. This simple representation has a
closed form solution for derivatives, making it efficient for sparse localized
representation and thus ensuring interactive performance. Experimental results
show that our method outperforms state-of-the-art data-driven mesh deformation
methods, for both quality of results and efficiency.
</summary>
    <author>
      <name>Lin Gao</name>
    </author>
    <author>
      <name>Yu-Kun Lai</name>
    </author>
    <author>
      <name>Jie Yang</name>
    </author>
    <author>
      <name>Ling-Xiao Zhang</name>
    </author>
    <author>
      <name>Leif Kobbelt</name>
    </author>
    <author>
      <name>Shihong Xia</name>
    </author>
    <link href="http://arxiv.org/abs/1709.01250v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.01250v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.01638v1</id>
    <updated>2017-09-06T00:47:54Z</updated>
    <published>2017-09-06T00:47:54Z</published>
    <title>360 Panorama Cloning on Sphere</title>
    <summary>  In this paper, we address a novel problem of cloning a patch of the source
spherical panoramic image to the target spherical panoramic image, which we
call 360 panorama cloning. Considering the sphere geometry constraint embedded
in spherical panoramic images, we develop a coordinate-based method that
directly clones in the spherical domain. Our method neither differentiates the
polar regions and equatorial regions, nor identifies the boundaries in the
unrolled planar-formatted panorama. We discuss in depth two unique issues in
panorama cloning, i.e. preserving the patch's orientation, and handling the
large-patch cloning (covering over 180 field of view) which may suffer from
discoloration artifacts. As experimental results demonstrate, our method is
able to get visually pleasing cloning results and achieve real time cloning
performance.
</summary>
    <author>
      <name>Qiang Zhao</name>
    </author>
    <author>
      <name>Liang Wan</name>
    </author>
    <author>
      <name>Wei Feng</name>
    </author>
    <author>
      <name>Jiawan Zhang</name>
    </author>
    <author>
      <name>Tien-Tsin Wong</name>
    </author>
    <link href="http://arxiv.org/abs/1709.01638v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.01638v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.02782v1</id>
    <updated>2017-09-04T18:30:54Z</updated>
    <published>2017-09-04T18:30:54Z</published>
    <title>Global spectral graph wavelet signature for surface analysis of carpal
  bones</title>
    <summary>  In this paper, we present a spectral graph wavelet approach for shape
analysis of carpal bones of human wrist. We apply a metric called global
spectral graph wavelet signature for representation of cortical surface of the
carpal bone based on eigensystem of Laplace-Beltrami operator. Furthermore, we
propose a heuristic and efficient way of aggregating local descriptors of a
carpal bone surface to global descriptor. The resultant global descriptor is
not only isometric invariant, but also much more efficient and requires less
memory storage. We perform experiments on shape of the carpal bones of ten
women and ten men from a publicly-available database. Experimental results show
the excellency of the proposed GSGW compared to recent proposed GPS embedding
approach for comparing shapes of the carpal bones across populations.
</summary>
    <author>
      <name>Majid Masoumi</name>
    </author>
    <author>
      <name>A. Ben Hamza</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: substantial text overlap with arXiv:1705.06250</arxiv:comment>
    <link href="http://arxiv.org/abs/1709.02782v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.02782v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.04304v1</id>
    <updated>2017-09-13T12:59:48Z</updated>
    <published>2017-09-13T12:59:48Z</published>
    <title>Mesh-based Autoencoders for Localized Deformation Component Analysis</title>
    <summary>  Spatially localized deformation components are very useful for shape analysis
and synthesis in 3D geometry processing. Several methods have recently been
developed, with an aim to extract intuitive and interpretable deformation
components. However, these techniques suffer from fundamental limitations
especially for meshes with noise or large-scale deformations, and may not
always be able to identify important deformation components. In this paper we
propose a novel mesh-based autoencoder architecture that is able to cope with
meshes with irregular topology. We introduce sparse regularization in this
framework, which along with convolutional operations, helps localize
deformations. Our framework is capable of extracting localized deformation
components from mesh data sets with large-scale deformations and is robust to
noise. It also provides a nonlinear approach to reconstruction of meshes using
the extracted basis, which is more effective than the current linear
combination approach. Extensive experiments show that our method outperforms
state-of-the-art methods in both qualitative and quantitative evaluations.
</summary>
    <author>
      <name>Qingyang Tan</name>
    </author>
    <author>
      <name>Lin Gao</name>
    </author>
    <author>
      <name>Yu-Kun Lai</name>
    </author>
    <author>
      <name>Jie Yang</name>
    </author>
    <author>
      <name>Shihong Xia</name>
    </author>
    <link href="http://arxiv.org/abs/1709.04304v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.04304v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.04307v1</id>
    <updated>2017-09-13T13:09:22Z</updated>
    <published>2017-09-13T13:09:22Z</published>
    <title>Variational Autoencoders for Deforming 3D Mesh Models</title>
    <summary>  3D geometric contents are becoming increasingly popular. In this paper, we
study the problem of analyzing deforming 3D meshes using deep neural networks.
Deforming 3D meshes are flexible to represent 3D animation sequences as well as
collections of objects of the same category, allowing diverse shapes with
large-scale non-linear deformations. We propose a novel framework which we call
mesh variational autoencoders (mesh VAE), to explore the probabilistic latent
space of 3D surfaces. The framework is easy to train, and requires very few
training examples. We also propose an extended model which allows flexibly
adjusting the significance of different latent variables by altering the prior
distribution. Extensive experiments demonstrate that our general framework is
able to learn a reasonable representation for a collection of deformable
shapes, and produce competitive results for a variety of applications,
including shape generation, shape interpolation, shape space embedding and
shape exploration, outperforming state-of-the-art methods.
</summary>
    <author>
      <name>Qingyang Tan</name>
    </author>
    <author>
      <name>Lin Gao</name>
    </author>
    <author>
      <name>Yu-Kun Lai</name>
    </author>
    <author>
      <name>Shihong Xia</name>
    </author>
    <link href="http://arxiv.org/abs/1709.04307v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.04307v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.07581v1</id>
    <updated>2017-09-22T03:17:34Z</updated>
    <published>2017-09-22T03:17:34Z</published>
    <title>Hierarchical Detail Enhancing Mesh-Based Shape Generation with 3D
  Generative Adversarial Network</title>
    <summary>  Automatic mesh-based shape generation is of great interest across a wide
range of disciplines, from industrial design to gaming, computer graphics and
various other forms of digital art. While most traditional methods focus on
primitive based model generation, advances in deep learning made it possible to
learn 3-dimensional geometric shape representations in an end-to-end manner.
However, most current deep learning based frameworks focus on the
representation and generation of voxel and point-cloud based shapes, making it
not directly applicable to design and graphics communities. This study
addresses the needs for automatic generation of mesh-based geometries, and
propose a novel framework that utilizes signed distance function representation
that generates detail preserving three-dimensional surface mesh by a deep
learning based approach.
</summary>
    <author>
      <name>Chiyu "Max" Jiang</name>
    </author>
    <author>
      <name>Philip Marcus</name>
    </author>
    <link href="http://arxiv.org/abs/1709.07581v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.07581v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.08774v1</id>
    <updated>2017-09-26T01:15:26Z</updated>
    <published>2017-09-26T01:15:26Z</published>
    <title>Exploring the Design Space of Immersive Urban Analytics</title>
    <summary>  Recent years have witnessed the rapid development and wide adoption of
immersive head-mounted devices, such as HTC VIVE, Oculus Rift, and Microsoft
HoloLens. These immersive devices have the potential to significantly extend
the methodology of urban visual analytics by providing critical 3D context
information and creating a sense of presence. In this paper, we propose an
theoretical model to characterize the visualizations in immersive urban
analytics. Further more, based on our comprehensive and concise model, we
contribute a typology of combination methods of 2D and 3D visualizations that
distinguish between linked views, embedded views, and mixed views. We also
propose a supporting guideline to assist users in selecting a proper view under
certain circumstances by considering visual geometry and spatial distribution
of the 2D and 3D visualizations. Finally, based on existing works, possible
future research opportunities are explored and discussed.
</summary>
    <author>
      <name>Zhutian Chen</name>
    </author>
    <author>
      <name>Yifang Wang</name>
    </author>
    <author>
      <name>Tianchen Sun</name>
    </author>
    <author>
      <name>Xiang Gao</name>
    </author>
    <author>
      <name>Wei Chen</name>
    </author>
    <author>
      <name>Zhigeng Pan</name>
    </author>
    <author>
      <name>Huamin Qu</name>
    </author>
    <author>
      <name>Yingcai Wu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">23 pages,11 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1709.08774v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.08774v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.09701v1</id>
    <updated>2017-09-27T18:58:56Z</updated>
    <published>2017-09-27T18:58:56Z</published>
    <title>Functional Characterization of Deformation Fields</title>
    <summary>  In this paper we present a novel representation for deformation fields of 3D
shapes, by considering the induced changes in the underlying metric. In
particular, our approach allows to represent a deformation field in a
coordinate-free way as a linear operator acting on real-valued functions
defined on the shape. Such a representation both provides a way to relate
deformation fields to other classical functional operators and enables analysis
and processing of deformation fields using standard linear-algebraic tools.
This opens the door to a wide variety of applications such as explicitly adding
extrinsic information into the computation of functional maps, intrinsic shape
symmetrization, joint deformation design through precise control of metric
distortion, and coordinate-free deformation transfer without requiring
pointwise correspondences. Our method is applicable to both surface and
volumetric shape representations and we guarantee the equivalence between the
operator-based and standard deformation field representation under mild
genericity conditions in the discrete setting. We demonstrate the utility of
our approach by comparing it with existing techniques and show how our
representation provides a powerful toolbox for a wide variety of challenging
problems.
</summary>
    <author>
      <name>Etienne Corman</name>
    </author>
    <author>
      <name>Maks Ovsjanikov</name>
    </author>
    <link href="http://arxiv.org/abs/1709.09701v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.09701v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1710.01802v1</id>
    <updated>2017-09-19T22:57:31Z</updated>
    <published>2017-09-19T22:57:31Z</published>
    <title>Automatic Structural Scene Digitalization</title>
    <summary>  In this paper, we present an automatic system for the analysis and labeling
of structural scenes, floor plan drawings in Computer-aided Design (CAD)
format. The proposed system applies a fusion strategy to detect and recognize
various components of CAD floor plans, such as walls, doors, windows and other
ambiguous assets. Technically, a general rule-based filter parsing method is
fist adopted to extract effective information from the original floor plan.
Then, an image-processing based recovery method is employed to correct
information extracted in the first step. Our proposed method is fully automatic
and real-time. Such analysis system provides high accuracy and is also
evaluated on a public website that, on average, archives more than ten
thousands effective uses per day and reaches a relatively high satisfaction
rate.
</summary>
    <author>
      <name>Rui Tang</name>
    </author>
    <author>
      <name>Yuhan Wang</name>
    </author>
    <author>
      <name>Darren Cosker</name>
    </author>
    <author>
      <name>Wenbin Li</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">paper submitted to PloS One</arxiv:comment>
    <link href="http://arxiv.org/abs/1710.01802v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1710.01802v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0109116v1</id>
    <updated>2001-09-26T22:14:40Z</updated>
    <published>2001-09-26T22:14:40Z</published>
    <title>Digital Color Imaging</title>
    <summary>  This paper surveys current technology and research in the area of digital
color imaging. In order to establish the background and lay down terminology,
fundamental concepts of color perception and measurement are first presented
us-ing vector-space notation and terminology. Present-day color recording and
reproduction systems are reviewed along with the common mathematical models
used for representing these devices. Algorithms for processing color images for
display and communication are surveyed, and a forecast of research trends is
attempted. An extensive bibliography is provided.
</summary>
    <author>
      <name>Gaurav Sharma</name>
    </author>
    <author>
      <name>H. Joel Trussell</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/83.597268</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/83.597268" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE Trans. Image Proc., vol. 6, no. 7, pp. 901-932, Jul. 1997</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0109116v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0109116v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="A.1;I.4,I.3.3,I.2.10;I.3.7;B.4.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0212007v1</id>
    <updated>2002-12-06T21:59:17Z</updated>
    <published>2002-12-06T21:59:17Z</published>
    <title>Optimized Color Gamuts for Tiled Displays</title>
    <summary>  We consider the problem of finding a large color space that can be generated
by all units in multi-projector tiled display systems. Viewing the problem
geometrically as one of finding a large parallelepiped within the intersection
of multiple parallelepipeds, and using colorimetric principles to define a
volume-based objective function for comparing feasible solutions, we develop an
algorithm for finding the optimal gamut in time O(n^3), where n denotes the
number of projectors in the system. We also discuss more efficient quasiconvex
programming algorithms for alternative objective functions based on maximizing
the quality of the color space extrema.
</summary>
    <author>
      <name>Marshall Bern</name>
    </author>
    <author>
      <name>David Eppstein</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0212007v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0212007v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.2.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0306087v1</id>
    <updated>2003-06-14T05:42:43Z</updated>
    <published>2003-06-14T05:42:43Z</published>
    <title>OO Model of the STAR offline production "Event Display" and its
  implementation based on Qt-ROOT</title>
    <summary>  The paper presents the "Event Display" package for the STAR offline
production as a special visualization tool to debug the reconstruction code.
This can be achieved if an author of the algorithm / code may build his/her own
custom Event Display alone from the base software blocks and re-used some
well-designed, easy to learn user-friendly patterns. For STAR offline
production Event Display ROOT with Qt lower level interface was chosen as the
base tools.
</summary>
    <author>
      <name>Valeri Fine</name>
    </author>
    <author>
      <name>Jerome Lauret</name>
    </author>
    <author>
      <name>Victor Perevoztchikov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3 pages, 4 figures, Computing in High Energy Physics, CHEP2003, La
  Jolla California, USA, March 24-28</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0306087v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0306087v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.7; D.1.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0310008v1</id>
    <updated>2003-10-06T14:20:00Z</updated>
    <published>2003-10-06T14:20:00Z</published>
    <title>Poster on MPI application in Computational Fluid Dynamics</title>
    <summary>  Poster-presentation of the paper "Message Passing Fluids: molecules as
processes in parallel computational fluids" held at "EURO PVMMPI 2003"
Congress; the paper is on the proceedings "Recent Advances in Parallel Virtual
Machine and Message Passing Interface", 10th European PVM/MPI User's Group
Meeting, LNCS 2840, Springer-Verlag, Dongarra-Laforenza-Orlando editors, pp.
550-554.
</summary>
    <author>
      <name>Gianluca Argentini</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">1 page, PDF version of a poster-session presentation during
  "EuroPVM/MPI 2003", Sep. 29 - Oct. 2, Venice (Italy), please visit
  http://www.dsi.unive.it/pvmmpi03</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0310008v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0310008v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.1.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0603115v1</id>
    <updated>2006-03-29T11:48:29Z</updated>
    <published>2006-03-29T11:48:29Z</published>
    <title>Implementation of float-float operators on graphics hardware</title>
    <summary>  The Graphic Processing Unit (GPU) has evolved into a powerful and flexible
processor. The latest graphic processors provide fully programmable vertex and
pixel processing units that support vector operations up to single
floating-point precision. This computational power is now being used for
general-purpose computations. However, some applications require higher
precision than single precision. This paper describes the emulation of a 44-bit
floating-point number format and its corresponding operations. An
implementation is presented along with performance and accuracy results.
</summary>
    <author>
      <name>Guillaume Da Graçca</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LP2A</arxiv:affiliation>
    </author>
    <author>
      <name>David Defour</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LP2A</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/cs/0603115v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0603115v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0606056v1</id>
    <updated>2006-06-13T00:47:34Z</updated>
    <published>2006-06-13T00:47:34Z</published>
    <title>Fast and Simple Methods For Computing Control Points</title>
    <summary>  The purpose of this paper is to present simple and fast methods for computing
control points for polynomial curves and polynomial surfaces given explicitly
in terms of polynomials (written as sums of monomials). We give recurrence
formulae w.r.t. arbitrary affine frames. As a corollary, it is amusing that we
can also give closed-form expressions in the case of the frame (r, s) for
curves, and the frame ((1, 0, 0), (0, 1, 0), (0, 0, 1) for surfaces. Our
methods have the same low polynomial (time and space) complexity as the other
best known algorithms, and are very easy to implement.
</summary>
    <author>
      <name>Jean Gallier</name>
    </author>
    <author>
      <name>Weqing Gu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0606056v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0606056v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0606061v1</id>
    <updated>2006-06-13T15:09:24Z</updated>
    <published>2006-06-13T15:09:24Z</published>
    <title>On the Efficiency of Strategies for Subdividing Polynomial Triangular
  Surface Patches</title>
    <summary>  In this paper, we investigate the efficiency of various strategies for
subdividing polynomial triangular surface patches. We give a simple algorithm
performing a regular subdivision in four calls to the standard de Casteljau
algorithm (in its subdivision version). A naive version uses twelve calls. We
also show that any method for obtaining a regular subdivision using the
standard de Casteljau algorithm requires at least 4 calls. Thus, our method is
optimal. We give another subdivision algorithm using only three calls to the de
Casteljau algorithm. Instead of being regular, the subdivision pattern is
diamond-like. Finally, we present a ``spider-like'' subdivision scheme
producing six subtriangles in four calls to the de Casteljau algorithm.
</summary>
    <author>
      <name>Jean Gallier</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0606061v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0606061v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0703088v1</id>
    <updated>2007-03-16T00:18:11Z</updated>
    <published>2007-03-16T00:18:11Z</published>
    <title>Plot 94 in ambiance X-Window</title>
    <summary>  &lt;PLOT &gt; is a collection of routines to draw surfaces, contours and so on. In
this work we are presenting a version, that functions over work stations with
the operative system UNIX, that count with the graphic ambiance X-WINDOW with
the tools XLIB and OSF/MOTIF. This implant was realized for the work stations
DEC 5000-200, DEC IPX, and DEC ALFA of the CINVESTAV (Center of Investigation
and Advanced Studies). Also implanted in SILICON GRAPHICS of the CENAC
(National Center of Calculation of the Polytechnic National Institute
</summary>
    <author>
      <name>Ignacio Vega-Paez</name>
    </author>
    <author>
      <name>Carlos Alberto Hernandez-Hernandez</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings in Information Systems Analysis and Synthesis ISAS
  1995, 5th, International Symposium on Systems Research, Informatics and
  Cybernetics, pp. 135-139, August 16-20, 95, Baden-Baden, Germany</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0703088v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0703088v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/math/0608789v7</id>
    <updated>2006-11-11T16:25:24Z</updated>
    <published>2006-08-31T14:59:20Z</published>
    <title>One method for proving inequalities by computer</title>
    <summary>  In this article we consider a method for proving a class of analytical
inequalities via minimax rational approximations. All numerical calculations in
this paper are given by Maple computer program.
</summary>
    <author>
      <name>Branko J. Malesevic</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted in Journal of Inequalities and Applications</arxiv:comment>
    <link href="http://arxiv.org/abs/math/0608789v7" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/math/0608789v7" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.CA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.GM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="26Dxx, 33F05, 41A20" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/quant-ph/0602063v2</id>
    <updated>2006-05-22T17:10:49Z</updated>
    <published>2006-02-06T10:43:50Z</published>
    <title>Topological Quantum Error Correction with Optimal Encoding Rate</title>
    <summary>  We prove the existence of topological quantum error correcting codes with
encoding rates $k/n$ asymptotically approaching the maximum possible value.
Explicit constructions of these topological codes are presented using surfaces
of arbitrary genus. We find a class of regular toric codes that are optimal.
For physical implementations, we present planar topological codes.
</summary>
    <author>
      <name>H. Bombin</name>
    </author>
    <author>
      <name>M. A. Martin-Delgado</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1103/PhysRevA.73.062303</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1103/PhysRevA.73.062303" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">REVTEX4 file, 5 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Phys.Rev.A73:062303,2006</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/quant-ph/0602063v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/quant-ph/0602063v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.str-el" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="hep-th" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.AT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.MP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0802.1617v1</id>
    <updated>2008-02-12T11:06:38Z</updated>
    <published>2008-02-12T11:06:38Z</published>
    <title>Discrete Complex Structure on Surfel Surfaces</title>
    <summary>  This paper defines a theory of conformal parametrization of digital surfaces
made of surfels equipped with a normal vector. The main idea is to locally
project each surfel to the tangent plane, therefore deforming its aspect-ratio.
It is a generalization of the theory known for polyhedral surfaces. The main
difference is that the conformal ratios that appear are no longer real in
general. It yields a generalization of the standard Laplacian on weighted
graphs.
</summary>
    <author>
      <name>Christian Mercat</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">I3M</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Dans 14th IAPR International Conference on Discrete Geometry for
  Computer Imagery - 14th IAPR International Conference on Discrete Geometry
  for Computer Imagery, Lyon : France (2008)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0802.1617v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0802.1617v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0804.1046v1</id>
    <updated>2008-04-07T14:47:03Z</updated>
    <published>2008-04-07T14:47:03Z</published>
    <title>Discrete schemes for Gaussian curvature and their convergence</title>
    <summary>  In this paper, several discrete schemes for Gaussian curvature are surveyed.
The convergence property of a modified discrete scheme for the Gaussian
curvature is considered. Furthermore, a new discrete scheme for Gaussian
curvature is resented. We prove that the new scheme converges at the regular
vertex with valence not less than 5. By constructing a counterexample, we also
show that it is impossible for building a discrete scheme for Gaussian
curvature which converges over the regular vertex with valence 4. Finally,
asymptotic errors of several discrete scheme for Gaussian curvature are
compared.
</summary>
    <author>
      <name>Zhiqiang Xu</name>
    </author>
    <author>
      <name>Guoliang Xu</name>
    </author>
    <link href="http://arxiv.org/abs/0804.1046v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0804.1046v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0810.3418v1</id>
    <updated>2008-10-19T18:04:51Z</updated>
    <published>2008-10-19T18:04:51Z</published>
    <title>Detecting the Most Unusual Part of a Digital Image</title>
    <summary>  The purpose of this paper is to introduce an algorithm that can detect the
most unusual part of a digital image. The most unusual part of a given shape is
defined as a part of the image that has the maximal distance to all non
intersecting shapes with the same form.
  The method can be used to scan image databases with no clear model of the
interesting part or large image databases, as for example medical databases.
</summary>
    <author>
      <name>K. Koroutchev</name>
    </author>
    <author>
      <name>E. Korutcheva</name>
    </author>
    <link href="http://arxiv.org/abs/0810.3418v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0810.3418v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0903.1448v1</id>
    <updated>2009-03-09T08:06:09Z</updated>
    <published>2009-03-09T08:06:09Z</published>
    <title>The Digital Restoration of Da Vinci's Sketches</title>
    <summary>  A sketch, found in one of Leonardo da Vinci's notebooks and covered by the
written notes of this genius, has been recently restored. The restoration
reveals a possible self-portrait of the artist, drawn when he was young. Here,
we discuss the discovery of this self-portrait and the procedure used for
restoration. Actually, this is a restoration performed on the digital image of
the sketch, a procedure that can easily extended and applied to ancient
documents for studies of art and palaeography.
</summary>
    <author>
      <name>Amelia Sparavigna</name>
    </author>
    <link href="http://arxiv.org/abs/0903.1448v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0903.1448v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0903.2119v1</id>
    <updated>2009-03-12T10:16:13Z</updated>
    <published>2009-03-12T10:16:13Z</published>
    <title>Adaptive Mesh Approach for Predicting Algorithm Behavior with
  Application to Visibility Culling in Computer Graphics</title>
    <summary>  We propose a concise approximate description, and a method for efficiently
obtaining this description, via adaptive random sampling of the performance
(running time, memory consumption, or any other profileable numerical quantity)
of a given algorithm on some low-dimensional rectangular grid of inputs. The
formal correctness is proven under reasonable assumptions on the algorithm
under consideration; and the approach's practical benefit is demonstrated by
predicting for which observer positions and viewing directions an occlusion
culling algorithm yields a net performance benefit or loss compared to a simple
brute force renderer.
</summary>
    <author>
      <name>Matthias Fischer</name>
    </author>
    <author>
      <name>Claudius Jähn</name>
    </author>
    <author>
      <name>Martin Ziegler</name>
    </author>
    <link href="http://arxiv.org/abs/0903.2119v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0903.2119v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="C.4; I.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0906.3224v1</id>
    <updated>2009-06-17T16:07:01Z</updated>
    <published>2009-06-17T16:07:01Z</published>
    <title>Personal applications, based on moveable / resizable elements</title>
    <summary>  All the modern day applications have the interface, absolutely defined by the
developers. The use of adaptive interface or dynamic layout allows some
variations, but even all of them are predetermined on the design stage, because
the best reaction (from designer's view) on any possible users' movement was
hardcoded. But there is a different world of applications, totally constructed
on moveable / resizable elements; such applications turn the full control to
the users. The crucial thing in such programs is that not something but
everything must become moveable and resizable. This article describes the
features of such applications and the algorithm behind their design.
</summary>
    <author>
      <name>Sergey Andreyev</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 12 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0906.3224v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0906.3224v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1002.4317v1</id>
    <updated>2010-02-23T12:32:34Z</updated>
    <published>2010-02-23T12:32:34Z</published>
    <title>CLD-shaped Brushstrokes in Non-Photorealistic Rendering</title>
    <summary>  Rendering techniques based on a random grid can be improved by adapting
brushstrokes to the shape of different areas of the original picture. In this
paper, the concept of Coherence Length Diagram is applied to determine the
adaptive brushstrokes, in order to simulate an impressionist painting. Some
examples are provided to instance the proposed algorithm.
</summary>
    <author>
      <name>Amelia Carolina Sparavigna</name>
    </author>
    <author>
      <name>Roberto Marazzato</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Keywords: Image processing, Non-photorealistic processing,
  Image-based rendering Coherence Length Diagram</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Software Engineering and Computing, 2011,
  Volume 3, Issue 1, Pages 11-15</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1002.4317v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1002.4317v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1004.0258v1</id>
    <updated>2010-04-01T23:48:23Z</updated>
    <published>2010-04-01T23:48:23Z</published>
    <title>Trends and Techniques in Visual Gaze Analysis</title>
    <summary>  Visualizing gaze data is an effective way for the quick interpretation of eye
tracking results. This paper presents a study investigation benefits and
limitations of visual gaze analysis among eye tracking professionals and
researchers. The results were used to create a tool for visual gaze analysis
within a Master's project.
</summary>
    <author>
      <name>Sophie Stellmach</name>
    </author>
    <author>
      <name>Lennart E. Nacke</name>
    </author>
    <author>
      <name>Raimund Dachselt</name>
    </author>
    <author>
      <name>Craig A. Lindley</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">pages 89-93, The 5th Conference on Communication by Gaze Interaction
  - COGAIN 2009: Gaze Interaction For Those Who Want It Most, ISBN:
  978-87-643-0475-6</arxiv:comment>
    <link href="http://arxiv.org/abs/1004.0258v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1004.0258v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="00A66" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.1; I.4.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1005.3992v2</id>
    <updated>2010-06-26T21:43:47Z</updated>
    <published>2010-05-19T11:26:36Z</published>
    <title>Groebner bases in Java with applications in computer graphics</title>
    <summary>  In this paper we present a Java implementation of the algorithm that computes
Buchbereger's and reduced Groebner's basis step by step. The Java application
enables graphical representation of the intersection of two surfaces in
3-dimensional space and determines conditions of existence and planarity of the
intersection.
</summary>
    <author>
      <name>Branko J. Malesevic</name>
    </author>
    <author>
      <name>Ivana V. Jovovic</name>
    </author>
    <author>
      <name>Milan Z. Campara</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">International convention on Descriptive Geometry and Engineering
  Graphics moNGeometrija 2010, http://www.mongeometrija.org/</arxiv:comment>
    <link href="http://arxiv.org/abs/1005.3992v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1005.3992v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.MG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.RA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1009.2231v2</id>
    <updated>2010-09-16T11:43:20Z</updated>
    <published>2010-09-12T11:56:13Z</published>
    <title>Symbolic landforms created by ancient earthworks near Lake Titicaca</title>
    <summary>  Interesting landforms created by an ancient network of earthworks are shown,
using Google satellite imagery enhanced by an image processing. This network
covers a large part of the land near the Titicaca Lake. Satellite images
clearly display the slopes of hills criss-crossed with terrace walls and the
surfaces of the plains covered with raised fields, indicating that this was
once a highly productive agricultural place for the south central Andes. Some
of the landforms are rather remarkable, having a clear symbolic function. Among
them, there are structures which seem to represent birds, where ponds are their
eyes.
</summary>
    <author>
      <name>Amelia Carolina Sparavigna</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Keywords: Satellite maps, Landforms, Artificial landforms,
  Geo-glyphs, Image processing, Archaeology</arxiv:comment>
    <link href="http://arxiv.org/abs/1009.2231v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1009.2231v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.geo-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1012.0467v1</id>
    <updated>2010-12-02T16:01:21Z</updated>
    <published>2010-12-02T16:01:21Z</published>
    <title>MT4j - A Cross-platform Multi-touch Development Framework</title>
    <summary>  This article describes requirements and challenges of crossplatform
multi-touch software engineering, and presents the open source framework
Multi-Touch for Java (MT4j) as a solution. MT4j is designed for rapid
development of graphically rich applications on a variety of contemporary
hardware, from common PCs and notebooks to large-scale ambient displays, as
well as different operating systems. The framework has a special focus on
making multi-touch software development easier and more efficient. Architecture
and abstractions used by MT4j are described, and implementations of several
common use cases are presented.
</summary>
    <author>
      <name>Uwe Laufs</name>
    </author>
    <author>
      <name>Christopher Ruff</name>
    </author>
    <author>
      <name>Jan Zibuschka</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ACM EICS 2010, Workshop: Engineering patterns for multi-touch
  interfaces (2010), p. 52-57</arxiv:comment>
    <link href="http://arxiv.org/abs/1012.0467v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1012.0467v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.2; D.2.11; D.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.5028v2</id>
    <updated>2013-06-06T19:56:55Z</updated>
    <published>2011-03-25T16:45:22Z</published>
    <title>User guide to TIM, a ray-tracing program for forbidden ray optics</title>
    <summary>  This user guide outlines the use of TIM, an interactive ray-tracing program
with a number of special powers. TIM can be customised and embedded into
internet pages, making it suitable not only for research but also for its
dissemination.
</summary>
    <author>
      <name>Dean Lambert</name>
    </author>
    <author>
      <name>Alasdair C. Hamilton</name>
    </author>
    <author>
      <name>George Constable</name>
    </author>
    <author>
      <name>Harsh Snehanshu</name>
    </author>
    <author>
      <name>Sharvil Talati</name>
    </author>
    <author>
      <name>Johannes Courtial</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages, 15 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1103.5028v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.5028v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.ed-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ed-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1108.3529v1</id>
    <updated>2011-08-17T17:22:46Z</updated>
    <published>2011-08-17T17:22:46Z</published>
    <title>Fat Triangulations and Differential Geometry</title>
    <summary>  We study the differential geometric consequences of our previous result on
the existence of fat triangulations, in conjunction with a result of Cheeger,
M\"{u}ller and Schrader, regarding the convergence of Lipschitz-Killing
curvatures of piecewise-flat approximations of smooth Riemannian manifolds. A
further application to the existence of quasiconformal mappings between
manifolds, as well as an extension of the triangulation result to the case of
almost Riemannian manifolds, are also given. In addition, the notion of fatness
of triangulations and its relation to metric curvature and to excess is
explored. Moreover, applications of the main results, and in particular a
purely metric approach to Regge calculus, are also investigated.
</summary>
    <author>
      <name>Emil Saucan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">29 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1108.3529v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1108.3529v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.DG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="Primary: 53C23, 83C27, 57Q15, Secondary: 30C65, 68U05" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1108.5673v1</id>
    <updated>2011-08-29T17:56:15Z</updated>
    <published>2011-08-29T17:56:15Z</published>
    <title>Partial wave analysis at BES III harnessing the power of GPUs</title>
    <summary>  Partial wave analysis is a core tool in hadron spectroscopy. With the high
statistics data available at facilities such as the Beijing Spectrometer III,
this procedure becomes computationally very expensive. We have successfully
implemented a framework for performing partial wave analysis on graphics
processors. We discuss the implementation, the parallel computing frameworks
employed and the performance achieved, with a focus on the recent transition to
the OpenCL framework.
</summary>
    <author>
      <name>Niklaus Berger</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1063/1.3647201</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1063/1.3647201" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 2 figures, prepared for the proceedings of Computing in High
  Energy Physics (CHEP) 2010</arxiv:comment>
    <link href="http://arxiv.org/abs/1108.5673v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1108.5673v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="hep-ex" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1109.6288v1</id>
    <updated>2011-09-28T18:35:51Z</updated>
    <published>2011-09-28T18:35:51Z</published>
    <title>Using Stereoscopic 3D Technologies for the Diagnosis and Treatment of
  Amblyopia in Children</title>
    <summary>  The 3D4Amb project aims at developing a system based on the stereoscopic 3D
techonlogy, like the NVIDIA 3D Vision, for the diagnosis and treatment of
amblyopia in young children. It exploits the active shutter technology to
provide binocular vision, i.e. to show different images to the amblyotic (or
lazy) and the normal eye. It would allow easy diagnosis of amblyopia and its
treatment by means of interactive games or other entertainment activities. It
should not suffer from the compliance problems of the classical treatment, it
is suitable to domestic use, and it could at least partially substitute
occlusion or patching of the normal eye.
</summary>
    <author>
      <name>Angelo Gargantini</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Extended version of the HEALTHINF 2011 paper</arxiv:comment>
    <link href="http://arxiv.org/abs/1109.6288v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1109.6288v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1201.2936v1</id>
    <updated>2012-01-13T17:48:47Z</updated>
    <published>2012-01-13T17:48:47Z</published>
    <title>Finding Convex Hulls Using Quickhull on the GPU</title>
    <summary>  We present a convex hull algorithm that is accelerated on commodity graphics
hardware. We analyze and identify the hurdles of writing a recursive divide and
conquer algorithm on the GPU and divise a framework for representing this class
of problems. Our framework transforms the recursive splitting step into a
permutation step that is well-suited for graphics hardware. Our convex hull
algorithm of choice is Quickhull. Our parallel Quickhull implementation (for
both 2D and 3D cases) achieves an order of magnitude speedup over standard
computational geometry libraries.
</summary>
    <author>
      <name>Stanley Tzeng</name>
    </author>
    <author>
      <name>John D. Owens</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1201.2936v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1201.2936v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.1968v4</id>
    <updated>2012-10-02T07:54:53Z</updated>
    <published>2012-06-09T20:04:38Z</published>
    <title>A novel 2.5D approach for interfacing with web applications</title>
    <summary>  Web applications need better user interface to be interactive and attractive.
A new approach/concept of dimensional enhancement - 2.5D "a 2D display of a
virtual 3D environment", which can be implemented in social networking sites
and further in other system applications.
</summary>
    <author>
      <name>Saurabh Sarkar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">An approach offering a new idea for Human Computer Interaction,
  including 3 pages and 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.1968v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.1968v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.4634v1</id>
    <updated>2012-06-18T15:14:24Z</updated>
    <published>2012-06-18T15:14:24Z</published>
    <title>Artist Agent: A Reinforcement Learning Approach to Automatic Stroke
  Generation in Oriental Ink Painting</title>
    <summary>  Oriental ink painting, called Sumi-e, is one of the most appealing painting
styles that has attracted artists around the world. Major challenges in
computer-based Sumi-e simulation are to abstract complex scene information and
draw smooth and natural brush strokes. To automatically find such strokes, we
propose to model the brush as a reinforcement learning agent, and learn desired
brush-trajectories by maximizing the sum of rewards in the policy search
framework. We also provide elaborate design of actions, states, and rewards
tailored for a Sumi-e agent. The effectiveness of our proposed approach is
demonstrated through simulated Sumi-e experiments.
</summary>
    <author>
      <name>Ning Xie</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Tokyo Institute of Technology</arxiv:affiliation>
    </author>
    <author>
      <name>Hirotaka Hachiya</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Tokyo Institute of Technology</arxiv:affiliation>
    </author>
    <author>
      <name>Masashi Sugiyama</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Tokyo Institute of Technology</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1587/transinf.E96.D.1134</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1587/transinf.E96.D.1134" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICML2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.4634v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.4634v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1208.5124v1</id>
    <updated>2012-08-25T10:45:55Z</updated>
    <published>2012-08-25T10:45:55Z</published>
    <title>A Novel Data Hiding Scheme for Binary Images</title>
    <summary>  This paper presents a new scheme for hiding a secret message in binary
images. Given m*n cover image block, the new scheme can conceal as many as
log(m*n +1) bits of data in block, by changing at most one bit in the block.
The hiding ability of the new scheme is the same as Chang et al.'s scheme and
higher than Tseng et al.'s scheme. Additionally, the security of the new scheme
is higher than the two above schemes.
</summary>
    <author>
      <name>Do Van Tuan</name>
    </author>
    <author>
      <name>Tran Dang Hien</name>
    </author>
    <author>
      <name>Pham Van At</name>
    </author>
    <link href="http://arxiv.org/abs/1208.5124v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1208.5124v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.4982v1</id>
    <updated>2012-09-22T10:36:11Z</updated>
    <published>2012-09-22T10:36:11Z</published>
    <title>Using multimodal speech production data to evaluate articulatory
  animation for audiovisual speech synthesis</title>
    <summary>  The importance of modeling speech articulation for high-quality audiovisual
(AV) speech synthesis is widely acknowledged. Nevertheless, while
state-of-the-art, data-driven approaches to facial animation can make use of
sophisticated motion capture techniques, the animation of the intraoral
articulators (viz. the tongue, jaw, and velum) typically makes use of simple
rules or viseme morphing, in stark contrast to the otherwise high quality of
facial modeling. Using appropriate speech production data could significantly
improve the quality of articulatory animation for AV synthesis.
</summary>
    <author>
      <name>Ingmar Steiner</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Lorraine - LORIA, Trinity College Dublin</arxiv:affiliation>
    </author>
    <author>
      <name>Korin Richmond</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CSTR</arxiv:affiliation>
    </author>
    <author>
      <name>Slim Ouni</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Lorraine - LORIA</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">3rd International Symposium on Facial Analysis and Animation
  (2012)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1209.4982v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.4982v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.0026v1</id>
    <updated>2012-09-28T20:29:37Z</updated>
    <published>2012-09-28T20:29:37Z</published>
    <title>Coupled quasi-harmonic bases</title>
    <summary>  The use of Laplacian eigenbases has been shown to be fruitful in many
computer graphics applications. Today, state-of-the-art approaches to shape
analysis, synthesis, and correspondence rely on these natural harmonic bases
that allow using classical tools from harmonic analysis on manifolds. However,
many applications involving multiple shapes are obstacled by the fact that
Laplacian eigenbases computed independently on different shapes are often
incompatible with each other. In this paper, we propose the construction of
common approximate eigenbases for multiple shapes using approximate joint
diagonalization algorithms. We illustrate the benefits of the proposed approach
on tasks from shape editing, pose transfer, correspondence, and similarity.
</summary>
    <author>
      <name>A. Kovnatsky</name>
    </author>
    <author>
      <name>M. M. Bronstein</name>
    </author>
    <author>
      <name>A. M. Bronstein</name>
    </author>
    <author>
      <name>K. Glashoff</name>
    </author>
    <author>
      <name>R. Kimmel</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 9 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1210.0026v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.0026v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.5556v1</id>
    <updated>2012-11-23T17:13:07Z</updated>
    <published>2012-11-23T17:13:07Z</published>
    <title>Improving Perceptual Color Difference using Basic Color Terms</title>
    <summary>  We suggest a new color distance based on two observations. First, perceptual
color differences were designed to be used to compare very similar colors. They
do not capture human perception for medium and large color differences well.
Thresholding was proposed to solve the problem for large color differences,
i.e. two totally different colors are always the same distance apart. We show
that thresholding alone cannot improve medium color differences. We suggest to
alleviate this problem using basic color terms. Second, when a color distance
is used for edge detection, many small distances around the just noticeable
difference may account for false edges. We suggest to reduce the effect of
small distances.
</summary>
    <author>
      <name>Ofir Pele</name>
    </author>
    <author>
      <name>Michael Werman</name>
    </author>
    <link href="http://arxiv.org/abs/1211.5556v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.5556v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.1378v2</id>
    <updated>2015-04-16T23:29:37Z</updated>
    <published>2013-01-08T01:57:09Z</published>
    <title>Apollonian Circumcircles of IFS Fractals</title>
    <summary>  Euclidean triangles and IFS fractals seem to be disparate geometrical
concepts, unless we consider the Sierpi\'{n}ski gasket, which is a self-similar
collection of triangles. The "circumcircle" hints at a direct link, as it can
be derived for three-map IFS fractals in general, defined in an Apollonian
manner. Following this path, one may discover a broader relationship between
polygons and IFS fractals.
</summary>
    <author>
      <name>József Vass</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted for publication. (Contains 8 pages with 4 figures.)</arxiv:comment>
    <link href="http://arxiv.org/abs/1301.1378v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.1378v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="28A80 (Primary), 68U05, 52A27 (Secondary)" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.4535v1</id>
    <updated>2013-01-19T07:01:46Z</updated>
    <published>2013-01-19T07:01:46Z</published>
    <title>Applications and a Three-dimensional Desktop Environment for an
  Immersive Virtual Reality System</title>
    <summary>  We developed an application launcher called Multiverse for scientific
visualizations in a CAVE-type virtual reality (VR) system. Multiverse can be
regarded as a type of three-dimensional (3D) desktop environment. In
Multiverse, a user in a CAVE room can browse multiple visualization
applications with 3D icons and explore movies that float in the air. Touching
one of the movies causes "teleportation" into the application's VR space. After
analyzing the simulation data using the application, the user can jump back
into Multiverse's VR desktop environment in the CAVE.
</summary>
    <author>
      <name>Akira Kageyama</name>
    </author>
    <author>
      <name>Youhei Masada</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1088/1742-6596/454/1/012077</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1088/1742-6596/454/1/012077" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 15 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1301.4535v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.4535v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.6549v1</id>
    <updated>2013-07-19T10:57:31Z</updated>
    <published>2013-07-19T10:57:31Z</published>
    <title>Making Laplacians commute</title>
    <summary>  In this paper, we construct multimodal spectral geometry by finding a pair of
closest commuting operators (CCO) to a given pair of Laplacians. The CCOs are
jointly diagonalizable and hence have the same eigenbasis. Our construction
naturally extends classical data analysis tools based on spectral geometry,
such as diffusion maps and spectral clustering. We provide several synthetic
and real examples of applications in dimensionality reduction, shape analysis,
and clustering, demonstrating that our method better captures the inherent
structure of multi-modal data.
</summary>
    <author>
      <name>Michael M. Bronstein</name>
    </author>
    <author>
      <name>Klaus Glashoff</name>
    </author>
    <author>
      <name>Terry A. Loring</name>
    </author>
    <link href="http://arxiv.org/abs/1307.6549v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.6549v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.SP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1401.1742v1</id>
    <updated>2014-01-08T16:22:09Z</updated>
    <published>2014-01-08T16:22:09Z</published>
    <title>Content Based Image Indexing and Retrieval</title>
    <summary>  In this paper, we present the efficient content based image retrieval systems
which employ the color, texture and shape information of images to facilitate
the retrieval process. For efficient feature extraction, we extract the color,
texture and shape feature of images automatically using edge detection which is
widely used in signal processing and image compression. For facilitated the
speedy retrieval we are implements the antipole-tree algorithm for indexing the
images.
</summary>
    <author>
      <name>Avinash N Bhute</name>
    </author>
    <author>
      <name>B. B. Meshram</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IJGIP 2013 Vol 3 issue 4</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1401.1742v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1401.1742v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1403.0087v1</id>
    <updated>2014-03-01T14:08:22Z</updated>
    <published>2014-03-01T14:08:22Z</published>
    <title>Temporal Image Fusion</title>
    <summary>  This paper introduces temporal image fusion. The proposed technique builds
upon previous research in exposure fusion and expands it to deal with the
limited Temporal Dynamic Range of existing sensors and camera technologies. In
particular, temporal image fusion enables the rendering of long-exposure
effects on full frame-rate video, as well as the generation of arbitrarily long
exposures from a sequence of images of the same scene taken over time. We
explore the problem of temporal under-exposure, and show how it can be
addressed by selectively enhancing dynamic structure. Finally, we show that the
use of temporal image fusion together with content-selective image filters can
produce a range of striking visual effects on a given input sequence.
</summary>
    <author>
      <name>Francisco J. Estrada</name>
    </author>
    <link href="http://arxiv.org/abs/1403.0087v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1403.0087v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1403.0728v1</id>
    <updated>2014-03-04T09:52:13Z</updated>
    <published>2014-03-04T09:52:13Z</published>
    <title>A Novel Method for Vectorization</title>
    <summary>  Vectorization of images is a key concern uniting computer graphics and
computer vision communities. In this paper we are presenting a novel idea for
efficient, customizable vectorization of raster images, based on Catmull Rom
spline fitting. The algorithm maintains a good balance between photo-realism
and photo abstraction, and hence is applicable to applications with artistic
concerns or applications where less information loss is crucial. The resulting
algorithm is fast, parallelizable and can satisfy general soft realtime
requirements. Moreover, the smoothness of the vectorized images aesthetically
outperforms outputs of many polygon-based methods
</summary>
    <author>
      <name>Tolga Birdal</name>
    </author>
    <author>
      <name>Emrah Bala</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Prepared in Siggraph format, not published in a conference, 7 pages,
  9 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1403.0728v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1403.0728v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1403.7987v1</id>
    <updated>2014-03-31T13:20:53Z</updated>
    <published>2014-03-31T13:20:53Z</published>
    <title>Implementation of interaction between soft tissues and foreign bodies
  using modified voxel model</title>
    <summary>  Interactive bodies collision detection and elimination is one of the most
popular task nowadays. Collisions can be detected in different ways. Collision
search using space voxelization is one of the most fast. This paper describes
improved voxel model that covers only area of collision interest and quickly
eliminates collisions. This new method can be useful in real time collision
processing of different rigid and soft bodies grids.
</summary>
    <author>
      <name>Sergei Nikolaev</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 9 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal Computer Tools in Education. 3 (2013) 28-32</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1403.7987v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1403.7987v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.3109v3</id>
    <updated>2014-10-22T09:12:44Z</updated>
    <published>2014-04-11T13:58:09Z</published>
    <title>Automated detection of coherent Lagrangian vortices in two-dimensional
  unsteady flows</title>
    <summary>  Coherent boundaries of Lagrangian vortices in fluid flows have recently been
identified as closed orbits of line fields associated with the Cauchy-Green
strain tensor. Here we develop a fully automated procedure for the detection of
such closed orbits in large-scale velocity data sets. We illustrate the power
of our method on ocean surface velocities derived from satellite altimetry.
</summary>
    <author>
      <name>Daniel Karrasch</name>
    </author>
    <author>
      <name>Florian Huhn</name>
    </author>
    <author>
      <name>George Haller</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1098/rspa.2014.0639</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1098/rspa.2014.0639" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages, 6 figures, 1 table, accepted for publication in Proc. R.
  Soc. Lond., Ser. A</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the Royal Society A, 471, 20140639, 2015</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1404.3109v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.3109v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ao-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.flu-dyn" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1407.2971v1</id>
    <updated>2014-07-10T21:27:03Z</updated>
    <published>2014-07-10T21:27:03Z</published>
    <title>Numerical investigation of lensless zoomable holographic multiple
  projections to tilted planes</title>
    <summary>  This paper numerically investigates the feasibility of lensless zoomable
holographic multiple projections to tilted planes. We have already developed
lensless zoomable holographic single projection using scaled diffraction, which
calculates diffraction between parallel planes with different sampling pitches.
The structure of this zoomable holographic projection is very simple because it
does not need a lens; however, it only projects a single image to a plane
parallel to the hologram. The lensless zoomable holographic projection in this
paper is capable of projecting multiple images onto tilted planes
simultaneously.
</summary>
    <author>
      <name>Tomoyoshi Shimobaba</name>
    </author>
    <author>
      <name>Michal Makowski</name>
    </author>
    <author>
      <name>Takashi Kakue</name>
    </author>
    <author>
      <name>Naohisa Okada</name>
    </author>
    <author>
      <name>Yutaka Endo</name>
    </author>
    <author>
      <name>Ryuji Hirayam</name>
    </author>
    <author>
      <name>Daisuke Hiyama</name>
    </author>
    <author>
      <name>Satoki Hasegawa</name>
    </author>
    <author>
      <name>Yuki Nagahama</name>
    </author>
    <author>
      <name>Tomoyoshi Ito</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.optcom.2014.07.081</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.optcom.2014.07.081" rel="related"/>
    <link href="http://arxiv.org/abs/1407.2971v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1407.2971v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.optics" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.optics" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.6022v1</id>
    <updated>2014-10-22T12:36:34Z</updated>
    <published>2014-10-22T12:36:34Z</published>
    <title>The physics of volume rendering</title>
    <summary>  Radiation transfer is an important topic in several physical disciplines,
probably most prominently in astrophysics. Computer scientists use radiation
transfer, among other things, for the visualisation of complex data sets with
direct volume rendering. In this note, I point out the connection between
physical radiation transfer and volume rendering, and I describe an
implementation of direct volume rendering in the astrophysical radiation
transfer code RADMC-3D. I show examples for the use of this module on
analytical models and simulation data.
</summary>
    <author>
      <name>Thomas Peters</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1088/0143-0807/35/6/065028</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1088/0143-0807/35/6/065028" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Eur. J. Phys. 35 (2014) 065028</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1410.6022v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.6022v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.IM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.IM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ed-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1501.00108v1</id>
    <updated>2014-12-31T10:53:50Z</updated>
    <published>2014-12-31T10:53:50Z</published>
    <title>HSI based colour image equalization using iterative nth root and nth
  power</title>
    <summary>  In this paper an equalization technique for colour images is introduced. The
method is based on nth root and nth power equalization approach but with
optimization of the mean of the image in different colour channels such as RGB
and HSI. The performance of the proposed method has been measured by the means
of peak signal to noise ratio. The proposed algorithm has been compared with
conventional histogram equalization and the visual and quantitative
experimental results are showing that the proposed method over perform the
histogram equalization.
</summary>
    <author>
      <name>Gholamreza Anbarjafari</name>
    </author>
    <link href="http://arxiv.org/abs/1501.00108v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1501.00108v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.01804v1</id>
    <updated>2015-03-05T22:15:33Z</updated>
    <published>2015-03-05T22:15:33Z</published>
    <title>Frequency Domain TOF: Encoding Object Depth in Modulation Frequency</title>
    <summary>  Time of flight cameras may emerge as the 3-D sensor of choice. Today, time of
flight sensors use phase-based sampling, where the phase delay between emitted
and received, high-frequency signals encodes distance. In this paper, we
present a new time of flight architecture that relies only on frequency---we
refer to this technique as frequency-domain time of flight (FD-TOF). Inspired
by optical coherence tomography (OCT), FD-TOF excels when frequency bandwidth
is high. With the increasing frequency of TOF sensors, new challenges to time
of flight sensing continue to emerge. At high frequencies, FD-TOF offers
several potential benefits over phase-based time of flight methods.
</summary>
    <author>
      <name>Achuta Kadambi</name>
    </author>
    <author>
      <name>Vage Taamazyan</name>
    </author>
    <author>
      <name>Suren Jayasuriya</name>
    </author>
    <author>
      <name>Ramesh Raskar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1503.01804v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.01804v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.01049v1</id>
    <updated>2015-04-04T20:34:11Z</updated>
    <published>2015-04-04T20:34:11Z</published>
    <title>3D visual analysis of seabed on smartphone</title>
    <summary>  We create a 'virtual-seabed' platform to realize the 3D visual analysis of
seabed on smartphone. The 3D seabed platform is based on a 'section-drilling'
model, implementing visualization and analysis of the integrated data of seabed
on the 3D browser on smartphone. Some 3D visual analysis functions are
developed. This work presents a thorough and interesting way of presenting
seabed data on smartphone, which raises many application possibilities. This
platform is another practical proof based on our WebVRGIS platform.
</summary>
    <author>
      <name>Zhihan Lv</name>
    </author>
    <author>
      <name>Tianyun Su</name>
    </author>
    <author>
      <name>Xiaoming Li</name>
    </author>
    <author>
      <name>Shengzhong Feng</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2015 IEEE Pacific Visualization Symposium (PacificVis)</arxiv:comment>
    <link href="http://arxiv.org/abs/1504.01049v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.01049v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.06922v1</id>
    <updated>2015-04-27T03:58:12Z</updated>
    <published>2015-04-27T03:58:12Z</published>
    <title>Simple Derivation of the Lifetime and the Distribution of Faces for a
  Binary Subdivision Model</title>
    <summary>  The iterative random subdivision of rectangles is used as a generation model
of networks in physics, computer science, and urban planning. However, these
researches were independent. We consider some relations in them, and derive
fundamental properties for the average lifetime depending on birth-time and the
balanced distribution of rectangle faces.
</summary>
    <author>
      <name>Yukio Hayashi</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1587/transfun.E98.A.1841</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1587/transfun.E98.A.1841" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IEICE Trans. Fundamentals, Vol.E98-A, No.8, pp.1841-1844, (2015)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1504.06922v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.06922v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.MP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.02710v1</id>
    <updated>2015-10-09T15:47:00Z</updated>
    <published>2015-10-09T15:47:00Z</published>
    <title>Procams-Based Cybernetics</title>
    <summary>  Procams-based cybernetics is a unique, emerging research field, which aims at
enhancing and supporting our activities by naturally connecting human and
computers/machines as a cooperative integrated system via projector-camera
systems (procams). It rests on various research domains such as
virtual/augmented reality, computer vision, computer graphics, projection
display, human computer interface, human robot interaction and so on. This
laboratory presentation provides a brief history including recent achievements
of our procams-based cybernetics project.
</summary>
    <author>
      <name>Kosuke Sato</name>
    </author>
    <author>
      <name>Daisuke Iwai</name>
    </author>
    <author>
      <name>Sei Ikeda</name>
    </author>
    <author>
      <name>Noriko Takemura</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2 pages, 2 figures, IEEE VR 2015 Lab/Project presentation</arxiv:comment>
    <link href="http://arxiv.org/abs/1510.02710v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.02710v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.04902v1</id>
    <updated>2015-11-16T10:34:25Z</updated>
    <published>2015-11-16T10:34:25Z</published>
    <title>Graph-based denoising for time-varying point clouds</title>
    <summary>  Noisy 3D point clouds arise in many applications. They may be due to errors
when constructing a 3D model from images or simply to imprecise depth sensors.
Point clouds can be given geometrical structure using graphs created from the
similarity information between points. This paper introduces a technique that
uses this graph structure and convex optimization methods to denoise 3D point
clouds. A short discussion presents how those methods naturally generalize to
time-varying inputs such as 3D point cloud time series.
</summary>
    <author>
      <name>Yann Schoenenberger</name>
    </author>
    <author>
      <name>Johan Paratte</name>
    </author>
    <author>
      <name>Pierre Vandergheynst</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/3DTV.2015.7169366</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/3DTV.2015.7169366" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 3 figures, 3DTV-Con 2015</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">3DTV-Conference: The True Vision - Capture, Transmission and
  Display of 3D Video (3DTV-CON) (2015) 1-4</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1511.04902v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.04902v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.5.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1602.03308v1</id>
    <updated>2016-02-10T09:45:38Z</updated>
    <published>2016-02-10T09:45:38Z</published>
    <title>Gabor Wavelets in Image Processing</title>
    <summary>  This work shows the use of a two-dimensional Gabor wavelets in image
processing. Convolution with such a two-dimensional wavelet can be separated
into two series of one-dimensional ones. The key idea of this work is to
utilize a Gabor wavelet as a multiscale partial differential operator of a
given order. Gabor wavelets are used here to detect edges, corners and blobs. A
performance of such an interest point detector is compared to detectors
utilizing a Haar wavelet and a derivative of a Gaussian function. The proposed
approach may be useful when a fast implementation of the Gabor transform is
available or when the transform is already precomputed.
</summary>
    <author>
      <name>David Barina</name>
    </author>
    <link href="http://arxiv.org/abs/1602.03308v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1602.03308v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1602.05256v1</id>
    <updated>2016-02-17T00:41:58Z</updated>
    <published>2016-02-17T00:41:58Z</published>
    <title>2D SEM images turn into 3D object models</title>
    <summary>  The scanning electron microscopy (SEM) is probably one the most fascinating
examination approach that has been used since more than two decades to detailed
inspection of micro scale objects. Most of the scanning electron microscopes
could only produce 2D images that could not assist operational analysis of
microscopic surface properties. Computer vision algorithms combined with very
advanced geometry and mathematical approaches turn any SEM into a full 3D
measurement device. This work focuses on a methodical literature review for
automatic 3D surface reconstruction of scanning electron microscope images.
</summary>
    <author>
      <name>Wichai Shanklin</name>
    </author>
    <link href="http://arxiv.org/abs/1602.05256v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1602.05256v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.08551v1</id>
    <updated>2016-03-28T20:28:09Z</updated>
    <published>2016-03-28T20:28:09Z</published>
    <title>Genetic cellular neural networks for generating three-dimensional
  geometry</title>
    <summary>  There are a number of ways to procedurally generate interesting
three-dimensional shapes, and a method where a cellular neural network is
combined with a mesh growth algorithm is presented here. The aim is to create a
shape from a genetic code in such a way that a crude search can find
interesting shapes. Identical neural networks are placed at each vertex of a
mesh which can communicate with neural networks on neighboring vertices. The
output of the neural networks determine how the mesh grows, allowing
interesting shapes to be produced emergently, mimicking some of the complexity
of biological organism development. Since the neural networks' parameters can
be freely mutated, the approach is amenable for use in a genetic algorithm.
</summary>
    <author>
      <name>Hugo Martay</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1603.08551v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.08551v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="92B20" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.02245v1</id>
    <updated>2016-05-07T20:41:58Z</updated>
    <published>2016-05-07T20:41:58Z</published>
    <title>Real-time collision detection method for deformable bodies</title>
    <summary>  This paper presents a real-time solution for collision detection between
objects based on the physics properties. Traditional approaches on collision
detection often rely on the geometric relationships that computing the
intersections between polygons. Such technique is very computationally
expensive when applied for deformable objects. As an alternative, we
approximate the 3D mesh in an spherical surface implicitly. This allows us to
perform a coarse-level collision detection at extremely fast speed. Then a
dynamic programming based procedure is applied to identify the collision in
fine details. Our method demonstrates better prevention to collision tunnelling
and works more efficiently than the state-of-the-arts.
</summary>
    <author>
      <name>Claudio Paglia</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Computer-Aided Design, 2015</arxiv:comment>
    <link href="http://arxiv.org/abs/1605.02245v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.02245v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.05785v1</id>
    <updated>2016-06-18T17:42:27Z</updated>
    <published>2016-06-18T17:42:27Z</published>
    <title>Automatic 3D Reconstruction for Symmetric Shapes</title>
    <summary>  Generic 3D reconstruction from a single image is a difficult problem. A lot
of data loss occurs in the projection. A domain based approach to
reconstruction where we solve a smaller set of problems for a particular use
case lead to greater returns. The project provides a way to automatically
generate full 3-D renditions of actual symmetric images that have some prior
information provided in the pipeline by a recognition algorithm. We provide a
critical analysis on how this can be enhanced and improved to provide a general
reconstruction framework for automatic reconstruction for any symmetric shape.
</summary>
    <author>
      <name>Atishay Jain</name>
    </author>
    <link href="http://arxiv.org/abs/1606.05785v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.05785v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.04767v1</id>
    <updated>2016-07-16T16:54:39Z</updated>
    <published>2016-07-16T16:54:39Z</published>
    <title>Optimized Automatic Code Generation for Geometric Algebra Based
  Algorithms with Ray Tracing Application</title>
    <summary>  Automatic code generation for low-dimensional geometric algorithms is capable
of producing efficient low-level software code through a high-level geometric
domain specific language. Geometric Algebra (GA) is one of the most suitable
algebraic systems for being the base for such code generator. This work
presents an attempt at realizing such idea in practice. A novel GA-based
geometric code generator, called GMac, is proposed. Comparisons to similar
GA-based code generators are provided. The possibility of fully benefiting from
the symbolic power of GA while obtaining good performance and maintainability
of software implementations is illustrated through a ray tracing application.
</summary>
    <author>
      <name>Ahmad Hosney Awad Eid</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">PhD Thesis, 2010, 249 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1607.04767v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.04767v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.06138v2</id>
    <updated>2017-02-03T03:19:21Z</updated>
    <published>2016-07-20T22:24:10Z</published>
    <title>Dappled tiling</title>
    <summary>  We consider a certain tiling problem of a planar region in which there are no
long horizontal or vertical strips consisting of copies of the same tile.
Intuitively speaking, we would like to create a dappled pattern with two or
more kinds of tiles. We give an efficient algorithm to turn any tiling into one
satisfying the condition, and discuss its applications in texturing.
</summary>
    <author>
      <name>Shizuo Kaji</name>
    </author>
    <author>
      <name>Alexandre Derouet-Jourdan</name>
    </author>
    <author>
      <name>Hiroyuki Ochiai</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">minor errors fixed, more pictures added</arxiv:comment>
    <link href="http://arxiv.org/abs/1607.06138v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.06138v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="52C20, 68U05" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.2.3; I.3.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.01140v1</id>
    <updated>2016-08-03T10:33:21Z</updated>
    <published>2016-08-03T10:33:21Z</published>
    <title>Fast Spherical Quasiconformal Parameterization of Genus-0 Closed
  Surfaces with Application to Adaptive Remeshing</title>
    <summary>  In this work, we are concerned with the spherical quasiconformal
parameterization of genus-0 closed surfaces. Given a genus-0 closed
triangulated surface and an arbitrary user-defined quasiconformal distortion,
we propose a fast algorithm for computing a spherical parameterization of the
surface that satisfies the prescribed distortion. The proposed algorithm can be
effectively applied to adaptive surface remeshing for improving the
visualization in computer graphics and animations. Experimental results are
presented to illustrate the effectiveness of our algorithm.
</summary>
    <author>
      <name>Gary Pui-Tung Choi</name>
    </author>
    <author>
      <name>Mandy Hiu-Ying Man</name>
    </author>
    <author>
      <name>Lok Ming Lui</name>
    </author>
    <link href="http://arxiv.org/abs/1608.01140v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.01140v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.01499v1</id>
    <updated>2016-09-06T11:43:08Z</updated>
    <published>2016-09-06T11:43:08Z</published>
    <title>Depth Estimation Through a Generative Model of Light Field Synthesis</title>
    <summary>  Light field photography captures rich structural information that may
facilitate a number of traditional image processing and computer vision tasks.
A crucial ingredient in such endeavors is accurate depth recovery. We present a
novel framework that allows the recovery of a high quality continuous depth map
from light field data. To this end we propose a generative model of a light
field that is fully parametrized by its corresponding depth map. The model
allows for the integration of powerful regularization techniques such as a
non-local means prior, facilitating accurate depth map estimation.
</summary>
    <author>
      <name>Mehdi S. M. Sajjadi</name>
    </author>
    <author>
      <name>Rolf Köhler</name>
    </author>
    <author>
      <name>Bernhard Schölkopf</name>
    </author>
    <author>
      <name>Michael Hirsch</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-319-45886-1_35</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-319-45886-1_35" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">German Conference on Pattern Recognition (GCPR) 2016</arxiv:comment>
    <link href="http://arxiv.org/abs/1609.01499v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.01499v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1611.00939v1</id>
    <updated>2016-11-03T10:11:10Z</updated>
    <published>2016-11-03T10:11:10Z</published>
    <title>Recent Advances in Transient Imaging: A Computer Graphics and Vision
  Perspective</title>
    <summary>  Transient imaging has recently made a huge impact in the computer graphics
and computer vision fields. By capturing, reconstructing, or simulating light
transport at extreme temporal resolutions, researchers have proposed novel
techniques to show movies of light in motion, see around corners, detect
objects in highly-scattering media, or infer material properties from a
distance, to name a few. The key idea is to leverage the wealth of information
in the temporal domain at the pico or nanosecond resolution, information
usually lost during the capture-time temporal integration. This paper presents
recent advances in this field of transient imaging from a graphics and vision
perspective, including capture techniques, analysis, applications and
simulation.
</summary>
    <author>
      <name>Adrian Jarabo</name>
    </author>
    <author>
      <name>Belen Masia</name>
    </author>
    <author>
      <name>Julio Marco</name>
    </author>
    <author>
      <name>Diego Gutierrez</name>
    </author>
    <link href="http://arxiv.org/abs/1611.00939v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1611.00939v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1611.01055v1</id>
    <updated>2016-11-03T15:15:00Z</updated>
    <published>2016-11-03T15:15:00Z</published>
    <title>Learning Locomotion Skills Using DeepRL: Does the Choice of Action Space
  Matter?</title>
    <summary>  The use of deep reinforcement learning allows for high-dimensional state
descriptors, but little is known about how the choice of action representation
impacts the learning difficulty and the resulting performance. We compare the
impact of four different action parameterizations (torques, muscle-activations,
target joint angles, and target joint-angle velocities) in terms of learning
time, policy robustness, motion quality, and policy query rates. Our results
are evaluated on a gait-cycle imitation task for multiple planar articulated
figures and multiple gaits. We demonstrate that the local feedback provided by
higher-level action parameterizations can significantly impact the learning,
robustness, and quality of the resulting policies.
</summary>
    <author>
      <name>Xue Bin Peng</name>
    </author>
    <author>
      <name>Michiel van de Panne</name>
    </author>
    <link href="http://arxiv.org/abs/1611.01055v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1611.01055v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.04956v2</id>
    <updated>2017-03-20T19:45:44Z</updated>
    <published>2016-12-15T07:53:27Z</published>
    <title>Cloud Dictionary: Sparse Coding and Modeling for Point Clouds</title>
    <summary>  With the development of range sensors such as LIDAR and time-of-flight
cameras, 3D point cloud scans have become ubiquitous in computer vision
applications, the most prominent ones being gesture recognition and autonomous
driving. Parsimony-based algorithms have shown great success on images and
videos where data points are sampled on a regular Cartesian grid. We propose an
adaptation of these techniques to irregularly sampled signals by using
continuous dictionaries. We present an example application in the form of point
cloud denoising.
</summary>
    <author>
      <name>Or Litany</name>
    </author>
    <author>
      <name>Tal Remez</name>
    </author>
    <author>
      <name>Alex Bronstein</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Signal Processing with Adaptive Sparse Structured Representations
  (SPARS), 2017</arxiv:comment>
    <link href="http://arxiv.org/abs/1612.04956v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.04956v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.01595v3</id>
    <updated>2017-09-14T12:40:17Z</updated>
    <published>2017-01-06T11:14:19Z</published>
    <title>Analysis of Framelet Transforms on a Simplex</title>
    <summary>  In this paper, we construct framelets associated with a sequence of
quadrature rules on the simplex $T^{2}$ in $\mathbb{R}^{2}$. We give the
framelet transforms -- decomposition and reconstruction of the coefficients for
framelets of a function on $T^{2}$. We prove that the reconstruction is exact
when the framelets are tight. We give an example of construction of framelets
and show that the framelet transforms can be computed as fast as FFT.
</summary>
    <author>
      <name>Yu Guang Wang</name>
    </author>
    <author>
      <name>Houying Zhu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1701.01595v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.01595v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="42C15, 42C40, 94A08, 65T60, 65T50, 41A55, 58C35, 42B05" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.02123v1</id>
    <updated>2017-01-09T10:16:11Z</updated>
    <published>2017-01-09T10:16:11Z</published>
    <title>Green-Blue Stripe Pattern for Range Sensing from a Single Image</title>
    <summary>  In this paper, we present a novel method for rapid high-resolution range
sensing using green-blue stripe pattern. We use green and blue for designing
high-frequency stripe projection pattern. For accurate and reliable range
recovery, we identify the stripe patterns by our color-stripe segmentation and
unwrapping algorithms. The experimental result for a naked human face shows the
effectiveness of our method.
</summary>
    <author>
      <name>Changsoo Je</name>
    </author>
    <author>
      <name>Kyuhyoung Choi</name>
    </author>
    <author>
      <name>Sang Wook Lee</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 5 figures. Updated version of a conference paper</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. 30th Fall Semiannual Conference of Korea Information Science
  Society, vol. 2, pp. 661-663, Seoul, Korea, October, 2003</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1701.02123v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.02123v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.10; I.4.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.07403v2</id>
    <updated>2017-08-15T12:57:10Z</updated>
    <published>2017-01-25T17:50:19Z</published>
    <title>Learning Light Transport the Reinforced Way</title>
    <summary>  We show that the equations of reinforcement learning and light transport
simulation are related integral equations. Based on this correspondence, a
scheme to learn importance while sampling path space is derived. The new
approach is demonstrated in a consistent light transport simulation algorithm
that uses reinforcement learning to progressively learn where light comes from.
As using this information for importance sampling includes information about
visibility, too, the number of light transport paths with zero contribution is
dramatically reduced, resulting in much less noisy images within a fixed time
budget.
</summary>
    <author>
      <name>Ken Dahm</name>
    </author>
    <author>
      <name>Alexander Keller</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Revised version</arxiv:comment>
    <link href="http://arxiv.org/abs/1701.07403v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.07403v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1704.02525v1</id>
    <updated>2017-04-08T19:08:08Z</updated>
    <published>2017-04-08T19:08:08Z</published>
    <title>Density-equalizing maps for simply-connected open surfaces</title>
    <summary>  In this paper, we are concerned with the problem of creating flattening maps
of simply-connected open surfaces in $\mathbb{R}^3$. Using a natural principle
of density diffusion in physics, we propose an effective algorithm for
computing density-equalizing flattening maps with any prescribed density
distribution. By varying the initial density distribution, a large variety of
mappings with different properties can be achieved. For instance,
area-preserving parameterizations of simply-connected open surfaces can be
easily computed. Experimental results are presented to demonstrate the
effectiveness of our proposed method. Applications to data visualization and
surface remeshing are explored.
</summary>
    <author>
      <name>Gary P. T. Choi</name>
    </author>
    <author>
      <name>Chris H. Rycroft</name>
    </author>
    <link href="http://arxiv.org/abs/1704.02525v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1704.02525v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.05016v1</id>
    <updated>2017-05-14T19:02:03Z</updated>
    <published>2017-05-14T19:02:03Z</published>
    <title>A Correspondence Relaxation Approach for 3D Shape Reconstruction</title>
    <summary>  This paper presents a new method for 3D shape reconstruction based on two
existing methods. A 3D reconstruction from a single photograph is introduced by
both papers: the first one uses a photograph and a set of existing 3D model to
generate the 3D object in the photograph, while the second one uses a
photograph and a selected similar model to create the 3D object in the
photograph. According to their difference, we propose a relaxation based method
for more accurate correspondence establishment and shape recovery. The
experiment demonstrates promising results compared to the state-of-the-art work
on 3D shape estimation.
</summary>
    <author>
      <name>Yong Khoo</name>
    </author>
    <link href="http://arxiv.org/abs/1705.05016v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.05016v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.07108v1</id>
    <updated>2017-05-19T17:39:43Z</updated>
    <published>2017-05-19T17:39:43Z</published>
    <title>Snapshot Difference Imaging using Time-of-Flight Sensors</title>
    <summary>  Computational photography encompasses a diversity of imaging techniques, but
one of the core operations performed by many of them is to compute image
differences. An intuitive approach to computing such differences is to capture
several images sequentially and then process them jointly. Usually, this
approach leads to artifacts when recording dynamic scenes. In this paper, we
introduce a snapshot difference imaging approach that is directly implemented
in the sensor hardware of emerging time-of-flight cameras. With a variety of
examples, we demonstrate that the proposed snapshot difference imaging
technique is useful for direct-global illumination separation, for direct
imaging of spatial and temporal image gradients, for direct depth edge imaging,
and more.
</summary>
    <author>
      <name>Clara Callenberg</name>
    </author>
    <author>
      <name>Felix Heide</name>
    </author>
    <author>
      <name>Gordon Wetzstein</name>
    </author>
    <author>
      <name>Matthias Hullin</name>
    </author>
    <link href="http://arxiv.org/abs/1705.07108v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.07108v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.00082v1</id>
    <updated>2017-05-31T20:43:19Z</updated>
    <published>2017-05-31T20:43:19Z</published>
    <title>Megapixel Size Image Creation using Generative Adversarial Networks</title>
    <summary>  Since its appearance, Generative Adversarial Networks (GANs) have received a
lot of interest in the AI community. In image generation several projects
showed how GANs are able to generate photorealistic images but the results so
far did not look adequate for the quality standard of visual media production
industry. We present an optimized image generation process based on a Deep
Convolutional Generative Adversarial Networks (DCGANs), in order to create
photorealistic high-resolution images (up to 1024x1024 pixels). Furthermore,
the system was fed with a limited dataset of images, less than two thousand
images. All these results give more clue about future exploitation of GANs in
Computer Graphics and Visual Effects.
</summary>
    <author>
      <name>Marco Marchesi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1706.00082v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.00082v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.5.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.00223v1</id>
    <updated>2017-08-01T09:46:18Z</updated>
    <published>2017-08-01T09:46:18Z</published>
    <title>Learning to Hallucinate Face Images via Component Generation and
  Enhancement</title>
    <summary>  We propose a two-stage method for face hallucination. First, we generate
facial components of the input image using CNNs. These components represent the
basic facial structures. Second, we synthesize fine-grained facial structures
from high resolution training images. The details of these structures are
transferred into facial components for enhancement. Therefore, we generate
facial components to approximate ground truth global appearance in the first
stage and enhance them through recovering details in the second stage. The
experiments demonstrate that our method performs favorably against
state-of-the-art methods
</summary>
    <author>
      <name>Yibing Song</name>
    </author>
    <author>
      <name>Jiawei Zhang</name>
    </author>
    <author>
      <name>Shengfeng He</name>
    </author>
    <author>
      <name>Linchao Bao</name>
    </author>
    <author>
      <name>Qingxiong Yang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">IJCAI 2017. Project page:
  http://www.cs.cityu.edu.hk/~yibisong/ijcai17_sr/index.html</arxiv:comment>
    <link href="http://arxiv.org/abs/1708.00223v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.00223v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
