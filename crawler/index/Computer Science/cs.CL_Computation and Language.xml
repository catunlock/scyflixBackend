<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3Dall%3Acs.CL%26id_list%3D%26start%3D0%26max_results%3D500" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=all:cs.CL&amp;id_list=&amp;start=0&amp;max_results=500</title>
  <id>http://arxiv.org/api/54XJXwCepKBK8cYw34hZi2p4Q1M</id>
  <updated>2017-10-08T00:00:00-04:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">7344</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">500</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/cs/0303002v2</id>
    <updated>2003-03-21T12:34:45Z</updated>
    <published>2003-03-05T08:50:42Z</published>
    <title>About compression of vocabulary in computer oriented languages</title>
    <summary>  The author uses the entropy of the ideal Bose-Einstein gas to minimize losses
in computer-oriented languages.
</summary>
    <author>
      <name>V. P. Maslov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Latex, 7 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0303002v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0303002v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="B.1.4; H.3.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0303007v1</id>
    <updated>2003-03-14T05:15:20Z</updated>
    <published>2003-03-14T05:15:20Z</published>
    <title>Glottochronology and problems of protolanguage reconstruction</title>
    <summary>  A method of languages genealogical trees construction is proposed.
</summary>
    <author>
      <name>Kromer Victor</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages, 9 figures. In Russian</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0303007v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0303007v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0304024v1</id>
    <updated>2003-04-17T02:22:06Z</updated>
    <published>2003-04-17T02:22:06Z</published>
    <title>Glottochronologic Retrognostic of Language System</title>
    <summary>  A glottochronologic retrognostic of language system is proposed
</summary>
    <author>
      <name>Kromer Victor</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 7 figures. In Russian</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0304024v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0304024v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0801.1415v1</id>
    <updated>2008-01-09T12:34:40Z</updated>
    <published>2008-01-09T12:34:40Z</published>
    <title>The emerging field of language dynamics</title>
    <summary>  A simple review by a linguist, citing many articles by physicists:
Quantitative methods, agent-based computer simulations, language dynamics,
language typology, historical linguistics
</summary>
    <author>
      <name>S. Wichmann</name>
    </author>
    <link href="http://arxiv.org/abs/0801.1415v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0801.1415v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1106.5973v1</id>
    <updated>2011-06-27T20:13:07Z</updated>
    <published>2011-06-27T20:13:07Z</published>
    <title>Entropy of Telugu</title>
    <summary>  This paper presents an investigation of the entropy of the Telugu script.
Since this script is syllabic, and not alphabetic, the computation of entropy
is somewhat complicated.
</summary>
    <author>
      <name>Venkata Ravinder Paruchuri</name>
    </author>
    <link href="http://arxiv.org/abs/1106.5973v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1106.5973v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1311.3011v2</id>
    <updated>2016-10-08T22:26:41Z</updated>
    <published>2013-11-13T03:58:38Z</published>
    <title>Cornell SPF: Cornell Semantic Parsing Framework</title>
    <summary>  The Cornell Semantic Parsing Framework (SPF) is a learning and inference
framework for mapping natural language to formal representation of its meaning.
</summary>
    <author>
      <name>Yoav Artzi</name>
    </author>
    <link href="http://arxiv.org/abs/1311.3011v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1311.3011v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1408.1774v1</id>
    <updated>2014-08-08T07:39:13Z</updated>
    <published>2014-08-08T07:39:13Z</published>
    <title>Beyond description. Comment on "Approaching human language with complex
  networks" by Cong &amp; Liu</title>
    <summary>  Comment on "Approaching human language with complex networks" by Cong &amp; Liu
</summary>
    <author>
      <name>Ramon Ferrer-i-Cancho</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.plrev.2014.07.014</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.plrev.2014.07.014" rel="related"/>
    <link href="http://arxiv.org/abs/1408.1774v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1408.1774v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0002017v1</id>
    <updated>2000-02-27T04:09:59Z</updated>
    <published>2000-02-27T04:09:59Z</published>
    <title>An Usage Measure Based on Psychophysical Relations</title>
    <summary>  A new word usage measure is proposed. It is based on psychophysical relations
and allows to reveal words by its degree of "importance" for making basic
dictionaries of sublanguages.
</summary>
    <author>
      <name>V. Kromer</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 1 figure, 1 table</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0002017v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0002017v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0607088v1</id>
    <updated>2006-07-18T07:43:07Z</updated>
    <published>2006-07-18T07:43:07Z</published>
    <title>Using Answer Set Programming in an Inference-Based approach to Natural
  Language Semantics</title>
    <summary>  Using Answer Set Programming in an Inference-Based approach to Natural
Language Semantics
</summary>
    <author>
      <name>Farid Nouioua</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIPN</arxiv:affiliation>
    </author>
    <author>
      <name>Pascal Nicolas</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LERIA</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Inference in Computational Semantics ICoS-5, France (2006) 77-86</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0607088v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0607088v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0610124v1</id>
    <updated>2006-10-20T11:48:38Z</updated>
    <published>2006-10-20T11:48:38Z</published>
    <title>Dependency Treebanks: Methods, Annotation Schemes and Tools</title>
    <summary>  In this paper, current dependencybased treebanks are introduced and analyzed.
The methods used for building the resources, the annotation schemes applied,
and the tools used (such as POS taggers, parsers and annotation software) are
discussed.
</summary>
    <author>
      <name>Tuomo Kakkonen</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 15th Nordic Conference of Computational
  Linguistics (NODALIDA 2005), pp. 94-104. Joensuu, Finland, 2005</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0610124v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0610124v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0711.3197v1</id>
    <updated>2007-11-20T19:57:23Z</updated>
    <published>2007-11-20T19:57:23Z</published>
    <title>How to realize "a sense of humour" in computers ?</title>
    <summary>  Computer model of a "sense of humour" suggested previously [arXiv:0711.2058,
0711.2061, 0711.2270] is raised to the level of a realistic algorithm.
</summary>
    <author>
      <name>I. M. Suslov</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">P.L.Kapitza Institute for Physical Problems, Moscow, Russia</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 6 figures included</arxiv:comment>
    <link href="http://arxiv.org/abs/0711.3197v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0711.3197v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0711.3452v1</id>
    <updated>2007-11-21T20:38:29Z</updated>
    <published>2007-11-21T20:38:29Z</published>
    <title>In memoriam Maurice Gross</title>
    <summary>  Maurice Gross (1934-2001) was both a great linguist and a pioneer in natural
language processing. This article is written in homage to his memory
</summary>
    <author>
      <name>Eric Laporte</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IGM-LabInfo</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Archives of Control Sciences 15, 3 (2005) 257-278</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0711.3452v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0711.3452v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0802.4198v1</id>
    <updated>2008-02-28T12:58:49Z</updated>
    <published>2008-02-28T12:58:49Z</published>
    <title>Some properties of the Ukrainian writing system</title>
    <summary>  We investigate the grapheme-phoneme relation in Ukrainian and some properties
of the Ukrainian version of the Cyrillic alphabet.
</summary>
    <author>
      <name>Solomija Buk</name>
    </author>
    <author>
      <name>Ján Mačutek</name>
    </author>
    <author>
      <name>Andrij Rovenchak</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Glottometrics 16, 63-79 (2008)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0802.4198v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0802.4198v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0807.3845v1</id>
    <updated>2008-07-24T10:31:55Z</updated>
    <published>2008-07-24T10:31:55Z</published>
    <title>Formal semantics of language and the Richard-Berry paradox</title>
    <summary>  The classical logical antinomy known as Richard-Berry paradox is combined
with plausible assumptions about the size i.e. the descriptional complexity of
Turing machines formalizing certain sentences, to show that formalization of
language leads to contradiction.
</summary>
    <author>
      <name>Stefano Crespi Reghizzi</name>
    </author>
    <link href="http://arxiv.org/abs/0807.3845v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0807.3845v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0911.5116v1</id>
    <updated>2009-11-26T16:27:58Z</updated>
    <published>2009-11-26T16:27:58Z</published>
    <title>Standardization of the formal representation of lexical information for
  NLP</title>
    <summary>  A survey of dictionary models and formats is presented as well as a
presentation of corresponding recent standardisation activities.
</summary>
    <author>
      <name>Laurent Romary</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Saclay - Ile de France, IDSL</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Dictionarie. An International Encyclopedia of Lexicography.
  Supplementary volume: Recent developments with special focus on computational
  lexicography (2010) -</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0911.5116v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0911.5116v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0911.5568v1</id>
    <updated>2009-11-30T08:07:16Z</updated>
    <published>2009-11-30T08:07:16Z</published>
    <title>Acquisition d'informations lexicales à partir de corpus Cédric
  Messiant et Thierry Poibeau</title>
    <summary>  This paper is about automatic acquisition of lexical information from
corpora, especially subcategorization acquisition.
</summary>
    <author>
      <name>Cédric Messiant</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIPN</arxiv:affiliation>
    </author>
    <author>
      <name>Thierry Poibeau</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIPN</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Troisi\`eme colloque international de l'Association Fran\c{c}aise
  de Linguistique Cognitive (AFLICO), Nanterre : France (2009)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0911.5568v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0911.5568v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1004.3183v2</id>
    <updated>2011-07-01T17:08:12Z</updated>
    <published>2010-04-19T13:11:56Z</published>
    <title>Statistical Physics for Natural Language Processing</title>
    <summary>  This paper has been withdrawn by the author.
</summary>
    <author>
      <name>Juan-Manuel Torres Moreno</name>
    </author>
    <author>
      <name>Silvia Fernandez</name>
    </author>
    <author>
      <name>Eric SanJuan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper has been withdrawn</arxiv:comment>
    <link href="http://arxiv.org/abs/1004.3183v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1004.3183v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1005.4697v3</id>
    <updated>2010-08-25T13:10:44Z</updated>
    <published>2010-05-25T20:36:09Z</published>
    <title>The Lambek-Grishin calculus is NP-complete</title>
    <summary>  The Lambek-Grishin calculus LG is the symmetric extension of the
non-associative Lambek calculus NL. In this paper we prove that the
derivability problem for LG is NP-complete.
</summary>
    <author>
      <name>Jeroen Bransen</name>
    </author>
    <link href="http://arxiv.org/abs/1005.4697v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1005.4697v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1107.1753v1</id>
    <updated>2011-07-09T00:40:06Z</updated>
    <published>2011-07-09T00:40:06Z</published>
    <title>Notes on Electronic Lexicography</title>
    <summary>  These notes are a continuation of topics covered by V. Selegej in his article
"Electronic Dictionaries and Computational lexicography". How can an electronic
dictionary have as its object the description of closely related languages?
Obviously, such a question allows multiple answers.
</summary>
    <author>
      <name>Yavor Parvanov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1107.1753v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1107.1753v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.7917v1</id>
    <updated>2012-10-30T07:25:46Z</updated>
    <published>2012-10-30T07:25:46Z</published>
    <title>The Model of Semantic Concepts Lattice For Data Mining Of Microblogs</title>
    <summary>  The model of semantic concept lattice for data mining of microblogs has been
proposed in this work. It is shown that the use of this model is effective for
the semantic relations analysis and for the detection of associative rules of
key words.
</summary>
    <author>
      <name>Bohdan Pavlyshenko</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Ukrainian</arxiv:comment>
    <link href="http://arxiv.org/abs/1210.7917v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.7917v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.4674v1</id>
    <updated>2012-12-19T14:40:38Z</updated>
    <published>2012-12-19T14:40:38Z</published>
    <title>Natural Language Understanding Based on Semantic Relations between
  Sentences</title>
    <summary>  In this paper, we define event expression over sentences of natural language
and semantic relations between events. Based on this definition, we formally
consider text understanding process having events as basic unit.
</summary>
    <author>
      <name>Hyeok Kong</name>
    </author>
    <link href="http://arxiv.org/abs/1212.4674v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.4674v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1409.3813v1</id>
    <updated>2014-09-12T18:37:35Z</updated>
    <published>2014-09-12T18:37:35Z</published>
    <title>Incorporating Semi-supervised Features into Discontinuous Easy-First
  Constituent Parsing</title>
    <summary>  This paper describes adaptations for EaFi, a parser for easy-first parsing of
discontinuous constituents, to adapt it to multiple languages as well as make
use of the unlabeled data that was provided as part of the SPMRL shared task
2014.
</summary>
    <author>
      <name>Yannick Versley</name>
    </author>
    <link href="http://arxiv.org/abs/1409.3813v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1409.3813v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.1342v1</id>
    <updated>2014-12-03T14:37:36Z</updated>
    <published>2014-12-03T14:37:36Z</published>
    <title>A perspective on the advancement of natural language processing tasks
  via topological analysis of complex networks</title>
    <summary>  Comment on "Approaching human language with complex networks" by Cong and Liu
(Physics of Life Reviews, Volume 11, Issue 4, December 2014, Pages 598-618).
</summary>
    <author>
      <name>Diego R. Amancio</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.plrev.2014.07.010</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.plrev.2014.07.010" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Physics of Life Reviews, v. 11, p. 641-643, 2014</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1412.1342v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.1342v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.03783v1</id>
    <updated>2016-01-15T00:09:52Z</updated>
    <published>2016-01-15T00:09:52Z</published>
    <title>Towards Turkish ASR: Anatomy of a rule-based Turkish g2p</title>
    <summary>  This paper describes the architecture and implementation of a rule-based
grapheme to phoneme converter for Turkish. The system accepts surface form as
input, outputs SAMPA mapping of the all parallel pronounciations according to
the morphological analysis together with stress positions. The system has been
implemented in Python
</summary>
    <author>
      <name>Duygu Altinok</name>
    </author>
    <link href="http://arxiv.org/abs/1601.03783v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.03783v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.02905v2</id>
    <updated>2016-03-10T19:20:47Z</updated>
    <published>2016-03-09T14:56:44Z</published>
    <title>Lexical bundles in computational linguistics academic literature</title>
    <summary>  In this study we analyzed a corpus of 8 million words academic literature
from Computational lingustics' academic literature. the lexical bundles from
this corpus are categorized based on structures and functions.
</summary>
    <author>
      <name>Adel Rahimi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 6 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1603.02905v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.02905v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.03872v1</id>
    <updated>2017-06-12T23:57:48Z</updated>
    <published>2017-06-12T23:57:48Z</published>
    <title>Six Challenges for Neural Machine Translation</title>
    <summary>  We explore six challenges for neural machine translation: domain mismatch,
amount of training data, rare words, long sentences, word alignment, and beam
search. We show both deficiencies and improvements over the quality of
phrase-based statistical machine translation.
</summary>
    <author>
      <name>Philipp Koehn</name>
    </author>
    <author>
      <name>Rebecca Knowles</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages; First Workshop on Neural Machine Translation, 2017</arxiv:comment>
    <link href="http://arxiv.org/abs/1706.03872v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.03872v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.04872v1</id>
    <updated>2017-06-15T14:01:40Z</updated>
    <published>2017-06-15T14:01:40Z</published>
    <title>Towards a theory of word order. Comment on "Dependency distance: a new
  perspective on syntactic patterns in natural language" by Haitao Liu et al</title>
    <summary>  Comment on "Dependency distance: a new perspective on syntactic patterns in
natural language" by Haitao Liu et al
</summary>
    <author>
      <name>Ramon Ferrer-i-Cancho</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.plrev.2017.06.019</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.plrev.2017.06.019" rel="related"/>
    <link href="http://arxiv.org/abs/1706.04872v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.04872v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.08196v1</id>
    <updated>2017-09-24T13:48:36Z</updated>
    <published>2017-09-24T13:48:36Z</published>
    <title>Identifying Phrasemes via Interlingual Association Measures -- A
  Data-driven Approach on Dependency-parsed and Word-aligned Parallel Corpora</title>
    <summary>  This is a preprint of the article "Identifying Phrasemes via Interlingual
Association Measures" that was presented in February 2016 at the LeKo (Lexical
combinations and typified speech in a multilingual context) conference in
Innsbruck.
</summary>
    <author>
      <name>Johannes Graën</name>
    </author>
    <link href="http://arxiv.org/abs/1709.08196v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.08196v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1107.3119v2</id>
    <updated>2011-07-23T00:14:36Z</updated>
    <published>2011-07-15T18:06:37Z</published>
    <title>Experimenting with Transitive Verbs in a DisCoCat</title>
    <summary>  Formal and distributional semantic models offer complementary benefits in
modeling meaning. The categorical compositional distributional (DisCoCat) model
of meaning of Coecke et al. (arXiv:1003.4394v1 [cs.CL]) combines aspected of
both to provide a general framework in which meanings of words, obtained
distributionally, are composed using methods from the logical setting to form
sentence meaning. Concrete consequences of this general abstract setting and
applications to empirical data are under active study (Grefenstette et al.,
arxiv:1101.0309; Grefenstette and Sadrzadeh, arXiv:1106.4058v1 [cs.CL]). . In
this paper, we extend this study by examining transitive verbs, represented as
matrices in a DisCoCat. We discuss three ways of constructing such matrices,
and evaluate each method in a disambiguation task developed by Grefenstette and
Sadrzadeh (arXiv:1106.4058v1 [cs.CL]).
</summary>
    <author>
      <name>Edward Grefenstette</name>
    </author>
    <author>
      <name>Mehrnoosh Sadrzadeh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, to be presented at GEMS 2011, as part of EMNLP'11 workshops</arxiv:comment>
    <link href="http://arxiv.org/abs/1107.3119v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1107.3119v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T50" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.3; H.3.1; H.3.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9902027v1</id>
    <updated>1999-02-16T15:34:02Z</updated>
    <published>1999-02-16T15:34:02Z</published>
    <title>Autocatalytic Theory of Meaning</title>
    <summary>  Recently it has been argued that autocatalytic theory could be applied to the
origin of culture. Here possible application to a theory of meaning in the
philosophy of language, called radical interpretation, is commented upon and
compared to previous applications.
</summary>
    <author>
      <name>Mark D. Roberts</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, no diagrams, LaTex2e</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">PSYCHOLOQUY.99.10.014</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/9902027v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9902027v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="adap-org" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.6; J.4; I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9902030v1</id>
    <updated>1999-02-25T14:41:32Z</updated>
    <published>1999-02-25T14:41:32Z</published>
    <title>Is Word Sense Disambiguation just one more NLP task?</title>
    <summary>  This paper compares the tasks of part-of-speech (POS) tagging and
word-sense-tagging or disambiguation (WSD), and argues that the tasks are not
related by fineness of grain or anything like that, but are quite different
kinds of task, particularly becuase there is nothing in POS corresponding to
sense novelty. The paper also argues for the reintegration of sub-tasks that
are being separated for evaluation
</summary>
    <author>
      <name>Yorick Wilks</name>
    </author>
    <link href="http://arxiv.org/abs/cs/9902030v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9902030v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9906009v1</id>
    <updated>1999-06-06T17:36:34Z</updated>
    <published>1999-06-06T17:36:34Z</published>
    <title>Cascaded Markov Models</title>
    <summary>  This paper presents a new approach to partial parsing of context-free
structures. The approach is based on Markov Models. Each layer of the resulting
structure is represented by its own Markov Model, and output of a lower layer
is passed as input to the next higher layer. An empirical evaluation of the
method yields very good results for NP/PP chunking of German newspaper texts.
</summary>
    <author>
      <name>Thorsten Brants</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of EACL-99, Bergen, Norway</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/9906009v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9906009v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9906027v1</id>
    <updated>1999-06-25T11:44:42Z</updated>
    <published>1999-06-25T11:44:42Z</published>
    <title>Human-Computer Conversation</title>
    <summary>  The article surveys a little of the history of the technology, sets out the
main current theoretical approaches in brief, and discusses the on-going
opposition between theoretical and empirical approaches. It illustrates the
situation with some discussion of CONVERSE, a system that won the Loebner prize
in 1997 and which displays features of both approaches.
</summary>
    <author>
      <name>Yorick Wilks</name>
    </author>
    <author>
      <name>Roberta Catizone</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/9906027v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9906027v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7;H.1.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9906034v1</id>
    <updated>1999-06-30T23:06:09Z</updated>
    <published>1999-06-30T23:06:09Z</published>
    <title>A Unified Example-Based and Lexicalist Approach to Machine Translation</title>
    <summary>  We present an approach to Machine Translation that combines the ideas and
methodologies of the Example-Based and Lexicalist theoretical frameworks. The
approach has been implemented in a multilingual Machine Translation system.
</summary>
    <author>
      <name>Davide Turcato</name>
    </author>
    <author>
      <name>Paul McFetridge</name>
    </author>
    <author>
      <name>Fred Popowich</name>
    </author>
    <author>
      <name>Janine Toole</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, to be presented at the 8th International Conference on
  Theoretical and Methodological Issues in Machine Translation (TMI-99)</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/9906034v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9906034v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9907004v2</id>
    <updated>1999-10-14T00:31:39Z</updated>
    <published>1999-07-06T01:44:00Z</published>
    <title>MAP Lexicon is useful for segmentation and word discovery in
  child-directed speech</title>
    <summary>  Because of rather fundamental changes to the underlying model proposed in the
paper, it has been withdrawn from the archive.
</summary>
    <author>
      <name>Anand Venkataraman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Because of rather fundamental changes to the underlying model
  proposed in the paper, it has been withdrawn from the archive.</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/9907004v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9907004v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.6; I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9910011v1</id>
    <updated>1999-10-13T03:25:33Z</updated>
    <published>1999-10-13T03:25:33Z</published>
    <title>A statistical model for word discovery in child directed speech</title>
    <summary>  A statistical model for segmentation and word discovery in child directed
speech is presented. An incremental unsupervised learning algorithm to infer
word boundaries based on this model is described and results of empirical tests
showing that the algorithm is competitive with other models that have been used
for similar tasks are also presented.
</summary>
    <author>
      <name>Anand Venkataraman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">48 pgs, 10 figs</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/9910011v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9910011v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.6; I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9911006v1</id>
    <updated>1999-11-15T05:48:03Z</updated>
    <published>1999-11-15T05:48:03Z</published>
    <title>Question Answering System Using Syntactic Information</title>
    <summary>  Question answering task is now being done in TREC8 using English documents.
We examined question answering task in Japanese sentences. Our method selects
the answer by matching the question sentence with knowledge-based data written
in natural language. We use syntactic information to obtain highly accurate
answers.
</summary>
    <author>
      <name>M. Murata</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CRL</arxiv:affiliation>
    </author>
    <author>
      <name>M. Utiyama</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CRL</arxiv:affiliation>
    </author>
    <author>
      <name>H. Isahara</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CRL</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 0 figures. Computation and Language</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/9911006v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9911006v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3; I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0001012v1</id>
    <updated>2000-01-18T23:19:22Z</updated>
    <published>2000-01-18T23:19:22Z</published>
    <title>Measures of Distributional Similarity</title>
    <summary>  We study distributional similarity measures for the purpose of improving
probability estimation for unseen cooccurrences. Our contributions are
three-fold: an empirical comparison of a broad range of measures; a
classification of similarity functions based on the information that they
incorporate; and the introduction of a novel function that is superior at
evaluating potential proxy distributions.
</summary>
    <author>
      <name>Lillian Lee</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 3 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">37th Annual Meeting of the ACL, 1999, pp. 25-32</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0001012v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0001012v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0003083v1</id>
    <updated>2000-03-30T16:56:02Z</updated>
    <published>2000-03-30T16:56:02Z</published>
    <title>Advances in domain independent linear text segmentation</title>
    <summary>  This paper describes a method for linear text segmentation which is twice as
accurate and over seven times as fast as the state-of-the-art (Reynar, 1998).
Inter-sentence similarity is replaced by rank in the local context. Boundary
locations are discovered by divisive clustering.
</summary>
    <author>
      <name>Freddy Y. Y. Choi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Manchester</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 8 figures. To appear in Proceedings of NAACL00, Seattle.
  Software and experiment packages available from author's homepage:
  http://www.cs.man.ac.uk/~choif</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0003083v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0003083v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0009008v1</id>
    <updated>2000-09-18T12:08:54Z</updated>
    <published>2000-09-18T12:08:54Z</published>
    <title>Introduction to the CoNLL-2000 Shared Task: Chunking</title>
    <summary>  We describe the CoNLL-2000 shared task: dividing text into syntactically
related non-overlapping groups of words, so-called text chunking. We give
background information on the data sets, present a general overview of the
systems that have taken part in the shared task and briefly discuss their
performance.
</summary>
    <author>
      <name>Erik F. Tjong Kim Sang</name>
    </author>
    <author>
      <name>Sabine Buchholz</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of CoNLL-2000 and LLL-2000, Lisbon, Portugal</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0009008v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0009008v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0011040v1</id>
    <updated>2000-11-24T23:51:21Z</updated>
    <published>2000-11-24T23:51:21Z</published>
    <title>Do All Fragments Count?</title>
    <summary>  We aim at finding the minimal set of fragments which achieves maximal parse
accuracy in Data Oriented Parsing. Experiments with the Penn Wall Street
Journal treebank show that counts of almost arbitrary fragments within parse
trees are important, leading to improved parse accuracy over previous models
tested on this treebank. We isolate a number of dependency relations which
previous models neglect but which contribute to higher parse accuracy.
</summary>
    <author>
      <name>Rens Bod</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Technical Report COMP-11-12</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0011040v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0011040v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0103007v1</id>
    <updated>2001-03-08T06:30:27Z</updated>
    <published>2001-03-08T06:30:27Z</published>
    <title>Two-parameter Model of Word Length "Language - Genre"</title>
    <summary>  A two-parameter model of word length measured by the number of syllables
comprising it is proposed. The first parameter is dependent on language type,
the second one - on text genre and reflects the degree of completion of
synergetic processes of language optimization.
</summary>
    <author>
      <name>Victor Kromer</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2 pages, 1 figure. In Russian</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0103007v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0103007v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0105035v1</id>
    <updated>2001-05-30T03:55:23Z</updated>
    <published>2001-05-30T03:55:23Z</published>
    <title>Historical Dynamics of Lexical System as Random Walk Process</title>
    <summary>  It is offered to consider word meanings changes in diachrony as
semicontinuous random walk with reflecting and swallowing screens. The basic
characteristics of word life cycle are defined. Verification of the model has
been realized on the data of Russian words distribution on various age periods.
</summary>
    <author>
      <name>Victor Kromer</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 1 table, 3 figures. Submitted to conference "Language in
  Sinchrony and Diachrony", to be held in Petrozavodsk State Pedagogical
  University (Russia), 15-17 October, 2001. (In Russian)</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0105035v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0105035v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0107016v1</id>
    <updated>2001-07-15T12:51:01Z</updated>
    <published>2001-07-15T12:51:01Z</published>
    <title>Introduction to the CoNLL-2001 Shared Task: Clause Identification</title>
    <summary>  We describe the CoNLL-2001 shared task: dividing text into clauses. We give
background information on the data sets, present a general overview of the
systems that have taken part in the shared task and briefly discuss their
performance.
</summary>
    <author>
      <name>Erik F. Tjong Kim Sang</name>
    </author>
    <author>
      <name>Herve Dejean</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">In: Walter Daelemans and Remi Zajac (eds.), Proceedings of
  CoNLL-2001, Toulouse, France, 2001, pp. 53-57</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0107016v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0107016v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0111064v1</id>
    <updated>2001-11-30T20:30:52Z</updated>
    <published>2001-11-30T20:30:52Z</published>
    <title>A procedure for unsupervised lexicon learning</title>
    <summary>  We describe an incremental unsupervised procedure to learn words from
transcribed continuous speech. The algorithm is based on a conservative and
traditional statistical model, and results of empirical tests show that it is
competitive with other algorithms that have been proposed recently for this
task.
</summary>
    <author>
      <name>Anand Venkataraman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Expanded version of this paper appears in Computational Linguistics
  27(3)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the eighteenth international conference on machine
  learning, ICML-01, pp.569--576, 2001</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0111064v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0111064v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.6;I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0111065v1</id>
    <updated>2001-11-30T20:40:50Z</updated>
    <published>2001-11-30T20:40:50Z</published>
    <title>A Statistical Model for Word Discovery in Transcribed Speech</title>
    <summary>  A statistical model for segmentation and word discovery in continuous speech
is presented. An incremental unsupervised learning algorithm to infer word
boundaries based on this model is described. Results of empirical tests showing
that the algorithm is competitive with other models that have been used for
similar tasks are also presented.
</summary>
    <author>
      <name>Anand Venkataraman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Expanded version of ICML-01 paper (pp.569--576)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Computational Linguistics, 27(3), pp.352--372, 2001</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0111065v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0111065v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.6;I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0112005v1</id>
    <updated>2001-12-05T05:56:13Z</updated>
    <published>2001-12-05T05:56:13Z</published>
    <title>Universal Model for Paraphrasing -- Using Transformation Based on a
  Defined Criteria --</title>
    <summary>  This paper describes a universal model for paraphrasing that transforms
according to defined criteria. We showed that by using different criteria we
could construct different kinds of paraphrasing systems including one for
answering questions, one for compressing sentences, one for polishing up, and
one for transforming written language to spoken language.
</summary>
    <author>
      <name>Masaki Murata</name>
    </author>
    <author>
      <name>Hitoshi Isahara</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages. Computation and Language</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">NLPRS'2001, Workshop on Automatic Paraphrasing: Theories and
  Applications</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0112005v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0112005v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3; I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0204025v1</id>
    <updated>2002-04-11T11:22:43Z</updated>
    <published>2002-04-11T11:22:43Z</published>
    <title>Phonology</title>
    <summary>  Phonology is the systematic study of the sounds used in language, their
internal structure, and their composition into syllables, words and phrases.
Computational phonology is the application of formal and computational
techniques to the representation and processing of phonological information.
This chapter will present the fundamentals of descriptive phonology along with
a brief overview of computational phonology.
</summary>
    <author>
      <name>Steven Bird</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">27 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">In Ruslan Mitkov (ed) (2002). Oxford Handbook of Computational
  Linguistics</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0204025v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0204025v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7; J.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0205026v1</id>
    <updated>2002-05-17T08:24:56Z</updated>
    <published>2002-05-17T08:24:56Z</published>
    <title>Monads for natural language semantics</title>
    <summary>  Accounts of semantic phenomena often involve extending types of meanings and
revising composition rules at the same time. The concept of monads allows many
such accounts -- for intensionality, variable binding, quantification and focus
-- to be stated uniformly and compositionally.
</summary>
    <author>
      <name>Chung-chieh Shan</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Harvard University</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 2001 European Summer School in Logic, Language
  and Information student session, ed. Kristina Striegnitz, 285-298</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0205026v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0205026v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7; D.3.1; F.3.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0205067v1</id>
    <updated>2002-05-27T18:42:10Z</updated>
    <published>2002-05-27T18:42:10Z</published>
    <title>Evaluating the Effectiveness of Ensembles of Decision Trees in
  Disambiguating Senseval Lexical Samples</title>
    <summary>  This paper presents an evaluation of an ensemble--based system that
participated in the English and Spanish lexical sample tasks of Senseval-2. The
system combines decision trees of unigrams, bigrams, and co--occurrences into a
single classifier. The analysis is extended to include the Senseval-1 data.
</summary>
    <author>
      <name>Ted Pedersen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in the Proceedings of the ACL-02 Workshop on Word Sense
  Disambiguation: Recent Successes and Future Directions, July 11, 2002,
  Philadelphia, PA</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0205067v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0205067v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0205068v1</id>
    <updated>2002-05-27T18:49:01Z</updated>
    <published>2002-05-27T18:49:01Z</published>
    <title>Assessing System Agreement and Instance Difficulty in the Lexical Sample
  Tasks of Senseval-2</title>
    <summary>  This paper presents a comparative evaluation among the systems that
participated in the Spanish and English lexical sample tasks of Senseval-2. The
focus is on pairwise comparisons among systems to assess the degree to which
they agree, and on measuring the difficulty of the test instances included in
these tasks.
</summary>
    <author>
      <name>Ted Pedersen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in the Proceedings of the ACL-02 Workshop on Word Sense
  Disambiguation: Recent Successes and Future Directions, July 11, 2002,
  Philadelphia, PA</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0205068v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0205068v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0207005v1</id>
    <updated>2002-07-03T11:54:21Z</updated>
    <published>2002-07-03T11:54:21Z</published>
    <title>Efficient Deep Processing of Japanese</title>
    <summary>  We present a broad coverage Japanese grammar written in the HPSG formalism
with MRS semantics. The grammar is created for use in real world applications,
such that robustness and performance issues play an important role. It is
connected to a POS tagging and word segmentation tool. This grammar is being
developed in a multilingual context, requiring MRS structures that are easily
comparable across languages.
</summary>
    <author>
      <name>Melanie Siegel</name>
    </author>
    <author>
      <name>Emily M. Bender</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 19th International Conference on Computational
  Linguistics</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0207005v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0207005v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0209010v1</id>
    <updated>2002-09-05T19:03:06Z</updated>
    <published>2002-09-05T19:03:06Z</published>
    <title>Introduction to the CoNLL-2002 Shared Task: Language-Independent Named
  Entity Recognition</title>
    <summary>  We describe the CoNLL-2002 shared task: language-independent named entity
recognition. We give background information on the data sets and the evaluation
method, present a general overview of the systems that have taken part in the
task and discuss their performance.
</summary>
    <author>
      <name>Erik F. Tjong Kim Sang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Dan Roth and Antal van den Bosch (eds.), Proceedings of
  CoNLL-2002, Taipei, Taiwan, 2002, pp. 155-158</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0209010v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0209010v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0302032v1</id>
    <updated>2003-02-22T23:37:26Z</updated>
    <published>2003-02-22T23:37:26Z</published>
    <title>Empirical Methods for Compound Splitting</title>
    <summary>  Compounded words are a challenge for NLP applications such as machine
translation (MT). We introduce methods to learn splitting rules from
monolingual and parallel corpora. We evaluate them against a gold standard and
measure their impact on performance of statistical MT systems. Results show
accuracy of 99.1% and performance gains for MT of 0.039 BLEU on a
German-English noun phrase translation task.
</summary>
    <author>
      <name>Philipp Koehn</name>
    </author>
    <author>
      <name>Kevin Knight</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 2 figures. Published at EACL 2003</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0302032v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0302032v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0306050v1</id>
    <updated>2003-06-12T12:35:00Z</updated>
    <published>2003-06-12T12:35:00Z</published>
    <title>Introduction to the CoNLL-2003 Shared Task: Language-Independent Named
  Entity Recognition</title>
    <summary>  We describe the CoNLL-2003 shared task: language-independent named entity
recognition. We give background information on the data sets (English and
German) and the evaluation method, present a general overview of the systems
that have taken part in the task and discuss their performance.
</summary>
    <author>
      <name>Erik F. Tjong Kim Sang</name>
    </author>
    <author>
      <name>Fien De Meulder</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of CoNLL-2003, Edmonton, Canada, 2003, pp. 142-147</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0306050v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0306050v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0307030v1</id>
    <updated>2003-07-11T15:42:51Z</updated>
    <published>2003-07-11T15:42:51Z</published>
    <title>Parsing and Generation with Tabulation and Compilation</title>
    <summary>  The standard tabulation techniques for logic programming presuppose fixed
order of computation. Some data-driven control should be introduced in order to
deal with diverse contexts. The present paper describes a data-driven method of
constraint transformation with a sort of compilation which subsumes
accessibility check and last-call optimization, which characterize standard
natural-language parsing techniques, semantic-head-driven generation, etc.
</summary>
    <author>
      <name>Koiti Hasida</name>
    </author>
    <author>
      <name>Takashi Miyata</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 5 figures, Proceedings of TAPD'98, pp.26-35</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0307030v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0307030v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7; D.1.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0311033v1</id>
    <updated>2003-11-21T19:48:17Z</updated>
    <published>2003-11-21T19:48:17Z</published>
    <title>The Rank-Frequency Analysis for the Functional Style Corpora in the
  Ukrainian Language</title>
    <summary>  We use the rank-frequency analysis for the estimation of Kernel Vocabulary
size within specific corpora of Ukrainian. The extrapolation of high-rank
behaviour is utilized for estimation of the total vocabulary size.
</summary>
    <author>
      <name>Solomija N. Buk</name>
    </author>
    <author>
      <name>Andrij A. Rovenchak</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1080/0929617042000314912</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1080/0929617042000314912" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Quantitative Linguistics, Vol. 11, No. 3, P. 161-171
  (2004)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0311033v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0311033v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0404009v1</id>
    <updated>2004-04-05T11:51:43Z</updated>
    <published>2004-04-05T11:51:43Z</published>
    <title>Tabular Parsing</title>
    <summary>  This is a tutorial on tabular parsing, on the basis of tabulation of
nondeterministic push-down automata. Discussed are Earley's algorithm, the
Cocke-Kasami-Younger algorithm, tabular LR parsing, the construction of parse
trees, and further issues.
</summary>
    <author>
      <name>Mark-Jan Nederhof</name>
    </author>
    <author>
      <name>Giorgio Satta</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages, 14 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">M.-J. Nederhof and G. Satta. Tabular Parsing. In C. Martin-Vide,
  V. Mitrana, and G. Paun, editors, Formal Languages and Applications, Studies
  in Fuzziness and Soft Computing 148, pages 529-549. Springer, 2004</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0404009v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0404009v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.4.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0405037v1</id>
    <updated>2004-05-10T16:05:23Z</updated>
    <published>2004-05-10T16:05:23Z</published>
    <title>A Probabilistic Model of Machine Translation</title>
    <summary>  A probabilistic model for computer-based generation of a machine translation
system on the basis of English-Russian parallel text corpora is suggested. The
model is trained using parallel text corpora with pre-aligned source and target
sentences. The training of the model results in a bilingual dictionary of words
and "word blocks" with relevant translation probability.
</summary>
    <author>
      <name>G. E. Miram</name>
    </author>
    <author>
      <name>V. K. Petrov</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0405037v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0405037v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0406054v1</id>
    <updated>2004-06-28T10:25:22Z</updated>
    <published>2004-06-28T10:25:22Z</published>
    <title>Building a linguistic corpus from bee dance data</title>
    <summary>  This paper discusses the problems and possibility of collecting bee dance
data in a linguistic \textit{corpus} and use linguistic instruments such as
Zipf's law and entropy statistics to decide on the question whether the dance
carries information of any kind. We describe this against the historical
background of attempts to analyse non-human communication systems.
</summary>
    <author>
      <name>J. J. Paijmans</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the first international congres of bioinformatics,
  Havana (Cuba), 2004</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0406054v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0406054v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0407046v1</id>
    <updated>2004-07-19T11:57:42Z</updated>
    <published>2004-07-19T11:57:42Z</published>
    <title>A Bimachine Compiler for Ranked Tagging Rules</title>
    <summary>  This paper describes a novel method of compiling ranked tagging rules into a
deterministic finite-state device called a bimachine. The rules are formulated
in the framework of regular rewrite operations and allow unrestricted regular
expressions in both left and right rule contexts. The compiler is illustrated
by an application within a speech synthesis system.
</summary>
    <author>
      <name>Wojciech Skut</name>
    </author>
    <author>
      <name>Stefan Ulrich</name>
    </author>
    <author>
      <name>Kathrine Hammervold</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 3 figures Proceedings of COLING 2004 (to appear)</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0407046v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0407046v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7;F.4.2;F.4.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0501078v1</id>
    <updated>2005-01-26T22:43:17Z</updated>
    <published>2005-01-26T22:43:17Z</published>
    <title>Multi-document Biography Summarization</title>
    <summary>  In this paper we describe a biography summarization system using sentence
classification and ideas from information retrieval. Although the individual
techniques are not new, assembling and applying them to generate multi-document
biographies is new. Our system was evaluated in DUC2004. It is among the top
performers in task 5-short summaries focused by person questions.
</summary>
    <author>
      <name>Liang Zhou</name>
    </author>
    <author>
      <name>Miruna Ticrea</name>
    </author>
    <author>
      <name>Eduard Hovy</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of EMNLP, pp. 434-441, 2004</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0501078v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0501078v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0504022v1</id>
    <updated>2005-04-06T20:04:55Z</updated>
    <published>2005-04-06T20:04:55Z</published>
    <title>A Matter of Opinion: Sentiment Analysis and Business Intelligence
  (position paper)</title>
    <summary>  A general-audience introduction to the area of "sentiment analysis", the
computational treatment of subjective, opinion-oriented language (an example
application is determining whether a review is "thumbs up" or "thumbs down").
Some challenges, applications to business-intelligence tasks, and potential
future directions are described.
</summary>
    <author>
      <name>Lillian Lee</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Presented at the IBM Faculty Summit on the Architecture of
  On-Demand Business, May 2004</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0504022v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0504022v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0504074v1</id>
    <updated>2005-04-15T20:10:53Z</updated>
    <published>2005-04-15T20:10:53Z</published>
    <title>Metalinguistic Information Extraction for Terminology</title>
    <summary>  This paper describes and evaluates the Metalinguistic Operation Processor
(MOP) system for automatic compilation of metalinguistic information from
technical and scientific documents. This system is designed to extract
non-standard terminological resources that we have called Metalinguistic
Information Databases (or MIDs), in order to help update changing glossaries,
knowledge bases and ontologies, as well as to reflect the metastable dynamics
of special-domain knowledge.
</summary>
    <author>
      <name>Carlos Rodriguez</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented at CompuTerm 2004, COLING. Geneve</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0504074v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0504074v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0510015v1</id>
    <updated>2005-10-05T14:23:19Z</updated>
    <published>2005-10-05T14:23:19Z</published>
    <title>Word sense disambiguation criteria: a systematic study</title>
    <summary>  This article describes the results of a systematic in-depth study of the
criteria used for word sense disambiguation. Our study is based on 60 target
words: 20 nouns, 20 adjectives and 20 verbs. Our results are not always in line
with some practices in the field. For example, we show that omitting
non-content words decreases performance and that bigrams yield better results
than unigrams.
</summary>
    <author>
      <name>Laurent Audibert</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">DELIC</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">20th International Conference on Computational Linguistics
  (COLING-2004) (2004) pp. 910-916</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0510015v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0510015v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0605076v1</id>
    <updated>2006-05-17T17:12:25Z</updated>
    <published>2006-05-17T17:12:25Z</published>
    <title>Numeration-automatic sequences</title>
    <summary>  We present a base class of automata that induce a numeration system and we
give an algorithm to give the n-th word in the language of the automaton when
the expansion of n in the induced numeration system is feeded to the automaton.
Furthermore we give some algorithms for reverse reading of this expansion and a
way to combine automata to other automata having the same properties.
</summary>
    <author>
      <name>J. F. J. Laros</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">25 pages, 22 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0605076v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0605076v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0609043v1</id>
    <updated>2006-09-08T14:01:57Z</updated>
    <published>2006-09-08T14:01:57Z</published>
    <title>Challenging the principle of compositionality in interpreting natural
  language texts</title>
    <summary>  The paper aims at emphasizing that, even relaxed, the hypothesis of
compositionality has to face many problems when used for interpreting natural
language texts. Rather than fixing these problems within the compositional
framework, we believe that a more radical change is necessary, and propose
another approach.
</summary>
    <author>
      <name>Françoise Gayral</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIPN</arxiv:affiliation>
    </author>
    <author>
      <name>Daniel Kayser</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIPN</arxiv:affiliation>
    </author>
    <author>
      <name>François Lévy</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIPN</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">conference on Compositionality, Concepts and Cognition, Allemagne
  (2004)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0609043v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0609043v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0707.3269v1</id>
    <updated>2007-07-22T15:24:48Z</updated>
    <published>2007-07-22T15:24:48Z</published>
    <title>International Standard for a Linguistic Annotation Framework</title>
    <summary>  This paper describes the Linguistic Annotation Framework under development
within ISO TC37 SC4 WG1. The Linguistic Annotation Framework is intended to
serve as a basis for harmonizing existing language resources as well as
developing new ones.
</summary>
    <author>
      <name>Laurent Romary</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Lorraine - LORIA</arxiv:affiliation>
    </author>
    <author>
      <name>Nancy Ide</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Lorraine - LORIA</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Natural Language Engineering 10, 3-4 (09/2004) 211-225</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0707.3269v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0707.3269v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0711.2444v1</id>
    <updated>2007-11-15T15:39:48Z</updated>
    <published>2007-11-15T15:39:48Z</published>
    <title>Proof nets for display logic</title>
    <summary>  This paper explores several extensions of proof nets for the Lambek calculus
in order to handle the different connectives of display logic in a natural way.
The new proof net calculus handles some recent additions to the Lambek
vocabulary such as Galois connections and Grishin interactions. It concludes
with an exploration of the generative capacity of the Lambek-Grishin calculus,
presenting an embedding of lexicalized tree adjoining grammars into the
Lambek-Grishin calculus.
</summary>
    <author>
      <name>Richard Moot</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Futurs, Labri</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/0711.2444v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0711.2444v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0808.2904v1</id>
    <updated>2008-08-21T10:54:54Z</updated>
    <published>2008-08-21T10:54:54Z</published>
    <title>Investigation of the Zipf-plot of the extinct Meroitic language</title>
    <summary>  The ancient and extinct language Meroitic is investigated using Zipf's Law.
In particular, since Meroitic is still undeciphered, the Zipf law analysis
allows us to assess the quality of current texts and possible avenues for
future investigation using statistical techniques.
</summary>
    <author>
      <name>Reginald D. Smith</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 2 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Glottometrics 15, 2007, 53-61</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0808.2904v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0808.2904v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0808.3889v1</id>
    <updated>2008-08-28T11:59:34Z</updated>
    <published>2008-08-28T11:59:34Z</published>
    <title>Open architecture for multilingual parallel texts</title>
    <summary>  Multilingual parallel texts (abbreviated to parallel texts) are linguistic
versions of the same content ("translations"); e.g., the Maastricht Treaty in
English and Spanish are parallel texts. This document is about creating an open
architecture for the whole Authoring, Translation and Publishing Chain
(ATP-chain) for the processing of parallel texts.
</summary>
    <author>
      <name>M. T. Carrasco Benitez</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">22 pages - for comments to the author and follow-ups go to
  http://dragoman.org/par</arxiv:comment>
    <link href="http://arxiv.org/abs/0808.3889v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0808.3889v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0810.0200v1</id>
    <updated>2008-10-01T15:53:36Z</updated>
    <published>2008-10-01T15:53:36Z</published>
    <title>Distribution of complexities in the Vai script</title>
    <summary>  In the paper, we analyze the distribution of complexities in the Vai script,
an indigenous syllabic writing system from Liberia. It is found that the
uniformity hypothesis for complexities fails for this script. The models using
Poisson distribution for the number of components and hyper-Poisson
distribution for connections provide good fits in the case of the Vai script.
</summary>
    <author>
      <name>Andrij Rovenchak</name>
    </author>
    <author>
      <name>Ján Mačutek</name>
    </author>
    <author>
      <name>Charles Riley</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Glottometrics 18, 1-12 (2009)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0810.0200v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0810.0200v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0810.3416v1</id>
    <updated>2008-10-19T17:34:33Z</updated>
    <published>2008-10-19T17:34:33Z</published>
    <title>Text as Statistical Mechanics Object</title>
    <summary>  In this article we present a model of human written text based on statistical
mechanics approach by deriving the potential energy for different parts of the
text using large text corpus. We have checked the results numerically and found
that the specific heat parameter effectively separates the closed class words
from the specific terms used in the text.
</summary>
    <author>
      <name>K. Koroutchev</name>
    </author>
    <author>
      <name>E. Korutcheva</name>
    </author>
    <link href="http://arxiv.org/abs/0810.3416v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0810.3416v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0906.5114v1</id>
    <updated>2009-06-28T02:32:53Z</updated>
    <published>2009-06-28T02:32:53Z</published>
    <title>Non-Parametric Bayesian Areal Linguistics</title>
    <summary>  We describe a statistical model over linguistic areas and phylogeny.
  Our model recovers known areas and identifies a plausible hierarchy of areal
features. The use of areas improves genetic reconstruction of languages both
qualitatively and quantitatively according to a variety of metrics. We model
linguistic areas by a Pitman-Yor process and linguistic phylogeny by Kingman's
coalescent.
</summary>
    <author>
      <name>Hal Daumé III</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the Conference of the North American Association
  for Computational Linguistics, 2009</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0906.5114v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0906.5114v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0908.4431v1</id>
    <updated>2009-08-30T23:20:41Z</updated>
    <published>2009-08-30T23:20:41Z</published>
    <title>An OLAC Extension for Dravidian Languages</title>
    <summary>  OLAC was founded in 2000 for creating online databases of language resources.
This paper intends to review the bottom-up distributed character of the project
and proposes an extension of the architecture for Dravidian languages. An
ontological structure is considered for effective natural language processing
(NLP) and its advantages over statistical methods are reviewed
</summary>
    <author>
      <name>B Prabhulla Chandran Pillai</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 Pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0908.4431v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0908.4431v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0909.1147v1</id>
    <updated>2009-09-07T06:29:51Z</updated>
    <published>2009-09-07T06:29:51Z</published>
    <title>Empowering OLAC Extension using Anusaaraka and Effective text processing
  using Double Byte coding</title>
    <summary>  The paper reviews the hurdles while trying to implement the OLAC extension
for Dravidian / Indian languages. The paper further explores the possibilities
which could minimise or solve these problems. In this context, the Chinese
system of text processing and the anusaaraka system are scrutinised.
</summary>
    <author>
      <name>B Prabhulla Chandran Pillai</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 Pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0909.1147v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0909.1147v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0912.2881v2</id>
    <updated>2009-12-16T08:02:57Z</updated>
    <published>2009-12-15T13:30:14Z</published>
    <title>Representing human and machine dictionaries in Markup languages</title>
    <summary>  In this chapter we present the main issues in representing machine readable
dictionaries in XML, and in particular according to the Text Encoding
Dictionary (TEI) guidelines.
</summary>
    <author>
      <name>Lothar Lemnitzer</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Saclay - Ile de France, IDSL</arxiv:affiliation>
    </author>
    <author>
      <name>Laurent Romary</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Saclay - Ile de France, IDSL</arxiv:affiliation>
    </author>
    <author>
      <name>Andreas Witt</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Dictionaries. An International Encyclopedia of Lexicography.
  Supplementary volume: Recent developments with special focus on computational
  lexicography, Ulrich Heid (Ed.) (2010)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0912.2881v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0912.2881v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1002.0904v1</id>
    <updated>2010-02-04T06:30:14Z</updated>
    <published>2010-02-04T06:30:14Z</published>
    <title>On Event Structure in the Torn Dress</title>
    <summary>  Using Pustejovsky's "The Syntax of Event Structure" and Fong's "On Mending a
Torn Dress" we give a glimpse of a Pustejovsky-like analysis to some example
sentences in Fong. We attempt to give a framework for semantics to the noun
phrases and adverbs as appropriate as well as the lexical entries for all words
in the examples and critique both papers in light of our findings and
difficulties.
</summary>
    <author>
      <name>Serguei A. Mokhov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages; a 2003 report</arxiv:comment>
    <link href="http://arxiv.org/abs/1002.0904v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1002.0904v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1004.4181v1</id>
    <updated>2010-04-23T17:00:18Z</updated>
    <published>2010-04-23T17:00:18Z</published>
    <title>Displacement Calculus</title>
    <summary>  The Lambek calculus provides a foundation for categorial grammar in the form
of a logic of concatenation. But natural language is characterized by
dependencies which may also be discontinuous. In this paper we introduce the
displacement calculus, a generalization of Lambek calculus, which preserves its
good proof-theoretic properties while embracing discontinuiity and subsuming
it. We illustrate linguistic applications and prove Cut-elimination, the
subformula property, and decidability
</summary>
    <author>
      <name>Glyn Morrill</name>
    </author>
    <author>
      <name>Oriol Valentín</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">26 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1004.4181v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1004.4181v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1005.3902v1</id>
    <updated>2010-05-21T08:12:12Z</updated>
    <published>2010-05-21T08:12:12Z</published>
    <title>Morphonette: a morphological network of French</title>
    <summary>  This paper describes in details the first version of Morphonette, a new
French morphological resource and a new radically lexeme-based method of
morphological analysis. This research is grounded in a paradigmatic conception
of derivational morphology where the morphological structure is a structure of
the entire lexicon and not one of the individual words it contains. The
discovery of this structure relies on a measure of morphological similarity
between words, on formal analogy and on the properties of two morphological
paradigms:
</summary>
    <author>
      <name>Nabil Hathout</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CLLE</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/1005.3902v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1005.3902v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1108.5016v1</id>
    <updated>2011-08-25T06:07:06Z</updated>
    <published>2011-08-25T06:07:06Z</published>
    <title>Une analyse basée sur la S-DRT pour la modélisation de dialogues
  pathologiques</title>
    <summary>  In this article, we present a corpus of dialogues between a schizophrenic
speaker and an interlocutor who drives the dialogue. We had identified specific
discontinuities for paranoid schizophrenics. We propose a modeling of these
discontinuities with S-DRT (its pragmatic part)
</summary>
    <author>
      <name>Maxime Amblard</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LORIA</arxiv:affiliation>
    </author>
    <author>
      <name>Musiol Michel</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LABPSYLOR</arxiv:affiliation>
    </author>
    <author>
      <name>Rebuschi Manuel</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LHSP</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Traitement Automatique des Langues, Montpellier : France (2011)</arxiv:comment>
    <link href="http://arxiv.org/abs/1108.5016v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1108.5016v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.6553v1</id>
    <updated>2011-11-28T19:17:57Z</updated>
    <published>2011-11-28T19:17:57Z</published>
    <title>Exploring Twitter Hashtags</title>
    <summary>  Twitter messages often contain so-called hashtags to denote keywords related
to them. Using a dataset of 29 million messages, I explore relations among
these hashtags with respect to co-occurrences. Furthermore, I present an
attempt to classify hashtags into five intuitive classes, using a
machine-learning approach. The overall outcome is an interactive Web
application to explore Twitter hashtags.
</summary>
    <author>
      <name>Jan Pöschko</name>
    </author>
    <link href="http://arxiv.org/abs/1111.6553v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.6553v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1201.1192v1</id>
    <updated>2012-01-05T15:22:05Z</updated>
    <published>2012-01-05T15:22:05Z</published>
    <title>Formalization of semantic network of image constructions in electronic
  content</title>
    <summary>  A formal theory based on a binary operator of directional associative
relation is constructed in the article and an understanding of an associative
normal form of image constructions is introduced. A model of a commutative
semigroup, which provides a presentation of a sentence as three components of
an interrogative linguistic image construction, is considered.
</summary>
    <author>
      <name>Oleg Bisikalo</name>
    </author>
    <author>
      <name>Irina Kravchuk</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1201.1192v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1201.1192v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.6735v1</id>
    <updated>2012-06-28T15:43:57Z</updated>
    <published>2012-06-28T15:43:57Z</published>
    <title>Elimination of Spurious Ambiguity in Transition-Based Dependency Parsing</title>
    <summary>  We present a novel technique to remove spurious ambiguity from transition
systems for dependency parsing. Our technique chooses a canonical sequence of
transition operations (computation) for a given dependency tree. Our technique
can be applied to a large class of bottom-up transition systems, including for
instance Nivre (2004) and Attardi (2006).
</summary>
    <author>
      <name>Shay B. Cohen</name>
    </author>
    <author>
      <name>Carlos Gómez-Rodríguez</name>
    </author>
    <author>
      <name>Giorgio Satta</name>
    </author>
    <link href="http://arxiv.org/abs/1206.6735v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.6735v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.2265v1</id>
    <updated>2012-07-10T08:48:13Z</updated>
    <published>2012-07-10T08:48:13Z</published>
    <title>Challenges for Distributional Compositional Semantics</title>
    <summary>  This paper summarises the current state-of-the art in the study of
compositionality in distributional semantics, and major challenges for this
area. We single out generalised quantifiers and intensional semantics as areas
on which to focus attention for the development of the theory. Once suitable
theories have been developed, algorithms will be needed to apply the theory to
tasks. Evaluation is a major problem; we single out application to recognising
textual entailment and machine translation for this purpose.
</summary>
    <author>
      <name>Daoud Clarke</name>
    </author>
    <link href="http://arxiv.org/abs/1207.2265v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.2265v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1208.2777v1</id>
    <updated>2012-08-14T03:25:33Z</updated>
    <published>2012-08-14T03:25:33Z</published>
    <title>A Method for Selecting Noun Sense using Co-occurrence Relation in
  English-Korean Translation</title>
    <summary>  The sense analysis is still critical problem in machine translation system,
especially such as English-Korean translation which the syntactical different
between source and target languages is very great. We suggest a method for
selecting the noun sense using contextual feature in English-Korean
Translation.
</summary>
    <author>
      <name>Hyonil Kim</name>
    </author>
    <author>
      <name>Changil Choe</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Serdica Journal of Computing, Vol.'6 No.4, 2012, pp. 401-408</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1208.2777v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1208.2777v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1208.4503v1</id>
    <updated>2012-08-22T14:11:07Z</updated>
    <published>2012-08-22T14:11:07Z</published>
    <title>Introduction of the weight edition errors in the Levenshtein distance</title>
    <summary>  In this paper, we present a new approach dedicated to correcting the spelling
errors of the Arabic language. This approach corrects typographical errors like
inserting, deleting, and permutation. Our method is inspired from the
Levenshtein algorithm, and allows a finer and better scheduling than
Levenshtein. The results obtained are very satisfactory and encouraging, which
shows the interest of our new approach.
</summary>
    <author>
      <name>Gueddah Hicham</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3 pages, 5 figures; International Journal of Advanced Research in
  Artificial Intelligence (IJARAI)2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1208.4503v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1208.4503v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.0249v1</id>
    <updated>2012-09-03T06:00:04Z</updated>
    <published>2012-09-03T06:00:04Z</published>
    <title>Robopinion: Opinion Mining Framework Inspired by Autonomous Robot
  Navigation</title>
    <summary>  Data association methods are used by autonomous robots to find matches
between the current landmarks and the new set of observed features. We seek a
framework for opinion mining to benefit from advancements in autonomous robot
navigation in both research and development
</summary>
    <author>
      <name>M. A. El-Dosuky</name>
    </author>
    <author>
      <name>M. Z. Rashad</name>
    </author>
    <author>
      <name>T. T. Hamza</name>
    </author>
    <author>
      <name>A. H. EL-Bassiouny</name>
    </author>
    <link href="http://arxiv.org/abs/1209.0249v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.0249v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.4471v1</id>
    <updated>2012-09-20T09:21:29Z</updated>
    <published>2012-09-20T09:21:29Z</published>
    <title>Stemmer for Serbian language</title>
    <summary>  In linguistic morphology and information retrieval, stemming is the process
for reducing inflected (or sometimes derived) words to their stem, base or root
form; generally a written word form. In this work is presented suffix stripping
stemmer for Serbian language, one of the highly inflectional languages.
</summary>
    <author>
      <name>Nikola Milošević</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 8 figures, code included</arxiv:comment>
    <link href="http://arxiv.org/abs/1209.4471v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.4471v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.0252v2</id>
    <updated>2014-02-15T11:25:46Z</updated>
    <published>2012-09-30T22:55:45Z</published>
    <title>A Linguistic Model for Terminology Extraction based Conditional Random
  Fields</title>
    <summary>  In this paper, we show the possibility of using a linear Conditional Random
Fields (CRF) for terminology extraction from a specialized text corpus.
</summary>
    <author>
      <name>Fethi Fkih</name>
    </author>
    <author>
      <name>Mohamed Nazih Omri</name>
    </author>
    <author>
      <name>Imen Toumia</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper has been withdrawn by the author due to the poor
  readability and the low quality of the English</arxiv:comment>
    <link href="http://arxiv.org/abs/1210.0252v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.0252v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.6; I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1302.4619v1</id>
    <updated>2013-02-19T14:32:17Z</updated>
    <published>2013-02-19T14:32:17Z</published>
    <title>Compactified Horizontal Visibility Graph for the Language Network</title>
    <summary>  A compactified horizontal visibility graph for the language network is
proposed. It was found that the networks constructed in such way are scale
free, and have a property that among the nodes with largest degrees there are
words that determine not only a text structure communication, but also its
informational structure.
</summary>
    <author>
      <name>D. V. Lande</name>
    </author>
    <author>
      <name>A. A. Snarskii</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 3 figures, 2 appendix tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1302.4619v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1302.4619v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1305.5785v1</id>
    <updated>2013-05-24T16:34:22Z</updated>
    <published>2013-05-24T16:34:22Z</published>
    <title>An Inventory of Preposition Relations</title>
    <summary>  We describe an inventory of semantic relations that are expressed by
prepositions. We define these relations by building on the word sense
disambiguation task for prepositions and propose a mapping from preposition
senses to the relation labels by collapsing semantically related senses across
prepositions.
</summary>
    <author>
      <name>Vivek Srikumar</name>
    </author>
    <author>
      <name>Dan Roth</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Supplementary material for Srikumar and Roth, 2013. Modeling Semantic
  Relations Expressed by Prepositions, TACL</arxiv:comment>
    <link href="http://arxiv.org/abs/1305.5785v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1305.5785v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1305.6238v1</id>
    <updated>2013-05-27T14:36:53Z</updated>
    <published>2013-05-27T14:36:53Z</published>
    <title>Extended Lambek calculi and first-order linear logic</title>
    <summary>  First-order multiplicative intuitionistic linear logic (MILL1) can be seen as
an extension of the Lambek calculus. In addition to the fragment of MILL1 which
corresponds to the Lambek calculus (of Moot &amp; Piazza 2001), I will show
fragments of MILL1 which generate the multiple context-free languages and which
correspond to the Displacement calculus of Morrilll e.a.
</summary>
    <author>
      <name>Richard Moot</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LaBRI</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Logic and Language, Allemagne (2013)</arxiv:comment>
    <link href="http://arxiv.org/abs/1305.6238v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1305.6238v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1306.1343v1</id>
    <updated>2013-06-06T08:56:32Z</updated>
    <published>2013-06-06T08:56:32Z</published>
    <title>The User Feedback on SentiWordNet</title>
    <summary>  With the release of SentiWordNet 3.0 the related Web interface has been
restyled and improved in order to allow users to submit feedback on the
SentiWordNet entries, in the form of the suggestion of alternative triplets of
values for an entry. This paper reports on the release of the user feedback
collected so far and on the plans for the future.
</summary>
    <author>
      <name>Andrea Esuli</name>
    </author>
    <link href="http://arxiv.org/abs/1306.1343v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1306.1343v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1306.4134v1</id>
    <updated>2013-06-18T10:32:43Z</updated>
    <published>2013-06-18T10:32:43Z</published>
    <title>Dialogue System: A Brief Review</title>
    <summary>  A Dialogue System is a system which interacts with human in natural language.
At present many universities are developing the dialogue system in their
regional language. This paper will discuss about dialogue system, its
components, challenges and its evaluation. This paper helps the researchers for
getting info regarding dialogues system.
</summary>
    <author>
      <name>Suket Arora</name>
    </author>
    <author>
      <name>Kamaljeet Batra</name>
    </author>
    <author>
      <name>Sarabjit Singh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4</arxiv:comment>
    <link href="http://arxiv.org/abs/1306.4134v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1306.4134v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1306.6944v1</id>
    <updated>2013-06-07T15:48:06Z</updated>
    <published>2013-06-07T15:48:06Z</published>
    <title>The DeLiVerMATH project - Text analysis in mathematics</title>
    <summary>  A high-quality content analysis is essential for retrieval functionalities
but the manual extraction of key phrases and classification is expensive.
Natural language processing provides a framework to automatize the process.
Here, a machine-based approach for the content analysis of mathematical texts
is described. A prototype for key phrase extraction and classification of
mathematical texts is presented.
</summary>
    <author>
      <name>Ulf Schöneberg</name>
    </author>
    <author>
      <name>Wolfram Sperber</name>
    </author>
    <link href="http://arxiv.org/abs/1306.6944v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1306.6944v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1308.5499v1</id>
    <updated>2013-08-26T07:18:17Z</updated>
    <published>2013-08-26T07:18:17Z</published>
    <title>Linear models and linear mixed effects models in R with linguistic
  applications</title>
    <summary>  This text is a conceptual introduction to mixed effects modeling with
linguistic applications, using the R programming environment. The reader is
introduced to linear modeling and assumptions, as well as to mixed
effects/multilevel modeling, including a discussion of random intercepts,
random slopes and likelihood ratio tests. The example used throughout the text
focuses on the phonetic analysis of voice pitch data.
</summary>
    <author>
      <name>Bodo Winter</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">42 pages, 17 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1308.5499v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1308.5499v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1311.6063v4</id>
    <updated>2014-10-13T20:43:09Z</updated>
    <published>2013-11-23T22:39:52Z</published>
    <title>A Short Introduction to NILE</title>
    <summary>  In this paper, we briefly introduce the Narrative Information Linear
Extraction (NILE) system, a natural language processing library for clinical
narratives. NILE is an experiment of our ideas on efficient and effective
medical language processing. We introduce the overall design of NILE and its
major components, and show the performance of it in real projects.
</summary>
    <author>
      <name>Sheng Yu</name>
    </author>
    <author>
      <name>Tianxi Cai</name>
    </author>
    <link href="http://arxiv.org/abs/1311.6063v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1311.6063v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1401.4869v1</id>
    <updated>2014-01-20T11:49:11Z</updated>
    <published>2014-01-20T11:49:11Z</published>
    <title>Does Syntactic Knowledge help English-Hindi SMT?</title>
    <summary>  In this paper we explore various parameter settings of the state-of-art
Statistical Machine Translation system to improve the quality of the
translation for a `distant' language pair like English-Hindi. We proposed new
techniques for efficient reordering. A slight improvement over the baseline is
reported using these techniques. We also show that a simple pre-processing step
can improve the quality of the translation significantly.
</summary>
    <author>
      <name>Taraka Rama</name>
    </author>
    <author>
      <name>Karthik Gali</name>
    </author>
    <author>
      <name>Avinesh PVS</name>
    </author>
    <link href="http://arxiv.org/abs/1401.4869v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1401.4869v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1402.0543v1</id>
    <updated>2014-02-03T23:09:28Z</updated>
    <published>2014-02-03T23:09:28Z</published>
    <title>How Does Latent Semantic Analysis Work? A Visualisation Approach</title>
    <summary>  By using a small example, an analogy to photographic compression, and a
simple visualization using heatmaps, we show that latent semantic analysis
(LSA) is able to extract what appears to be semantic meaning of words from a
set of documents by blurring the distinctions between the words.
</summary>
    <author>
      <name>Jan Koeman</name>
    </author>
    <author>
      <name>William Rea</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 6 figures, 2 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1402.0543v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1402.0543v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1402.2796v1</id>
    <updated>2014-02-12T11:55:31Z</updated>
    <published>2014-02-12T11:55:31Z</published>
    <title>PR2: A Language Independent Unsupervised Tool for Personality
  Recognition from Text</title>
    <summary>  We present PR2, a personality recognition system available online, that
performs instance-based classification of Big5 personality types from
unstructured text, using language-independent features. It has been tested on
English and Italian, achieving performances up to f=.68.
</summary>
    <author>
      <name>Fabio Celli</name>
    </author>
    <author>
      <name>Massimo Poesio</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, peer reviewed</arxiv:comment>
    <link href="http://arxiv.org/abs/1402.2796v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1402.2796v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1402.7265v1</id>
    <updated>2014-02-28T14:49:31Z</updated>
    <published>2014-02-28T14:49:31Z</published>
    <title>Semantics, Modelling, and the Problem of Representation of Meaning -- a
  Brief Survey of Recent Literature</title>
    <summary>  Over the past 50 years many have debated what representation should be used
to capture the meaning of natural language utterances. Recently new needs of
such representations have been raised in research. Here I survey some of the
interesting representations suggested to answer for these new needs.
</summary>
    <author>
      <name>Yarin Gal</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, no figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1402.7265v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1402.7265v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1403.4928v1</id>
    <updated>2014-03-19T19:59:49Z</updated>
    <published>2014-03-19T19:59:49Z</published>
    <title>Clinical TempEval</title>
    <summary>  We describe the Clinical TempEval task which is currently in preparation for
the SemEval-2015 evaluation exercise. This task involves identifying and
describing events, times and the relations between them in clinical text. Six
discrete subtasks are included, focusing on recognising mentions of times and
events, describing those mentions for both entity types, identifying the
relation between an event and the document creation time, and identifying
narrative container relations.
</summary>
    <author>
      <name>Steven Bethard</name>
    </author>
    <author>
      <name>Leon Derczynski</name>
    </author>
    <author>
      <name>James Pustejovsky</name>
    </author>
    <author>
      <name>Marc Verhagen</name>
    </author>
    <link href="http://arxiv.org/abs/1403.4928v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1403.4928v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.1872v1</id>
    <updated>2014-04-07T18:12:08Z</updated>
    <published>2014-04-07T18:12:08Z</published>
    <title>Intégration des données d'un lexique syntaxique dans un analyseur
  syntaxique probabiliste</title>
    <summary>  This article reports the evaluation of the integration of data from a
syntactic-semantic lexicon, the Lexicon-Grammar of French, into a syntactic
parser. We show that by changing the set of labels for verbs and predicational
nouns, we can improve the performance on French of a non-lexicalized
probabilistic parser.
</summary>
    <author>
      <name>Anthony Sigogne</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIGM</arxiv:affiliation>
    </author>
    <author>
      <name>Matthieu Constant</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIGM</arxiv:affiliation>
    </author>
    <author>
      <name>Eric Laporte</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIGM</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">in French</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Penser le Lexique-Grammaire. Perspectives actuelles, Fryni
  Kakoyianni-Doa (Ed.) (2014) 505-516</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1404.1872v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.1872v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.0947v1</id>
    <updated>2014-05-05T16:24:09Z</updated>
    <published>2014-05-05T16:24:09Z</published>
    <title>Learning Bilingual Word Representations by Marginalizing Alignments</title>
    <summary>  We present a probabilistic model that simultaneously learns alignments and
distributed representations for bilingual data. By marginalizing over word
alignments the model captures a larger semantic context than prior work relying
on hard alignments. The advantage of this approach is demonstrated in a
cross-lingual classification task, where we outperform the prior published
state of the art.
</summary>
    <author>
      <name>Tomáš Kočiský</name>
    </author>
    <author>
      <name>Karl Moritz Hermann</name>
    </author>
    <author>
      <name>Phil Blunsom</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of ACL 2014 (Short Papers)</arxiv:comment>
    <link href="http://arxiv.org/abs/1405.0947v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.0947v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.6068v1</id>
    <updated>2014-05-23T14:05:45Z</updated>
    <published>2014-05-23T14:05:45Z</published>
    <title>Building of Networks of Natural Hierarchies of Terms Based on Analysis
  of Texts Corpora</title>
    <summary>  The technique of building of networks of hierarchies of terms based on the
analysis of chosen text corpora is offered. The technique is based on the
methodology of horizontal visibility graphs. Constructed and investigated
language network, formed on the basis of electronic preprints arXiv on topics
of information retrieval.
</summary>
    <author>
      <name>Dmitry Lande</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1405.6068v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.6068v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.6682v1</id>
    <updated>2014-05-26T18:51:06Z</updated>
    <published>2014-05-26T18:51:06Z</published>
    <title>Optimality Theory as a Framework for Lexical Acquisition</title>
    <summary>  This paper re-investigates a lexical acquisition system initially developed
for French.We show that, interestingly, the architecture of the system
reproduces and implements the main components of Optimality Theory. However, we
formulate the hypothesis that some of its limitations are mainly due to a poor
representation of the constraints used. Finally, we show how a better
representation of the constraints used would yield better results.
</summary>
    <author>
      <name>Thierry Poibeau</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LaTTICe</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">15th International Conference on Intelligent Text Processing and
  Computational Linguistics, Nepal (2014)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1405.6682v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.6682v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1406.2903v2</id>
    <updated>2014-06-12T01:39:49Z</updated>
    <published>2014-06-11T13:47:22Z</published>
    <title>A Brief State of the Art for Ontology Authoring</title>
    <summary>  One of the main challenges for building the Semantic web is Ontology
Authoring. Controlled Natural Languages CNLs offer a user friendly means for
non-experts to author ontologies. This paper provides a snapshot of the
state-of-the-art for the core CNLs for ontology authoring and reviews their
respective evaluations.
</summary>
    <author>
      <name>Hazem Safwat</name>
    </author>
    <author>
      <name>Brian Davis</name>
    </author>
    <link href="http://arxiv.org/abs/1406.2903v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1406.2903v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1406.3287v3</id>
    <updated>2015-02-18T19:44:24Z</updated>
    <published>2014-06-12T17:01:10Z</published>
    <title>A Clustering Analysis of Tweet Length and its Relation to Sentiment</title>
    <summary>  Sentiment analysis of Twitter data is performed. The researcher has made the
following contributions via this paper: (1) an innovative method for deriving
sentiment score dictionaries using an existing sentiment dictionary as seed
words is explored, and (2) an analysis of clustered tweet sentiment scores
based on tweet length is performed.
</summary>
    <author>
      <name>Matthew Mayo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1406.3287v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1406.3287v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1407.1933v1</id>
    <updated>2014-07-08T02:53:29Z</updated>
    <published>2014-07-08T02:53:29Z</published>
    <title>Lexpresso: a Controlled Natural Language</title>
    <summary>  This paper presents an overview of `Lexpresso', a Controlled Natural Language
developed at the Defence Science &amp; Technology Organisation as a bidirectional
natural language interface to a high-level information fusion system. The paper
describes Lexpresso's main features including lexical coverage, expressiveness
and range of linguistic syntactic and semantic structures. It also touches on
its tight integration with a formal semantic formalism and tentatively
classifies it against the PENS system.
</summary>
    <author>
      <name>Adam Saulwick</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 2 figures, 4th Workshop on Controlled Natural Language 2014</arxiv:comment>
    <link href="http://arxiv.org/abs/1407.1933v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1407.1933v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1407.6027v1</id>
    <updated>2014-07-22T20:25:40Z</updated>
    <published>2014-07-22T20:25:40Z</published>
    <title>Modeling languages from graph networks</title>
    <summary>  We model and compute the probability distribution of the letters in random
generated words in a language by using the theory of set partitions, Young
tableaux and graph theoretical representation methods. This has been of
interest for several application areas such as network systems, bioinformatics,
internet search, data mining and computacional linguistics.
</summary>
    <author>
      <name>Alberto Besana</name>
    </author>
    <author>
      <name>Cristina Martínez</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1407.6027v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1407.6027v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1409.5502v1</id>
    <updated>2014-09-19T02:50:04Z</updated>
    <published>2014-09-19T02:50:04Z</published>
    <title>Using crowdsourcing system for creating site-specific statistical
  machine translation engine</title>
    <summary>  A crowdsourcing translation approach is an effective tool for globalization
of site content, but it is also an important source of parallel linguistic
data. For the given site, processed with a crowdsourcing system, a
sentence-aligned corpus can be fetched, which covers a very narrow domain of
terminology and language patterns - a site-specific domain. These data can be
used for training and estimation of site-specific statistical machine
translation engine
</summary>
    <author>
      <name>Alexander Kalinin</name>
    </author>
    <author>
      <name>George Savchenko</name>
    </author>
    <link href="http://arxiv.org/abs/1409.5502v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1409.5502v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1409.7619v1</id>
    <updated>2014-09-25T13:54:37Z</updated>
    <published>2014-09-25T13:54:37Z</published>
    <title>Generating Conceptual Metaphors from Proposition Stores</title>
    <summary>  Contemporary research on computational processing of linguistic metaphors is
divided into two main branches: metaphor recognition and metaphor
interpretation. We take a different line of research and present an automated
method for generating conceptual metaphors from linguistic data. Given the
generated conceptual metaphors, we find corresponding linguistic metaphors in
corpora. In this paper, we describe our approach and its evaluation using
English and Russian data.
</summary>
    <author>
      <name>Ekaterina Ovchinnikova</name>
    </author>
    <author>
      <name>Vladimir Zaytsev</name>
    </author>
    <author>
      <name>Suzanne Wertheim</name>
    </author>
    <author>
      <name>Ross Israel</name>
    </author>
    <link href="http://arxiv.org/abs/1409.7619v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1409.7619v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.0291v2</id>
    <updated>2014-12-16T03:22:57Z</updated>
    <published>2014-10-01T17:03:18Z</published>
    <title>A Morphological Analyzer for Japanese Nouns, Verbs and Adjectives</title>
    <summary>  We present an open source morphological analyzer for Japanese nouns, verbs
and adjectives. The system builds upon the morphological analyzing capabilities
of MeCab to incorporate finer details of classification such as politeness,
tense, mood and voice attributes. We implemented our analyzer in the form of a
finite state transducer using the open source finite state compiler FOMA
toolkit. The source code and tool is available at
https://bitbucket.org/skylander/yc-nlplab/.
</summary>
    <author>
      <name>Yanchuan Sim</name>
    </author>
    <link href="http://arxiv.org/abs/1410.0291v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.0291v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.4639v3</id>
    <updated>2015-07-22T02:15:06Z</updated>
    <published>2014-10-17T05:19:12Z</published>
    <title>Dependent Types for Pragmatics</title>
    <summary>  This paper proposes the use of dependent types for pragmatic phenomena such
as pronoun binding and presupposition resolution as a type-theoretic
alternative to formalisms such as Discourse Representation Theory and Dynamic
Semantics.
</summary>
    <author>
      <name>Darryl McAdams</name>
    </author>
    <author>
      <name>Jonathan Sterling</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This version updates the paper for publication in LEUS</arxiv:comment>
    <link href="http://arxiv.org/abs/1410.4639v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.4639v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.4966v1</id>
    <updated>2014-10-18T14:53:19Z</updated>
    <published>2014-10-18T14:53:19Z</published>
    <title>The Visualization of Change in Word Meaning over Time using Temporal
  Word Embeddings</title>
    <summary>  We describe a visualization tool that can be used to view the change in
meaning of words over time. The tool makes use of existing (static) word
embedding datasets together with a timestamped $n$-gram corpus to create {\em
temporal} word embeddings.
</summary>
    <author>
      <name>Chiraag Lala</name>
    </author>
    <author>
      <name>Shay B. Cohen</name>
    </author>
    <link href="http://arxiv.org/abs/1410.4966v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.4966v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1411.3561v1</id>
    <updated>2014-11-13T14:44:00Z</updated>
    <published>2014-11-13T14:44:00Z</published>
    <title>A Text to Speech (TTS) System with English to Punjabi Conversion</title>
    <summary>  The paper aims to show how an application can be developed that converts the
English language into the Punjabi Language, and the same application can
convert the Text to Speech(TTS) i.e. pronounce the text. This application can
be really beneficial for those with special needs.
</summary>
    <author>
      <name>Prabhsimran Singh</name>
    </author>
    <author>
      <name>Amritpal Singh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 8 figures, 3 tables</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer and Communication System
  Engineering, Volume 1, Issue 04, December 2014</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1411.3561v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1411.3561v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.2821v1</id>
    <updated>2014-12-09T00:39:16Z</updated>
    <published>2014-12-09T00:39:16Z</published>
    <title>Zipf's Law and the Frequency of Characters or Words of Oracles</title>
    <summary>  The article discusses the frequency of characters of Oracle,concluding that
the frequency and the rank of a word or character is fit to Zipf-Mandelboit Law
or Zipf's law with three parameters,and figuring out the parameters based on
the frequency,and pointing out that what some researchers of Oracle call the
assembling on the two ends is just a description by their impression about the
Oracle data.
</summary>
    <author>
      <name>Xiuli Wang</name>
    </author>
    <link href="http://arxiv.org/abs/1412.2821v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.2821v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.03659v1</id>
    <updated>2015-04-14T18:48:58Z</updated>
    <published>2015-04-14T18:48:58Z</published>
    <title>Temporal ordering of clinical events</title>
    <summary>  This report describes a minimalistic set of methods engineered to anchor
clinical events onto a temporal space. Specifically, we describe methods to
extract clinical events (e.g., Problems, Treatments and Tests), temporal
expressions (i.e., time, date, duration, and frequency), and temporal links
(e.g., Before, After, Overlap) between events and temporal entities. These
methods are developed and validated using high quality datasets.
</summary>
    <author>
      <name>Azad Dehghan</name>
    </author>
    <link href="http://arxiv.org/abs/1504.03659v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.03659v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.00528v1</id>
    <updated>2015-06-01T15:21:00Z</updated>
    <published>2015-06-01T15:21:00Z</published>
    <title>Medical Synonym Extraction with Concept Space Models</title>
    <summary>  In this paper, we present a novel approach for medical synonym extraction. We
aim to integrate the term embedding with the medical domain knowledge for
healthcare applications. One advantage of our method is that it is very
scalable. Experiments on a dataset with more than 1M term pairs show that the
proposed approach outperforms the baseline approaches by a large margin.
</summary>
    <author>
      <name>Chang Wang</name>
    </author>
    <author>
      <name>Liangliang Cao</name>
    </author>
    <author>
      <name>Bowen Zhou</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, to appear in IJCAI 2015</arxiv:comment>
    <link href="http://arxiv.org/abs/1506.00528v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.00528v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.04229v1</id>
    <updated>2015-06-13T05:53:57Z</updated>
    <published>2015-06-13T05:53:57Z</published>
    <title>Evaluation of the Accuracy of the BGLemmatizer</title>
    <summary>  This paper reveals the results of an analysis of the accuracy of developed
software for automatic lemmatization for the Bulgarian language. This
lemmatization software is written entirely in Java and is distributed as a GATE
plugin. Certain statistical methods are used to define the accuracy of this
software. The results of the analysis show 95% lemmatization accuracy.
</summary>
    <author>
      <name>Elena Karashtranova</name>
    </author>
    <author>
      <name>Grigor Iliev</name>
    </author>
    <author>
      <name>Nadezhda Borisova</name>
    </author>
    <author>
      <name>Yana Chankova</name>
    </author>
    <author>
      <name>Irena Atanasova</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, Sixth International Scientific Conference - FMNS2015</arxiv:comment>
    <link href="http://arxiv.org/abs/1506.04229v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.04229v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.00639v1</id>
    <updated>2015-07-02T15:58:25Z</updated>
    <published>2015-07-02T15:58:25Z</published>
    <title>Simple, Fast Semantic Parsing with a Tensor Kernel</title>
    <summary>  We describe a simple approach to semantic parsing based on a tensor product
kernel. We extract two feature vectors: one for the query and one for each
candidate logical form. We then train a classifier using the tensor product of
the two vectors. Using very simple features for both, our system achieves an
average F1 score of 40.1% on the WebQuestions dataset. This is comparable to
more complex systems but is simpler to implement and runs faster.
</summary>
    <author>
      <name>Daoud Clarke</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">in CICLing 2015</arxiv:comment>
    <link href="http://arxiv.org/abs/1507.00639v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.00639v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.02045v2</id>
    <updated>2015-08-16T18:06:17Z</updated>
    <published>2015-07-08T06:52:50Z</published>
    <title>What Your Username Says About You</title>
    <summary>  Usernames are ubiquitous on the Internet, and they are often suggestive of
user demographics. This work looks at the degree to which gender and language
can be inferred from a username alone by making use of unsupervised morphology
induction to decompose usernames into sub-units. Experimental results on the
two tasks demonstrate the effectiveness of the proposed morphological features
compared to a character n-gram baseline.
</summary>
    <author>
      <name>Aaron Jaech</name>
    </author>
    <author>
      <name>Mari Ostendorf</name>
    </author>
    <link href="http://arxiv.org/abs/1507.02045v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.02045v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.06028v1</id>
    <updated>2015-07-22T01:27:05Z</updated>
    <published>2015-07-22T01:27:05Z</published>
    <title>The challenges of SVM optimization using Adaboost on a phoneme
  recognition problem</title>
    <summary>  The use of digital technology is growing at a very fast pace which led to the
emergence of systems based on the cognitive infocommunications. The expansion
of this sector impose the use of combining methods in order to ensure the
robustness in cognitive systems.
</summary>
    <author>
      <name>Rimah Amami</name>
    </author>
    <author>
      <name>Dorra Ben Ayed</name>
    </author>
    <author>
      <name>Noureddine Ellouze</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/CogInfoCom.2013.6719292</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/CogInfoCom.2013.6719292" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE 4th International Conference on Cognitive Infocommunications
  (CogInfoCom), Budapest 2-5 Dec. 2013, pgs 463-468</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1507.06028v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.06028v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.06837v1</id>
    <updated>2015-07-24T13:21:59Z</updated>
    <published>2015-07-24T13:21:59Z</published>
    <title>YARBUS : Yet Another Rule Based belief Update System</title>
    <summary>  We introduce a new rule based system for belief tracking in dialog systems.
Despite the simplicity of the rules being considered, the proposed belief
tracker ranks favourably compared to the previous submissions on the second and
third Dialog State Tracking challenges. The results of this simple tracker
allows to reconsider the performances of previous submissions using more
elaborate techniques.
</summary>
    <author>
      <name>Jeremy Fix</name>
    </author>
    <author>
      <name>Herve Frezza-buet</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Source code at : https://github.com/jeremyfix/dstc</arxiv:comment>
    <link href="http://arxiv.org/abs/1507.06837v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.06837v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.04515v1</id>
    <updated>2015-08-19T03:26:05Z</updated>
    <published>2015-08-19T03:26:05Z</published>
    <title>Exploring Metaphorical Senses and Word Representations for Identifying
  Metonyms</title>
    <summary>  A metonym is a word with a figurative meaning, similar to a metaphor. Because
metonyms are closely related to metaphors, we apply features that are used
successfully for metaphor recognition to the task of detecting metonyms. On the
ACL SemEval 2007 Task 8 data with gold standard metonym annotations, our system
achieved 86.45% accuracy on the location metonyms. Our code can be found on
GitHub.
</summary>
    <author>
      <name>Wei Zhang</name>
    </author>
    <author>
      <name>Judith Gelernter</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 8 pages content</arxiv:comment>
    <link href="http://arxiv.org/abs/1508.04515v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.04515v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1509.00705v1</id>
    <updated>2015-09-02T13:54:57Z</updated>
    <published>2015-09-02T13:54:57Z</published>
    <title>Analysis of Communication Pattern with Scammers in Enron Corpus</title>
    <summary>  This paper is an exploratory analysis into fraud detection taking Enron email
corpus as the case study. The paper posits conclusions like strict servitude
and unquestionable faith among employees as breeding grounds for sham among
higher executives. We also try to infer on the nature of communication between
fraudulent employees and between non- fraudulent-fraudulent employees
</summary>
    <author>
      <name>Dinesh Balaji Sashikanth</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1509.00705v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1509.00705v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1509.03295v3</id>
    <updated>2016-02-27T07:58:19Z</updated>
    <published>2015-09-09T11:27:03Z</published>
    <title>Liberating language research from dogmas of the 20th century</title>
    <summary>  A commentary on the article "Large-scale evidence of dependency length
minimization in 37 languages" by Futrell, Mahowald &amp; Gibson (PNAS 2015 112 (33)
10336-10341).
</summary>
    <author>
      <name>Ramon Ferrer-i-Cancho</name>
    </author>
    <author>
      <name>Carlos Gómez-Rodríguez</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Minor corrections</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Liberating language research from dogmas of the 20th century.
  Glottometrics 33, 33-34 (2016)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1509.03295v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1509.03295v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.01886v1</id>
    <updated>2015-10-07T10:50:31Z</updated>
    <published>2015-10-07T10:50:31Z</published>
    <title>Using Ontology-Based Context in the Portuguese-English Translation of
  Homographs in Textual Dialogues</title>
    <summary>  This paper introduces a novel approach to tackle the existing gap on message
translations in dialogue systems. Currently, submitted messages to the dialogue
systems are considered as isolated sentences. Thus, missing context information
impede the disambiguation of homographs words in ambiguous sentences. Our
approach solves this disambiguation problem by using concepts over existing
ontologies.
</summary>
    <author>
      <name>Diego Moussallem</name>
    </author>
    <author>
      <name>Ricardo Choren</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5121/ijaia.2015.6502</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5121/ijaia.2015.6502" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages, 7 figures, 2 tables in International journal of Artificial
  Intelligence &amp; Applications 2015</arxiv:comment>
    <link href="http://arxiv.org/abs/1510.01886v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.01886v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.07851v1</id>
    <updated>2015-10-27T10:43:50Z</updated>
    <published>2015-10-27T10:43:50Z</published>
    <title>Standards for language resources in ISO -- Looking back at 13 fruitful
  years</title>
    <summary>  This paper provides an overview of the various projects carried out within
ISO committee TC 37/SC 4 dealing with the management of language (digital)
resources. On the basis of the technical experience gained in the committee and
the wider standardization landscape the paper identifies some possible trends
for the future.
</summary>
    <author>
      <name>Laurent Romary</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">ALPAGE, CMB</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">edition - die Terminologiefachzeitschrift, Deutscher Terminologie-Tag
  e.V. (DTT), 2015</arxiv:comment>
    <link href="http://arxiv.org/abs/1510.07851v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.07851v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.01666v1</id>
    <updated>2015-11-05T09:25:41Z</updated>
    <published>2015-11-05T09:25:41Z</published>
    <title>Comparing Writing Styles using Word Embedding and Dynamic Time Warping</title>
    <summary>  The development of plot or story in novels is reflected in the content and
the words used. The flow of sentiments, which is one aspect of writing style,
can be quantified by analyzing the flow of words. This study explores literary
works as signals in word embedding space and tries to compare writing styles of
popular classic novels using dynamic time warping.
</summary>
    <author>
      <name>Abhinav Tushar</name>
    </author>
    <author>
      <name>Abhinav Dahiya</name>
    </author>
    <link href="http://arxiv.org/abs/1511.01666v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.01666v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.06312v1</id>
    <updated>2015-11-19T19:13:58Z</updated>
    <published>2015-11-19T19:13:58Z</published>
    <title>Good, Better, Best: Choosing Word Embedding Context</title>
    <summary>  We propose two methods of learning vector representations of words and
phrases that each combine sentence context with structural features extracted
from dependency trees. Using several variations of neural network classifier,
we show that these combined methods lead to improved performance when used as
input features for supervised term-matching.
</summary>
    <author>
      <name>James Cross</name>
    </author>
    <author>
      <name>Bing Xiang</name>
    </author>
    <author>
      <name>Bowen Zhou</name>
    </author>
    <link href="http://arxiv.org/abs/1511.06312v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.06312v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.00710v1</id>
    <updated>2016-01-05T00:49:22Z</updated>
    <published>2016-01-05T00:49:22Z</published>
    <title>Multi-Source Neural Translation</title>
    <summary>  We build a multi-source machine translation model and train it to maximize
the probability of a target English string given French and German sources.
Using the neural encoder-decoder framework, we explore several combination
methods and report up to +4.8 Bleu increases on top of a very strong
attention-based neural translation model.
</summary>
    <author>
      <name>Barret Zoph</name>
    </author>
    <author>
      <name>Kevin Knight</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1601.00710v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.00710v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.05472v1</id>
    <updated>2016-01-20T23:31:58Z</updated>
    <published>2016-01-20T23:31:58Z</published>
    <title>Hierarchical Latent Word Clustering</title>
    <summary>  This paper presents a new Bayesian non-parametric model by extending the
usage of Hierarchical Dirichlet Allocation to extract tree structured word
clusters from text data. The inference algorithm of the model collects words in
a cluster if they share similar distribution over documents. In our
experiments, we observed meaningful hierarchical structures on NIPS corpus and
radiology reports collected from public repositories.
</summary>
    <author>
      <name>Halid Ziya Yerebakan</name>
    </author>
    <author>
      <name>Fitsum Reda</name>
    </author>
    <author>
      <name>Yiqiang Zhan</name>
    </author>
    <author>
      <name>Yoshihisa Shinagawa</name>
    </author>
    <link href="http://arxiv.org/abs/1601.05472v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.05472v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.07435v2</id>
    <updated>2016-02-08T08:18:24Z</updated>
    <published>2016-01-27T16:37:08Z</published>
    <title>Co-Occurrence Patterns in the Voynich Manuscript</title>
    <summary>  The Voynich Manuscript is a medieval book written in an unknown script. This
paper studies the distribution of similarly spelled words in the Voynich
Manuscript. It shows that the distribution of words within the manuscript is
not compatible with natural languages.
</summary>
    <author>
      <name>Torsten Timm</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages; tables for sections of the VMS added; 'The Towneley plays'
  as example for English poetry added; revised version</arxiv:comment>
    <link href="http://arxiv.org/abs/1601.07435v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.07435v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1602.07618v1</id>
    <updated>2016-02-22T16:17:54Z</updated>
    <published>2016-02-22T16:17:54Z</published>
    <title>From quantum foundations via natural language meaning to a theory of
  everything</title>
    <summary>  In this paper we argue for a paradigmatic shift from `reductionism' to
`togetherness'. In particular, we show how interaction between systems in
quantum theory naturally carries over to modelling how word meanings interact
in natural language. Since meaning in natural language, depending on the
subject domain, encompasses discussions within any scientific discipline, we
obtain a template for theories such as social interaction, animal behaviour,
and many others.
</summary>
    <author>
      <name>Bob Coecke</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Invited contribution to: `The Incomputable'</arxiv:comment>
    <link href="http://arxiv.org/abs/1602.07618v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1602.07618v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.00375v2</id>
    <updated>2016-05-26T10:11:44Z</updated>
    <published>2016-03-01T17:43:37Z</published>
    <title>Easy-First Dependency Parsing with Hierarchical Tree LSTMs</title>
    <summary>  We suggest a compositional vector representation of parse trees that relies
on a recursive combination of recurrent-neural network encoders. To demonstrate
its effectiveness, we use the representation as the backbone of a greedy,
bottom-up dependency parser, achieving state-of-the-art accuracies for English
and Chinese, without relying on external word embeddings. The parser's
implementation is available for download at the first author's webpage.
</summary>
    <author>
      <name>Eliyahu Kiperwasser</name>
    </author>
    <author>
      <name>Yoav Goldberg</name>
    </author>
    <link href="http://arxiv.org/abs/1603.00375v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.00375v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.04513v1</id>
    <updated>2016-03-15T00:25:02Z</updated>
    <published>2016-03-15T00:25:02Z</published>
    <title>Multichannel Variable-Size Convolution for Sentence Classification</title>
    <summary>  We propose MVCNN, a convolution neural network (CNN) architecture for
sentence classification. It (i) combines diverse versions of pretrained word
embeddings and (ii) extracts features of multigranular phrases with
variable-size convolution filters. We also show that pretraining MVCNN is
critical for good performance. MVCNN achieves state-of-the-art performance on
four tasks: on small-scale binary, small-scale multi-class and largescale
Twitter sentiment prediction and on subjectivity classification.
</summary>
    <author>
      <name>Wenpeng Yin</name>
    </author>
    <author>
      <name>Hinrich Schütze</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">in Proceeding of CoNLL2015</arxiv:comment>
    <link href="http://arxiv.org/abs/1603.04513v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.04513v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.00502v1</id>
    <updated>2016-04-02T13:52:23Z</updated>
    <published>2016-04-02T13:52:23Z</published>
    <title>Online Updating of Word Representations for Part-of-Speech Tagging</title>
    <summary>  We propose online unsupervised domain adaptation (DA), which is performed
incrementally as data comes in and is applicable when batch DA is not possible.
In a part-of-speech (POS) tagging evaluation, we find that online unsupervised
DA performs as well as batch DA.
</summary>
    <author>
      <name>Wenpeng Yin</name>
    </author>
    <author>
      <name>Tobias Schnabel</name>
    </author>
    <author>
      <name>Hinrich Schütze</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">EMNLP'2015. Released POS tagger "FLORS" for online domain adaptation</arxiv:comment>
    <link href="http://arxiv.org/abs/1604.00502v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.00502v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.03357v1</id>
    <updated>2016-04-12T11:57:05Z</updated>
    <published>2016-04-12T11:57:05Z</published>
    <title>Improving sentence compression by learning to predict gaze</title>
    <summary>  We show how eye-tracking corpora can be used to improve sentence compression
models, presenting a novel multi-task learning algorithm based on multi-layer
LSTMs. We obtain performance competitive with or better than state-of-the-art
approaches.
</summary>
    <author>
      <name>Sigrid Klerke</name>
    </author>
    <author>
      <name>Yoav Goldberg</name>
    </author>
    <author>
      <name>Anders Søgaard</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">NAACL 2016. Received Best Short Paper Award</arxiv:comment>
    <link href="http://arxiv.org/abs/1604.03357v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.03357v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.04873v1</id>
    <updated>2016-04-17T14:07:34Z</updated>
    <published>2016-04-17T14:07:34Z</published>
    <title>From Incremental Meaning to Semantic Unit (phrase by phrase)</title>
    <summary>  This paper describes an experimental approach to Detection of Minimal
Semantic Units and their Meaning (DiMSUM), explored within the framework of
SemEval 2016 Task 10. The approach is primarily based on a combination of word
embeddings and parserbased features, and employs unidirectional incremental
computation of compositional embeddings for multiword expressions.
</summary>
    <author>
      <name>Andreas Scherbakov</name>
    </author>
    <author>
      <name>Ekaterina Vylomova</name>
    </author>
    <author>
      <name>Fei Liu</name>
    </author>
    <author>
      <name>Timothy Baldwin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 1 figure, International Workshop on Semantic Evaluation
  (SemEval-2016)</arxiv:comment>
    <link href="http://arxiv.org/abs/1604.04873v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.04873v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T50" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.05559v1</id>
    <updated>2016-04-18T18:51:18Z</updated>
    <published>2016-04-18T18:51:18Z</published>
    <title>Efficient Calculation of Bigram Frequencies in a Corpus of Short Texts</title>
    <summary>  We show that an efficient and popular method for calculating bigram
frequencies is unsuitable for bodies of short texts and offer a simple
alternative. Our method has the same computational complexity as the old method
and offers an exact count instead of an approximation.
</summary>
    <author>
      <name>Melvyn Drag</name>
    </author>
    <author>
      <name>Gauthaman Vasudevan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2 pages, no figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1604.05559v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.05559v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.06650v1</id>
    <updated>2016-04-22T13:33:08Z</updated>
    <published>2016-04-22T13:33:08Z</published>
    <title>Detecting state of aggression in sentences using CNN</title>
    <summary>  In this article we study verbal expression of aggression and its detection
using machine learning and neural networks methods. We test our results using
our corpora of messages from anonymous imageboards. We also compare Random
forest classifier with convolutional neural network for "Movie reviews with one
sentence per review" corpus.
</summary>
    <author>
      <name>Rodmonga Potapova</name>
    </author>
    <author>
      <name>Denis Gordeev</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">submitted for SPECOM-2016</arxiv:comment>
    <link href="http://arxiv.org/abs/1604.06650v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.06650v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.02945v2</id>
    <updated>2016-05-11T17:20:26Z</updated>
    <published>2016-05-10T11:29:28Z</published>
    <title>The Yahoo Query Treebank, V. 1.0</title>
    <summary>  A description and annotation guidelines for the Yahoo Webscope release of
Query Treebank, Version 1.0, May 2016.
</summary>
    <author>
      <name>Yuval Pinter</name>
    </author>
    <author>
      <name>Roi Reichart</name>
    </author>
    <author>
      <name>Idan Szpektor</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Co-released with the Webscope Dataset (L-28) and with Pinter et al.,
  Syntactic Parsing of Web Queries with Question Intent, NAACL-HLT 2016</arxiv:comment>
    <link href="http://arxiv.org/abs/1605.02945v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.02945v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.05172v2</id>
    <updated>2016-07-02T12:29:08Z</updated>
    <published>2016-05-17T14:07:43Z</published>
    <title>Siamese convolutional networks based on phonetic features for cognate
  identification</title>
    <summary>  In this paper, we explore the use of convolutional networks (ConvNets) for
the purpose of cognate identification. We compare our architecture with binary
classifiers based on string similarity measures on different language families.
Our experiments show that convolutional networks achieve competitive results
across concepts and across language families at the task of cognate
identification.
</summary>
    <author>
      <name>Taraka Rama</name>
    </author>
    <link href="http://arxiv.org/abs/1605.05172v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.05172v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.07346v1</id>
    <updated>2016-05-24T09:19:05Z</updated>
    <published>2016-05-24T09:19:05Z</published>
    <title>Multi-Level Analysis and Annotation of Arabic Corpora for Text-to-Sign
  Language MT</title>
    <summary>  In this paper, we present an ongoing effort in lexical semantic analysis and
annotation of Modern Standard Arabic (MSA) text, a semi automatic annotation
tool concerned with the morphologic, syntactic, and semantic levels of
description.
</summary>
    <author>
      <name>Abdelaziz Lakhfif</name>
    </author>
    <author>
      <name>Mohammed T. Laskri</name>
    </author>
    <author>
      <name>Eric Atwell</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Second Workshop on Arabic Corpus Linguistics (WACL-2), 22nd July
  2013, Lancaster University, UK</arxiv:comment>
    <link href="http://arxiv.org/abs/1605.07346v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.07346v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.04503v1</id>
    <updated>2016-06-14T19:00:59Z</updated>
    <published>2016-06-14T19:00:59Z</published>
    <title>Shallow Discourse Parsing Using Distributed Argument Representations and
  Bayesian Optimization</title>
    <summary>  This paper describes the Georgia Tech team's approach to the CoNLL-2016
supplementary evaluation on discourse relation sense classification. We use
long short-term memories (LSTM) to induce distributed representations of each
argument, and then combine these representations with surface features in a
neural network. The architecture of the neural network is determined by
Bayesian hyperparameter search.
</summary>
    <author>
      <name> Akanksha</name>
    </author>
    <author>
      <name>Jacob Eisenstein</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">describes our system at the CoNLL 2016 shared task</arxiv:comment>
    <link href="http://arxiv.org/abs/1606.04503v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.04503v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.08270v1</id>
    <updated>2016-06-27T13:39:54Z</updated>
    <published>2016-06-27T13:39:54Z</published>
    <title>Evaluating Informal-Domain Word Representations With UrbanDictionary</title>
    <summary>  Existing corpora for intrinsic evaluation are not targeted towards tasks in
informal domains such as Twitter or news comment forums. We want to test
whether a representation of informal words fulfills the promise of eliding
explicit text normalization as a preprocessing step. One possible evaluation
metric for such domains is the proximity of spelling variants. We propose how
such a metric might be computed and how a spelling variant dataset can be
collected using UrbanDictionary.
</summary>
    <author>
      <name>Naomi Saphra</name>
    </author>
    <author>
      <name>Adam Lopez</name>
    </author>
    <link href="http://arxiv.org/abs/1606.08270v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.08270v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.04110v1</id>
    <updated>2016-07-14T12:45:07Z</updated>
    <published>2016-07-14T12:45:07Z</published>
    <title>Using Recurrent Neural Network for Learning Expressive Ontologies</title>
    <summary>  Recently, Neural Networks have been proven extremely effective in many
natural language processing tasks such as sentiment analysis, question
answering, or machine translation. Aiming to exploit such advantages in the
Ontology Learning process, in this technical report we present a detailed
description of a Recurrent Neural Network based system to be used to pursue
such goal.
</summary>
    <author>
      <name>Giulio Petrucci</name>
    </author>
    <author>
      <name>Chiara Ghidini</name>
    </author>
    <author>
      <name>Marco Rospocher</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Technical Report</arxiv:comment>
    <link href="http://arxiv.org/abs/1607.04110v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.04110v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.05408v1</id>
    <updated>2016-07-19T05:38:58Z</updated>
    <published>2016-07-19T05:38:58Z</published>
    <title>Discriminating between similar languages in Twitter using label
  propagation</title>
    <summary>  Identifying the language of social media messages is an important first step
in linguistic processing. Existing models for Twitter focus on content
analysis, which is successful for dissimilar language pairs. We propose a label
propagation approach that takes the social graph of tweet authors into account
as well as content to better tease apart similar languages. This results in
state-of-the-art shared task performance of $76.63\%$, $1.4\%$ higher than the
top system.
</summary>
    <author>
      <name>Will Radford</name>
    </author>
    <author>
      <name>Matthias Galle</name>
    </author>
    <link href="http://arxiv.org/abs/1607.05408v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.05408v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.05650v2</id>
    <updated>2016-09-07T03:09:17Z</updated>
    <published>2016-07-13T06:57:38Z</published>
    <title>A Supervised Authorship Attribution Framework for Bengali Language</title>
    <summary>  Authorship Attribution is a long-standing problem in Natural Language
Processing. Several statistical and computational methods have been used to
find a solution to this problem. In this paper, we have proposed methods to
deal with the authorship attribution problem in Bengali.
</summary>
    <author>
      <name>Shanta Phani</name>
    </author>
    <author>
      <name>Shibamouli Lahiri</name>
    </author>
    <author>
      <name>Arindam Biswas</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper has been withdrawn by the authors as the results need to
  be changed</arxiv:comment>
    <link href="http://arxiv.org/abs/1607.05650v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.05650v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.05755v4</id>
    <updated>2017-03-14T02:36:05Z</updated>
    <published>2016-07-10T19:14:00Z</published>
    <title>A New Bengali Readability Score</title>
    <summary>  In this paper we have proposed methods to analyze the readability of Bengali
language texts. We have got some exceptionally good results out of the
experiments.
</summary>
    <author>
      <name>Shanta Phani</name>
    </author>
    <author>
      <name>Shibamouli Lahiri</name>
    </author>
    <author>
      <name>Arindam Biswas</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper has been withdrawn by the author as the results need to be
  changed</arxiv:comment>
    <link href="http://arxiv.org/abs/1607.05755v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.05755v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.07931v1</id>
    <updated>2016-07-27T01:44:54Z</updated>
    <published>2016-07-27T01:44:54Z</published>
    <title>Synthetic Language Generation and Model Validation in BEAST2</title>
    <summary>  Generating synthetic languages aids in the testing and validation of future
computational linguistic models and methods. This thesis extends the BEAST2
phylogenetic framework to add linguistic sequence generation under multiple
models. The new plugin is then used to test the effects of the phenomena of
word borrowing on the inference process under two widely used phylolinguistic
models.
</summary>
    <author>
      <name>Stuart Bradley</name>
    </author>
    <link href="http://arxiv.org/abs/1607.07931v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.07931v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.08592v1</id>
    <updated>2016-07-28T19:47:25Z</updated>
    <published>2016-07-28T19:47:25Z</published>
    <title>Modeling selectional restrictions in a relational type system</title>
    <summary>  Selectional restrictions are semantic constraints on forming certain complex
types in natural language. The paper gives an overview of modeling selectional
restrictions in a relational type system with morphological and syntactic
types. We discuss some foundations of the system and ways of formalizing
selectional restrictions.
  Keywords: type theory, selectional restrictions, syntax, morphology
</summary>
    <author>
      <name>Erkki Luuk</name>
    </author>
    <link href="http://arxiv.org/abs/1607.08592v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.08592v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.01404v1</id>
    <updated>2016-08-04T00:36:57Z</updated>
    <published>2016-08-04T00:36:57Z</published>
    <title>Quantifier Scope in Categorical Compositional Distributional Semantics</title>
    <summary>  In previous work with J. Hedges, we formalised a generalised quantifiers
theory of natural language in categorical compositional distributional
semantics with the help of bialgebras. In this paper, we show how quantifier
scope ambiguity can be represented in that setting and how this representation
can be generalised to branching quantifiers.
</summary>
    <author>
      <name>Mehrnoosh Sadrzadeh</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Queen Mary University of London</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.221.6</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.221.6" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings SLPCS 2016, arXiv:1608.01018</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 221, 2016, pp. 49-57</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1608.01404v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.01404v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.01448v2</id>
    <updated>2016-09-29T12:43:43Z</updated>
    <published>2016-08-04T07:37:54Z</published>
    <title>Word Segmentation on Micro-blog Texts with External Lexicon and
  Heterogeneous Data</title>
    <summary>  This paper describes our system designed for the NLPCC 2016 shared task on
word segmentation on micro-blog texts.
</summary>
    <author>
      <name>Qingrong Xia</name>
    </author>
    <author>
      <name>Zhenghua Li</name>
    </author>
    <author>
      <name>Jiayuan Chao</name>
    </author>
    <author>
      <name>Min Zhang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 3 figures, Proceedings of 5th {CCF} Conference on Natural
  Language Processing and Chinese Computing (2016)</arxiv:comment>
    <link href="http://arxiv.org/abs/1608.01448v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.01448v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.02094v1</id>
    <updated>2016-08-06T10:47:05Z</updated>
    <published>2016-08-06T10:47:05Z</published>
    <title>Desiderata for Vector-Space Word Representations</title>
    <summary>  A plethora of vector-space representations for words is currently available,
which is growing. These consist of fixed-length vectors containing real values,
which represent a word. The result is a representation upon which the power of
many conventional information processing and data mining techniques can be
brought to bear, as long as the representations are designed with some
forethought and fit certain constraints. This paper details desiderata for the
design of vector space representations of words.
</summary>
    <author>
      <name>Leon Derczynski</name>
    </author>
    <link href="http://arxiv.org/abs/1608.02094v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.02094v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.02784v1</id>
    <updated>2016-08-09T12:26:19Z</updated>
    <published>2016-08-09T12:26:19Z</published>
    <title>Canonical Correlation Inference for Mapping Abstract Scenes to Text</title>
    <summary>  We describe a technique for structured prediction, based on canonical
correlation analysis. Our learning algorithm finds two projections for the
input and the output spaces that aim at projecting a given input and its
correct output into points close to each other. We demonstrate our technique on
a language-vision problem, namely the problem of giving a textual description
to an "abstract scene".
</summary>
    <author>
      <name>Helen Jiang</name>
    </author>
    <author>
      <name>Nikos Papasarantopoulos</name>
    </author>
    <author>
      <name>Shay B. Cohen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1608.02784v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.02784v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.03030v1</id>
    <updated>2016-08-10T03:05:26Z</updated>
    <published>2016-08-10T03:05:26Z</published>
    <title>Hierarchical Character-Word Models for Language Identification</title>
    <summary>  Social media messages' brevity and unconventional spelling pose a challenge
to language identification. We introduce a hierarchical model that learns
character and contextualized word-level representations for language
identification. Our method performs well against strong base- lines, and can
also reveal code-switching.
</summary>
    <author>
      <name>Aaron Jaech</name>
    </author>
    <author>
      <name>George Mulcaire</name>
    </author>
    <author>
      <name>Shobhit Hathi</name>
    </author>
    <author>
      <name>Mari Ostendorf</name>
    </author>
    <author>
      <name>Noah A. Smith</name>
    </author>
    <link href="http://arxiv.org/abs/1608.03030v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.03030v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.04485v1</id>
    <updated>2016-08-16T05:04:46Z</updated>
    <published>2016-08-16T05:04:46Z</published>
    <title>Authorship clustering using multi-headed recurrent neural networks</title>
    <summary>  A recurrent neural network that has been trained to separately model the
language of several documents by unknown authors is used to measure similarity
between the documents. It is able to find clues of common authorship even when
the documents are very short and about disparate topics. While it is easy to
make statistically significant predictions regarding authorship, it is
difficult to group documents into definite clusters with high accuracy.
</summary>
    <author>
      <name>Douglas Bagnall</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 5 figures; notebook for PAN@CLEF 2016</arxiv:comment>
    <link href="http://arxiv.org/abs/1608.04485v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.04485v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.06204v2</id>
    <updated>2017-04-13T08:33:33Z</updated>
    <published>2016-09-20T14:53:05Z</published>
    <title>Italy goes to Stanford: a collection of CoreNLP modules for Italian</title>
    <summary>  In this we paper present Tint, an easy-to-use set of fast, accurate and
extendable Natural Language Processing modules for Italian. It is based on
Stanford CoreNLP and is freely available as a standalone software or a library
that can be integrated in an existing project.
</summary>
    <author>
      <name>Alessio Palmero Aprosio</name>
    </author>
    <author>
      <name>Giovanni Moretti</name>
    </author>
    <link href="http://arxiv.org/abs/1609.06204v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.06204v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.06239v1</id>
    <updated>2016-09-20T16:19:54Z</updated>
    <published>2016-09-20T16:19:54Z</published>
    <title>Generating Politically-Relevant Event Data</title>
    <summary>  Automatically generated political event data is an important part of the
social science data ecosystem. The approaches for generating this data, though,
have remained largely the same for two decades. During this time, the field of
computational linguistics has progressed tremendously. This paper presents an
overview of political event data, including methods and ontologies, and a set
of experiments to determine the applicability of deep neural networks to the
extraction of political events from news text.
</summary>
    <author>
      <name>John Beieler</name>
    </author>
    <link href="http://arxiv.org/abs/1609.06239v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.06239v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.08389v1</id>
    <updated>2016-09-27T12:55:10Z</updated>
    <published>2016-09-27T12:55:10Z</published>
    <title>A Hackathon for Classical Tibetan</title>
    <summary>  We describe the course of a hackathon dedicated to the development of
linguistic tools for Tibetan Buddhist studies. Over a period of five days, a
group of seventeen scholars, scientists, and students developed and compared
algorithms for intertextual alignment and text classification, along with some
basic language tools, including a stemmer and word segmenter.
</summary>
    <author>
      <name>Orna Almogi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">TAU-CS</arxiv:affiliation>
    </author>
    <author>
      <name>Lena Dankin</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">TAU-CS</arxiv:affiliation>
    </author>
    <author>
      <name>Nachum Dershowitz</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">TAU-CS</arxiv:affiliation>
    </author>
    <author>
      <name>Lior Wolf</name>
    </author>
    <link href="http://arxiv.org/abs/1609.08389v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.08389v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.09007v1</id>
    <updated>2016-09-28T16:55:52Z</updated>
    <published>2016-09-28T16:55:52Z</published>
    <title>Unsupervised Neural Hidden Markov Models</title>
    <summary>  In this work, we present the first results for neuralizing an Unsupervised
Hidden Markov Model. We evaluate our approach on tag in- duction. Our approach
outperforms existing generative models and is competitive with the
state-of-the-art though with a simpler model easily extended to include
additional context.
</summary>
    <author>
      <name>Ke Tran</name>
    </author>
    <author>
      <name>Yonatan Bisk</name>
    </author>
    <author>
      <name>Ashish Vaswani</name>
    </author>
    <author>
      <name>Daniel Marcu</name>
    </author>
    <author>
      <name>Kevin Knight</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">accepted at EMNLP 2016, Workshop on Structured Prediction for NLP.
  Oral presentation</arxiv:comment>
    <link href="http://arxiv.org/abs/1609.09007v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.09007v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1610.00602v1</id>
    <updated>2016-10-03T15:40:08Z</updated>
    <published>2016-10-03T15:40:08Z</published>
    <title>Multimodal Semantic Simulations of Linguistically Underspecified Motion
  Events</title>
    <summary>  In this paper, we describe a system for generating three-dimensional visual
simulations of natural language motion expressions. We use a rich formal model
of events and their participants to generate simulations that satisfy the
minimal constraints entailed by the associated utterance, relying on semantic
knowledge of physical objects and motion events. This paper outlines technical
considerations and discusses implementing the aforementioned semantic models
into such a system.
</summary>
    <author>
      <name>Nikhil Krishnaswamy</name>
    </author>
    <author>
      <name>James Pustejovsky</name>
    </author>
    <link href="http://arxiv.org/abs/1610.00602v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1610.00602v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1610.03246v1</id>
    <updated>2016-10-11T09:19:06Z</updated>
    <published>2016-10-11T09:19:06Z</published>
    <title>Toward a new instances of NELL</title>
    <summary>  We are developing the method to start new instances of NELL in various
languages and develop then NELL multilingualism. We base our method on our
experience on NELL Portuguese and NELL French. This reports explain our method
and develops some research perspectives.
</summary>
    <author>
      <name>Maisa C. Duarte</name>
    </author>
    <author>
      <name>Pierre Maret</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 1 figure and 2 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1610.03246v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1610.03246v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1610.03759v2</id>
    <updated>2017-02-05T11:24:05Z</updated>
    <published>2016-10-12T15:53:02Z</published>
    <title>Language Models with Pre-Trained (GloVe) Word Embeddings</title>
    <summary>  In this work we implement a training of a Language Model (LM), using
Recurrent Neural Network (RNN) and GloVe word embeddings, introduced by
Pennigton et al. in [1]. The implementation is following the general idea of
training RNNs for LM tasks presented in [2], but is rather using Gated
Recurrent Unit (GRU) [3] for a memory cell, and not the more commonly used LSTM
[4].
</summary>
    <author>
      <name>Victor Makarenkov</name>
    </author>
    <author>
      <name>Bracha Shapira</name>
    </author>
    <author>
      <name>Lior Rokach</name>
    </author>
    <link href="http://arxiv.org/abs/1610.03759v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1610.03759v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1610.06053v1</id>
    <updated>2016-10-19T15:09:21Z</updated>
    <published>2016-10-19T15:09:21Z</published>
    <title>Chinese Restaurant Process for cognate clustering: A threshold free
  approach</title>
    <summary>  In this paper, we introduce a threshold free approach, motivated from Chinese
Restaurant Process, for the purpose of cognate clustering. We show that our
approach yields similar results to a linguistically motivated cognate
clustering system known as LexStat. Our Chinese Restaurant Process system is
fast and does not require any threshold and can be applied to any language
family of the world.
</summary>
    <author>
      <name>Taraka Rama</name>
    </author>
    <link href="http://arxiv.org/abs/1610.06053v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1610.06053v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1610.07365v1</id>
    <updated>2016-10-24T11:30:22Z</updated>
    <published>2016-10-24T11:30:22Z</published>
    <title>Introduction: Cognitive Issues in Natural Language Processing</title>
    <summary>  This special issue is dedicated to get a better picture of the relationships
between computational linguistics and cognitive science. It specifically raises
two questions: "what is the potential contribution of computational language
modeling to cognitive science?" and conversely: "what is the influence of
cognitive science in contemporary computational linguistics?"
</summary>
    <author>
      <name>Thierry Poibeau</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LaTTICe</arxiv:affiliation>
    </author>
    <author>
      <name>Shravan Vasishth</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1201/b21583-2</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1201/b21583-2" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Traitement Automatique des Langues, ATALA, 2014, Traitement
  Automatique des Langues et Sciences Cognitives, 55 (3), pp.7-19</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1610.07365v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1610.07365v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1610.09565v1</id>
    <updated>2016-10-29T19:21:19Z</updated>
    <published>2016-10-29T19:21:19Z</published>
    <title>Sequence-to-sequence neural network models for transliteration</title>
    <summary>  Transliteration is a key component of machine translation systems and
software internationalization. This paper demonstrates that neural
sequence-to-sequence models obtain state of the art or close to state of the
art results on existing datasets. In an effort to make machine transliteration
accessible, we open source a new Arabic to English transliteration dataset and
our trained models.
</summary>
    <author>
      <name>Mihaela Rosca</name>
    </author>
    <author>
      <name>Thomas Breuel</name>
    </author>
    <link href="http://arxiv.org/abs/1610.09565v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1610.09565v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1611.03641v2</id>
    <updated>2017-02-27T18:38:56Z</updated>
    <published>2016-11-11T10:06:29Z</published>
    <title>Improving Reliability of Word Similarity Evaluation by Redesigning
  Annotation Task and Performance Measure</title>
    <summary>  We suggest a new method for creating and using gold-standard datasets for
word similarity evaluation. Our goal is to improve the reliability of the
evaluation, and we do this by redesigning the annotation task to achieve higher
inter-rater agreement, and by defining a performance measure which takes the
reliability of each annotation decision in the dataset into account.
</summary>
    <author>
      <name>Oded Avraham</name>
    </author>
    <author>
      <name>Yoav Goldberg</name>
    </author>
    <link href="http://arxiv.org/abs/1611.03641v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1611.03641v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.02801v1</id>
    <updated>2016-12-08T20:33:17Z</updated>
    <published>2016-12-08T20:33:17Z</published>
    <title>Discovering Conversational Dependencies between Messages in Dialogs</title>
    <summary>  We investigate the task of inferring conversational dependencies between
messages in one-on-one online chat, which has become one of the most popular
forms of customer service. We propose a novel probabilistic classifier that
leverages conversational, lexical and semantic information. The approach is
evaluated empirically on a set of customer service chat logs from a Chinese
e-commerce website. It outperforms heuristic baselines.
</summary>
    <author>
      <name>Wenchao Du</name>
    </author>
    <author>
      <name>Pascal Poupart</name>
    </author>
    <author>
      <name>Wei Xu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">AAAI2017 student abstract camera-ready version</arxiv:comment>
    <link href="http://arxiv.org/abs/1612.02801v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.02801v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.05202v1</id>
    <updated>2016-12-15T19:28:17Z</updated>
    <published>2016-12-15T19:28:17Z</published>
    <title>Building a robust sentiment lexicon with (almost) no resource</title>
    <summary>  Creating sentiment polarity lexicons is labor intensive. Automatically
translating them from resourceful languages requires in-domain machine
translation systems, which rely on large quantities of bi-texts. In this paper,
we propose to replace machine translation by transferring words from the
lexicon through word embeddings aligned across languages with a simple linear
transform. The approach leads to no degradation, compared to machine
translation, when tested on sentiment polarity classification on tweets from
four languages.
</summary>
    <author>
      <name>Mickael Rouvier</name>
    </author>
    <author>
      <name>Benoit Favre</name>
    </author>
    <link href="http://arxiv.org/abs/1612.05202v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.05202v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.00168v1</id>
    <updated>2016-12-31T21:37:10Z</updated>
    <published>2016-12-31T21:37:10Z</published>
    <title>Social Media Argumentation Mining: The Quest for Deliberateness in
  Raucousness</title>
    <summary>  Argumentation mining from social media content has attracted increasing
attention. The task is both challenging and rewarding. The informal nature of
user-generated content makes the task dauntingly difficult. On the other hand,
the insights that could be gained by a large-scale analysis of social media
argumentation make it a very worthwhile task. In this position paper I discuss
the motivation for social media argumentation mining, as well as the tasks and
challenges involved.
</summary>
    <author>
      <name>Jan Šnajder</name>
    </author>
    <link href="http://arxiv.org/abs/1701.00168v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.00168v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.00504v1</id>
    <updated>2017-01-02T19:23:55Z</updated>
    <published>2017-01-02T19:23:55Z</published>
    <title>Stance detection in online discussions</title>
    <summary>  This paper describes our system created to detect stance in online
discussions. The goal is to identify whether the author of a comment is in
favor of the given target or against. Our approach is based on a maximum
entropy classifier, which uses surface-level, sentiment and domain-specific
features. The system was originally developed to detect stance in English
tweets. We adapted it to process Czech news commentaries.
</summary>
    <author>
      <name>Peter Krejzl</name>
    </author>
    <author>
      <name>Barbora Hourová</name>
    </author>
    <author>
      <name>Josef Steinberger</name>
    </author>
    <link href="http://arxiv.org/abs/1701.00504v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.00504v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.03092v1</id>
    <updated>2017-01-11T18:42:09Z</updated>
    <published>2017-01-11T18:42:09Z</published>
    <title>Job Detection in Twitter</title>
    <summary>  In this report, we propose a new application for twitter data called
\textit{job detection}. We identify people's job category based on their
tweets. As a preliminary work, we limited our task to identify only IT workers
from other job holders. We have used and compared both simple bag of words
model and a document representation based on Skip-gram model. Our results show
that the model based on Skip-gram, achieves a 76\% precision and 82\% recall.
</summary>
    <author>
      <name>Besat Kassaie</name>
    </author>
    <link href="http://arxiv.org/abs/1701.03092v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.03092v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1702.05962v1</id>
    <updated>2017-02-20T13:36:23Z</updated>
    <published>2017-02-20T13:36:23Z</published>
    <title>Latent Variable Dialogue Models and their Diversity</title>
    <summary>  We present a dialogue generation model that directly captures the variability
in possible responses to a given input, which reduces the `boring output' issue
of deterministic dialogue models. Experiments show that our model generates
more diverse outputs than baseline models, and also generates more consistently
acceptable output than sampling from a deterministic encoder-decoder model.
</summary>
    <author>
      <name>Kris Cao</name>
    </author>
    <author>
      <name>Stephen Clark</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at EACL 2017</arxiv:comment>
    <link href="http://arxiv.org/abs/1702.05962v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1702.05962v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.03091v1</id>
    <updated>2017-03-09T01:04:07Z</updated>
    <published>2017-03-09T01:04:07Z</published>
    <title>Deep Learning applied to NLP</title>
    <summary>  Convolutional Neural Network (CNNs) are typically associated with Computer
Vision. CNNs are responsible for major breakthroughs in Image Classification
and are the core of most Computer Vision systems today. More recently CNNs have
been applied to problems in Natural Language Processing and gotten some
interesting results. In this paper, we will try to explain the basics of CNNs,
its different variations and how they have been applied to NLP.
</summary>
    <author>
      <name>Marc Moreno Lopez</name>
    </author>
    <author>
      <name>Jugal Kalita</name>
    </author>
    <link href="http://arxiv.org/abs/1703.03091v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.03091v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.05465v1</id>
    <updated>2017-03-16T03:15:22Z</updated>
    <published>2017-03-16T03:15:22Z</published>
    <title>Neobility at SemEval-2017 Task 1: An Attention-based Sentence Similarity
  Model</title>
    <summary>  This paper describes a neural-network model which performed competitively
(top 6) at the SemEval 2017 cross-lingual Semantic Textual Similarity (STS)
task. Our system employs an attention-based recurrent neural network model that
optimizes the sentence similarity. In this paper, we describe our participation
in the multilingual STS task which measures similarity across English, Spanish,
and Arabic.
</summary>
    <author>
      <name>Wenli Zhuang</name>
    </author>
    <author>
      <name>Ernie Chang</name>
    </author>
    <link href="http://arxiv.org/abs/1703.05465v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.05465v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.07438v2</id>
    <updated>2017-07-22T04:44:38Z</updated>
    <published>2017-03-21T21:36:28Z</published>
    <title>The NLTK FrameNet API: Designing for Discoverability with a Rich
  Linguistic Resource</title>
    <summary>  A new Python API, integrated within the NLTK suite, offers access to the
FrameNet 1.7 lexical database. The lexicon (structured in terms of frames) as
well as annotated sentences can be processed programatically, or browsed with
human-readable displays via the interactive Python prompt.
</summary>
    <author>
      <name>Nathan Schneider</name>
    </author>
    <author>
      <name>Chuck Wooters</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">EMNLP 2017 Demo</arxiv:comment>
    <link href="http://arxiv.org/abs/1703.07438v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.07438v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.09570v1</id>
    <updated>2017-03-27T02:18:36Z</updated>
    <published>2017-03-27T02:18:36Z</published>
    <title>A Tidy Data Model for Natural Language Processing using cleanNLP</title>
    <summary>  The package cleanNLP provides a set of fast tools for converting a textual
corpus into a set of normalized tables. The underlying natural language
processing pipeline utilizes Stanford's CoreNLP library, exposing a number of
annotation tasks for text written in English, French, German, and Spanish.
Annotators include tokenization, part of speech tagging, named entity
recognition, entity linking, sentiment analysis, dependency parsing,
coreference resolution, and information extraction.
</summary>
    <author>
      <name>Taylor Arnold</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages; 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1703.09570v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.09570v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1704.01938v1</id>
    <updated>2017-04-06T17:07:40Z</updated>
    <published>2017-04-06T17:07:40Z</published>
    <title>The Interplay of Semantics and Morphology in Word Embeddings</title>
    <summary>  We explore the ability of word embeddings to capture both semantic and
morphological similarity, as affected by the different types of linguistic
properties (surface form, lemma, morphological tag) used to compose the
representation of each word. We train several models, where each uses a
different subset of these properties to compose its representations. By
evaluating the models on semantic and morphological measures, we reveal some
useful insights on the relationship between semantics and morphology.
</summary>
    <author>
      <name>Oded Avraham</name>
    </author>
    <author>
      <name>Yoav Goldberg</name>
    </author>
    <link href="http://arxiv.org/abs/1704.01938v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1704.01938v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1704.03693v1</id>
    <updated>2017-04-12T10:47:10Z</updated>
    <published>2017-04-12T10:47:10Z</published>
    <title>Trainable Referring Expression Generation using Overspecification
  Preferences</title>
    <summary>  Referring expression generation (REG) models that use speaker-dependent
information require a considerable amount of training data produced by every
individual speaker, or may otherwise perform poorly. In this work we present a
simple REG experiment that allows the use of larger training data sets by
grouping speakers according to their overspecification preferences. Intrinsic
evaluation shows that this method generally outperforms the personalised method
found in previous work.
</summary>
    <author>
      <name>Thiago castro Ferreira</name>
    </author>
    <author>
      <name>Ivandre Paraboni</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1704.03693v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1704.03693v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1704.05347v1</id>
    <updated>2017-04-18T14:12:37Z</updated>
    <published>2017-04-18T14:12:37Z</published>
    <title>Baselines and test data for cross-lingual inference</title>
    <summary>  Research in natural language inference is currently exclusive to English.
Here, we propose to advance toward multilingual evaluation. To that end, we
provide test data for four major languages. We experiment with a set of
baselines based on cross-lingual embeddings and machine translation. While our
best system scores an average accuracy of just over 75%, we focus largely on
enabling further research in multilingual inference.
</summary>
    <author>
      <name>Željko Agić</name>
    </author>
    <author>
      <name>Natalie Schluter</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted for review at EMNLP 2017</arxiv:comment>
    <link href="http://arxiv.org/abs/1704.05347v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1704.05347v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1704.06841v1</id>
    <updated>2017-04-22T19:39:32Z</updated>
    <published>2017-04-22T19:39:32Z</published>
    <title>Medical Text Classification using Convolutional Neural Networks</title>
    <summary>  We present an approach to automatically classify clinical text at a sentence
level. We are using deep convolutional neural networks to represent complex
features. We train the network on a dataset providing a broad categorization of
health information. Through a detailed evaluation, we demonstrate that our
method outperforms several approaches widely used in natural language
processing tasks by about 15%.
</summary>
    <author>
      <name>Mark Hughes</name>
    </author>
    <author>
      <name>Irene Li</name>
    </author>
    <author>
      <name>Spyros Kotoulas</name>
    </author>
    <author>
      <name>Toyotaro Suzumura</name>
    </author>
    <link href="http://arxiv.org/abs/1704.06841v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1704.06841v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1704.08388v2</id>
    <updated>2017-04-28T01:16:07Z</updated>
    <published>2017-04-27T00:29:17Z</published>
    <title>Duluth at Semeval-2017 Task 7 : Puns upon a midnight dreary, Lexical
  Semantics for the weak and weary</title>
    <summary>  This paper describes the Duluth systems that participated in SemEval-2017
Task 7 : Detection and Interpretation of English Puns. The Duluth systems
participated in all three subtasks, and relied on methods that included word
sense disambiguation and measures of semantic relatedness.
</summary>
    <author>
      <name>Ted Pedersen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, to Appear in the Proceedings of the 11th International
  Workshop on Semantic Evaluation (SemEval 2017), August 2017, Vancouver, BC</arxiv:comment>
    <link href="http://arxiv.org/abs/1704.08388v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1704.08388v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1704.08531v1</id>
    <updated>2017-04-27T12:27:25Z</updated>
    <published>2017-04-27T12:27:25Z</published>
    <title>A Survey of Neural Network Techniques for Feature Extraction from Text</title>
    <summary>  This paper aims to catalyze the discussions about text feature extraction
techniques using neural network architectures. The research questions discussed
in the paper focus on the state-of-the-art neural network techniques that have
proven to be useful tools for language processing, language generation, text
classification and other computational linguistics tasks.
</summary>
    <author>
      <name>Vineet John</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1704.08531v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1704.08531v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T50" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.02700v1</id>
    <updated>2017-05-07T21:16:35Z</updated>
    <published>2017-05-07T21:16:35Z</published>
    <title>Generating Memorable Mnemonic Encodings of Numbers</title>
    <summary>  The major system is a mnemonic system that can be used to memorize sequences
of numbers. In this work, we present a method to automatically generate
sentences that encode a given number. We propose several encoding models and
compare the most promising ones in a password memorability study. The results
of the study show that a model combining part-of-speech sentence templates with
an $n$-gram language model produces the most memorable password
representations.
</summary>
    <author>
      <name>Vincent Fiorentini</name>
    </author>
    <author>
      <name>Megan Shao</name>
    </author>
    <author>
      <name>Julie Medero</name>
    </author>
    <link href="http://arxiv.org/abs/1705.02700v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.02700v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.03645v1</id>
    <updated>2017-05-10T08:05:44Z</updated>
    <published>2017-05-10T08:05:44Z</published>
    <title>A Survey of Deep Learning Methods for Relation Extraction</title>
    <summary>  Relation Extraction is an important sub-task of Information Extraction which
has the potential of employing deep learning (DL) models with the creation of
large datasets using distant supervision. In this review, we compare the
contributions and pitfalls of the various DL models that have been used for the
task, to help guide the path ahead.
</summary>
    <author>
      <name>Shantanu Kumar</name>
    </author>
    <link href="http://arxiv.org/abs/1705.03645v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.03645v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.05437v1</id>
    <updated>2017-05-10T10:00:00Z</updated>
    <published>2017-05-10T10:00:00Z</published>
    <title>A Biomedical Information Extraction Primer for NLP Researchers</title>
    <summary>  Biomedical Information Extraction is an exciting field at the crossroads of
Natural Language Processing, Biology and Medicine. It encompasses a variety of
different tasks that require application of state-of-the-art NLP techniques,
such as NER and Relation Extraction. This paper provides an overview of the
problems in the field and discusses some of the techniques used for solving
them.
</summary>
    <author>
      <name>Surag Nair</name>
    </author>
    <link href="http://arxiv.org/abs/1705.05437v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.05437v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.09755v1</id>
    <updated>2017-05-27T02:23:18Z</updated>
    <published>2017-05-27T02:23:18Z</published>
    <title>word2vec Skip-Gram with Negative Sampling is a Weighted Logistic PCA</title>
    <summary>  We show that the skip-gram formulation of word2vec trained with negative
sampling is equivalent to a weighted logistic PCA. This connection allows us to
better understand the objective, compare it to other word embedding methods,
and extend it to higher dimensional models.
</summary>
    <author>
      <name>Andrew J. Landgraf</name>
    </author>
    <author>
      <name>Jeremy Bellay</name>
    </author>
    <link href="http://arxiv.org/abs/1705.09755v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.09755v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.02551v1</id>
    <updated>2017-06-08T12:48:15Z</updated>
    <published>2017-06-08T12:48:15Z</published>
    <title>The Algorithmic Inflection of Russian and Generation of Grammatically
  Correct Text</title>
    <summary>  We present a deterministic algorithm for Russian inflection. This algorithm
is implemented in a publicly available web-service www.passare.ru which
provides functions for inflection of single words, word matching and synthesis
of grammatically correct Russian text. The inflectional functions have been
tested against the annotated corpus of Russian language OpenCorpora.
</summary>
    <author>
      <name>T. M. Sadykov</name>
    </author>
    <author>
      <name>T. A. Zhukov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1706.02551v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.02551v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T35" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.02883v1</id>
    <updated>2017-06-09T10:17:24Z</updated>
    <published>2017-06-09T10:17:24Z</published>
    <title>Overview of the NLPCC 2017 Shared Task: Chinese News Headline
  Categorization</title>
    <summary>  In this paper, we give an overview for the shared task at the CCF Conference
on Natural Language Processing \&amp; Chinese Computing (NLPCC 2017): Chinese News
Headline Categorization. The dataset of this shared task consists 18 classes,
12,000 short texts along with corresponded labels for each class. The dataset
and example code can be accessed at
https://github.com/FudanNLP/nlpcc2017_news_headline_categorization.
</summary>
    <author>
      <name>Xipeng Qiu</name>
    </author>
    <author>
      <name>Jingjing Gong</name>
    </author>
    <author>
      <name>Xuanjing Huang</name>
    </author>
    <link href="http://arxiv.org/abs/1706.02883v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.02883v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.09562v1</id>
    <updated>2017-06-29T03:19:39Z</updated>
    <published>2017-06-29T03:19:39Z</published>
    <title>Frame-Based Continuous Lexical Semantics through Exponential Family
  Tensor Factorization and Semantic Proto-Roles</title>
    <summary>  We study how different frame annotations complement one another when learning
continuous lexical semantics. We learn the representations from a tensorized
skip-gram model that consistently encodes syntactic-semantic content better,
with multiple 10% gains over baselines.
</summary>
    <author>
      <name>Francis Ferraro</name>
    </author>
    <author>
      <name>Adam Poliak</name>
    </author>
    <author>
      <name>Ryan Cotterell</name>
    </author>
    <author>
      <name>Benjamin Van Durme</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at the Sixth Joint Conference on Lexical and Computational
  Semantics (*SEM). Association for Computational Linguistics, Vancouver,
  Canada. 2017</arxiv:comment>
    <link href="http://arxiv.org/abs/1706.09562v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.09562v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.09856v1</id>
    <updated>2017-06-29T17:04:48Z</updated>
    <published>2017-06-29T17:04:48Z</published>
    <title>Automatic Mapping of French Discourse Connectives to PDTB Discourse
  Relations</title>
    <summary>  In this paper, we present an approach to exploit phrase tables generated by
statistical machine translation in order to map French discourse connectives to
discourse relations. Using this approach, we created ConcoLeDisCo, a lexicon of
French discourse connectives and their PDTB relations. When evaluated against
LEXCONN, ConcoLeDisCo achieves a recall of 0.81 and an Average Precision of
0.68 for the Concession and Condition relations.
</summary>
    <author>
      <name>Majid Laali</name>
    </author>
    <author>
      <name>Leila Kosseim</name>
    </author>
    <link href="http://arxiv.org/abs/1706.09856v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.09856v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.00299v1</id>
    <updated>2017-07-02T14:39:21Z</updated>
    <published>2017-07-02T14:39:21Z</published>
    <title>Grammatical Error Correction with Neural Reinforcement Learning</title>
    <summary>  We propose a neural encoder-decoder model with reinforcement learning (NRL)
for grammatical error correction (GEC). Unlike conventional maximum likelihood
estimation (MLE), the model directly optimizes towards an objective that
considers a sentence-level, task-specific evaluation metric, avoiding the
exposure bias issue in MLE. We demonstrate that NRL outperforms MLE both in
human and automated evaluation metrics, achieving the state-of-the-art on a
fluency-oriented GEC corpus.
</summary>
    <author>
      <name>Keisuke Sakaguchi</name>
    </author>
    <author>
      <name>Matt Post</name>
    </author>
    <author>
      <name>Benjamin Van Durme</name>
    </author>
    <link href="http://arxiv.org/abs/1707.00299v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.00299v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.02063v1</id>
    <updated>2017-07-07T07:46:54Z</updated>
    <published>2017-07-07T07:46:54Z</published>
    <title>External Evaluation of Event Extraction Classifiers for Automatic
  Pathway Curation: An extended study of the mTOR pathway</title>
    <summary>  This paper evaluates the impact of various event extraction systems on
automatic pathway curation using the popular mTOR pathway. We quantify the
impact of training data sets as well as different machine learning classifiers
and show that some improve the quality of automatically extracted pathways.
</summary>
    <author>
      <name>Wojciech Kusa</name>
    </author>
    <author>
      <name>Michael Spranger</name>
    </author>
    <link href="http://arxiv.org/abs/1707.02063v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.02063v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.03819v1</id>
    <updated>2017-07-12T10:09:32Z</updated>
    <published>2017-07-12T10:09:32Z</published>
    <title>A Critique of a Critique of Word Similarity Datasets: Sanity Check or
  Unnecessary Confusion?</title>
    <summary>  Critical evaluation of word similarity datasets is very important for
computational lexical semantics. This short report concerns the sanity check
proposed in Batchkarov et al. (2016) to evaluate several popular datasets such
as MC, RG and MEN -- the first two reportedly failed. I argue that this test is
unstable, offers no added insight, and needs major revision in order to fulfill
its purported goal.
</summary>
    <author>
      <name>Minh Le</name>
    </author>
    <link href="http://arxiv.org/abs/1707.03819v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.03819v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.05850v3</id>
    <updated>2017-07-25T21:00:14Z</updated>
    <published>2017-07-18T20:38:42Z</published>
    <title>A Short Survey of Biomedical Relation Extraction Techniques</title>
    <summary>  Biomedical information is growing rapidly in the recent years and retrieving
useful data through information extraction system is getting more attention. In
the current research, we focus on different aspects of relation extraction
techniques in biomedical domain and briefly describe the state-of-the-art for
relation extraction between a variety of biological elements.
</summary>
    <author>
      <name>Elham Shahab</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">updated keywords and reference format</arxiv:comment>
    <link href="http://arxiv.org/abs/1707.05850v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.05850v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.06480v1</id>
    <updated>2017-07-20T12:46:09Z</updated>
    <published>2017-07-20T12:46:09Z</published>
    <title>Syllable-aware Neural Language Models: A Failure to Beat Character-aware
  Ones</title>
    <summary>  Syllabification does not seem to improve word-level RNN language modeling
quality when compared to character-based segmentation. However, our best
syllable-aware language model, achieving performance comparable to the
competitive character-aware model, has 18%-33% fewer parameters and is trained
1.2-2.2 times faster.
</summary>
    <author>
      <name>Zhenisbek Assylbekov</name>
    </author>
    <author>
      <name>Rustem Takhanov</name>
    </author>
    <author>
      <name>Bagdat Myrzakhmetov</name>
    </author>
    <author>
      <name>Jonathan N. Washington</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">EMNLP 2017</arxiv:comment>
    <link href="http://arxiv.org/abs/1707.06480v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.06480v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T50" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.07719v2</id>
    <updated>2017-08-16T06:37:55Z</updated>
    <published>2017-07-24T19:39:22Z</published>
    <title>Global Normalization of Convolutional Neural Networks for Joint Entity
  and Relation Classification</title>
    <summary>  We introduce globally normalized convolutional neural networks for joint
entity classification and relation extraction. In particular, we propose a way
to utilize a linear-chain conditional random field output layer for predicting
entity types and relations between entities at the same time. Our experiments
show that global normalization outperforms a locally normalized softmax layer
on a benchmark dataset.
</summary>
    <author>
      <name>Heike Adel</name>
    </author>
    <author>
      <name>Hinrich Schütze</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">EMNLP 2017</arxiv:comment>
    <link href="http://arxiv.org/abs/1707.07719v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.07719v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.07755v2</id>
    <updated>2017-08-02T15:47:32Z</updated>
    <published>2017-07-24T21:33:21Z</published>
    <title>AMR Parsing using Stack-LSTMs</title>
    <summary>  We present a transition-based AMR parser that directly generates AMR parses
from plain text. We use Stack-LSTMs to represent our parser state and make
decisions greedily. In our experiments, we show that our parser achieves very
competitive scores on English using only AMR training data. Adding additional
information, such as POS tags and dependency trees, improves the results
further.
</summary>
    <author>
      <name>Miguel Ballesteros</name>
    </author>
    <author>
      <name>Yaser Al-Onaizan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">EMNLP 2017</arxiv:comment>
    <link href="http://arxiv.org/abs/1707.07755v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.07755v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.09769v1</id>
    <updated>2017-07-31T08:56:32Z</updated>
    <published>2017-07-31T08:56:32Z</published>
    <title>Low-Resource Neural Headline Generation</title>
    <summary>  Recent neural headline generation models have shown great results, but are
generally trained on very large datasets. We focus our efforts on improving
headline quality on smaller datasets by the means of pretraining. We propose
new methods that enable pre-training all the parameters of the model and
utilize all available text, resulting in improvements by up to 32.4% relative
in perplexity and 2.84 points in ROUGE.
</summary>
    <author>
      <name>Ottokar Tilk</name>
    </author>
    <author>
      <name>Tanel Alumäe</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to EMNLP 2017 Workshop on New Frontiers in Summarization</arxiv:comment>
    <link href="http://arxiv.org/abs/1707.09769v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.09769v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.03699v1</id>
    <updated>2017-08-11T20:37:27Z</updated>
    <published>2017-08-11T20:37:27Z</published>
    <title>Improved Abusive Comment Moderation with User Embeddings</title>
    <summary>  Experimenting with a dataset of approximately 1.6M user comments from a Greek
news sports portal, we explore how a state of the art RNN-based moderation
method can be improved by adding user embeddings, user type embeddings, user
biases, or user type biases. We observe improvements in all cases, with user
embeddings leading to the biggest performance gains.
</summary>
    <author>
      <name>John Pavlopoulos</name>
    </author>
    <author>
      <name>Prodromos Malakasiotis</name>
    </author>
    <author>
      <name>Juli Bakagianni</name>
    </author>
    <author>
      <name>Ion Androutsopoulos</name>
    </author>
    <link href="http://arxiv.org/abs/1708.03699v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.03699v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.06708v1</id>
    <updated>2017-08-19T18:18:22Z</updated>
    <published>2017-08-19T18:18:22Z</published>
    <title>A rule based algorithm for detecting negative words in Persian</title>
    <summary>  In this paper, we present a novel method for detecting negative words in
Persian. We first used an algorithm to an exceptions list which was later
modified by hand. We then used the mentioned lists and a Persian polarity
corpus in our rule based algorithm to detect negative words.
</summary>
    <author>
      <name>Reza Takhshid</name>
    </author>
    <author>
      <name>Adel Rahimi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1708.06708v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.06708v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.07722v2</id>
    <updated>2017-09-11T08:27:18Z</updated>
    <published>2017-08-24T04:59:53Z</published>
    <title>A dependency look at the reality of constituency</title>
    <summary>  A comment on "Neurophysiological dynamics of phrase-structure building during
sentence processing" by Nelson et al (2017), Proceedings of the National
Academy of Sciences USA 114(18), E3669-E3678.
</summary>
    <author>
      <name>Xinying Chen</name>
    </author>
    <author>
      <name>Carlos Gómez-Rodríguez</name>
    </author>
    <author>
      <name>Ramon Ferrer-i-Cancho</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Reformatted, typos corrected and reference to Lester's research added</arxiv:comment>
    <link href="http://arxiv.org/abs/1708.07722v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.07722v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.00489v1</id>
    <updated>2017-09-01T21:38:28Z</updated>
    <published>2017-09-01T21:38:28Z</published>
    <title>Arc-Standard Spinal Parsing with Stack-LSTMs</title>
    <summary>  We present a neural transition-based parser for spinal trees, a dependency
representation of constituent trees. The parser uses Stack-LSTMs that compose
constituent nodes with dependency-based derivations. In experiments, we show
that this model adapts to different styles of dependency relations, but this
choice has little effect for predicting constituent structure, suggesting that
LSTMs induce useful states by themselves.
</summary>
    <author>
      <name>Miguel Ballesteros</name>
    </author>
    <author>
      <name>Xavier Carreras</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">IWPT 2017</arxiv:comment>
    <link href="http://arxiv.org/abs/1709.00489v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.00489v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.03815v1</id>
    <updated>2017-09-12T12:58:07Z</updated>
    <published>2017-09-12T12:58:07Z</published>
    <title>OpenNMT: Open-source Toolkit for Neural Machine Translation</title>
    <summary>  We introduce an open-source toolkit for neural machine translation (NMT) to
support research into model architectures, feature representations, and source
modalities, while maintaining competitive performance, modularity and
reasonable training requirements.
</summary>
    <author>
      <name>Guillaume Klein</name>
    </author>
    <author>
      <name>Yoon Kim</name>
    </author>
    <author>
      <name>Yuntian Deng</name>
    </author>
    <author>
      <name>Josep Crego</name>
    </author>
    <author>
      <name>Jean Senellart</name>
    </author>
    <author>
      <name>Alexander M. Rush</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published in EAMT 2017 User Studies and Project/Product Descriptions</arxiv:comment>
    <link href="http://arxiv.org/abs/1709.03815v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.03815v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.05599v1</id>
    <updated>2017-09-17T02:56:40Z</updated>
    <published>2017-09-17T02:56:40Z</published>
    <title>Hierarchical Gated Recurrent Neural Tensor Network for Answer Triggering</title>
    <summary>  In this paper, we focus on the problem of answer triggering ad-dressed by
Yang et al. (2015), which is a critical component for a real-world question
answering system. We employ a hierarchical gated recurrent neural tensor
(HGRNT) model to capture both the context information and the deep
in-teractions between the candidate answers and the question. Our result on F
val-ue achieves 42.6%, which surpasses the baseline by over 10 %.
</summary>
    <author>
      <name>Wei Li</name>
    </author>
    <author>
      <name>Yunfang Wu</name>
    </author>
    <link href="http://arxiv.org/abs/1709.05599v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.05599v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.07809v1</id>
    <updated>2017-09-22T15:28:24Z</updated>
    <published>2017-09-22T15:28:24Z</published>
    <title>Neural Machine Translation</title>
    <summary>  Draft of textbook chapter on neural machine translation. a comprehensive
treatment of the topic, ranging from introduction to neural networks,
computation graphs, description of the currently dominant attentional
sequence-to-sequence model, recent refinements, alternative architectures and
challenges. Written as chapter for the textbook Statistical Machine
Translation. Used in the JHU Fall 2017 class on machine translation.
</summary>
    <author>
      <name>Philipp Koehn</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">100+ pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1709.07809v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.07809v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.10053v1</id>
    <updated>2017-09-28T16:44:22Z</updated>
    <published>2017-09-28T16:44:22Z</published>
    <title>Graph Convolutional Networks for Named Entity Recognition</title>
    <summary>  In this paper we investigate the role of the dependency tree in a named
entity recognizer upon using a set of GCN. We perform a comparison among
different NER architectures and show that the grammar of a sentence positively
influences the results. Experiments on the ontonotes dataset demonstrate
consistent performance improvements, without requiring heavy feature
engineering nor additional language-specific knowledge.
</summary>
    <author>
      <name>A. Cetoli</name>
    </author>
    <author>
      <name>S. Bragaglia</name>
    </author>
    <author>
      <name>A. D. O'Harney</name>
    </author>
    <author>
      <name>M. Sloan</name>
    </author>
    <link href="http://arxiv.org/abs/1709.10053v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.10053v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.10486v1</id>
    <updated>2017-09-29T16:36:53Z</updated>
    <published>2017-09-29T16:36:53Z</published>
    <title>Symbol, Conversational, and Societal Grounding with a Toy Robot</title>
    <summary>  Essential to meaningful interaction is grounding at the symbolic,
conversational, and societal levels. We present ongoing work with Anki's Cozmo
toy robot as a research platform where we leverage the recent
words-as-classifiers model of lexical semantics in interactive reference
resolution tasks for language grounding.
</summary>
    <author>
      <name>Casey Kennington</name>
    </author>
    <author>
      <name>Sarah Plane</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1709.10486v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.10486v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1710.00803v1</id>
    <updated>2017-10-02T17:18:37Z</updated>
    <published>2017-10-02T17:18:37Z</published>
    <title>Compiling and Processing Historical and Contemporary Portuguese Corpora</title>
    <summary>  This technical report describes the framework used for processing three large
Portuguese corpora. Two corpora contain texts from newspapers, one published in
Brazil and the other published in Portugal. The third corpus is Colonia, a
historical Portuguese collection containing texts written between the 16th and
the early 20th century. The report presents pre-processing methods,
segmentation, and annotation of the corpora as well as indexing and querying
methods. Finally, it presents published research papers using the corpora.
</summary>
    <author>
      <name>Marcos Zampieri</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Technical Report</arxiv:comment>
    <link href="http://arxiv.org/abs/1710.00803v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1710.00803v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0807.0565v1</id>
    <updated>2008-07-03T13:42:00Z</updated>
    <published>2008-07-03T13:42:00Z</published>
    <title>Music, Complexity, Information</title>
    <summary>  These are the preparatory notes for a Science &amp; Music essay, "Playing by
numbers", appeared in Nature 453 (2008) 988-989.
</summary>
    <author>
      <name>Damian H. Zanette</name>
    </author>
    <link href="http://arxiv.org/abs/0807.0565v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0807.0565v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1512.08982v1</id>
    <updated>2015-12-30T15:46:30Z</updated>
    <published>2015-12-30T15:46:30Z</published>
    <title>Technical Report: a tool for measuring Prosodic Accommodation</title>
    <summary>  This article has been withdrawn by arXiv administrators because the submitter
did not have the legal authority to grant the license applied to the work.
</summary>
    <author>
      <name>Sucheta Ghosh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Withdrawn by arXiv administrators</arxiv:comment>
    <link href="http://arxiv.org/abs/1512.08982v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1512.08982v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9809020v1</id>
    <updated>1998-09-15T23:49:32Z</updated>
    <published>1998-09-15T23:49:32Z</published>
    <title>Linear Segmentation and Segment Significance</title>
    <summary>  We present a new method for discovering a segmental discourse structure of a
document while categorizing segment function. We demonstrate how retrieval of
noun phrases and pronominal forms, along with a zero-sum weighting scheme,
determines topicalized segmentation. Futhermore, we use term distribution to
aid in identifying the role that the segment performs in the document. Finally,
we present results of evaluation in terms of precision and recall which surpass
earlier approaches.
</summary>
    <author>
      <name>Min-Yen Kan</name>
    </author>
    <author>
      <name>Judith L. Klavans</name>
    </author>
    <author>
      <name>Kathleen R. McKeown</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, US Letter, 4 figures. Software License can be found at
  http://www.cs.columbia.edu/nlp/licenses/segmenterLicenseDownload.html</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of 6th International Workshop of Very Large Corpora
  (WVLC-6), Montreal, Quebec, Canada: Aug. 1998. pp. 197-205</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/9809020v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9809020v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9809028v1</id>
    <updated>1998-09-18T04:44:02Z</updated>
    <published>1998-09-18T04:44:02Z</published>
    <title>Separating Dependency from Constituency in a Tree Rewriting System</title>
    <summary>  In this paper we present a new tree-rewriting formalism called Link-Sharing
Tree Adjoining Grammar (LSTAG) which is a variant of synchronous TAGs. Using
LSTAG we define an approach towards coordination where linguistic dependency is
distinguished from the notion of constituency. Such an approach towards
coordination that explicitly distinguishes dependencies from constituency gives
a better formal understanding of its representation when compared to previous
approaches that use tree-rewriting systems which conflate the two issues.
</summary>
    <author>
      <name>Anoop Sarkar</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Pennsylvania</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 6 Postscript figures, uses fullname.sty</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings of the Fifth Meeting on Mathematics of Language,
  Saarbruecken, August 1997</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/9809028v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9809028v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7; D.3.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9809029v1</id>
    <updated>1998-09-18T05:03:48Z</updated>
    <published>1998-09-18T05:03:48Z</published>
    <title>Incremental Parser Generation for Tree Adjoining Grammars</title>
    <summary>  This paper describes the incremental generation of parse tables for the
LR-type parsing of Tree Adjoining Languages (TALs). The algorithm presented
handles modifications to the input grammar by updating the parser generated so
far. In this paper, a lazy generation of LR-type parsers for TALs is defined in
which parse tables are created by need while parsing. We then describe an
incremental parser generator for TALs which responds to modification of the
input grammar by updating parse tables built so far.
</summary>
    <author>
      <name>Anoop Sarkar</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Pennsylvania</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1063/1.1594535</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1063/1.1594535" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 12 Postscript figures, uses fullname.sty</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Longer version of paper in Proceedings of the 34th Meeting of the
  ACL, Student Session. Santa Cruz, June 1996</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/9809029v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9809029v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7; D.3.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9809050v1</id>
    <updated>1998-09-23T12:59:39Z</updated>
    <published>1998-09-23T12:59:39Z</published>
    <title>A Freely Available Morphological Analyzer, Disambiguator and Context
  Sensitive Lemmatizer for German</title>
    <summary>  In this paper we present Morphy, an integrated tool for German morphology,
part-of-speech tagging and context-sensitive lemmatization. Its large lexicon
of more than 320,000 word forms plus its ability to process German compound
nouns guarantee a wide morphological coverage. Syntactic ambiguities can be
resolved with a standard statistical part-of-speech tagger. By using the output
of the tagger, the lemmatizer can determine the correct root even for ambiguous
word forms. The complete package is freely available and can be downloaded from
the World Wide Web.
</summary>
    <author>
      <name>Wolfgang Lezius</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Paderborn</arxiv:affiliation>
    </author>
    <author>
      <name>Reinhard Rapp</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Mainz</arxiv:affiliation>
    </author>
    <author>
      <name>Manfred Wettler</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Paderborn</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, Postscript only</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the COLING-ACL 1998, pp. 743-748</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/9809050v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9809050v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9809112v1</id>
    <updated>1998-09-28T07:49:11Z</updated>
    <published>1998-09-28T07:49:11Z</published>
    <title>On the Evaluation and Comparison of Taggers: The Effect of Noise in
  Testing Corpora</title>
    <summary>  This paper addresses the issue of {\sc pos} tagger evaluation. Such
evaluation is usually performed by comparing the tagger output with a reference
test corpus, which is assumed to be error-free. Currently used corpora contain
noise which causes the obtained performance to be a distortion of the real
value. We analyze to what extent this distortion may invalidate the comparison
between taggers or the measure of the improvement given by a new system. The
main conclusion is that a more rigorous testing experimentation
setting/designing is needed to reliably evaluate and compare tagger accuracies.
</summary>
    <author>
      <name>L. Padro</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Universitat Politecnica de Catalunya</arxiv:affiliation>
    </author>
    <author>
      <name>L. Marquez</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Universitat Politecnica de Catalunya</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in proceedings of joint COLING-ACL 1998, Montreal, Canada</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/9809112v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9809112v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9809113v1</id>
    <updated>1998-09-28T07:50:55Z</updated>
    <published>1998-09-28T07:50:55Z</published>
    <title>Improving Tagging Performance by Using Voting Taggers</title>
    <summary>  We present a bootstrapping method to develop an annotated corpus, which is
specially useful for languages with few available resources. The method is
being applied to develop a corpus of Spanish of over 5Mw. The method consists
on taking advantage of the collaboration of two different POS taggers. The
cases in which both taggers agree present a higher accuracy and are used to
retrain the taggers.
</summary>
    <author>
      <name>L. Marquez</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Universitat Politecnica de Catalunya</arxiv:affiliation>
    </author>
    <author>
      <name>L. Padro</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Universitat Politecnica de Catalunya</arxiv:affiliation>
    </author>
    <author>
      <name>H. Rodriguez</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Universitat Politecnica de Catalunya</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in proceedings of NLP+IA/TAL+AI'98. Moncton, New Brunswick,
  Canada, 1998</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/9809113v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9809113v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9810015v1</id>
    <updated>1998-10-13T21:17:13Z</updated>
    <published>1998-10-13T21:17:13Z</published>
    <title>Restrictions on Tree Adjoining Languages</title>
    <summary>  Several methods are known for parsing languages generated by Tree Adjoining
Grammars (TAGs) in O(n^6) worst case running time. In this paper we investigate
which restrictions on TAGs and TAG derivations are needed in order to lower
this O(n^6) time complexity, without introducing large runtime constants, and
without losing any of the generative power needed to capture the syntactic
constructions in natural language that can be handled by unrestricted TAGs. In
particular, we describe an algorithm for parsing a strict subclass of TAG in
O(n^5), and attempt to show that this subclass retains enough generative power
to make it useful in the general case.
</summary>
    <author>
      <name>Giorgio Satta</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Universita di Padova</arxiv:affiliation>
    </author>
    <author>
      <name>William Schuler</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Pennsylvania</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages LaTeX + 5 eps figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of COLING-ACL'98</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/9810015v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9810015v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9811006v1</id>
    <updated>1998-11-02T18:57:23Z</updated>
    <published>1998-11-02T18:57:23Z</published>
    <title>Machine Learning of Generic and User-Focused Summarization</title>
    <summary>  A key problem in text summarization is finding a salience function which
determines what information in the source should be included in the summary.
This paper describes the use of machine learning on a training corpus of
documents and their abstracts to discover salience functions which describe
what combination of features is optimal for a given summarization task. The
method addresses both "generic" and user-focused summaries.
</summary>
    <author>
      <name>Inderjeet Mani</name>
    </author>
    <author>
      <name>Eric Bloedorn</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings of the Fifteenth National Conference on AI (AAAI-98),
  p. 821-826</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/9811006v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9811006v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.6; I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9811008v1</id>
    <updated>1998-11-02T21:29:41Z</updated>
    <published>1998-11-02T21:29:41Z</published>
    <title>Translating near-synonyms: Possibilities and preferences in the
  interlingua</title>
    <summary>  This paper argues that an interlingual representation must explicitly
represent some parts of the meaning of a situation as possibilities (or
preferences), not as necessary or definite components of meaning (or
constraints). Possibilities enable the analysis and generation of nuance,
something required for faithful translation. Furthermore, the representation of
the meaning of words, especially of near-synonyms, is crucial, because it
specifies which nuances words can convey in which contexts.
</summary>
    <author>
      <name>Philip Edmonds</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Toronto</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, LaTeX2e, 1 eps figure, uses colacl.sty, epsfig.sty, avm.sty,
  times.sty</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the AMTA/SIG-IL Second Workshop on Interlinguas,
  October 1998</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/9811008v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9811008v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7; I.2.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9811009v1</id>
    <updated>1998-11-02T23:06:19Z</updated>
    <published>1998-11-02T23:06:19Z</published>
    <title>Choosing the Word Most Typical in Context Using a Lexical Co-occurrence
  Network</title>
    <summary>  This paper presents a partial solution to a component of the problem of
lexical choice: choosing the synonym most typical, or expected, in context. We
apply a new statistical approach to representing the context of a word through
lexical co-occurrence networks. The implementation was trained and evaluated on
a large corpus, and results show that the inclusion of second-order
co-occurrence relations improves the performance of our implemented lexical
choice program.
</summary>
    <author>
      <name>Philip Edmonds</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Toronto</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3 pages, LaTeX2e, 1 ps figure, uses mathptm.sty, colacl.sty,
  psfig.sty</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of ACL-EACL '97, student session</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/9811009v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9811009v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9811022v2</id>
    <updated>2000-01-25T15:37:36Z</updated>
    <published>1998-11-12T17:31:17Z</published>
    <title>Expoiting Syntactic Structure for Language Modeling</title>
    <summary>  The paper presents a language model that develops syntactic structure and
uses it to extract meaningful information from the word history, thus enabling
the use of long distance dependencies. The model assigns probability to every
joint sequence of words--binary-parse-structure with headword annotation and
operates in a left-to-right manner --- therefore usable for automatic speech
recognition. The model, its probabilistic parameterization, and a set of
experiments meant to evaluate its predictive power are presented; an
improvement over standard trigram modeling is achieved.
</summary>
    <author>
      <name>Ciprian Chelba</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CLSP The Johns Hopkins University</arxiv:affiliation>
    </author>
    <author>
      <name>Frederick Jelinek</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CLSP The Johns Hopkins University</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">changed ACM-class membership and buggy author names</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of ACL'98, Montreal, Canada</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/9811022v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9811022v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.3, I.2.7, I.5.1, I.5.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9811025v2</id>
    <updated>2000-01-25T15:46:48Z</updated>
    <published>1998-11-13T16:53:15Z</published>
    <title>A Structured Language Model</title>
    <summary>  The paper presents a language model that develops syntactic structure and
uses it to extract meaningful information from the word history, thus enabling
the use of long distance dependencies. The model assigns probability to every
joint sequence of words - binary-parse-structure with headword annotation. The
model, its probabilistic parametrization, and a set of experiments meant to
evaluate its predictive power are presented.
</summary>
    <author>
      <name>Ciprian Chelba</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CLSP, The Johns Hopkins University, USA</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">changed ACM-class membership, Proceedings of ACL-EACL'97, Student
  Section, Madrid, Spain</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/9811025v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9811025v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.3, I.2.7, I.5.1, I.5.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9812005v1</id>
    <updated>1998-12-04T16:16:35Z</updated>
    <published>1998-12-04T16:16:35Z</published>
    <title>Optimal Multi-Paragraph Text Segmentation by Dynamic Programming</title>
    <summary>  There exist several methods of calculating a similarity curve, or a sequence
of similarity values, representing the lexical cohesion of successive text
constituents, e.g., paragraphs. Methods for deciding the locations of fragment
boundaries are, however, scarce. We propose a fragmentation method based on
dynamic programming. The method is theoretically sound and guaranteed to
provide an optimal splitting on the basis of a similarity curve, a preferred
fragment length, and a cost function defined. The method is especially useful
when control on fragment size is of importance.
</summary>
    <author>
      <name>Oskari Heinonen</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Helsinki</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 3 eps figures, LaTeX2e; includes errata; uses colacl, epsf,
  times</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of COLING-ACL '98, pp. 1484-1486, Montreal, Canada</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/9812005v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9812005v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9904004v1</id>
    <updated>1999-04-12T11:37:49Z</updated>
    <published>1999-04-12T11:37:49Z</published>
    <title>Mixing Metaphors</title>
    <summary>  Mixed metaphors have been neglected in recent metaphor research. This paper
suggests that such neglect is short-sighted. Though mixing is a more complex
phenomenon than straight metaphors, the same kinds of reasoning and knowledge
structures are required. This paper provides an analysis of both parallel and
serial mixed metaphors within the framework of an AI system which is already
capable of reasoning about straight metaphorical manifestations and argues that
the processes underlying mixing are central to metaphorical meaning. Therefore,
any theory of metaphors must be able to account for mixing.
</summary>
    <author>
      <name>Mark Lee</name>
    </author>
    <author>
      <name>John Barnden</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the AISB'99 Symposium on Metaphor, Artificial
  Intelligence, and Cognition, pages 11-16, Edinburgh</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/9904004v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9904004v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.0; I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9904008v1</id>
    <updated>1999-04-15T14:00:41Z</updated>
    <published>1999-04-15T14:00:41Z</published>
    <title>Transducers from Rewrite Rules with Backreferences</title>
    <summary>  Context sensitive rewrite rules have been widely used in several areas of
natural language processing, including syntax, morphology, phonology and speech
processing. Kaplan and Kay, Karttunen, and Mohri &amp; Sproat have given various
algorithms to compile such rewrite rules into finite-state transducers. The
present paper extends this work by allowing a limited form of backreferencing
in such rules. The explicit use of backreferencing leads to more elegant and
general solutions.
</summary>
    <author>
      <name>Dale Gerdemann</name>
    </author>
    <author>
      <name>Gertjan van Noord</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, EACL 1999 Bergen</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/9904008v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9904008v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.1.1; F.4.3; I.2.1; J.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9904018v1</id>
    <updated>1999-04-24T23:45:26Z</updated>
    <published>1999-04-24T23:45:26Z</published>
    <title>A Computational Memory and Processing Model for Processing</title>
    <summary>  This paper links prosody to the information in a text and how it is processed
by the speaker. It describes the operation and output of LOQ, a text-to-speech
implementation that includes a model of limited attention and working memory.
Attentional limitations are key. Varying the attentional parameter in the
simulations varies in turn what counts as given and new in a text, and
therefore, the intonational contours with which it is uttered. Currently, the
system produces prosody in three different styles: child-like, adult
expressive, and knowledgeable. This prosody also exhibits differences within
each style -- no two simulations are alike. The limited resource approach
captures some of the stylistic and individual variety found in natural prosody.
</summary>
    <author>
      <name>Janet E. Cahn</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/9904018v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9904018v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7, I.2.0" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9905008v1</id>
    <updated>1999-05-19T14:52:33Z</updated>
    <published>1999-05-19T14:52:33Z</published>
    <title>Inducing a Semantically Annotated Lexicon via EM-Based Clustering</title>
    <summary>  We present a technique for automatic induction of slot annotations for
subcategorization frames, based on induction of hidden classes in the EM
framework of statistical estimation. The models are empirically evalutated by a
general decision test. Induction of slot labeling for subcategorization frames
is accomplished by a further application of EM, and applied experimentally on
frame observations derived from parsing large corpora. We outline an
interpretation of the learned representations as theoretical-linguistic
decompositional lexical entries.
</summary>
    <author>
      <name>Mats Rooth</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IMS, University of Stuttgart</arxiv:affiliation>
    </author>
    <author>
      <name>Stefan Riezler</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IMS, University of Stuttgart</arxiv:affiliation>
    </author>
    <author>
      <name>Detlef Prescher</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IMS, University of Stuttgart</arxiv:affiliation>
    </author>
    <author>
      <name>Glenn Carroll</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IMS, University of Stuttgart</arxiv:affiliation>
    </author>
    <author>
      <name>Franz Beil</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IMS, University of Stuttgart</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, uses colacl.sty. Proceedings of the 37th Annual Meeting of
  the ACL, 1999</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/9905008v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9905008v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.6; I.2.7; I.5.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9905009v1</id>
    <updated>1999-05-19T14:47:21Z</updated>
    <published>1999-05-19T14:47:21Z</published>
    <title>Inside-Outside Estimation of a Lexicalized PCFG for German</title>
    <summary>  The paper describes an extensive experiment in inside-outside estimation of a
lexicalized probabilistic context free grammar for German verb-final clauses.
Grammar and formalism features which make the experiment feasible are
described. Successive models are evaluated on precision and recall of phrase
markup.
</summary>
    <author>
      <name>Franz Beil</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IMS, University of Stuttgart</arxiv:affiliation>
    </author>
    <author>
      <name>Glenn Carroll</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IMS, University of Stuttgart</arxiv:affiliation>
    </author>
    <author>
      <name>Detlef Prescher</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IMS, University of Stuttgart</arxiv:affiliation>
    </author>
    <author>
      <name>Stefan Riezler</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IMS, University of Stuttgart</arxiv:affiliation>
    </author>
    <author>
      <name>Mats Rooth</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IMS, University of Stuttgart</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, uses colacl.sty. Proceedings of the 37th Annual Meeting of
  the ACL, 1999</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/9905009v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9905009v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.6; I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9906004v1</id>
    <updated>1999-06-02T13:41:51Z</updated>
    <published>1999-06-02T13:41:51Z</published>
    <title>Cascaded Grammatical Relation Assignment</title>
    <summary>  In this paper we discuss cascaded Memory-Based grammatical relations
assignment. In the first stages of the cascade, we find chunks of several types
(NP,VP,ADJP,ADVP,PP) and label them with their adverbial function (e.g. local,
temporal). In the last stage, we assign grammatical relations to pairs of
chunks. We studied the effect of adding several levels to this cascaded
classifier and we found that even the less performing chunkers enhanced the
performance of the relation finder.
</summary>
    <author>
      <name>Sabine Buchholz</name>
    </author>
    <author>
      <name>Jorn Veenstra</name>
    </author>
    <author>
      <name>Walter Daelemans</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, to appear in: proceedings of EMNLP/VLC-99, University of
  Maryland, USA, June 21-22, 1999</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/9906004v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9906004v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.6.2;I.7.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9906005v1</id>
    <updated>1999-06-02T13:48:48Z</updated>
    <published>1999-06-02T13:48:48Z</published>
    <title>Memory-Based Shallow Parsing</title>
    <summary>  We present a memory-based learning (MBL) approach to shallow parsing in which
POS tagging, chunking, and identification of syntactic relations are formulated
as memory-based modules. The experiments reported in this paper show
competitive results, the F-value for the Wall Street Journal (WSJ) treebank is:
93.8% for NP chunking, 94.7% for VP chunking, 77.1% for subject detection and
79.0% for object detection.
</summary>
    <author>
      <name>Walter Daelemans</name>
    </author>
    <author>
      <name>Sabine Buchholz</name>
    </author>
    <author>
      <name>Jorn Veenstra</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, to appear in: Proceedings of the EACL'99 workshop on
  Computational Natural Language Learning (CoNLL-99), Bergen, Norway, June 1999</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/9906005v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9906005v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.6.2;I.7.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9906015v1</id>
    <updated>1999-06-14T22:06:24Z</updated>
    <published>1999-06-14T22:06:24Z</published>
    <title>Learning Transformation Rules to Find Grammatical Relations</title>
    <summary>  Grammatical relationships are an important level of natural language
processing. We present a trainable approach to find these relationships through
transformation sequences and error-driven learning. Our approach finds
grammatical relationships between core syntax groups and bypasses much of the
parsing phase. On our training and test set, our procedure achieves 63.6%
recall and 77.3% precision (f-score = 69.8).
</summary>
    <author>
      <name>Lisa Ferro</name>
    </author>
    <author>
      <name>Marc Vilain</name>
    </author>
    <author>
      <name>Alexander Yeh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages. Uses latex-acl.sty and named.sty</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Computational Natural Language Learning (CoNLL-99), pages 43-52,
  June, 1999. Bergen, Norway</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/9906015v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9906015v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9906025v1</id>
    <updated>1999-06-24T16:56:45Z</updated>
    <published>1999-06-24T16:56:45Z</published>
    <title>Mapping Multilingual Hierarchies Using Relaxation Labeling</title>
    <summary>  This paper explores the automatic construction of a multilingual Lexical
Knowledge Base from pre-existing lexical resources. We present a new and robust
approach for linking already existing lexical/semantic hierarchies. We used a
constraint satisfaction algorithm (relaxation labeling) to select --among all
the candidate translations proposed by a bilingual dictionary-- the right
English WordNet synset for each sense in a taxonomy automatically derived from
a Spanish monolingual dictionary. Although on average, there are 15 possible
WordNet connections for each sense in the taxonomy, the method achieves an
accuracy over 80%. Finally, we also propose several ways in which this
technique could be applied to enrich and improve existing lexical databases.
</summary>
    <author>
      <name>J. Daude</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">TALP Research Center. LSI Dept. Universitat Politecnica de Catalunya. Barcelona</arxiv:affiliation>
    </author>
    <author>
      <name>L. Padro</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">TALP Research Center. LSI Dept. Universitat Politecnica de Catalunya. Barcelona</arxiv:affiliation>
    </author>
    <author>
      <name>G. Rigau</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">TALP Research Center. LSI Dept. Universitat Politecnica de Catalunya. Barcelona</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages. 1 eps figure</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/9906025v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9906025v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9906026v1</id>
    <updated>1999-06-25T08:16:23Z</updated>
    <published>1999-06-25T08:16:23Z</published>
    <title>Robust Grammatical Analysis for Spoken Dialogue Systems</title>
    <summary>  We argue that grammatical analysis is a viable alternative to concept
spotting for processing spoken input in a practical spoken dialogue system. We
discuss the structure of the grammar, and a model for robust parsing which
combines linguistic sources of information and statistical sources of
information. We discuss test results suggesting that grammatical processing
allows fast and accurate processing of spoken input.
</summary>
    <author>
      <name>Gertjan van Noord</name>
    </author>
    <author>
      <name>Gosse Bouma</name>
    </author>
    <author>
      <name>Rob Koeling</name>
    </author>
    <author>
      <name>Mark-Jan Nederhof</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted for JNLE</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/9906026v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9906026v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.4.0;H.5.1;H.5.2;I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9907006v1</id>
    <updated>1999-07-06T12:44:20Z</updated>
    <published>1999-07-06T12:44:20Z</published>
    <title>Representing Text Chunks</title>
    <summary>  Dividing sentences in chunks of words is a useful preprocessing step for
parsing, information extraction and information retrieval. (Ramshaw and Marcus,
1995) have introduced a "convenient" data representation for chunking by
converting it to a tagging task. In this paper we will examine seven different
data representations for the problem of recognizing noun phrase chunks. We will
show that the the data representation choice has a minor influence on chunking
performance. However, equipped with the most suitable data representation, our
memory-based learning chunker was able to improve the best published chunking
results for a standard data set.
</summary>
    <author>
      <name>Erik F. Tjong Kim Sang</name>
    </author>
    <author>
      <name>Jorn Veenstra</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EACL'99, Bergen</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/9907006v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9907006v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9907008v1</id>
    <updated>1999-07-06T18:35:41Z</updated>
    <published>1999-07-06T18:35:41Z</published>
    <title>Explanation-based Learning for Machine Translation</title>
    <summary>  In this paper we present an application of explanation-based learning (EBL)
in the parsing module of a real-time English-Spanish machine translation system
designed to translate closed captions. We discuss the efficiency/coverage
trade-offs available in EBL and introduce the techniques we use to increase
coverage while maintaining a high level of space and time efficiency. Our
performance results indicate that this approach is effective.
</summary>
    <author>
      <name>Janine Toole</name>
    </author>
    <author>
      <name>Fred Popowich</name>
    </author>
    <author>
      <name>Devlan Nicholson</name>
    </author>
    <author>
      <name>Davide Turcato</name>
    </author>
    <author>
      <name>Paul McFetridge</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 3 figures, To appear in Proceedings of the 8th
  International Conference on Theoretical and Methodological Issues in Machine
  Translation</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/9907008v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9907008v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9907010v1</id>
    <updated>1999-07-07T09:28:40Z</updated>
    <published>1999-07-07T09:28:40Z</published>
    <title>Language Identification With Confidence Limits</title>
    <summary>  A statistical classification algorithm and its application to language
identification from noisy input are described. The main innovation is to
compute confidence limits on the classification, so that the algorithm
terminates when enough evidence to make a clear decision has been made, and so
avoiding problems with categories that have similar characteristics. A second
application, to genre identification, is briefly examined. The results show
that some of the problems of other language identification techniques can be
avoided, and illustrate a more important point: that a statistical language
process can be used to provide feedback about its own success rate.
</summary>
    <author>
      <name>David Elworthy</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages; needs colacl.sty. Appeared in Proceedings of the Sixth
  Workshop on Very Large Corpora (COLING-ACL 98)</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/9907010v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9907010v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7; I.5.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9907012v1</id>
    <updated>1999-07-08T09:46:37Z</updated>
    <published>1999-07-08T09:46:37Z</published>
    <title>Selective Magic HPSG Parsing</title>
    <summary>  We propose a parser for constraint-logic grammars implementing HPSG that
combines the advantages of dynamic bottom-up and advanced top-down control. The
parser allows the user to apply magic compilation to specific constraints in a
grammar which as a result can be processed dynamically in a bottom-up and
goal-directed fashion. State of the art top-down processing techniques are used
to deal with the remaining constraints. We discuss various aspects concerning
the implementation of the parser as part of a grammar development system.
</summary>
    <author>
      <name>Guido Minnen</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Sussex</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, LaTeX with 4 postscript figures (uses avm.sty, eaclap.sty
  and psfig-scale.sty)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of EACL99, Bergen, Norway, June 8-11</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/9907012v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9907012v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9907013v1</id>
    <updated>1999-07-08T10:08:59Z</updated>
    <published>1999-07-08T10:08:59Z</published>
    <title>Corpus Annotation for Parser Evaluation</title>
    <summary>  We describe a recently developed corpus annotation scheme for evaluating
parsers that avoids shortcomings of current methods. The scheme encodes
grammatical relations between heads and dependents, and has been used to mark
up a new public-domain corpus of naturally occurring English text. We show how
the corpus can be used to evaluate the accuracy of a robust parser, and relate
the corpus to extant resources.
</summary>
    <author>
      <name>John Carroll</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Sussex</arxiv:affiliation>
    </author>
    <author>
      <name>Guido Minnen</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Sussex</arxiv:affiliation>
    </author>
    <author>
      <name>Ted Briscoe</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Cambridge University</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, LaTeX (uses eaclap.sty)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the EACL99 workshop on Linguistically Interpreted
  Corpora (LINC), Bergen, Norway, June 12</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/9907013v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9907013v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9908001v1</id>
    <updated>1999-08-01T14:02:57Z</updated>
    <published>1999-08-01T14:02:57Z</published>
    <title>Detecting Sub-Topic Correspondence through Bipartite Term Clustering</title>
    <summary>  This paper addresses a novel task of detecting sub-topic correspondence in a
pair of text fragments, enhancing common notions of text similarity. This task
is addressed by coupling corresponding term subsets through bipartite
clustering. The paper presents a cost-based clustering scheme and compares it
with a bipartite version of the single-link method, providing illustrating
results.
</summary>
    <author>
      <name>Zvika Marx</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Bar-Ilan University</arxiv:affiliation>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">The Hebrew University of Jerusalem</arxiv:affiliation>
    </author>
    <author>
      <name>Ido Dagan</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Bar-Ilan University</arxiv:affiliation>
    </author>
    <author>
      <name>Eli Shamir</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">The Hebrew University of Jerusalem</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">html with 3 gif figures; generated from 7 pages MS-Word file</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of ACL'99 Workshop on Unsupervised Learning in Natural
  Language Processing, 1999, pp 45-51</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/9908001v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9908001v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.6, I.2.7, H.3.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9909002v1</id>
    <updated>1999-09-02T15:53:07Z</updated>
    <published>1999-09-02T15:53:07Z</published>
    <title>Semantic robust parsing for noun extraction from natural language
  queries</title>
    <summary>  This paper describes how robust parsing techniques can be fruitful applied
for building a query generation module which is part of a pipelined NLP
architecture aimed at process natural language queries in a restricted domain.
We want to show that semantic robustness represents a key issue in those NLP
systems where it is more likely to have partial and ill-formed utterances due
to various factors (e.g. noisy environments, low quality of speech recognition
modules, etc...) and where it is necessary to succeed, even if partially, in
extracting some meaningful information.
</summary>
    <author>
      <name>Afzal Ballim</name>
    </author>
    <author>
      <name>Vincenzo Pallotta</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of WPDI'99 (Workshop on Procedures in Discourse
  Interpretation),1999, Iasi - Romania</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/9909002v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9909002v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9910022v1</id>
    <updated>1999-10-25T15:00:52Z</updated>
    <published>1999-10-25T15:00:52Z</published>
    <title>Practical experiments with regular approximation of context-free
  languages</title>
    <summary>  Several methods are discussed that construct a finite automaton given a
context-free grammar, including both methods that lead to subsets and those
that lead to supersets of the original context-free language. Some of these
methods of regular approximation are new, and some others are presented here in
a more refined form with respect to existing literature. Practical experiments
with the different methods of regular approximation are performed for
spoken-language input: hypotheses from a speech recognizer are filtered through
a finite automaton.
</summary>
    <author>
      <name>Mark-Jan Nederhof</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">28 pages. To appear in Computational Linguistics 26(1), March 2000</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/9910022v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9910022v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.4.3; F.1.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9912006v1</id>
    <updated>1999-12-13T05:19:46Z</updated>
    <published>1999-12-13T05:19:46Z</published>
    <title>Resolution of Verb Ellipsis in Japanese Sentence using Surface
  Expressions and Examples</title>
    <summary>  Verbs are sometimes omitted in Japanese sentences. It is necessary to recover
omitted verbs for purposes of language understanding, machine translation, and
conversational processing. This paper describes a practical way to recover
omitted verbs by using surface expressions and examples. We experimented the
resolution of verb ellipses by using this information, and obtained a recall
rate of 73% and a precision rate of 66% on test sentences.
</summary>
    <author>
      <name>M. Murata</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Kyoto University</arxiv:affiliation>
    </author>
    <author>
      <name>M. Nagao</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Kyoto University</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 0 figures. Computation and Language</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Natural Language Processing Pacific Rim Symposium 1997 (NLPRS'97),
  Cape Panwa Hotel, Phuket, Thailand, December 2-4, 1997 p75-80</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/9912006v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9912006v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9912009v1</id>
    <updated>1999-12-15T11:02:22Z</updated>
    <published>1999-12-15T11:02:22Z</published>
    <title>Deduction over Mixed-Level Logic Representations for Text Passage
  Retrieval</title>
    <summary>  A system is described that uses a mixed-level representation of (part of)
meaning of natural language documents (based on standard Horn Clause Logic) and
a variable-depth search strategy that distinguishes between the different
levels of abstraction in the knowledge representation to locate specific
passages in the documents. Mixed-level representations as well as
variable-depth search strategies are applicable in fields outside that of NLP.
</summary>
    <author>
      <name>Michael Hess</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TAI.1996.560480</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TAI.1996.560480" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, Proceedings of the Eighth International Conference on Tools
  with Artificial Intelligence (TAI'96), Los Alamitos CA</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE Computer Society Press, 1996. 383-390</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/9912009v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9912009v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.1; I.2.3; I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9912016v1</id>
    <updated>1999-12-23T01:07:33Z</updated>
    <published>1999-12-23T01:07:33Z</published>
    <title>HMM Specialization with Selective Lexicalization</title>
    <summary>  We present a technique which complements Hidden Markov Models by
incorporating some lexicalized states representing syntactically uncommon
words. Our approach examines the distribution of transitions, selects the
uncommon words, and makes lexicalized states for the words. We performed a
part-of-speech tagging experiment on the Brown corpus to evaluate the resultant
language model and discovered that this technique improved the tagging accuracy
by 0.21% at the 95% level of confidence.
</summary>
    <author>
      <name>Jin-Dong Kim</name>
    </author>
    <author>
      <name>Sang-Zoo Lee</name>
    </author>
    <author>
      <name>Hae-Chang Rim</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 6 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 1999 Joint SIGDAT Conference on Empirical
  Methods in Natural Language Processing and Very Large Corpora, pp.121-127,
  1999</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/9912016v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9912016v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.6; I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9912017v1</id>
    <updated>1999-12-23T15:48:26Z</updated>
    <published>1999-12-23T15:48:26Z</published>
    <title>Mixed-Level Knowledge Representation and Variable-Depth Inference in
  Natural Language Processing</title>
    <summary>  A system is described that uses a mixed-level knowledge representation based
on standard Horn Clause Logic to represent (part of) the meaning of natural
language documents. A variable-depth search strategy is outlined that
distinguishes between the different levels of abstraction in the knowledge
representation to locate specific passages in the documents. A detailed
description of the linguistic aspects of the system is given. Mixed-level
representations as well as variable-depth search strategies are applicable in
fields outside that of NLP.
</summary>
    <author>
      <name>Michael Hess</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">29 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal on Artificial Intelligence Tools (IJAIT),
  vol 6, no 4, 1997. 481-509</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/9912017v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9912017v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.1; I.2.3; I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0001021v1</id>
    <updated>2000-01-24T20:55:17Z</updated>
    <published>2000-01-24T20:55:17Z</published>
    <title>Refinement of a Structured Language Model</title>
    <summary>  A new language model for speech recognition inspired by linguistic analysis
is presented. The model develops hidden hierarchical structure incrementally
and uses it to extract meaningful information from the word history - thus
enabling the use of extended distance dependencies - in an attempt to
complement the locality of currently used n-gram Markov models. The model, its
probabilistic parametrization, a reestimation algorithm for the model
parameters and a set of experiments meant to evaluate its potential for speech
recognition are presented.
</summary>
    <author>
      <name>Ciprian Chelba</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CLSP The Johns Hopkins University</arxiv:affiliation>
    </author>
    <author>
      <name>Frederick Jelinek</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CLSP The Johns Hopkins University</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the International Conference on Advances in Pattern
  Recognition, 1998, pp. 275-284, Plymouth, UK</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0001021v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0001021v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.3, I.2.7, I.5.1, I.5.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0001022v1</id>
    <updated>2000-01-24T21:18:37Z</updated>
    <published>2000-01-24T21:18:37Z</published>
    <title>Recognition Performance of a Structured Language Model</title>
    <summary>  A new language model for speech recognition inspired by linguistic analysis
is presented. The model develops hidden hierarchical structure incrementally
and uses it to extract meaningful information from the word history - thus
enabling the use of extended distance dependencies - in an attempt to
complement the locality of currently used trigram models. The structured
language model, its probabilistic parameterization and performance in a
two-pass speech recognizer are presented. Experiments on the SWITCHBOARD corpus
show an improvement in both perplexity and word error rate over conventional
trigram models.
</summary>
    <author>
      <name>Ciprian Chelba</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CLSP The Johns Hopkins University</arxiv:affiliation>
    </author>
    <author>
      <name>Frederick Jelinek</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CLSP The Johns Hopkins University</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of Eurospeech, 1999, pp. 1567-1570, Budapest, Hungary</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0001022v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0001022v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.3, I.2.7, I.5.1, I.5.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0001023v1</id>
    <updated>2000-01-25T19:35:01Z</updated>
    <published>2000-01-25T19:35:01Z</published>
    <title>Structured Language Modeling for Speech Recognition</title>
    <summary>  A new language model for speech recognition is presented. The model develops
hidden hierarchical syntactic-like structure incrementally and uses it to
extract meaningful information from the word history, thus complementing the
locality of currently used trigram models. The structured language model (SLM)
and its performance in a two-pass speech recognizer --- lattice decoding ---
are presented. Experiments on the WSJ corpus show an improvement in both
perplexity (PPL) and word error rate (WER) over conventional trigram models.
</summary>
    <author>
      <name>Ciprian Chelba</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CLSP, The Johns Hopkins University</arxiv:affiliation>
    </author>
    <author>
      <name>Frederick Jelinek</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CLSP, The Johns Hopkins University</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages + 2 pages of ERRATA</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of NLDB'99, Klagenfurt, Austria</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0001023v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0001023v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.3, I.2.7, I.5.1, I.5.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0003055v1</id>
    <updated>2000-03-13T09:55:08Z</updated>
    <published>2000-03-13T09:55:08Z</published>
    <title>TnT - A Statistical Part-of-Speech Tagger</title>
    <summary>  Trigrams'n'Tags (TnT) is an efficient statistical part-of-speech tagger.
Contrary to claims found elsewhere in the literature, we argue that a tagger
based on Markov models performs at least as well as other current approaches,
including the Maximum Entropy framework. A recent comparison has even shown
that TnT performs significantly better for the tested corpora. We describe the
basic model of TnT, the techniques used for smoothing and for handling unknown
words. Furthermore, we present evaluations on two corpora.
</summary>
    <author>
      <name>Thorsten Brants</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Saarland University, Germany</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of ANLP-2000, Seattle, WA</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0003055v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0003055v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0003060v1</id>
    <updated>2000-03-14T13:09:28Z</updated>
    <published>2000-03-14T13:09:28Z</published>
    <title>Message Classification in the Call Center</title>
    <summary>  Customer care in technical domains is increasingly based on e-mail
communication, allowing for the reproduction of approved solutions. Identifying
the customer's problem is often time-consuming, as the problem space changes if
new products are launched. This paper describes a new approach to the
classification of e-mail requests based on shallow text processing and machine
learning techniques. It is implemented within an assistance system for call
center agents that is used in a commercial setting.
</summary>
    <author>
      <name>Stephan Busemann</name>
    </author>
    <author>
      <name>Sven Schmeier</name>
    </author>
    <author>
      <name>Roman G. Arens</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages with 2 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of ANLP-2000, Seattle, WA</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0003060v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0003060v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.6; I.2.7; I.7.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0003074v1</id>
    <updated>2000-03-23T11:29:15Z</updated>
    <published>2000-03-23T11:29:15Z</published>
    <title>A Finite State and Data-Oriented Method for Grapheme to Phoneme
  Conversion</title>
    <summary>  A finite-state method, based on leftmost longest-match replacement, is
presented for segmenting words into graphemes, and for converting graphemes
into phonemes. A small set of hand-crafted conversion rules for Dutch achieves
a phoneme accuracy of over 93%. The accuracy of the system is further improved
by using transformation-based learning. The phoneme accuracy of the best system
(using a large set of rule templates and a `lazy' variant of Brill's algoritm),
trained on only 40K words, reaches 99% accuracy.
</summary>
    <author>
      <name>Gosse Bouma</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of NAACL-2000, Seattle, WA</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0003074v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0003074v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0003081v1</id>
    <updated>2000-03-29T16:35:58Z</updated>
    <published>2000-03-29T16:35:58Z</published>
    <title>Variable Word Rate N-grams</title>
    <summary>  The rate of occurrence of words is not uniform but varies from document to
document. Despite this observation, parameters for conventional n-gram language
models are usually derived using the assumption of a constant word rate. In
this paper we investigate the use of variable word rate assumption, modelled by
a Poisson distribution or a continuous mixture of Poissons. We present an
approach to estimating the relative frequencies of words or n-grams taking
prior information of their occurrences into account. Discounting and smoothing
schemes are also considered. Using the Broadcast News task, the approach
demonstrates a reduction of perplexity up to 10%.
</summary>
    <author>
      <name>Yoshihiko Gotoh</name>
    </author>
    <author>
      <name>Steve Renals</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 4 figures, ICASSP-2000</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0003081v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0003081v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0005006v1</id>
    <updated>2000-05-07T00:15:59Z</updated>
    <published>2000-05-07T00:15:59Z</published>
    <title>A Simple Approach to Building Ensembles of Naive Bayesian Classifiers
  for Word Sense Disambiguation</title>
    <summary>  This paper presents a corpus-based approach to word sense disambiguation that
builds an ensemble of Naive Bayesian classifiers, each of which is based on
lexical features that represent co--occurring words in varying sized windows of
context. Despite the simplicity of this approach, empirical results
disambiguating the widely studied nouns line and interest show that such an
ensemble achieves accuracy rivaling the best previously published results.
</summary>
    <author>
      <name>Ted Pedersen</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Minnesota Duluth</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, Latex, uses colnaacl.sty. Appears in Proceedings of NAACL,
  pages 63-69, May 2000, Seattle, WA</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0005006v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0005006v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0005015v1</id>
    <updated>2000-05-10T11:58:12Z</updated>
    <published>2000-05-10T11:58:12Z</published>
    <title>Noun Phrase Recognition by System Combination</title>
    <summary>  The performance of machine learning algorithms can be improved by combining
the output of different systems. In this paper we apply this idea to the
recognition of noun phrases.We generate different classifiers by using
different representations of the data. By combining the results with voting
techniques described in (Van Halteren et.al. 1998) we manage to improve the
best reported performances on standard data sets for base noun phrases and
arbitrary noun phrases.
</summary>
    <author>
      <name>Erik F. Tjong Kim Sang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of NAACL 2000, Seattle, WA, USA</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0005015v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0005015v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0005016v1</id>
    <updated>2000-05-10T14:51:14Z</updated>
    <published>2000-05-10T14:51:14Z</published>
    <title>Improving Testsuites via Instrumentation</title>
    <summary>  This paper explores the usefulness of a technique from software engineering,
namely code instrumentation, for the development of large-scale natural
language grammars. Information about the usage of grammar rules in test
sentences is used to detect untested rules, redundant test sentences, and
likely causes of overgeneration. Results show that less than half of a
large-coverage grammar for German is actually tested by two large testsuites,
and that 10-30% of testing time is redundant. The methodology applied can be
seen as a re-use of grammar writing knowledge for testsuite compilation.
</summary>
    <author>
      <name>Norbert Broeker</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, LaTeX2e</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. ANLP--NAACL, Seattle/WA, Apr29--May4 2000, pp.325-330</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0005016v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0005016v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.2.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0005020v1</id>
    <updated>2000-05-12T17:24:06Z</updated>
    <published>2000-05-12T17:24:06Z</published>
    <title>Centroid-based summarization of multiple documents: sentence extraction,
  utility-based evaluation, and user studies</title>
    <summary>  We present a multi-document summarizer, called MEAD, which generates
summaries using cluster centroids produced by a topic detection and tracking
system. We also describe two new techniques, based on sentence utility and
subsumption, which we have applied to the evaluation of both single and
multiple document summaries. Finally, we describe two user studies that test
our models of multi-document summarization.
</summary>
    <author>
      <name>Dragomir R. Radev</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Michigan</arxiv:affiliation>
    </author>
    <author>
      <name>Hongyan Jing</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Columbia University</arxiv:affiliation>
    </author>
    <author>
      <name>Malgorzata Budzikowska</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IBM TJ Watson Research Center</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages Corpus availability at http://perun.si.umich.edu/~radev/mds</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">NAACL/ANLP Workshop on Automatic Summarization, Seattle, WA, April
  30, 2000</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0005020v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0005020v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.1; H.3.4; H.3.7; H.5.2; I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0005025v1</id>
    <updated>2000-05-22T14:07:28Z</updated>
    <published>2000-05-22T14:07:28Z</published>
    <title>Finite-State Reduplication in One-Level Prosodic Morphology</title>
    <summary>  Reduplication, a central instance of prosodic morphology, is particularly
challenging for state-of-the-art computational morphology, since it involves
copying of some part of a phonological string. In this paper I advocate a
finite-state method that combines enriched lexical representations via
intersection to implement the copying. The proposal includes a
resource-conscious variant of automata and can benefit from the existence of
lazy algorithms. Finally, the implementation of a complex case from Koasati is
presented.
</summary>
    <author>
      <name>Markus Walther</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Marburg</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. NAACL-2000, Seattle/WA, pp.296-302</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0005025v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0005025v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0005029v1</id>
    <updated>2000-05-30T17:10:33Z</updated>
    <published>2000-05-30T17:10:33Z</published>
    <title>Ranking suspected answers to natural language questions using predictive
  annotation</title>
    <summary>  In this paper, we describe a system to rank suspected answers to natural
language questions. We process both corpus and query using a new technique,
predictive annotation, which augments phrases in texts with labels anticipating
their being targets of certain kinds of questions. Given a natural language
question, an IR system returns a set of matching passages, which are then
analyzed and ranked according to various criteria described in this paper. We
provide an evaluation of the techniques based on results from the TREC Q&amp;A
evaluation in which our system participated.
</summary>
    <author>
      <name>Dragomir R. Radev</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Michigan</arxiv:affiliation>
    </author>
    <author>
      <name>John Prager</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IBM TJ Watson Research Center</arxiv:affiliation>
    </author>
    <author>
      <name>Valerie Samn</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Teachers College, Columbia University</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ANLP'00, Seattle, WA, May 2000</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0005029v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0005029v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.1;H.3.3;H.3.4;H.5.2;I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0006003v1</id>
    <updated>2000-06-01T18:42:24Z</updated>
    <published>2000-06-01T18:42:24Z</published>
    <title>Exploiting Diversity in Natural Language Processing: Combining Parsers</title>
    <summary>  Three state-of-the-art statistical parsers are combined to produce more
accurate parses, as well as new bounds on achievable Treebank parsing accuracy.
Two general approaches are presented and two combination techniques are
described for each approach. Both parametric and non-parametric models are
explored. The resulting parsers surpass the best previously published
performance results for the Penn Treebank.
</summary>
    <author>
      <name>John C. Henderson</name>
    </author>
    <author>
      <name>Eric Brill</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the Fourth Conference on Empirical Methods in
  Natural Language Processing (EMNLP-99), pages 187-194. College Park,
  Maryland, USA. June, 1999</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0006003v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0006003v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0006011v1</id>
    <updated>2000-06-05T18:04:51Z</updated>
    <published>2000-06-05T18:04:51Z</published>
    <title>Bagging and Boosting a Treebank Parser</title>
    <summary>  Bagging and boosting, two effective machine learning techniques, are applied
to natural language parsing. Experiments using these techniques with a
trainable statistical parser are described. The best resulting system provides
roughly as large of a gain in F-measure as doubling the corpus size. Error
analysis of the result of the boosting technique reveals some inconsistent
annotations in the Penn Treebank, suggesting a semi-automatic method for
finding inconsistent treebank annotations.
</summary>
    <author>
      <name>John C. Henderson</name>
    </author>
    <author>
      <name>Eric Brill</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 1st Meeting of the North American Chapter of
  the Association for Computational Linguistics (NAACL-2000), pages 34-41</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0006011v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0006011v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0006019v1</id>
    <updated>2000-06-09T21:41:54Z</updated>
    <published>2000-06-09T21:41:54Z</published>
    <title>A Compact Architecture for Dialogue Management Based on Scripts and
  Meta-Outputs</title>
    <summary>  We describe an architecture for spoken dialogue interfaces to semi-autonomous
systems that transforms speech signals through successive representations of
linguistic, dialogue, and domain knowledge. Each step produces an output, and a
meta-output describing the transformation, with an executable program in a
simple scripting language as the final result. The output/meta-output
distinction permits perspicuous treatment of diverse tasks such as resolving
pronouns, correcting user misconceptions, and optimizing scripts.
</summary>
    <author>
      <name>Manny Rayner</name>
    </author>
    <author>
      <name>Beth Ann Hockey</name>
    </author>
    <author>
      <name>Frankie James</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Language Technology Joint Conference ANLP-NAACL 2000. 29 April - 4
  May 2000, Seattle, WA</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0006019v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0006019v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7; H.5.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0006021v1</id>
    <updated>2000-06-09T22:03:10Z</updated>
    <published>2000-06-09T22:03:10Z</published>
    <title>Compiling Language Models from a Linguistically Motivated Unification
  Grammar</title>
    <summary>  Systems now exist which are able to compile unification grammars into
language models that can be included in a speech recognizer, but it is so far
unclear whether non-trivial linguistically principled grammars can be used for
this purpose. We describe a series of experiments which investigate the
question empirically, by incrementally constructing a grammar and discovering
what problems emerge when successively larger versions are compiled into finite
state graph representations and used as language models for a medium-vocabulary
recognition task.
</summary>
    <author>
      <name>Manny Rayner</name>
    </author>
    <author>
      <name>Beth Ann Hockey</name>
    </author>
    <author>
      <name>Frankie James</name>
    </author>
    <author>
      <name>Elizabeth O. Bratt</name>
    </author>
    <author>
      <name>Sharon Goldwater</name>
    </author>
    <author>
      <name>Mark Gawron</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To be published in COLING 2000</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0006021v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0006021v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0006038v1</id>
    <updated>2000-06-28T10:06:02Z</updated>
    <published>2000-06-28T10:06:02Z</published>
    <title>Approximation and Exactness in Finite State Optimality Theory</title>
    <summary>  Previous work (Frank and Satta 1998; Karttunen, 1998) has shown that
Optimality Theory with gradient constraints generally is not finite state. A
new finite-state treatment of gradient constraints is presented which improves
upon the approximation of Karttunen (1998). The method turns out to be exact,
and very compact, for the syllabification analysis of Prince and Smolensky
(1993).
</summary>
    <author>
      <name>Dale Gerdemann</name>
    </author>
    <author>
      <name>Gertjan van Noord</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 1 figure, Finite-State Phonology : SIGPHON 2000, Fifth
  Meeting of the ACL Special Interest Group in Computational Phonology, COLING
  2000</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0006038v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0006038v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0006042v1</id>
    <updated>2000-06-29T09:17:45Z</updated>
    <published>2000-06-29T09:17:45Z</published>
    <title>Semantic Parsing based on Verbal Subcategorization</title>
    <summary>  The aim of this work is to explore new methodologies on Semantic Parsing for
unrestricted texts. Our approach follows the current trends in Information
Extraction (IE) and is based on the application of a verbal subcategorization
lexicon (LEXPIR) by means of complex pattern recognition techniques. LEXPIR is
framed on the theoretical model of the verbal subcategorization developed in
the Pirapides project.
</summary>
    <author>
      <name>Jordi Atserias</name>
    </author>
    <author>
      <name>Irene Castellon</name>
    </author>
    <author>
      <name>Montse Civit</name>
    </author>
    <author>
      <name>German Rigau</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, extended version of the paper. Spanish version of the paper
  also available from authors home page</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Conference on Intelligence text Processing and Computational
  Linguistics, CICLing 2000. pg 330-340</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0006042v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0006042v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7;I.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0006044v1</id>
    <updated>2000-06-30T13:22:33Z</updated>
    <published>2000-06-30T13:22:33Z</published>
    <title>Finite-State Non-Concatenative Morphotactics</title>
    <summary>  Finite-state morphology in the general tradition of the Two-Level and Xerox
implementations has proved very successful in the production of robust
morphological analyzer-generators, including many large-scale commercial
systems. However, it has long been recognized that these implementations have
serious limitations in handling non-concatenative phenomena. We describe a new
technique for constructing finite-state transducers that involves reapplying
the regular-expression compiler to its own output. Implemented in an algorithm
called compile-replace, this technique has proved useful for handling
non-concatenative phenomena; and we demonstrate it on Malay full-stem
reduplication and Arabic stem interdigitation.
</summary>
    <author>
      <name>Kenneth R. Beesley</name>
    </author>
    <author>
      <name>Lauri Karttunen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">SIGPHON-2000, Proceedings of the Fifth Workshop of the ACL Special
  Interest Group in Computational Phonology, p. 1-12. Aug. 6, 2000. Luxembourg</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0006044v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0006044v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="A0;F1.1;J5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0007009v1</id>
    <updated>2000-07-06T14:15:26Z</updated>
    <published>2000-07-06T14:15:26Z</published>
    <title>Incremental construction of minimal acyclic finite-state automata</title>
    <summary>  In this paper, we describe a new method for constructing minimal,
deterministic, acyclic finite-state automata from a set of strings. Traditional
methods consist of two phases: the first to construct a trie, the second one to
minimize it. Our approach is to construct a minimal automaton in a single phase
by adding new strings one by one and minimizing the resulting automaton
on-the-fly. We present a general algorithm as well as a specialization that
relies upon the lexicographical ordering of the input strings.
</summary>
    <author>
      <name>Jan Daciuk</name>
    </author>
    <author>
      <name>Stoyan Mihov</name>
    </author>
    <author>
      <name>Bruce Watson</name>
    </author>
    <author>
      <name>Richard Watson</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 7 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Computational Linguistics, Vol. 26, Number 1, March 2000</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0007009v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0007009v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0007018v1</id>
    <updated>2000-07-13T12:46:00Z</updated>
    <published>2000-07-13T12:46:00Z</published>
    <title>Bootstrapping a Tagged Corpus through Combination of Existing
  Heterogeneous Taggers</title>
    <summary>  This paper describes a new method, Combi-bootstrap, to exploit existing
taggers and lexical resources for the annotation of corpora with new tagsets.
Combi-bootstrap uses existing resources as features for a second level machine
learning module, that is trained to make the mapping to the new tagset on a
very small sample of annotated corpus material. Experiments show that
Combi-bootstrap: i) can integrate a wide variety of existing resources, and ii)
achieves much higher accuracy (up to 44.7 % error reduction) than both the best
single tagger and an ensemble tagger constructed out of the same small training
sample.
</summary>
    <author>
      <name>Jakub Zavrel</name>
    </author>
    <author>
      <name>Walter Daelemans</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 2nd International Conference on Language
  Resources and Evaluation (LREC 2000), pp. 17--20</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0007018v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0007018v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7; I.2.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0007031v2</id>
    <updated>2000-07-24T04:17:49Z</updated>
    <published>2000-07-21T06:07:31Z</published>
    <title>Parameter-free Model of Rank Polysemantic Distribution</title>
    <summary>  A model of rank polysemantic distribution with a minimal number of fitting
parameters is offered. In an ideal case a parameter-free description of the
dependence on the basis of one or several immediate features of the
distribution is possible.
</summary>
    <author>
      <name>Victor Kromer</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3 pages, no figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 4th conference of the International
  Quantitative Linguistics Association (QUALICO 2000). Prague, August 24-26,
  2000. P. 21-22.The full version (in Russian) is available in Web Journal
  FCCL. See URL http://fccl.ksu.ru/fcclpap.htm</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0007031v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0007031v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0007035v1</id>
    <updated>2000-07-25T17:20:47Z</updated>
    <published>2000-07-25T17:20:47Z</published>
    <title>Mapping WordNets Using Structural Information</title>
    <summary>  We present a robust approach for linking already existing lexical/semantic
hierarchies. We used a constraint satisfaction algorithm (relaxation labeling)
to select --among a set of candidates-- the node in a target taxonomy that
bests matches each node in a source taxonomy. In particular, we use it to map
the nominal part of WordNet 1.5 onto WordNet 1.6, with a very high precision
and a very low remaining ambiguity.
</summary>
    <author>
      <name>J. Daude</name>
    </author>
    <author>
      <name>L. Padro</name>
    </author>
    <author>
      <name>G. Rigau</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, uses epsfig. To appear in ACL'2000 proceedings</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">38th Anual Meeting of the Association for Computational
  Linguistics (ACL'2000). Hong Kong, October 2000.</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0007035v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0007035v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0008004v1</id>
    <updated>2000-08-08T22:42:51Z</updated>
    <published>2000-08-08T22:42:51Z</published>
    <title>Comparing two trainable grammatical relations finders</title>
    <summary>  Grammatical relationships (GRs) form an important level of natural language
processing, but different sets of GRs are useful for different purposes.
Therefore, one may often only have time to obtain a small training corpus with
the desired GR annotations. On such a small training corpus, we compare two
systems. They use different learning techniques, but we find that this
difference by itself only has a minor effect. A larger factor is that in
English, a different GR length measure appears better suited for finding simple
argument GRs than for finding modifier GRs. We also find that partitioning the
data may help memory-based learning.
</summary>
    <author>
      <name>Alexander Yeh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, uses colacl.sty</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">18th International Conference on Computational Linguistics (COLING
  2000), pages 1146-1150, Saarbruecken, Germany, July, 2000</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0008004v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0008004v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0008005v1</id>
    <updated>2000-08-08T23:52:02Z</updated>
    <published>2000-08-08T23:52:02Z</published>
    <title>More accurate tests for the statistical significance of result
  differences</title>
    <summary>  Statistical significance testing of differences in values of metrics like
recall, precision and balanced F-score is a necessary part of empirical natural
language processing. Unfortunately, we find in a set of experiments that many
commonly used tests often underestimate the significance and so are less likely
to detect differences that exist between different techniques. This
underestimation comes from an independence assumption that is often violated.
We point out some useful tests that do not make this assumption, including
computationally-intensive randomization tests.
</summary>
    <author>
      <name>Alexander Yeh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, uses colacl.sty</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">18th International Conference on Computational Linguistics (COLING
  2000), pages 947-953, Saarbruecken, Germany, July, 2000</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0008005v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0008005v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0008012v1</id>
    <updated>2000-08-17T13:13:42Z</updated>
    <published>2000-08-17T13:13:42Z</published>
    <title>Applying System Combination to Base Noun Phrase Identification</title>
    <summary>  We use seven machine learning algorithms for one task: identifying base noun
phrases. The results have been processed by different system combination
methods and all of these outperformed the best individual result. We have
applied the seven learners with the best combinator, a majority vote of the top
five systems, to a standard data set and managed to improve the best published
result for this data set.
</summary>
    <author>
      <name>Erik F. Tjong Kim Sang</name>
    </author>
    <author>
      <name>Walter Daelemans</name>
    </author>
    <author>
      <name>Herve Dejean</name>
    </author>
    <author>
      <name>Rob Koeling</name>
    </author>
    <author>
      <name>Yuval Krymolowski</name>
    </author>
    <author>
      <name>Vasin Punyakanok</name>
    </author>
    <author>
      <name>Dan Roth</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of COLING 2000, Saarbruecken, Germany</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0008012v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0008012v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0008017v1</id>
    <updated>2000-08-21T19:27:18Z</updated>
    <published>2000-08-21T19:27:18Z</published>
    <title>Efficient probabilistic top-down and left-corner parsing</title>
    <summary>  This paper examines efficient predictive broad-coverage parsing without
dynamic programming. In contrast to bottom-up methods, depth-first top-down
parsing produces partial parses that are fully connected trees spanning the
entire left context, from which any kind of non-local dependency or partial
semantic interpretation can in principle be read. We contrast two predictive
parsing approaches, top-down and left-corner parsing, and find both to be
viable. In addition, we find that enhancement with non-local information not
only improves parser accuracy, but also substantially improves the search
efficiency.
</summary>
    <author>
      <name>Brian Roark</name>
    </author>
    <author>
      <name>Mark Johnson</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 3 tables, 3 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 37th Annual Meeting of the Association for
  Computational Linguistics, 1999, pages 421-428</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0008017v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0008017v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0008021v1</id>
    <updated>2000-08-22T15:16:22Z</updated>
    <published>2000-08-22T15:16:22Z</published>
    <title>Compact non-left-recursive grammars using the selective left-corner
  transform and factoring</title>
    <summary>  The left-corner transform removes left-recursion from (probabilistic)
context-free grammars and unification grammars, permitting simple top-down
parsing techniques to be used. Unfortunately the grammars produced by the
standard left-corner transform are usually much larger than the original. The
selective left-corner transform described in this paper produces a transformed
grammar which simulates left-corner recognition of a user-specified set of the
original productions, and top-down recognition of the others. Combined with two
factorizations, it produces non-left-recursive grammars that are not much
larger than the original.
</summary>
    <author>
      <name>Mark Johnson</name>
    </author>
    <author>
      <name>Brian Roark</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 5 tables, 2 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 18th International Conference on Computational
  Linguistics (COLING), 2000, pages 355-361</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0008021v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0008021v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0008028v1</id>
    <updated>2000-08-25T17:23:07Z</updated>
    <published>2000-08-25T17:23:07Z</published>
    <title>Estimators for Stochastic ``Unification-Based'' Grammars</title>
    <summary>  Log-linear models provide a statistically sound framework for Stochastic
``Unification-Based'' Grammars (SUBGs) and stochastic versions of other kinds
of grammars. We describe two computationally-tractable ways of estimating the
parameters of such grammars from a training corpus of syntactic analyses, and
apply these to estimate a stochastic version of Lexical-Functional Grammar.
</summary>
    <author>
      <name>Mark Johnson</name>
    </author>
    <author>
      <name>Stuart Geman</name>
    </author>
    <author>
      <name>Stephen Canon</name>
    </author>
    <author>
      <name>Zhiyi Chi</name>
    </author>
    <author>
      <name>Stefan Riezler</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc 37th Annual Conference of the Association for Computational
  Linguistics, 1999, pages 535-541</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0008028v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0008028v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0008029v1</id>
    <updated>2000-08-25T17:31:53Z</updated>
    <published>2000-08-25T17:31:53Z</published>
    <title>Exploiting auxiliary distributions in stochastic unification-based
  grammars</title>
    <summary>  This paper describes a method for estimating conditional probability
distributions over the parses of ``unification-based'' grammars which can
utilize auxiliary distributions that are estimated by other means. We show how
this can be used to incorporate information about lexical selectional
preferences gathered from other sources into Stochastic ``Unification-based''
Grammars (SUBGs). While we apply this estimator to a Stochastic
Lexical-Functional Grammar, the method is general, and should be applicable to
stochastic versions of HPSGs, categorial grammars and transformational
grammars.
</summary>
    <author>
      <name>Mark Johnson</name>
    </author>
    <author>
      <name>Stefan Riezler</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc 1st NAACL, 2000, pages 154-161</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0008029v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0008029v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0008030v1</id>
    <updated>2000-08-28T08:10:14Z</updated>
    <published>2000-08-28T08:10:14Z</published>
    <title>Metonymy Interpretation Using X NO Y Examples</title>
    <summary>  We developed on example-based method of metonymy interpretation. One
advantages of this method is that a hand-built database of metonymy is not
necessary because it instead uses examples in the form ``Noun X no Noun Y (Noun
Y of Noun X).'' Another advantage is that we will be able to interpret
newly-coined metonymic sentences by using a new corpus. We experimented with
metonymy interpretation and obtained a precision rate of 66% when using this
method.
</summary>
    <author>
      <name>Masaki Murata</name>
    </author>
    <author>
      <name>Qing Ma</name>
    </author>
    <author>
      <name>Atsumu Yamamoto</name>
    </author>
    <author>
      <name>Hitoshi Isahara</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages. Computation and Language</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">SNLP2000, Chiang Mai, Thailand, May 10, 2000</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0008030v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0008030v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0008031v1</id>
    <updated>2000-08-28T08:17:18Z</updated>
    <published>2000-08-28T08:17:18Z</published>
    <title>Bunsetsu Identification Using Category-Exclusive Rules</title>
    <summary>  This paper describes two new bunsetsu identification methods using supervised
learning. Since Japanese syntactic analysis is usually done after bunsetsu
identification, bunsetsu identification is important for analyzing Japanese
sentences. In experiments comparing the four previously available
machine-learning methods (decision tree, maximum-entropy method, example-based
approach and decision list) and two new methods using category-exclusive rules,
the new method using the category-exclusive rules with the highest similarity
performed best.
</summary>
    <author>
      <name>Masaki Murata</name>
    </author>
    <author>
      <name>Kiyotaka Uchimoto</name>
    </author>
    <author>
      <name>Qing Ma</name>
    </author>
    <author>
      <name>Hitoshi Isahara</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages. Computation and Language</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">COLING'2000, Saarbrucken, Germany, August, 2000</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0008031v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0008031v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0008033v1</id>
    <updated>2000-08-28T19:51:32Z</updated>
    <published>2000-08-28T19:51:32Z</published>
    <title>Temporal Expressions in Japanese-to-English Machine Translation</title>
    <summary>  This paper describes in outline a method for translating Japanese temporal
expressions into English. We argue that temporal expressions form a special
subset of language that is best handled as a special module in machine
translation. The paper deals with problems of lexical idiosyncrasy as well as
the choice of articles and prepositions within temporal expressions. In
addition temporal expressions are considered as parts of larger structures, and
the question of whether to translate them as noun phrases or adverbials is
addressed.
</summary>
    <author>
      <name>Francis Bond</name>
    </author>
    <author>
      <name>Kentaro Ogura</name>
    </author>
    <author>
      <name>Hajime Uchino</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, slightly reformatted to avoid obscure style file</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Seventh International Conference on Theoretical and Methodological
  Issues in Machine Translation: TMI-97, Santa Fe, July 1997, pp 55--62</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0008033v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0008033v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0008034v1</id>
    <updated>2000-08-30T13:14:58Z</updated>
    <published>2000-08-30T13:14:58Z</published>
    <title>Lexicalized Stochastic Modeling of Constraint-Based Grammars using
  Log-Linear Measures and EM Training</title>
    <summary>  We present a new approach to stochastic modeling of constraint-based grammars
that is based on log-linear models and uses EM for estimation from unannotated
data. The techniques are applied to an LFG grammar for German. Evaluation on an
exact match task yields 86% precision for an ambiguity rate of 5.4, and 90%
precision on a subcat frame match for an ambiguity rate of 25. Experimental
comparison to training from a parsebank shows a 10% gain from EM training.
Also, a new class-based grammar lexicalization is presented, showing a 10% gain
over unlexicalized models.
</summary>
    <author>
      <name>Stefan Riezler</name>
    </author>
    <author>
      <name>Detlef Prescher</name>
    </author>
    <author>
      <name>Jonas Kuhn</name>
    </author>
    <author>
      <name>Mark Johnson</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, uses acl2000.sty</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 38th Annual Meeting of the ACL, 2000</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0008034v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0008034v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.6; I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0008035v1</id>
    <updated>2000-08-30T13:24:06Z</updated>
    <published>2000-08-30T13:24:06Z</published>
    <title>Using a Probabilistic Class-Based Lexicon for Lexical Ambiguity
  Resolution</title>
    <summary>  This paper presents the use of probabilistic class-based lexica for
disambiguation in target-word selection. Our method employs minimal but precise
contextual information for disambiguation. That is, only information provided
by the target-verb, enriched by the condensed information of a probabilistic
class-based lexicon, is used. Induction of classes and fine-tuning to verbal
arguments is done in an unsupervised manner by EM-based clustering techniques.
The method shows promising results in an evaluation on real-world translations.
</summary>
    <author>
      <name>Detlef Prescher</name>
    </author>
    <author>
      <name>Stefan Riezler</name>
    </author>
    <author>
      <name>Mats Rooth</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, uses colacl.sty</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 18th COLING, 2000</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0008035v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0008035v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.6, I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0009003v1</id>
    <updated>2000-09-08T15:48:53Z</updated>
    <published>2000-09-08T15:48:53Z</published>
    <title>Automatic Extraction of Subcategorization Frames for Czech</title>
    <summary>  We present some novel machine learning techniques for the identification of
subcategorization information for verbs in Czech. We compare three different
statistical techniques applied to this problem. We show how the learning
algorithm can be used to discover previously unknown subcategorization frames
from the Czech Prague Dependency Treebank. The algorithm can then be used to
label dependents of a verb in the Czech treebank as either arguments or
adjuncts. Using our techniques, we ar able to achieve 88% precision on unseen
parsed text.
</summary>
    <author>
      <name>Anoop Sarkar</name>
    </author>
    <author>
      <name>Daniel Zeman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages. Another version under the name "Learning Verb
  Subcategorization from Corpora: Counting Frame Subsets", authors: Zeman,
  Sarkar, in proceedings of LREC 2000, Athens, Greece</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 18th International Conference on Computational
  Linguistics (Coling 2000), Universit</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0009003v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0009003v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7, G.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0009011v1</id>
    <updated>2000-09-19T00:44:47Z</updated>
    <published>2000-09-19T00:44:47Z</published>
    <title>Anaphora Resolution in Japanese Sentences Using Surface Expressions and
  Examples</title>
    <summary>  Anaphora resolution is one of the major problems in natural language
processing. It is also one of the important tasks in machine translation and
man/machine dialogue. We solve the problem by using surface expressions and
examples. Surface expressions are the words in sentences which provide clues
for anaphora resolution. Examples are linguistic data which are actually used
in conversations and texts. The method using surface expressions and examples
is a practical method. This thesis handles almost all kinds of anaphora: i. The
referential property and number of a noun phrase ii. Noun phrase direct
anaphora iii. Noun phrase indirect anaphora iv. Pronoun anaphora v. Verb phrase
ellipsis
</summary>
    <author>
      <name>Masaki Murata</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">156 pages. Doctoral thesis in Kyoto University, December 1996,
  supervised by M. Nagao</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0009011v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0009011v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0009015v1</id>
    <updated>2000-09-20T13:23:17Z</updated>
    <published>2000-09-20T13:23:17Z</published>
    <title>A Tableaux Calculus for Ambiguous Quantification</title>
    <summary>  Coping with ambiguity has recently received a lot of attention in natural
language processing. Most work focuses on the semantic representation of
ambiguous expressions. In this paper we complement this work in two ways.
First, we provide an entailment relation for a language with ambiguous
expressions. Second, we give a sound and complete tableaux calculus for
reasoning with statements involving ambiguous quantification. The calculus
interleaves partial disambiguation steps with steps in a traditional deductive
process, so as to minimize and postpone branching in the proof process, and
thereby increases its efficiency.
</summary>
    <author>
      <name>Christof Monz</name>
    </author>
    <author>
      <name>Maarten de Rijke</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In: H. de Swart (editor). Automated Reasoning with Analytic Tableaux
  and Related Methods, Tableaux'98 LNAI 1397, Springer, 1998, pp. 232-246</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0009015v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0009015v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.4.1 I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0009017v1</id>
    <updated>2000-09-21T14:49:19Z</updated>
    <published>2000-09-21T14:49:19Z</published>
    <title>A Tableau Calculus for Pronoun Resolution</title>
    <summary>  We present a tableau calculus for reasoning in fragments of natural language.
We focus on the problem of pronoun resolution and the way in which it
complicates automated theorem proving for natural language processing. A method
for explicitly manipulating contextual information during deduction is
proposed, where pronouns are resolved against this context during deduction. As
a result, pronoun resolution and deduction can be interleaved in such a way
that pronouns are only resolved if this is licensed by a deduction rule; this
helps us to avoid the combinatorial complexity of total pronoun disambiguation.
</summary>
    <author>
      <name>Christof Monz</name>
    </author>
    <author>
      <name>Maarten de Rijke</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">In: N.V. Murray (ed.) Automated Reasoning with Analytic Tableaux
  and Related Methods. Lecture Notes in Artificial Intelligence 1617, Springer,
  1999, pages 247-262</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0009017v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0009017v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.4.1; I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0009018v1</id>
    <updated>2000-09-21T15:21:01Z</updated>
    <published>2000-09-21T15:21:01Z</published>
    <title>A Resolution Calculus for Dynamic Semantics</title>
    <summary>  This paper applies resolution theorem proving to natural language semantics.
The aim is to circumvent the computational complexity triggered by natural
language ambiguities like pronoun binding, by interleaving pronoun binding with
resolution deduction. Therefore disambiguation is only applied to expression
that actually occur during derivations.
</summary>
    <author>
      <name>Christof Monz</name>
    </author>
    <author>
      <name>Maarten de Rijke</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">In: J. Dix, L. Farinas del Cerro, and U. Furbach (eds.) Logics in
  Artificial Intelligence (JELIA'98). Lecture Notes in Artificial Intelligence
  1489, Springer, 1998, pp. 184-198</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0009018v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0009018v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.4.1; I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0009022v1</id>
    <updated>2000-09-22T15:02:26Z</updated>
    <published>2000-09-22T15:02:26Z</published>
    <title>A Comparison between Supervised Learning Algorithms for Word Sense
  Disambiguation</title>
    <summary>  This paper describes a set of comparative experiments, including cross-corpus
evaluation, between five alternative algorithms for supervised Word Sense
Disambiguation (WSD), namely Naive Bayes, Exemplar-based learning, SNoW,
Decision Lists, and Boosting. Two main conclusions can be drawn: 1) The
LazyBoosting algorithm outperforms the other four state-of-the-art algorithms
in terms of accuracy and ability to tune to new domains; 2) The domain
dependence of WSD systems seems very strong and suggests that some kind of
adaptation or tuning is required for cross-corpus application.
</summary>
    <author>
      <name>Gerard Escudero</name>
    </author>
    <author>
      <name>Lluis Marquez</name>
    </author>
    <author>
      <name>German Rigau</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 4th Conference on Computational Natural
  Language Learning, CoNLL'2000, pp. 31-36</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0009022v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0009022v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7;I.2.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0009025v1</id>
    <updated>2000-09-27T13:22:54Z</updated>
    <published>2000-09-27T13:22:54Z</published>
    <title>Parsing with the Shortest Derivation</title>
    <summary>  Common wisdom has it that the bias of stochastic grammars in favor of shorter
derivations of a sentence is harmful and should be redressed. We show that the
common wisdom is wrong for stochastic grammars that use elementary trees
instead of context-free rules, such as Stochastic Tree-Substitution Grammars
used by Data-Oriented Parsing models. For such grammars a non-probabilistic
metric based on the shortest derivation outperforms a probabilistic metric on
the ATIS and OVIS corpora, while it obtains very competitive results on the
Wall Street Journal corpus. This paper also contains the first published
experiments with DOP on the Wall Street Journal.
</summary>
    <author>
      <name>Rens Bod</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings COLING'2000, with a minor correction</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0009025v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0009025v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0009026v1</id>
    <updated>2000-09-27T13:38:31Z</updated>
    <published>2000-09-27T13:38:31Z</published>
    <title>An improved parser for data-oriented lexical-functional analysis</title>
    <summary>  We present an LFG-DOP parser which uses fragments from LFG-annotated
sentences to parse new sentences. Experiments with the Verbmobil and Homecentre
corpora show that (1) Viterbi n best search performs about 100 times faster
than Monte Carlo search while both achieve the same accuracy; (2) the DOP
hypothesis which states that parse accuracy increases with increasing fragment
size is confirmed for LFG-DOP; (3) LFG-DOP's relative frequency estimator
performs worse than a discounted frequency estimator; and (4) LFG-DOP
significantly outperforms Tree-DOP is evaluated on tree structures only.
</summary>
    <author>
      <name>Rens Bod</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings ACL'2000, Hong Kong</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0009026v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0009026v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0010014v1</id>
    <updated>2000-10-10T17:33:02Z</updated>
    <published>2000-10-10T17:33:02Z</published>
    <title>On a cepstrum-based speech detector robust to white noise</title>
    <summary>  We study effects of additive white noise on the cepstral representation of
speech signals. Distribution of each individual cepstrum coefficient of speech
is shown to depend strongly on noise and to overlap significantly with the
cepstrum distribution of noise. Based on these studies, we suggest a scalar
quantity, V, equal to the sum of weighted cepstral coefficients, which is able
to classify frames containing speech against noise-like frames. The
distributions of V for speech and noise frames are reasonably well separated
above SNR = 5 dB, demonstrating the feasibility of robust speech detector based
on V.
</summary>
    <author>
      <name>Sergei Skorik</name>
    </author>
    <author>
      <name>Frederic Berthommier</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages pdf format, requires Acrobat Reader v 4.0 or later</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0010014v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0010014v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7; I.2.1; I.2.10; H.5.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0010020v1</id>
    <updated>2000-10-11T22:30:09Z</updated>
    <published>2000-10-11T22:30:09Z</published>
    <title>Using existing systems to supplement small amounts of annotated
  grammatical relations training data</title>
    <summary>  Grammatical relationships (GRs) form an important level of natural language
processing, but different sets of GRs are useful for different purposes.
Therefore, one may often only have time to obtain a small training corpus with
the desired GR annotations. To boost the performance from using such a small
training corpus on a transformation rule learner, we use existing systems that
find related types of annotations.
</summary>
    <author>
      <name>Alexander Yeh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, uses acl2000.sty</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">38th Annual Meeting of the Association for Computational
  Linguistics (ACL-2000), pages 126-132, Hong Kong, October, 2000</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0010020v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0010020v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0010030v1</id>
    <updated>2000-10-23T15:14:02Z</updated>
    <published>2000-10-23T15:14:02Z</published>
    <title>Reduction of Intermediate Alphabets in Finite-State Transducer Cascades</title>
    <summary>  This article describes an algorithm for reducing the intermediate alphabets
in cascades of finite-state transducers (FSTs). Although the method modifies
the component FSTs, there is no change in the overall relation described by the
whole cascade. No additional information or special algorithm, that could
decelerate the processing of input, is required at runtime. Two examples from
Natural Language Processing are used to illustrate the effect of the algorithm
on the sizes of the FSTs and their alphabets. With some FSTs the number of arcs
and symbols shrank considerably.
</summary>
    <author>
      <name>Andre Kempe</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 7 figures, LaTeX (+ eps)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. TALN 2000, pp. 207-215, Lausanne, Switzerland. October 16-18</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0010030v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0010030v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.1.1; I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0011001v1</id>
    <updated>2000-11-02T09:02:12Z</updated>
    <published>2000-11-02T09:02:12Z</published>
    <title>Utilizing the World Wide Web as an Encyclopedia: Extracting Term
  Descriptions from Semi-Structured Texts</title>
    <summary>  In this paper, we propose a method to extract descriptions of technical terms
from Web pages in order to utilize the World Wide Web as an encyclopedia. We
use linguistic patterns and HTML text structures to extract text fragments
containing term descriptions. We also use a language model to discard
extraneous descriptions, and a clustering method to summarize resultant
descriptions. We show the effectiveness of our method by way of experiments.
</summary>
    <author>
      <name>Atsushi Fujii</name>
    </author>
    <author>
      <name>Tetsuya Ishikawa</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 2 Postscript figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 38th Annual Meeting of the Association for
  Computational Linguistics (ACL-2000), pp.488-495, Oct. 2000</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0011001v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0011001v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7; H.3.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0011002v1</id>
    <updated>2000-11-02T10:00:27Z</updated>
    <published>2000-11-02T10:00:27Z</published>
    <title>A Novelty-based Evaluation Method for Information Retrieval</title>
    <summary>  In information retrieval research, precision and recall have long been used
to evaluate IR systems. However, given that a number of retrieval systems
resembling one another are already available to the public, it is valuable to
retrieve novel relevant documents, i.e., documents that cannot be retrieved by
those existing systems. In view of this problem, we propose an evaluation
method that favors systems retrieving as many novel documents as possible. We
also used our method to evaluate systems that participated in the IREX
workshop.
</summary>
    <author>
      <name>Atsushi Fujii</name>
    </author>
    <author>
      <name>Tetsuya Ishikawa</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 2nd International Conference on Language
  Resources and Evaluation (LREC-2000), pp.1637-1641, Jun. 2000</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0011002v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0011002v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0011007v1</id>
    <updated>2000-11-06T13:56:42Z</updated>
    <published>2000-11-06T13:56:42Z</published>
    <title>Tree-gram Parsing: Lexical Dependencies and Structural Relations</title>
    <summary>  This paper explores the kinds of probabilistic relations that are important
in syntactic disambiguation. It proposes that two widely used kinds of
relations, lexical dependencies and structural relations, have complementary
disambiguation capabilities. It presents a new model based on structural
relations, the Tree-gram model, and reports experiments showing that structural
relations should benefit from enrichment by lexical dependencies.
</summary>
    <author>
      <name>Khalil Sima'an</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages. Appeared in Proceedings of the 38th Annual Meeting of the
  Association for Computational Linguistics (ACL'00), Hong Kong, China</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0011007v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0011007v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2; K.3.2; J.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0011020v2</id>
    <updated>2000-11-30T15:07:33Z</updated>
    <published>2000-11-16T17:40:10Z</published>
    <title>The Use of Instrumentation in Grammar Engineering</title>
    <summary>  This paper explores the usefulness of a technique from software engineering,
code instrumentation, for the development of large-scale natural language
grammars. Information about the usage of grammar rules in test and corpus
sentences is used to improve grammar and testsuite, as well as adapting a
grammar to a specific genre. Results show that less than half of a
large-coverage grammar for German is actually tested by two large testsuites,
and that 10--30% of testing time is redundant. This methodology applied can be
seen as a re-use of grammar writing knowledge for testsuite compilation.
</summary>
    <author>
      <name>Norbert Broeker</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, LaTeX2e, correction includes bibliography</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">adapted from COLING2000, Saarbruecken/FRG, July31--Aug4 2000,
  pp.118-124</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0011020v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0011020v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.2.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0011034v1</id>
    <updated>2000-11-22T15:35:46Z</updated>
    <published>2000-11-22T15:35:46Z</published>
    <title>Semantic interpretation of temporal information by abductive inference</title>
    <summary>  Besides temporal information explicitly available in verbs and adjuncts, the
temporal interpretation of a text also depends on general world knowledge and
default assumptions. We will present a theory for describing the relation
between, on the one hand, verbs, their tenses and adjuncts and, on the other,
the eventualities and periods of time they represent and their relative
temporal locations.
  The theory is formulated in logic and is a practical implementation of the
concepts described in Ness Schelkens et al. We will show how an abductive
resolution procedure can be used on this representation to extract temporal
information from texts.
</summary>
    <author>
      <name>Sven Verdoolaege</name>
    </author>
    <author>
      <name>Marc Denecker</name>
    </author>
    <author>
      <name>Ness Schelkens</name>
    </author>
    <author>
      <name>Danny De Schreye</name>
    </author>
    <author>
      <name>Frank Van Eynde</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0011034v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0011034v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.4; I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0102022v2</id>
    <updated>2001-02-23T03:27:18Z</updated>
    <published>2001-02-22T14:10:20Z</published>
    <title>Finite-State Phonology: Proceedings of the 5th Workshop of the ACL
  Special Interest Group in Computational Phonology (SIGPHON)</title>
    <summary>  Home page of the workshop proceedings, with pointers to the individually
archived papers. Includes front matter from the printed version of the
proceedings.
</summary>
    <author>
      <name>Jason Eisner</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Rochester</arxiv:affiliation>
    </author>
    <author>
      <name>Lauri Karttunen</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Xerox Research Centre Europe</arxiv:affiliation>
    </author>
    <author>
      <name>Alain Theriault</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Universite de Montreal</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">HTML page, Conference programme, short abstracts, links to papers,
  preface</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Jason Eisner, Lauri Karttunen and Alain Theriault (eds.),
  Finite-State Phonology: Proceedings of the 5th Workshop of the ACL Special
  Interest Group in Computational Phonology (SIGPHON). Luxembourg, August 2000</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0102022v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0102022v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0102026v1</id>
    <updated>2001-02-24T06:56:43Z</updated>
    <published>2001-02-24T06:56:43Z</published>
    <title>Mathematical Model of Word Length on the Basis of the Cebanov-Fucks
  Distribution with Uniform Parameter Distribution</title>
    <summary>  The data on 13 typologically different languages have been processed using a
two-parameter word length model, based on 1-displaced uniform Poisson
distribution. Statistical dependencies of the 2nd parameter on the 1st one are
revealed for the German texts and genre of letters.
</summary>
    <author>
      <name>Victor Kromer</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 1 table, 2 figures.Submitted to Conference on Informatics
  and Telecommunications, to be held in Sibirian State University of
  Telecommunications (Novosibirsk, Russia) in April, 2001</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Kromer V.W. Matematiceskaja model' dliny slova na osnove
  raspredelenija Cebanova-Fuksa s ravnomernym raspredeleniem parametra //
  Informatika i problemy telekommunikacij: Mezdunarodnaja naucno-techniceskaja
  konferencija (SibGUTI, 26-27 aprelja 2001 g.) Materialy konferencii. -
  Novosibirsk: Isd-vo SibGUTI, 2001. - S. 74-75.</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0102026v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0102026v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0103002v1</id>
    <updated>2001-03-02T00:20:01Z</updated>
    <published>2001-03-02T00:20:01Z</published>
    <title>Quantitative Neural Network Model of the Tip-of-the-Tongue Phenomenon
  Based on Synthesized Memory-Psycholinguistic-Metacognitive Approach</title>
    <summary>  A new three-stage computer artificial neural network model of the
tip-of-the-tongue phenomenon is proposed. Each word's node is build from some
interconnected learned auto-associative two-layer neural networks each of which
represents separate word's semantic, lexical, or phonological components. The
model synthesizes memory, psycholinguistic, and metamemory approaches, bridges
speech errors and naming chronometry research traditions, and can explain
quantitatively many tip-of-the-tongue effects.
</summary>
    <author>
      <name>Petro M. Gopych</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of The Second International Conference
  Internet-Education-Science-2000 (IES-2000): New Informational and Computer
  Technologies in Education and Science, held on October 10-12, 2000 in
  Vinnytsia, Ukraine, page 273</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0103002v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0103002v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0103026v1</id>
    <updated>2001-03-29T23:08:33Z</updated>
    <published>2001-03-29T23:08:33Z</published>
    <title>A Decision Tree of Bigrams is an Accurate Predictor of Word Sense</title>
    <summary>  This paper presents a corpus-based approach to word sense disambiguation
where a decision tree assigns a sense to an ambiguous word based on the bigrams
that occur nearby. This approach is evaluated using the sense-tagged corpora
from the 1998 SENSEVAL word sense disambiguation exercise. It is more accurate
than the average results reported for 30 of 36 words, and is more accurate than
the best results for 19 of 36 words.
</summary>
    <author>
      <name>Ted Pedersen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the Second Meeting of the North American Chapter of
  the Association for Computational Linguistics (NAACL-01), June 2-7, 2001,
  Pittsburgh, PA; 8 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0103026v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0103026v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0104010v1</id>
    <updated>2001-04-03T23:22:17Z</updated>
    <published>2001-04-03T23:22:17Z</published>
    <title>Type Arithmetics: Computation based on the theory of types</title>
    <summary>  The present paper shows meta-programming turn programming, which is rich
enough to express arbitrary arithmetic computations. We demonstrate a type
system that implements Peano arithmetics, slightly generalized to negative
numbers. Certain types in this system denote numerals. Arithmetic operations on
such types-numerals - addition, subtraction, and even division - are expressed
as type reduction rules executed by a compiler. A remarkable trait is that
division by zero becomes a type error - and reported as such by a compiler.
</summary>
    <author>
      <name>Oleg Kiselyov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">1 HTML page, 1 C++ source code file</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0104010v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0104010v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.3.3; F.4.2; D.3.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0104019v1</id>
    <updated>2001-04-27T22:50:31Z</updated>
    <published>2001-04-27T22:50:31Z</published>
    <title>Dynamic Nonlocal Language Modeling via Hierarchical Topic-Based
  Adaptation</title>
    <summary>  This paper presents a novel method of generating and applying hierarchical,
dynamic topic-based language models. It proposes and evaluates new cluster
generation, hierarchical smoothing and adaptive topic-probability estimation
techniques. These combined models help capture long-distance lexical
dependencies. Experiments on the Broadcast News corpus show significant
improvement in perplexity (10.5% overall and 33.5% on target vocabulary).
</summary>
    <author>
      <name>Radu Florian</name>
    </author>
    <author>
      <name>David Yarowsky</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 29 figures, presented at ACL99, College Park, Maryland</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 37th Annual Meeting of the ACL, pages 167-174,
  College Park, Maryland</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0104019v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0104019v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0105001v1</id>
    <updated>2001-05-02T05:29:27Z</updated>
    <published>2001-05-02T05:29:27Z</published>
    <title>Correction of Errors in a Modality Corpus Used for Machine Translation
  by Using Machine-learning Method</title>
    <summary>  We performed corpus correction on a modality corpus for machine translation
by using such machine-learning methods as the maximum-entropy method. We thus
constructed a high-quality modality corpus based on corpus correction. We
compared several kinds of methods for corpus correction in our experiments and
developed a good method for corpus correction.
</summary>
    <author>
      <name>Masaki Murata</name>
    </author>
    <author>
      <name>Masao Utiyama</name>
    </author>
    <author>
      <name>Kiyotaka Uchimoto</name>
    </author>
    <author>
      <name>Qing Ma</name>
    </author>
    <author>
      <name>Hitoshi Isahara</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages. Computation and Language. This paper is the English
  translation of our Japanese papar</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0105001v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0105001v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3; I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0105002v1</id>
    <updated>2001-05-02T07:49:14Z</updated>
    <published>2001-05-02T07:49:14Z</published>
    <title>Man [and Woman] vs. Machine: A Case Study in Base Noun Phrase Learning</title>
    <summary>  A great deal of work has been done demonstrating the ability of machine
learning algorithms to automatically extract linguistic knowledge from
annotated corpora. Very little work has gone into quantifying the difference in
ability at this task between a person and a machine. This paper is a first step
in that direction.
</summary>
    <author>
      <name>Eric Brill</name>
    </author>
    <author>
      <name>Grace Ngai</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 2 figures, presented at ACL 1999</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 37th Annual Meeting of the Association of
  Computational Linguistics, pages 65-72, College Park, MD, USA (1999)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0105002v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0105002v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0105003v1</id>
    <updated>2001-05-02T08:39:32Z</updated>
    <published>2001-05-02T08:39:32Z</published>
    <title>Rule Writing or Annotation: Cost-efficient Resource Usage for Base Noun
  Phrase Chunking</title>
    <summary>  This paper presents a comprehensive empirical comparison between two
approaches for developing a base noun phrase chunker: human rule writing and
active learning using interactive real-time human annotation. Several novel
variations on active learning are investigated, and underlying cost models for
cross-modal machine learning comparison are presented and explored. Results
show that it is more efficient and more successful by several measures to train
a system using active learning annotation rather than hand-crafted rule writing
at a comparable level of human labor investment.
</summary>
    <author>
      <name>Grace Ngai</name>
    </author>
    <author>
      <name>David Yarowsky</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 4 figures, appeared in ACL2000</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 38th Annual Meeting of the Association for
  Computational Linguistics, pages 117-125, Hong Kong (2000)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0105003v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0105003v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0105005v1</id>
    <updated>2001-05-04T08:55:02Z</updated>
    <published>2001-05-04T08:55:02Z</published>
    <title>A Complete WordNet1.5 to WordNet1.6 Mapping</title>
    <summary>  We describe a robust approach for linking already existing lexical/semantic
hierarchies. We use a constraint satisfaction algorithm (relaxation labelling)
to select --among a set of candidates-- the node in a target taxonomy that
bests matches each node in a source taxonomy. In this paper we present the
complete mapping of the nominal, verbal, adjectival and adverbial parts of
WordNet 1.5 onto WordNet 1.6.
</summary>
    <author>
      <name>J. Daudé</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">TALP Research Center, Universitat Politècnica de Catalunya</arxiv:affiliation>
    </author>
    <author>
      <name>L. Padró</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">TALP Research Center, Universitat Politècnica de Catalunya</arxiv:affiliation>
    </author>
    <author>
      <name>G. Rigau</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">TALP Research Center, Universitat Politècnica de Catalunya</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 5 figures. To appear in proceedings of NAACL'01 Workshop on
  WordNet and Other Lexical Resources</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0105005v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0105005v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0105012v1</id>
    <updated>2001-05-07T14:25:22Z</updated>
    <published>2001-05-07T14:25:22Z</published>
    <title>Joint and conditional estimation of tagging and parsing models</title>
    <summary>  This paper compares two different ways of estimating statistical language
models. Many statistical NLP tagging and parsing models are estimated by
maximizing the (joint) likelihood of the fully-observed training data. However,
since these applications only require the conditional probability
distributions, these distributions can in principle be learnt by maximizing the
conditional likelihood of the training data. Perhaps somewhat surprisingly,
models estimated by maximizing the joint were superior to models estimated by
maximizing the conditional, even though some of the latter models intuitively
had access to ``more information''.
</summary>
    <author>
      <name>Mark Johnson</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, Proceedings of the ACL 2001</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0105012v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0105012v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0105023v1</id>
    <updated>2001-05-14T09:05:45Z</updated>
    <published>2001-05-14T09:05:45Z</published>
    <title>Generating a 3D Simulation of a Car Accident from a Written Description
  in Natural Language: the CarSim System</title>
    <summary>  This paper describes a prototype system to visualize and animate 3D scenes
from car accident reports, written in French. The problem of generating such a
3D simulation can be divided into two subtasks: the linguistic analysis and the
virtual scene generation. As a means of communication between these two
modules, we first designed a template formalism to represent a written accident
report. The CarSim system first processes written reports, gathers relevant
information, and converts it into a formal description. Then, it creates the
corresponding 3D scene and animates the vehicles.
</summary>
    <author>
      <name>Sylvain Dupuy</name>
    </author>
    <author>
      <name>Arjan Egges</name>
    </author>
    <author>
      <name>Vincent Legendre</name>
    </author>
    <author>
      <name>Pierre Nugues</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, ACL 2001, Workshop on Temporal and Spatial Information
  Processing</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0105023v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0105023v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7; H.5.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0105037v1</id>
    <updated>2001-05-31T18:08:57Z</updated>
    <published>2001-05-31T18:08:57Z</published>
    <title>Integrating Prosodic and Lexical Cues for Automatic Topic Segmentation</title>
    <summary>  We present a probabilistic model that uses both prosodic and lexical cues for
the automatic segmentation of speech into topically coherent units. We propose
two methods for combining lexical and prosodic information using hidden Markov
models and decision trees. Lexical information is obtained from a speech
recognizer, and prosodic features are extracted automatically from speech
waveforms. We evaluate our approach on the Broadcast News corpus, using the
DARPA-TDT evaluation metrics. Results show that the prosodic model alone is
competitive with word-based segmentation methods. Furthermore, we achieve a
significant reduction in error by combining the prosodic and word-based
knowledge sources.
</summary>
    <author>
      <name>G. Tur</name>
    </author>
    <author>
      <name>D. Hakkani-Tur</name>
    </author>
    <author>
      <name>A. Stolcke</name>
    </author>
    <author>
      <name>E. Shriberg</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">27 pages, 8 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Computation Linguistics 27(1), 31-57, March 2001</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0105037v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0105037v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0106011v1</id>
    <updated>2001-06-07T15:47:31Z</updated>
    <published>2001-06-07T15:47:31Z</published>
    <title>Computational properties of environment-based disambiguation</title>
    <summary>  The standard pipeline approach to semantic processing, in which sentences are
morphologically and syntactically resolved to a single tree before they are
interpreted, is a poor fit for applications such as natural language
interfaces. This is because the environment information, in the form of the
objects and events in the application's run-time environment, cannot be used to
inform parsing decisions unless the input sentence is semantically analyzed,
but this does not occur until after parsing in the single-tree semantic
architecture. This paper describes the computational properties of an
alternative architecture, in which semantic analysis is performed on all
possible interpretations during parsing, in polynomial time.
</summary>
    <author>
      <name>William Schuler</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, published in Proceedings of the 39th Annual Meeting of the
  ACL 2001</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0106011v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0106011v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7; H.5.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0106015v1</id>
    <updated>2001-06-10T06:14:09Z</updated>
    <published>2001-06-10T06:14:09Z</published>
    <title>Organizing Encyclopedic Knowledge based on the Web and its Application
  to Question Answering</title>
    <summary>  We propose a method to generate large-scale encyclopedic knowledge, which is
valuable for much NLP research, based on the Web. We first search the Web for
pages containing a term in question. Then we use linguistic patterns and HTML
structures to extract text fragments describing the term. Finally, we organize
extracted term descriptions based on word senses and domains. In addition, we
apply an automatically generated encyclopedia to a question answering system
targeting the Japanese Information-Technology Engineers Examination.
</summary>
    <author>
      <name>Atsushi Fujii</name>
    </author>
    <author>
      <name>Tetsuya Ishikawa</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, Proceedings of the 39th Annual Meeting of the Association
  for Computational Linguistics (To appear)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 39th Annual Meeting of the Association for
  Computational Linguistics (ACL-EACL 2001), pp.196-203, July. 2001</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0106015v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0106015v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7; H.3.3; H.3.4; H.3.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0106016v1</id>
    <updated>2001-06-10T14:56:51Z</updated>
    <published>2001-06-10T14:56:51Z</published>
    <title>File mapping Rule-based DBMS and Natural Language Processing</title>
    <summary>  This paper describes the system of storage, extract and processing of
information structured similarly to the natural language. For recursive
inference the system uses the rules having the same representation, as the
data. The environment of storage of information is provided with the File
Mapping (SHM) mechanism of operating system. In the paper the main principles
of construction of dynamic data structure and language for record of the
inference rules are stated; the features of available implementation are
considered and the description of the application realizing semantic
information retrieval on the natural language is given.
</summary>
    <author>
      <name>Vjacheslav M. Novikov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0106016v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0106016v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.3.2; H.2.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0106040v1</id>
    <updated>2001-06-19T14:56:02Z</updated>
    <published>2001-06-19T14:56:02Z</published>
    <title>Stacking classifiers for anti-spam filtering of e-mail</title>
    <summary>  We evaluate empirically a scheme for combining classifiers, known as stacked
generalization, in the context of anti-spam filtering, a novel cost-sensitive
application of text categorization. Unsolicited commercial e-mail, or "spam",
floods mailboxes, causing frustration, wasting bandwidth, and exposing minors
to unsuitable content. Using a public corpus, we show that stacking can improve
the efficiency of automatically induced anti-spam filters, and that such
filters can be used in real-life applications.
</summary>
    <author>
      <name>G. Sakkis</name>
    </author>
    <author>
      <name>I. Androutsopoulos</name>
    </author>
    <author>
      <name>G. Paliouras</name>
    </author>
    <author>
      <name>V. Karkaletsis</name>
    </author>
    <author>
      <name>C. D. Spyropoulos</name>
    </author>
    <author>
      <name>P. Stamatopoulos</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of "Empirical Methods in Natural Language Processing"
  (EMNLP 2001), L. Lee and D. Harman (Eds.), pp. 44-50, Carnegie Mellon
  University, Pittsburgh, PA, 2001</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0106040v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0106040v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.4.3; I.2.6; I.2.7; I.5.4; K.4.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0106043v1</id>
    <updated>2001-06-20T14:16:17Z</updated>
    <published>2001-06-20T14:16:17Z</published>
    <title>Using the Distribution of Performance for Studying Statistical NLP
  Systems and Corpora</title>
    <summary>  Statistical NLP systems are frequently evaluated and compared on the basis of
their performances on a single split of training and test data. Results
obtained using a single split are, however, subject to sampling noise. In this
paper we argue in favour of reporting a distribution of performance figures,
obtained by resampling the training data, rather than a single number. The
additional information from distributions can be used to make statistically
quantified statements about differences across parameter settings, systems, and
corpora.
</summary>
    <author>
      <name>Yuval Krymolowski</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To be presented in ACL/EACL Workshop on Evaluation for Language and
  Dialogue Systems</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0106043v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0106043v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.3; I.2.6; I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0106047v1</id>
    <updated>2001-06-21T20:37:43Z</updated>
    <published>2001-06-21T20:37:43Z</published>
    <title>Modeling informational novelty in a conversational system with a hybrid
  statistical and grammar-based approach to natural language generation</title>
    <summary>  We present a hybrid statistical and grammar-based system for surface natural
language generation (NLG) that uses grammar rules, conditions on using those
grammar rules, and corpus statistics to determine the word order. We also
describe how this surface NLG module is implemented in a prototype
conversational system, and how it attempts to model informational novelty by
varying the word order. Using a combination of rules and statistical
information, the conversational system expresses the novel information
differently than the given information, based on the run-time dialog state. We
also discuss our plans for evaluating the generation strategy.
</summary>
    <author>
      <name>Adwait Ratnaparkhi</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the NAACL Workshop on Adaptation in Dialogue
  Systems, June 4, 2001, Pittsburgh, PA, USA</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0106047v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0106047v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0107005v1</id>
    <updated>2001-07-03T10:27:44Z</updated>
    <published>2001-07-03T10:27:44Z</published>
    <title>The Role of Conceptual Relations in Word Sense Disambiguation</title>
    <summary>  We explore many ways of using conceptual distance measures in Word Sense
Disambiguation, starting with the Agirre-Rigau conceptual density measure. We
use a generalized form of this measure, introducing many (parameterized)
refinements and performing an exhaustive evaluation of all meaningful
combinations. We finally obtain a 42% improvement over the original algorithm,
and show that measures of conceptual distance are not worse indicators for
sense disambiguation than measures based on word-coocurrence (exemplified by
the Lesk algorithm). Our results, however, reinforce the idea that only a
combination of different sources of knowledge might eventually lead to accurate
word sense disambiguation.
</summary>
    <author>
      <name>David Fernandez-Amoros</name>
    </author>
    <author>
      <name>Julio Gonzalo</name>
    </author>
    <author>
      <name>Felisa Verdejo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 3 figures, published in the proceedings of NLDB'01</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0107005v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0107005v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0107019v2</id>
    <updated>2001-07-16T23:21:34Z</updated>
    <published>2001-07-16T22:59:15Z</published>
    <title>Applying Natural Language Generation to Indicative Summarization</title>
    <summary>  The task of creating indicative summaries that help a searcher decide whether
to read a particular document is a difficult task. This paper examines the
indicative summarization task from a generation perspective, by first analyzing
its required content via published guidelines and corpus analysis. We show how
these summaries can be factored into a set of document features, and how an
implemented content planner uses the topicality document feature to create
indicative multidocument query-based summaries.
</summary>
    <author>
      <name>Min-Yen Kan</name>
    </author>
    <author>
      <name>Kathleen R. McKeown</name>
    </author>
    <author>
      <name>Judith L. Klavans</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, published in Proc. of 8th European Workshop on NLG</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0107019v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0107019v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0109010v2</id>
    <updated>2002-09-13T18:13:28Z</updated>
    <published>2001-09-09T16:41:59Z</published>
    <title>Anaphora and Discourse Structure</title>
    <summary>  We argue in this paper that many common adverbial phrases generally taken to
signal a discourse relation between syntactically connected units within
discourse structure, instead work anaphorically to contribute relational
meaning, with only indirect dependence on discourse structure. This allows a
simpler discourse structure to provide scaffolding for compositional semantics,
and reveals multiple ways in which the relational meaning conveyed by adverbial
connectives can interact with that associated with discourse structure. We
conclude by sketching out a lexicalised grammar for discourse that facilitates
discourse interpretation as a product of compositional rules, anaphor
resolution and inference.
</summary>
    <author>
      <name>Bonnie Webber</name>
    </author>
    <author>
      <name>Matthew Stone</name>
    </author>
    <author>
      <name>Aravind Joshi</name>
    </author>
    <author>
      <name>Alistair Knott</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">45 pages, 17 figures. Revised resubmission to Computational
  Linguistics</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0109010v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0109010v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0109013v1</id>
    <updated>2001-09-11T12:17:04Z</updated>
    <published>2001-09-11T12:17:04Z</published>
    <title>Conceptual Analysis of Lexical Taxonomies: The Case of WordNet Top-Level</title>
    <summary>  In this paper we propose an analysis and an upgrade of WordNet's top-level
synset taxonomy. We briefly review WordNet and identify its main semantic
limitations. Some principles from a forthcoming OntoClean methodology are
applied to the ontological analysis of WordNet. A revised top-level taxonomy is
proposed, which is meant to be more conceptually rigorous, cognitively
transparent, and efficiently exploitable in several applications.
</summary>
    <author>
      <name>Aldo Gangemi</name>
    </author>
    <author>
      <name>Nicola Guarino</name>
    </author>
    <author>
      <name>Alessandro Oltramari</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 2 figures, 2 tables, submitted to FOIS 2001</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0109013v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0109013v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H3.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0109015v1</id>
    <updated>2001-09-13T14:52:41Z</updated>
    <published>2001-09-13T14:52:41Z</published>
    <title>Boosting Trees for Anti-Spam Email Filtering</title>
    <summary>  This paper describes a set of comparative experiments for the problem of
automatically filtering unwanted electronic mail messages. Several variants of
the AdaBoost algorithm with confidence-rated predictions [Schapire &amp; Singer,
99] have been applied, which differ in the complexity of the base learners
considered. Two main conclusions can be drawn from our experiments: a) The
boosting-based methods clearly outperform the baseline learning algorithms
(Naive Bayes and Induction of Decision Trees) on the PU1 corpus, achieving very
high levels of the F1 measure; b) Increasing the complexity of the base
learners allows to obtain better ``high-precision'' classifiers, which is a
very important issue when misclassification costs are considered.
</summary>
    <author>
      <name>Xavier Carreras</name>
    </author>
    <author>
      <name>Lluis Marquez</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 13 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of RANLP-2001, pp. 58-64, Bulgaria, 2001</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0109015v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0109015v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7;I.5.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0109023v1</id>
    <updated>2001-09-17T14:41:14Z</updated>
    <published>2001-09-17T14:41:14Z</published>
    <title>Integrating Multiple Knowledge Sources for Robust Semantic Parsing</title>
    <summary>  This work explores a new robust approach for Semantic Parsing of unrestricted
texts. Our approach considers Semantic Parsing as a Consistent Labelling
Problem (CLP), allowing the integration of several knowledge types (syntactic
and semantic) obtained from different sources (linguistic and statistic). The
current implementation obtains 95% accuracy in model identification and 72% in
case-role filling.
</summary>
    <author>
      <name>Jordi Atserias</name>
    </author>
    <author>
      <name>Lluis Padro</name>
    </author>
    <author>
      <name>German Rigau</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of Euroconference on Recent Advances in Natural
  Language Processing (RANLP'01), p.8-14. Tzigov Chark, Bulgaria. Sept. 2001</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0109023v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0109023v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0109029v1</id>
    <updated>2001-09-18T14:00:27Z</updated>
    <published>2001-09-18T14:00:27Z</published>
    <title>Learning class-to-class selectional preferences</title>
    <summary>  Selectional preference learning methods have usually focused on word-to-class
relations, e.g., a verb selects as its subject a given nominal class. This
papers extends previous statistical models to class-to-class preferences, and
presents a model that learns selectional preferences for classes of verbs. The
motivation is twofold: different senses of a verb may have different
preferences, and some classes of verbs can share preferences. The model is
tested on a word sense disambiguation task which uses subject-verb and
object-verb relationships extracted from a small sense-disambiguated corpus.
</summary>
    <author>
      <name>E. Agirre</name>
    </author>
    <author>
      <name>D. Martinez</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the Workshop "Computational Natural Language
  Learning" (CoNLL-2001). In conjunction with ACL'2001/EACL'2001. Toulouse,
  France. 6-7th July 2001</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0109029v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0109029v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0109031v2</id>
    <updated>2001-09-19T10:41:58Z</updated>
    <published>2001-09-18T14:18:58Z</published>
    <title>Enriching WordNet concepts with topic signatures</title>
    <summary>  This paper explores the possibility of enriching the content of existing
ontologies. The overall goal is to overcome the lack of topical links among
concepts in WordNet. Each concept is to be associated to a topic signature,
i.e., a set of related words with associated weights. The signatures can be
automatically constructed from the WWW or from sense-tagged corpora. Both
approaches are compared and evaluated on a word sense disambiguation task. The
results show that it is possible to construct clean signatures from the WWW
using some filtering techniques.
</summary>
    <author>
      <name>Eneko Agirre</name>
    </author>
    <author>
      <name>Olatz Ansa</name>
    </author>
    <author>
      <name>Eduard Hovy</name>
    </author>
    <author>
      <name>David Martinez</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Author list corrected</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the NAACL workshop on WordNet and Other lexical
  Resources: Applications, Extensions and Customizations. Pittsburg, 2001</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0109031v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0109031v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0109039v1</id>
    <updated>2001-09-20T06:42:11Z</updated>
    <published>2001-09-20T06:42:11Z</published>
    <title>Testing for Mathematical Lineation in Jim Crace's "Quarantine" and T. S.
  Eliot's "Four Quartets"</title>
    <summary>  The mathematical distinction between prose and verse may be detected in
writings that are not apparently lineated, for example in T. S. Eliot's "Burnt
Norton", and Jim Crace's "Quarantine". In this paper we offer comments on
appropriate statistical methods for such work, and also on the nature of formal
innovation in these two texts. Additional remarks are made on the roots of
lineation as a metrical form, and on the prose-verse continuum.
</summary>
    <author>
      <name>John Constable</name>
    </author>
    <author>
      <name>Hideaki Aoyama</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages, 8 figures in LaTeX2e and EPS formats</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0109039v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0109039v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.1;I.2.7;I.5.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0110015v1</id>
    <updated>2001-10-03T18:34:36Z</updated>
    <published>2001-10-03T18:34:36Z</published>
    <title>Richer Syntactic Dependencies for Structured Language Modeling</title>
    <summary>  The paper investigates the use of richer syntactic dependencies in the
structured language model (SLM). We present two simple methods of enriching the
dependencies in the syntactic parse trees used for intializing the SLM. We
evaluate the impact of both methods on the perplexity (PPL) and
word-error-rate(WER, N-best rescoring) performance of the SLM. We show that the
new model achieves an improvement in PPL and WER over the baseline results
reported using the SLM on the UPenn Treebank and Wall Street Journal (WSJ)
corpora, respectively.
</summary>
    <author>
      <name>Ciprian Chelba</name>
    </author>
    <author>
      <name>Peng Xu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of ASRU 2001, 4 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0110015v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0110015v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7; G.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0110050v1</id>
    <updated>2001-10-24T11:01:08Z</updated>
    <published>2001-10-24T11:01:08Z</published>
    <title>What is the minimal set of fragments that achieves maximal parse
  accuracy?</title>
    <summary>  We aim at finding the minimal set of fragments which achieves maximal parse
accuracy in Data Oriented Parsing. Experiments with the Penn Wall Street
Journal treebank show that counts of almost arbitrary fragments within parse
trees are important, leading to improved parse accuracy over previous models
tested on this treebank (a precision of 90.8% and a recall of 90.6%). We
isolate some dependency relations which previous models neglect but which
contribute to higher parse accuracy.
</summary>
    <author>
      <name>Rens Bod</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings ACL'2001, Toulouse, France</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0110050v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0110050v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0110051v1</id>
    <updated>2001-10-24T11:30:50Z</updated>
    <published>2001-10-24T11:30:50Z</published>
    <title>Combining semantic and syntactic structure for language modeling</title>
    <summary>  Structured language models for speech recognition have been shown to remedy
the weaknesses of n-gram models. All current structured language models are,
however, limited in that they do not take into account dependencies between
non-headwords. We show that non-headword dependencies contribute to
significantly improved word error rate, and that a data-oriented parsing model
trained on semantically and syntactically annotated data can exploit these
dependencies. This paper also contains the first DOP model trained by means of
a maximum likelihood reestimation procedure, which solves some of the
theoretical shortcomings of previous DOP models.
</summary>
    <author>
      <name>Rens Bod</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings ICSLP'2000, Beijing, China</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0110051v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0110051v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0112003v1</id>
    <updated>2001-12-05T05:35:07Z</updated>
    <published>2001-12-05T05:35:07Z</published>
    <title>Using a Support-Vector Machine for Japanese-to-English Translation of
  Tense, Aspect, and Modality</title>
    <summary>  This paper describes experiments carried out using a variety of
machine-learning methods, including the k-nearest neighborhood method that was
used in a previous study, for the translation of tense, aspect, and modality.
It was found that the support-vector machine method was the most precise of all
the methods tested.
</summary>
    <author>
      <name>Masaki Murata</name>
    </author>
    <author>
      <name>Kiyotaka Uchimoto</name>
    </author>
    <author>
      <name>Qing Ma</name>
    </author>
    <author>
      <name>Hitoshi Isahara</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages. Computation and Language</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ACL Workshop, the Data-Driven Machine Translation, 2001</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0112003v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0112003v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3; I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0204005v1</id>
    <updated>2002-04-03T17:32:53Z</updated>
    <published>2002-04-03T17:32:53Z</published>
    <title>Creating Annotation Tools with the Annotation Graph Toolkit</title>
    <summary>  The Annotation Graph Toolkit is a collection of software supporting the
development of annotation tools based on the annotation graph model. The
toolkit includes application programming interfaces for manipulating annotation
graph data and for importing data from other formats. There are interfaces for
the scripting languages Tcl and Python, a database interface, specialized
graphical user interfaces for a variety of annotation tasks, and several sample
applications. This paper describes all the toolkit components for the benefit
of would-be application developers.
</summary>
    <author>
      <name>Kazuaki Maeda</name>
    </author>
    <author>
      <name>Steven Bird</name>
    </author>
    <author>
      <name>Xiaoyi Ma</name>
    </author>
    <author>
      <name>Haejoong Lee</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 12 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the Third International Conference on Language
  Resources and Evaluation, Paris: European Language Resources Association,
  2002</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0204005v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0204005v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.2.13; H.5.5; I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0204007v1</id>
    <updated>2002-04-03T18:55:01Z</updated>
    <published>2002-04-03T18:55:01Z</published>
    <title>An Integrated Framework for Treebanks and Multilayer Annotations</title>
    <summary>  Treebank formats and associated software tools are proliferating rapidly,
with little consideration for interoperability. We survey a wide variety of
treebank structures and operations, and show how they can be mapped onto the
annotation graph model, and leading to an integrated framework encompassing
tree and non-tree annotations alike. This development opens up new
possibilities for managing and exploiting multilayer annotations.
</summary>
    <author>
      <name>Scott Cotton</name>
    </author>
    <author>
      <name>Steven Bird</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the Third International Conference on Language
  Resources and Evaluation, Paris: European Language Resources Association,
  2002</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0204007v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0204007v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0204022v1</id>
    <updated>2002-04-10T15:37:26Z</updated>
    <published>2002-04-10T15:37:26Z</published>
    <title>Annotation Graphs and Servers and Multi-Modal Resources: Infrastructure
  for Interdisciplinary Education, Research and Development</title>
    <summary>  Annotation graphs and annotation servers offer infrastructure to support the
analysis of human language resources in the form of time-series data such as
text, audio and video. This paper outlines areas of common need among empirical
linguists and computational linguists. After reviewing examples of data and
tools used or under development for each of several areas, it proposes a common
framework for future tool development, data annotation and resource sharing
based upon annotation graphs and servers.
</summary>
    <author>
      <name>Christopher Cieri</name>
    </author>
    <author>
      <name>Steven Bird</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 6 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of ACL Workshop on Sharing Tools and Resources for
  Research and Education, Toulouse, July 2001, pp 23-30</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0204022v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0204022v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.2.4; H.5.3; H.5.5; I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0204023v1</id>
    <updated>2002-04-10T15:49:24Z</updated>
    <published>2002-04-10T15:49:24Z</published>
    <title>Computational Phonology</title>
    <summary>  Phonology, as it is practiced, is deeply computational. Phonological analysis
is data-intensive and the resulting models are nothing other than specialized
data structures and algorithms. In the past, phonological computation -
managing data and developing analyses - was done manually with pencil and
paper. Increasingly, with the proliferation of affordable computers, IPA fonts
and drawing software, phonologists are seeking to move their computation work
online. Computational Phonology provides the theoretical and technological
framework for this migration, building on methodologies and tools from
computational linguistics. This piece consists of an apology for computational
phonology, a history, and an overview of current research.
</summary>
    <author>
      <name>Steven Bird</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Oxford International Encyclopedia of Linguistics, 2nd Edition,
  2002</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0204023v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0204023v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7; J.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0204049v1</id>
    <updated>2002-04-24T14:48:31Z</updated>
    <published>2002-04-24T14:48:31Z</published>
    <title>Memory-Based Shallow Parsing</title>
    <summary>  We present memory-based learning approaches to shallow parsing and apply
these to five tasks: base noun phrase identification, arbitrary base phrase
recognition, clause detection, noun phrase parsing and full parsing. We use
feature selection techniques and system combination methods for improving the
performance of the memory-based learner. Our approach is evaluated on standard
data sets and the results are compared with that of other systems. This reveals
that our approach works well for base phrase identification while its
application towards recognizing embedded structures leaves some room for
improvement.
</summary>
    <author>
      <name>Erik F. Tjong Kim Sang</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Machine Learning Research, volume 2 (March), 2002, pp.
  559-594</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0204049v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0204049v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0205028v1</id>
    <updated>2002-05-17T12:51:00Z</updated>
    <published>2002-05-17T12:51:00Z</published>
    <title>NLTK: The Natural Language Toolkit</title>
    <summary>  NLTK, the Natural Language Toolkit, is a suite of open source program
modules, tutorials and problem sets, providing ready-to-use computational
linguistics courseware. NLTK covers symbolic and statistical natural language
processing, and is interfaced to annotated corpora. Students augment and
replace existing components, learn structured programming by example, and
manipulate sophisticated models from the outset.
</summary>
    <author>
      <name>Edward Loper</name>
    </author>
    <author>
      <name>Steven Bird</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 1 figure, Proceedings of the ACL Workshop on Effective Tools
  and Methodologies for Teaching Natural Language Processing and Computational
  Linguistics, Philadelphia, July 2002, Association for Computational
  Linguistics</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0205028v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0205028v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.2.6; I.2.7; J.5; K.3.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0205057v1</id>
    <updated>2002-05-21T14:37:22Z</updated>
    <published>2002-05-21T14:37:22Z</published>
    <title>Unsupervised Discovery of Morphemes</title>
    <summary>  We present two methods for unsupervised segmentation of words into
morpheme-like units. The model utilized is especially suited for languages with
a rich morphology, such as Finnish. The first method is based on the Minimum
Description Length (MDL) principle and works online. In the second method,
Maximum Likelihood (ML) optimization is used. The quality of the segmentations
is measured using an evaluation method that compares the segmentations produced
to an existing morphological analysis. Experiments on both Finnish and English
corpora show that the presented methods perform well compared to a current
state-of-the-art system.
</summary>
    <author>
      <name>Mathias Creutz</name>
    </author>
    <author>
      <name>Krista Lagus</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, to appear in Proceedings of Morphological and Phonological
  Learning Workshop of ACL'02</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0205057v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0205057v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0205069v1</id>
    <updated>2002-05-27T18:57:11Z</updated>
    <published>2002-05-27T18:57:11Z</published>
    <title>Machine Learning with Lexical Features: The Duluth Approach to
  Senseval-2</title>
    <summary>  This paper describes the sixteen Duluth entries in the Senseval-2 comparative
exercise among word sense disambiguation systems. There were eight pairs of
Duluth systems entered in the Spanish and English lexical sample tasks. These
are all based on standard machine learning algorithms that induce classifiers
from sense-tagged training text where the context in which ambiguous words
occur are represented by simple lexical features. These are highly portable,
robust methods that can serve as a foundation for more tailored approaches.
</summary>
    <author>
      <name>Ted Pedersen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in the Proceedings of SENSEVAL-2: Second International
  Workshop on Evaluating Word Sense Disambiguation Systems July 5-6, 2001,
  Toulouse, France</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0205069v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0205069v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0205070v1</id>
    <updated>2002-05-28T02:01:55Z</updated>
    <published>2002-05-28T02:01:55Z</published>
    <title>Thumbs up? Sentiment Classification using Machine Learning Techniques</title>
    <summary>  We consider the problem of classifying documents not by topic, but by overall
sentiment, e.g., determining whether a review is positive or negative. Using
movie reviews as data, we find that standard machine learning techniques
definitively outperform human-produced baselines. However, the three machine
learning methods we employed (Naive Bayes, maximum entropy classification, and
support vector machines) do not perform as well on sentiment classification as
on traditional topic-based categorization. We conclude by examining factors
that make the sentiment classification problem more challenging.
</summary>
    <author>
      <name>Bo Pang</name>
    </author>
    <author>
      <name>Lillian Lee</name>
    </author>
    <author>
      <name>Shivakumar Vaithyanathan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in EMNLP-2002</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0205070v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0205070v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7; I.2.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0205072v1</id>
    <updated>2002-05-29T17:48:48Z</updated>
    <published>2002-05-29T17:48:48Z</published>
    <title>Unsupervised Learning of Morphology without Morphemes</title>
    <summary>  The first morphological learner based upon the theory of Whole Word
Morphology Ford et al. (1997) is outlined, and preliminary evaluation results
are presented. The program, Whole Word Morphologizer, takes a POS-tagged
lexicon as input, induces morphological relationships without attempting to
discover or identify morphemes, and is then able to generate new words beyond
the learning sample. The accuracy (precision) of the generated new words is as
high as 80% using the pure Whole Word theory, and 92% after a post-hoc
adjustment is added to the routine.
</summary>
    <author>
      <name>Sylvain Neuvel</name>
    </author>
    <author>
      <name>Sean A. Fulop</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, to appear in Proceedings of the Workshop on Morphological
  and Phonological Learning 2002, ACL Publications</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0205072v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0205072v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0206026v1</id>
    <updated>2002-06-18T15:11:52Z</updated>
    <published>2002-06-18T15:11:52Z</published>
    <title>Interleaved semantic interpretation in environment-based parsing</title>
    <summary>  This paper extends a polynomial-time parsing algorithm that resolves
structural ambiguity in input to a speech-based user interface by calculating
and comparing the denotations of rival constituents, given some model of the
interfaced application environment (Schuler 2001). The algorithm is extended to
incorporate a full set of logical operators, including quantifiers and
conjunctions, into this calculation without increasing the complexity of the
overall algorithm beyond polynomial time, both in terms of the length of the
input and the number of entities in the environment model.
</summary>
    <author>
      <name>William Schuler</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 19th International Conference on Computational
  Linguistics (COLING 2002)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0206026v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0206026v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7; H.2.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0206034v1</id>
    <updated>2002-06-24T07:46:06Z</updated>
    <published>2002-06-24T07:46:06Z</published>
    <title>Applying a Hybrid Query Translation Method to Japanese/English
  Cross-Language Patent Retrieval</title>
    <summary>  This paper applies an existing query translation method to cross-language
patent retrieval. In our method, multiple dictionaries are used to derive all
possible translations for an input query, and collocational statistics are used
to resolve translation ambiguity. We used Japanese/English parallel patent
abstracts to perform comparative experiments, where our method outperformed a
simple dictionary-based query translation method, and achieved 76% of
monolingual retrieval in terms of average precision.
</summary>
    <author>
      <name>Masatoshi Fukui</name>
    </author>
    <author>
      <name>Shigeto Higuchi</name>
    </author>
    <author>
      <name>Youichi Nakatani</name>
    </author>
    <author>
      <name>Masao Tanaka</name>
    </author>
    <author>
      <name>Atsushi Fujii</name>
    </author>
    <author>
      <name>Tetsuya Ishikawa</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ACM SIGIR 2000 Workshop on Patent Retrieval, July, 2000</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0206034v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0206034v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3; I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0206035v1</id>
    <updated>2002-06-24T08:00:45Z</updated>
    <published>2002-06-24T08:00:45Z</published>
    <title>PRIME: A System for Multi-lingual Patent Retrieval</title>
    <summary>  Given the growing number of patents filed in multiple countries, users are
interested in retrieving patents across languages. We propose a multi-lingual
patent retrieval system, which translates a user query into the target
language, searches a multilingual database for patents relevant to the query,
and improves the browsing efficiency by way of machine translation and
clustering. Our system also extracts new translations from patent families
consisting of comparable patents, to enhance the translation dictionary.
</summary>
    <author>
      <name>Shigeto Higuchi</name>
    </author>
    <author>
      <name>Masatoshi Fukui</name>
    </author>
    <author>
      <name>Atsushi Fujii</name>
    </author>
    <author>
      <name>Tetsuya Ishikawa</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of MT Summit VIII, pp.163-167, Sep. 2001</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0206035v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0206035v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3; I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0206036v1</id>
    <updated>2002-06-24T08:38:36Z</updated>
    <published>2002-06-24T08:38:36Z</published>
    <title>Language Modeling for Multi-Domain Speech-Driven Text Retrieval</title>
    <summary>  We report experimental results associated with speech-driven text retrieval,
which facilitates retrieving information in multiple domains with spoken
queries. Since users speak contents related to a target collection, we produce
language models used for speech recognition based on the target collection, so
as to improve both the recognition and retrieval accuracy. Experiments using
existing test collections combined with dictated queries showed the
effectiveness of our method.
</summary>
    <author>
      <name>Katunobu Itou</name>
    </author>
    <author>
      <name>Atsushi Fujii</name>
    </author>
    <author>
      <name>Tetsuya Ishikawa</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/ASRU.2001.1034653</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/ASRU.2001.1034653" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE Automatic Speech Recognition and Understanding Workshop, Dec.
  2001</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0206036v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0206036v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7; H.3.3; H.5.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0206037v1</id>
    <updated>2002-06-24T10:28:02Z</updated>
    <published>2002-06-24T10:28:02Z</published>
    <title>Speech-Driven Text Retrieval: Using Target IR Collections for
  Statistical Language Model Adaptation in Speech Recognition</title>
    <summary>  Speech recognition has of late become a practical technology for real world
applications. Aiming at speech-driven text retrieval, which facilitates
retrieving information with spoken queries, we propose a method to integrate
speech recognition and retrieval methods. Since users speak contents related to
a target collection, we adapt statistical language models used for speech
recognition based on the target collection, so as to improve both the
recognition and retrieval accuracy. Experiments using existing test collections
combined with dictated queries showed the effectiveness of our method.
</summary>
    <author>
      <name>Atsushi Fujii</name>
    </author>
    <author>
      <name>Katunobu Itou</name>
    </author>
    <author>
      <name>Tetsuya Ishikawa</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Anni R. Coden and Eric W. Brown and Savitha Srinivasan (Eds.),
  Information Retrieval Techniques for Speech Applications (LNCS 2273),
  pp.94-104, Springer, 2002</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0206037v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0206037v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7; H.3.3; H.5.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0208020v1</id>
    <updated>2002-08-13T03:39:20Z</updated>
    <published>2002-08-13T03:39:20Z</published>
    <title>Using the DIFF Command for Natural Language Processing</title>
    <summary>  Diff is a software program that detects differences between two data sets and
is useful in natural language processing. This paper shows several examples of
the application of diff. They include the detection of differences between two
different datasets, extraction of rewriting rules, merging of two different
datasets, and the optimal matching of two different data sets. Since diff comes
with any standard UNIX system, it is readily available and very easy to use.
Our studies showed that diff is a practical tool for research into natural
language processing.
</summary>
    <author>
      <name>Masaki Murata</name>
    </author>
    <author>
      <name>Hitoshi Isahara</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages. Computation and Language. This paper is the rough English
  translation of our Japanese papar</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0208020v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0208020v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3; I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0208035v1</id>
    <updated>2002-08-21T14:09:48Z</updated>
    <published>2002-08-21T14:09:48Z</published>
    <title>Evaluation of Coreference Rules on Complex Narrative Texts</title>
    <summary>  This article studies the problem of assessing relevance to each of the rules
of a reference resolution system. The reference solver described here stems
from a formal model of reference and is integrated in a reference processing
workbench. Evaluation of the reference resolution is essential, as it enables
differential evaluation of individual rules. Numerical values of these measures
are given, and discussed, for simple selection rules and other processing
rules; such measures are then studied for numerical parameters.
</summary>
    <author>
      <name>Andrei Popescu-Belis</name>
    </author>
    <author>
      <name>Isabelle Robba</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of DAARC2 (Discourse Anaphora and Anaphor Resolution
  Colloquium), Lancaster, UK, 1998, p.178-185</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0208035v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0208035v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0208036v1</id>
    <updated>2002-08-21T14:28:51Z</updated>
    <published>2002-08-21T14:28:51Z</published>
    <title>Three New Methods for Evaluating Reference Resolution</title>
    <summary>  Reference resolution on extended texts (several thousand references) cannot
be evaluated manually. An evaluation algorithm has been proposed for the MUC
tests, using equivalence classes for the coreference relation. However, we show
here that this algorithm is too indulgent, yielding good scores even for poor
resolution strategies. We elaborate on the same formalism to propose two new
evaluation algorithms, comparing them first with the MUC algorithm and giving
then results on a variety of examples. A third algorithm using only
distributional comparison of equivalence classes is finally described; it
assesses the relative importance of the recall vs. precision errors.
</summary>
    <author>
      <name>Andrei Popescu-Belis</name>
    </author>
    <author>
      <name>Isabelle Robba</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the LREC'98 Workshop on Linguistic Coreference,
  Madrid, Spain, 1998</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0208036v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0208036v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0208038v1</id>
    <updated>2002-08-21T14:43:18Z</updated>
    <published>2002-08-21T14:43:18Z</published>
    <title>Reference Resolution Beyond Coreference: a Conceptual Frame and its
  Application</title>
    <summary>  A model for reference use in communication is proposed, from a
representationist point of view. Both the sender and the receiver of a message
handle representations of their common environment, including mental
representations of objects. Reference resolution by a computer is viewed as the
construction of object representations using referring expressions from the
discourse, whereas often only coreference links between such expressions are
looked for. Differences between these two approaches are discussed. The model
has been implemented with elementary rules, and tested on complex narrative
texts (hundreds to thousands of referring expressions). The results support the
mental representations paradigm.
</summary>
    <author>
      <name>Andrei Popescu-Belis</name>
    </author>
    <author>
      <name>Isabelle Robba</name>
    </author>
    <author>
      <name>Gerard Sabah</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of COLING-ACL'98, Montreal, Canada, 1998, p.1046-1052</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0208038v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0208038v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0211017v1</id>
    <updated>2002-11-14T16:16:44Z</updated>
    <published>2002-11-14T16:16:44Z</published>
    <title>Probabilistic Parsing Strategies</title>
    <summary>  We present new results on the relation between purely symbolic context-free
parsing strategies and their probabilistic counter-parts. Such parsing
strategies are seen as constructions of push-down devices from grammars. We
show that preservation of probability distribution is possible under two
conditions, viz. the correct-prefix property and the property of strong
predictiveness. These results generalize existing results in the literature
that were obtained by considering parsing strategies in isolation. From our
general results we also derive negative results on so-called generalized LR
parsing.
</summary>
    <author>
      <name>Mark-Jan Nederhof</name>
    </author>
    <author>
      <name>Giorgio Satta</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">36 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0211017v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0211017v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.4.3; I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0304006v1</id>
    <updated>2003-04-02T23:02:44Z</updated>
    <published>2003-04-02T23:02:44Z</published>
    <title>Learning to Paraphrase: An Unsupervised Approach Using Multiple-Sequence
  Alignment</title>
    <summary>  We address the text-to-text generation problem of sentence-level paraphrasing
-- a phenomenon distinct from and more difficult than word- or phrase-level
paraphrasing. Our approach applies multiple-sequence alignment to sentences
gathered from unannotated comparable corpora: it learns a set of paraphrasing
patterns represented by word lattice pairs and automatically determines how to
apply these patterns to rewrite new sentences. The results of our evaluation
experiments show that the system derives accurate paraphrases, outperforming
baseline systems.
</summary>
    <author>
      <name>Regina Barzilay</name>
    </author>
    <author>
      <name>Lillian Lee</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of HLT-NAACL 2003 (Human Language Technology Conference)</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0304006v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0304006v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0304027v1</id>
    <updated>2003-04-21T22:10:21Z</updated>
    <published>2003-04-21T22:10:21Z</published>
    <title>"I'm sorry Dave, I'm afraid I can't do that": Linguistics, Statistics,
  and Natural Language Processing circa 2001</title>
    <summary>  A brief, general-audience overview of the history of natural language
processing, focusing on data-driven approaches.Topics include "Ambiguity and
language analysis", "Firth things first", "A 'C' change", and "The empiricists
strike back".
</summary>
    <author>
      <name>Lillian Lee</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear, National Research Council study on the Fundamentals of
  Computer Science. 7 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">In "Computer Science: Reflections on the Field, Reflections from
  the Field" (report of the National Academies' Study on the Fundamentals of
  Computer Science), pp. 111--118, 2004</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0304027v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0304027v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0304029v1</id>
    <updated>2003-04-22T13:45:37Z</updated>
    <published>2003-04-22T13:45:37Z</published>
    <title>An XML based Document Suite</title>
    <summary>  We report about the current state of development of a document suite and its
applications. This collection of tools for the flexible and robust processing
of documents in German is based on the use of XML as unifying formalism for
encoding input and output data as well as process information. It is organized
in modules with limited responsibilities that can easily be combined into
pipelines to solve complex tasks. Strong emphasis is laid on a number of
techniques to deal with lexical and conceptual gaps that are typical when
starting a new application.
</summary>
    <author>
      <name>Dietmar Roesner</name>
    </author>
    <author>
      <name>Manuela Kunze</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of COLING 2002; p. 1278-1282</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0304029v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0304029v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7; H.3.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0304035v1</id>
    <updated>2003-04-23T08:02:53Z</updated>
    <published>2003-04-23T08:02:53Z</published>
    <title>Exploiting Sublanguage and Domain Characteristics in a Bootstrapping
  Approach to Lexicon and Ontology Creation</title>
    <summary>  It is very costly to build up lexical resources and domain ontologies.
Especially when confronted with a new application domain lexical gaps and a
poor coverage of domain concepts are a problem for the successful exploitation
of natural language document analysis systems that need and exploit such
knowledge sources. In this paper we report about ongoing experiments with
`bootstrapping techniques' for lexicon and ontology creation.
</summary>
    <author>
      <name>Dietmar Roesner</name>
    </author>
    <author>
      <name>Manuela Kunze</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Workshop-Proceedings of the OntoLex 2002 - Ontologies and Lexical
  Knowledge Bases at the LREC 2002, p. 68-73</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0304035v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0304035v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.1; I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0306022v1</id>
    <updated>2003-06-04T23:08:03Z</updated>
    <published>2003-06-04T23:08:03Z</published>
    <title>Techniques for effective vocabulary selection</title>
    <summary>  The vocabulary of a continuous speech recognition (CSR) system is a
significant factor in determining its performance. In this paper, we present
three principled approaches to select the target vocabulary for a particular
domain by trading off between the target out-of-vocabulary (OOV) rate and
vocabulary size. We evaluate these approaches against an ad-hoc baseline
strategy. Results are presented in the form of OOV rate graphs plotted against
increasing vocabulary size for each technique.
</summary>
    <author>
      <name>Anand Venkataraman</name>
    </author>
    <author>
      <name>Wen Wang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages. To appear Proc. Eurospeech 2003, Geneva</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0306022v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0306022v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.6;I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0306039v1</id>
    <updated>2003-06-10T04:40:45Z</updated>
    <published>2003-06-10T04:40:45Z</published>
    <title>Bayesian Information Extraction Network</title>
    <summary>  Dynamic Bayesian networks (DBNs) offer an elegant way to integrate various
aspects of language in one model. Many existing algorithms developed for
learning and inference in DBNs are applicable to probabilistic language
modeling. To demonstrate the potential of DBNs for natural language processing,
we employ a DBN in an information extraction task. We show how to assemble
wealth of emerging linguistic instruments for shallow parsing, syntactic and
semantic tagging, morphological decomposition, named entity recognition etc. in
order to incrementally build a robust information extraction system. Our method
outperforms previously published results on an established benchmark domain.
</summary>
    <author>
      <name>Leonid Peshkin</name>
    </author>
    <author>
      <name>Avi Pfeffer</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Intl. Joint Conference on Artificial Intelligence, 2003</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0306039v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0306039v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="C.1.3; I.5.1; I.7.2; I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0306062v1</id>
    <updated>2003-06-13T09:05:10Z</updated>
    <published>2003-06-13T09:05:10Z</published>
    <title>Learning to Order Facts for Discourse Planning in Natural Language
  Generation</title>
    <summary>  This paper presents a machine learning approach to discourse planning in
natural language generation. More specifically, we address the problem of
learning the most natural ordering of facts in discourse plans for a specific
domain. We discuss our methodology and how it was instantiated using two
different machine learning algorithms. A quantitative evaluation performed in
the domain of museum exhibit descriptions indicates that our approach performs
significantly better than manually constructed ordering rules. Being
retrainable, the resulting planners can be ported easily to other similar
domains, without requiring language technology expertise.
</summary>
    <author>
      <name>Aggeliki Dimitromanolaki</name>
    </author>
    <author>
      <name>Ion Androutsopoulos</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 4 figures, 1 table</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of EACL 2003 Workshop on Natural Language Generation</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0306062v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0306062v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0307028v1</id>
    <updated>2003-07-11T14:43:51Z</updated>
    <published>2003-07-11T14:43:51Z</published>
    <title>Issues in Communication Game</title>
    <summary>  As interaction between autonomous agents, communication can be analyzed in
game-theoretic terms. Meaning game is proposed to formalize the core of
intended communication in which the sender sends a message and the receiver
attempts to infer its meaning intended by the sender. Basic issues involved in
the game of natural language communication are discussed, such as salience,
grammaticality, common sense, and common belief, together with some
demonstration of the feasibility of game-theoretic account of language.
</summary>
    <author>
      <name>Koiti Hasida</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 5 figures, Proceedings of the 16th International Conference
  on Computational Linguistics, pp.531-536</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0307028v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0307028v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.5; I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0309019v1</id>
    <updated>2003-09-12T12:43:00Z</updated>
    <published>2003-09-12T12:43:00Z</published>
    <title>Building a Test Collection for Speech-Driven Web Retrieval</title>
    <summary>  This paper describes a test collection (benchmark data) for retrieval systems
driven by spoken queries. This collection was produced in the subtask of the
NTCIR-3 Web retrieval task, which was performed in a TREC-style evaluation
workshop. The search topics and document collection for the Web retrieval task
were used to produce spoken queries and language models for speech recognition,
respectively. We used this collection to evaluate the performance of our
retrieval system. Experimental results showed that (a) the use of target
documents for language modeling and (b) enhancement of the vocabulary size in
speech recognition were effective in improving the system performance.
</summary>
    <author>
      <name>Atsushi Fujii</name>
    </author>
    <author>
      <name>Katunobu Itou</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 8th European Conference on Speech Communication
  and Technology (Eurospeech 2003), pp.1153-1156, Sep. 2003</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0309019v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0309019v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7; H.3.3; H.5.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0310041v1</id>
    <updated>2003-10-21T18:19:52Z</updated>
    <published>2003-10-21T18:19:52Z</published>
    <title>A Dynamic Programming Algorithm for the Segmentation of Greek Texts</title>
    <summary>  In this paper we introduce a dynamic programming algorithm to perform linear
text segmentation by global minimization of a segmentation cost function which
consists of: (a) within-segment word similarity and (b) prior information about
segment length. The evaluation of the segmentation accuracy of the algorithm on
a text collection consisting of Greek texts showed that the algorithm achieves
high segmentation accuracy and appears to be very innovating and promissing.
</summary>
    <author>
      <name>Pavlina Fragkou</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper will appear in the Proceedings of the CONSOLE XII
  Conference (Patras, Greece, 2003)</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0310041v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0310041v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.1; H.3.3; H.3.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0310058v1</id>
    <updated>2003-10-29T20:13:30Z</updated>
    <published>2003-10-29T20:13:30Z</published>
    <title>Application Architecture for Spoken Language Resources in Organisational
  Settings</title>
    <summary>  Special technologies need to be used to take advantage of, and overcome, the
challenges associated with acquiring, transforming, storing, processing, and
distributing spoken language resources in organisations. This paper introduces
an application architecture consisting of tools and supporting utilities for
indexing and transcription, and describes how these tools, together with
downstream processing and distribution systems, can be integrated into a
workflow. Two sample applications for this architecture are outlined- the
analysis of decision-making processes in organisations and the deployment of
systems development methods by designers in the field.
</summary>
    <author>
      <name>Rodney J. Clarke</name>
    </author>
    <author>
      <name>Dali Dong</name>
    </author>
    <author>
      <name>Philip C. Windridge</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0310058v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0310058v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0312050v1</id>
    <updated>2003-12-22T16:23:34Z</updated>
    <published>2003-12-22T16:23:34Z</published>
    <title>A Flexible Pragmatics-driven Language Generator for Animated Agents</title>
    <summary>  This paper describes the NECA MNLG; a fully implemented Multimodal Natural
Language Generation module. The MNLG is deployed as part of the NECA system
which generates dialogues between animated agents. The generation module
supports the seamless integration of full grammar rules, templates and canned
text. The generator takes input which allows for the specification of
syntactic, semantic and pragmatic constraints on the output.
</summary>
    <author>
      <name>Paul Piwek</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the Research Note Sessions of the 10th Conference
  of the European Chapter of the Association for Computational Linguistics
  (EACL'03), 2003, pp. 151-154</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0312050v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0312050v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0312052v1</id>
    <updated>2003-12-22T17:07:31Z</updated>
    <published>2003-12-22T17:07:31Z</published>
    <title>Dialogue as Discourse: Controlling Global Properties of Scripted
  Dialogue</title>
    <summary>  This paper explains why scripted dialogue shares some crucial properties with
discourse. In particular, when scripted dialogues are generated by a Natural
Language Generation system, the generator can apply revision strategies that
cannot normally be used when the dialogue results from an interaction between
autonomous agents (i.e., when the dialogue is not scripted). The paper explains
that the relevant revision operators are best applied at the level of a
dialogue plan and discusses how the generator may decide when to apply a given
revision operator.
</summary>
    <author>
      <name>Paul Piwek</name>
    </author>
    <author>
      <name>Kees van Deemter</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of AAAI Spring Symposium on Natural Language
  Generation in Spoken and Written Dialogue, Stanford, 2003</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0312052v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0312052v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0312058v1</id>
    <updated>2003-12-25T16:45:20Z</updated>
    <published>2003-12-25T16:45:20Z</published>
    <title>Acquiring Lexical Paraphrases from a Single Corpus</title>
    <summary>  This paper studies the potential of identifying lexical paraphrases within a
single corpus, focusing on the extraction of verb paraphrases. Most previous
approaches detect individual paraphrase instances within a pair (or set) of
comparable corpora, each of them containing roughly the same information, and
rely on the substantial level of correspondence of such corpora. We present a
novel method that successfully detects isolated paraphrase instances within a
single corpus without relying on any a-priori structure and information. A
comparison suggests that an instance-based approach may be combined with a
vector based approach in order to assess better the paraphrase likelihood for
many verb pairs.
</summary>
    <author>
      <name>Oren Glickman</name>
    </author>
    <author>
      <name>Ido Dagan</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0312058v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0312058v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0312060v1</id>
    <updated>2003-12-27T21:21:48Z</updated>
    <published>2003-12-27T21:21:48Z</published>
    <title>Part-of-Speech Tagging with Minimal Lexicalization</title>
    <summary>  We use a Dynamic Bayesian Network to represent compactly a variety of
sublexical and contextual features relevant to Part-of-Speech (PoS) tagging.
The outcome is a flexible tagger (LegoTag) with state-of-the-art performance
(3.6% error on a benchmark corpus). We explore the effect of eliminating
redundancy and radically reducing the size of feature vocabularies. We find
that a small but linguistically motivated set of suffixes results in improved
cross-corpora generalization. We also show that a minimal lexicon limited to
function words is sufficient to ensure reasonable performance.
</summary>
    <author>
      <name>Virginia Savova</name>
    </author>
    <author>
      <name>Leonid Peshkin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages text; 1 figure. To appear in "Current Issues in Linguistic
  Theory: Recent Advances in Natural Language Processing";John Benjamins
  Publishers, Amsterdam</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0312060v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0312060v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0402055v1</id>
    <updated>2004-02-24T09:34:16Z</updated>
    <published>2004-02-24T09:34:16Z</published>
    <title>Lexical Base as a Compressed Language Model of the World (on the
  material of the Ukrainian language)</title>
    <summary>  In the article the fact is verified that the list of words selected by formal
statistical methods (frequency and functional genre unrestrictedness) is not a
conglomerate of non-related words. It creates a system of interrelated items
and it can be named "lexical base of language". This selected list of words
covers all the spheres of human activities. To verify this statement the
invariant synoptical scheme common for ideographic dictionaries of different
language was determined.
</summary>
    <author>
      <name>Solomiya Buk</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.2478/v10057-009-0008-3</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.2478/v10057-009-0008-3" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 2 tables</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Psychology of Language and Communication. 2009, vol. 13, no. 2,
  pp. 35-44</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0402055v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0402055v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0403039v1</id>
    <updated>2004-03-23T21:06:11Z</updated>
    <published>2004-03-23T21:06:11Z</published>
    <title>A Flexible Rule Compiler for Speech Synthesis</title>
    <summary>  We present a flexible rule compiler developed for a text-to-speech (TTS)
system. The compiler converts a set of rules into a finite-state transducer
(FST). The input and output of the FST are subject to parameterization, so that
the system can be applied to strings and sequences of feature-structures. The
resulting transducer is guaranteed to realize a function (as opposed to a
relation), and therefore can be implemented as a deterministic device (either a
deterministic FST or a bimachine).
</summary>
    <author>
      <name>Wojciech Skut</name>
    </author>
    <author>
      <name>Stefan Ulrich</name>
    </author>
    <author>
      <name>Kathrine Hammervold</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 6 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">In: Klopotek, Mieczyslaw A.; Wierzchon, Slawomir T.; Trojanowski,
  Krzysztof (Eds.): "Intelligent Information Processing and Web Mining -
  Proceedings of the International IIS:IIPWM?04 Conference"; Springer Verlag,
  2004</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0403039v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0403039v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.2; F.4.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0404007v1</id>
    <updated>2004-04-05T02:14:50Z</updated>
    <published>2004-04-05T02:14:50Z</published>
    <title>Polarity sensitivity and evaluation order in type-logical grammar</title>
    <summary>  We present a novel, type-logical analysis of_polarity sensitivity_: how
negative polarity items (like "any" and "ever") or positive ones (like "some")
are licensed or prohibited. It takes not just scopal relations but also linear
order into account, using the programming-language notions of delimited
continuations and evaluation order, respectively. It thus achieves greater
empirical coverage than previous proposals.
</summary>
    <author>
      <name>Chung-chieh Shan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 2004 Human Language Technology Conference of
  the North American Chapter of the Association for Computational Linguistics</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0404007v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0404007v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.5; D.3.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0404025v1</id>
    <updated>2004-04-10T08:43:31Z</updated>
    <published>2004-04-10T08:43:31Z</published>
    <title>Test Collections for Patent-to-Patent Retrieval and Patent Map
  Generation in NTCIR-4 Workshop</title>
    <summary>  This paper describes the Patent Retrieval Task in the Fourth NTCIR Workshop,
and the test collections produced in this task. We perform the invalidity
search task, in which each participant group searches a patent collection for
the patents that can invalidate the demand in an existing claim. We also
perform the automatic patent map generation task, in which the patents
associated with a specific topic are organized in a multi-dimensional matrix.
</summary>
    <author>
      <name>Atsushi Fujii</name>
    </author>
    <author>
      <name>Makoto Iwayama</name>
    </author>
    <author>
      <name>Noriko Kando</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, Proceedings of the 4th International Conference on Language
  Resources and Evaluation (to appear)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 4th International Conference on Language
  Resources and Evaluation (LREC-2004), pp.1643-1646, May. 2004.</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0404025v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0404025v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3; H.3.4; I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0404041v2</id>
    <updated>2006-02-06T15:05:13Z</updated>
    <published>2004-04-21T06:30:28Z</published>
    <title>NLOMJ--Natural Language Object Model in Java</title>
    <summary>  In this paper we present NLOMJ--a natural language object model in Java with
English as the experiment language. This modal describes the grammar elements
of any permissible expression in a natural language and their complicated
relations with each other with the concept "Object" in OOP(Object Oriented
Programming). Directly mapped to the syntax and semantics of the natural
language, it can be used in information retrieval as a linguistic method.
Around the UML diagram of the NLOMJ the important classes(Sentence, Clause and
Phrase) and their sub classes are introduced and their syntactic and semantic
meanings are explained.
</summary>
    <author>
      <name>Jiyou Jia</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 1 figure. Submitted to ICICP04</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0404041v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0404041v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7; D.1.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0405039v1</id>
    <updated>2004-05-12T14:14:52Z</updated>
    <published>2004-05-12T14:14:52Z</published>
    <title>Catching the Drift: Probabilistic Content Models, with Applications to
  Generation and Summarization</title>
    <summary>  We consider the problem of modeling the content structure of texts within a
specific domain, in terms of the topics the texts address and the order in
which these topics appear. We first present an effective knowledge-lean method
for learning content models from un-annotated documents, utilizing a novel
adaptation of algorithms for Hidden Markov Models. We then apply our method to
two complementary tasks: information ordering and extractive summarization. Our
experiments show that incorporating content models in these applications yields
substantial improvement over previously-proposed methods.
</summary>
    <author>
      <name>Regina Barzilay</name>
    </author>
    <author>
      <name>Lillian Lee</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Best paper award</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">HLT-NAACL 2004: Proceedings of the Main Conference, pp. 113--120</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0405039v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0405039v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0407002v1</id>
    <updated>2004-07-01T16:18:52Z</updated>
    <published>2004-07-01T16:18:52Z</published>
    <title>Annotating Predicate-Argument Structure for a Parallel Treebank</title>
    <summary>  We report on a recently initiated project which aims at building a
multi-layered parallel treebank of English and German. Particular attention is
devoted to a dedicated predicate-argument layer which is used for aligning
translationally equivalent sentences of the two languages. We describe both our
conceptual decisions and aspects of their technical realisation. We discuss
some selected problems and conclude with a few remarks on how this project
relates to similar projects in the field.
</summary>
    <author>
      <name>Lea Cyrus</name>
    </author>
    <author>
      <name>Hendrik Feddes</name>
    </author>
    <author>
      <name>Frank Schumacher</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 5 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the LREC 2004 Workshop on Building Lexical
  Resources from Semantically Annotated Corpora, Lisbon, May 30, 2004, pp.
  39-46</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0407002v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0407002v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0407026v1</id>
    <updated>2004-07-10T11:18:42Z</updated>
    <published>2004-07-10T11:18:42Z</published>
    <title>Summarizing Encyclopedic Term Descriptions on the Web</title>
    <summary>  We are developing an automatic method to compile an encyclopedic corpus from
the Web. In our previous work, paragraph-style descriptions for a term are
extracted from Web pages and organized based on domains. However, these
descriptions are independent and do not comprise a condensed text as in
hand-crafted encyclopedias. To resolve this problem, we propose a summarization
method, which produces a single text from multiple descriptions. The resultant
summary concisely describes a term from different viewpoints. We also show the
effectiveness of our method by means of experiments.
</summary>
    <author>
      <name>Atsushi Fujii</name>
    </author>
    <author>
      <name>Tetsuya Ishikawa</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, Proceedings of the 20th International Conference on
  Computational Linguistics (to appear)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 20th International Conference on Computational
  Linguistics (COLING 2004), pp.645-651, Aug. 2004</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0407026v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0407026v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7; H.3.3; H.3.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0408026v1</id>
    <updated>2004-08-10T11:09:48Z</updated>
    <published>2004-08-10T11:09:48Z</published>
    <title>Incremental Construction of Minimal Acyclic Sequential Transducers from
  Unsorted Data</title>
    <summary>  This paper presents an efficient algorithm for the incremental construction
of a minimal acyclic sequential transducer (ST) for a dictionary consisting of
a list of input and output strings. The algorithm generalises a known method of
constructing minimal finite-state automata (Daciuk et al. 2000). Unlike the
algorithm published by Mihov and Maurel (2001), it does not require the input
strings to be sorted. The new method is illustrated by an application to
pronunciation dictionaries.
</summary>
    <author>
      <name>Wojciech Skut</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of COLING 2004 (to appear), 7 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0408026v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0408026v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.4.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0408052v1</id>
    <updated>2004-08-22T19:32:48Z</updated>
    <published>2004-08-22T19:32:48Z</published>
    <title>Application of the Double Metaphone Algorithm to Amharic Orthography</title>
    <summary>  The Metaphone algorithm applies the phonetic encoding of orthographic
sequences to simplify words prior to comparison. While Metaphone has been
highly successful for the English language, for which it was designed, it may
not be applied directly to Ethiopian languages. The paper details how the
principles of Metaphone can be applied to Ethiopic script and uses Amharic as a
case study. Match results improve as specific considerations are made for
Amharic writing practices. Results are shown to improve further when common
errors from Amharic input methods are considered.
</summary>
    <author>
      <name>Daniel Yacob</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">International Conference of Ethiopian Studies XV, 13 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0408052v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0408052v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0408059v1</id>
    <updated>2004-08-26T10:50:45Z</updated>
    <published>2004-08-26T10:50:45Z</published>
    <title>Proofing Tools Technology at Neurosoft S.A.</title>
    <summary>  The aim of this paper is to present the R&amp;D activities carried out at
Neurosoft S.A. regarding the development of proofing tools for Modern Greek.
Firstly, we focus on infrastructure issues that we faced during our initial
steps. Subsequently, we describe the most important insights of three proofing
tools developed by Neurosoft, i.e. the spelling checker, the hyphenator and the
thesaurus, outlining their efficiencies and inefficiencies. Finally, we discuss
some improvement ideas and give our future directions.
</summary>
    <author>
      <name>Ch. Tsalidis</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Neurosoft S.A</arxiv:affiliation>
    </author>
    <author>
      <name>G. Orphanos</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Neurosoft S.A</arxiv:affiliation>
    </author>
    <author>
      <name>A. Iordanidou</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Patra's University</arxiv:affiliation>
    </author>
    <author>
      <name>A. Vagelatos</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">RACTI</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Workshop on International Proofing Tools and Language Technologies
  July 1-2, 2004, Patras, Greece</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0408059v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0408059v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0408060v1</id>
    <updated>2004-08-26T12:44:15Z</updated>
    <published>2004-08-26T12:44:15Z</published>
    <title>Verbal chunk extraction in French using limited resources</title>
    <summary>  A way of extracting French verbal chunks, inflected and infinitive, is
explored and tested on effective corpus. Declarative morphological and local
grammar rules specifying chunks and some simple contextual structures are used,
relying on limited lexical information and some simple heuristic/statistic
properties obtained from restricted corpora. The specific goals, the
architecture and the formalism of the system, the linguistic information on
which it relies and the obtained results on effective corpus are presented.
</summary>
    <author>
      <name>Gabriel G. Bes</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">GRIL</arxiv:affiliation>
    </author>
    <author>
      <name>Lionel Lamadon</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">GRIL</arxiv:affiliation>
    </author>
    <author>
      <name>Francois Trouilleux</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">GRIL</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/cs/0408060v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0408060v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0409058v1</id>
    <updated>2004-09-29T20:34:04Z</updated>
    <published>2004-09-29T20:34:04Z</published>
    <title>A Sentimental Education: Sentiment Analysis Using Subjectivity
  Summarization Based on Minimum Cuts</title>
    <summary>  Sentiment analysis seeks to identify the viewpoint(s) underlying a text span;
an example application is classifying a movie review as "thumbs up" or "thumbs
down". To determine this sentiment polarity, we propose a novel
machine-learning method that applies text-categorization techniques to just the
subjective portions of the document. Extracting these portions can be
implemented using efficient techniques for finding minimum cuts in graphs; this
greatly facilitates incorporation of cross-sentence contextual constraints.
</summary>
    <author>
      <name>Bo Pang</name>
    </author>
    <author>
      <name>Lillian Lee</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Data available at
  http://www.cs.cornell.edu/people/pabo/movie-review-data/</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 42nd ACL, pp. 271--278, 2004</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0409058v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0409058v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0410058v1</id>
    <updated>2004-10-22T23:41:52Z</updated>
    <published>2004-10-22T23:41:52Z</published>
    <title>Robust Dialogue Understanding in HERALD</title>
    <summary>  We tackle the problem of robust dialogue processing from the perspective of
language engineering. We propose an agent-oriented architecture that allows us
a flexible way of composing robust processors. Our approach is based on
Shoham's Agent Oriented Programming (AOP) paradigm. We will show how the AOP
agent model can be enriched with special features and components that allow us
to deal with classical problems of dialogue understanding.
</summary>
    <author>
      <name>Vincenzo Pallotta</name>
    </author>
    <author>
      <name>Afzal Ballim</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of RANLP 2001 - EuroConference on Recent Advances in
  Natural Language Processing, September 5-7, 2001, Tzigov-Chark, Bulgaria</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0410058v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0410058v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.2, I.2.7, I.2.11" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0412015v2</id>
    <updated>2005-03-11T14:05:04Z</updated>
    <published>2004-12-03T17:10:17Z</published>
    <title>A Tutorial on the Expectation-Maximization Algorithm Including
  Maximum-Likelihood Estimation and EM Training of Probabilistic Context-Free
  Grammars</title>
    <summary>  The paper gives a brief review of the expectation-maximization algorithm
(Dempster 1977) in the comprehensible framework of discrete mathematics. In
Section 2, two prominent estimation methods, the relative-frequency estimation
and the maximum-likelihood estimation are presented. Section 3 is dedicated to
the expectation-maximization algorithm and a simpler variant, the generalized
expectation-maximization algorithm. In Section 4, two loaded dice are rolled. A
more interesting example is presented in Section 5: The estimation of
probabilistic context-free grammars.
</summary>
    <author>
      <name>Detlef Prescher</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented at the 15th European Summer School in Logic, Language and
  Information (ESSLLI 2003). Example 5 extended (and partially corrected)</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0412015v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0412015v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0412016v1</id>
    <updated>2004-12-03T18:10:17Z</updated>
    <published>2004-12-03T18:10:17Z</published>
    <title>Inside-Outside Estimation Meets Dynamic EM</title>
    <summary>  We briefly review the inside-outside and EM algorithm for probabilistic
context-free grammars. As a result, we formally prove that inside-outside
estimation is a dynamic-programming variant of EM. This is interesting in its
own right, but even more when considered in a theoretical context since the
well-known convergence behavior of inside-outside estimation has been confirmed
by many experiments but apparently has never been formally proved. However,
being a version of EM, inside-outside estimation also inherits the good
convergence behavior of EM. Therefore, the as yet imperfect line of
argumentation can be transformed into a coherent proof.
</summary>
    <author>
      <name>Detlef Prescher</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, some typos corrected</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of IWPT 2001</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0412016v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0412016v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0509092v1</id>
    <updated>2005-09-28T16:15:27Z</updated>
    <published>2005-09-28T16:15:27Z</published>
    <title>Automatic extraction of paraphrastic phrases from medium size corpora</title>
    <summary>  This paper presents a versatile system intended to acquire paraphrastic
phrases from a representative corpus. In order to decrease the time spent on
the elaboration of resources for NLP system (for example Information
Extraction, IE hereafter), we suggest to use a machine learning system that
helps defining new templates and associated resources. This knowledge is
automatically derived from the text collection, in interaction with a large
semantic network.
</summary>
    <author>
      <name>Thierry Poibeau</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIPN</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Actes de la conf\'{e}rence Computational Linguisitcs (COLING 2004)
  (2004) 638-644</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0509092v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0509092v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0511079v1</id>
    <updated>2005-11-22T07:06:43Z</updated>
    <published>2005-11-22T07:06:43Z</published>
    <title>An elitist approach for extracting automatically well-realized speech
  sounds with high confidence</title>
    <summary>  This paper presents an "elitist approach" for extracting automatically
well-realized speech sounds with high confidence. The elitist approach uses a
speech recognition system based on Hidden Markov Models (HMM). The HMM are
trained on speech sounds which are systematically well-detected in an iterative
procedure. The results show that, by using the HMM models defined in the
training phase, the speech recognizer detects reliably specific speech sounds
with a small rate of errors.
</summary>
    <author>
      <name>Jean-Baptiste Maj</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LORIA</arxiv:affiliation>
    </author>
    <author>
      <name>Anne Bonneau</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LORIA</arxiv:affiliation>
    </author>
    <author>
      <name>Dominique Fohr</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LORIA</arxiv:affiliation>
    </author>
    <author>
      <name>Yves Laprie</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LORIA</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/cs/0511079v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0511079v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0512102v1</id>
    <updated>2005-12-28T13:45:54Z</updated>
    <published>2005-12-28T13:45:54Z</published>
    <title>Statistical Parameters of the Novel "Perekhresni stezhky" ("The
  Cross-Paths") by Ivan Franko</title>
    <summary>  In the paper, a complex statistical characteristics of a Ukrainian novel is
given for the first time. The distribution of word-forms with respect to their
size is studied. The linguistic laws by Zipf-Mandelbrot and Altmann-Menzerath
are analyzed.
</summary>
    <author>
      <name>Solomija Buk</name>
    </author>
    <author>
      <name>Andrij Rovenchak</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Quantitative Linguistics 62: Exact methods in the study of
  language and text: dedicated to Professor Gabriel Altmann on the occasion of
  his 75th birthday / Ed. by P. Grzybek and R. Kohler (Berlin; New York: de
  Gruyter), 39-48 (2007)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0512102v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0512102v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0604027v1</id>
    <updated>2006-04-07T13:10:30Z</updated>
    <published>2006-04-07T13:10:30Z</published>
    <title>Unification of multi-lingual scientific terminological resources using
  the ISO 16642 standard. The TermSciences initiative</title>
    <summary>  This paper presents the TermSciences portal, which deals with the
implementation of a conceptual model that uses the recent ISO 16642 standard
(Terminological Markup Framework). This standard turns out to be suitable for
concept modeling since it allowed for organizing the original resources by
concepts and to associate the various terms for a given concept. Additional
structuring is produced by sharing conceptual relationships, that is,
cross-linking of resource results through the introduction of semantic
relations which may have initially be missing.
</summary>
    <author>
      <name>Majid Khayari</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INIST</arxiv:affiliation>
    </author>
    <author>
      <name>Stéphane Schneider</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INIST</arxiv:affiliation>
    </author>
    <author>
      <name>Isabelle Kramer</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LORIA</arxiv:affiliation>
    </author>
    <author>
      <name>Laurent Romary</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LORIA</arxiv:affiliation>
    </author>
    <author>
      <name>the termsciences Collaboration</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6p</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0604027v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0604027v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0606118v1</id>
    <updated>2006-06-28T14:43:42Z</updated>
    <published>2006-06-28T14:43:42Z</published>
    <title>Adapting a general parser to a sublanguage</title>
    <summary>  In this paper, we propose a method to adapt a general parser (Link Parser) to
sublanguages, focusing on the parsing of texts in biology. Our main proposal is
the use of terminology (identication and analysis of terms) in order to reduce
the complexity of the text to be parsed. Several other strategies are explored
and finally combined among which text normalization, lexicon and
morpho-guessing module extensions and grammar rules adaptation. We compare the
parsing results before and after these adaptations.
</summary>
    <author>
      <name>Sophie Aubin</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIPN</arxiv:affiliation>
    </author>
    <author>
      <name>Adeline Nazarenko</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIPN</arxiv:affiliation>
    </author>
    <author>
      <name>Claire Nédellec</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">MIG</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the International Conference on Recent Advances in
  Natural Language Processing (RANLP'05) (2005) 89-93</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0606118v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0606118v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0609044v1</id>
    <updated>2006-09-08T14:11:50Z</updated>
    <published>2006-09-08T14:11:50Z</published>
    <title>The role of time in considering collections</title>
    <summary>  The paper concerns the understanding of plurals in the framework of
Artificial Intelligence and emphasizes the role of time. The construction of
collection(s) and their evolution across time is often crucial and has to be
accounted for. The paper contrasts a "de dicto" collection where the collection
can be considered as persisting over these situations even if its members
change with a "de re" collection whose composition does not vary through time.
It expresses different criteria of choice between the two interpretations (de
re and de dicto) depending on the context of enunciation.
</summary>
    <author>
      <name>Françoise Gayral</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIPN</arxiv:affiliation>
    </author>
    <author>
      <name>Daniel Kayser</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIPN</arxiv:affiliation>
    </author>
    <author>
      <name>François Lévy</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIPN</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journ\'{e}es de S\'{e}mantique et Mod\'{e}lisation, France (2004)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0609044v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0609044v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0610004v1</id>
    <updated>2006-10-01T17:39:44Z</updated>
    <published>2006-10-01T17:39:44Z</published>
    <title>Rapport technique du projet OGRE</title>
    <summary>  This repport concerns automatic understanding of (french) iterative
sentences, i.e. sentences where one single verb has to be interpreted by a more
or less regular plurality of events. A linguistic analysis is proposed along an
extension of Reichenbach's theory, several formal representations are
considered and a corpus of 18000 newspaper extracts is described.
</summary>
    <author>
      <name>Gérard Bécher</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">GREYC</arxiv:affiliation>
    </author>
    <author>
      <name>Patrice Enjalbert</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">GREYC</arxiv:affiliation>
    </author>
    <author>
      <name>Estelle Fievé</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIMSI</arxiv:affiliation>
    </author>
    <author>
      <name>Laurent Gosselin</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">DS</arxiv:affiliation>
    </author>
    <author>
      <name>François Lévy</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIPN</arxiv:affiliation>
    </author>
    <author>
      <name>Gérard Ligozat</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIMSI</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">92 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0610004v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0610004v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0611069v1</id>
    <updated>2006-11-15T12:35:45Z</updated>
    <published>2006-11-15T12:35:45Z</published>
    <title>Scaling Construction Grammar up to Production Systems: the SCIM</title>
    <summary>  While a great effort has concerned the development of fully integrated
modular understanding systems, few researches have focused on the problem of
unifying existing linguistic formalisms with cognitive processing models. The
Situated Constructional Interpretation Model is one of these attempts. In this
model, the notion of "construction" has been adapted in order to be able to
mimic the behavior of Production Systems. The Construction Grammar approach
establishes a model of the relations between linguistic forms and meaning, by
the mean of constructions. The latter can be considered as pairings from a
topologically structured space to an unstructured space, in some way a special
kind of production rules.
</summary>
    <author>
      <name>Guillaume Pitel</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Lorraine - LORIA</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Dans Scalable Natural Language Understanding 2006 (2006)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0611069v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0611069v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0701181v1</id>
    <updated>2007-01-27T19:09:53Z</updated>
    <published>2007-01-27T19:09:53Z</published>
    <title>A Note on Local Ultrametricity in Text</title>
    <summary>  High dimensional, sparsely populated data spaces have been characterized in
terms of ultrametric topology. This implies that there are natural, not
necessarily unique, tree or hierarchy structures defined by the ultrametric
topology. In this note we study the extent of local ultrametric topology in
texts, with the aim of finding unique ``fingerprints'' for a text or corpus,
discriminating between texts from different domains, and opening up the
possibility of exploiting hierarchical structures in the data. We use coherent
and meaningful collections of over 1000 texts, comprising over 1.3 million
words.
</summary>
    <author>
      <name>Fionn Murtagh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pp</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0701181v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0701181v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.5.3; I.7.2; H.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0701194v1</id>
    <updated>2007-01-30T16:58:07Z</updated>
    <published>2007-01-30T16:58:07Z</published>
    <title>Menzerath-Altmann Law for Syntactic Structures in Ukrainian</title>
    <summary>  In the paper, the definition of clause suitable for an automated processing
of a Ukrainian text is proposed. The Menzerath-Altmann law is verified on the
sentence level and the parameters for the dependences of the clause length
counted in words and syllables on the sentence length counted in clauses are
calculated for "Perekhresni Stezhky" ("The Cross-Paths"), a novel by Ivan
Franko.
</summary>
    <author>
      <name>Solomija Buk</name>
    </author>
    <author>
      <name>Andrij Rovenchak</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages; submitted to the Proceedings of the International scientific
  conference on Modern Methods in Linguistics held in honour of the anniversary
  of Prof. Gabriel L. Altmann (October 23rd and 24th, 2006, Budmerice Castle,
  Slovakia)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Glottotheory. Vol. 1, No. 1, pp 10-17 (2008)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0701194v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0701194v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0702081v1</id>
    <updated>2007-02-14T06:05:20Z</updated>
    <published>2007-02-14T06:05:20Z</published>
    <title>Random Sentences from a Generalized Phrase-Structure Grammar Interpreter</title>
    <summary>  In numerous domains in cognitive science it is often useful to have a source
for randomly generated corpora. These corpora may serve as a foundation for
artificial stimuli in a learning experiment (e.g., Ellefson &amp; Christiansen,
2000), or as input into computational models (e.g., Christiansen &amp; Dale, 2001).
The following compact and general C program interprets a phrase-structure
grammar specified in a text file. It follows parameters set at a Unix or
Unix-based command-line and generates a corpus of random sentences from that
grammar.
</summary>
    <author>
      <name>Rick Dale</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Brief paper with source code and examples</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0702081v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0702081v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0703027v2</id>
    <updated>2008-05-31T16:10:52Z</updated>
    <published>2007-03-06T19:50:37Z</published>
    <title>Interroger un corpus par le sens</title>
    <summary>  In textual knowledge management, statistical methods prevail. Nonetheless,
some difficulties cannot be overcome by these methodologies. I propose a
symbolic approach using a complete textual analysis to identify which analysis
level can improve the the answers provided by a system. The approach identifies
word senses and relation between words and generates as many rephrasings as
possible. Using synonyms and derivative, the system provides new utterances
without changing the original meaning of the sentences. Such a way, an
information can be retrieved whatever the question or answer's wording may be.
</summary>
    <author>
      <name>Bernard Jacquemin</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">ISC</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pp</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Dans "Mots, termes et contextes", Actes des septi\`emes Journ\'ees
  scientifiques du r\'eseau de chercheurs Lexicologie, Terminologie, Traduction
  - Bruxelles : Belgique (2005)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0703027v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0703027v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0703135v1</id>
    <updated>2007-03-27T22:12:25Z</updated>
    <published>2007-03-27T22:12:25Z</published>
    <title>Dependency Parsing with Dynamic Bayesian Network</title>
    <summary>  Exact parsing with finite state automata is deemed inappropriate because of
the unbounded non-locality languages overwhelmingly exhibit. We propose a way
to structure the parsing task in order to make it amenable to local
classification methods. This allows us to build a Dynamic Bayesian Network
which uncovers the syntactic dependency structure of English sentences.
Experiments with the Wall Street Journal demonstrate that the model
successfully learns from labeled data.
</summary>
    <author>
      <name>Virginia Savova</name>
    </author>
    <author>
      <name>Leonid Peshkin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">In proceedings of American Association for Artificial Intelligence
  AAAI 2005</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0703135v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0703135v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7; I.2.1; G.3; H.3.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0704.2083v1</id>
    <updated>2007-04-17T01:04:01Z</updated>
    <published>2007-04-17T01:04:01Z</published>
    <title>Introduction to Arabic Speech Recognition Using CMUSphinx System</title>
    <summary>  In this paper Arabic was investigated from the speech recognition problem
point of view. We propose a novel approach to build an Arabic Automated Speech
Recognition System (ASR). This system is based on the open source CMU Sphinx-4,
from the Carnegie Mellon University. CMU Sphinx is a large-vocabulary;
speaker-independent, continuous speech recognition system based on discrete
Hidden Markov Models (HMMs). We build a model using utilities from the
OpenSource CMU Sphinx. We will demonstrate the possible adaptability of this
system to Arabic voice recognition.
</summary>
    <author>
      <name>H. Satori</name>
    </author>
    <author>
      <name>M. Harti</name>
    </author>
    <author>
      <name>N. Chenfour</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 3 figures and 2 tables, was in Information and Communication
  Technologies International Symposium proceeding ICTIS07 Fes (2007)</arxiv:comment>
    <link href="http://arxiv.org/abs/0704.2083v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0704.2083v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0704.2201v1</id>
    <updated>2007-04-17T17:04:26Z</updated>
    <published>2007-04-17T17:04:26Z</published>
    <title>Arabic Speech Recognition System using CMU-Sphinx4</title>
    <summary>  In this paper we present the creation of an Arabic version of Automated
Speech Recognition System (ASR). This system is based on the open source
Sphinx-4, from the Carnegie Mellon University. Which is a speech recognition
system based on discrete hidden Markov models (HMMs). We investigate the
changes that must be made to the model to adapt Arabic voice recognition.
  Keywords: Speech recognition, Acoustic model, Arabic language, HMMs,
CMUSphinx-4, Artificial intelligence.
</summary>
    <author>
      <name>H. Satori</name>
    </author>
    <author>
      <name>M. Harti</name>
    </author>
    <author>
      <name>N. Chenfour</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 3 figures and 2 tables, in French</arxiv:comment>
    <link href="http://arxiv.org/abs/0704.2201v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0704.2201v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0704.3665v1</id>
    <updated>2007-04-27T05:58:32Z</updated>
    <published>2007-04-27T05:58:32Z</published>
    <title>On the Development of Text Input Method - Lessons Learned</title>
    <summary>  Intelligent Input Methods (IM) are essential for making text entries in many
East Asian scripts, but their application to other languages has not been fully
explored. This paper discusses how such tools can contribute to the development
of computer processing of other oriental languages. We propose a design
philosophy that regards IM as a text service platform, and treats the study of
IM as a cross disciplinary subject from the perspectives of software
engineering, human-computer interaction (HCI), and natural language processing
(NLP). We discuss these three perspectives and indicate a number of possible
future research directions.
</summary>
    <author>
      <name>Mike Tian-Jian Jiang</name>
    </author>
    <author>
      <name>Deng Liu</name>
    </author>
    <author>
      <name>Meng-Juei Hsieh</name>
    </author>
    <author>
      <name>Wen-Lien Hsu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/0704.3665v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0704.3665v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0707.3270v1</id>
    <updated>2007-07-22T15:25:27Z</updated>
    <published>2007-07-22T15:25:27Z</published>
    <title>A Formal Model of Dictionary Structure and Content</title>
    <summary>  We show that a general model of lexical information conforms to an abstract
model that reflects the hierarchy of information found in a typical dictionary
entry. We show that this model can be mapped into a well-formed XML document,
and how the XSL transformation language can be used to implement a semantics
defined over the abstract model to enable extraction and manipulation of the
information in any format.
</summary>
    <author>
      <name>Laurent Romary</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Lorraine - LORIA</arxiv:affiliation>
    </author>
    <author>
      <name>Nancy Ide</name>
    </author>
    <author>
      <name>Adam Kilgarriff</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Dans Euralex 2000 Euralex 2000, Stuttgart : Allemagne (2000)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0707.3270v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0707.3270v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0707.3559v1</id>
    <updated>2007-07-24T14:30:27Z</updated>
    <published>2007-07-24T14:30:27Z</published>
    <title>Practical Approach to Knowledge-based Question Answering with Natural
  Language Understanding and Advanced Reasoning</title>
    <summary>  This research hypothesized that a practical approach in the form of a
solution framework known as Natural Language Understanding and Reasoning for
Intelligence (NaLURI), which combines full-discourse natural language
understanding, powerful representation formalism capable of exploiting
ontological information and reasoning approach with advanced features, will
solve the following problems without compromising practicality factors: 1)
restriction on the nature of question and response, and 2) limitation to scale
across domains and to real-life natural language text.
</summary>
    <author>
      <name>Wilson Wong</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Master of Science thesis, National Technical University College of
  Malaysia, 2005</arxiv:comment>
    <link href="http://arxiv.org/abs/0707.3559v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0707.3559v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7; H.5.2; H.3.4; H.3.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0707.3972v1</id>
    <updated>2007-07-26T17:02:40Z</updated>
    <published>2007-07-26T17:02:40Z</published>
    <title>Learning Probabilistic Models of Word Sense Disambiguation</title>
    <summary>  This dissertation presents several new methods of supervised and unsupervised
learning of word sense disambiguation models. The supervised methods focus on
performing model searches through a space of probabilistic models, and the
unsupervised methods rely on the use of Gibbs Sampling and the Expectation
Maximization (EM) algorithm. In both the supervised and unsupervised case, the
Naive Bayesian model is found to perform well. An explanation for this success
is presented in terms of learning rates and bias-variance decompositions.
</summary>
    <author>
      <name>Ted Pedersen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">195 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">PhD dissertation, May 1998, Department of Computer Science and
  Engineering, Southern Methodist University</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0707.3972v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0707.3972v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0708.1564v1</id>
    <updated>2007-08-11T13:09:27Z</updated>
    <published>2007-08-11T13:09:27Z</published>
    <title>Learning Phonotactics Using ILP</title>
    <summary>  This paper describes experiments on learning Dutch phonotactic rules using
Inductive Logic Programming, a machine learning discipline based on inductive
logical operators. Two different ways of approaching the problem are
experimented with, and compared against each other as well as with related work
on the task. The results show a direct correspondence between the quality and
informedness of the background knowledge and the constructed theory,
demonstrating the ability of ILP to take good advantage of the prior domain
knowledge available. Further research is outlined.
</summary>
    <author>
      <name>Stasinos Konstantopoulos</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Special Issue of the WEB-SLS Journal: The Language Sections of the
  ESSLLI-01 Student Session. 2002</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0708.1564v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0708.1564v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0709.2401v1</id>
    <updated>2007-09-15T01:37:21Z</updated>
    <published>2007-09-15T01:37:21Z</published>
    <title>Bootstrapping Deep Lexical Resources: Resources for Courses</title>
    <summary>  We propose a range of deep lexical acquisition methods which make use of
morphological, syntactic and ontological language resources to model word
similarity and bootstrap from a seed lexicon. The different methods are
deployed in learning lexical items for a precision grammar, and shown to each
have strengths and weaknesses over different word classes. A particular focus
of this paper is the relative accessibility of different language resource
types, and predicted ``bang for the buck'' associated with each in deep lexical
acquisition applications.
</summary>
    <author>
      <name>Timothy Baldwin</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings of the ACL-SIGLEX 2005 Workshop on Deep Lexical
  Acquisition, Ann Arbor, USA, pp. 67-76</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0709.2401v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0709.2401v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0710.0105v2</id>
    <updated>2007-10-03T03:36:45Z</updated>
    <published>2007-09-30T03:21:54Z</published>
    <title>Zipf's Law and Avoidance of Excessive Synonymy</title>
    <summary>  Zipf's law states that if words of language are ranked in the order of
decreasing frequency in texts, the frequency of a word is inversely
proportional to its rank. It is very robust as an experimental observation, but
to date it escaped satisfactory theoretical explanation. We suggest that Zipf's
law may arise from the evolution of word semantics dominated by expansion of
meanings and competition of synonyms.
</summary>
    <author>
      <name>Dmitrii Manin</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1080/03640210802020003</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1080/03640210802020003" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">47 pages; fixed reference list missing in v.1</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Main text in Cognitive Science, 32 (7) 2008, pp. 1075 - 1098;
  Appendix A TBP separately in J. Quant. Ling.</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0710.0105v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0710.0105v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0710.0225v1</id>
    <updated>2007-10-01T08:23:24Z</updated>
    <published>2007-10-01T08:23:24Z</published>
    <title>On the role of autocorrelations in texts</title>
    <summary>  The task of finding a criterion allowing to distinguish a text from an
arbitrary set of words is rather relevant in itself, for instance, in the
aspect of development of means for internet-content indexing or separating
signals and noise in communication channels. The Zipf law is currently
considered to be the most reliable criterion of this kind [3]. At any rate,
conventional stochastic word sets do not meet this law. The present paper deals
with one of possible criteria based on the determination of the degree of data
compression.
</summary>
    <author>
      <name>D. V. Lande</name>
    </author>
    <author>
      <name>A. A. Snarskii</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 4 figures, 5 references</arxiv:comment>
    <link href="http://arxiv.org/abs/0710.0225v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0710.0225v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0710.1481v1</id>
    <updated>2007-10-08T08:36:32Z</updated>
    <published>2007-10-08T08:36:32Z</published>
    <title>What's in a Name?</title>
    <summary>  This paper describes experiments on identifying the language of a single name
in isolation or in a document written in a different language. A new corpus has
been compiled and made available, matching names against languages. This corpus
is used in a series of experiments measuring the performance of general
language models and names-only language models on the language identification
task. Conclusions are drawn from the comparison between using general language
models and names-only language models and between identifying the language of
isolated names and the language of very short document fragments. Future
research directions are outlined.
</summary>
    <author>
      <name>Stasinos Konstantopoulos</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented at the Computational Phonology Workshop, 6th Intl. Conf.
  Recent Advances in NLP, Borovets, Bulgaria, September 2007</arxiv:comment>
    <link href="http://arxiv.org/abs/0710.1481v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0710.1481v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0710.2674v1</id>
    <updated>2007-10-14T16:09:53Z</updated>
    <published>2007-10-14T16:09:53Z</published>
    <title>Linguistic Information Energy</title>
    <summary>  In this treatment a text is considered to be a series of word impulses which
are read at a constant rate. The brain then assembles these units of
information into higher units of meaning. A classical systems approach is used
to model an initial part of this assembly process. The concepts of linguistic
system response, information energy, and ordering energy are defined and
analyzed. Finally, as a demonstration, information energy is used to estimate
the publication dates of a series of texts and the similarity of a set of
texts.
</summary>
    <author>
      <name>James Ford</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 7 graphs</arxiv:comment>
    <link href="http://arxiv.org/abs/0710.2674v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0710.2674v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0710.2852v1</id>
    <updated>2007-10-15T15:45:13Z</updated>
    <published>2007-10-15T15:45:13Z</published>
    <title>Generating models for temporal representations</title>
    <summary>  We discuss the use of model building for temporal representations. We chose
Polish to illustrate our discussion because it has an interesting aspectual
system, but the points we wish to make are not language specific. Rather, our
goal is to develop theoretical and computational tools for temporal model
building tasks in computational semantics. To this end, we present a
first-order theory of time and events which is rich enough to capture
interesting semantic distinctions, and an algorithm which takes minimal models
for first-order theories and systematically attempts to ``perturb'' their
temporal component to provide non-minimal, but semantically significant,
models.
</summary>
    <author>
      <name>Patrick Blackburn</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Lorraine - LORIA</arxiv:affiliation>
    </author>
    <author>
      <name>Sébastien Hinderer</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Lorraine - LORIA</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Dans Recent Advances in Natural Language Processing (2007) 69-75</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0710.2852v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0710.2852v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0710.2988v1</id>
    <updated>2007-10-16T09:16:24Z</updated>
    <published>2007-10-16T09:16:24Z</published>
    <title>Using Description Logics for Recognising Textual Entailment</title>
    <summary>  The aim of this paper is to show how we can handle the Recognising Textual
Entailment (RTE) task by using Description Logics (DLs). To do this, we propose
a representation of natural language semantics in DLs inspired by existing
representations in first-order logic. But our most significant contribution is
the definition of two novel inference tasks: A-Box saturation and subgraph
detection which are crucial for our approach to RTE.
</summary>
    <author>
      <name>Paul Bedaride</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Lorraine - Loria</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Dans 19th European Summer School in Logic, Language and
  Information (2007) 11-21</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0710.2988v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0710.2988v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0711.2270v1</id>
    <updated>2007-11-14T18:32:09Z</updated>
    <published>2007-11-14T18:32:09Z</published>
    <title>Can a Computer Laugh ?</title>
    <summary>  A computer model of "a sense of humour" suggested previously
[arXiv:0711.2058,0711.2061], relating the humorous effect with a specific
malfunction in information processing, is given in somewhat different
exposition. Psychological aspects of humour are elaborated more thoroughly. The
mechanism of laughter is formulated on the more general level. Detailed
discussion is presented for the higher levels of information processing, which
are responsible for a perception of complex samples of humour. Development of a
sense of humour in the process of evolution is discussed.
</summary>
    <author>
      <name>I. M. Suslov</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">P.L.Kapitza Institute for Physical Problems, Moscow, Russia</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">English translation of the paper in Russian; 18 pages, 6 figures
  included</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Computer Chronicle (Moscow), 1994, issue 1, p.1</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0711.2270v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0711.2270v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0711.3449v1</id>
    <updated>2007-11-21T20:34:08Z</updated>
    <published>2007-11-21T20:34:08Z</published>
    <title>Lexicon management and standard formats</title>
    <summary>  International standards for lexicon formats are in preparation. To a certain
extent, the proposed formats converge with prior results of standardization
projects. However, their adequacy for (i) lexicon management and (ii)
lexicon-driven applications have been little debated in the past, nor are they
as a part of the present standardization effort. We examine these issues. IGM
has developed XML formats compatible with the emerging international standards,
and we report experimental results on large-coverage lexica.
</summary>
    <author>
      <name>Eric Laporte</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IGM-LabInfo</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Archives of Control Sciences 15, 3 (2005) 329-340</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0711.3449v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0711.3449v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0711.3453v1</id>
    <updated>2007-11-21T20:41:59Z</updated>
    <published>2007-11-21T20:41:59Z</published>
    <title>A resource-based Korean morphological annotation system</title>
    <summary>  We describe a resource-based method of morphological annotation of written
Korean text. Korean is an agglutinative language. The output of our system is a
graph of morphemes annotated with accurate linguistic information. The language
resources used by the system can be easily updated, which allows us-ers to
control the evolution of the per-formances of the system. We show that
morphological annotation of Korean text can be performed directly with a
lexicon of words and without morpho-logical rules.
</summary>
    <author>
      <name>Hyun-Gue Huh</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IGM-LabInfo</arxiv:affiliation>
    </author>
    <author>
      <name>Eric Laporte</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IGM-LabInfo</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Dans Proceedings of the International Joint Conference on Natural
  Language Processing (IJCNLP) - A resource-based Korean morphological
  annotation system, Jeju : Cor\'ee, R\'epublique de (2005)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0711.3453v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0711.3453v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0711.3454v1</id>
    <updated>2007-11-21T20:44:04Z</updated>
    <published>2007-11-21T20:44:04Z</published>
    <title>Graphes paramétrés et outils de lexicalisation</title>
    <summary>  Shifting to a lexicalized grammar reduces the number of parsing errors and
improves application results. However, such an operation affects a syntactic
parser in all its aspects. One of our research objectives is to design a
realistic model for grammar lexicalization. We carried out experiments for
which we used a grammar with a very simple content and formalism, and a very
informative syntactic lexicon, the lexicon-grammar of French elaborated by the
LADL. Lexicalization was performed by applying the parameterized-graph
approach. Our results tend to show that most information in the lexicon-grammar
can be transferred into a grammar and exploited successfully for the syntactic
parsing of sentences.
</summary>
    <author>
      <name>Eric Laporte</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IGM-LabInfo</arxiv:affiliation>
    </author>
    <author>
      <name>Sébastien Paumier</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IGM-LabInfo</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Dans Verbum ex machina. Proceedings of TALN - Graphes
  param\'etr\'es et outils de lexicalisation, Louvain : Belgique (2006)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0711.3454v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0711.3454v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0711.3457v1</id>
    <updated>2007-11-21T20:49:21Z</updated>
    <published>2007-11-21T20:49:21Z</published>
    <title>Evaluation of a Grammar of French Determiners</title>
    <summary>  Existing syntactic grammars of natural languages, even with a far from
complete coverage, are complex objects. Assessments of the quality of parts of
such grammars are useful for the validation of their construction. We evaluated
the quality of a grammar of French determiners that takes the form of a
recursive transition network. The result of the application of this local
grammar gives deeper syntactic information than chunking or information
available in treebanks. We performed the evaluation by comparison with a corpus
independently annotated with information on determiners. We obtained 86%
precision and 92% recall on text not tagged for parts of speech.
</summary>
    <author>
      <name>Eric Laporte</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IGM-LabInfo</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Dans Annals of the 27th Congress of the Brazilian Society of
  Computation - Evaluation of a Grammar of French Determiners, Rio de Janeiro :
  Br\'esil (2007)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0711.3457v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0711.3457v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0801.3239v1</id>
    <updated>2008-01-21T17:41:57Z</updated>
    <published>2008-01-21T17:41:57Z</published>
    <title>Online-concordance "Perekhresni stezhky" ("The Cross-Paths"), a novel by
  Ivan Franko</title>
    <summary>  In the article, theoretical principles and practical realization for the
compilation of the concordance to "Perekhresni stezhky" ("The Cross-Paths"), a
novel by Ivan Franko, are described. Two forms for the context presentation are
proposed. The electronic version of this lexicographic work is available
online.
</summary>
    <author>
      <name>Solomiya Buk</name>
    </author>
    <author>
      <name>Andrij Rovenchak</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">in Ukrainian</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Ivan Franko: Spirit, Science, Thought, Will (Proceedings of the
  International Scientific Congress dedicated to the 150th anniversary (Lviv,
  27 September -- 1 October 2006, Lviv University Press, Vol. 2, pp. 203-211,
  2010)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0801.3239v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0801.3239v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0801.4746v5</id>
    <updated>2008-02-10T08:26:02Z</updated>
    <published>2008-01-30T19:40:45Z</published>
    <title>Concerning Olga, the Beautiful Little Street Dancer (Adjectives as
  Higher-Order Polymorphic Functions)</title>
    <summary>  In this paper we suggest a typed compositional seman-tics for nominal
compounds of the form [Adj Noun] that models adjectives as higher-order
polymorphic functions, and where types are assumed to represent concepts in an
ontology that reflects our commonsense view of the world and the way we talk
about it in or-dinary language. In addition to [Adj Noun] compounds our
proposal seems also to suggest a plausible explana-tion for well known
adjective ordering restrictions.
</summary>
    <author>
      <name>Walid S. Saba</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/0801.4746v5" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0801.4746v5" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0804.3269v1</id>
    <updated>2008-04-21T15:38:45Z</updated>
    <published>2008-04-21T15:38:45Z</published>
    <title>Phoneme recognition in TIMIT with BLSTM-CTC</title>
    <summary>  We compare the performance of a recurrent neural network with the best
results published so far on phoneme recognition in the TIMIT database. These
published results have been obtained with a combination of classifiers.
However, in this paper we apply a single recurrent neural network to the same
task. Our recurrent neural network attains an error rate of 24.6%. This result
is not significantly different from that obtained by the other best methods,
but they rely on a combination of classifiers for achieving comparable
performance.
</summary>
    <author>
      <name>Santiago Fernández</name>
    </author>
    <author>
      <name>Alex Graves</name>
    </author>
    <author>
      <name>Juergen Schmidhuber</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/0804.3269v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0804.3269v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7; I.5.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0804.4584v1</id>
    <updated>2008-04-29T11:39:18Z</updated>
    <published>2008-04-29T11:39:18Z</published>
    <title>Feature Unification in TAG Derivation Trees</title>
    <summary>  The derivation trees of a tree adjoining grammar provide a first insight into
the sentence semantics, and are thus prime targets for generation systems. We
define a formalism, feature-based regular tree grammars, and a translation from
feature based tree adjoining grammars into this new formalism. The translation
preserves the derivation structures of the original grammar, and accounts for
feature unification.
</summary>
    <author>
      <name>Sylvain Schmitz</name>
    </author>
    <author>
      <name>Joseph Le Roux</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 4 figures In TAG+9, Ninth International Workshop on Tree
  Adjoining Grammars and Related Formalisms, 2008</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">In TAG+9, Ninth International Workshop on Tree Adjoining Grammars
  and Related Formalisms, 2008</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0804.4584v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0804.4584v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.4.2; I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0805.2537v1</id>
    <updated>2008-05-16T13:58:44Z</updated>
    <published>2008-05-16T13:58:44Z</published>
    <title>A toolkit for a generative lexicon</title>
    <summary>  In this paper we describe the conception of a software toolkit designed for
the construction, maintenance and collaborative use of a Generative Lexicon. In
order to ease its portability and spreading use, this tool was built with free
and open source products. We eventually tested the toolkit and showed it
filters the adequate form of anaphoric reference to the modifier in endocentric
compounds.
</summary>
    <author>
      <name>Patrick Henry</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LaBRI</arxiv:affiliation>
    </author>
    <author>
      <name>Christian Bassac</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LaBRI</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">poster - 6 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Dans A toolkit for a Generative Lexicon - Fourth International
  Workshop on Generative Approaches to the Lexicon, PARIS : France (2007)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0805.2537v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0805.2537v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0805.3366v1</id>
    <updated>2008-05-21T23:44:06Z</updated>
    <published>2008-05-21T23:44:06Z</published>
    <title>Computational Representation of Linguistic Structures using
  Domain-Specific Languages</title>
    <summary>  We describe a modular system for generating sentences from formal definitions
of underlying linguistic structures using domain-specific languages. The system
uses Java in general, Prolog for lexical entries and custom domain-specific
languages based on Functional Grammar and Functional Discourse Grammar
notation, implemented using the ANTLR parser generator. We show how linguistic
and technological parts can be brought together in a natural language
processing system and how domain-specific languages can be used as a tool for
consistent formal notation in linguistic description.
</summary>
    <author>
      <name>Fabian Steeg</name>
    </author>
    <author>
      <name>Christoph Benden</name>
    </author>
    <author>
      <name>Paul O. Samuelsdorff</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 9 figures; based on work presented at the 12th
  International Conference on Functional Grammar</arxiv:comment>
    <link href="http://arxiv.org/abs/0805.3366v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0805.3366v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.4; I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0805.3410v1</id>
    <updated>2008-05-22T08:48:28Z</updated>
    <published>2008-05-22T08:48:28Z</published>
    <title>Exploring a type-theoretic approach to accessibility constraint
  modelling</title>
    <summary>  The type-theoretic modelling of DRT that [degroote06] proposed features
continuations for the management of the context in which a clause has to be
interpreted. This approach, while keeping the standard definitions of
quantifier scope, translates the rules of the accessibility constraints of
discourse referents inside the semantic recipes. In this paper, we deal with
additional rules for these accessibility constraints. In particular in the case
of discourse referents introduced by proper nouns, that negation does not
block, and in the case of rhetorical relations that structure discourses. We
show how this continuation-based approach applies to those accessibility
constraints and how we can consider the parallel management of various
principles.
</summary>
    <author>
      <name>Sylvain Pogodalla</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Lorraine - LORIA</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Dans Journ\'ees S\'emantiques et Mod\'elisation (2008)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0805.3410v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0805.3410v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0805.4521v1</id>
    <updated>2008-05-29T11:53:39Z</updated>
    <published>2008-05-29T11:53:39Z</published>
    <title>Textual Entailment Recognizing by Theorem Proving Approach</title>
    <summary>  In this paper we present two original methods for recognizing textual
inference. First one is a modified resolution method such that some linguistic
considerations are introduced in the unification of two atoms. The approach is
possible due to the recent methods of transforming texts in logic formulas.
Second one is based on semantic relations in text, as presented in WordNet.
Some similarities between these two methods are remarked.
</summary>
    <author>
      <name>Doina Tatar</name>
    </author>
    <author>
      <name>Militon Frentiu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Studia Univ.Babes-Bolyai, Informatica, Vol.LI, Number 2, 2006</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0805.4521v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0805.4521v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0806.2581v1</id>
    <updated>2008-06-16T13:48:55Z</updated>
    <published>2008-06-16T13:48:55Z</published>
    <title>A chain dictionary method for Word Sense Disambiguation and applications</title>
    <summary>  A large class of unsupervised algorithms for Word Sense Disambiguation (WSD)
is that of dictionary-based methods. Various algorithms have as the root Lesk's
algorithm, which exploits the sense definitions in the dictionary directly. Our
approach uses the lexical base WordNet for a new algorithm originated in
Lesk's, namely "chain algorithm for disambiguation of all words", CHAD. We show
how translation from a language into another one and also text entailment
verification could be accomplished by this disambiguation.
</summary>
    <author>
      <name>Doina Tatar</name>
    </author>
    <author>
      <name>Gabriela Serban</name>
    </author>
    <author>
      <name>Andreea Mihis</name>
    </author>
    <author>
      <name>Mihaiela Lupea</name>
    </author>
    <author>
      <name>Dana Lupsa</name>
    </author>
    <author>
      <name>Militon Frentiu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 5 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Studia Universitatis Babes-Bolyai, Special Issue, KEPT 2007,
  Knowledge Engineering: Principles and Technologies, Cluj-Napoca, June 6-8,
  2007, pp 33-40,</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0806.2581v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0806.2581v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0807.0311v1</id>
    <updated>2008-07-02T09:49:14Z</updated>
    <published>2008-07-02T09:49:14Z</published>
    <title>About the creation of a parallel bilingual corpora of web-publications</title>
    <summary>  The algorithm of the creation texts parallel corpora was presented. The
algorithm is based on the use of "key words" in text documents, and on the
means of their automated translation. Key words were singled out by means of
using Russian and Ukrainian morphological dictionaries, as well as dictionaries
of the translation of nouns for the Russian and Ukrainianlanguages. Besides, to
calculate the weights of the terms in the documents, empiric-statistic rules
were used. The algorithm under consideration was realized in the form of a
program complex, integrated into the content-monitoring InfoStream system. As a
result, a parallel bilingual corpora of web-publications containing about 30
thousand documents, was created
</summary>
    <author>
      <name>D. V. Lande</name>
    </author>
    <author>
      <name>V. V. Zhygalo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/0807.0311v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0807.0311v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0808.3563v1</id>
    <updated>2008-08-26T18:17:44Z</updated>
    <published>2008-08-26T18:17:44Z</published>
    <title>What It Feels Like To Hear Voices: Fond Memories of Julian Jaynes</title>
    <summary>  Julian Jaynes's profound humanitarian convictions not only prevented him from
going to war, but would have prevented him from ever kicking a dog. Yet
according to his theory, not only are language-less dogs unconscious, but so
too were the speaking/hearing Greeks in the Bicameral Era, when they heard
gods' voices telling them what to do rather than thinking for themselves. I
argue that to be conscious is to be able to feel, and that all mammals (and
probably lower vertebrates and invertebrates too) feel, hence are conscious.
Julian Jaynes's brilliant analysis of our concepts of consciousness
nevertheless keeps inspiring ever more inquiry and insights into the age-old
mind/body problem and its relation to cognition and language.
</summary>
    <author>
      <name>Stevan Harnad</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/0808.3563v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0808.3563v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0808.3616v3</id>
    <updated>2009-03-30T11:53:07Z</updated>
    <published>2008-08-27T02:02:40Z</published>
    <title>Constructing word similarities in Meroitic as an aid to decipherment</title>
    <summary>  Meroitic is the still undeciphered language of the ancient civilization of
Kush. Over the years, various techniques for decipherment such as finding a
bilingual text or cognates from modern or other ancient languages in the Sudan
and surrounding areas has not been successful. Using techniques borrowed from
information theory and natural language statistics, similar words are paired
and attempts are made to use currently defined words to extract at least
partial meaning from unknown words.
</summary>
    <author>
      <name>Reginald D. Smith</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages; 2 figures; to appear in British Museum studies in Ancient
  Egypt and Sudan</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">British Museum Studies in Ancient Egypt and Sudan, 12, 1-10 (2009)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0808.3616v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0808.3616v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0809.0103v1</id>
    <updated>2008-08-31T06:08:15Z</updated>
    <published>2008-08-31T06:08:15Z</published>
    <title>On the nature of long-range letter correlations in texts</title>
    <summary>  The origin of long-range letter correlations in natural texts is studied
using random walk analysis and Jensen-Shannon divergence. It is concluded that
they result from slow variations in letter frequency distribution, which are a
consequence of slow variations in lexical composition within the text. These
correlations are preserved by random letter shuffling within a moving window.
As such, they do reflect structural properties of the text, but in a very
indirect manner.
</summary>
    <author>
      <name>Dmitrii Y. Manin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 5 figures, unpublished</arxiv:comment>
    <link href="http://arxiv.org/abs/0809.0103v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0809.0103v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0809.3250v1</id>
    <updated>2008-09-18T20:48:13Z</updated>
    <published>2008-09-18T20:48:13Z</published>
    <title>Using descriptive mark-up to formalize translation quality assessment</title>
    <summary>  The paper deals with using descriptive mark-up to emphasize translation
mistakes. The author postulates the necessity to develop a standard and formal
XML-based way of describing translation mistakes. It is considered to be
important for achieving impersonal translation quality assessment. Marked-up
translations can be used in corpus translation studies; moreover, automatic
translation assessment based on marked-up mistakes is possible. The paper
concludes with setting up guidelines for further activity within the described
field.
</summary>
    <author>
      <name>Andrey Kutuzov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Published in Russian in 'Translation industry and information
  supply in international business activities: materials of international
  conference' - Perm, 2008, pp. 90-101</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0809.3250v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0809.3250v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0811.0453v1</id>
    <updated>2008-11-04T09:08:32Z</updated>
    <published>2008-11-04T09:08:32Z</published>
    <title>CoZo+ - A Content Zoning Engine for textual documents</title>
    <summary>  Content zoning can be understood as a segmentation of textual documents into
zones. This is inspired by [6] who initially proposed an approach for the
argumentative zoning of textual documents. With the prototypical CoZo+ engine,
we focus on content zoning towards an automatic processing of textual streams
while considering only the actors as the zones. We gain information that can be
used to realize an automatic recognition of content for pre-defined actors. We
understand CoZo+ as a necessary pre-step towards an automatic generation of
summaries and to make intellectual ownership of documents detectable.
</summary>
    <author>
      <name>Cynthia Wagner</name>
    </author>
    <author>
      <name>Christoph Schommer</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0811.0453v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0811.0453v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3; H.3.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0812.3070v1</id>
    <updated>2008-12-16T14:24:23Z</updated>
    <published>2008-12-16T14:24:23Z</published>
    <title>A Computational Model to Disentangle Semantic Information Embedded in
  Word Association Norms</title>
    <summary>  Two well-known databases of semantic relationships between pairs of words
used in psycholinguistics, feature-based and association-based, are studied as
complex networks. We propose an algorithm to disentangle feature based
relationships from free association semantic networks. The algorithm uses the
rich topology of the free association semantic network to produce a new set of
relationships between words similar to those observed in feature production
norms.
</summary>
    <author>
      <name>J. Borge</name>
    </author>
    <author>
      <name>A. Arenas</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0812.3070v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0812.3070v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0901.4180v2</id>
    <updated>2015-01-28T20:10:34Z</updated>
    <published>2009-01-27T06:29:10Z</published>
    <title>Google distance between words</title>
    <summary>  Cilibrasi and Vitanyi have demonstrated that it is possible to extract the
meaning of words from the world-wide web. To achieve this, they rely on the
number of webpages that are found through a Google search containing a given
word and they associate the page count to the probability that the word appears
on a webpage. Thus, conditional probabilities allow them to correlate one word
with another word's meaning. Furthermore, they have developed a similarity
distance function that gauges how closely related a pair of words is. We
present a specific counterexample to the triangle inequality for this
similarity distance function.
</summary>
    <author>
      <name>Bjørn Kjos-Hanssen</name>
    </author>
    <author>
      <name>Alberto J. Evangelista</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented at Frontiers in Undergraduate Research, University of
  Connecticut, 2006</arxiv:comment>
    <link href="http://arxiv.org/abs/0901.4180v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0901.4180v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0902.2230v1</id>
    <updated>2009-02-12T23:02:06Z</updated>
    <published>2009-02-12T23:02:06Z</published>
    <title>BagPack: A general framework to represent semantic relations</title>
    <summary>  We introduce a way to represent word pairs instantiating arbitrary semantic
relations that keeps track of the contexts in which the words in the pair occur
both together and independently. The resulting features are of sufficient
generality to allow us, with the help of a standard supervised machine learning
algorithm, to tackle a variety of unrelated semantic tasks with good results
and almost no task-specific tailoring.
</summary>
    <author>
      <name>Amaç Herdağdelen</name>
    </author>
    <author>
      <name>Marco Baroni</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Long paper presented at GEMS - Geometric Models of Natural Language
  Semantics, workshop held in conjunction with the 12th Conference of the
  European Chapter of the Association for Computational Linguistics (EACL-09),
  Athens, Greece</arxiv:comment>
    <link href="http://arxiv.org/abs/0902.2230v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0902.2230v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7; I.5.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0902.3072v1</id>
    <updated>2009-02-18T08:51:28Z</updated>
    <published>2009-02-18T08:51:28Z</published>
    <title>Syntactic variation of support verb constructions</title>
    <summary>  We report experiments about the syntactic variations of support verb
constructions, a special type of multiword expressions (MWEs) containing
predicative nouns. In these expressions, the noun can occur with or without the
verb, with no clear-cut semantic difference. We extracted from a large French
corpus a set of examples of the two situations and derived statistical results
from these data. The extraction involved large-coverage language resources and
finite-state techniques. The results show that, most frequently, predicative
nouns occur without a support verb. This fact has consequences on methods of
extracting or recognising MWEs.
</summary>
    <author>
      <name>Eric Laporte</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IGM-LabInfo</arxiv:affiliation>
    </author>
    <author>
      <name>Elisabete Ranchhod</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">ONSET-CEL</arxiv:affiliation>
    </author>
    <author>
      <name>Anastasia Yannacopoulou</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IGM-LabInfo</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Lingvisticae Investigationes 31, 2 (2008) 173-185</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0902.3072v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0902.3072v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0905.0740v1</id>
    <updated>2009-05-06T04:29:51Z</updated>
    <published>2009-05-06T04:29:51Z</published>
    <title>A FORTRAN coded regular expression Compiler for IBM 1130 Computing
  System</title>
    <summary>  REC (Regular Expression Compiler) is a concise programming language which
allows students to write programs without knowledge of the complicated syntax
of languages like FORTRAN and ALGOL. The language is recursive and contains
only four elements for control. This paper describes an interpreter of REC
written in FORTRAN.
</summary>
    <author>
      <name>Gerardo Cisneros</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This version of REC is archaeological reconstruction of REC/A
  language on IBM1130 Simulator (SIMH IBM 1130 Emulator and Disk Monitor System
  R2V12) from Computer History Simulation Project (www.ibm1130.org), also see
  REC language is a live for Ignacio Vega-Paez</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Acta Mexicana de Ciencia y Tecnologia Vol. IV No. 1, page 30-86,
  1970</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0905.0740v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0905.0740v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0905.1609v1</id>
    <updated>2009-05-11T12:17:36Z</updated>
    <published>2009-05-11T12:17:36Z</published>
    <title>Acquisition of morphological families and derivational series from a
  machine readable dictionary</title>
    <summary>  The paper presents a linguistic and computational model aiming at making the
morphological structure of the lexicon emerge from the formal and semantic
regularities of the words it contains. The model is word-based. The proposed
morphological structure consists of (1) binary relations that connect each
headword with words that are morphologically related, and especially with the
members of its morphological family and its derivational series, and of (2) the
analogies that hold between the words. The model has been tested on the lexicon
of French using the TLFi machine readable dictionary.
</summary>
    <author>
      <name>Nabil Hathout</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CLLE</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">proceedings of the 6th D\'ecembrettes</arxiv:comment>
    <link href="http://arxiv.org/abs/0905.1609v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0905.1609v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0907.0785v1</id>
    <updated>2009-07-04T18:43:16Z</updated>
    <published>2009-07-04T18:43:16Z</published>
    <title>A Bayesian Model for Discovering Typological Implications</title>
    <summary>  A standard form of analysis for linguistic typology is the universal
implication. These implications state facts about the range of extant
languages, such as ``if objects come after verbs, then adjectives come after
nouns.'' Such implications are typically discovered by painstaking hand
analysis over a small sample of languages. We propose a computational model for
assisting at this process. Our model is able to discover both well-known
implications as well as some novel implications that deserve further study.
Moreover, through a careful application of hierarchical analysis, we are able
to cope with the well-known sampling problem: languages are not independent.
</summary>
    <author>
      <name>Hal Daumé III</name>
    </author>
    <author>
      <name>Lyle Campbell</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ACL 2007</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0907.0785v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0907.0785v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0907.0806v1</id>
    <updated>2009-07-04T22:26:47Z</updated>
    <published>2009-07-04T22:26:47Z</published>
    <title>A Noisy-Channel Model for Document Compression</title>
    <summary>  We present a document compression system that uses a hierarchical
noisy-channel model of text production. Our compression system first
automatically derives the syntactic structure of each sentence and the overall
discourse structure of the text given as input. The system then uses a
statistical hierarchical model of text production in order to drop
non-important syntactic and discourse constituents so as to generate coherent,
grammatical document compressions of arbitrary length. The system outperforms
both a baseline and a sentence-based compression system that operates by
simplifying sequentially all sentences in a text. Our results support the claim
that discourse knowledge plays an important role in document summarization.
</summary>
    <author>
      <name>Hal Daumé III</name>
    </author>
    <author>
      <name>Daniel Marcu</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ACL 2002</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0907.0806v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0907.0806v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0907.1814v1</id>
    <updated>2009-07-10T13:24:55Z</updated>
    <published>2009-07-10T13:24:55Z</published>
    <title>Bayesian Query-Focused Summarization</title>
    <summary>  We present BayeSum (for ``Bayesian summarization''), a model for sentence
extraction in query-focused summarization. BayeSum leverages the common case in
which multiple documents are relevant to a single query. Using these documents
as reinforcement for query terms, BayeSum is not afflicted by the paucity of
information in short queries. We show that approximate inference in BayeSum is
possible on large data sets and results in a state-of-the-art summarization
system. Furthermore, we show how BayeSum can be understood as a justified query
expansion technique in the language modeling for IR framework.
</summary>
    <author>
      <name>Hal Daumé III</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ACL 2006</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0907.1814v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0907.1814v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0907.2452v1</id>
    <updated>2009-07-14T21:02:14Z</updated>
    <published>2009-07-14T21:02:14Z</published>
    <title>Pattern Based Term Extraction Using ACABIT System</title>
    <summary>  In this paper, we propose a pattern-based term extraction approach for
Japanese, applying ACABIT system originally developed for French. The proposed
approach evaluates termhood using morphological patterns of basic terms and
term variants. After extracting term candidates, ACABIT system filters out
non-terms from the candidates based on log-likelihood. This approach is
suitable for Japanese term extraction because most of Japanese terms are
compound nouns or simple phrasal patterns.
</summary>
    <author>
      <name>Koichi Takeuchi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">NII</arxiv:affiliation>
    </author>
    <author>
      <name>Kyo Kageura</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">NII</arxiv:affiliation>
    </author>
    <author>
      <name>Teruo Koyama</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">NII</arxiv:affiliation>
    </author>
    <author>
      <name>Béatrice Daille</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LINA</arxiv:affiliation>
    </author>
    <author>
      <name>Laurent Romary</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Lorraine - LORIA</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IEIC Technical Report 103, 280 (2003) 31-36</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0907.2452v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0907.2452v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0907.3781v1</id>
    <updated>2009-07-22T06:25:59Z</updated>
    <published>2009-07-22T06:25:59Z</published>
    <title>Un système modulaire d'acquisition automatique de traductions à
  partir du Web</title>
    <summary>  We present a method of automatic translation (French/English) of Complex
Lexical Units (CLU) for aiming at extracting a bilingual lexicon. Our modular
system is based on linguistic properties (compositionality, polysemy, etc.).
Different aspects of the multilingual Web are used to validate candidate
translations and collect new terms. We first build a French corpus of Web pages
to collect CLU. Three adapted processing stages are applied for each linguistic
property : compositional and non polysemous translations, compositional
polysemous translations and non compositional translations. Our evaluation on a
sample of CLU shows that our technique based on the Web can reach a very high
precision.
</summary>
    <author>
      <name>Stéphanie Léon</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIRMM</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">TALN'09 (Traitement Automatique des Langues Naturelles), France
  (2009)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0907.3781v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0907.3781v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0909.2715v1</id>
    <updated>2009-09-15T06:02:56Z</updated>
    <published>2009-09-15T06:02:56Z</published>
    <title>Marking-up multiple views of a Text: Discourse and Reference</title>
    <summary>  We describe an encoding scheme for discourse structure and reference, based
on the TEI Guidelines and the recommendations of the Corpus Encoding
Specification (CES). A central feature of the scheme is a CES-based data
architecture enabling the encoding of and access to multiple views of a
marked-up document. We describe a tool architecture that supports the encoding
scheme, and then show how we have used the encoding scheme and the tools to
perform a discourse analytic task in support of a model of global discourse
cohesion called Veins Theory (Cristea &amp; Ide, 1998).
</summary>
    <author>
      <name>Dan Cristea</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Lorraine - LORIA</arxiv:affiliation>
    </author>
    <author>
      <name>Nancy Ide</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Lorraine - LORIA</arxiv:affiliation>
    </author>
    <author>
      <name>Laurent Romary</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Lorraine - LORIA</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">First International Language Resources and Evaluation Conference,
  Grenada, Espagne : France (1998)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0909.2715v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0909.2715v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0909.2719v1</id>
    <updated>2009-09-15T06:10:45Z</updated>
    <published>2009-09-15T06:10:45Z</published>
    <title>Standards for Language Resources</title>
    <summary>  This paper presents an abstract data model for linguistic annotations and its
implementation using XML, RDF and related standards; and to outline the work of
a newly formed committee of the International Standards Organization (ISO),
ISO/TC 37/SC 4 Language Resource Management, which will use this work as its
starting point. The primary motive for presenting the latter is to solicit the
participation of members of the research community to contribute to the work of
the committee.
</summary>
    <author>
      <name>Nancy Ide</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">COMPUTER Science Department</arxiv:affiliation>
    </author>
    <author>
      <name>Laurent Romary</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Lorraine - Loria</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Colloque avec actes et comit\'e de lecture. internationale</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Third International Conference on Language Resources and
  Evaluation - LREC 2002, Las Palmas, Spain : France (2002)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0909.2719v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0909.2719v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0909.3027v1</id>
    <updated>2009-09-16T14:38:19Z</updated>
    <published>2009-09-16T14:38:19Z</published>
    <title>Language Models for Handwritten Short Message Services</title>
    <summary>  Handwriting is an alternative method for entering texts composing Short
Message Services. However, a whole new language features the texts which are
produced. They include for instance abbreviations and other consonantal writing
which sprung up for time saving and fashion. We have collected and processed a
significant number of such handwriting SMS, and used various strategies to
tackle this challenging area of handwriting recognition. We proposed to study
more specifically three different phenomena: consonant skeleton, rebus, and
phonetic writing. For each of them, we compare the rough results produced by a
standard recognition system with those obtained when using a specific language
model.
</summary>
    <author>
      <name>Emmanuel Ep Prochasson</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LINA</arxiv:affiliation>
    </author>
    <author>
      <name>Christian Viard-Gaudin</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IRCCyN</arxiv:affiliation>
    </author>
    <author>
      <name>Emmanuel Morin</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LINA</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Conference on Document Analysis and Recognition,
  Brazil (2007)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0909.3027v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0909.3027v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0909.3028v1</id>
    <updated>2009-09-16T14:39:05Z</updated>
    <published>2009-09-16T14:39:05Z</published>
    <title>Vers la reconnaissance de mini-messages manuscrits</title>
    <summary>  Handwriting is an alternative method for entering texts which composed Short
Message Services. However, a whole new language features the texts which are
produced. They include for instance abbreviations and other consonantal writing
which sprung up for time saving and fashion. We have collected and processed a
significant number of such handwritten SMS, and used various strategies to
tackle this challenging area of handwriting recognition. We proposed to study
more specifically three different phenomena: consonant skeleton, rebus, and
phonetic writing. For each of them, we compare the rough results produced by a
standard recognition system with those obtained when using a specific language
model to take care of them.
</summary>
    <author>
      <name>Emmanuel Prochasson</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LINA</arxiv:affiliation>
    </author>
    <author>
      <name>Emmanuel Morin</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LINA</arxiv:affiliation>
    </author>
    <author>
      <name>Christian Viard-Gaudin</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IRCCyN</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Colloque International sur le Lexique et la Grammaire, Bonifacio :
  France (2007)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0909.3028v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0909.3028v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0909.3591v1</id>
    <updated>2009-09-19T15:38:55Z</updated>
    <published>2009-09-19T15:38:55Z</published>
    <title>Mathematics, Recursion, and Universals in Human Languages</title>
    <summary>  There are many scientific problems generated by the multiple and conflicting
alternative definitions of linguistic recursion and human recursive processing
that exist in the literature. The purpose of this article is to make available
to the linguistic community the standard mathematical definition of recursion
and to apply it to discuss linguistic recursion. As a byproduct, we obtain an
insight into certain "soft universals" of human languages, which are related to
cognitive constructs necessary to implement mathematical reasoning, i.e.
mathematical model theory.
</summary>
    <author>
      <name>P. Gilkey</name>
    </author>
    <author>
      <name>S. Lopez Ornat</name>
    </author>
    <author>
      <name>A. Karousou</name>
    </author>
    <link href="http://arxiv.org/abs/0909.3591v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0909.3591v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91F20, 03B65, 68T50" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0910.0537v1</id>
    <updated>2009-10-03T12:26:47Z</updated>
    <published>2009-10-03T12:26:47Z</published>
    <title>A Note On Higher Order Grammar</title>
    <summary>  Both syntax-phonology and syntax-semantics interfaces in Higher Order Grammar
(HOG) are expressed as axiomatic theories in higher-order logic (HOL), i.e. a
language is defined entirely in terms of provability in the single logical
system. An important implication of this elegant architecture is that the
meaning of a valid expression turns out to be represented not by a single, nor
even by a few "discrete" terms (in case of ambiguity), but by a "continuous"
set of logically equivalent terms. The note is devoted to precise formulation
and proof of this observation.
</summary>
    <author>
      <name>Victor Gluzberg</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages in single-spaced pdf format</arxiv:comment>
    <link href="http://arxiv.org/abs/0910.0537v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0910.0537v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0910.1484v1</id>
    <updated>2009-10-08T12:21:22Z</updated>
    <published>2009-10-08T12:21:22Z</published>
    <title>Ludics and its Applications to natural Language Semantics</title>
    <summary>  Proofs, in Ludics, have an interpretation provided by their counter-proofs,
that is the objects they interact with. We follow the same idea by proposing
that sentence meanings are given by the counter-meanings they are opposed to in
a dialectical interaction. The conception is at the intersection of a
proof-theoretic and a game-theoretic accounts of semantics, but it enlarges
them by allowing to deal with possibly infinite processes.
</summary>
    <author>
      <name>Alain Lecomte</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Futurs, SFLTAMP</arxiv:affiliation>
    </author>
    <author>
      <name>Myriam Quatrini</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IML</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Lecture Notes in Artificial Intelligence LNAI, 5514 (2009) pp
  242--255</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0910.1484v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0910.1484v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0911.1842v1</id>
    <updated>2009-11-10T07:12:03Z</updated>
    <published>2009-11-10T07:12:03Z</published>
    <title>Standards for Language Resources</title>
    <summary>  The goal of this paper is two-fold: to present an abstract data model for
linguistic annotations and its implementation using XML, RDF and related
standards; and to outline the work of a newly formed committee of the
International Standards Organization (ISO), ISO/TC 37/SC 4 Language Resource
Management, which will use this work as its starting point.
</summary>
    <author>
      <name>Nancy Ide</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Lorraine - LORIA</arxiv:affiliation>
    </author>
    <author>
      <name>Laurent Romary</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Lorraine - LORIA</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Colloque avec actes et comit\'e de lecture. internationale</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IRCS Workshop on Linguistic Databases, Philadelphia : United
  States (2001)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0911.1842v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0911.1842v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0911.1965v1</id>
    <updated>2009-11-10T19:52:01Z</updated>
    <published>2009-11-10T19:52:01Z</published>
    <title>Active Learning for Mention Detection: A Comparison of Sentence
  Selection Strategies</title>
    <summary>  We propose and compare various sentence selection strategies for active
learning for the task of detecting mentions of entities. The best strategy
employs the sum of confidences of two statistical classifiers trained on
different views of the data. Our experimental results show that, compared to
the random selection strategy, this strategy reduces the amount of required
labeled training data by over 50% while achieving the same performance. The
effect is even more significant when only named mentions are considered: the
system achieves the same performance by using only 42% of the training data
required by the random selection strategy.
</summary>
    <author>
      <name>Nitin Madnani</name>
    </author>
    <author>
      <name>Hongyan Jing</name>
    </author>
    <author>
      <name>Nanda Kambhatla</name>
    </author>
    <author>
      <name>Salim Roukos</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 9 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0911.1965v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0911.1965v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0912.3917v1</id>
    <updated>2009-12-19T18:29:43Z</updated>
    <published>2009-12-19T18:29:43Z</published>
    <title>Speech Recognition Oriented Vowel Classification Using Temporal Radial
  Basis Functions</title>
    <summary>  The recent resurgence of interest in spatio-temporal neural network as speech
recognition tool motivates the present investigation. In this paper an approach
was developed based on temporal radial basis function "TRBF" looking to many
advantages: few parameters, speed convergence and time invariance. This
application aims to identify vowels taken from natural speech samples from the
Timit corpus of American speech. We report a recognition accuracy of 98.06
percent in training and 90.13 in test on a subset of 6 vowel phonemes, with the
possibility to expend the vowel sets in future.
</summary>
    <author>
      <name>Mustapha Guezouri</name>
    </author>
    <author>
      <name>Larbi Mesbahi</name>
    </author>
    <author>
      <name>Abdelkader Benyettou</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Computing, Volume 1, Issue 1, pp 162-167, December 2009</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0912.3917v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0912.3917v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1002.0485v1</id>
    <updated>2010-02-02T13:35:02Z</updated>
    <published>2010-02-02T13:35:02Z</published>
    <title>Morphological study of Albanian words, and processing with NooJ</title>
    <summary>  We are developing electronic dictionaries and transducers for the automatic
processing of the Albanian Language. We will analyze the words inside a linear
segment of text. We will also study the relationship between units of sense and
units of form. The composition of words takes different forms in Albanian. We
have found that morphemes are frequently concatenated or simply juxtaposed or
contracted. The inflected grammar of NooJ allows constructing the dictionaries
of flexed forms (declensions or conjugations). The diversity of word structures
requires tools to identify words created by simple concatenation, or to treat
contractions. The morphological tools of NooJ allow us to create grammatical
tools to represent and treat these phenomena. But certain problems exceed the
morphological analysis and must be represented by syntactical grammars.
</summary>
    <author>
      <name>Odile Piton</name>
    </author>
    <author>
      <name>Klara Lagji</name>
    </author>
    <link href="http://arxiv.org/abs/1002.0485v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1002.0485v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1002.1095v1</id>
    <updated>2010-02-04T22:48:31Z</updated>
    <published>2010-02-04T22:48:31Z</published>
    <title>Towards a Heuristic Categorization of Prepositional Phrases in English
  with WordNet</title>
    <summary>  This document discusses an approach and its rudimentary realization towards
automatic classification of PPs; the topic, that has not received as much
attention in NLP as NPs and VPs. The approach is a rule-based heuristics
outlined in several levels of our research. There are 7 semantic categories of
PPs considered in this document that we are able to classify from an annotated
corpus.
</summary>
    <author>
      <name>Frank Rudzicz</name>
    </author>
    <author>
      <name>Serguei A. Mokhov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages; 4 tables; 1 figure; a year 2003 report</arxiv:comment>
    <link href="http://arxiv.org/abs/1002.1095v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1002.1095v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1003.0337v1</id>
    <updated>2010-03-01T18:04:39Z</updated>
    <published>2010-03-01T18:04:39Z</published>
    <title>Change of word types to word tokens ratio in the course of translation
  (based on Russian translations of K. Vonnegut novels)</title>
    <summary>  The article provides lexical statistical analysis of K. Vonnegut's two novels
and their Russian translations. It is found out that there happen some changes
between the speed of word types and word tokens ratio change in the source and
target texts. The author hypothesizes that these changes are typical for
English-Russian translations, and moreover, they represent an example of
Baker's translation feature of levelling out.
</summary>
    <author>
      <name>Andrey Kutuzov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 5 figures, to be reported at International Computational
  Linguistic Conference "Dialog-21"-2010 (http://dialog-21.ru)</arxiv:comment>
    <link href="http://arxiv.org/abs/1003.0337v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1003.0337v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1003.0628v1</id>
    <updated>2010-03-02T16:52:32Z</updated>
    <published>2010-03-02T16:52:32Z</published>
    <title>Linguistic Geometries for Unsupervised Dimensionality Reduction</title>
    <summary>  Text documents are complex high dimensional objects. To effectively visualize
such data it is important to reduce its dimensionality and visualize the low
dimensional embedding as a 2-D or 3-D scatter plot. In this paper we explore
dimensionality reduction methods that draw upon domain knowledge in order to
achieve a better low dimensional embedding and visualization of documents. We
consider the use of geometries specified manually by an expert, geometries
derived automatically from corpus statistics, and geometries computed from
linguistic resources.
</summary>
    <author>
      <name>Yi Mao</name>
    </author>
    <author>
      <name>Krishnakumar Balasubramanian</name>
    </author>
    <author>
      <name>Guy Lebanon</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 15 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1003.0628v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1003.0628v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1003.4149v1</id>
    <updated>2010-03-22T13:09:57Z</updated>
    <published>2010-03-22T13:09:57Z</published>
    <title>Les Entités Nommées : usage et degrés de précision et de
  désambiguïsation</title>
    <summary>  The recognition and classification of Named Entities (NER) are regarded as an
important component for many Natural Language Processing (NLP) applications.
The classification is usually made by taking into account the immediate context
in which the NE appears. In some cases, this immediate context does not allow
getting the right classification. We show in this paper that the use of an
extended syntactic context and large-scale resources could be very useful in
the NER task.
</summary>
    <author>
      <name>Claude Martineau</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IGM-LabInfo</arxiv:affiliation>
    </author>
    <author>
      <name>Elsa Tolone</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IGM-LabInfo</arxiv:affiliation>
    </author>
    <author>
      <name>Stavroula Voyatzi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IGM-LabInfo</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">26\`eme Colloque international sur le Lexique et la Grammaire
  (LGC'07), Bonifacio : France (2007)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1003.4149v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1003.4149v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1005.5466v1</id>
    <updated>2010-05-29T16:37:02Z</updated>
    <published>2010-05-29T16:37:02Z</published>
    <title>Quantitative parametrization of texts written by Ivan Franko: An attempt
  of the project</title>
    <summary>  In the article, the project of quantitative parametrization of all texts by
Ivan Franko is manifested. It can be made only by using modern computer
techniques after the frequency dictionaries for all Franko's works are
compiled. The paper describes the application spheres, methodology, stages,
principles and peculiarities in the compilation of the frequency dictionary of
the second half of the 19th century - the beginning of the 20th century. The
relation between the Ivan Franko frequency dictionary, explanatory dictionary
of writer's language and text corpus is discussed.
</summary>
    <author>
      <name>Solomiya Buk</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages, in Ukrainian</arxiv:comment>
    <link href="http://arxiv.org/abs/1005.5466v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1005.5466v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1006.0153v1</id>
    <updated>2010-06-01T15:20:59Z</updated>
    <published>2010-06-01T15:20:59Z</published>
    <title>Ivan Franko's novel Dlja domashnjoho ohnyshcha (For the Hearth) in the
  light of the frequency dictionary</title>
    <summary>  In the article, the methodology and the principles of the compilation of the
Frequency dictionary for Ivan Franko's novel Dlja domashnjoho ohnyshcha (For
the Hearth) are described. The following statistical parameters of the novel
vocabulary are obtained: variety, exclusiveness, concentration indexes,
correlation between word rank and text coverage, etc. The main quantitative
characteristics of Franko's novels Perekhresni stezhky (The Cross-Paths) and
Dlja domashnjoho ohnyshcha are compared on the basis of their frequency
dictionaries.
</summary>
    <author>
      <name>Solomiya Buk</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, in Ukrainian</arxiv:comment>
    <link href="http://arxiv.org/abs/1006.0153v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1006.0153v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1006.1343v1</id>
    <updated>2010-06-07T19:36:18Z</updated>
    <published>2010-06-07T19:36:18Z</published>
    <title>Segmentation and Nodal Points in Narrative: Study of Multiple Variations
  of a Ballad</title>
    <summary>  The Lady Maisry ballads afford us a framework within which to segment a
storyline into its major components. Segments and as a consequence nodal points
are discussed for nine different variants of the Lady Maisry story of a (young)
woman being burnt to death by her family, on account of her becoming pregnant
by a foreign personage. We motivate the importance of nodal points in textual
and literary analysis. We show too how the openings of the nine variants can be
analyzed comparatively, and also the conclusions of the ballads.
</summary>
    <author>
      <name>Fionn Murtagh</name>
    </author>
    <author>
      <name>Adam Ganz</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">27 pp., 13 figures. Submitted</arxiv:comment>
    <link href="http://arxiv.org/abs/1006.1343v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1006.1343v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.1; H.3.2; I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1006.2835v1</id>
    <updated>2010-06-14T20:07:32Z</updated>
    <published>2010-06-14T20:07:32Z</published>
    <title>Fuzzy Modeling and Natural Language Processing for Panini's Sanskrit
  Grammar</title>
    <summary>  Indian languages have long history in World Natural languages. Panini was the
first to define Grammar for Sanskrit language with about 4000 rules in fifth
century. These rules contain uncertainty information. It is not possible to
Computer processing of Sanskrit language with uncertain information. In this
paper, fuzzy logic and fuzzy reasoning are proposed to deal to eliminate
uncertain information for reasoning with Sanskrit grammar. The Sanskrit
language processing is also discussed in this paper.
</summary>
    <author>
      <name>P. Venkata Subba Reddy</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to Journal of Computer Science and Engineering, see
  http://sites.google.com/site/jcseuk/volume-1-issue-1-may-2010</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Computer Science and Engineering, Volume 1, Issue 1,
  p99-101, May 2010</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1006.2835v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1006.2835v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1006.5880v1</id>
    <updated>2010-06-30T15:10:33Z</updated>
    <published>2010-06-30T15:10:33Z</published>
    <title>Testing SDRT's Right Frontier</title>
    <summary>  The Right Frontier Constraint (RFC), as a constraint on the attachment of new
constituents to an existing discourse structure, has important implications for
the interpretation of anaphoric elements in discourse and for Machine Learning
(ML) approaches to learning discourse structures. In this paper we provide
strong empirical support for SDRT's version of RFC. The analysis of about 100
doubly annotated documents by five different naive annotators shows that SDRT's
RFC is respected about 95% of the time. The qualitative analysis of presumed
violations that we have performed shows that they are either click-errors or
structural misconceptions.
</summary>
    <author>
      <name>Stergos Afantenos</name>
    </author>
    <author>
      <name>Nicholas Asher</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of COLING 2010</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1006.5880v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1006.5880v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1008.1986v1</id>
    <updated>2010-08-11T20:01:59Z</updated>
    <published>2010-08-11T20:01:59Z</published>
    <title>For the sake of simplicity: Unsupervised extraction of lexical
  simplifications from Wikipedia</title>
    <summary>  We report on work in progress on extracting lexical simplifications (e.g.,
"collaborate" -&gt; "work together"), focusing on utilizing edit histories in
Simple English Wikipedia for this task. We consider two main approaches: (1)
deriving simplification probabilities via an edit model that accounts for a
mixture of different operations, and (2) using metadata to focus on edits that
are more likely to be simplification operations. We find our methods to
outperform a reasonable baseline and yield many high-quality lexical
simplifications not included in an independently-created manually prepared
list.
</summary>
    <author>
      <name>Mark Yatskar</name>
    </author>
    <author>
      <name>Bo Pang</name>
    </author>
    <author>
      <name>Cristian Danescu-Niculescu-Mizil</name>
    </author>
    <author>
      <name>Lillian Lee</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pp; data available at
  http://www.cs.cornell.edu/home/llee/data/simple/</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the NAACL, pp. 365-368, 2010. Short paper</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1008.1986v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1008.1986v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1009.1117v2</id>
    <updated>2010-09-24T06:37:16Z</updated>
    <published>2010-09-06T18:35:08Z</published>
    <title>Constructions définitoires des tables du Lexique-Grammaire</title>
    <summary>  Lexicon-Grammar tables are a very rich syntactic lexicon for the French
language. This linguistic database is nevertheless not directly suitable for
use by computer programs, as it is incomplete and lacks consistency. Tables are
defined on the basis of features which are not explicitly recorded in the
lexicon. These features are only described in literature. Our aim is to define
for each tables these essential properties to make them usable in various
Natural Language Processing (NLP) applications, such as parsing.
</summary>
    <author>
      <name>Elsa Tolone</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIGM</arxiv:affiliation>
    </author>
    <author>
      <name>Stavroula Voyatzi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIGM</arxiv:affiliation>
    </author>
    <author>
      <name>Christian Leclère</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIGM</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">29\`eme Colloque international sur le Lexique et la Grammaire
  (LGC'10), Belgrade : Serbie (2010)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1009.1117v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1009.1117v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1010.2384v1</id>
    <updated>2010-10-12T13:20:30Z</updated>
    <published>2010-10-12T13:20:30Z</published>
    <title>Learning Taxonomy for Text Segmentation by Formal Concept Analysis</title>
    <summary>  In this paper the problems of deriving a taxonomy from a text and
concept-oriented text segmentation are approached. Formal Concept Analysis
(FCA) method is applied to solve both of these linguistic problems. The
proposed segmentation method offers a conceptual view for text segmentation,
using a context-driven clustering of sentences. The Concept-oriented Clustering
Segmentation algorithm (COCS) is based on k-means linear clustering of the
sentences. Experimental results obtained using COCS algorithm are presented.
</summary>
    <author>
      <name>Mihaiela Lupea</name>
    </author>
    <author>
      <name>Doina Tatar</name>
    </author>
    <author>
      <name>Zsuzsana Marian</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented at Synasc 2010, Timisoara, Romania</arxiv:comment>
    <link href="http://arxiv.org/abs/1010.2384v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1010.2384v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T50, 03H65" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1011.0835v1</id>
    <updated>2010-11-03T10:05:15Z</updated>
    <published>2010-11-03T10:05:15Z</published>
    <title>A PDTB-Styled End-to-End Discourse Parser</title>
    <summary>  We have developed a full discourse parser in the Penn Discourse Treebank
(PDTB) style. Our trained parser first identifies all discourse and
non-discourse relations, locates and labels their arguments, and then
classifies their relation types. When appropriate, the attribution spans to
these relations are also determined. We present a comprehensive evaluation from
both component-wise and error-cascading perspectives.
</summary>
    <author>
      <name>Ziheng Lin</name>
    </author>
    <author>
      <name>Hwee Tou Ng</name>
    </author>
    <author>
      <name>Min-Yen Kan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 5 figures, 7 tables</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Natural Language Engineering 20 (02), 151 - 184, 2014</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1011.0835v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1011.0835v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1011.2922v1</id>
    <updated>2010-11-12T14:43:04Z</updated>
    <published>2010-11-12T14:43:04Z</published>
    <title>Emoticonsciousness</title>
    <summary>  A temporal analysis of emoticon use in Swedish, Italian, German and English
asynchronous electronic communication is reported. Emoticons are classified as
positive, negative and neutral. Postings to newsgroups over a 66 week period
are considered. The aggregate analysis of emoticon use in newsgroups for
science and politics tend on the whole to be consistent over the entire time
period. Where possible, events that coincide with divergences from trends in
language-subject pairs are noted. Political discourse in Italian over the
period shows marked use of negative emoticons, and in Swedish, positive
emoticons.
</summary>
    <author>
      <name>Carl Vogel</name>
    </author>
    <author>
      <name>Jerom Janssen</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-642-12397-9_2</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-642-12397-9_2" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">COST Action 2102 and euCognition International School Vietri sul
  Mare, Italy, April 21-26, 2008 Revised Selected and Invited Papers</arxiv:comment>
    <link href="http://arxiv.org/abs/1011.2922v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1011.2922v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91C99" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.4; J.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1011.4155v1</id>
    <updated>2010-11-18T08:59:55Z</updated>
    <published>2010-11-18T08:59:55Z</published>
    <title>Motifs de graphe pour le calcul de dépendances syntaxiques complètes</title>
    <summary>  This article describes a method to build syntactical dependencies starting
from the phrase structure parsing process. The goal is to obtain all the
information needed for a detailled semantical analysis. Interaction Grammars
are used for parsing; the saturation of polarities which is the core of this
formalism can be mapped to dependency relation. Formally, graph patterns are
used to express the set of constraints which control dependency creations.
</summary>
    <author>
      <name>Jonathan Marchand</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Lorraine - LORIA</arxiv:affiliation>
    </author>
    <author>
      <name>Bruno Guillaume</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Lorraine - LORIA</arxiv:affiliation>
    </author>
    <author>
      <name>Guy Perrier</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Lorraine - LORIA</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Conf\'erence sur le Traitement Automatique des Langues Naturelles
  - TALN'10, Montr\'eal : Canada (2010)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1011.4155v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1011.4155v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1011.5209v2</id>
    <updated>2011-01-29T10:31:58Z</updated>
    <published>2010-11-23T20:11:35Z</published>
    <title>The semantic mapping of words and co-words in contexts</title>
    <summary>  Meaning can be generated when information is related at a systemic level.
Such a system can be an observer, but also a discourse, for example,
operationalized as a set of documents. The measurement of semantics as
similarity in patterns (correlations) and latent variables (factor analysis)
has been enhanced by computer techniques and the use of statistics; for
example, in "Latent Semantic Analysis". This communication provides an
introduction, an example, pointers to relevant software, and summarizes the
choices that can be made by the analyst. Visualization ("semantic mapping") is
thus made more accessible.
</summary>
    <author>
      <name>Loet Leydesdorff</name>
    </author>
    <author>
      <name>Kasper Welbers</name>
    </author>
    <link href="http://arxiv.org/abs/1011.5209v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1011.5209v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1101.5494v1</id>
    <updated>2011-01-28T09:58:39Z</updated>
    <published>2011-01-28T09:58:39Z</published>
    <title>Developing a New Approach for Arabic Morphological Analysis and
  Generation</title>
    <summary>  Arabic morphological analysis is one of the essential stages in Arabic
Natural Language Processing. In this paper we present an approach for Arabic
morphological analysis. This approach is based on Arabic morphological
automaton (AMAUT). The proposed technique uses a morphological database
realized using XMODEL language. Arabic morphology represents a special type of
morphological systems because it is based on the concept of scheme to represent
Arabic words. We use this concept to develop the Arabic morphological automata.
The proposed approach has development standardization aspect. It can be
exploited by NLP applications such as syntactic and semantic analysis,
information retrieval, machine translation and orthographical correction. The
proposed approach is compared with Xerox Arabic Analyzer and Smrz Arabic
Analyzer.
</summary>
    <author>
      <name>Mourad Gridach</name>
    </author>
    <author>
      <name>Noureddine Chenfour</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, 15 figures, 7 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1101.5494v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1101.5494v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1101.5757v1</id>
    <updated>2011-01-30T10:41:46Z</updated>
    <published>2011-01-30T10:41:46Z</published>
    <title>Polarized Montagovian Semantics for the Lambek-Grishin calculus</title>
    <summary>  Grishin proposed enriching the Lambek calculus with multiplicative
disjunction (par) and coresiduals. Applications to linguistics were discussed
by Moortgat, who spoke of the Lambek-Grishin calculus (LG). In this paper, we
adapt Girard's polarity-sensitive double negation embedding for classical logic
to extract a compositional Montagovian semantics from a display calculus for
focused proof search in LG. We seize the opportunity to illustrate our approach
alongside an analysis of extraction, providing linguistic motivation for linear
distributivity of tensor over par, thus answering a question of
Kurtonina&amp;Moortgat. We conclude by comparing our proposal to the continuation
semantics of Bernardi&amp;Moortgat, corresponding to call-by- name and
call-by-value evaluation strategies.
</summary>
    <author>
      <name>Arno Bastenhof</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in the proceedings of the 15th conference on Formal
  Grammar, Copenhagen, 2010</arxiv:comment>
    <link href="http://arxiv.org/abs/1101.5757v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1101.5757v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.5676v1</id>
    <updated>2011-03-29T15:05:11Z</updated>
    <published>2011-03-29T15:05:11Z</published>
    <title>Codeco: A Grammar Notation for Controlled Natural Language in Predictive
  Editors</title>
    <summary>  Existing grammar frameworks do not work out particularly well for controlled
natural languages (CNL), especially if they are to be used in predictive
editors. I introduce in this paper a new grammar notation, called Codeco, which
is designed specifically for CNLs and predictive editors. Two different parsers
have been implemented and a large subset of Attempto Controlled English (ACE)
has been represented in Codeco. The results show that Codeco is practical,
adequate and efficient.
</summary>
    <author>
      <name>Tobias Kuhn</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">In Pre-Proceedings of the Second Workshop on Controlled Natural
  Languages (CNL 2010), CEUR Workshop Proceedings, Volume 622, 2010</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1103.5676v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.5676v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.2; F.4.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1104.2034v1</id>
    <updated>2011-04-11T19:50:50Z</updated>
    <published>2011-04-11T19:50:50Z</published>
    <title>Materials to the Russian-Bulgarian Comparative Dictionary "EAD"</title>
    <summary>  This article presents a fragment of a new comparative dictionary "A
comparative dictionary of names of expansive action in Russian and Bulgarian
languages". Main features of the new web-based comparative dictionary are
placed, the principles of its formation are shown, primary links between the
word-matches are classified. The principal difference between translation
dictionaries and the model of double comparison is also shown. The
classification scheme of the pages is proposed. New concepts and keywords have
been introduced. The real prototype of the dictionary with a few key pages is
published. The broad debate about the possibility of this prototype to become a
version of Russian-Bulgarian comparative dictionary of a new generation is
available.
</summary>
    <author>
      <name>Yavor Angelov Parvanov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Bulgarian Rusistics; Vol. 1 (2010)</arxiv:comment>
    <link href="http://arxiv.org/abs/1104.2034v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1104.2034v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1104.2086v1</id>
    <updated>2011-04-11T23:06:54Z</updated>
    <published>2011-04-11T23:06:54Z</published>
    <title>A Universal Part-of-Speech Tagset</title>
    <summary>  To facilitate future research in unsupervised induction of syntactic
structure and to standardize best-practices, we propose a tagset that consists
of twelve universal part-of-speech categories. In addition to the tagset, we
develop a mapping from 25 different treebank tagsets to this universal set. As
a result, when combined with the original treebank data, this universal tagset
and mapping produce a dataset consisting of common parts-of-speech for 22
different languages. We highlight the use of this resource via two experiments,
including one that reports competitive accuracies for unsupervised grammar
induction without gold standard part-of-speech tags.
</summary>
    <author>
      <name>Slav Petrov</name>
    </author>
    <author>
      <name>Dipanjan Das</name>
    </author>
    <author>
      <name>Ryan McDonald</name>
    </author>
    <link href="http://arxiv.org/abs/1104.2086v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1104.2086v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1105.1072v1</id>
    <updated>2011-05-05T13:51:46Z</updated>
    <published>2011-05-05T13:51:46Z</published>
    <title>English-Lithuanian-English Machine Translation lexicon and engine:
  current state and future work</title>
    <summary>  This article overviews the current state of the English-Lithuanian-English
machine translation system. The first part of the article describes the
problems that system poses today and what actions will be taken to solve them
in the future. The second part of the article tackles the main issue of the
translation process. Article briefly overviews the word sense disambiguation
for MT technique using Google.
</summary>
    <author>
      <name>G. Barisevičius</name>
    </author>
    <author>
      <name>B. Tamulynas</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Informacin\.{e}s technologijos 2006 : conference proceedings /
  Kaunas University of Technology. T. 1. Kaunas : Technologija, 2006. p.
  109-112</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1105.1072v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1105.1072v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1107.4687v2</id>
    <updated>2011-10-07T09:50:12Z</updated>
    <published>2011-07-23T12:56:02Z</published>
    <title>Fence - An Efficient Parser with Ambiguity Support for Model-Driven
  Language Specification</title>
    <summary>  Model-based language specification has applications in the implementation of
language processors, the design of domain-specific languages, model-driven
software development, data integration, text mining, natural language
processing, and corpus-based induction of models. Model-based language
specification decouples language design from language processing and, unlike
traditional grammar-driven approaches, which constrain language designers to
specific kinds of grammars, it needs general parser generators able to deal
with ambiguities. In this paper, we propose Fence, an efficient bottom-up
parsing algorithm with lexical and syntactic ambiguity support that enables the
use of model-based language specification in practice.
</summary>
    <author>
      <name>Luis Quesada</name>
    </author>
    <author>
      <name>Fernando Berzal</name>
    </author>
    <author>
      <name>Francisco J. Cortijo</name>
    </author>
    <link href="http://arxiv.org/abs/1107.4687v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1107.4687v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1107.5752v2</id>
    <updated>2011-09-12T19:29:29Z</updated>
    <published>2011-07-28T15:59:21Z</published>
    <title>An Effective Approach to Biomedical Information Extraction with Limited
  Training Data</title>
    <summary>  Overall, the two main contributions of this work include the application of
sentence simplification to association extraction as described above, and the
use of distributional semantics for concept extraction. The proposed work on
concept extraction amalgamates for the first time two diverse research areas
-distributional semantics and information extraction. This approach renders all
the advantages offered in other semi-supervised machine learning systems, and,
unlike other proposed semi-supervised approaches, it can be used on top of
different basic frameworks and algorithms.
http://gradworks.umi.com/34/49/3449837.html
</summary>
    <author>
      <name>Siddhartha Jonnalagadda</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper has been withdrawn</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Jonnalagadda S. An effective approach to biomedical information
  extraction with limited training data (PhD Dissertation, Arizona State
  University). 2011;</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1107.5752v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1107.5752v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1108.3850v1</id>
    <updated>2011-08-18T20:17:58Z</updated>
    <published>2011-08-18T20:17:58Z</published>
    <title>Solving puzzles described in English by automated translation to answer
  set programming and learning how to do that translation</title>
    <summary>  We present a system capable of automatically solving combinatorial logic
puzzles given in (simplified) English. It involves translating the English
descriptions of the puzzles into answer set programming(ASP) and using ASP
solvers to provide solutions of the puzzles. To translate the descriptions, we
use a lambda-calculus based approach using Probabilistic Combinatorial
Categorial Grammars (PCCG) where the meanings of words are associated with
parameters to be able to distinguish between multiple meanings of the same
word. Meaning of many words and the parameters are learned. The puzzles are
represented in ASP using an ontology which is applicable to a large set of
logic puzzles.
</summary>
    <author>
      <name>Chitta Baral</name>
    </author>
    <author>
      <name>Juraj Dzifcak</name>
    </author>
    <link href="http://arxiv.org/abs/1108.3850v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1108.3850v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1108.4052v1</id>
    <updated>2011-08-19T21:41:29Z</updated>
    <published>2011-08-19T21:41:29Z</published>
    <title>Query Expansion: Term Selection using the EWC Semantic Relatedness
  Measure</title>
    <summary>  This paper investigates the efficiency of the EWC semantic relatedness
measure in an ad-hoc retrieval task. This measure combines the Wikipedia-based
Explicit Semantic Analysis measure, the WordNet path measure and the mixed
collocation index. In the experiments, the open source search engine Terrier
was utilised as a tool to index and retrieve data. The proposed technique was
tested on the NTCIR data collection. The experiments demonstrated promising
results.
</summary>
    <author>
      <name>Vitaly Klyuev</name>
    </author>
    <author>
      <name>Yannis Haralambous</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 1 figure, accepted at ASIR'11
  &lt;http://fedcsis.org/?q=node/62&gt;</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of 1st International Workshop on Advances in Semantic
  Information Retrieval (ASIR'11), Szczecin, Poland, September 18-21, 2011</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1108.4052v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1108.4052v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1108.4297v1</id>
    <updated>2011-08-22T12:55:20Z</updated>
    <published>2011-08-22T12:55:20Z</published>
    <title>Why is language well-designed for communication? (Commentary on
  Christiansen and Chater: 'Language as shaped by the brain')</title>
    <summary>  Selection through iterated learning explains no more than other
non-functional accounts, such as universal grammar, why language is so
well-designed for communicative efficiency. It does not predict several
distinctive features of language like central embedding, large lexicons or the
lack of iconicity, that seem to serve communication purposes at the expense of
learnability.
</summary>
    <author>
      <name>Jean-Louis Dessalles</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INFRES, LTCI</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">jld-08041101</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Behavioral and Brain Sciences 31, 5 (2008) 518-519</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1108.4297v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1108.4297v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1108.5017v1</id>
    <updated>2011-08-25T06:08:16Z</updated>
    <published>2011-08-25T06:08:16Z</published>
    <title>Event in Compositional Dynamic Semantics</title>
    <summary>  We present a framework which constructs an event-style dis- course semantics.
The discourse dynamics are encoded in continuation semantics and various
rhetorical relations are embedded in the resulting interpretation of the
framework. We assume discourse and sentence are distinct semantic objects, that
play different roles in meaning evalua- tion. Moreover, two sets of composition
functions, for handling different discourse relations, are introduced. The
paper first gives the necessary background and motivation for event and dynamic
semantics, then the framework with detailed examples will be introduced.
</summary>
    <author>
      <name>Sai Qian</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LORIA</arxiv:affiliation>
    </author>
    <author>
      <name>Maxime Amblard</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LORIA</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages; Logical Aspect of Computational Linguistic, Montpellier :
  France (2011)</arxiv:comment>
    <link href="http://arxiv.org/abs/1108.5017v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1108.5017v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1108.5027v1</id>
    <updated>2011-08-25T07:22:09Z</updated>
    <published>2011-08-25T07:22:09Z</published>
    <title>Encoding Phases using Commutativity and Non-commutativity in a Logical
  Framework</title>
    <summary>  This article presents an extension of Minimalist Categorial Gram- mars (MCG)
to encode Chomsky's phases. These grammars are based on Par- tially Commutative
Logic (PCL) and encode properties of Minimalist Grammars (MG) of Stabler. The
first implementation of MCG were using both non- commutative properties (to
respect the linear word order in an utterance) and commutative ones (to model
features of different constituents). Here, we pro- pose to adding Chomsky's
phases with the non-commutative tensor product of the logic. Then we could give
account of the PIC just by using logical prop- erties of the framework.
</summary>
    <author>
      <name>Maxime Amblard</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LORIA</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Logical Aspect of Computational Linguistic, Montpellier : France
  (2011)</arxiv:comment>
    <link href="http://arxiv.org/abs/1108.5027v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1108.5027v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1108.5096v1</id>
    <updated>2011-08-25T14:15:46Z</updated>
    <published>2011-08-25T14:15:46Z</published>
    <title>Minimalist Grammars and Minimalist Categorial Grammars, definitions
  toward inclusion of generated languages</title>
    <summary>  Stabler proposes an implementation of the Chomskyan Minimalist Program,
Chomsky 95 with Minimalist Grammars - MG, Stabler 97. This framework inherits a
long linguistic tradition. But the semantic calculus is more easily added if
one uses the Curry-Howard isomorphism. Minimalist Categorial Grammars - MCG,
based on an extension of the Lambek calculus, the mixed logic, were introduced
to provide a theoretically-motivated syntax-semantics interface, Amblard 07. In
this article, we give full definitions of MG with algebraic tree descriptions
and of MCG, and take the first steps towards giving a proof of inclusion of
their generated languages.
</summary>
    <author>
      <name>Maxime Amblard</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LORIA</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Logic and Grammar (2011) 1-20</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1108.5096v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1108.5096v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1108.5974v1</id>
    <updated>2011-08-30T14:45:41Z</updated>
    <published>2011-08-30T14:45:41Z</published>
    <title>Emotional Analysis of Blogs and Forums Data</title>
    <summary>  We perform a statistical analysis of emotionally annotated comments in two
large online datasets, examining chains of consecutive posts in the
discussions. Using comparisons with randomised data we show that there is a
high level of correlation for the emotional content of messages.
</summary>
    <author>
      <name>Paweł Weroński</name>
    </author>
    <author>
      <name>Julian Sienkiewicz</name>
    </author>
    <author>
      <name>Georgios Paltoglou</name>
    </author>
    <author>
      <name>Kevan Buckley</name>
    </author>
    <author>
      <name>Mike Thelwall</name>
    </author>
    <author>
      <name>Janusz A. Hołyst</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">REVTEX format, 5 pages, 6 figures, 2 tables, accepted to Acta Physica
  Polonica A</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Acta Physica Polonica A 121, B-128 (2012)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1108.5974v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1108.5974v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1109.0069v2</id>
    <updated>2014-04-20T16:56:40Z</updated>
    <published>2011-09-01T02:20:12Z</published>
    <title>Inter-rater Agreement on Sentence Formality</title>
    <summary>  Formality is one of the most important dimensions of writing style variation.
In this study we conducted an inter-rater reliability experiment for assessing
sentence formality on a five-point Likert scale, and obtained good agreement
results as well as different rating distributions for different sentence
categories. We also performed a difficulty analysis to identify the bottlenecks
of our rating procedure. Our main objective is to design an automatic scoring
mechanism for sentence-level formality, and this study is important for that
purpose.
</summary>
    <author>
      <name>Shibamouli Lahiri</name>
    </author>
    <author>
      <name>Xiaofei Lu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 1 figure, 1 table</arxiv:comment>
    <link href="http://arxiv.org/abs/1109.0069v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1109.0069v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.1; I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1109.0624v1</id>
    <updated>2011-09-03T14:30:44Z</updated>
    <published>2011-09-03T14:30:44Z</published>
    <title>Building Ontologies to Understand Spoken Tunisian Dialect</title>
    <summary>  This paper presents a method to understand spoken Tunisian dialect based on
lexical semantic. This method takes into account the specificity of the
Tunisian dialect which has no linguistic processing tools. This method is
ontology-based which allows exploiting the ontological concepts for semantic
annotation and ontological relations for speech interpretation. This
combination increases the rate of comprehension and limits the dependence on
linguistic resources. This paper also details the process of building the
ontology used for annotation and interpretation of Tunisian dialect in the
context of speech understanding in dialogue systems for restricted domain.
</summary>
    <author>
      <name>Marwa Graja</name>
    </author>
    <author>
      <name>Maher Jaoua</name>
    </author>
    <author>
      <name>Lamia Hadrich Belguith</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 3 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Science, Engineering and
  Applications (IJCSEA) Vol.1, No.4, August 2011</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1109.0624v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1109.0624v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1109.5798v1</id>
    <updated>2011-09-27T08:00:46Z</updated>
    <published>2011-09-27T08:00:46Z</published>
    <title>Object-oriented semantics of English in natural language understanding
  system</title>
    <summary>  A new approach to the problem of natural language understanding is proposed.
The knowledge domain under consideration is the social behavior of people.
English sentences are translated into set of predicates of a semantic database,
which describe persons, occupations, organizations, projects, actions, events,
messages, machines, things, animals, location and time of actions, relations
between objects, thoughts, cause-and-effect relations, abstract objects. There
is a knowledge base containing the description of semantics of objects
(functions and structure), actions (motives and causes), and operations.
</summary>
    <author>
      <name>Yuriy Ostapov</name>
    </author>
    <link href="http://arxiv.org/abs/1109.5798v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1109.5798v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1110.1758v2</id>
    <updated>2012-03-04T19:00:21Z</updated>
    <published>2011-10-08T19:15:12Z</published>
    <title>Data formats for phonological corpora</title>
    <summary>  The goal of the present chapter is to explore the possibility of providing
the research (but also the industrial) community that commonly uses spoken
corpora with a stable portfolio of well-documented standardised formats that
allow a high re-use rate of annotated spoken resources and, as a consequence,
better interoperability across tools used to produce or exploit such resources.
</summary>
    <author>
      <name>Laurent Romary</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IDSL, INRIA Saclay - Ile de France</arxiv:affiliation>
    </author>
    <author>
      <name>Andreas Witt</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IDS</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Handbook of Corpus Phonology Oxford University Press (Ed.) (2012)</arxiv:comment>
    <link href="http://arxiv.org/abs/1110.1758v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1110.1758v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1110.4248v1</id>
    <updated>2011-10-19T11:45:16Z</updated>
    <published>2011-10-19T11:45:16Z</published>
    <title>Ideogram Based Chinese Sentiment Word Orientation Computation</title>
    <summary>  This paper presents a novel algorithm to compute sentiment orientation of
Chinese sentiment word. The algorithm uses ideograms which are a distinguishing
feature of Chinese language. The proposed algorithm can be applied to any
sentiment classification scheme. To compute a word's sentiment orientation
using the proposed algorithm, only the word itself and a precomputed character
ontology is required, rather than a corpus. The influence of three parameters
over the algorithm performance is analyzed and verified by experiment.
Experiment also shows that proposed algorithm achieves an F Measure of 85.02%
outperforming existing ideogram based algorithm.
</summary>
    <author>
      <name>Luojie Xiang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 3 figures, accepted by CET 2011</arxiv:comment>
    <link href="http://arxiv.org/abs/1110.4248v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1110.4248v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.1673v1</id>
    <updated>2011-11-07T18:46:54Z</updated>
    <published>2011-11-07T18:46:54Z</published>
    <title>Algebras over a field and semantics for context based reasoning</title>
    <summary>  This paper introduces context algebras and demonstrates their application to
combining logical and vector-based representations of meaning. Other approaches
to this problem attempt to reproduce aspects of logical semantics within new
frameworks. The approach we present here is different: We show how logical
semantics can be embedded within a vector space framework, and use this to
combine distributional semantics, in which the meanings of words are
represented as vectors, with logical semantics, in which the meaning of a
sentence is represented as a logical form.
</summary>
    <author>
      <name>Daoud Clarke</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Draft chapter for a proposed Oxford University Press volume
  "Compositional methods in Physics and Linguistics"</arxiv:comment>
    <link href="http://arxiv.org/abs/1111.1673v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.1673v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.3152v1</id>
    <updated>2011-11-14T09:34:34Z</updated>
    <published>2011-11-14T09:34:34Z</published>
    <title>Évaluation de lexiques syntaxiques par leur intégartion dans
  l'analyseur syntaxiques FRMG</title>
    <summary>  In this paper, we evaluate various French lexica with the parser FRMG: the
Lefff, LGLex, the lexicon built from the tables of the French Lexicon-Grammar,
the lexicon DICOVALENCE and a new version of the verbal entries of the Lefff,
obtained by merging with DICOVALENCE and partial manual validation. For this,
all these lexica have been converted to the format of the Lefff, Alexina
format. The evaluation was made on the part of the EASy corpus used in the
first evaluation campaign Passage.
</summary>
    <author>
      <name>Elsa Tolone</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIGM, FaMAF</arxiv:affiliation>
    </author>
    <author>
      <name>Éric De La Clergerie</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rocquencourt</arxiv:affiliation>
    </author>
    <author>
      <name>Sagot Benoit</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rocquencourt</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">30\`eme Colloque international sur le Lexique et la Grammaire
  (LGC'11), Nicosie : Chypre (2011)</arxiv:comment>
    <link href="http://arxiv.org/abs/1111.3152v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.3152v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.3153v1</id>
    <updated>2011-11-14T09:34:59Z</updated>
    <published>2011-11-14T09:34:59Z</published>
    <title>Construction du lexique LGLex à partir des tables du Lexique-Grammaire
  des verbes du grec moderne</title>
    <summary>  In this paper, we summerize the work done on the resources of Modern Greek on
the Lexicon-Grammar of verbs. We detail the definitional features of each
table, and all changes made to the names of features to make them consistent.
Through the development of the table of classes, including all the features, we
have considered the conversion of tables in a syntactic lexicon: LGLex. The
lexicon, in plain text format or XML, is generated by the LGExtract tool
(Constant &amp; Tolone, 2010). This format is directly usable in applications of
Natural Language Processing (NLP).
</summary>
    <author>
      <name>Kyriaki Ioannidou</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LTTL</arxiv:affiliation>
    </author>
    <author>
      <name>Elsa Tolone</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIGM, FaMAF</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">30\`eme Colloque international sur le Lexique et la Grammaire
  (LGC'11), Nicosie : Chypre (2011)</arxiv:comment>
    <link href="http://arxiv.org/abs/1111.3153v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.3153v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1112.0168v1</id>
    <updated>2011-12-01T12:52:22Z</updated>
    <published>2011-12-01T12:52:22Z</published>
    <title>Statistical Sign Language Machine Translation: from English written text
  to American Sign Language Gloss</title>
    <summary>  This works aims to design a statistical machine translation from English text
to American Sign Language (ASL). The system is based on Moses tool with some
modifications and the results are synthesized through a 3D avatar for
interpretation. First, we translate the input text to gloss, a written form of
ASL. Second, we pass the output to the WebSign Plug-in to play the sign.
Contributions of this work are the use of a new couple of language English/ASL
and an improvement of statistical machine translation based on string matching
thanks to Jaro-distance.
</summary>
    <author>
      <name>Achraf Othman</name>
    </author>
    <author>
      <name>Mohamed Jemni</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IJCSI International Journal of Computer Science Issues, Vol. 8,
  Issue 5, No 3, 2011, 65-73</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1112.0168v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1112.0168v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1112.6384v1</id>
    <updated>2011-12-29T19:16:20Z</updated>
    <published>2011-12-29T19:16:20Z</published>
    <title>Proof nets for the Lambek-Grishin calculus</title>
    <summary>  Grishin's generalization of Lambek's Syntactic Calculus combines a
non-commutative multiplicative conjunction and its residuals (product, left and
right division) with a dual family: multiplicative disjunction, right and left
difference. Interaction between these two families takes the form of linear
distributivity principles. We study proof nets for the Lambek-Grishin calculus
and the correspondence between these nets and unfocused and focused versions of
its sequent calculus.
</summary>
    <author>
      <name>Michael Moortgat</name>
    </author>
    <author>
      <name>Richard Moot</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Revised version to appear as a chapter in E. Grefenstette, C. Heunen,
  and M. Sadrzadeh (eds.) 'Compositional Methods in Physics and Linguistics',
  Oxford University Press</arxiv:comment>
    <link href="http://arxiv.org/abs/1112.6384v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1112.6384v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1201.4733v1</id>
    <updated>2012-01-20T17:35:29Z</updated>
    <published>2012-01-20T17:35:29Z</published>
    <title>Du TAL au TIL</title>
    <summary>  Historically two types of NLP have been investigated: fully automated
processing of language by machines (NLP) and autonomous processing of natural
language by people, i.e. the human brain (psycholinguistics). We believe that
there is room and need for another kind, INLP: interactive natural language
processing. This intermediate approach starts from peoples' needs, trying to
bridge the gap between their actual knowledge and a given goal. Given the fact
that peoples' knowledge is variable and often incomplete, the aim is to build
bridges linking a given knowledge state to a given goal. We present some
examples, trying to show that this goal is worth pursuing, achievable and at a
reasonable cost.
</summary>
    <author>
      <name>Michael Zock</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIF</arxiv:affiliation>
    </author>
    <author>
      <name>Guy Lapalme</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">DIRO</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">TALN, Montr\'eal : Canada (2010)</arxiv:comment>
    <link href="http://arxiv.org/abs/1201.4733v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1201.4733v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.1054v1</id>
    <updated>2012-02-06T06:33:03Z</updated>
    <published>2012-02-06T06:33:03Z</published>
    <title>Considering a resource-light approach to learning verb valencies</title>
    <summary>  Here we describe work on learning the subcategories of verbs in a
morphologically rich language using only minimal linguistic resources. Our goal
is to learn verb subcategorizations for Quechua, an under-resourced
morphologically rich language, from an unannotated corpus. We compare results
from applying this approach to an unannotated Arabic corpus with those achieved
by processing the same text in treebank form. The original plan was to use only
a morphological analyzer and an unannotated corpus, but experiments suggest
that this approach by itself will not be effective for learning the
combinatorial potential of Arabic verbs in general. The lower bound on
resources for acquiring this information is somewhat higher, apparently
requiring a a part-of-speech tagger and chunker for most languages, and a
morphological disambiguater for Arabic.
</summary>
    <author>
      <name>Alex Rudnick</name>
    </author>
    <link href="http://arxiv.org/abs/1202.1054v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.1054v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.6266v1</id>
    <updated>2012-02-28T16:04:36Z</updated>
    <published>2012-02-28T16:04:36Z</published>
    <title>Realisation d'un systeme de reconnaissance automatique de la parole
  arabe base sur CMU Sphinx</title>
    <summary>  This paper presents the continuation of the work completed by Satori and all.
[SCH07] by the realization of an automatic speech recognition system (ASR) for
Arabic language based SPHINX 4 system. The previous work was limited to the
recognition of the first ten digits, whereas the present work is a remarkable
projection consisting in continuous Arabic speech recognition with a rate of
recognition of surroundings 96%.
</summary>
    <author>
      <name>Ali Sadiqui</name>
    </author>
    <author>
      <name>Noureddine Chenfour</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Ann. Univ. Tibiscus Comp. Sci. Series VIII / 1 (2010), 27-40</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1202.6266v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.6266v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.6583v1</id>
    <updated>2012-02-29T15:59:54Z</updated>
    <published>2012-02-29T15:59:54Z</published>
    <title>A Lexical Analysis Tool with Ambiguity Support</title>
    <summary>  Lexical ambiguities naturally arise in languages. We present Lamb, a lexical
analyzer that produces a lexical analysis graph describing all the possible
sequences of tokens that can be found within the input string. Parsers can
process such lexical analysis graphs and discard any sequence of tokens that
does not produce a valid syntactic sentence, therefore performing, together
with Lamb, a context-sensitive lexical analysis in lexically-ambiguous language
specifications.
</summary>
    <author>
      <name>Luis Quesada</name>
    </author>
    <author>
      <name>Fernando Berzal</name>
    </author>
    <author>
      <name>Francisco J. Cortijo</name>
    </author>
    <link href="http://arxiv.org/abs/1202.6583v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.6583v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1203.5055v1</id>
    <updated>2012-03-22T17:50:08Z</updated>
    <published>2012-03-22T17:50:08Z</published>
    <title>Using Signals to Improve Automatic Classification of Temporal Relations</title>
    <summary>  Temporal information conveyed by language describes how the world around us
changes through time. Events, durations and times are all temporal elements
that can be viewed as intervals. These intervals are sometimes temporally
related in text. Automatically determining the nature of such relations is a
complex and unsolved problem. Some words can act as "signals" which suggest a
temporal ordering between intervals. In this paper, we use these signal words
to improve the accuracy of a recent approach to classification of temporal
links.
</summary>
    <author>
      <name>Leon Derczynski</name>
    </author>
    <author>
      <name>Robert Gaizauskas</name>
    </author>
    <link href="http://arxiv.org/abs/1203.5055v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1203.5055v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
