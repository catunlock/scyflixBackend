<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3Dall%3Acs.CV%26id_list%3D%26start%3D0%26max_results%3D500" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=all:cs.CV&amp;id_list=&amp;start=0&amp;max_results=500</title>
  <id>http://arxiv.org/api/z4PXAfIIeZ2GtEBWISFkuSpCy9o</id>
  <updated>2017-10-08T00:00:00-04:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">13980</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">500</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/0903.0134v2</id>
    <updated>2010-01-08T10:32:52Z</updated>
    <published>2009-03-01T11:10:27Z</published>
    <title>Recognition of Regular Shapes in Satelite Images</title>
    <summary>  This paper has been withdrawn by the author ali pourmohammad.
</summary>
    <author>
      <name>Ahmad Reza Eskandari</name>
    </author>
    <author>
      <name>Ali Pourmohammad</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper has been withdrawn</arxiv:comment>
    <link href="http://arxiv.org/abs/0903.0134v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0903.0134v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1010.0422v1</id>
    <updated>2010-10-03T16:55:56Z</updated>
    <published>2010-10-03T16:55:56Z</published>
    <title>Convolutional Matching Pursuit and Dictionary Training</title>
    <summary>  Matching pursuit and K-SVD is demonstrated in the translation invariant
setting
</summary>
    <author>
      <name>Arthur Szlam</name>
    </author>
    <author>
      <name>Koray Kavukcuoglu</name>
    </author>
    <author>
      <name>Yann LeCun</name>
    </author>
    <link href="http://arxiv.org/abs/1010.0422v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1010.0422v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1406.7120v1</id>
    <updated>2014-06-27T09:18:44Z</updated>
    <published>2014-06-27T09:18:44Z</published>
    <title>Template Matching based Object Detection Using HOG Feature Pyramid</title>
    <summary>  This article provides a step by step development of designing a Object
Detection scheme using the HOG based Feature Pyramid aligned with the concept
of Template Matching.
</summary>
    <author>
      <name>Anish Acharya</name>
    </author>
    <link href="http://arxiv.org/abs/1406.7120v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1406.7120v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.01243v1</id>
    <updated>2017-07-05T07:43:00Z</updated>
    <published>2017-07-05T07:43:00Z</published>
    <title>Exploration of object recognition from 3D point cloud</title>
    <summary>  We present our latest experiment results of object recognition from 3D point
cloud data collected through moving car.
</summary>
    <author>
      <name>Lin Duan</name>
    </author>
    <link href="http://arxiv.org/abs/1707.01243v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.01243v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0406047v1</id>
    <updated>2004-06-24T13:14:58Z</updated>
    <published>2004-06-24T13:14:58Z</published>
    <title>Self-organizing neural networks in classification and image recognition</title>
    <summary>  Self-organizing neural networks are used for brick finding in OPERA
experiment. Self-organizing neural networks and wavelet analysis used for
recognition and extraction of car numbers from images.
</summary>
    <author>
      <name>G. A. Ososkov</name>
    </author>
    <author>
      <name>S. G. Dmitrievskiy</name>
    </author>
    <author>
      <name>A. V. Stadnik</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0406047v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0406047v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0902.2788v2</id>
    <updated>2010-01-08T10:23:17Z</updated>
    <published>2009-02-16T21:13:35Z</published>
    <title>Using SLP Neural Network to Persian Handwritten Digits Recognition</title>
    <summary>  This paper has been withdrawn by the author ali pourmohammad.
</summary>
    <author>
      <name>Ali Pourmohammad</name>
    </author>
    <author>
      <name>Seyed Mohammad Ahadi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper has been withdrawn</arxiv:comment>
    <link href="http://arxiv.org/abs/0902.2788v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0902.2788v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0906.5120v1</id>
    <updated>2009-06-28T08:10:33Z</updated>
    <published>2009-06-28T08:10:33Z</published>
    <title>Comments on "A new combination of evidence based on compromise" by K.
  Yamada</title>
    <summary>  Comments on ``A new combination of evidence based on compromise'' by K.
Yamada
</summary>
    <author>
      <name>Jean Dezert</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">ONERA</arxiv:affiliation>
    </author>
    <author>
      <name>Arnaud Martin</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">E3I2</arxiv:affiliation>
    </author>
    <author>
      <name>Florentin Smarandache</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">UNM</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Fuzzy Sets and Systems 160, 6 (2009) 853-855</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0906.5120v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0906.5120v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.4; I.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0908.1369v1</id>
    <updated>2009-08-10T18:33:51Z</updated>
    <published>2009-08-10T18:33:51Z</published>
    <title>Segmentation for radar images based on active contour</title>
    <summary>  We exam various geometric active contour methods for radar image
segmentation. Due to special properties of radar images, we propose our new
model based on modified Chan-Vese functional. Our method is efficient in
separating non-meteorological noises from meteorological images.
</summary>
    <author>
      <name>Meijun Zhu</name>
    </author>
    <author>
      <name>Pengfei Zhang</name>
    </author>
    <link href="http://arxiv.org/abs/0908.1369v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0908.1369v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1004.4793v1</id>
    <updated>2010-04-27T13:22:36Z</updated>
    <published>2010-04-27T13:22:36Z</published>
    <title>Logical methods of object recognition on satellite images using spatial
  constraints</title>
    <summary>  A logical approach to object recognition on image is proposed. The main idea
of the approach is to perform the object recognition as a logical inference on
a set of rules describing an object shape.
</summary>
    <author>
      <name>R. K. Fedorov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1004.4793v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1004.4793v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.4.8; I.5.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1006.4910v2</id>
    <updated>2014-09-15T09:16:48Z</updated>
    <published>2010-06-25T04:51:32Z</published>
    <title>3D Visual Tracking with Particle and Kalman Filters</title>
    <summary>  One of the most visually demonstrable and straightforward uses of filtering
is in the field of Computer Vision. In this document we will try to outline the
issues encountered while designing and implementing a particle and kalman
filter based tracking system.
</summary>
    <author>
      <name>Burak Bayramli</name>
    </author>
    <link href="http://arxiv.org/abs/1006.4910v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1006.4910v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1107.2085v1</id>
    <updated>2011-07-11T18:44:17Z</updated>
    <published>2011-07-11T18:44:17Z</published>
    <title>Kunchenko's Polynomials for Template Matching</title>
    <summary>  This paper reviews Kunchenko's polynomials using as template matching method
to recognize template in one-dimensional input signal. Kunchenko's polynomials
method is compared with classical methods - cross-correlation and sum of
squared differences according to numerical statistical example.
</summary>
    <author>
      <name>Oleg Chertov</name>
    </author>
    <author>
      <name>Taras Slipets</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1107.2085v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1107.2085v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.5.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.0466v1</id>
    <updated>2011-11-02T11:42:37Z</updated>
    <published>2011-11-02T11:42:37Z</published>
    <title>Kernel diff-hash</title>
    <summary>  This paper presents a kernel formulation of the recently introduced diff-hash
algorithm for the construction of similarity-sensitive hash functions. Our
kernel diff-hash algorithm that shows superior performance on the problem of
image feature descriptor matching.
</summary>
    <author>
      <name>Michael M Bronstein</name>
    </author>
    <link href="http://arxiv.org/abs/1111.0466v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.0466v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.1615v1</id>
    <updated>2012-04-07T09:28:19Z</updated>
    <published>2012-04-07T09:28:19Z</published>
    <title>Discrimination between Arabic and Latin from bilingual documents</title>
    <summary>  2011 International Conference on Communications, Computing and Control
Applications (CCCA)
</summary>
    <author>
      <name>Sofiene Haboubi</name>
    </author>
    <author>
      <name>Samia Maddouri</name>
    </author>
    <author>
      <name>Hamid Amiri</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/CCCA.2011.6031496</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/CCCA.2011.6031496" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1204.1615v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.1615v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.0819v1</id>
    <updated>2012-12-04T18:39:14Z</updated>
    <published>2012-12-04T18:39:14Z</published>
    <title>A Topological Code for Plane Images</title>
    <summary>  It is proposed a new code for contours of plane images. This code was applied
for optical character recognition of printed and handwritten characters. One
can apply it to recognition of any visual images.
</summary>
    <author>
      <name>Evgeny Shchepin</name>
    </author>
    <link href="http://arxiv.org/abs/1212.0819v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.0819v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.GT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1303.1829v1</id>
    <updated>2013-03-07T21:15:29Z</updated>
    <published>2013-03-07T21:15:29Z</published>
    <title>Watersheds on edge or node weighted graphs "par l'exemple"</title>
    <summary>  Watersheds have been defined both for node and edge weighted graphs. We show
that they are identical: for each edge (resp.\ node) weighted graph exists a
node (resp. edge) weighted graph with the same minima and catchment basin.
</summary>
    <author>
      <name>Fernand Meyer</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1303.1829v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1303.1829v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.7948v2</id>
    <updated>2013-06-02T20:32:05Z</updated>
    <published>2013-04-30T10:41:26Z</published>
    <title>Convolutional Neural Networks learn compact local image descriptors</title>
    <summary>  A standard deep convolutional neural network paired with a suitable loss
function learns compact local image descriptors that perform comparably to
state-of-the art approaches.
</summary>
    <author>
      <name>Christian Osendorfer</name>
    </author>
    <author>
      <name>Justin Bayer</name>
    </author>
    <author>
      <name>Patrick van der Smagt</name>
    </author>
    <link href="http://arxiv.org/abs/1304.7948v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.7948v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1305.5905v1</id>
    <updated>2013-05-25T09:30:49Z</updated>
    <published>2013-05-25T09:30:49Z</published>
    <title>ÖAGM/AAPR 2013 - The 37th Annual Workshop of the Austrian Association
  for Pattern Recognition</title>
    <summary>  In this editorial, the organizers summarize facts and background about the
event.
</summary>
    <author>
      <name>Justus Piater</name>
    </author>
    <author>
      <name>Antonio J. Rodríguez Sánchez</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Part of the OAGM/AAPR 2013 proceedings (arXiv:1304.1876)</arxiv:comment>
    <link href="http://arxiv.org/abs/1305.5905v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1305.5905v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1309.0261v1</id>
    <updated>2013-09-01T20:35:17Z</updated>
    <published>2013-09-01T20:35:17Z</published>
    <title>Multi-Column Deep Neural Networks for Offline Handwritten Chinese
  Character Classification</title>
    <summary>  Our Multi-Column Deep Neural Networks achieve best known recognition rates on
Chinese characters from the ICDAR 2011 and 2013 offline handwriting
competitions, approaching human performance.
</summary>
    <author>
      <name>Dan Cireşan</name>
    </author>
    <author>
      <name>Jürgen Schmidhuber</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 1 figure, IDSIA tech report</arxiv:comment>
    <link href="http://arxiv.org/abs/1309.0261v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1309.0261v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.0365v1</id>
    <updated>2013-10-01T16:06:00Z</updated>
    <published>2013-10-01T16:06:00Z</published>
    <title>The complex-valued encoding for dicision-making based on aliasing data</title>
    <summary>  It is proposed a complex valued channel encoding for multidimensional data.
The basic approach contains overlapping of complex nonlinear mappings. Its
development leads to sparse representation of multi-channel data, increasing
their dimensions and the distance between the images.
</summary>
    <author>
      <name>P. A. Golovinski</name>
    </author>
    <author>
      <name>V. A. Astapenko</name>
    </author>
    <link href="http://arxiv.org/abs/1310.0365v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.0365v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1403.5590v1</id>
    <updated>2014-03-21T23:26:47Z</updated>
    <published>2014-03-21T23:26:47Z</published>
    <title>Continuous Optimization for Fields of Experts Denoising Works</title>
    <summary>  Several recent papers use image denoising with a Fields of Experts prior to
benchmark discrete optimization methods. We show that a non-linear least
squares solver significantly outperforms all known discrete methods on this
problem.
</summary>
    <author>
      <name>Petter Strandmark</name>
    </author>
    <author>
      <name>Sameer Agarwal</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1403.5590v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1403.5590v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1411.1446v1</id>
    <updated>2014-11-05T23:14:10Z</updated>
    <published>2014-11-05T23:14:10Z</published>
    <title>Electrocardiography Separation of Mother and Baby</title>
    <summary>  Extraction of Electrocardiography (ECG or EKG) signals of mother and baby is
a challenging task, because one single device is used and it receives a mixture
of multiple heart beats. In this paper, we would like to design a filter to
separate the signals from each other.
</summary>
    <author>
      <name>Wei Wang</name>
    </author>
    <link href="http://arxiv.org/abs/1411.1446v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1411.1446v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.5796v1</id>
    <updated>2014-12-18T10:32:57Z</updated>
    <published>2014-12-18T10:32:57Z</published>
    <title>Image Enhancement Using a Generalization of Homographic Function</title>
    <summary>  This paper presents a new method of gray level image enhancement, based on
point transforms. In order to define the transform function, it was used a
generalization of the homographic function.
</summary>
    <author>
      <name>Vasile Patrascu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The IEEE International Conference COMMUNICATIONS 2002, pp. 429-434,
  December 5-7, 2002, Bucharest, Romania</arxiv:comment>
    <link href="http://arxiv.org/abs/1412.5796v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.5796v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.01994v1</id>
    <updated>2015-11-06T07:18:56Z</updated>
    <published>2015-11-06T07:18:56Z</published>
    <title>Next Generation Multicuts for Semi-Planar Graphs</title>
    <summary>  We study the problem of multicut segmentation. We introduce modified versions
of the Semi-PlanarCC based on bounding Lagrange multipliers. We apply our work
to natural image segmentation.
</summary>
    <author>
      <name>Julian Yarkony</name>
    </author>
    <link href="http://arxiv.org/abs/1511.01994v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.01994v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.07963v1</id>
    <updated>2015-11-25T06:09:42Z</updated>
    <published>2015-11-25T06:09:42Z</published>
    <title>Calculate distance to object in the area where car, using video analysis</title>
    <summary>  The method of using video cameras installed on the car, to calculate the
distance to the object in its area of movement.
</summary>
    <author>
      <name>Elena Legchekova</name>
    </author>
    <author>
      <name>Oleg Titov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, in Russian</arxiv:comment>
    <link href="http://arxiv.org/abs/1511.07963v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.07963v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.07021v1</id>
    <updated>2016-01-26T13:41:48Z</updated>
    <published>2016-01-26T13:41:48Z</published>
    <title>Polyhedron Volume-Ratio-based Classification for Image Recognition</title>
    <summary>  In this paper, a novel method, called polyhedron volume ratio classification
(PVRC) is proposed for image recognition
</summary>
    <author>
      <name>Qingxiang Feng</name>
    </author>
    <author>
      <name>Jeng-Shyang Pan</name>
    </author>
    <author>
      <name>Jar-Ferr Yang</name>
    </author>
    <author>
      <name>Yang-Ting Chou</name>
    </author>
    <link href="http://arxiv.org/abs/1601.07021v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.07021v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.05518v1</id>
    <updated>2016-08-19T07:30:33Z</updated>
    <published>2016-08-19T07:30:33Z</published>
    <title>On the Existence of a Projective Reconstruction</title>
    <summary>  In this note we study the connection between the existence of a projective
reconstruction and the existence of a fundamental matrix satisfying the
epipolar constraints.
</summary>
    <author>
      <name>Hon-Leung Lee</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1608.05518v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.05518v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.08380v1</id>
    <updated>2017-01-29T13:42:14Z</updated>
    <published>2017-01-29T13:42:14Z</published>
    <title>The HASYv2 dataset</title>
    <summary>  This paper describes the HASYv2 dataset. HASY is a publicly available, free
of charge dataset of single symbols similar to MNIST. It contains 168233
instances of 369 classes. HASY contains two challenges: A classification
challenge with 10 pre-defined folds for 10-fold cross-validation and a
verification challenge.
</summary>
    <author>
      <name>Martin Thoma</name>
    </author>
    <link href="http://arxiv.org/abs/1701.08380v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.08380v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1702.01507v1</id>
    <updated>2017-02-06T06:32:14Z</updated>
    <published>2017-02-06T06:32:14Z</published>
    <title>Challenge of Multi-Camera Tracking</title>
    <summary>  Multi-camera tracking is quite different from single camera tracking, and it
faces new technology and system architecture challenges. By analyzing the
corresponding characteristics and disadvantages of the existing algorithms,
problems in multi-camera tracking are summarized and some new directions for
future work are also generalized.
</summary>
    <author>
      <name>Yong Wang</name>
    </author>
    <author>
      <name>Ke Lu</name>
    </author>
    <link href="http://arxiv.org/abs/1702.01507v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1702.01507v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.00523v1</id>
    <updated>2017-03-01T21:41:58Z</updated>
    <published>2017-03-01T21:41:58Z</published>
    <title>ISIC 2017 - Skin Lesion Analysis Towards Melanoma Detection</title>
    <summary>  Our system addresses Part 1, Lesion Segmentation and Part 3, Lesion
Classification of the ISIC 2017 challenge. Both algorithms make use of deep
convolutional networks to achieve the challenge objective.
</summary>
    <author>
      <name>Matt Berseth</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ISIC2017</arxiv:comment>
    <link href="http://arxiv.org/abs/1703.00523v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.00523v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.05165v2</id>
    <updated>2017-09-28T02:26:32Z</updated>
    <published>2017-03-15T14:18:23Z</published>
    <title>Automatic skin lesion segmentation with fully
  convolutional-deconvolutional networks</title>
    <summary>  This paper summarizes our method and validation results for the ISBI
Challenge 2017 - Skin Lesion Analysis Towards Melanoma Detection - Part I:
Lesion Segmentation
</summary>
    <author>
      <name>Yading Yuan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ISIC2017 challenge, 4 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1703.05165v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.05165v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.06942v1</id>
    <updated>2017-06-21T14:54:15Z</updated>
    <published>2017-06-21T14:54:15Z</published>
    <title>Graphcut Texture Synthesis for Single-Image Superresolution</title>
    <summary>  Texture synthesis has proven successful at imitating a wide variety of
textures. Adding additional constraints (in the form of a low-resolution
version of the texture to be synthesized) makes it possible to use texture
synthesis methods for texture superresolution.
</summary>
    <author>
      <name>Douglas Summers-Stay</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">NYU Master's Thesis from 2006</arxiv:comment>
    <link href="http://arxiv.org/abs/1706.06942v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.06942v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.03088v2</id>
    <updated>2017-07-12T04:38:13Z</updated>
    <published>2017-07-11T00:28:23Z</published>
    <title>Online Handwritten Mathematical Expressions Recognition System Using
  Fuzzy Neural Network</title>
    <summary>  The article describes developed information technology for online recognition
of handwritten mathematical expressions that based on proposed approaches to
handwritten symbols recognition and structural analysis.
</summary>
    <author>
      <name>E. Naderan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">in Russian</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ITHEA, Information Content and Processing, 2014, 1 (3) , 262-268</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1707.03088v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.03088v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9810003v1</id>
    <updated>1998-10-02T03:34:38Z</updated>
    <published>1998-10-02T03:34:38Z</published>
    <title>A Linear Shift Invariant Multiscale Transform</title>
    <summary>  This paper presents a multiscale decomposition algorithm. Unlike standard
wavelet transforms, the proposed operator is both linear and shift invariant.
The central idea is to obtain shift invariance by averaging the aligned wavelet
transform projections over all circular shifts of the signal. It is shown how
the same transform can be obtained by a linear filter bank.
</summary>
    <author>
      <name>Andreas Siebert</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 5 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings 1998 International Conference on Image Processing,
  Chicago, 4-7 October 1998</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/9810003v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9810003v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.4.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9810017v1</id>
    <updated>1998-10-19T20:46:16Z</updated>
    <published>1998-10-19T20:46:16Z</published>
    <title>General Theory of Image Normalization</title>
    <summary>  We give a systematic, abstract formulation of the image normalization method
as applied to a general group of image transformations, and then illustrate the
abstract analysis by applying it to the hierarchy of viewing transformations of
a planar object.
</summary>
    <author>
      <name>Stephen L. Adler</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">33 pages, plain tex, no figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/9810017v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9810017v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.10, I.4.7, I.4.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9908017v1</id>
    <updated>1999-08-26T17:18:49Z</updated>
    <published>1999-08-26T17:18:49Z</published>
    <title>A Differential Invariant for Zooming</title>
    <summary>  This paper presents an invariant under scaling and linear brightness change.
The invariant is based on differentials and therefore is a local feature.
Rotationally invariant 2-d differential Gaussian operators up to third order
are proposed for the implementation of the invariant. The performance is
analyzed by simulating a camera zoom-out.
</summary>
    <author>
      <name>Andreas Siebert</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 7 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings 1999 International Conference on Image Processing,
  Kobe, 25-28 October 1999</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/9908017v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9908017v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.4.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0001024v1</id>
    <updated>2000-01-25T16:09:37Z</updated>
    <published>2000-01-25T16:09:37Z</published>
    <title>A Parallel Algorithm for Dilated Contour Extraction from Bilevel Images</title>
    <summary>  We describe a simple, but efficient algorithm for the generation of dilated
contours from bilevel images. The initial part of the contour extraction is
explained to be a good candidate for parallel computer code generation. The
remainder of the algorithm is of linear nature.
</summary>
    <author>
      <name>B. R. Schlei</name>
    </author>
    <author>
      <name>L. Prasad</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, including 3 figures. For additional detail check
  http://www.nis.lanl.gov/~bschlei/labvis/index.html</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0001024v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0001024v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.10, D.1.3, G.1.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0003079v1</id>
    <updated>2000-03-26T23:18:43Z</updated>
    <published>2000-03-26T23:18:43Z</published>
    <title>Differential Invariants under Gamma Correction</title>
    <summary>  This paper presents invariants under gamma correction and similarity
transformations. The invariants are local features based on differentials which
are implemented using derivatives of the Gaussian. The use of the proposed
invariant representation is shown to yield improved correlation results in a
template matching scenario.
</summary>
    <author>
      <name>Andreas Siebert</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 12 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Vision Interface 2000, Montreal, 2000</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0003079v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0003079v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.4.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0006001v1</id>
    <updated>2000-05-31T23:37:48Z</updated>
    <published>2000-05-31T23:37:48Z</published>
    <title>Boosting the Differences: A fast Bayesian classifier neural network</title>
    <summary>  A Bayesian classifier that up-weights the differences in the attribute values
is discussed. Using four popular datasets from the UCI repository, some
interesting features of the network are illustrated. The network is suitable
for classification problems.
</summary>
    <author>
      <name>Ninan Sajeeth Philip</name>
    </author>
    <author>
      <name>K. Babu Joseph</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">latex 18pages no figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0006001v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0006001v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I1.2;F.1.1;F1.2;C1.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0006002v1</id>
    <updated>2000-05-31T23:52:31Z</updated>
    <published>2000-05-31T23:52:31Z</published>
    <title>Distorted English Alphabet Identification : An application of Difference
  Boosting Algorithm</title>
    <summary>  The difference-boosting algorithm is used on letters dataset from the UCI
repository to classify distorted raster images of English alphabets. In
contrast to rather complex networks, the difference-boosting is found to
produce comparable or better classification efficiency on this complex problem.
</summary>
    <author>
      <name>Ninan Sajeeth Philip</name>
    </author>
    <author>
      <name>K. Babu Joseph</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">latex 14pages no figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0006002v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0006002v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I1.2;F.1.1;F1.2;C1.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0006040v1</id>
    <updated>2000-06-28T18:34:14Z</updated>
    <published>2000-06-28T18:34:14Z</published>
    <title>Correlation over Decomposed Signals: A Non-Linear Approach to Fast and
  Effective Sequences Comparison</title>
    <summary>  A novel non-linear approach to fast and effective comparison of sequences is
presented, compared to the traditional cross-correlation operator, and
illustrated with respect to DNA sequences.
</summary>
    <author>
      <name>Luciano da Fontoura Costa</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0006040v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0006040v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.5.4; F.2.2; I.5.4; J.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0301001v1</id>
    <updated>2003-01-01T19:58:03Z</updated>
    <published>2003-01-01T19:58:03Z</published>
    <title>Least squares fitting of circles and lines</title>
    <summary>  We study theoretical and computational aspects of the least squares fit (LSF)
of circles and circular arcs. First we discuss the existence and uniqueness of
LSF and various parametrization schemes. Then we evaluate several popular
circle fitting algorithms and propose a new one that surpasses the existing
methods in reliability. We also discuss and compare direct (algebraic) circle
fits.
</summary>
    <author>
      <name>N. Chernov</name>
    </author>
    <author>
      <name>C. Lesort</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">26 pages, 14 figures, submitted</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0301001v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0301001v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.4.8; I.5.1; I.2.10; G.1.2; G.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0308034v1</id>
    <updated>2003-08-21T10:47:27Z</updated>
    <published>2003-08-21T10:47:27Z</published>
    <title>Fingerprint based bio-starter and bio-access</title>
    <summary>  In the paper will be presented a safety and security system based on
fingerprint technology. The results suggest a new scenario where the new cars
can use a fingerprint sensor integrated in car handle to allow access and in
the dashboard as starter button.
</summary>
    <author>
      <name>G. Iovane</name>
    </author>
    <author>
      <name>P. Giordano</name>
    </author>
    <author>
      <name>C. Iovane</name>
    </author>
    <author>
      <name>F. Rotulo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, Proceeding of Automotive 2003, Turin (Italy)</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0308034v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0308034v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.10, I.4, I.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0308035v1</id>
    <updated>2003-08-21T10:52:53Z</updated>
    <published>2003-08-21T10:52:53Z</published>
    <title>IS (Iris Security)</title>
    <summary>  In the paper will be presented a safety system based on iridology. The
results suggest a new scenario where the security problem in supervised and
unsupervised areas can be treat with the present system and the iris image
recognition.
</summary>
    <author>
      <name>G. Iovane</name>
    </author>
    <author>
      <name>F. S. Tortoriello</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, Proceeding of NIDays 2003 (Sponsored by National
  Instruments), Rome (Italy)</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0308035v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0308035v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.5, I.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0401018v1</id>
    <updated>2004-01-22T05:53:30Z</updated>
    <published>2004-01-22T05:53:30Z</published>
    <title>Factor Temporal Prognosis of Tick-Borne Encephalitis Foci Functioning on
  the South of Russian Far East</title>
    <summary>  A method of temporal factor prognosis of TE (tick-borne encephalitis)
infection has been developed. The high precision of the prognosis results for a
number of geographical regions of Primorsky Krai has been achieved. The method
can be applied not only to epidemiological research but also to others.
</summary>
    <author>
      <name>E. I. Bolotin</name>
    </author>
    <author>
      <name>G. Sh. Tsitsiashvili</name>
    </author>
    <author>
      <name>I. V. Golycheva</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0401018v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0401018v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="B.1.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0608073v1</id>
    <updated>2006-08-18T08:28:23Z</updated>
    <published>2006-08-18T08:28:23Z</published>
    <title>Parametrical Neural Networks and Some Other Similar Architectures</title>
    <summary>  A review of works on associative neural networks accomplished during last
four years in the Institute of Optical Neural Technologies RAS is given. The
presentation is based on description of parametrical neural networks (PNN). For
today PNN have record recognizing characteristics (storage capacity, noise
immunity and speed of operation). Presentation of basic ideas and principles is
accentuated.
</summary>
    <author>
      <name>Leonid B. Litinskii</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 2 figures, accepted for publication in "Optical Memory &amp;
  Neural Networks" (2006)</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0608073v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0608073v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0609164v1</id>
    <updated>2006-09-29T13:48:35Z</updated>
    <published>2006-09-29T13:48:35Z</published>
    <title>Conditional Expressions for Blind Deconvolution: Multi-point form</title>
    <summary>  We present conditional expression (CE) for finding blurs convolved in given
images. The CE is given in terms of the zero-values of the blurs evaluated at
multi-point. The CE can detect multiple blur all at once. We illustrate the
multiple blur-detection by using a test image.
</summary>
    <author>
      <name>S. Aogaki</name>
    </author>
    <author>
      <name>I. Moritani</name>
    </author>
    <author>
      <name>T. Sugai</name>
    </author>
    <author>
      <name>F. Takeutchi</name>
    </author>
    <author>
      <name>F. M. Toyama</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 3 figures, conference</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0609164v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0609164v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0609165v1</id>
    <updated>2006-09-29T13:50:12Z</updated>
    <published>2006-09-29T13:50:12Z</published>
    <title>Simple method to eliminate blur based on Lane and Bates algorithm</title>
    <summary>  A simple search method for finding a blur convolved in a given image is
presented. The method can be easily extended to a large blur. The method has
been experimentally tested with a model blurred image.
</summary>
    <author>
      <name>S. Aogaki</name>
    </author>
    <author>
      <name>I. Moritani</name>
    </author>
    <author>
      <name>T. Sugai</name>
    </author>
    <author>
      <name>F. Takeutchi</name>
    </author>
    <author>
      <name>F. M. Toyama</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3 pages, 2 figures, conference</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0609165v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0609165v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0705.0214v1</id>
    <updated>2007-05-02T07:32:58Z</updated>
    <published>2007-05-02T07:32:58Z</published>
    <title>Riemannian level-set methods for tensor-valued data</title>
    <summary>  We present a novel approach for the derivation of PDE modeling
curvature-driven flows for matrix-valued data. This approach is based on the
Riemannian geometry of the manifold of Symmetric Positive Definite Matrices
Pos(n).
</summary>
    <author>
      <name>Mourad Zerai</name>
    </author>
    <author>
      <name>Maher Moakher</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 03 figures, to be published in the proceedings of SSVM
  2007, LNCS Springer</arxiv:comment>
    <link href="http://arxiv.org/abs/0705.0214v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0705.0214v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.4.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0706.0300v1</id>
    <updated>2007-06-03T05:17:38Z</updated>
    <published>2007-06-03T05:17:38Z</published>
    <title>Automatic Detection of Pulmonary Embolism using Computational
  Intelligence</title>
    <summary>  This article describes the implementation of a system designed to
automatically detect the presence of pulmonary embolism in lung scans. These
images are firstly segmented, before alignment and feature extraction using
PCA. The neural network was trained using the Hybrid Monte Carlo method,
resulting in a committee of 250 neural networks and good results are obtained.
</summary>
    <author>
      <name>Simon Scurrell</name>
    </author>
    <author>
      <name>Tshilidzi Marwala</name>
    </author>
    <author>
      <name>David Rubin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/0706.0300v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0706.0300v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0712.0131v1</id>
    <updated>2007-12-02T10:02:01Z</updated>
    <published>2007-12-02T10:02:01Z</published>
    <title>Learning Similarity for Character Recognition and 3D Object Recognition</title>
    <summary>  I describe an approach to similarity motivated by Bayesian methods. This
yields a similarity function that is learnable using a standard Bayesian
methods. The relationship of the approach to variable kernel and variable
metric methods is discussed. The approach is related to variable kernel
Experimental results on character recognition and 3D object recognition are
presented..
</summary>
    <author>
      <name>Thomas M. Breuel</name>
    </author>
    <link href="http://arxiv.org/abs/0712.0131v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0712.0131v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0712.2923v1</id>
    <updated>2007-12-18T10:43:23Z</updated>
    <published>2007-12-18T10:43:23Z</published>
    <title>A Class of LULU Operators on Multi-Dimensional Arrays</title>
    <summary>  The LULU operators for sequences are extended to multi-dimensional arrays via
the morphological concept of connection in a way which preserves their
essential properties, e.g. they are separators and form a four element fully
ordered semi-group. The power of the operators is demonstrated by deriving a
total variation preserving discrete pulse decomposition of images.
</summary>
    <author>
      <name>Roumen Anguelov</name>
    </author>
    <author>
      <name>Inger Plaskitt</name>
    </author>
    <link href="http://arxiv.org/abs/0712.2923v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0712.2923v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0802.1258v1</id>
    <updated>2008-02-09T12:22:47Z</updated>
    <published>2008-02-09T12:22:47Z</published>
    <title>Bayesian Nonlinear Principal Component Analysis Using Random Fields</title>
    <summary>  We propose a novel model for nonlinear dimension reduction motivated by the
probabilistic formulation of principal component analysis. Nonlinearity is
achieved by specifying different transformation matrices at different locations
of the latent space and smoothing the transformation using a Markov random
field type prior. The computation is made feasible by the recent advances in
sampling from von Mises-Fisher distributions.
</summary>
    <author>
      <name>Heng Lian</name>
    </author>
    <link href="http://arxiv.org/abs/0802.1258v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0802.1258v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0805.2690v1</id>
    <updated>2008-05-17T17:15:26Z</updated>
    <published>2008-05-17T17:15:26Z</published>
    <title>Increasing Linear Dynamic Range of Commercial Digital Photocamera Used
  in Imaging Systems with Optical Coding</title>
    <summary>  Methods of increasing linear optical dynamic range of commercial photocamera
for optical-digital imaging systems are described. Use of such methods allows
to use commercial photocameras for optical measurements. Experimental results
are reported.
</summary>
    <author>
      <name>M. V. Konnik</name>
    </author>
    <author>
      <name>E. A. Manykin</name>
    </author>
    <author>
      <name>S. N. Starikov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">unnecessary figures were removed; typos corrected</arxiv:comment>
    <link href="http://arxiv.org/abs/0805.2690v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0805.2690v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0806.3885v1</id>
    <updated>2008-06-24T13:43:06Z</updated>
    <published>2008-06-24T13:43:06Z</published>
    <title>Conceptualization of seeded region growing by pixels aggregation. Part
  1: the framework</title>
    <summary>  Adams and Bishop have proposed in 1994 a novel region growing algorithm
called seeded region growing by pixels aggregation (SRGPA). This paper
introduces a framework to implement an algorithm using SRGPA. This framework is
built around two concepts: localization and organization of applied action.
This conceptualization gives a quick implementation of algorithms, a direct
translation between the mathematical idea and the numerical implementation, and
an improvement of algorithms efficiency.
</summary>
    <author>
      <name>Vincent Tariel</name>
    </author>
    <link href="http://arxiv.org/abs/0806.3885v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0806.3885v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0808.2227v1</id>
    <updated>2008-08-16T01:34:48Z</updated>
    <published>2008-08-16T01:34:48Z</published>
    <title>Higher Order Moments Generation by Mellin Transform for Compound Models
  of Clutter</title>
    <summary>  The compound models of clutter statistics are found suitable to describe the
nonstationary nature of radar backscattering from high-resolution observations.
In this letter, we show that the properties of Mellin transform can be utilized
to generate higher order moments of simple and compound models of clutter
statistics in a compact manner.
</summary>
    <author>
      <name>C Bhattacharya</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/0808.2227v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0808.2227v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0809.3352v1</id>
    <updated>2008-09-19T11:02:39Z</updated>
    <published>2008-09-19T11:02:39Z</published>
    <title>Generalized Prediction Intervals for Arbitrary Distributed
  High-Dimensional Data</title>
    <summary>  This paper generalizes the traditional statistical concept of prediction
intervals for arbitrary probability density functions in high-dimensional
feature spaces by introducing significance level distributions, which provides
interval-independent probabilities for continuous random variables. The
advantage of the transformation of a probability density function into a
significance level distribution is that it enables one-class classification or
outlier detection in a direct manner.
</summary>
    <author>
      <name>Steffen Kuehn</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0809.3352v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0809.3352v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0809.4501v1</id>
    <updated>2008-09-25T20:54:29Z</updated>
    <published>2008-09-25T20:54:29Z</published>
    <title>Audio Classification from Time-Frequency Texture</title>
    <summary>  Time-frequency representations of audio signals often resemble texture
images. This paper derives a simple audio classification algorithm based on
treating sound spectrograms as texture images. The algorithm is inspired by an
earlier visual classification scheme particularly efficient at classifying
textures. While solely based on time-frequency texture features, the algorithm
achieves surprisingly good performance in musical instrument classification
experiments.
</summary>
    <author>
      <name>Guoshen Yu</name>
    </author>
    <author>
      <name>Jean-Jacques Slotine</name>
    </author>
    <link href="http://arxiv.org/abs/0809.4501v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0809.4501v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0811.4699v2</id>
    <updated>2009-03-03T09:49:07Z</updated>
    <published>2008-11-28T12:11:21Z</published>
    <title>Mapping Images with the Coherence Length Diagrams</title>
    <summary>  Statistical pattern recognition methods based on the Coherence Length Diagram
(CLD) have been proposed for medical image analyses, such as quantitative
characterisation of human skin textures, and for polarized light microscopy of
liquid crystal textures. Further investigations are made on image maps
originated from such diagram and some examples related to irregularity of
microstructures are shown.
</summary>
    <author>
      <name>A. Sparavigna</name>
    </author>
    <author>
      <name>R. Marazzato</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Software Engineering and Computing, pp.
  53-57, 2009, Vol. 1</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0811.4699v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0811.4699v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0812.0340v2</id>
    <updated>2009-10-01T18:44:03Z</updated>
    <published>2008-12-01T18:59:52Z</published>
    <title>A Matlab Implementation of a Flat Norm Motivated Polygonal Edge Matching
  Method using a Decomposition of Boundary into Four 1-Dimensional Currents</title>
    <summary>  We describe and provide code and examples for a polygonal edge matching
method.
</summary>
    <author>
      <name>Simon P. Morgan</name>
    </author>
    <author>
      <name>Wotao Yin</name>
    </author>
    <author>
      <name>Kevin R. Vixie</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Contains Matlab code and 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0812.0340v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0812.0340v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0812.1340v2</id>
    <updated>2009-02-03T16:31:46Z</updated>
    <published>2008-12-07T11:42:41Z</published>
    <title>Obtaining Depth Maps From Color Images By Region Based Stereo Matching
  Algorithms</title>
    <summary>  In the paper, region based stereo matching algorithms are developed for
extraction depth information from two color stereo image pair. A filter
eliminating unreliable disparity estimation was used for increasing reliability
of the disparity map. Obtained results by algorithms were represented and
compared.
</summary>
    <author>
      <name>B. Baykant Alagoz</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">New figures were added</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">OncuBilim Algorithm And Systems Labs. Vol.08, Art.No:04,(2008)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0812.1340v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0812.1340v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0902.4073v1</id>
    <updated>2009-02-24T20:34:43Z</updated>
    <published>2009-02-24T20:34:43Z</published>
    <title>Dipole and Quadrupole Moments in Image Processing</title>
    <summary>  This paper proposes an algorithm for image processing, obtained by adapting
to image maps the definitions of two well-known physical quantities. These
quantities are the dipole and quadrupole moments of a charge distribution. We
will see how it is possible to define dipole and quadrupole moments for the
gray-tone maps and apply them in the development of algorithms for edge
detection.
</summary>
    <author>
      <name>Amelia Sparavigna</name>
    </author>
    <link href="http://arxiv.org/abs/0902.4073v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0902.4073v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0902.4663v1</id>
    <updated>2009-02-26T18:42:30Z</updated>
    <published>2009-02-26T18:42:30Z</published>
    <title>Dipole Vectors in Images Processing</title>
    <summary>  Instead of evaluating the gradient field of the brightness map of an image,
we propose the use of dipole vectors. This approach is obtained by adapting to
the image gray-tone distribution the definition of the dipole moment of charge
distributions. We will show how to evaluate the dipoles and obtain a vector
field, which can be a good alternative to the gradient field in pattern
recognition.
</summary>
    <author>
      <name>Amelia Sparavigna</name>
    </author>
    <link href="http://arxiv.org/abs/0902.4663v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0902.4663v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0909.1608v1</id>
    <updated>2009-09-09T02:12:22Z</updated>
    <published>2009-09-09T02:12:22Z</published>
    <title>Motion Segmentation by SCC on the Hopkins 155 Database</title>
    <summary>  We apply the Spectral Curvature Clustering (SCC) algorithm to a benchmark
database of 155 motion sequences, and show that it outperforms all other
state-of-the-art methods. The average misclassification rate by SCC is 1.41%
for sequences having two motions and 4.85% for three motions.
</summary>
    <author>
      <name>G. Chen</name>
    </author>
    <author>
      <name>G. Lerman</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/ICCVW.2009.5457626</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/ICCVW.2009.5457626" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to 2009 ICCV Workshop on Dynamical Vision</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Computer Vision Workshops (ICCV Workshops), 2009 IEEE 12th
  International Conference on, 2009, pp. 759 - 764</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0909.1608v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0909.1608v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1003.0776v1</id>
    <updated>2010-03-03T10:58:20Z</updated>
    <published>2010-03-03T10:58:20Z</published>
    <title>Properties of the Discrete Pulse Transform for Multi-Dimensional Arrays</title>
    <summary>  This report presents properties of the Discrete Pulse Transform on
multi-dimensional arrays introduced by the authors two or so years ago. The
main result given here in Lemma 2.1 is also formulated in a paper to appear in
IEEE Transactions on Image Processing. However, the proof, being too technical,
was omitted there and hence it appears in full in this publication.
</summary>
    <author>
      <name>Roumen Anguelov</name>
    </author>
    <author>
      <name>Inger Fabris-Rotelli</name>
    </author>
    <link href="http://arxiv.org/abs/1003.0776v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1003.0776v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1003.5249v1</id>
    <updated>2010-03-27T00:17:19Z</updated>
    <published>2010-03-27T00:17:19Z</published>
    <title>Active Testing for Face Detection and Localization</title>
    <summary>  We provide a novel search technique, which uses a hierarchical model and a
mutual information gain heuristic to efficiently prune the search space when
localizing faces in images. We show exponential gains in computation over
traditional sliding window approaches, while keeping similar performance
levels.
</summary>
    <author>
      <name>Raphael Sznitman</name>
    </author>
    <author>
      <name>Bruno Jedynak</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TPAMI.2010.106</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TPAMI.2010.106" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 5 figures, accepted in IEEE Transactions on Pattern
  Analysis and Machine Intelligence (TPAMI), 2010</arxiv:comment>
    <link href="http://arxiv.org/abs/1003.5249v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1003.5249v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1006.2368v1</id>
    <updated>2010-06-11T19:05:05Z</updated>
    <published>2010-06-11T19:05:05Z</published>
    <title>L2-optimal image interpolation and its applications to medical imaging</title>
    <summary>  Digital medical images are always displayed scaled to fit particular view.
Interpolation is responsible for this scaling, and if not done properly, can
significantly degrade diagnostic image quality. However, theoretically-optimal
interpolation algorithms may also be the most time-consuming and impractical.
We propose a new approach, adapted to the needs of digital medical imaging, to
combine high interpolation speed and superior L2-optimal image quality.
</summary>
    <author>
      <name>Oleg Pianykh</name>
    </author>
    <link href="http://arxiv.org/abs/1006.2368v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1006.2368v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1007.1016v1</id>
    <updated>2010-07-06T23:25:39Z</updated>
    <published>2010-07-06T23:25:39Z</published>
    <title>Bilateral filters: what they can and cannot do</title>
    <summary>  Nonlinear bilateral filters (BF) deliver a fine blend of computational
simplicity and blur-free denoising. However, little is known about their
nature, noise-suppressing properties, and optimal choices of filter parameters.
Our study is meant to fill this gap-explaining the underlying mechanism of
bilateral filtering and providing the methodology for optimal filter selection.
Practical application to CT image denoising is discussed to illustrate our
results.
</summary>
    <author>
      <name>Oleg S. Pianykh</name>
    </author>
    <link href="http://arxiv.org/abs/1007.1016v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1007.1016v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1101.5766v1</id>
    <updated>2011-01-30T12:05:12Z</updated>
    <published>2011-01-30T12:05:12Z</published>
    <title>Geometric Models with Co-occurrence Groups</title>
    <summary>  A geometric model of sparse signal representations is introduced for classes
of signals. It is computed by optimizing co-occurrence groups with a maximum
likelihood estimate calculated with a Bernoulli mixture model. Applications to
face image compression and MNIST digit classification illustrate the
applicability of this model.
</summary>
    <author>
      <name>Joan Bruna</name>
    </author>
    <author>
      <name>Stéphane Mallat</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, ESANN 2010</arxiv:comment>
    <link href="http://arxiv.org/abs/1101.5766v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1101.5766v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1104.0582v1</id>
    <updated>2011-04-04T14:18:51Z</updated>
    <published>2011-04-04T14:18:51Z</published>
    <title>Visual Concept Detection and Real Time Object Detection</title>
    <summary>  Bag-of-words model is implemented and tried on 10-class visual concept
detection problem. The experimental results show that "DURF+ERT+SVM"
outperforms "SIFT+ERT+SVM" both in detection performance and computation
efficiency. Besides, combining DURF and SIFT results in even better detection
performance. Real-time object detection using SIFT and RANSAC is also tried on
simple objects, e.g. drink can, and good result is achieved.
</summary>
    <author>
      <name>Ran Tao</name>
    </author>
    <link href="http://arxiv.org/abs/1104.0582v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1104.0582v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1104.2059v1</id>
    <updated>2011-04-11T20:32:54Z</updated>
    <published>2011-04-11T20:32:54Z</published>
    <title>Template-based matching using weight maps</title>
    <summary>  Template matching is one of the most prevalent pattern recognition methods
worldwide. It has found uses in most visual concept detection fields. In this
work, we investigate methods for improving template matching by adjusting the
weights of different regions of the template. We compare several weight maps
and test the methods using the FERET face test set in the context of human eye
detection.
</summary>
    <author>
      <name>Kwie Min Wong</name>
    </author>
    <link href="http://arxiv.org/abs/1104.2059v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1104.2059v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1104.4989v6</id>
    <updated>2011-08-11T09:00:58Z</updated>
    <published>2011-04-26T18:38:01Z</published>
    <title>Preprocessing: A Step in Automating Early Detection of Cervical Cancer</title>
    <summary>  This paper has been withdrawn
</summary>
    <author>
      <name>Abhishek Das</name>
    </author>
    <author>
      <name>Avijit Kar</name>
    </author>
    <author>
      <name>Debasis Bhattacharyya</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">wrong conference name mentioned (This paper has been withdrawn)</arxiv:comment>
    <link href="http://arxiv.org/abs/1104.4989v6" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1104.4989v6" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1107.2807v1</id>
    <updated>2011-07-14T12:51:10Z</updated>
    <published>2011-07-14T12:51:10Z</published>
    <title>Modelling Distributed Shape Priors by Gibbs Random Fields of Second
  Order</title>
    <summary>  We analyse the potential of Gibbs Random Fields for shape prior modelling. We
show that the expressive power of second order GRFs is already sufficient to
express simple shapes and spatial relations between them simultaneously. This
allows to model and recognise complex shapes as spatial compositions of simpler
parts.
</summary>
    <author>
      <name>Boris Flach</name>
    </author>
    <author>
      <name>Dmitrij Schlesinger</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages, 8 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Control Systems and Computers, (2) 2011, pp 14-24</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1107.2807v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1107.2807v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.1461v1</id>
    <updated>2011-11-07T00:28:37Z</updated>
    <published>2011-11-07T00:28:37Z</published>
    <title>Multimodal diff-hash</title>
    <summary>  Many applications require comparing multimodal data with different structure
and dimensionality that cannot be compared directly. Recently, there has been
increasing interest in methods for learning and efficiently representing such
multimodal similarity. In this paper, we present a simple algorithm for
multimodal similarity-preserving hashing, trying to map multimodal data into
the Hamming space while preserving the intra- and inter-modal similarities. We
show that our method significantly outperforms the state-of-the-art method in
the field.
</summary>
    <author>
      <name>Michael M. Bronstein</name>
    </author>
    <link href="http://arxiv.org/abs/1111.1461v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.1461v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.6030v2</id>
    <updated>2011-12-06T13:21:25Z</updated>
    <published>2011-11-25T15:46:37Z</published>
    <title>An image processing of a Raphael's portrait of Leonardo</title>
    <summary>  In one of his paintings, the School of Athens, Raphael is depicting Leonardo
da Vinci as the philosopher Plato. Some image processing tools can help us in
comparing this portrait with two Leonardo's portraits, considered as
self-portraits.
</summary>
    <author>
      <name>Amelia Carolina Sparavigna</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Image processing. Portrait. Self-portrait. Leonardo da Vinci.
  Raphael. Raffaello Sanzio Images revised using a high-quality image of
  Raphael's Plato</arxiv:comment>
    <link href="http://arxiv.org/abs/1111.6030v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.6030v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.0216v1</id>
    <updated>2012-02-01T17:00:45Z</updated>
    <published>2012-02-01T17:00:45Z</published>
    <title>The watershed concept and its use in segmentation : a brief history</title>
    <summary>  The watershed is one of the most used tools in image segmentation. We present
how its concept is born and developed over time. Its implementation as an
algorithm or a hardwired device evolved together with the technology which
allowed it. We present also how it is used in practice, first together with
markers, and later introduced in a multiscale framework, in order to produce
not a unique partition but a complete hierarchy.
</summary>
    <author>
      <name>Fernand Meyer</name>
    </author>
    <link href="http://arxiv.org/abs/1202.0216v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.0216v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68U10, 05C85" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.1634v1</id>
    <updated>2012-04-07T13:46:24Z</updated>
    <published>2012-04-07T13:46:24Z</published>
    <title>Automatic liver segmentation method in CT images</title>
    <summary>  The aim of this work is to develop a method for automatic segmentation of the
liver based on a priori knowledge of the image, such as location and shape of
the liver.
</summary>
    <author>
      <name>Oussema zayane</name>
    </author>
    <author>
      <name>besma jouini</name>
    </author>
    <author>
      <name>Mohamed Ali Mahjoub</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Canadian Journal on Image Processing &amp; Computer Vision Vol. 2, No.
  8, 1923-1717 December 2011</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1204.1634v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.1634v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.2994v1</id>
    <updated>2012-04-13T13:48:27Z</updated>
    <published>2012-04-13T13:48:27Z</published>
    <title>Image Restoration with Signal-dependent Camera Noise</title>
    <summary>  This article describes a fast iterative algorithm for image denoising and
deconvolution with signal-dependent observation noise. We use an optimization
strategy based on variable splitting that adapts traditional Gaussian
noise-based restoration algorithms to account for the observed image being
corrupted by mixed Poisson-Gaussian noise and quantization errors.
</summary>
    <author>
      <name>Ayan Chakrabarti</name>
    </author>
    <author>
      <name>Todd Zickler</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 3 figures, 2 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1204.2994v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.2994v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.3766v1</id>
    <updated>2012-05-16T19:11:51Z</updated>
    <published>2012-05-16T19:11:51Z</published>
    <title>Efficient Topology-Controlled Sampling of Implicit Shapes</title>
    <summary>  Sampling from distributions of implicitly defined shapes enables analysis of
various energy functionals used for image segmentation. Recent work describes a
computationally efficient Metropolis-Hastings method for accomplishing this
task. Here, we extend that framework so that samples are accepted at every
iteration of the sampler, achieving an order of magnitude speed up in
convergence. Additionally, we show how to incorporate topological constraints.
</summary>
    <author>
      <name>Jason Chang</name>
    </author>
    <author>
      <name>John W. Fisher III</name>
    </author>
    <link href="http://arxiv.org/abs/1205.3766v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.3766v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.7244v1</id>
    <updated>2012-06-29T15:07:26Z</updated>
    <published>2012-06-29T15:07:26Z</published>
    <title>Visual Vocabulary Learning and Its Application to 3D and Mobile Visual
  Search</title>
    <summary>  In this technical report, we review related works and recent trends in visual
vocabulary based web image search, object recognition, mobile visual search,
and 3D object retrieval. Especial focuses would be also given for the recent
trends in supervised/unsupervised vocabulary optimization, compact descriptor
for visual search, as well as in multi-view based 3D object representation.
</summary>
    <author>
      <name>Liujuan Cao</name>
    </author>
    <link href="http://arxiv.org/abs/1207.7244v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.7244v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.5653v1</id>
    <updated>2012-10-20T20:37:22Z</updated>
    <published>2012-10-20T20:37:22Z</published>
    <title>Identifications of concealed weapon in a Human Body</title>
    <summary>  The detection of weapons concealed underneath a person cloths is very much
important to the improvement of the security of the public as well as the
safety of public assets like airports, buildings and railway stations etc.
</summary>
    <author>
      <name>Prof. Samir K. Bandyopadhyay</name>
    </author>
    <author>
      <name>Biswajita Datta</name>
    </author>
    <author>
      <name>Sudipta Roy</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, International Journal of Scientific &amp; Engineering Research
  (ISSN 2229-5518) 2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1210.5653v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.5653v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.1127v1</id>
    <updated>2012-11-06T07:26:49Z</updated>
    <published>2012-11-06T07:26:49Z</published>
    <title>Visual Transfer Learning: Informal Introduction and Literature Overview</title>
    <summary>  Transfer learning techniques are important to handle small training sets and
to allow for quick generalization even from only a few examples. The following
paper is the introduction as well as the literature overview part of my thesis
related to the topic of transfer learning for visual recognition problems.
</summary>
    <author>
      <name>Erik Rodner</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">part of my PhD thesis</arxiv:comment>
    <link href="http://arxiv.org/abs/1211.1127v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.1127v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.5712v1</id>
    <updated>2012-11-24T23:08:15Z</updated>
    <published>2012-11-24T23:08:15Z</published>
    <title>Detection of elliptical shapes via cross-entropy clustering</title>
    <summary>  The problem of finding elliptical shapes in an image will be considered. We
discuss the solution which uses cross-entropy clustering. The proposed method
allows the search for ellipses with predefined sizes and position in the space.
Moreover, it works well for search of ellipsoids in higher dimensions.
</summary>
    <author>
      <name>Jacek Tabor</name>
    </author>
    <author>
      <name>Krzysztof Misztal</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-642-38628-2_78</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-642-38628-2_78" rel="related"/>
    <link href="http://arxiv.org/abs/1211.5712v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.5712v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.4527v1</id>
    <updated>2012-12-18T22:30:23Z</updated>
    <published>2012-12-18T22:30:23Z</published>
    <title>GMM-Based Hidden Markov Random Field for Color Image and 3D Volume
  Segmentation</title>
    <summary>  In this project, we first study the Gaussian-based hidden Markov random field
(HMRF) model and its expectation-maximization (EM) algorithm. Then we
generalize it to Gaussian mixture model-based hidden Markov random field. The
algorithm is implemented in MATLAB. We also apply this algorithm to color image
segmentation problems and 3D volume segmentation problems.
</summary>
    <author>
      <name>Quan Wang</name>
    </author>
    <link href="http://arxiv.org/abs/1212.4527v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.4527v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1302.2575v1</id>
    <updated>2013-02-04T22:52:13Z</updated>
    <published>2013-02-04T22:52:13Z</published>
    <title>Coded aperture compressive temporal imaging</title>
    <summary>  We use mechanical translation of a coded aperture for code division multiple
access compression of video. We present experimental results for reconstruction
at 148 frames per coded snapshot.
</summary>
    <author>
      <name>Patrick Llull</name>
    </author>
    <author>
      <name>Xuejun Liao</name>
    </author>
    <author>
      <name>Xin Yuan</name>
    </author>
    <author>
      <name>Jianbo Yang</name>
    </author>
    <author>
      <name>David Kittle</name>
    </author>
    <author>
      <name>Lawrence Carin</name>
    </author>
    <author>
      <name>Guillermo Sapiro</name>
    </author>
    <author>
      <name>David J. Brady</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1364/OE.21.010526</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1364/OE.21.010526" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages (when compiled with Optics Express' TEX template), 15
  figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1302.2575v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1302.2575v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1302.5985v1</id>
    <updated>2013-02-25T03:12:12Z</updated>
    <published>2013-02-25T03:12:12Z</published>
    <title>A Meta-Theory of Boundary Detection Benchmarks</title>
    <summary>  Human labeled datasets, along with their corresponding evaluation algorithms,
play an important role in boundary detection. We here present a psychophysical
experiment that addresses the reliability of such benchmarks. To find better
remedies to evaluate the performance of any boundary detection algorithm, we
propose a computational framework to remove inappropriate human labels and
estimate the intrinsic properties of boundaries.
</summary>
    <author>
      <name>Xiaodi Hou</name>
    </author>
    <author>
      <name>Alan Yuille</name>
    </author>
    <author>
      <name>Christof Koch</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">NIPS 2012 Workshop on Human Computation for Science and Computational
  Sustainability</arxiv:comment>
    <link href="http://arxiv.org/abs/1302.5985v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1302.5985v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1303.2844v1</id>
    <updated>2013-03-12T11:23:47Z</updated>
    <published>2013-03-12T11:23:47Z</published>
    <title>A Stochastic Grammar for Natural Shapes</title>
    <summary>  We consider object detection using a generic model for natural shapes. A
common approach for object recognition involves matching object models directly
to images. Another approach involves building intermediate representations via
a generic grouping processes. We argue that these two processes (model-based
recognition and grouping) may use similar computational mechanisms. By defining
a generic model for shapes we can use model-based techniques to implement a
mid-level vision grouping process.
</summary>
    <author>
      <name>Pedro F. Felzenszwalb</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-1-4471-5195-1_21</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-1-4471-5195-1_21" rel="related"/>
    <link href="http://arxiv.org/abs/1303.2844v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1303.2844v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.0421v1</id>
    <updated>2013-04-01T19:14:27Z</updated>
    <published>2013-04-01T19:14:27Z</published>
    <title>Stroke-Based Cursive Character Recognition</title>
    <summary>  Human eye can see and read what is written or displayed either in natural
handwriting or in printed format. The same work in case the machine does is
called handwriting recognition. Handwriting recognition can be broken down into
two categories: off-line and on-line. ...
</summary>
    <author>
      <name>K. C. Santosh</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LORIA</arxiv:affiliation>
    </author>
    <author>
      <name>E. Iwata</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Advances in Character Recognition INTECH (Ed.) (2012) 175-192</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1304.0421v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.0421v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.1876v3</id>
    <updated>2013-05-28T05:24:25Z</updated>
    <published>2013-04-06T10:36:25Z</published>
    <title>Proceedings of the 37th Annual Workshop of the Austrian Association for
  Pattern Recognition (ÖAGM/AAPR), 2013</title>
    <summary>  This volume represents the proceedings of the 37th Annual Workshop of the
Austrian Association for Pattern Recognition (\"OAGM/AAPR), held May 23-24,
2013, in Innsbruck, Austria.
</summary>
    <author>
      <name>Justus Piater</name>
    </author>
    <author>
      <name>Antonio Rodríguez-Sánchez</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Contributed papers presented at \"OAGM/AAPR 2013</arxiv:comment>
    <link href="http://arxiv.org/abs/1304.1876v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.1876v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.4; I.5; I.2.10" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.1972v1</id>
    <updated>2013-04-07T09:43:47Z</updated>
    <published>2013-04-07T09:43:47Z</published>
    <title>Facial transformations of ancient portraits: the face of Caesar</title>
    <summary>  Some software solutions used to obtain the facial transformations can help
investigating the artistic metamorphosis of the ancient portraits of the same
person. An analysis with a freely available software of portraitures of Julius
Caesar is proposed, showing his several "morphs". The software helps enhancing
the mood the artist added to a portrait.
</summary>
    <author>
      <name>Amelia Carolina Sparavigna</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Image processing, Facial transformation, Morphing, Portraits, Julius
  Caesar, Arles bust, Tusculum bust</arxiv:comment>
    <link href="http://arxiv.org/abs/1304.1972v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.1972v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.2743v1</id>
    <updated>2013-03-27T19:48:54Z</updated>
    <published>2013-03-27T19:48:54Z</published>
    <title>Comparisons of Reasoning Mechanisms for Computer Vision</title>
    <summary>  An evidential reasoning mechanism based on the Dempster-Shafer theory of
evidence is introduced. Its performance in real-world image analysis is
compared with other mechanisms based on the Bayesian formalism and a simple
weight combination method.
</summary>
    <author>
      <name>Ze-Nian Li</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the Third Conference on Uncertainty in
  Artificial Intelligence (UAI1987)</arxiv:comment>
    <link href="http://arxiv.org/abs/1304.2743v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.2743v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.2749v1</id>
    <updated>2013-03-27T19:49:25Z</updated>
    <published>2013-03-27T19:49:25Z</published>
    <title>Evidential Reasoning in Image Understanding</title>
    <summary>  In this paper, we present some results of evidential reasoning in
understanding multispectral images of remote sensing systems. The
Dempster-Shafer approach of combination of evidences is pursued to yield
contextual classification results, which are compared with previous results of
the Bayesian context free classification, contextual classifications of dynamic
programming and stochastic relaxation approaches.
</summary>
    <author>
      <name>Minchuan Zhang</name>
    </author>
    <author>
      <name>Su-shing Chen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the Third Conference on Uncertainty in
  Artificial Intelligence (UAI1987)</arxiv:comment>
    <link href="http://arxiv.org/abs/1304.2749v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.2749v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.3447v1</id>
    <updated>2013-03-27T19:58:23Z</updated>
    <published>2013-03-27T19:58:23Z</published>
    <title>Developing and Analyzing Boundary Detection Operators Using
  Probabilistic Models</title>
    <summary>  Most feature detectors such as edge detectors or circle finders are
statistical, in the sense that they decide at each point in an image about the
presence of a feature, this paper describes the use of Bayesian feature
detectors.
</summary>
    <author>
      <name>David Sher</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the First Conference on Uncertainty in
  Artificial Intelligence (UAI1985)</arxiv:comment>
    <link href="http://arxiv.org/abs/1304.3447v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.3447v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.1303v1</id>
    <updated>2013-07-02T15:25:09Z</updated>
    <published>2013-07-02T15:25:09Z</published>
    <title>Submodularity of a Set Label Disagreement Function</title>
    <summary>  A set label disagreement function is defined over the number of variables
that deviates from the dominant label. The dominant label is the value assumed
by the largest number of variables within a set of binary variables. The
submodularity of a certain family of set label disagreement function is
discussed in this manuscript. Such disagreement function could be utilized as a
cost function in combinatorial optimization approaches for problems defined
over hypergraphs.
</summary>
    <author>
      <name>Toufiq Parag</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Janelia Farm Research Campus-HHMI</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/1307.1303v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.1303v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.3759v1</id>
    <updated>2013-07-14T17:37:36Z</updated>
    <published>2013-07-14T17:37:36Z</published>
    <title>A Minimal Six-Point Auto-Calibration Algorithm</title>
    <summary>  A non-iterative auto-calibration algorithm is presented. It deals with a
minimal set of six scene points in three views taken by a camera with fixed but
unknown intrinsic parameters. Calibration is based on the image correspondences
only. The algorithm is implemented and validated on synthetic image data.
</summary>
    <author>
      <name>Evgeniy Martyushev</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 4 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 23rd International Conference on Computer
  Graphics and Vision, September 16-20, 2013 Vladivostok, Russia</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1307.3759v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.3759v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1308.0890v1</id>
    <updated>2013-08-05T05:17:26Z</updated>
    <published>2013-08-05T05:17:26Z</published>
    <title>Head Gesture Recognition using Optical Flow based Classification with
  Reinforcement of GMM based Background Subtraction</title>
    <summary>  This paper describes a technique of real time head gesture recognition
system. The method includes Gaussian mixture model (GMM) accompanied by optical
flow algorithm which provided us the required information regarding head
movement. The proposed model can be implemented in various control system. We
are also presenting the result and implementation of both mentioned method.
</summary>
    <author>
      <name>Parimita Saikia</name>
    </author>
    <author>
      <name>Karen Das</name>
    </author>
    <link href="http://arxiv.org/abs/1308.0890v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1308.0890v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.0319v3</id>
    <updated>2013-11-03T08:37:46Z</updated>
    <published>2013-10-01T14:26:29Z</published>
    <title>Second Croatian Computer Vision Workshop (CCVW 2013)</title>
    <summary>  Proceedings of the Second Croatian Computer Vision Workshop (CCVW 2013,
http://www.fer.unizg.hr/crv/ccvw2013) held September 19, 2013, in Zagreb,
Croatia. Workshop was organized by the Center of Excellence for Computer Vision
of the University of Zagreb.
</summary>
    <author>
      <name>Sven Lončarić</name>
    </author>
    <author>
      <name>Siniša Šegvić</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Papers presented at the Second Croatian Computer Vision Workshop CCVW
  2013</arxiv:comment>
    <link href="http://arxiv.org/abs/1310.0319v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.0319v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1311.6500v1</id>
    <updated>2013-11-11T20:32:50Z</updated>
    <published>2013-11-11T20:32:50Z</published>
    <title>Stitched Panoramas from Toy Airborne Video Cameras</title>
    <summary>  Effective panoramic photographs are taken from vantage points that are high.
High vantage points have recently become easier to reach as the cost of
quadrotor helicopters has dropped to nearly disposable levels. Although cameras
carried by such aircraft weigh only a few grams, their low-quality video can be
converted into panoramas of high quality and high resolution. Also, the small
size of these aircraft vastly reduces the risks inherent to flight.
</summary>
    <author>
      <name>Camille Goudeseune</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 9 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1311.6500v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1311.6500v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.3; I.4; J.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1312.3035v1</id>
    <updated>2013-12-11T04:59:49Z</updated>
    <published>2013-12-11T04:59:49Z</published>
    <title>Heat kernel coupling for multiple graph analysis</title>
    <summary>  In this paper, we introduce heat kernel coupling (HKC) as a method of
constructing multimodal spectral geometry on weighted graphs of different size
without vertex-wise bijective correspondence. We show that Laplacian averaging
can be derived as a limit case of HKC, and demonstrate its applications on
several problems from the manifold learning and pattern recognition domain.
</summary>
    <author>
      <name>Michael M. Bronstein</name>
    </author>
    <author>
      <name>Klaus Glashoff</name>
    </author>
    <link href="http://arxiv.org/abs/1312.3035v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1312.3035v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1312.3724v1</id>
    <updated>2013-12-13T07:54:22Z</updated>
    <published>2013-12-13T07:54:22Z</published>
    <title>ARIANNA: pAth Recognition for Indoor Assisted NavigatioN with Augmented
  perception</title>
    <summary>  ARIANNA stands for pAth Recognition for Indoor Assisted Navigation with
Augmented perception. It is a flexible and low cost navigation system for vi-
sually impaired people. Arianna permits to navigate colored paths painted or
sticked on the floor revealing their directions through vibrational feedback on
commercial smartphones.
</summary>
    <author>
      <name>Pierluigi Gallo</name>
    </author>
    <author>
      <name>Ilenia Tinnirello</name>
    </author>
    <author>
      <name>Laura Giarré</name>
    </author>
    <author>
      <name>Domenico Garlisi</name>
    </author>
    <author>
      <name>Daniele Croce</name>
    </author>
    <author>
      <name>Adriano Fagiolini</name>
    </author>
    <link href="http://arxiv.org/abs/1312.3724v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1312.3724v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1403.2031v1</id>
    <updated>2014-03-09T06:53:13Z</updated>
    <published>2014-03-09T06:53:13Z</published>
    <title>Texture Defect Detection in Gradient Space</title>
    <summary>  In this paper, we propose a machine vision algorithm for automatically
detecting defects in patterned textures with the help of gradient space and its
energy. Experiments on real fabric images with defects show that the proposed
method can be used for automatic detection of fabric defects in textile
industries.
</summary>
    <author>
      <name>V. Asha</name>
    </author>
    <author>
      <name>N. U. Bhajantri</name>
    </author>
    <author>
      <name>P. Nagabhushan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, ICFoCS-2011</arxiv:comment>
    <link href="http://arxiv.org/abs/1403.2031v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1403.2031v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="11K70, 39A14, 39A70, 47A30, 62H30, 68M20" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1403.3964v1</id>
    <updated>2014-03-16T22:03:45Z</updated>
    <published>2014-03-16T22:03:45Z</published>
    <title>Image processing using miniKanren</title>
    <summary>  An integral image is one of the most efficient optimization technique for
image processing. However an integral image is only a special case of delayed
stream or memoization. This research discusses generalizing concept of integral
image optimization technique, and how to generate an integral image optimized
program code automatically from abstracted image processing algorithm. In oder
to abstruct algorithms, we forces to miniKanren.
</summary>
    <author>
      <name>Hirotaka Niitsuma</name>
    </author>
    <link href="http://arxiv.org/abs/1403.3964v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1403.3964v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.7748v1</id>
    <updated>2014-04-30T14:54:19Z</updated>
    <published>2014-04-30T14:54:19Z</published>
    <title>A graph-based mathematical morphology reader</title>
    <summary>  This survey paper aims at providing a "literary" anthology of mathematical
morphology on graphs. It describes in the English language many ideas stemming
from a large number of different papers, hence providing a unified view of an
active and diverse field of research.
</summary>
    <author>
      <name>Laurent Najman</name>
    </author>
    <author>
      <name>Jean Cousty</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.patrec.2014.05.007</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.patrec.2014.05.007" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Pattern Recognition Letters 47 (2014) 3-17</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1404.7748v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.7748v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.1678v3</id>
    <updated>2015-03-12T12:38:13Z</updated>
    <published>2014-05-07T17:51:52Z</published>
    <title>RPCA-KFE: Key Frame Extraction for Consumer Video based Robust Principal
  Component Analysis</title>
    <summary>  Key frame extraction algorithms consider the problem of selecting a subset of
the most informative frames from a video to summarize its content.
</summary>
    <author>
      <name>Chinh Dang</name>
    </author>
    <author>
      <name>Abdolreza Moghadam</name>
    </author>
    <author>
      <name>Hayder Radha</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper has been withdrawn by the author due to a crucial sign
  error in equation 1</arxiv:comment>
    <link href="http://arxiv.org/abs/1405.1678v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.1678v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.6132v1</id>
    <updated>2014-02-05T00:46:18Z</updated>
    <published>2014-02-05T00:46:18Z</published>
    <title>Comparative analysis of common edge detection techniques in context of
  object extraction</title>
    <summary>  Edges characterize boundaries and are therefore a problem of practical
importance in remote sensing.In this paper a comparative study of various edge
detection techniques and band wise analysis of these algorithms in the context
of object extraction with regard to remote sensing satellite images from the
Indian Remote Sensing Satellite (IRS) sensors LISS 3, LISS 4 and Cartosat1 as
well as Google Earth is presented.
</summary>
    <author>
      <name>S. K. Katiyar</name>
    </author>
    <author>
      <name>P. V. Arun</name>
    </author>
    <link href="http://arxiv.org/abs/1405.6132v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.6132v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.6133v1</id>
    <updated>2014-02-05T14:49:36Z</updated>
    <published>2014-02-05T14:49:36Z</published>
    <title>A review over the applicability of image entropy in analyses of remote
  sensing datasets</title>
    <summary>  Entropy is the measure of uncertainty in any data and is adopted for
maximisation of mutual information in many remote sensing operations. The
availability of wide entropy variations motivated us for an investigation over
the suitability preference of these versions to specific operations.
</summary>
    <author>
      <name>S. K. Katiyar</name>
    </author>
    <author>
      <name>P. V. Arun</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: substantial text overlap with arXiv:1303.6926</arxiv:comment>
    <link href="http://arxiv.org/abs/1405.6133v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.6133v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1407.3673v2</id>
    <updated>2016-10-21T16:07:15Z</updated>
    <published>2014-07-03T10:55:52Z</published>
    <title>Enhanced EZW Technique for Compression of Image by Setting Detail
  Retaining Pass Number</title>
    <summary>  This submission has been withdrawn by arXiv administrators because it
contains excessive and unattributed reuse of content from other authors.
</summary>
    <author>
      <name>Isha Tyagi</name>
    </author>
    <author>
      <name>Ashish Nautiyal</name>
    </author>
    <author>
      <name>Vishwanath Bijalwan</name>
    </author>
    <author>
      <name>Meenu Balodhi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This submission has been withdrawn by arXiv administrators because it
  contains excessive and unattributed reuse of content from other authors</arxiv:comment>
    <link href="http://arxiv.org/abs/1407.3673v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1407.3673v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1407.6492v2</id>
    <updated>2014-08-14T11:28:48Z</updated>
    <published>2014-07-24T08:53:00Z</published>
    <title>Recognition of Handwritten Persian/Arabic Numerals Based on Robust
  Feature Set and K-NN Classifier</title>
    <summary>  This paper has been withdrawn by the author due to a crucial sign error in
equation 2 and some mistake in Table 1 information. please let me for changing
this information and updating this paper.
</summary>
    <author>
      <name>Reza Azad</name>
    </author>
    <author>
      <name>Fatemeh Davami</name>
    </author>
    <author>
      <name>Hamid Reza Shayegh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper has been withdrawn by the main author due to the Table 1
  and equation 2 errors</arxiv:comment>
    <link href="http://arxiv.org/abs/1407.6492v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1407.6492v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1408.1986v1</id>
    <updated>2014-08-08T21:24:59Z</updated>
    <published>2014-08-08T21:24:59Z</published>
    <title>Gabor-like Image Filtering using a Neural Microcircuit</title>
    <summary>  In this letter, we present an implementation of a neural microcircuit for
image processing employing Hebbian-adaptive learning. The neuronal circuit
utilizes only excitatory synapses to correlate action potentials, extracting
the uncorrelated ones, which contain significant image information. This
circuit is capable of approximating Gabor-like image filtering and other image
processing functions
</summary>
    <author>
      <name>C. Mayr</name>
    </author>
    <author>
      <name>A. Heittmann</name>
    </author>
    <author>
      <name>R. Schüffny</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TNN.2007.891687</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TNN.2007.891687" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE Transactions on Neural Networks, vol. 18, pages 955-959, 2007</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1408.1986v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1408.1986v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.ET" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.2474v1</id>
    <updated>2014-10-09T14:08:46Z</updated>
    <published>2014-10-09T14:08:46Z</published>
    <title>Genetic Stereo Matching Algorithm with Fuzzy Fitness</title>
    <summary>  This paper presents a genetic stereo matching algorithm with fuzzy evaluation
function. The proposed algorithm presents a new encoding scheme in which a
chromosome is represented by a disparity matrix. Evolution is controlled by a
fuzzy fitness function able to deal with noise and uncertain camera
measurements, and uses classical evolutionary operators. The result of the
algorithm is accurate dense disparity maps obtained in a reasonable
computational time suitable for real-time applications as shown in experimental
results.
</summary>
    <author>
      <name>Haythem Ghazouani</name>
    </author>
    <link href="http://arxiv.org/abs/1410.2474v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.2474v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.2663v1</id>
    <updated>2014-10-10T02:48:08Z</updated>
    <published>2014-10-10T02:48:08Z</published>
    <title>Challenge IEEE-ISBI/TCB : Application of Covariance matrices and wavelet
  marginals</title>
    <summary>  This short memo aims at explaining our approach for the challenge IEEE-ISBI
on Bone Texture Characterization. In this work, we focus on the use of
covariance matrices and wavelet marginals in an SVM classifier.
</summary>
    <author>
      <name>Florian Yger</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 4 Figues, 2 Tables, Challenge IEEE-ISBI : Bone Texture
  Characterization</arxiv:comment>
    <link href="http://arxiv.org/abs/1410.2663v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.2663v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1411.1442v1</id>
    <updated>2014-11-05T22:56:10Z</updated>
    <published>2014-11-05T22:56:10Z</published>
    <title>Optical Character Recognition, Using K-Nearest Neighbors</title>
    <summary>  The problem of optical character recognition, OCR, has been widely discussed
in the literature. Having a hand-written text, the program aims at recognizing
the text. Even though there are several approaches to this issue, it is still
an open problem. In this paper we would like to propose an approach that uses
K-nearest neighbors algorithm, and has the accuracy of more than 90%. The
training and run time is also very short.
</summary>
    <author>
      <name>Wei Wang</name>
    </author>
    <link href="http://arxiv.org/abs/1411.1442v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1411.1442v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1411.6850v1</id>
    <updated>2014-11-25T13:13:47Z</updated>
    <published>2014-11-25T13:13:47Z</published>
    <title>Similarity- based approach for outlier detection</title>
    <summary>  This paper presents a new approach for detecting outliers by introducing the
notion of object's proximity. The main idea is that normal point has similar
characteristics with several neighbors. So the point in not an outlier if it
has a high degree of proximity and its neighbors are several. The performance
of this approach is illustrated through real datasets
</summary>
    <author>
      <name>Amina Dik</name>
    </author>
    <author>
      <name>Khalid Jebari</name>
    </author>
    <author>
      <name>Abdelaziz Bouroumi</name>
    </author>
    <author>
      <name>Aziz Ettouhami</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Science Issues 2014</arxiv:comment>
    <link href="http://arxiv.org/abs/1411.6850v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1411.6850v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1411.7855v1</id>
    <updated>2014-11-28T13:18:22Z</updated>
    <published>2014-11-28T13:18:22Z</published>
    <title>V-variable image compression</title>
    <summary>  V-variable fractals, where $V$ is a positive integer, are intuitively
fractals with at most $V$ different "forms" or "shapes" at all levels of
magnification. In this paper we describe how V-variable fractals can be used
for the purpose of image compression.
</summary>
    <author>
      <name>Franklin Mendivil</name>
    </author>
    <author>
      <name>Örjan Stenflo</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1142/S0218348X15500073</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1142/S0218348X15500073" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 22 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Fractals, 23, no 02, (2015)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1411.7855v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1411.7855v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="28A80, 68U10, 94A08" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.5334v1</id>
    <updated>2014-12-17T10:58:46Z</updated>
    <published>2014-12-17T10:58:46Z</published>
    <title>The Affine Transforms for Image Enhancement in the Context of
  Logarithmic Models</title>
    <summary>  The logarithmic model offers new tools for image processing. An efficient
method for image enhancement is to use an affine transformation with the
logarithmic operations: addition and scalar multiplication. We define some
criteria for automatically determining the parameters of the processing and
this is done via mean and variance computed by logarithmic operations.
</summary>
    <author>
      <name>Vasile Patrascu</name>
    </author>
    <author>
      <name>Vasile Buzuloiu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">International Conference on Computer Vision and Graphics, ICCVG2002,
  25-29 September, 2002, Zakopane, Poland</arxiv:comment>
    <link href="http://arxiv.org/abs/1412.5334v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.5334v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.5769v1</id>
    <updated>2014-12-18T09:19:50Z</updated>
    <published>2014-12-18T09:19:50Z</published>
    <title>Gray level image enhancement using the Bernstein polynomials</title>
    <summary>  This paper presents a method for enhancing the gray level images. This
presented method takes part from the category of point operations and it is
based on piecewise linear functions. The interpolation nodes of these functions
are calculated using the Bernstein polynomials.
</summary>
    <author>
      <name>Vasile Patrascu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Scientific Bulletin of the Politechnica, University of
  Timisoara,Transactions on Electronics and Communications, Vol. 47 (61), No:
  2,pp.121-126, June 2002</arxiv:comment>
    <link href="http://arxiv.org/abs/1412.5769v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.5769v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.6061v1</id>
    <updated>2014-12-15T06:55:28Z</updated>
    <published>2014-12-15T06:55:28Z</published>
    <title>CITlab ARGUS for Arabic Handwriting</title>
    <summary>  In the recent years it turned out that multidimensional recurrent neural
networks (MDRNN) perform very well for offline handwriting recognition tasks
like the OpenHaRT 2013 evaluation DIR. With suitable writing preprocessing and
dictionary lookup, our ARGUS software completed this task with an error rate of
26.27% in its primary setup.
</summary>
    <author>
      <name>Gundram Leifert</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Rostock - CITlab</arxiv:affiliation>
    </author>
    <author>
      <name>Roger Labahn</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Rostock - CITlab</arxiv:affiliation>
    </author>
    <author>
      <name>Tobias Strauß</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Rostock - CITlab</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">http://www.nist.gov/itl/iad/mig/upload/OpenHaRT2013_SysDesc_CITLAB.pdf</arxiv:comment>
    <link href="http://arxiv.org/abs/1412.6061v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.6061v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T10, 68T05" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.6154v1</id>
    <updated>2014-10-06T11:45:07Z</updated>
    <published>2014-10-06T11:45:07Z</published>
    <title>Effective persistent homology of digital images</title>
    <summary>  In this paper, three Computational Topology methods (namely effective
homology, persistent homology and discrete vector fields) are mixed together to
produce algorithms for homological digital image processing. The algorithms
have been implemented as extensions of the Kenzo system and have shown a good
performance when applied on some actual images extracted from a public dataset.
</summary>
    <author>
      <name>Ana Romero</name>
    </author>
    <author>
      <name>Julio Rubio</name>
    </author>
    <author>
      <name>Francis Sergeraert</name>
    </author>
    <link href="http://arxiv.org/abs/1412.6154v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.6154v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1501.07692v1</id>
    <updated>2015-01-30T08:12:48Z</updated>
    <published>2015-01-30T08:12:48Z</published>
    <title>Blob indentation identification via curvature measurement</title>
    <summary>  This paper presents a novel method for identifying indentations on the
boundary of solid 2D shape. It uses the signed curvature at a set of points
along the boundary to identify indentations and provides one parameter for
tuning the selection mechanism for discriminating indentations from other
boundary irregularities. An efficient implementation is described based on the
Fourier transform for calculating curvature from a sequence of points obtained
from the boundary of a binary blob.
</summary>
    <author>
      <name>Matthew Sottile</name>
    </author>
    <link href="http://arxiv.org/abs/1501.07692v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1501.07692v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.05565v1</id>
    <updated>2015-02-19T13:35:06Z</updated>
    <published>2015-02-19T13:35:06Z</published>
    <title>Multi-valued Color Representation Based on Frank t-norm Properties</title>
    <summary>  In this paper two knowledge representation models are proposed, FP4 and FP6.
Both combine ideas from fuzzy sets and four-valued and hexa-valued logics. Both
represent imprecise properties whose accomplished degree is unknown or
contradictory for some objects. A possible application in the color analysis
and color image processing is discussed.
</summary>
    <author>
      <name>Vasile Patrascu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12th International Conference Information Processing and Management
  of Uncertainty for Knowledge-Based Systems, IPMU'2008, pp. 1215-1222, June
  22-27, 2008, Malaga, Spain</arxiv:comment>
    <link href="http://arxiv.org/abs/1502.05565v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.05565v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.06556v1</id>
    <updated>2015-02-23T19:11:12Z</updated>
    <published>2015-02-23T19:11:12Z</published>
    <title>Shannon, Tsallis and Kaniadakis entropies in bi-level image thresholding</title>
    <summary>  The maximum entropy principle is often used for bi-level or multi-level
thresholding of images. For this purpose, some methods are available based on
Shannon and Tsallis entropies. In this paper, we discuss them and propose a
method based on Kaniadakis entropy.
</summary>
    <author>
      <name>Amelia Carolina Sparavigna</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.18483/ijSci.626</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.18483/ijSci.626" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Keywords: Kaniadakis Entropy, Image Processing, Image Segmentation,
  Image Thresholding, Texture Transitions</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Sciences 4(2), 35-43, 2015</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1502.06556v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.06556v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.01557v3</id>
    <updated>2015-04-19T02:42:16Z</updated>
    <published>2015-03-05T07:06:02Z</published>
    <title>Supervised Discrete Hashing</title>
    <summary>  This paper has been withdrawn by the authour.
</summary>
    <author>
      <name>Fumin Shen</name>
    </author>
    <author>
      <name>Chunhua Shen</name>
    </author>
    <author>
      <name>Wei Liu</name>
    </author>
    <author>
      <name>Heng Tao Shen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper has been withdrawn by the authour since the algorithm is
  being used for patent application</arxiv:comment>
    <link href="http://arxiv.org/abs/1503.01557v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.01557v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.01065v1</id>
    <updated>2015-04-30T10:10:16Z</updated>
    <published>2015-04-30T10:10:16Z</published>
    <title>Proceedings of The 39th Annual Workshop of the Austrian Association for
  Pattern Recognition (OAGM), 2015</title>
    <summary>  The 39th annual workshop of the Austrian Association for Pattern Recognition
(OAGM/AAPR) provides a platform for presentation and discussion of research
progress as well as research projects within the OAGM/AAPR community.
</summary>
    <author>
      <name>Sebastian Hegenbart</name>
    </author>
    <author>
      <name>Roland Kwitt</name>
    </author>
    <author>
      <name>Andreas Uhl</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Index submitted before individual papers</arxiv:comment>
    <link href="http://arxiv.org/abs/1505.01065v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.01065v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.02890v2</id>
    <updated>2015-08-25T15:12:37Z</updated>
    <published>2015-05-12T07:30:22Z</published>
    <title>Sparse 3D convolutional neural networks</title>
    <summary>  We have implemented a convolutional neural network designed for processing
sparse three-dimensional input data. The world we live in is three dimensional
so there are a large number of potential applications including 3D object
recognition and analysis of space-time objects. In the quest for efficiency, we
experiment with CNNs on the 2D triangular-lattice and 3D tetrahedral-lattice.
</summary>
    <author>
      <name>Ben Graham</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">BMVC 2015</arxiv:comment>
    <link href="http://arxiv.org/abs/1505.02890v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.02890v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.03795v1</id>
    <updated>2015-05-14T16:43:07Z</updated>
    <published>2015-05-14T16:43:07Z</published>
    <title>Fast and numerically stable circle fit</title>
    <summary>  We develop a new algorithm for fitting circles that does not have drawbacks
commonly found in existing circle fits. Our fit achieves ultimate accuracy (to
machine precision), avoids divergence, and is numerically stable even when
fitting circles get arbitrary large. Lastly, our algorithm takes less than 10
iterations to converge, on average.
</summary>
    <author>
      <name>Houssam Abdul-Rahman</name>
    </author>
    <author>
      <name>Nikolai Chernov</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s10851-013-0461-4</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s10851-013-0461-4" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Mathematical Imaging and Vision June 2014, Volume 49,
  Issue 2, pp 289-295</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1505.03795v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.03795v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.05240v1</id>
    <updated>2015-05-20T04:09:47Z</updated>
    <published>2015-05-20T04:09:47Z</published>
    <title>Benchmarking KAZE and MCM for Multiclass Classification</title>
    <summary>  In this paper, we propose a novel approach for feature generation by
appropriately fusing KAZE and SIFT features. We then use this feature set along
with Minimal Complexity Machine(MCM) for object classification. We show that
KAZE and SIFT features are complementary. Experimental results indicate that an
elementary integration of these techniques can outperform the state-of-the-art
approaches.
</summary>
    <author>
      <name>Siddharth Srivastava</name>
    </author>
    <author>
      <name>Prerana Mukherjee</name>
    </author>
    <author>
      <name>Brejesh Lall</name>
    </author>
    <link href="http://arxiv.org/abs/1505.05240v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.05240v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.4.7; I.5.4; I.4.8; I.4.9; I.5.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.06769v1</id>
    <updated>2015-05-25T22:18:36Z</updated>
    <published>2015-05-25T22:18:36Z</published>
    <title>VeinPLUS: A Transillumination and Reflection-based Hand Vein Database</title>
    <summary>  This paper gives a short summary of work related to the creation of a
department-hosted hand vein database. After the introducing section, special
properties of the hand vein acquisition are explained, followed by a comparison
table, which shows key differences to existing well-known hand vein databases.
At the end, the ROI extraction process is described and sample images and ROIs
are presented.
</summary>
    <author>
      <name>Alexander Gruschina</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented at OAGM Workshop, 2015 (arXiv:1505.01065)</arxiv:comment>
    <link href="http://arxiv.org/abs/1505.06769v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.06769v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.06274v1</id>
    <updated>2015-06-20T17:55:49Z</updated>
    <published>2015-06-20T17:55:49Z</published>
    <title>Pose Estimation Based on 3D Models</title>
    <summary>  In this paper, we proposed a pose estimation system based on rendered image
training set, which predicts the pose of objects in real image, with knowledge
of object category and tight bounding box. We developed a patch-based
multi-class classification algorithm, and an iterative approach to improve the
accuracy. We achieved state-of-the-art performance on pose estimation task.
</summary>
    <author>
      <name>Chuiwen Ma</name>
    </author>
    <author>
      <name>Hao Su</name>
    </author>
    <author>
      <name>Liang Shi</name>
    </author>
    <link href="http://arxiv.org/abs/1506.06274v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.06274v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.08959v2</id>
    <updated>2015-09-24T09:04:24Z</updated>
    <published>2015-06-30T06:47:50Z</published>
    <title>A Large-Scale Car Dataset for Fine-Grained Categorization and
  Verification</title>
    <summary>  Updated on 24/09/2015: This update provides preliminary experiment results
for fine-grained classification on the surveillance data of CompCars. The
train/test splits are provided in the updated dataset. See details in Section
6.
</summary>
    <author>
      <name>Linjie Yang</name>
    </author>
    <author>
      <name>Ping Luo</name>
    </author>
    <author>
      <name>Chen Change Loy</name>
    </author>
    <author>
      <name>Xiaoou Tang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">An extension to our conference paper in CVPR 2015</arxiv:comment>
    <link href="http://arxiv.org/abs/1506.08959v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.08959v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.05053v1</id>
    <updated>2015-07-17T17:48:49Z</updated>
    <published>2015-07-17T17:48:49Z</published>
    <title>Massively Deep Artificial Neural Networks for Handwritten Digit
  Recognition</title>
    <summary>  Greedy Restrictive Boltzmann Machines yield an fairly low 0.72% error rate on
the famous MNIST database of handwritten digits. All that was required to
achieve this result was a high number of hidden layers consisting of many
neurons, and a graphics card to greatly speed up the rate of learning.
</summary>
    <author>
      <name>Keiron O'Shea</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1507.05053v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.05053v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.05244v1</id>
    <updated>2015-07-19T03:14:56Z</updated>
    <published>2015-07-19T03:14:56Z</published>
    <title>Handwriting Recognition</title>
    <summary>  This paper describes the method to recognize offline handwritten characters.
A robust algorithm for handwriting segmentation is described here with the help
of which individual characters can be segmented from a selected word from a
paragraph of handwritten text image which is given as input.
</summary>
    <author>
      <name>Jayati Ghosh Dastidar</name>
    </author>
    <author>
      <name>Surabhi Sarkar</name>
    </author>
    <author>
      <name>Rick Punyadyuti Sinha</name>
    </author>
    <author>
      <name>Kasturi Basu</name>
    </author>
    <link href="http://arxiv.org/abs/1507.05244v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.05244v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.02246v1</id>
    <updated>2015-08-10T13:51:35Z</updated>
    <published>2015-08-10T13:51:35Z</published>
    <title>Feature Learning for Interaction Activity Recognition in RGBD Videos</title>
    <summary>  This paper proposes a human activity recognition method which is based on
features learned from 3D video data without incorporating domain knowledge. The
experiments on data collected by RGBD cameras produce results outperforming
other techniques. Our feature encoding method follows the bag-of-visual-word
model, then we use a SVM classifier to recognise the activities. We do not use
skeleton or tracking information and the same technique is applied on color and
depth data.
</summary>
    <author>
      <name>Ngu Nguyen</name>
    </author>
    <link href="http://arxiv.org/abs/1508.02246v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.02246v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1509.04232v1</id>
    <updated>2015-09-14T18:30:05Z</updated>
    <published>2015-09-14T18:30:05Z</published>
    <title>gSLICr: SLIC superpixels at over 250Hz</title>
    <summary>  We introduce a parallel GPU implementation of the Simple Linear Iterative
Clustering (SLIC) superpixel segmentation. Using a single graphic card, our
implementation achieves speedups of up to $83\times$ from the standard
sequential implementation. Our implementation is fully compatible with the
standard sequential implementation and the software is now available online and
is open source.
</summary>
    <author>
      <name>Carl Yuheng Ren</name>
    </author>
    <author>
      <name>Victor Adrian Prisacariu</name>
    </author>
    <author>
      <name>Ian D Reid</name>
    </author>
    <link href="http://arxiv.org/abs/1509.04232v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1509.04232v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1509.05054v1</id>
    <updated>2015-09-16T20:23:06Z</updated>
    <published>2015-09-16T20:23:06Z</published>
    <title>Overcomplete Dictionary Learning with Jacobi Atom Updates</title>
    <summary>  Dictionary learning for sparse representations is traditionally approached
with sequential atom updates, in which an optimized atom is used immediately
for the optimization of the next atoms. We propose instead a Jacobi version, in
which groups of atoms are updated independently, in parallel. Extensive
numerical evidence for sparse image representation shows that the parallel
algorithms, especially when all atoms are updated simultaneously, give better
dictionaries than their sequential counterparts.
</summary>
    <author>
      <name>Paul Irofti</name>
    </author>
    <author>
      <name>Bogdan Dumitrescu</name>
    </author>
    <link href="http://arxiv.org/abs/1509.05054v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1509.05054v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.03650v3</id>
    <updated>2015-12-07T14:20:01Z</updated>
    <published>2015-11-11T20:54:28Z</published>
    <title>Piecewise Linear Activation Functions For More Efficient Deep Networks</title>
    <summary>  This submission has been withdrawn by arXiv administrators because it is
intentionally incomplete, which is in violation of our policies.
</summary>
    <author>
      <name>Cheng-Yang Fu</name>
    </author>
    <author>
      <name>Alexander C. Berg</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Withdrawn by arXiv admins</arxiv:comment>
    <link href="http://arxiv.org/abs/1511.03650v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.03650v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.06489v1</id>
    <updated>2015-11-20T04:56:47Z</updated>
    <published>2015-11-20T04:56:47Z</published>
    <title>A Simple Hierarchical Pooling Data Structure for Loop Closure</title>
    <summary>  We propose a data structure obtained by hierarchically averaging bag-of-word
descriptors during a sequence of views that achieves average speedups in
large-scale loop closure applications ranging from 4 to 20 times on benchmark
datasets. Although simple, the method works as well as sophisticated
agglomerative schemes at a fraction of the cost with minimal loss of
performance.
</summary>
    <author>
      <name>Xiaohan Fei</name>
    </author>
    <author>
      <name>Konstantine Tsotsos</name>
    </author>
    <author>
      <name>Stefano Soatto</name>
    </author>
    <link href="http://arxiv.org/abs/1511.06489v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.06489v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.07347v1</id>
    <updated>2015-11-23T18:15:13Z</updated>
    <published>2015-11-23T18:15:13Z</published>
    <title>Node Specificity in Convolutional Deep Nets Depends on Receptive Field
  Position and Size</title>
    <summary>  In convolutional deep neural networks, receptive field (RF) size increases
with hierarchical depth. When RF size approaches full coverage of the input
image, different RF positions result in RFs with different specificity, as
portions of the RF fall out of the input space. This leads to a departure from
the convolutional concept of positional invariance and opens the possibility
for complex forms of context specificity.
</summary>
    <author>
      <name>Karl Zipser</name>
    </author>
    <link href="http://arxiv.org/abs/1511.07347v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.07347v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1512.01533v1</id>
    <updated>2015-12-04T20:28:27Z</updated>
    <published>2015-12-04T20:28:27Z</published>
    <title>Motion trails from time-lapse video</title>
    <summary>  From an image sequence captured by a stationary camera, background
subtraction can detect moving foreground objects in the scene. Distinguishing
foreground from background is further improved by various heuristics. Then each
object's motion can be emphasized by duplicating its positions as a motion
trail. These trails clarify the objects' spatial relationships. Also, adding
motion trails to a video before previewing it at high speed reduces the risk of
overlooking transient events.
</summary>
    <author>
      <name>Camille Goudeseune</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1512.01533v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1512.01533v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.3; I.4.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1512.02329v2</id>
    <updated>2015-12-15T06:18:35Z</updated>
    <published>2015-12-08T05:04:57Z</published>
    <title>Computational Models for Multiview Dense Depth Maps of Dynamic Scene</title>
    <summary>  This paper reviews the recent progresses of the depth map generation for
dynamic scene and its corresponding computational models. This paper mainly
covers the homogeneous ambiguity models in depth sensing, resolution models in
depth processing, and consistency models in depth optimization. We also
summarize the future work in the depth map generation.
</summary>
    <author>
      <name>Qifei Wang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, IEEE COMSOC MMTC E-Letter 2015</arxiv:comment>
    <link href="http://arxiv.org/abs/1512.02329v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1512.02329v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1512.02357v1</id>
    <updated>2015-12-08T07:25:29Z</updated>
    <published>2015-12-08T07:25:29Z</published>
    <title>Towards the Application of Linear Programming Methods For Multi-Camera
  Pose Estimation</title>
    <summary>  We presented a separation based optimization algorithm which, rather than
optimization the entire variables altogether, This would allow us to employ: 1)
a class of nonlinear functions with three variables and 2) a convex quadratic
multivariable polynomial, for minimization of reprojection error. Neglecting
the inversion required to minimize the nonlinear functions, in this paper we
demonstrate how separation allows eradication of matrix inversion.
</summary>
    <author>
      <name>Masoud Aghamohamadian-Sharbaf</name>
    </author>
    <author>
      <name>Ahmadreza Heravi</name>
    </author>
    <author>
      <name>Hamidreza Pourreza</name>
    </author>
    <link href="http://arxiv.org/abs/1512.02357v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1512.02357v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1512.06014v2</id>
    <updated>2016-12-04T20:42:48Z</updated>
    <published>2015-12-18T16:17:35Z</published>
    <title>Multiclass Classification of Cervical Cancer Tissues by Hidden Markov
  Model</title>
    <summary>  In this paper, we report a hidden Markov model based multiclass
classification of cervical cancer tissues. This model has been validated
directly over time series generated by the medium refractive index fluctuations
extracted from differential interference contrast images of healthy and
different stages of cancer tissues. The method shows promising results for
multiclass classification with higher accuracy.
</summary>
    <author>
      <name>Sabyasachi Mukhopadhyay</name>
    </author>
    <author>
      <name>Sanket Nandan</name>
    </author>
    <author>
      <name>Indrajit Kurmi</name>
    </author>
    <link href="http://arxiv.org/abs/1512.06014v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1512.06014v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.00396v1</id>
    <updated>2016-01-04T07:28:53Z</updated>
    <published>2016-01-04T07:28:53Z</published>
    <title>Automatic Detection and Decoding of Photogrammetric Coded Targets</title>
    <summary>  Close-range Photogrammetry is widely used in many industries because of the
cost effectiveness and efficiency of the technique. In this research, we
introduce an automated coded target detection method which can be used to
enhance the efficiency of the Photogrammetry.
</summary>
    <author>
      <name>Udaya Wijenayake</name>
    </author>
    <author>
      <name>Sung-In Choi</name>
    </author>
    <author>
      <name>Soon-Yong Park</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/ELINFOCOM.2014.6914413</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/ELINFOCOM.2014.6914413" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3 pages, 4 figures, Electronics, Information and Communications
  (ICEIC), 2014 International Conference on</arxiv:comment>
    <link href="http://arxiv.org/abs/1601.00396v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.00396v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.04568v1</id>
    <updated>2016-01-18T15:22:48Z</updated>
    <published>2016-01-18T15:22:48Z</published>
    <title>Content Aware Neural Style Transfer</title>
    <summary>  This paper presents a content-aware style transfer algorithm for paintings
and photos of similar content using pre-trained neural network, obtaining
better results than the previous work. In addition, the numerical experiments
show that the style pattern and the content information is not completely
separated by neural network.
</summary>
    <author>
      <name>Rujie Yin</name>
    </author>
    <link href="http://arxiv.org/abs/1601.04568v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.04568v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68T10" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.4.10; I.5.2; I.5.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.08003v1</id>
    <updated>2016-01-29T08:54:22Z</updated>
    <published>2016-01-29T08:54:22Z</published>
    <title>Efficient Robust Mean Value Calculation of 1D Features</title>
    <summary>  A robust mean value is often a good alternative to the standard mean value
when dealing with data containing many outliers. An efficient method for
samples of one-dimensional features and the truncated quadratic error norm is
presented and compared to the method of channel averaging (soft histograms).
</summary>
    <author>
      <name>Erik Jonsson</name>
    </author>
    <author>
      <name>Michael Felsberg</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented at the SSBA Symposium 2005, Malm\"o, Sweden</arxiv:comment>
    <link href="http://arxiv.org/abs/1601.08003v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.08003v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.01772v1</id>
    <updated>2016-03-06T00:30:34Z</updated>
    <published>2016-03-06T00:30:34Z</published>
    <title>Fast calculation of correlations in recognition systems</title>
    <summary>  Computationally efficient classification system architecture is proposed. It
utilizes fast tensor-vector multiplication algorithm to apply linear operators
upon input signals . The approach is applicable to wide variety of recognition
system architectures ranging from single stage matched filter bank classifiers
to complex neural networks with unlimited number of hidden layers.
</summary>
    <author>
      <name>Pavel Dourbal</name>
    </author>
    <author>
      <name>Mikhail Pekker</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1603.01772v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.01772v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62H30, 65F05, 65F10, 65F30, 65F50, 68T05, 68T10, 94A11, 94A12,&#10;  94A13, 94A15" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.2.1; G.1.0; G.1.3; G.4; H.4.2; I.1.2; I.2.2; I.5.2; I.5.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.06433v1</id>
    <updated>2016-03-21T14:23:00Z</updated>
    <published>2016-03-21T14:23:00Z</published>
    <title>Illumination-invariant image mosaic calculation based on logarithmic
  search</title>
    <summary>  This technical report describes an improved image mosaicking algorithm. It is
based on Jain's logarithmic search algorithm [Jain 1981] which is coupled to
the method of Kourogi (1999} for matching images in a video sequence.
Logarithmic search has a better invariance against illumination changes than
the original optical-flow-based method of Kourogi.
</summary>
    <author>
      <name>Wolfgang Konen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1603.06433v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.06433v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.09037v1</id>
    <updated>2016-03-30T04:40:31Z</updated>
    <published>2016-03-30T04:40:31Z</published>
    <title>Vector Quantization for Machine Vision</title>
    <summary>  This paper shows how to reduce the computational cost for a variety of common
machine vision tasks by operating directly in the compressed domain,
particularly in the context of hardware acceleration. Pyramid Vector
Quantization (PVQ) is the compression technique of choice and its properties
are exploited to simplify Support Vector Machines (SVM), Convolutional Neural
Networks(CNNs), Histogram of Oriented Gradients (HOG) features, interest points
matching and other algorithms.
</summary>
    <author>
      <name>Vincenzo Liguori</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1603.09037v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.09037v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.09129v1</id>
    <updated>2016-03-30T11:11:29Z</updated>
    <published>2016-03-30T11:11:29Z</published>
    <title>Exploiting Facial Landmarks for Emotion Recognition in the Wild</title>
    <summary>  In this paper, we describe an entry to the third Emotion Recognition in the
Wild Challenge, EmotiW2015. We detail the associated experiments and show that,
through more accurately locating the facial landmarks, and considering only the
distances between them, we can achieve a surprising level of performance. The
resulting system is not only more accurate than the challenge baseline, but
also much simpler.
</summary>
    <author>
      <name>Matthew Day</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, ICMI 2015</arxiv:comment>
    <link href="http://arxiv.org/abs/1603.09129v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.09129v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.10" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.04926v1</id>
    <updated>2016-04-17T20:48:49Z</updated>
    <published>2016-04-17T20:48:49Z</published>
    <title>Some medical applications of example-based super-resolution</title>
    <summary>  Example-based super-resolution (EBSR) reconstructs a high-resolution image
from a low-resolution image, given a training set of high-resolution images. In
this note I propose some applications of EBSR to medical imaging. A particular
interesting application, which I call "x-ray voxelization", approximates the
result of a CT scan from an x-ray image.
</summary>
    <author>
      <name>Ramin Zabih</name>
    </author>
    <link href="http://arxiv.org/abs/1604.04926v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.04926v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.04250v2</id>
    <updated>2016-08-01T13:25:06Z</updated>
    <published>2016-05-13T16:56:10Z</published>
    <title>Color Homography</title>
    <summary>  We show the surprising result that colors across a change in viewing
condition (changing light color, shading and camera) are related by a
homography. Our homography color correction application delivers improved color
fidelity compared with the linear least-square.
</summary>
    <author>
      <name>Graham D. Finlayson</name>
    </author>
    <author>
      <name>Han Gong</name>
    </author>
    <author>
      <name>Robert B. Fisher</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted by Progress in Colour Studies 2016</arxiv:comment>
    <link href="http://arxiv.org/abs/1605.04250v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.04250v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.04785v1</id>
    <updated>2016-05-16T14:42:34Z</updated>
    <published>2016-05-16T14:42:34Z</published>
    <title>An Alternative Matting Laplacian</title>
    <summary>  Cutting out and object and estimate its transparency mask is a key task in
many applications. We take on the work on closed-form matting by Levin et al.,
that is used at the core of many matting techniques, and propose an alternative
formulation that offers more flexible controls over the matting priors. We also
show that this new approach is efficient at upscaling transparency maps from
coarse estimates.
</summary>
    <author>
      <name>François Pitié</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICIP 2016</arxiv:comment>
    <link href="http://arxiv.org/abs/1605.04785v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.04785v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.03473v1</id>
    <updated>2016-06-10T20:34:39Z</updated>
    <published>2016-06-10T20:34:39Z</published>
    <title>Face Detection with the Faster R-CNN</title>
    <summary>  The Faster R-CNN has recently demonstrated impressive results on various
object detection benchmarks. By training a Faster R-CNN model on the large
scale WIDER face dataset, we report state-of-the-art results on two widely used
face detection benchmarks, FDDB and the recently released IJB-A.
</summary>
    <author>
      <name>Huaizu Jiang</name>
    </author>
    <author>
      <name>Erik Learned-Miller</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">technical report</arxiv:comment>
    <link href="http://arxiv.org/abs/1606.03473v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.03473v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.08315v1</id>
    <updated>2016-06-27T15:23:04Z</updated>
    <published>2016-06-27T15:23:04Z</published>
    <title>Depth Estimation from Single Image using Sparse Representations</title>
    <summary>  Monocular depth estimation is an interesting and challenging problem as there
is no analytic mapping known between an intensity image and its depth map.
Recently there has been a lot of data accumulated through depth-sensing
cameras, in parallel to that researchers started to tackle this task using
various learning algorithms. In this paper, a deep sparse coding method is
proposed for monocular depth estimation along with an approach for
deterministic dictionary initialization.
</summary>
    <author>
      <name>Yigit Oktar</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.13140/RG.2.1.5059.0323</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.13140/RG.2.1.5059.0323" rel="related"/>
    <link href="http://arxiv.org/abs/1606.08315v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.08315v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.03617v1</id>
    <updated>2016-08-11T20:53:48Z</updated>
    <published>2016-08-11T20:53:48Z</published>
    <title>Automatic detection of moving objects in video surveillance</title>
    <summary>  This work is in the field of video surveillance including motion detection.
The video surveillance is one of essential techniques for automatic video
analysis to extract crucial information or relevant scenes in video
surveillance systems. The aim of our work is to propose solutions for the
automatic detection of moving objects in real time with a surveillance camera.
The detected objects are objects that have some geometric shape (circle,
ellipse, square, and rectangle).
</summary>
    <author>
      <name>Larbi Guezouli</name>
    </author>
    <author>
      <name>Hanane Belhani</name>
    </author>
    <link href="http://arxiv.org/abs/1608.03617v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.03617v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.03832v1</id>
    <updated>2016-08-12T15:55:12Z</updated>
    <published>2016-08-12T15:55:12Z</published>
    <title>On Minimal Accuracy Algorithm Selection in Computer Vision and
  Intelligent Systems</title>
    <summary>  In this paper we discuss certain theoretical properties of algorithm
selection approach to image processing and to intelligent system in general. We
analyze the theoretical limits of algorithm selection with respect to the
algorithm selection accuracy. We show the theoretical formulation of a crisp
bound on the algorithm selector precision guaranteeing to always obtain better
than the best available algorithm result.
</summary>
    <author>
      <name>Martin Lukac</name>
    </author>
    <author>
      <name>Kamila Abdiyeva</name>
    </author>
    <author>
      <name>Michitaka Kameyama</name>
    </author>
    <link href="http://arxiv.org/abs/1608.03832v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.03832v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.02271v2</id>
    <updated>2016-09-09T18:37:03Z</updated>
    <published>2016-09-08T04:49:31Z</published>
    <title>Ashwin: Plug-and-Play System for Machine-Human Image Annotation</title>
    <summary>  We present an end-to-end machine-human image annotation system where each
component can be attached in a plug-and-play fashion. These components include
Feature Extraction, Machine Classifier, Task Sampling and Crowd Consensus.
</summary>
    <author>
      <name>Anand Sriraman</name>
    </author>
    <author>
      <name>Mandar Kulkarni</name>
    </author>
    <author>
      <name>Rahul Kumar</name>
    </author>
    <author>
      <name>Kanika Kalra</name>
    </author>
    <author>
      <name>Purushotam Radadia</name>
    </author>
    <author>
      <name>Shirish Karande</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">HCOMP 2016 Demonstrations Track</arxiv:comment>
    <link href="http://arxiv.org/abs/1609.02271v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.02271v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.03529v1</id>
    <updated>2016-09-12T19:00:24Z</updated>
    <published>2016-09-12T19:00:24Z</published>
    <title>Examining Representational Similarity in ConvNets and the Primate Visual
  Cortex</title>
    <summary>  We compare several ConvNets with different depth and regularization
techniques with multi-unit macaque IT cortex recordings and assess the impact
of the same on representational similarity with the primate visual cortex. We
find that with increasing depth and validation performance, ConvNet features
are closer to cortical IT representations.
</summary>
    <author>
      <name>Abhimanyu Dubey</name>
    </author>
    <author>
      <name> Jayadeva</name>
    </author>
    <author>
      <name>Sumeet Agarwal</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, short abstract, Accepted to the Workshop on Biological and
  Artificial Vision, ECCV, 2016</arxiv:comment>
    <link href="http://arxiv.org/abs/1609.03529v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.03529v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.05001v1</id>
    <updated>2016-09-16T11:20:07Z</updated>
    <published>2016-09-16T11:20:07Z</published>
    <title>Stamp processing with examplar features</title>
    <summary>  Document digitization is becoming increasingly crucial. In this work, we
propose a shape based approach for automatic stamp verification/detection in
document images using an unsupervised feature learning. Given a small set of
training images, our algorithm learns an appropriate shape representation using
an unsupervised clustering. Experimental results demonstrate the effectiveness
of our framework in challenging scenarios.
</summary>
    <author>
      <name>Yash Bhalgat</name>
    </author>
    <author>
      <name>Mandar Kulkarni</name>
    </author>
    <author>
      <name>Shirish Karande</name>
    </author>
    <author>
      <name>Sachin Lodha</name>
    </author>
    <link href="http://arxiv.org/abs/1609.05001v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.05001v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.07597v1</id>
    <updated>2016-09-24T10:32:30Z</updated>
    <published>2016-09-24T10:32:30Z</published>
    <title>DimensionApp : android app to estimate object dimensions</title>
    <summary>  In this project, we develop an android app that uses on computer vision
techniques to estimate an object dimension present in field of view. The app
while having compact size, is accurate upto +/- 5 mm and robust towards touch
inputs. We use single-view metrology to compute accurate measurement. Unlike
previous approaches, our technique does not rely on line detection and can be
generalize to any object shape easily.
</summary>
    <author>
      <name>Suriya Singh</name>
    </author>
    <author>
      <name>Vijay Kumar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Project Report 2014</arxiv:comment>
    <link href="http://arxiv.org/abs/1609.07597v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.07597v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1610.03660v1</id>
    <updated>2016-10-12T10:19:36Z</updated>
    <published>2016-10-12T10:19:36Z</published>
    <title>Image Based Camera Localization: an Overview</title>
    <summary>  Recently, virtual reality, augmented reality, robotics, self-driving cars et
al attractive much attention of industrial community, in which image based
camera localization is a key task. It is urgent to give an overview of image
based camera localization. In this paper, an overview of image based camera
localization is presented. It will be useful to not only researchers but also
engineers.
</summary>
    <author>
      <name>Yihong Wu</name>
    </author>
    <link href="http://arxiv.org/abs/1610.03660v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1610.03660v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1610.04575v1</id>
    <updated>2016-04-19T03:16:14Z</updated>
    <published>2016-04-19T03:16:14Z</published>
    <title>Comparing Face Detection and Recognition Techniques</title>
    <summary>  This paper implements and compares different techniques for face detection
and recognition. One is find where the face is located in the images that is
face detection and second is face recognition that is identifying the person.
We study three techniques in this paper: Face detection using self organizing
map (SOM), Face recognition by projection and nearest neighbor and Face
recognition using SVM.
</summary>
    <author>
      <name>Jyothi Korra</name>
    </author>
    <link href="http://arxiv.org/abs/1610.04575v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1610.04575v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1610.09520v1</id>
    <updated>2016-10-29T14:54:28Z</updated>
    <published>2016-10-29T14:54:28Z</published>
    <title>Multi-Camera Occlusion and Sudden-Appearance-Change Detection Using
  Hidden Markovian Chains</title>
    <summary>  This paper was originally submitted to Xinova as a response to a Request for
Invention (RFI) on new event monitoring methods. In this paper, a new object
tracking algorithm using multiple cameras for surveillance applications is
proposed. The proposed system can detect sudden-appearance-changes and
occlusions using a hidden Markovian statistical model. The experimental results
confirm that our system detect the sudden-appearance changes and occlusions
reliably.
</summary>
    <author>
      <name>Xudong Ma</name>
    </author>
    <link href="http://arxiv.org/abs/1610.09520v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1610.09520v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1611.03873v1</id>
    <updated>2016-11-11T21:00:58Z</updated>
    <published>2016-11-11T21:00:58Z</published>
    <title>Effective sparse representation of X-Ray medical images</title>
    <summary>  Effective sparse representation of X-Ray medical images within the context of
data reduction is considered. The proposed framework is shown to render an
enormous reduction in the cardinality of the data set required to represent
this class of images at very good quality. The particularity of the approach is
that it can be implemented at very competitive processing time and low memory
requirements
</summary>
    <author>
      <name>Laura Rebollo-Neira</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Routines for implementing the approach are available on
  http://www.nonlinear-approx.info/examples/node06.html</arxiv:comment>
    <link href="http://arxiv.org/abs/1611.03873v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1611.03873v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.01035v1</id>
    <updated>2017-01-04T14:53:07Z</updated>
    <published>2017-01-04T14:53:07Z</published>
    <title>Path-following based Point Matching using Similarity Transformation</title>
    <summary>  To address the problem of 3D point matching where the poses of two point sets
are unknown, we adapt a recently proposed path following based method to use
similarity transformation instead of the original affine transformation. The
reduced number of transformation parameters leads to more constrained and
desirable matching results. Experimental results demonstrate better robustness
of the proposed method over state-of-the-art methods.
</summary>
    <author>
      <name>Wei Lian</name>
    </author>
    <link href="http://arxiv.org/abs/1701.01035v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.01035v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.01885v1</id>
    <updated>2017-01-07T21:12:24Z</updated>
    <published>2017-01-07T21:12:24Z</published>
    <title>Group Visual Sentiment Analysis</title>
    <summary>  In this paper, we introduce a framework for classifying images according to
high-level sentiment. We subdivide the task into three primary problems:
emotion classification on faces, human pose estimation, and 3D estimation and
clustering of groups of people. We introduce novel algorithms for matching body
parts to a common individual and clustering people in images based on physical
location and orientation. Our results outperform several baseline approaches.
</summary>
    <author>
      <name>Zeshan Hussain</name>
    </author>
    <author>
      <name>Tariq Patanam</name>
    </author>
    <author>
      <name>Hardie Cate</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1701.01885v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.01885v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.07354v1</id>
    <updated>2017-01-25T15:35:09Z</updated>
    <published>2017-01-25T15:35:09Z</published>
    <title>Photographic dataset: playing cards</title>
    <summary>  This is a photographic dataset collected for testing image processing
algorithms. The idea is to have images that can exploit the properties of total
variation, therefore a set of playing cards was distributed on the scene. The
dataset is made available at www.fips.fi/photographic_dataset2.php
</summary>
    <author>
      <name>David Villacis</name>
    </author>
    <author>
      <name>Santeri Kaupinmäki</name>
    </author>
    <author>
      <name>Samuli Siltanen</name>
    </author>
    <author>
      <name>Teemu Helenius</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 12 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1701.07354v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.07354v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1702.00723v1</id>
    <updated>2017-02-01T18:32:12Z</updated>
    <published>2017-02-01T18:32:12Z</published>
    <title>Handwritten Recognition Using SVM, KNN and Neural Network</title>
    <summary>  Handwritten recognition (HWR) is the ability of a computer to receive and
interpret intelligible handwritten input from source such as paper documents,
photographs, touch-screens and other devices. In this paper we will using three
(3) classification t o re cognize the handwritten which is SVM, KNN and Neural
Network.
</summary>
    <author>
      <name>Norhidayu Abdul Hamid</name>
    </author>
    <author>
      <name>Nilam Nur Amir Sjarif</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages ; 22 Figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1702.00723v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1702.00723v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68Txx" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1702.07006v1</id>
    <updated>2017-02-22T21:03:49Z</updated>
    <published>2017-02-22T21:03:49Z</published>
    <title>Synthesising Dynamic Textures using Convolutional Neural Networks</title>
    <summary>  Here we present a parametric model for dynamic textures. The model is based
on spatiotemporal summary statistics computed from the feature representations
of a Convolutional Neural Network (CNN) trained on object recognition. We
demonstrate how the model can be used to synthesise new samples of dynamic
textures and to predict motion in simple movies.
</summary>
    <author>
      <name>Christina M. Funke</name>
    </author>
    <author>
      <name>Leon A. Gatys</name>
    </author>
    <author>
      <name>Alexander S. Ecker</name>
    </author>
    <author>
      <name>Matthias Bethge</name>
    </author>
    <link href="http://arxiv.org/abs/1702.07006v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1702.07006v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1702.07963v1</id>
    <updated>2017-02-26T00:56:25Z</updated>
    <published>2017-02-26T00:56:25Z</published>
    <title>Spatially Aware Melanoma Segmentation Using Hybrid Deep Learning
  Techniques</title>
    <summary>  In this paper, we proposed using a hybrid method that utilises deep
convolutional and recurrent neural networks for accurate delineation of skin
lesion of images supplied with ISBI 2017 lesion segmentation challenge. The
proposed method was trained using 1800 images and tested on 150 images from
ISBI 2017 challenge.
</summary>
    <author>
      <name>M. Attia</name>
    </author>
    <author>
      <name>M. Hossny</name>
    </author>
    <author>
      <name>S. Nahavandi</name>
    </author>
    <author>
      <name>A. Yazdabadi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ISIC2017</arxiv:comment>
    <link href="http://arxiv.org/abs/1702.07963v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1702.07963v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.01402v1</id>
    <updated>2017-03-04T06:32:15Z</updated>
    <published>2017-03-04T06:32:15Z</published>
    <title>Skin Lesion Classification Using Deep Multi-scale Convolutional Neural
  Networks</title>
    <summary>  We present a deep learning approach to the ISIC 2017 Skin Lesion
Classification Challenge using a multi-scale convolutional neural network. Our
approach utilizes an Inception-v3 network pre-trained on the ImageNet dataset,
which is fine-tuned for skin lesion classification using two different scales
of input images.
</summary>
    <author>
      <name>Terrance DeVries</name>
    </author>
    <author>
      <name>Dhanesh Ramachandram</name>
    </author>
    <link href="http://arxiv.org/abs/1703.01402v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.01402v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.03108v1</id>
    <updated>2017-03-09T02:35:59Z</updated>
    <published>2017-03-09T02:35:59Z</published>
    <title>Image Classification of Melanoma, Nevus and Seborrheic Keratosis by Deep
  Neural Network Ensemble</title>
    <summary>  This short paper reports the method and the evaluation results of Casio and
Shinshu University joint team for the ISBI Challenge 2017 - Skin Lesion
Analysis Towards Melanoma Detection - Part 3: Lesion Classification hosted by
ISIC. Our online validation score was 0.958 with melanoma classifier AUC 0.924
and seborrheic keratosis classifier AUC 0.993.
</summary>
    <author>
      <name>Kazuhisa Matsunaga</name>
    </author>
    <author>
      <name>Akira Hamada</name>
    </author>
    <author>
      <name>Akane Minagawa</name>
    </author>
    <author>
      <name>Hiroshi Koga</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages. 3 figures. ISIC2017</arxiv:comment>
    <link href="http://arxiv.org/abs/1703.03108v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.03108v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.03186v1</id>
    <updated>2017-03-09T09:14:40Z</updated>
    <published>2017-03-09T09:14:40Z</published>
    <title>Segmenting Dermoscopic Images</title>
    <summary>  We propose an automatic algorithm, named SDI, for the segmentation of skin
lesions in dermoscopic images, articulated into three main steps: selection of
the image ROI, selection of the segmentation band, and segmentation. We present
extensive experimental results achieved by the SDI algorithm on the lesion
segmentation dataset made available for the ISIC 2017 challenge on Skin Lesion
Analysis Towards Melanoma Detection, highlighting its advantages and
disadvantages.
</summary>
    <author>
      <name>Mario Rosario Guarracino</name>
    </author>
    <author>
      <name>Lucia Maddalena</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1703.03186v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.03186v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.03888v1</id>
    <updated>2017-03-11T01:18:14Z</updated>
    <published>2017-03-11T01:18:14Z</published>
    <title>Segmentation of skin lesions based on fuzzy classification of pixels and
  histogram thresholding</title>
    <summary>  This paper proposes an innovative method for segmentation of skin lesions in
dermoscopy images developed by the authors, based on fuzzy classification of
pixels and histogram thresholding.
</summary>
    <author>
      <name>Jose Luis Garcia-Arroyo</name>
    </author>
    <author>
      <name>Begonya Garcia-Zapirain</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1703.03888v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.03888v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.08366v1</id>
    <updated>2017-03-24T11:39:26Z</updated>
    <published>2017-03-24T11:39:26Z</published>
    <title>A Hybrid Deep Learning Approach for Texture Analysis</title>
    <summary>  Texture classification is a problem that has various applications such as
remote sensing and forest species recognition. Solutions tend to be custom fit
to the dataset used but fails to generalize. The Convolutional Neural Network
(CNN) in combination with Support Vector Machine (SVM) form a robust selection
between powerful invariant feature extractor and accurate classifier. The
fusion of experts provides stability in classification rates among different
datasets.
</summary>
    <author>
      <name>Hussein Adly</name>
    </author>
    <author>
      <name>Mohamed Moustafa</name>
    </author>
    <link href="http://arxiv.org/abs/1703.08366v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.08366v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1704.02956v1</id>
    <updated>2017-04-10T17:13:00Z</updated>
    <published>2017-04-10T17:13:00Z</published>
    <title>Surface Normals in the Wild</title>
    <summary>  We study the problem of single-image depth estimation for images in the wild.
We collect human annotated surface normals and use them to train a neural
network that directly predicts pixel-wise depth. We propose two novel loss
functions for training with surface normal annotations. Experiments on NYU
Depth and our own dataset demonstrate that our approach can significantly
improve the quality of depth estimation in the wild.
</summary>
    <author>
      <name>Weifeng Chen</name>
    </author>
    <author>
      <name>Donglai Xiang</name>
    </author>
    <author>
      <name>Jia Deng</name>
    </author>
    <link href="http://arxiv.org/abs/1704.02956v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1704.02956v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1704.03966v1</id>
    <updated>2017-04-13T01:41:30Z</updated>
    <published>2017-04-13T01:41:30Z</published>
    <title>Collaborative Low-Rank Subspace Clustering</title>
    <summary>  In this paper we present Collaborative Low-Rank Subspace Clustering. Given
multiple observations of a phenomenon we learn a unified representation matrix.
This unified matrix incorporates the features from all the observations, thus
increasing the discriminative power compared with learning the representation
matrix on each observation separately. Experimental evaluation shows that our
method outperforms subspace clustering on separate observations and the state
of the art collaborative learning algorithm.
</summary>
    <author>
      <name>Stephen Tierney</name>
    </author>
    <author>
      <name>Yi Guo</name>
    </author>
    <author>
      <name>Junbin Gao</name>
    </author>
    <link href="http://arxiv.org/abs/1704.03966v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1704.03966v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.01148v1</id>
    <updated>2017-05-02T19:21:51Z</updated>
    <published>2017-05-02T19:21:51Z</published>
    <title>Recovery of structure of looped jointed objects from multiframes</title>
    <summary>  A method to recover structural parameters of looped jointed objects from
multiframes is being developed. Each rigid part of the jointed body needs only
to be traced at two (that is at junction) points.
  This method has been linearized for 4-part loops, with recovery from at least
19 frames.
</summary>
    <author>
      <name>Mieczysław Kłopotek</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">a preliminary version for Machine Graphics and Vision, Vol. 3 No.
  4, pp. 645-656, 1995</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1705.01148v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.01148v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.01809v1</id>
    <updated>2017-05-04T12:20:56Z</updated>
    <published>2017-05-04T12:20:56Z</published>
    <title>Pixel Normalization from Numeric Data as Input to Neural Networks</title>
    <summary>  Text to image transformation for input to neural networks requires
intermediate steps. This paper attempts to present a new approach to pixel
normalization so as to convert textual data into image, suitable as input for
neural networks. This method can be further improved by its Graphics Processing
Unit (GPU) implementation to provide significant speedup in computational time.
</summary>
    <author>
      <name>Parth Sane</name>
    </author>
    <author>
      <name>Ravindra Agrawal</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE WiSPNET 2017 conference in Chennai</arxiv:comment>
    <link href="http://arxiv.org/abs/1705.01809v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.01809v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.04272v1</id>
    <updated>2017-04-29T11:14:16Z</updated>
    <published>2017-04-29T11:14:16Z</published>
    <title>Improved underwater image enhancement algorithms based on partial
  differential equations (PDEs)</title>
    <summary>  The experimental results of improved underwater image enhancement algorithms
based on partial differential equations (PDEs) are presented in this report.
This second work extends the study of previous work and incorporating several
improvements into the revised algorithm. Experiments show the evidence of the
improvements when compared to previously proposed approaches and other
conventional algorithms found in the literature.
</summary>
    <author>
      <name>U. A. Nnolim</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">22 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1705.04272v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.04272v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.00083v1</id>
    <updated>2017-05-31T20:44:55Z</updated>
    <published>2017-05-31T20:44:55Z</published>
    <title>Blood capillaries and vessels segmentation in optical coherence
  tomography angiogram using fuzzy C-means and Curvelet transform</title>
    <summary>  This paper has been removed from arXiv as the submitter did not have
ownership of the data presented in this work.
</summary>
    <author>
      <name>Fariborz Taherkhani</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: This paper has been removed from arXiv as the
  submitter did not have ownership of the data presented in this work</arxiv:comment>
    <link href="http://arxiv.org/abs/1706.00083v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.00083v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.03497v1</id>
    <updated>2017-06-12T08:04:42Z</updated>
    <published>2017-06-12T08:04:42Z</published>
    <title>A filter based approach for inbetweening</title>
    <summary>  We present a filter based approach for inbetweening. We train a convolutional
neural network to generate intermediate frames. This network aim to generate
smooth animation of line drawings. Our method can process scanned images
directly. Our method does not need to compute correspondence of lines and
topological changes explicitly. We experiment our method with real animation
production data. The results show that our method can generate intermediate
frames partially.
</summary>
    <author>
      <name>Yuichi Yagi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, in Japanese</arxiv:comment>
    <link href="http://arxiv.org/abs/1706.03497v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.03497v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.05534v1</id>
    <updated>2017-06-17T13:33:29Z</updated>
    <published>2017-06-17T13:33:29Z</published>
    <title>Rotation Invariance Neural Network</title>
    <summary>  Rotation invariance and translation invariance have great values in image
recognition tasks. In this paper, we bring a new architecture in convolutional
neural network (CNN) named cyclic convolutional layer to achieve rotation
invariance in 2-D symbol recognition. We can also get the position and
orientation of the 2-D symbol by the network to achieve detection purpose for
multiple non-overlap target. Last but not least, this architecture can achieve
one-shot learning in some cases using those invariance.
</summary>
    <author>
      <name>Shiyuan Li</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1706.05534v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.05534v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.06230v1</id>
    <updated>2017-06-20T00:43:22Z</updated>
    <published>2017-06-20T00:43:22Z</published>
    <title>A Bayesian algorithm for detecting identity matches and fraud in image
  databases</title>
    <summary>  A statistical algorithm for categorizing different types of matches and fraud
in image databases is presented. The approach is based on a generative model of
a graph representing images and connections between pairs of identities,
trained using properties of a matching algorithm between images.
</summary>
    <author>
      <name>Gaurav Thakur</name>
    </author>
    <link href="http://arxiv.org/abs/1706.06230v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.06230v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.07757v1</id>
    <updated>2017-04-14T14:54:14Z</updated>
    <published>2017-04-14T14:54:14Z</published>
    <title>Improved Human Emotion Recognition Using Symmetry of Facial Key Points
  with Dihedral Group</title>
    <summary>  This article describes how to deploy dihedral group theory to detect Facial
Key Points (FKP) symmetry to recognize emotions. The method can be applied in
many other areas which those have the same data texture.
</summary>
    <author>
      <name>Mehdi Ghayoumi</name>
    </author>
    <author>
      <name>Arvind Bansal</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IJASCSE Volume 6 Issue 01 2017</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1706.07757v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.07757v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.01159v1</id>
    <updated>2017-07-04T21:34:08Z</updated>
    <published>2017-07-04T21:34:08Z</published>
    <title>UPSET and ANGRI : Breaking High Performance Image Classifiers</title>
    <summary>  In this paper, targeted fooling of high performance image classifiers is
achieved by developing two novel attack methods. The first method generates
universal perturbations for target classes and the second generates image
specific perturbations. Extensive experiments are conducted on MNIST and
CIFAR10 datasets to provide insights about the proposed algorithms and show
their effectiveness.
</summary>
    <author>
      <name>Sayantan Sarkar</name>
    </author>
    <author>
      <name>Ankan Bansal</name>
    </author>
    <author>
      <name>Upal Mahbub</name>
    </author>
    <author>
      <name>Rama Chellappa</name>
    </author>
    <link href="http://arxiv.org/abs/1707.01159v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.01159v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.02051v1</id>
    <updated>2017-07-07T06:27:54Z</updated>
    <published>2017-07-07T06:27:54Z</published>
    <title>Image Segmentation Algorithms Overview</title>
    <summary>  The technology of image segmentation is widely used in medical image
processing, face recognition pedestrian detection, etc. The current image
segmentation techniques include region-based segmentation, edge detection
segmentation, segmentation based on clustering, segmentation based on
weakly-supervised learning in CNN, etc. This paper analyzes and summarizes
these algorithms of image segmentation, and compares the advantages and
disadvantages of different algorithms. Finally, we make a prediction of the
development trend of image segmentation with the combination of these
algorithms.
</summary>
    <author>
      <name>Song Yuheng</name>
    </author>
    <author>
      <name>Yan Hao</name>
    </author>
    <link href="http://arxiv.org/abs/1707.02051v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.02051v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.06825v1</id>
    <updated>2017-07-21T10:17:33Z</updated>
    <published>2017-07-21T10:17:33Z</published>
    <title>Evaluation of Hashing Methods Performance on Binary Feature Descriptors</title>
    <summary>  In this paper we evaluate performance of data-dependent hashing methods on
binary data. The goal is to find a hashing method that can effectively produce
lower dimensional binary representation of 512-bit FREAK descriptors. A
representative sample of recent unsupervised, semi-supervised and supervised
hashing methods was experimentally evaluated on large datasets of labelled
binary FREAK feature descriptors.
</summary>
    <author>
      <name>Jacek Komorowski</name>
    </author>
    <author>
      <name>Tomasz Trzcinski</name>
    </author>
    <link href="http://arxiv.org/abs/1707.06825v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.06825v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.08722v1</id>
    <updated>2017-07-27T07:00:02Z</updated>
    <published>2017-07-27T07:00:02Z</published>
    <title>Algebraic Relations and Triangulation of Unlabeled Image Points</title>
    <summary>  In multiview geometry when correspondences among multiple views are unknown
the image points can be understood as being unlabeled. This is a common problem
in computer vision. We give a novel approach to handle such a situation by
regarding unlabeled point configurations as points on the Chow variety
$\text{Sym}_m(\mathbb{P}^2)$. For two unlabeled points we design an algorithm
that solves the triangulation problem with unknown correspondences. Further the
unlabeled multiview variety $\text{Sym}_m(V_A)$ is studied.
</summary>
    <author>
      <name>André Wagner</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1707.08722v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.08722v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.09869v1</id>
    <updated>2017-07-23T01:35:55Z</updated>
    <published>2017-07-23T01:35:55Z</published>
    <title>A comment on the paper Prediction of Kidney Function from Biopsy Images
  using Convolutional Neural Networks</title>
    <summary>  This letter presente a comment on the paper Prediction of Kidney Function
from Biopsy Images using Convolutional Neural Networks by Ledbetter et al.
(2017)
</summary>
    <author>
      <name>Washington LC dos-Santos</name>
    </author>
    <author>
      <name>Angelo A Duarte</name>
    </author>
    <author>
      <name>Luiz AR de Freitas</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1707.09869v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.09869v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.00786v1</id>
    <updated>2017-09-04T02:13:15Z</updated>
    <published>2017-09-04T02:13:15Z</published>
    <title>Machine learning methods for histopathological image analysis</title>
    <summary>  Abundant accumulation of digital histopathological images has led to the
increased demand for their analysis, such as computer-aided diagnosis using
machine learning techniques. However, digital pathological images and related
tasks have some issues to be considered. In this mini-review, we introduce the
application of digital pathological image analysis using machine learning
algorithms, address some problems specific to such analysis, and propose
possible solutions.
</summary>
    <author>
      <name>Daisuke Komura</name>
    </author>
    <author>
      <name>Shumpei Ishikawa</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1709.00786v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.00786v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.05867v1</id>
    <updated>2017-09-18T11:28:15Z</updated>
    <published>2017-09-18T11:28:15Z</published>
    <title>Combinational neural network using Gabor filters for the classification
  of handwritten digits</title>
    <summary>  A classification algorithm that combines the components of k-nearest
neighbours and multilayer neural networks has been designed and tested. With
this method the computational time required for training the dataset has been
reduced substancially. Gabor filters were used for the feature extraction to
ensure a better performance. This algorithm is tested with MNIST dataset and it
will be integrated as a module in the object recognition software which is
currently under development.
</summary>
    <author>
      <name>N. Joshi</name>
    </author>
    <link href="http://arxiv.org/abs/1709.05867v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.05867v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1710.01462v1</id>
    <updated>2017-10-04T05:20:41Z</updated>
    <published>2017-10-04T05:20:41Z</published>
    <title>Secrets in Computing Optical Flow by Convolutional Networks</title>
    <summary>  Convolutional neural networks (CNNs) have been widely used over many areas in
compute vision. Especially in classification. Recently, FlowNet and several
works on opti- cal estimation using CNNs shows the potential ability of CNNs in
doing per-pixel regression. We proposed several CNNs network architectures that
can estimate optical flow, and fully unveiled the intrinsic different between
these structures.
</summary>
    <author>
      <name>Junxuan Li</name>
    </author>
    <link href="http://arxiv.org/abs/1710.01462v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1710.01462v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0001025v1</id>
    <updated>2000-01-28T14:23:18Z</updated>
    <published>2000-01-28T14:23:18Z</published>
    <title>Computational Geometry Column 38</title>
    <summary>  Recent results on curve reconstruction are described.
</summary>
    <author>
      <name>Joseph O'Rourke</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3 pages, 1 figure, 18 refs</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0001025v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0001025v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.2.2; I.5.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.3590v1</id>
    <updated>2013-01-16T05:20:01Z</updated>
    <published>2013-01-16T05:20:01Z</published>
    <title>Tree structured sparse coding on cubes</title>
    <summary>  A brief description of tree structured sparse coding on the binary cube.
</summary>
    <author>
      <name>Arthur Szlam</name>
    </author>
    <link href="http://arxiv.org/abs/1301.3590v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.3590v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.04311v1</id>
    <updated>2016-07-14T20:44:27Z</updated>
    <published>2016-07-14T20:44:27Z</published>
    <title>Defensive Distillation is Not Robust to Adversarial Examples</title>
    <summary>  We show that defensive distillation is not secure: it is no more resistant to
targeted misclassification attacks than unprotected neural networks.
</summary>
    <author>
      <name>Nicholas Carlini</name>
    </author>
    <author>
      <name>David Wagner</name>
    </author>
    <link href="http://arxiv.org/abs/1607.04311v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.04311v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.05549v1</id>
    <updated>2017-01-19T18:43:56Z</updated>
    <published>2017-01-19T18:43:56Z</published>
    <title>Deep Neural Networks - A Brief History</title>
    <summary>  Introduction to deep neural networks and their history.
</summary>
    <author>
      <name>Krzysztof J. Cios</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 14 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1701.05549v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.05549v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0004012v1</id>
    <updated>2000-04-21T17:32:29Z</updated>
    <published>2000-04-21T17:32:29Z</published>
    <title>Assisted Video Sequences Indexing : Motion Analysis Based on Interest
  Points</title>
    <summary>  This work deals with content-based video indexing. Our viewpoint is
semi-automatic analysis of compressed video. We consider the possible
applications of motion analysis and moving object detection : assisting moving
object indexing, summarising videos, and allowing image and motion queries. We
propose an approach based on interest points. As first results, we test and
compare the stability of different types of interest point detectors in
compressed sequences.
</summary>
    <author>
      <name>Emmanuel Etievent</name>
    </author>
    <author>
      <name>Frank Lebourgeois</name>
    </author>
    <author>
      <name>Jean-Michel Jolion</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">HTML, 8 pages, 6 figures, http://rfv.insa-lyon.fr/~etievent/</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Iciap 99, Venezia, 27-29 sept., 1059-1062</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0004012v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0004012v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.4.8; I.4.9" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0006047v1</id>
    <updated>2000-06-30T22:17:42Z</updated>
    <published>2000-06-30T22:17:42Z</published>
    <title>Geometric Morphology of Granular Materials</title>
    <summary>  We present a new method to transform the spectral pixel information of a
micrograph into an affine geometric description, which allows us to analyze the
morphology of granular materials. We use spectral and pulse-coupled neural
network based segmentation techniques to generate blobs, and a newly developed
algorithm to extract dilated contours. A constrained Delaunay tesselation of
the contour points results in a triangular mesh. This mesh is the basic
ingredient of the Chodal Axis Transform, which provides a morphological
decomposition of shapes. Such decomposition allows for grain separation and the
efficient computation of the statistical features of granular materials.
</summary>
    <author>
      <name>B. R. Schlei</name>
    </author>
    <author>
      <name>L. Prasad</name>
    </author>
    <author>
      <name>A. N. Skourikhine</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1117/12.404821</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1117/12.404821" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 9 figures. For more information visit
  http://www.nis.lanl.gov/~bschlei/labvis/index.html</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0006047v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0006047v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.10;I.4.6;I.4.10" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0109116v1</id>
    <updated>2001-09-26T22:14:40Z</updated>
    <published>2001-09-26T22:14:40Z</published>
    <title>Digital Color Imaging</title>
    <summary>  This paper surveys current technology and research in the area of digital
color imaging. In order to establish the background and lay down terminology,
fundamental concepts of color perception and measurement are first presented
us-ing vector-space notation and terminology. Present-day color recording and
reproduction systems are reviewed along with the common mathematical models
used for representing these devices. Algorithms for processing color images for
display and communication are surveyed, and a forecast of research trends is
attempted. An extensive bibliography is provided.
</summary>
    <author>
      <name>Gaurav Sharma</name>
    </author>
    <author>
      <name>H. Joel Trussell</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/83.597268</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/83.597268" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE Trans. Image Proc., vol. 6, no. 7, pp. 901-932, Jul. 1997</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0109116v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0109116v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="A.1;I.4,I.3.3,I.2.10;I.3.7;B.4.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0201019v1</id>
    <updated>2002-01-22T21:00:35Z</updated>
    <published>2002-01-22T21:00:35Z</published>
    <title>Structure from Motion: Theoretical Foundations of a Novel Approach Using
  Custom Built Invariants</title>
    <summary>  We rephrase the problem of 3D reconstruction from images in terms of
intersections of projections of orbits of custom built Lie groups actions. We
then use an algorithmic method based on moving frames "a la Fels-Olver" to
obtain a fundamental set of invariants of these groups actions. The invariants
are used to define a set of equations to be solved by the points of the 3D
object, providing a new technique for recovering 3D structure from motion.
</summary>
    <author>
      <name>Pierre-Louis Bazin</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Brown University</arxiv:affiliation>
    </author>
    <author>
      <name>Mireille Boutin</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Brown University</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0201019v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0201019v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.4.8;I.2.10" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0303015v1</id>
    <updated>2003-03-18T21:30:36Z</updated>
    <published>2003-03-18T21:30:36Z</published>
    <title>Statistical efficiency of curve fitting algorithms</title>
    <summary>  We study the problem of fitting parametrized curves to noisy data. Under
certain assumptions (known as Cartesian and radial functional models), we
derive asymptotic expressions for the bias and the covariance matrix of the
parameter estimates. We also extend Kanatani's version of the Cramer-Rao lower
bound, which he proved for unbiased estimates only, to more general estimates
that include many popular algorithms (most notably, the orthogonal least
squares and algebraic fits). We then show that the gradient-weighted algebraic
fit is statistically efficient and describe all other statistically efficient
algebraic fits.
</summary>
    <author>
      <name>N. Chernov</name>
    </author>
    <author>
      <name>C. Lesort</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0303015v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0303015v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.4.8;I.5.1;I.2.10;G.3;G.1.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0303024v1</id>
    <updated>2003-03-24T02:36:21Z</updated>
    <published>2003-03-24T02:36:21Z</published>
    <title>Differential Methods in Catadioptric Sensor Design with Applications to
  Panoramic Imaging</title>
    <summary>  We discuss design techniques for catadioptric sensors that realize given
projections. In general, these problems do not have solutions, but approximate
solutions may often be found that are visually acceptable. There are several
methods to approach this problem, but here we focus on what we call the
``vector field approach''. An application is given where a true panoramic
mirror is derived, i.e. a mirror that yields a cylindrical projection to the
viewer without any digital unwarping.
</summary>
    <author>
      <name>R. Andrew Hicks</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0303024v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0303024v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.9" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0307046v1</id>
    <updated>2003-07-20T05:18:59Z</updated>
    <published>2003-07-20T05:18:59Z</published>
    <title>A New Analytical Radial Distortion Model for Camera Calibration</title>
    <summary>  Common approach to radial distortion is by the means of polynomial
approximation, which introduces distortion-specific parameters into the camera
model and requires estimation of these distortion parameters. The task of
estimating radial distortion is to find a radial distortion model that allows
easy undistortion as well as satisfactory accuracy. This paper presents a new
radial distortion model with an easy analytical undistortion formula, which
also belongs to the polynomial approximation category. Experimental results are
presented to show that with this radial distortion model, satisfactory accuracy
is achieved.
</summary>
    <author>
      <name>Lili Ma</name>
    </author>
    <author>
      <name>YangQuan Chen</name>
    </author>
    <author>
      <name>Kevin L. Moore</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2 Postscript figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0307046v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0307046v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.4.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0307047v1</id>
    <updated>2003-07-20T05:54:42Z</updated>
    <published>2003-07-20T05:54:42Z</published>
    <title>Rational Radial Distortion Models with Analytical Undistortion Formulae</title>
    <summary>  The common approach to radial distortion is by the means of polynomial
approximation, which introduces distortion-specific parameters into the camera
model and requires estimation of these distortion parameters. The task of
estimating radial distortion is to find a radial distortion model that allows
easy undistortion as well as satisfactory accuracy. This paper presents a new
class of rational radial distortion models with easy analytical undistortion
formulae. Experimental results are presented to show that with this class of
rational radial distortion models, satisfactory and comparable accuracy is
achieved.
</summary>
    <author>
      <name>Lili Ma</name>
    </author>
    <author>
      <name>YangQuan Chen</name>
    </author>
    <author>
      <name>Kevin L. Moore</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0307047v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0307047v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.4.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0307072v1</id>
    <updated>2003-07-31T19:33:48Z</updated>
    <published>2003-07-31T19:33:48Z</published>
    <title>Camera Calibration: a USU Implementation</title>
    <summary>  The task of camera calibration is to estimate the intrinsic and extrinsic
parameters of a camera model. Though there are some restricted techniques to
infer the 3-D information about the scene from uncalibrated cameras, effective
camera calibration procedures will open up the possibility of using a wide
range of existing algorithms for 3-D reconstruction and recognition.
  The applications of camera calibration include vision-based metrology, robust
visual platooning and visual docking of mobile robots where the depth
information is important.
</summary>
    <author>
      <name>Lili Ma</name>
    </author>
    <author>
      <name>YangQuan Chen</name>
    </author>
    <author>
      <name>Kevin L. Moore</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">39 pages, 19 eps figures, source codes are in the codes.m and
  corners.dat</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0307072v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0307072v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.4.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0308037v1</id>
    <updated>2003-08-22T10:31:53Z</updated>
    <published>2003-08-22T10:31:53Z</published>
    <title>Distributed and Parallel Net Imaging</title>
    <summary>  A very complex vision system is developed to detect luminosity variations
connected with the discovery of new planets in the Universe. The traditional
imaging system can not manage a so large load. A private net is implemented to
perform an automatic vision and decision architecture. It lets to carry out an
on-line discrimination of interesting events by using two levels of triggers.
This system can even manage many Tbytes of data per day. The architecture
avails itself of a distributed parallel network system based on a maximum of
256 standard workstations with Microsoft Window as OS.
</summary>
    <author>
      <name>G. Iovane</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3 pages, 8 figures, Procedding of NIDays 2003 (sponsored by National
  Instruments), Rome 2003. Winner (2nd classified) of the price "Best
  Application of Measurement and Automation</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0308037v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0308037v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.4,I.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0308038v1</id>
    <updated>2003-08-22T18:47:33Z</updated>
    <published>2003-08-22T18:47:33Z</published>
    <title>Image Analysis in Astronomy for very large vision machine</title>
    <summary>  It is developed a very complex system (hardware/software) to detect
luminosity variations connected with the discovery of new planets outside the
Solar System. Traditional imaging approaches are very demanding in terms of
computing time; then, the implementation of an automatic vision and decision
software architecture is presented. It allows to perform an on-line
discrimination of interesting events by using two levels of triggers. A
fundamental challenge was to work with very large CCD camera (even 16k*16k
pixels) in line with very large telescopes. Then, the architecture can use a
distributed parallel network system based on a maximum of 256 standard
workstations.
</summary>
    <author>
      <name>G. Iovane</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3 pages, 9 figures, Proceeding of NIWEEK 2002 (sponsored by National
  Instruments), Austin (Usa), 2002</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0308038v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0308038v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.4,I.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0311012v1</id>
    <updated>2003-11-12T19:15:41Z</updated>
    <published>2003-11-12T19:15:41Z</published>
    <title>A rigorous definition of axial lines: ridges on isovist fields</title>
    <summary>  We suggest that 'axial lines' defined by (Hillier and Hanson, 1984) as lines
of uninterrupted movement within urban streetscapes or buildings, appear as
ridges in isovist fields (Benedikt, 1979). These are formed from the maximum
diametric lengths of the individual isovists, sometimes called viewsheds, that
make up these fields (Batty and Rana, 2004). We present an image processing
technique for the identification of lines from ridges, discuss current
strengths and weaknesses of the method, and show how it can be implemented
easily and effectively.
</summary>
    <author>
      <name>Rui Carvalho</name>
    </author>
    <author>
      <name>Michael Batty</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0311012v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0311012v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I2.10; I.4.10" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0402020v1</id>
    <updated>2004-02-11T16:34:16Z</updated>
    <published>2004-02-11T16:34:16Z</published>
    <title>Geometrical Complexity of Classification Problems</title>
    <summary>  Despite encouraging recent progresses in ensemble approaches, classification
methods seem to have reached a plateau in development. Further advances depend
on a better understanding of geometrical and topological characteristics of
point sets in high-dimensional spaces, the preservation of such characteristics
under feature transformations and sampling processes, and their interaction
with geometrical models used in classifiers. We discuss an attempt to measure
such properties from data sets and relate them to classifier accuracies.
</summary>
    <author>
      <name>Tin Kam Ho</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 7th Course on Ensemble Methods for Learning
  Machines at the International School on Neural Nets ``E.R. Caianiello''</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0402020v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0402020v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.5.0" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0404046v1</id>
    <updated>2004-04-22T13:42:48Z</updated>
    <published>2004-04-22T13:42:48Z</published>
    <title>Visualising the structure of architectural open spaces based on shape
  analysis</title>
    <summary>  This paper proposes the application of some well known two-dimensional
geometrical shape descriptors for the visualisation of the structure of
architectural open spaces. The paper demonstrates the use of visibility
measures such as distance to obstacles and amount of visible space to calculate
shape descriptors such as convexity and skeleton of the open space. The aim of
the paper is to indicate a simple, objective and quantifiable approach to
understand the structure of open spaces otherwise impossible due to the complex
construction of built structures.
</summary>
    <author>
      <name>Sanjay Rana</name>
    </author>
    <author>
      <name>Mike Batty</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 9 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Architectural Computing, 2(1), 2004</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0404046v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0404046v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.5;I.4.8;I.5.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0405093v2</id>
    <updated>2004-10-20T10:07:43Z</updated>
    <published>2004-05-25T11:36:34Z</published>
    <title>Computerized Face Detection and Recognition</title>
    <summary>  This publication presents methods for face detection, analysis and
recognition: fast normalized cross-correlation (fast correlation coefficient)
between multiple templates based face pre-detection method, method for
detection of exact face contour based on snakes and Generalized Gradient Vector
Flow field, method for combining recognition algorithms based on Cumulative
Match Characteristics in order to increase recognition speed and accuracy, and
face recognition method based on Principal Component Analysis of the Wavelet
Packet Decomposition allowing to use PCA - based recognition method with large
number of training images. For all the methods are presented experimental
results and comparisons of speed and accuracy with large face databases.
</summary>
    <author>
      <name>Vytautas Perlibakas</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">PhD dissertation summary. 35 pages, 12 figures, 7 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0405093v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0405093v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.4.8; I.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0405095v1</id>
    <updated>2004-05-25T22:40:42Z</updated>
    <published>2004-05-25T22:40:42Z</published>
    <title>Blind Detection and Compensation of Camera Lens Geometric Distortions</title>
    <summary>  This paper presents a blind detection and compensation technique for camera
lens geometric distortions. The lens distortion introduces higher-order
correlations in the frequency domain and in turn it can be detected using
higher-order spectral analysis tools without assuming any specific calibration
target. The existing blind lens distortion removal method only considered a
single-coefficient radial distortion model. In this paper, two coefficients are
considered to model approximately the geometric distortion. All the models
considered have analytical closed-form inverse formulae.
</summary>
    <author>
      <name>Lili Ma</name>
    </author>
    <author>
      <name>YangQuan Chen</name>
    </author>
    <author>
      <name>Kevin L. Moore</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 4 figures, 2 tables</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">SIAM Imaging Science, 2004</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0405095v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0405095v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I 4.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0503001v1</id>
    <updated>2005-03-01T05:17:33Z</updated>
    <published>2005-03-01T05:17:33Z</published>
    <title>Top-Down Unsupervised Image Segmentation (it sounds like oxymoron, but
  actually it is not)</title>
    <summary>  Pattern recognition is generally assumed as an interaction of two inversely
directed image-processing streams: the bottom-up information details gathering
and localization (segmentation) stream, and the top-down information features
aggregation, association and interpretation (recognition) stream. Inspired by
recent evidence from biological vision research and by the insights of
Kolmogorov Complexity theory, we propose a new, just top-down evolving,
procedure of initial image segmentation. We claim that traditional top-down
cognitive reasoning, which is supposed to guide the segmentation process to its
final result, is not at all a part of the image information content evaluation.
And that initial image segmentation is certainly an unsupervised process. We
present some illustrative examples, which support our claims.
</summary>
    <author>
      <name>Emanuel Diamant</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0503001v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0503001v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0504037v2</id>
    <updated>2006-10-31T14:34:47Z</updated>
    <published>2005-04-11T12:41:19Z</published>
    <title>Bayesian Restoration of Digital Images Employing Markov Chain Monte
  Carlo a Review</title>
    <summary>  A review of Bayesian restoration of digital images based on Monte Carlo
techniques is presented. The topics covered include Likelihood, Prior and
Posterior distributions, Poisson, Binay symmetric channel, and Gaussian channel
models of Likelihood distribution,Ising and Potts spin models of Prior
distribution, restoration of an image through Posterior maximization,
statistical estimation of a true image from Posterior ensembles, Markov Chain
Monte Carlo methods and cluster algorithms.
</summary>
    <author>
      <name>K. P. N. Murthy</name>
    </author>
    <author>
      <name>M. Janani</name>
    </author>
    <author>
      <name>B. Shenbga Priya</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">42 pages; 16 figures; revised version with several typos removed and
  mistakes in equations corrected</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0504037v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0504037v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cond-mat.stat-mech" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0604062v1</id>
    <updated>2006-04-14T04:40:29Z</updated>
    <published>2006-04-14T04:40:29Z</published>
    <title>Biologically Inspired Hierarchical Model for Feature Extraction and
  Localization</title>
    <summary>  Feature extraction and matching are among central problems of computer
vision. It is inefficent to search features over all locations and scales.
Neurophysiological evidence shows that to locate objects in a digital image the
human visual system employs visual attention to a specific object while
ignoring others. The brain also has a mechanism to search from coarse to fine.
In this paper, we present a feature extractor and an associated hierarchical
searching model to simulate such processes. With the hierarchical
representation of the object, coarse scanning is done through the matching of
the larger scale and precise localization is conducted through the matching of
the smaller scale. Experimental results justify the proposed model in its
effectiveness and efficiency to localize features.
</summary>
    <author>
      <name>Liang Wu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0604062v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0604062v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0606060v1</id>
    <updated>2006-06-13T12:53:45Z</updated>
    <published>2006-06-13T12:53:45Z</published>
    <title>Complex Networks: New Concepts and Tools for Real-Time Imaging and
  Vision</title>
    <summary>  This article discusses how concepts and methods of complex networks can be
applied to real-time imaging and computer vision. After a brief introduction of
complex networks basic concepts, their use as means to represent and
characterize images, as well as for modeling visual saliency, are briefly
described. The possibility to apply complex networks in order to model and
simulate the performance of parallel and distributed computing systems for
performance of visual methods is also proposed.
</summary>
    <author>
      <name>Luciano da Fontoura Costa</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0606060v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0606060v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0608115v1</id>
    <updated>2006-08-29T13:24:37Z</updated>
    <published>2006-08-29T13:24:37Z</published>
    <title>Neural Network Clustering Based on Distances Between Objects</title>
    <summary>  We present an algorithm of clustering of many-dimensional objects, where only
the distances between objects are used. Centers of classes are found with the
aid of neuron-like procedure with lateral inhibition. The result of clustering
does not depend on starting conditions. Our algorithm makes it possible to give
an idea about classes that really exist in the empirical data. The results of
computer simulations are presented.
</summary>
    <author>
      <name>Leonid B. Litinskii</name>
    </author>
    <author>
      <name>Dmitry E. Romanov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages,4 figures, presentation on ICANN (Athens, Greece, 2006)</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0608115v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0608115v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0610002v1</id>
    <updated>2006-09-30T08:05:02Z</updated>
    <published>2006-09-30T08:05:02Z</published>
    <title>Conditional Expressions for Blind Deconvolution: Derivative form</title>
    <summary>  We developed novel conditional expressions (CEs) for Lane and Bates' blind
deconvolution. The CEs are given in term of the derivatives of the zero-values
of the z-transform of given images. The CEs make it possible to automatically
detect multiple blur convolved in the given images all at once without
performing any analysis of the zero-sheets of the given images. We illustrate
the multiple blur-detection by the CEs for a model image
</summary>
    <author>
      <name>S. Aogaki</name>
    </author>
    <author>
      <name>I. Moritani</name>
    </author>
    <author>
      <name>T. Sugai</name>
    </author>
    <author>
      <name>F. Takeutchi</name>
    </author>
    <author>
      <name>F. M. Toyama</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 page, 3 figures, conference</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0610002v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0610002v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0701127v3</id>
    <updated>2007-12-28T15:30:19Z</updated>
    <published>2007-01-20T15:45:03Z</published>
    <title>A novel set of rotationally and translationally invariant features for
  images based on the non-commutative bispectrum</title>
    <summary>  We propose a new set of rotationally and translationally invariant features
for image or pattern recognition and classification. The new features are cubic
polynomials in the pixel intensities and provide a richer representation of the
original image than most existing systems of invariants. Our construction is
based on the generalization of the concept of bispectrum to the
three-dimensional rotation group SO(3), and a projection of the image onto the
sphere.
</summary>
    <author>
      <name>Risi Kondor</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The claim that the invariants uniquely determine the original image
  had to be dropped</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0701127v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0701127v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.4.7; I.2.10; I.5.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0701150v1</id>
    <updated>2007-01-24T15:13:06Z</updated>
    <published>2007-01-24T15:13:06Z</published>
    <title>Contains and Inside relationships within combinatorial Pyramids</title>
    <summary>  Irregular pyramids are made of a stack of successively reduced graphs
embedded in the plane. Such pyramids are used within the segmentation framework
to encode a hierarchy of partitions. The different graph models used within the
irregular pyramid framework encode different types of relationships between
regions. This paper compares different graph models used within the irregular
pyramid framework according to a set of relationships between regions. We also
define a new algorithm based on a pyramid of combinatorial maps which allows to
determine if one region contains the other using only local calculus.
</summary>
    <author>
      <name>Luc Brun</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">GREYC</arxiv:affiliation>
    </author>
    <author>
      <name>Walter G. Kropatsch</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PRIP</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">35 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Pattern Recognition 39 (01/04/2006) 515-526</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0701150v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0701150v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0703088v1</id>
    <updated>2007-03-16T00:18:11Z</updated>
    <published>2007-03-16T00:18:11Z</published>
    <title>Plot 94 in ambiance X-Window</title>
    <summary>  &lt;PLOT &gt; is a collection of routines to draw surfaces, contours and so on. In
this work we are presenting a version, that functions over work stations with
the operative system UNIX, that count with the graphic ambiance X-WINDOW with
the tools XLIB and OSF/MOTIF. This implant was realized for the work stations
DEC 5000-200, DEC IPX, and DEC ALFA of the CINVESTAV (Center of Investigation
and Advanced Studies). Also implanted in SILICON GRAPHICS of the CENAC
(National Center of Calculation of the Polytechnic National Institute
</summary>
    <author>
      <name>Ignacio Vega-Paez</name>
    </author>
    <author>
      <name>Carlos Alberto Hernandez-Hernandez</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings in Information Systems Analysis and Synthesis ISAS
  1995, 5th, International Symposium on Systems Research, Informatics and
  Cybernetics, pp. 135-139, August 16-20, 95, Baden-Baden, Germany</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0703088v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0703088v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0704.3635v1</id>
    <updated>2007-04-26T22:22:45Z</updated>
    <published>2007-04-26T22:22:45Z</published>
    <title>Rough Sets Computations to Impute Missing Data</title>
    <summary>  Many techniques for handling missing data have been proposed in the
literature. Most of these techniques are overly complex. This paper explores an
imputation technique based on rough set computations. In this paper,
characteristic relations are introduced to describe incompletely specified
decision tables.It is shown that the basic rough set idea of lower and upper
approximations for incompletely specified decision tables may be defined in a
variety of different ways. Empirical results obtained using real data are given
and they provide a valuable and promising insight to the problem of missing
data. Missing data were predicted with an accuracy of up to 99%.
</summary>
    <author>
      <name>Fulufhelo Vincent Nelwamondo</name>
    </author>
    <author>
      <name>Tshilidzi Marwala</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/0704.3635v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0704.3635v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0705.0449v1</id>
    <updated>2007-05-03T12:47:31Z</updated>
    <published>2007-05-03T12:47:31Z</published>
    <title>Multiresolution Approximation of Polygonal Curves in Linear Complexity</title>
    <summary>  We propose a new algorithm to the problem of polygonal curve approximation
based on a multiresolution approach. This algorithm is suboptimal but still
maintains some optimality between successive levels of resolution using dynamic
programming. We show theoretically and experimentally that this algorithm has a
linear complexity in time and space. We experimentally compare the outcomes of
our algorithm to the optimal "full search" dynamic programming solution and
finally to classical merge and split approaches. The experimental evaluations
confirm the theoretical derivations and show that the proposed approach
evaluated on 2D coastal maps either show a lower time complexity or provide
polygonal approximations closer to the input discrete curves.
</summary>
    <author>
      <name>Pierre-François Marteau</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">VALORIA</arxiv:affiliation>
    </author>
    <author>
      <name>Gilbas Ménier</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">VALORIA</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/0705.0449v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0705.0449v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0705.0781v1</id>
    <updated>2007-05-06T06:02:46Z</updated>
    <published>2007-05-06T06:02:46Z</published>
    <title>Medical Image Segmentation and Localization using Deformable Templates</title>
    <summary>  This paper presents deformable templates as a tool for segmentation and
localization of biological structures in medical images. Structures are
represented by a prototype template, combined with a parametric warp mapping
used to deform the original shape. The localization procedure is achieved using
a multi-stage, multi-resolution algorithm de-signed to reduce computational
complexity and time. The algorithm initially identifies regions in the image
most likely to contain the desired objects and then examines these regions at
progressively increasing resolutions. The final stage of the algorithm involves
warping the prototype template to match the localized objects. The algorithm is
presented along with the results of four example applications using MRI, x-ray
and ultrasound images.
</summary>
    <author>
      <name>Jonathan M. Spiller</name>
    </author>
    <author>
      <name>T. Marwala</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/0705.0781v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0705.0781v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0705.0952v1</id>
    <updated>2007-05-07T19:19:55Z</updated>
    <published>2007-05-07T19:19:55Z</published>
    <title>An Independent Evaluation of Subspace Face Recognition Algorithms</title>
    <summary>  This paper explores a comparative study of both the linear and kernel
implementations of three of the most popular Appearance-based Face Recognition
projection classes, these being the methodologies of Principal Component
Analysis, Linear Discriminant Analysis and Independent Component Analysis. The
experimental procedure provides a platform of equal working conditions and
examines the ten algorithms in the categories of expression, illumination,
occlusion and temporal delay. The results are then evaluated based on a
sequential combination of assessment tools that facilitate both intuitive and
statistical decisiveness among the intra and interclass comparisons. The best
categorical algorithms are then incorporated into a hybrid methodology, where
the advantageous effects of fusion strategies are considered.
</summary>
    <author>
      <name>Dhiresh R. Surajpal</name>
    </author>
    <author>
      <name>Tshilidzi Marwala</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/0705.0952v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0705.0952v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0705.3593v2</id>
    <updated>2007-06-19T12:14:51Z</updated>
    <published>2007-05-24T14:41:11Z</published>
    <title>MI image registration using prior knowledge</title>
    <summary>  Subtraction of aligned images is a means to assess changes in a wide variety
of clinical applications. In this paper we explore the information theoretical
origin of Mutual Information (MI), which is based on Shannon's entropy.However,
the interpretation of standard MI registration as a communication channel
suggests that MI is too restrictive a criterion. In this paper the concept of
Mutual Information (MI) is extended to (Normalized) Focussed Mutual Information
(FMI) to incorporate prior knowledge to overcome some shortcomings of MI. We
use this to develop new methodologies to successfully address specific
registration problems, the follow-up of dental restorations, cephalometry, and
the monitoring of implants.
</summary>
    <author>
      <name>W. Jacquet</name>
    </author>
    <author>
      <name>P. de Groen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/0705.3593v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0705.3593v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.4.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0706.1926v1</id>
    <updated>2007-06-13T15:15:00Z</updated>
    <published>2007-06-13T15:15:00Z</published>
    <title>Towards understanding and modelling office daily life</title>
    <summary>  Measuring and modeling human behavior is a very complex task. In this paper
we present our initial thoughts on modeling and automatic recognition of some
human activities in an office. We argue that to successfully model human
activities, we need to consider both individual behavior and group dynamics. To
demonstrate these theoretical approaches, we introduce an experimental system
for analyzing everyday activity in our office.
</summary>
    <author>
      <name>Michele Bezzi</name>
    </author>
    <author>
      <name>Robin Groenevelt</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, ECHISE 2006 - 2nd International Workshop on Exploiting
  Context Histories in Smart Environments - Infrastructures and Design, 8th
  International Conference of Ubiquitous Computing (Ubicomp 2006), Orange
  County, CA, 17-21 September 2006</arxiv:comment>
    <link href="http://arxiv.org/abs/0706.1926v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0706.1926v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.4.8; I.5.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0708.2432v1</id>
    <updated>2007-08-18T14:36:28Z</updated>
    <published>2007-08-18T14:36:28Z</published>
    <title>A structure from motion inequality</title>
    <summary>  We state an elementary inequality for the structure from motion problem for m
cameras and n points. This structure from motion inequality relates space
dimension, camera parameter dimension, the number of cameras and number points
and global symmetry properties and provides a rigorous criterion for which
reconstruction is not possible with probability 1. Mathematically the
inequality is based on Frobenius theorem which is a geometric incarnation of
the fundamental theorem of linear algebra. The paper also provides a general
mathematical formalism for the structure from motion problem. It includes the
situation the points can move while the camera takes the pictures.
</summary>
    <author>
      <name>Oliver Knill</name>
    </author>
    <author>
      <name>Jose Ramirez-Herran</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 22 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0708.2432v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0708.2432v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.10" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0708.2438v1</id>
    <updated>2007-08-17T21:36:08Z</updated>
    <published>2007-08-17T21:36:08Z</published>
    <title>On Ullman's theorem in computer vision</title>
    <summary>  Both in the plane and in space, we invert the nonlinear Ullman transformation
for 3 points and 3 orthographic cameras. While Ullman's theorem assures a
unique reconstruction modulo a reflection for 3 cameras and 4 points, we find a
locally unique reconstruction for 3 cameras and 3 points. Explicit
reconstruction formulas allow to decide whether picture data of three cameras
seeing three points can be realized as a point-camera configuration.
</summary>
    <author>
      <name>Oliver Knill</name>
    </author>
    <author>
      <name>Jose Ramirez-Herran</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 13 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0708.2438v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0708.2438v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.10" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0708.2974v1</id>
    <updated>2007-08-22T08:28:02Z</updated>
    <published>2007-08-22T08:28:02Z</published>
    <title>The Fuzzy Vault for fingerprints is Vulnerable to Brute Force Attack</title>
    <summary>  The \textit{fuzzy vault} approach is one of the best studied and well
accepted ideas for binding cryptographic security into biometric
authentication. The vault has been implemented in connection with fingerprint
data by Uludag and Jain. We show that this instance of the vault is vulnerable
to brute force attack. An interceptor of the vault data can recover both secret
and template data using only generally affordable computational resources. Some
possible alternatives are then discussed and it is suggested that cryptographic
security may be preferable to the one - way function approach to biometric
security.
</summary>
    <author>
      <name>Preda Mihailescu</name>
    </author>
    <link href="http://arxiv.org/abs/0708.2974v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0708.2974v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.4.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0709.1771v1</id>
    <updated>2007-09-12T08:41:36Z</updated>
    <published>2007-09-12T08:41:36Z</published>
    <title>Variational local structure estimation for image super-resolution</title>
    <summary>  Super-resolution is an important but difficult problem in image/video
processing. If a video sequence or some training set other than the given
low-resolution image is available, this kind of extra information can greatly
aid in the reconstruction of the high-resolution image. The problem is
substantially more difficult with only a single low-resolution image on hand.
The image reconstruction methods designed primarily for denoising is
insufficient for super-resolution problem in the sense that it tends to
oversmooth images with essentially no noise. We propose a new adaptive linear
interpolation method based on variational method and inspired by local linear
embedding (LLE). The experimental result shows that our method avoids the
problem of oversmoothing and preserves image structures well.
</summary>
    <author>
      <name>Heng Lian</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/0709.1771v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0709.1771v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0710.0243v1</id>
    <updated>2007-10-01T09:18:36Z</updated>
    <published>2007-10-01T09:18:36Z</published>
    <title>High-Order Nonparametric Belief-Propagation for Fast Image Inpainting</title>
    <summary>  In this paper, we use belief-propagation techniques to develop fast
algorithms for image inpainting. Unlike traditional gradient-based approaches,
which may require many iterations to converge, our techniques achieve
competitive results after only a few iterations. On the other hand, while
belief-propagation techniques are often unable to deal with high-order models
due to the explosion in the size of messages, we avoid this problem by
approximating our high-order prior model using a Gaussian mixture. By using
such an approximation, we are able to inpaint images quickly while at the same
time retaining good visual results.
</summary>
    <author>
      <name>Julian John McAuley</name>
    </author>
    <author>
      <name>Tiberio S. Caetano</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0710.0243v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0710.0243v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0710.0736v1</id>
    <updated>2007-10-03T08:51:44Z</updated>
    <published>2007-10-03T08:51:44Z</published>
    <title>Colour image segmentation by the vector-valued Allen-Cahn phase-field
  model: a multigrid solution</title>
    <summary>  We propose a new method for the numerical solution of a PDE-driven model for
colour image segmentation and give numerical examples of the results. The
method combines the vector-valued Allen-Cahn phase field equation with initial
data fitting terms. This method is known to be closely related to the
Mumford-Shah problem and the level set segmentation by Chan and Vese. Our
numerical solution is performed using a multigrid splitting of a finite element
space, thereby producing an efficient and robust method for the segmentation of
large images.
</summary>
    <author>
      <name>David A Kay</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Oxford University Computational Laboratory</arxiv:affiliation>
    </author>
    <author>
      <name>Alessandro Tomasi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Sussex</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TIP.2009.2026678</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TIP.2009.2026678" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages, 9 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0710.0736v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0710.0736v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.4.6; G.1.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0710.2037v2</id>
    <updated>2007-10-11T11:32:25Z</updated>
    <published>2007-10-10T15:12:20Z</published>
    <title>An Affinity Propagation Based method for Vector Quantization Codebook
  Design</title>
    <summary>  In this paper, we firstly modify a parameter in affinity propagation (AP) to
improve its convergence ability, and then, we apply it to vector quantization
(VQ) codebook design problem. In order to improve the quality of the resulted
codebook, we combine the improved AP (IAP) with the conventional LBG algorithm
to generate an effective algorithm call IAP-LBG. According to the experimental
results, the proposed method not only enhances the convergence abilities but
also is capable of providing higher-quality codebooks than conventional LBG
method.
</summary>
    <author>
      <name>Wu Jiang</name>
    </author>
    <author>
      <name>Fei Ding</name>
    </author>
    <author>
      <name>Qiao-liang Xiang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In this version we make some explaination about the network-support
  similarity</arxiv:comment>
    <link href="http://arxiv.org/abs/0710.2037v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0710.2037v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0712.4015v1</id>
    <updated>2007-12-24T17:11:56Z</updated>
    <published>2007-12-24T17:11:56Z</published>
    <title>A Fast Hierarchical Multilevel Image Segmentation Method using Unbiased
  Estimators</title>
    <summary>  This paper proposes a novel method for segmentation of images by hierarchical
multilevel thresholding. The method is global, agglomerative in nature and
disregards pixel locations. It involves the optimization of the ratio of the
unbiased estimators of within class to between class variances. We obtain a
recursive relation at each step for the variances which expedites the process.
The efficacy of the method is shown in a comparison with some well-known
methods.
</summary>
    <author>
      <name>Sreechakra Goparaju</name>
    </author>
    <author>
      <name>Jayadev Acharya</name>
    </author>
    <author>
      <name>Ajoy K. Ray</name>
    </author>
    <author>
      <name>Jaideva C. Goswami</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 5 figures, submitted to "IEEE Transactions on Pattern
  Analysis and Machine Intelligence"</arxiv:comment>
    <link href="http://arxiv.org/abs/0712.4015v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0712.4015v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0802.3285v1</id>
    <updated>2008-02-22T10:48:44Z</updated>
    <published>2008-02-22T10:48:44Z</published>
    <title>Some Aspects of Testing Process for Transport Streams in Digital Video
  Broadcasting</title>
    <summary>  This paper presents some aspects related to the DVB (Digital Video
Broadcasting) investigation. The basic aspects of DVB are presented, with an
emphasis on DVB-T version of standard. The main purpose of this research is to
analyze the way that the transmission of the transport streams is realized in
case of the Terrestrial Digital Video Broadcasting (DVB-T). To accomplish this,
first, Digital Video Broadcasting standard is presented, and then the main
aspects of DVB testing and analysis of the transport streams are investigated.
The paper presents also the results obtained using two programs designed for
DVB analysis: Mosalina and TSA.
</summary>
    <author>
      <name>Radu Arsinte</name>
    </author>
    <author>
      <name>Ciprian Ilioaei</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 3 figures, 3 tables</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Acta Technica Napocensis, Electronics and Telecommunications,
  nr.1/2004 pp.59-74</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0802.3285v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0802.3285v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0803.1586v1</id>
    <updated>2008-03-11T13:40:42Z</updated>
    <published>2008-03-11T13:40:42Z</published>
    <title>Spatio-activity based object detection</title>
    <summary>  We present the SAMMI lightweight object detection method which has a high
level of accuracy and robustness, and which is able to operate in an
environment with a large number of cameras. Background modeling is based on DCT
coefficients provided by cameras. Foreground detection uses similarity in
temporal characteristics of adjacent blocks of pixels, which is a
computationally inexpensive way to make use of object coherence. Scene model
updating uses the approximated median method for improved performance.
Evaluation at pixel level and application level shows that SAMMI object
detection performs better and faster than the conventional Mixture of Gaussians
method.
</summary>
    <author>
      <name>Jarrad Springett</name>
    </author>
    <author>
      <name>Jeroen Vendrig</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To be submitted to: AVSS 2008 conference</arxiv:comment>
    <link href="http://arxiv.org/abs/0803.1586v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0803.1586v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0804.1046v1</id>
    <updated>2008-04-07T14:47:03Z</updated>
    <published>2008-04-07T14:47:03Z</published>
    <title>Discrete schemes for Gaussian curvature and their convergence</title>
    <summary>  In this paper, several discrete schemes for Gaussian curvature are surveyed.
The convergence property of a modified discrete scheme for the Gaussian
curvature is considered. Furthermore, a new discrete scheme for Gaussian
curvature is resented. We prove that the new scheme converges at the regular
vertex with valence not less than 5. By constructing a counterexample, we also
show that it is impossible for building a discrete scheme for Gaussian
curvature which converges over the regular vertex with valence 4. Finally,
asymptotic errors of several discrete scheme for Gaussian curvature are
compared.
</summary>
    <author>
      <name>Zhiqiang Xu</name>
    </author>
    <author>
      <name>Guoliang Xu</name>
    </author>
    <link href="http://arxiv.org/abs/0804.1046v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0804.1046v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0804.1448v1</id>
    <updated>2008-04-09T10:06:15Z</updated>
    <published>2008-04-09T10:06:15Z</published>
    <title>Fast k Nearest Neighbor Search using GPU</title>
    <summary>  The recent improvements of graphics processing units (GPU) offer to the
computer vision community a powerful processing platform. Indeed, a lot of
highly-parallelizable computer vision problems can be significantly accelerated
using GPU architecture. Among these algorithms, the k nearest neighbor search
(KNN) is a well-known problem linked with many applications such as
classification, estimation of statistical properties, etc. The main drawback of
this task lies in its computation burden, as it grows polynomially with the
data size. In this paper, we show that the use of the NVIDIA CUDA API
accelerates the search for the KNN up to a factor of 120.
</summary>
    <author>
      <name>Vincent Garcia</name>
    </author>
    <author>
      <name>Eric Debreuve</name>
    </author>
    <author>
      <name>Michel Barlaud</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 2figures, submitted to CVGPU 2008</arxiv:comment>
    <link href="http://arxiv.org/abs/0804.1448v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0804.1448v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0805.2324v1</id>
    <updated>2008-05-15T13:15:08Z</updated>
    <published>2008-05-15T13:15:08Z</published>
    <title>A multilateral filtering method applied to airplane runway image</title>
    <summary>  By considering the features of the airport runway image filtering, an
improved bilateral filtering method was proposed which can remove noise with
edge preserving. Firstly the steerable filtering decomposition is used to
calculate the sub-band parameters of 4 orients, and the texture feature matrix
is then obtained from the sub-band local median energy. The texture similar,
the spatial closer and the color similar functions are used to filter the
image.The effect of the weighting function parameters is qualitatively analyzed
also. In contrast with the standard bilateral filter and the simulation results
for the real airport runway image show that the multilateral filtering is more
effective than the standard bilateral filtering.
</summary>
    <author>
      <name>Zhang Yu</name>
    </author>
    <author>
      <name>Shi Zhong-ke</name>
    </author>
    <author>
      <name>Wang Run-quan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 5 figures, 4 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/0805.2324v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0805.2324v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0806.0870v1</id>
    <updated>2008-06-04T22:58:41Z</updated>
    <published>2008-06-04T22:58:41Z</published>
    <title>The Euler-Poincare theory of Metamorphosis</title>
    <summary>  In the pattern matching approach to imaging science, the process of
``metamorphosis'' is template matching with dynamical templates. Here, we
recast the metamorphosis equations of into the Euler-Poincare variational
framework of and show that the metamorphosis equations contain the equations
for a perfect complex fluid \cite{Ho2002}. This result connects the ideas
underlying the process of metamorphosis in image matching to the physical
concept of order parameter in the theory of complex fluids. After developing
the general theory, we reinterpret various examples, including point set, image
and density metamorphosis. We finally discuss the issue of matching measures
with metamorphosis, for which we provide existence theorems for the initial and
boundary value problems.
</summary>
    <author>
      <name>Darryl D. Holm</name>
    </author>
    <author>
      <name>Alain Trouve</name>
    </author>
    <author>
      <name>Laurent Younes</name>
    </author>
    <link href="http://arxiv.org/abs/0806.0870v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0806.0870v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.CD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0806.1446v1</id>
    <updated>2008-06-08T10:15:04Z</updated>
    <published>2008-06-08T10:15:04Z</published>
    <title>Fast Wavelet-Based Visual Classification</title>
    <summary>  We investigate a biologically motivated approach to fast visual
classification, directly inspired by the recent work of Serre et al.
Specifically, trading-off biological accuracy for computational efficiency, we
explore using wavelet and grouplet-like transforms to parallel the tuning of
visual cortex V1 and V2 cells, alternated with max operations to achieve scale
and translation invariance. A feature selection procedure is applied during
learning to accelerate recognition. We introduce a simple attention-like
feedback mechanism, significantly improving recognition and robustness in
multiple-object scenes. In experiments, the proposed algorithm achieves or
exceeds state-of-the-art success rate on object recognition, texture and
satellite image classification, language identification and sound
classification.
</summary>
    <author>
      <name>Guoshen Yu</name>
    </author>
    <author>
      <name>Jean-Jacques Slotine</name>
    </author>
    <link href="http://arxiv.org/abs/0806.1446v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0806.1446v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0806.2006v2</id>
    <updated>2012-01-06T20:39:14Z</updated>
    <published>2008-06-12T06:42:07Z</published>
    <title>Fusion de classifieurs pour la classification d'images sonar</title>
    <summary>  In this paper, we present some high level information fusion approaches for
numeric and symbolic data. We study the interest of such method particularly
for classifier fusion. A comparative study is made in a context of sea bed
characterization from sonar images. The classi- fication of kind of sediment is
a difficult problem because of the data complexity. We compare high level
information fusion and give the obtained performance.
</summary>
    <author>
      <name>Arnaud Martin</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">E3I2</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Revue Nationale des Technologies de l'Information E, 5 (2005)
  259-268</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0806.2006v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0806.2006v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0806.2007v1</id>
    <updated>2008-06-12T06:44:55Z</updated>
    <published>2008-06-12T06:44:55Z</published>
    <title>Experts Fusion and Multilayer Perceptron Based on Belief Learning for
  Sonar Image Classification</title>
    <summary>  The sonar images provide a rapid view of the seabed in order to characterize
it. However, in such as uncertain environment, real seabed is unknown and the
only information we can obtain, is the interpretation of different human
experts, sometimes in conflict. In this paper, we propose to manage this
conflict in order to provide a robust reality for the learning step of
classification algorithms. The classification is conducted by a multilayer
perceptron, taking into account the uncertainty of the reality in the learning
stage. The results of this seabed characterization are presented on real sonar
images.
</summary>
    <author>
      <name>Arnaud Martin</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">E3I2</arxiv:affiliation>
    </author>
    <author>
      <name>Christophe Osswald</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">E3I2</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">International Conference on Information &amp; Communication Technologies:
  from Theory to Applications (ICTTA), Damascus : Syrie (2008)</arxiv:comment>
    <link href="http://arxiv.org/abs/0806.2007v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0806.2007v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.4; I.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0806.3887v1</id>
    <updated>2008-06-24T13:34:15Z</updated>
    <published>2008-06-24T13:34:15Z</published>
    <title>Conceptualization of seeded region growing by pixels aggregation. Part
  2: how to localize a final partition invariant about the seeded region
  initialisation order</title>
    <summary>  In the previous paper, we have conceptualized the localization and the
organization of seeded region growing by pixels aggregation (SRGPA) but we do
not give the issue when there is a collision between two distinct regions
during the growing process. In this paper, we propose two implementations to
manage two classical growing processes: one without a boundary region region to
divide the other regions and another with. Unfortunately, as noticed by Mehnert
and Jakway (1997), this partition depends on the seeded region initialisation
order (SRIO). We propose a growing process, invariant about SRIO such as the
boundary region is the set of ambiguous pixels.
</summary>
    <author>
      <name>Vincent Tariel</name>
    </author>
    <link href="http://arxiv.org/abs/0806.3887v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0806.3887v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0806.3928v1</id>
    <updated>2008-06-24T17:02:47Z</updated>
    <published>2008-06-24T17:02:47Z</published>
    <title>Conceptualization of seeded region growing by pixels aggregation. Part
  3: a wide range of algorithms</title>
    <summary>  In the two previous papers of this serie, we have created a library, called
Population, dedicated to seeded region growing by pixels aggregation and we
have proposed different growing processes to get a partition with or without a
boundary region to divide the other regions or to get a partition invariant
about the seeded region initialisation order. Using this work, we implement
some algorithms belonging to the field of SRGPA using this library and these
growing processes.
</summary>
    <author>
      <name>Vincent Tariel</name>
    </author>
    <link href="http://arxiv.org/abs/0806.3928v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0806.3928v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0807.2928v1</id>
    <updated>2008-07-18T11:23:27Z</updated>
    <published>2008-07-18T11:23:27Z</published>
    <title>Visual Grouping by Neural Oscillators</title>
    <summary>  Distributed synchronization is known to occur at several scales in the brain,
and has been suggested as playing a key functional role in perceptual grouping.
State-of-the-art visual grouping algorithms, however, seem to give
comparatively little attention to neural synchronization analogies. Based on
the framework of concurrent synchronization of dynamic systems, simple networks
of neural oscillators coupled with diffusive connections are proposed to solve
visual grouping problems. Multi-layer algorithms and feedback mechanisms are
also studied. The same algorithm is shown to achieve promising results on
several classical visual grouping problems, including point clustering, contour
integration and image segmentation.
</summary>
    <author>
      <name>Guoshen Yu</name>
    </author>
    <author>
      <name>Jean-Jacques Slotine</name>
    </author>
    <link href="http://arxiv.org/abs/0807.2928v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0807.2928v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0807.4701v1</id>
    <updated>2008-07-29T16:28:44Z</updated>
    <published>2008-07-29T16:28:44Z</published>
    <title>An image processing analysis of skin textures</title>
    <summary>  Colour and coarseness of skin are visually different. When image processing
is involved in the skin analysis, it is important to quantitatively evaluate
such differences using texture features. In this paper, we discuss a texture
analysis and measurements based on a statistical approach to the pattern
recognition. Grain size and anisotropy are evaluated with proper diagrams. The
possibility to determine the presence of pattern defects is also discussed.
</summary>
    <author>
      <name>A. Sparavigna</name>
    </author>
    <author>
      <name>R. Marazzato</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1111/j.1600-0846.2009.00413.x</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1111/j.1600-0846.2009.00413.x" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Skin Research and Technology, Volume 16 Issue 2, Pages 161 - 167,
  2010</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0807.4701v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0807.4701v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0809.3690v1</id>
    <updated>2008-09-22T12:08:24Z</updated>
    <published>2008-09-22T12:08:24Z</published>
    <title>Modeling and Control with Local Linearizing Nadaraya Watson Regression</title>
    <summary>  Black box models of technical systems are purely descriptive. They do not
explain why a system works the way it does. Thus, black box models are
insufficient for some problems. But there are numerous applications, for
example, in control engineering, for which a black box model is absolutely
sufficient. In this article, we describe a general stochastic framework with
which such models can be built easily and fully automated by observation.
Furthermore, we give a practical example and show how this framework can be
used to model and control a motorcar powertrain.
</summary>
    <author>
      <name>Steffen Kühn</name>
    </author>
    <author>
      <name>Clemens Gühmann</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0809.3690v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0809.3690v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0810.3418v1</id>
    <updated>2008-10-19T18:04:51Z</updated>
    <published>2008-10-19T18:04:51Z</published>
    <title>Detecting the Most Unusual Part of a Digital Image</title>
    <summary>  The purpose of this paper is to introduce an algorithm that can detect the
most unusual part of a digital image. The most unusual part of a given shape is
defined as a part of the image that has the maximal distance to all non
intersecting shapes with the same form.
  The method can be used to scan image databases with no clear model of the
interesting part or large image databases, as for example medical databases.
</summary>
    <author>
      <name>K. Koroutchev</name>
    </author>
    <author>
      <name>E. Korutcheva</name>
    </author>
    <link href="http://arxiv.org/abs/0810.3418v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0810.3418v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0902.0221v2</id>
    <updated>2009-09-14T10:14:32Z</updated>
    <published>2009-02-02T10:41:53Z</published>
    <title>Over-enhancement Reduction in Local Histogram Equalization using its
  Degrees of Freedom</title>
    <summary>  A well-known issue of local (adaptive) histogram equalization (LHE) is
over-enhancement (i.e., generation of spurious details) in homogenous areas of
the image. In this paper, we show that the LHE problem has many solutions due
to the ambiguity in ranking pixels with the same intensity. The LHE solution
space can be searched for the images having the maximum PSNR or structural
similarity (SSIM) with the input image. As compared to the results of the prior
art, these solutions are more similar to the input image while offering the
same local contrast.
  Index Terms: histogram modification or specification, contrast enhancement
</summary>
    <author>
      <name>Alireza Avanaki</name>
    </author>
    <link href="http://arxiv.org/abs/0902.0221v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0902.0221v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0903.0538v1</id>
    <updated>2009-03-03T14:08:24Z</updated>
    <published>2009-03-03T14:08:24Z</published>
    <title>Real-time Texture Error Detection</title>
    <summary>  This paper advocates an improved solution for real-time error detection of
texture errors that occurs in the production process in textile industry. The
research is focused on the mono-color products with 3D texture model (Jaquard
fabrics). This is a more difficult task than, for example, 2D multicolor
textures.
</summary>
    <author>
      <name>Dan Laurentiu Lacrama</name>
    </author>
    <author>
      <name>Florin Alexa</name>
    </author>
    <author>
      <name>Adriana Balta</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, exposed on 2nd "European conference on Computer Science &amp;
  Applications" - XA2008, Timisoara, Romania</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Ann. Univ. Tibiscus, Comp. Sci. Series 6 (2008), 127-134</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0903.0538v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0903.0538v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0903.1448v1</id>
    <updated>2009-03-09T08:06:09Z</updated>
    <published>2009-03-09T08:06:09Z</published>
    <title>The Digital Restoration of Da Vinci's Sketches</title>
    <summary>  A sketch, found in one of Leonardo da Vinci's notebooks and covered by the
written notes of this genius, has been recently restored. The restoration
reveals a possible self-portrait of the artist, drawn when he was young. Here,
we discuss the discovery of this self-portrait and the procedure used for
restoration. Actually, this is a restoration performed on the digital image of
the sketch, a procedure that can easily extended and applied to ancient
documents for studies of art and palaeography.
</summary>
    <author>
      <name>Amelia Sparavigna</name>
    </author>
    <link href="http://arxiv.org/abs/0903.1448v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0903.1448v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0903.3676v1</id>
    <updated>2009-03-23T17:18:08Z</updated>
    <published>2009-03-23T17:18:08Z</published>
    <title>Combinatorial Ricci Curvature and Laplacians for Image Processing</title>
    <summary>  A new Combinatorial Ricci curvature and Laplacian operators for grayscale
images are introduced and tested on 2D synthetic, natural and medical images.
Analogue formulae for voxels are also obtained. These notions are based upon
more general concepts developed by R. Forman. Further applications, in
particular a fitting Ricci flow, are discussed.
</summary>
    <author>
      <name>Emil Saucan</name>
    </author>
    <author>
      <name>Eli Appleboilm</name>
    </author>
    <author>
      <name>Gershon Wolansky</name>
    </author>
    <author>
      <name>Yehoshua Y. Zeevi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 8 figures (some of the these may be of lesser quality than
  those in the Technical report version)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of CISP'09, Vol. 2, 992-997, 2009</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0903.3676v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0903.3676v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0903.5045v1</id>
    <updated>2009-03-30T06:00:15Z</updated>
    <published>2009-03-30T06:00:15Z</published>
    <title>Digital Restoration of Ancient Papyri</title>
    <summary>  Image processing can be used for digital restoration of ancient papyri, that
is, for a restoration performed on their digital images. The digital
manipulation allows reducing the background signals and enhancing the
readability of texts. In the case of very old and damaged documents, this is
fundamental for identification of the patterns of letters. Some examples of
restoration, obtained with an image processing which uses edges detection and
Fourier filtering, are shown. One of them concerns 7Q5 fragment of the Dead Sea
Scrolls.
</summary>
    <author>
      <name>Amelia Sparavigna</name>
    </author>
    <link href="http://arxiv.org/abs/0903.5045v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0903.5045v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0904.0962v1</id>
    <updated>2009-04-06T16:25:08Z</updated>
    <published>2009-04-06T16:25:08Z</published>
    <title>Color Dipole Moments for Edge Detection</title>
    <summary>  Dipole and higher moments are physical quantities used to describe a charge
distribution. In analogy with electromagnetism, it is possible to define the
dipole moments for a gray-scale image, according to the single aspect of a
gray-tone map. In this paper we define the color dipole moments for color
images. For color maps in fact, we have three aspects, the three primary
colors, to consider. Associating three color charges to each pixel, color
dipole moments can be easily defined and used for edge detection.
</summary>
    <author>
      <name>Amelia Sparavigna</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/0904.0962v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0904.0962v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0904.1613v1</id>
    <updated>2009-04-09T22:15:25Z</updated>
    <published>2009-04-09T22:15:25Z</published>
    <title>On the closed-form solution of the rotation matrix arising in computer
  vision problems</title>
    <summary>  We show the closed-form solution to the maximization of trace(A'R), where A
is given and R is unknown rotation matrix. This problem occurs in many computer
vision tasks involving optimal rotation matrix estimation. The solution has
been continuously reinvented in different fields as part of specific problems.
We summarize the historical evolution of the problem and present the general
proof of the solution. We contribute to the proof by considering the degenerate
cases of A and discuss the uniqueness of R.
</summary>
    <author>
      <name>Andriy Myronenko</name>
    </author>
    <author>
      <name>Xubo Song</name>
    </author>
    <link href="http://arxiv.org/abs/0904.1613v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0904.1613v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0904.3944v1</id>
    <updated>2009-04-24T21:19:59Z</updated>
    <published>2009-04-24T21:19:59Z</published>
    <title>Better Global Polynomial Approximation for Image Rectification</title>
    <summary>  When using images to locate objects, there is the problem of correcting for
distortion and misalignment in the images. An elegant way of solving this
problem is to generate an error correcting function that maps points in an
image to their corrected locations. We generate such a function by fitting a
polynomial to a set of sample points. The objective is to identify a polynomial
that passes "sufficiently close" to these points with "good" approximation of
intermediate points. In the past, it has been difficult to achieve good global
polynomial approximation using only sample points. We report on the development
of a global polynomial approximation algorithm for solving this problem. Key
Words: Polynomial approximation, interpolation, image rectification.
</summary>
    <author>
      <name>Christopher O. Ward</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.2316/Journal.205.2008.3.205-4669</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.2316/Journal.205.2008.3.205-4669" rel="related"/>
    <link href="http://arxiv.org/abs/0904.3944v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0904.3944v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0905.3347v1</id>
    <updated>2009-05-20T16:37:16Z</updated>
    <published>2009-05-20T16:37:16Z</published>
    <title>Information Distance in Multiples</title>
    <summary>  Information distance is a parameter-free similarity measure based on
compression, used in pattern recognition, data mining, phylogeny, clustering,
and classification. The notion of information distance is extended from pairs
to multiples (finite lists). We study maximal overlap, metricity, universality,
minimal overlap, additivity, and normalized information distance in multiples.
We use the theoretical notion of Kolmogorov complexity which for practical
purposes is approximated by the length of the compressed version of the file
involved, using a real-world compression program.
  {\em Index Terms}-- Information distance, multiples, pattern recognition,
data mining, similarity, Kolmogorov complexity
</summary>
    <author>
      <name>Paul M. B. Vitanyi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">LateX 14 pages, Submitted to a technical journal</arxiv:comment>
    <link href="http://arxiv.org/abs/0905.3347v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0905.3347v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.3; E.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0906.3323v1</id>
    <updated>2009-06-17T23:24:38Z</updated>
    <published>2009-06-17T23:24:38Z</published>
    <title>Adaptive Regularization of Ill-Posed Problems: Application to Non-rigid
  Image Registration</title>
    <summary>  We introduce an adaptive regularization approach. In contrast to conventional
Tikhonov regularization, which specifies a fixed regularization operator, we
estimate it simultaneously with parameters. From a Bayesian perspective we
estimate the prior distribution on parameters assuming that it is close to some
given model distribution. We constrain the prior distribution to be a
Gauss-Markov random field (GMRF), which allows us to solve for the prior
distribution analytically and provides a fast optimization algorithm. We apply
our approach to non-rigid image registration to estimate the spatial
transformation between two images. Our evaluation shows that the adaptive
regularization approach significantly outperforms standard variational methods.
</summary>
    <author>
      <name>Andriy Myronenko</name>
    </author>
    <author>
      <name>Xubo Song</name>
    </author>
    <link href="http://arxiv.org/abs/0906.3323v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0906.3323v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0907.0288v1</id>
    <updated>2009-07-02T04:57:32Z</updated>
    <published>2009-07-02T04:57:32Z</published>
    <title>An Iterative Fingerprint Enhancement Algorithm Based on Accurate
  Determination of Orientation Flow</title>
    <summary>  We describe an algorithm to enhance and binarize a fingerprint image. The
algorithm is based on accurate determination of orientation flow of the ridges
of the fingerprint image by computing variance of the neighborhood pixels
around a pixel in different directions. We show that an iterative algorithm
which captures the mutual interdependence of orientation flow computation,
enhancement and binarization gives very good results on poor quality images.
</summary>
    <author>
      <name>Simant Dube</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 4 figures. Ongoing work. To be submitted to appropriate
  conference/journal</arxiv:comment>
    <link href="http://arxiv.org/abs/0907.0288v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0907.0288v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0907.5321v2</id>
    <updated>2009-08-04T06:01:53Z</updated>
    <published>2009-07-30T12:23:25Z</published>
    <title>Multiple pattern classification by sparse subspace decomposition</title>
    <summary>  A robust classification method is developed on the basis of sparse subspace
decomposition. This method tries to decompose a mixture of subspaces of
unlabeled data (queries) into class subspaces as few as possible. Each query is
classified into the class whose subspace significantly contributes to the
decomposed subspace. Multiple queries from different classes can be
simultaneously classified into their respective classes. A practical greedy
algorithm of the sparse subspace decomposition is designed for the
classification. The present method achieves high recognition rate and robust
performance exploiting joint sparsity.
</summary>
    <author>
      <name>Tomoya Sakai</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/ICCVW.2009.5457702</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/ICCVW.2009.5457702" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 3 figures, 2nd IEEE International Workshop on Subspace
  Methods, Workshop Proceedings of ICCV 2009</arxiv:comment>
    <link href="http://arxiv.org/abs/0907.5321v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0907.5321v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0908.1919v3</id>
    <updated>2009-10-01T06:50:18Z</updated>
    <published>2009-08-13T15:41:44Z</published>
    <title>A dyadic solution of relative pose problems</title>
    <summary>  A hierarchical interval subdivision is shown to lead to a $p$-adic encoding
of image data. This allows in the case of the relative pose problem in computer
vision and photogrammetry to derive equations having 2-adic numbers as
coefficients, and to use Hensel's lifting method to their solution. This method
is applied to the linear and non-linear equations coming from eight, seven or
five point correspondences. An inherent property of the method is its
robustness.
</summary>
    <author>
      <name>Patrick Erik Bradley</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages; references added; typos and Thm 2 corrected (not affecting
  the other results)</arxiv:comment>
    <link href="http://arxiv.org/abs/0908.1919v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0908.1919v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0909.5656v1</id>
    <updated>2009-09-30T18:50:24Z</updated>
    <published>2009-09-30T18:50:24Z</published>
    <title>Improvements of the 3D images captured with Time-of-Flight cameras</title>
    <summary>  3D Time-of-Flight camera's images are affected by errors due to the diffuse
(indirect) light and to the flare light. The presented method improves the 3D
image reducing the distance's errors to dark surface objects. This is achieved
by placing one or two contrast tags in the scene at different distances from
the ToF camera. The white and black parts of the tags are situated at the same
distance to the camera but the distances measured by the camera are different.
This difference is used to compute a correction vector. The distance to black
surfaces is corrected by subtracting this vector from the captured vector
image.
</summary>
    <author>
      <name>D. Falie</name>
    </author>
    <link href="http://arxiv.org/abs/0909.5656v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0909.5656v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0910.1293v1</id>
    <updated>2009-10-07T15:42:03Z</updated>
    <published>2009-10-07T15:42:03Z</published>
    <title>Introducing New AdaBoost Features for Real-Time Vehicle Detection</title>
    <summary>  This paper shows how to improve the real-time object detection in complex
robotics applications, by exploring new visual features as AdaBoost weak
classifiers. These new features are symmetric Haar filters (enforcing global
horizontal and vertical symmetry) and N-connexity control points. Experimental
evaluation on a car database show that the latter appear to provide the best
results for the vehicle-detection problem.
</summary>
    <author>
      <name>Bogdan Stanciulescu</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CAOR</arxiv:affiliation>
    </author>
    <author>
      <name>Amaury Breheret</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CAOR</arxiv:affiliation>
    </author>
    <author>
      <name>Fabien Moutarde</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CAOR</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">COGIS'07 conference on COGnitive systems with Interactive Sensors,
  Stanford, Palo Alto : United States (2007)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0910.1293v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0910.1293v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0911.0490v1</id>
    <updated>2009-11-03T04:33:55Z</updated>
    <published>2009-11-03T04:33:55Z</published>
    <title>Breast Cancer Detection Using Multilevel Thresholding</title>
    <summary>  This paper presents an algorithm which aims to assist the radiologist in
identifying breast cancer at its earlier stages. It combines several image
processing techniques like image negative, thresholding and segmentation
techniques for detection of tumor in mammograms. The algorithm is verified by
using mammograms from Mammographic Image Analysis Society. The results obtained
by applying these techniques are described.
</summary>
    <author>
      <name>Y. Ireaneus Anna Rejani</name>
    </author>
    <author>
      <name>S. Thamarai Selvi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 1, pp. 111-115, October 2009, USA</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0911.0490v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0911.0490v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0911.4874v2</id>
    <updated>2009-12-04T12:58:23Z</updated>
    <published>2009-11-25T15:16:53Z</published>
    <title>Non-photorealistic image processing: an Impressionist rendering</title>
    <summary>  The paper describes an image processing for a non-photorealistic rendering.
The algorithm is based on a random choice of a set of pixels from those ot the
original image and substitution of them with colour spots. An iterative
procedure is applied to cover, at a desired level, the canvas. The resulting
effect mimics the impressionist painting and Pointillism.
</summary>
    <author>
      <name>Amelia Carolina Sparavigna</name>
    </author>
    <author>
      <name>Roberto Marazzato</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Keywords: Image processing. Non-photorealistic processing.
  Image-based rendering</arxiv:comment>
    <link href="http://arxiv.org/abs/0911.4874v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0911.4874v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1001.0927v1</id>
    <updated>2010-01-06T16:05:25Z</updated>
    <published>2010-01-06T16:05:25Z</published>
    <title>Accelerating Competitive Learning Graph Quantization</title>
    <summary>  Vector quantization(VQ) is a lossy data compression technique from signal
processing for which simple competitive learning is one standard method to
quantize patterns from the input space. Extending competitive learning VQ to
the domain of graphs results in competitive learning for quantizing input
graphs. In this contribution, we propose an accelerated version of competitive
learning graph quantization (GQ) without trading computational time against
solution quality. For this, we lift graphs locally to vectors in order to avoid
unnecessary calculations of intractable graph distances. In doing so, the
accelerated version of competitive learning GQ gradually turns locally into a
competitive learning VQ with increasing number of iterations. Empirical results
show a significant speedup by maintaining a comparable solution quality.
</summary>
    <author>
      <name>Brijnesh J. Jain</name>
    </author>
    <author>
      <name>Klaus Obermayer</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages; submitted to CVIU</arxiv:comment>
    <link href="http://arxiv.org/abs/1001.0927v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1001.0927v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1001.5352v1</id>
    <updated>2010-01-29T08:29:57Z</updated>
    <published>2010-01-29T08:29:57Z</published>
    <title>Kannada Character Recognition System A Review</title>
    <summary>  Intensive research has been done on optical character recognition ocr and a
large number of articles have been published on this topic during the last few
decades. Many commercial OCR systems are now available in the market, but most
of these systems work for Roman, Chinese, Japanese and Arabic characters. There
are no sufficient number of works on Indian language character recognition
especially Kannada script among 12 major scripts in India. This paper presents
a review of existing work on printed Kannada script and their results. The
characteristics of Kannada script and Kannada Character Recognition System kcr
are discussed in detail. Finally fusion at the classifier level is proposed to
increase the recognition accuracy.
</summary>
    <author>
      <name>K. Indira</name>
    </author>
    <author>
      <name>S. Sethu Selvi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 8 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1001.5352v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1001.5352v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1002.0416v1</id>
    <updated>2010-02-02T08:15:20Z</updated>
    <published>2010-02-02T08:15:20Z</published>
    <title>Fusion of Multiple Matchers using SVM for Offline Signature
  Identification</title>
    <summary>  This paper uses Support Vector Machines (SVM) to fuse multiple classifiers
for an offline signature system. From the signature images, global and local
features are extracted and the signatures are verified with the help of
Gaussian empirical rule, Euclidean and Mahalanobis distance based classifiers.
SVM is used to fuse matching scores of these matchers. Finally, recognition of
query signatures is done by comparing it with all signatures of the database.
The proposed system is tested on a signature database contains 5400 offline
signatures of 600 individuals and the results are found to be promising.
</summary>
    <author>
      <name>Dakshina Ranjan Kisku</name>
    </author>
    <author>
      <name>Phalguni Gupta</name>
    </author>
    <author>
      <name>Jamuna Kanta Sing</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1002.0416v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1002.0416v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.2.2; I.2.10" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1002.3344v1</id>
    <updated>2010-02-17T18:29:09Z</updated>
    <published>2010-02-17T18:29:09Z</published>
    <title>Iterative exact global histogram specification and SSIM gradient ascent:
  a proof of convergence, step size and parameter selection</title>
    <summary>  The SSIM-optimized exact global histogram specification (EGHS) is shown to
converge in the sense that the first order approximation of the result's
quality (i.e., its structural similarity with input) does not decrease in an
iteration, when the step size is small. Each iteration is composed of SSIM
gradient ascent and basic EGHS with the specified target histogram. Selection
of step size and other parameters is also discussed.
</summary>
    <author>
      <name>Alireza Avanaki</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Supplement to published work, on SSIM-optimized exact global
  histogram specification; please see arXiv:0901.0065</arxiv:comment>
    <link href="http://arxiv.org/abs/1002.3344v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1002.3344v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1002.4317v1</id>
    <updated>2010-02-23T12:32:34Z</updated>
    <published>2010-02-23T12:32:34Z</published>
    <title>CLD-shaped Brushstrokes in Non-Photorealistic Rendering</title>
    <summary>  Rendering techniques based on a random grid can be improved by adapting
brushstrokes to the shape of different areas of the original picture. In this
paper, the concept of Coherence Length Diagram is applied to determine the
adaptive brushstrokes, in order to simulate an impressionist painting. Some
examples are provided to instance the proposed algorithm.
</summary>
    <author>
      <name>Amelia Carolina Sparavigna</name>
    </author>
    <author>
      <name>Roberto Marazzato</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Keywords: Image processing, Non-photorealistic processing,
  Image-based rendering Coherence Length Diagram</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Software Engineering and Computing, 2011,
  Volume 3, Issue 1, Pages 11-15</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1002.4317v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1002.4317v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1003.4021v1</id>
    <updated>2010-03-21T20:21:09Z</updated>
    <published>2010-03-21T20:21:09Z</published>
    <title>System-theoretic approach to image interest point detection</title>
    <summary>  Interest point detection is a common task in various computer vision
applications. Although a big variety of detector are developed so far
computational efficiency of interest point based image analysis remains to be
the problem. Current paper proposes a system-theoretic approach to interest
point detection. Starting from the analysis of interdependency between detector
and descriptor it is shown that given a descriptor it is possible to introduce
to notion of detector redundancy. Furthermore for each detector it is possible
to construct its irredundant and equivalent modification. Modified detector
possesses lower computational complexity and is preferable. It is also shown
that several known approaches to reduce computational complexity of image
registration can be generalized in terms of proposed theory.
</summary>
    <author>
      <name>Vitaly Pimenov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1003.4021v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1003.4021v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1003.4053v1</id>
    <updated>2010-03-22T03:39:46Z</updated>
    <published>2010-03-22T03:39:46Z</published>
    <title>A Comprehensive Review of Image Enhancement Techniques</title>
    <summary>  Principle objective of Image enhancement is to process an image so that
result is more suitable than original image for specific application. Digital
image enhancement techniques provide a multitude of choices for improving the
visual quality of images. Appropriate choice of such techniques is greatly
influenced by the imaging modality, task at hand and viewing conditions. This
paper will provide an overview of underlying concepts, along with algorithms
commonly used for image enhancement. The paper focuses on spatial domain
techniques for image enhancement, with particular reference to point processing
methods and histogram processing.
</summary>
    <author>
      <name>Raman Maini</name>
    </author>
    <author>
      <name>Himanshu Aggarwal</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Computing, Volume 2, Issue 3, March 2010,
  https://sites.google.com/site/journalofcomputing/</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1003.4053v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1003.4053v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1003.5865v1</id>
    <updated>2010-03-30T16:36:36Z</updated>
    <published>2010-03-30T16:36:36Z</published>
    <title>Offline Signature Identification by Fusion of Multiple Classifiers using
  Statistical Learning Theory</title>
    <summary>  This paper uses Support Vector Machines (SVM) to fuse multiple classifiers
for an offline signature system. From the signature images, global and local
features are extracted and the signatures are verified with the help of
Gaussian empirical rule, Euclidean and Mahalanobis distance based classifiers.
SVM is used to fuse matching scores of these matchers. Finally, recognition of
query signatures is done by comparing it with all signatures of the database.
The proposed system is tested on a signature database contains 5400 offline
signatures of 600 individuals and the results are found to be promising.
</summary>
    <author>
      <name>Dakshina Ranjan Kisku</name>
    </author>
    <author>
      <name>Phalguni Gupta</name>
    </author>
    <author>
      <name>Jamuna Kanta Sing</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 3 figures, IJSIA 2010</arxiv:comment>
    <link href="http://arxiv.org/abs/1003.5865v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1003.5865v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.2.2; I.2.10" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1003.5891v1</id>
    <updated>2010-03-30T18:35:37Z</updated>
    <published>2010-03-30T18:35:37Z</published>
    <title>Recognition of Handwritten Roman Script Using Tesseract Open source OCR
  Engine</title>
    <summary>  In the present work, we have used Tesseract 2.01 open source Optical
Character Recognition (OCR) Engine under Apache License 2.0 for recognition of
handwriting samples of lower case Roman script. Handwritten isolated and
free-flow text samples were collected from multiple users. Tesseract is trained
to recognize user-specific handwriting samples of both the categories of
document pages. On a single user model, the system is trained with 1844
isolated handwritten characters and the performance is tested on 1133
characters, taken form the test set. The overall character-level accuracy of
the system is observed as 83.5%. The system fails to segment 5.56% characters
and erroneously classifies 10.94% characters.
</summary>
    <author>
      <name>Sandip Rakshit</name>
    </author>
    <author>
      <name>Subhadip Basu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. National Conference on NAQC (2008) 141-145</arxiv:comment>
    <link href="http://arxiv.org/abs/1003.5891v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1003.5891v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1004.1227v1</id>
    <updated>2010-04-08T02:39:49Z</updated>
    <published>2010-04-08T02:39:49Z</published>
    <title>Signature Recognition using Multi Scale Fourier Descriptor And Wavelet
  Transform</title>
    <summary>  This paper present a novel off-line signature recognition method based on
multi scale Fourier Descriptor and wavelet transform . The main steps of
constructing a signature recognition system are discussed and experiments on
real data sets show that the average error rate can reach 1%. Finally we
compare 8 distance measures between feature vectors with respect to the
recognition performance.
  Key words: signature recognition; Fourier Descriptor; Wavelet transform;
personal verification
</summary>
    <author>
      <name>Ismail A. Ismail</name>
    </author>
    <author>
      <name>Mohammed A. Ramadan</name>
    </author>
    <author>
      <name>Talaat S. El danaf</name>
    </author>
    <author>
      <name>Ahmed H. Samak</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE Publication format, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IJCSIS, Vol. 7 No. 3, March 2010,</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1004.1227v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1004.1227v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1004.5351v2</id>
    <updated>2010-05-11T19:04:22Z</updated>
    <published>2010-04-29T17:56:47Z</published>
    <title>Isometric Embeddings in Imaging and Vision: Facts and Fiction</title>
    <summary>  We explore the practicability of Nash's Embedding Theorem in vision and
imaging sciences. In particular, we investigate the relevance of a result of
Burago and Zalgaller regarding the existence of isometric embeddings of
polyhedral surfaces in $\mathbb{R}^3$ and we show that their proof does not
extended directly to higher dimensions.
</summary>
    <author>
      <name>Emil Saucan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">23 pages, 1 figure Second version: Corrections made, subsection added</arxiv:comment>
    <link href="http://arxiv.org/abs/1004.5351v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1004.5351v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="52B70, 57R40, 53C42, 30C65" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1005.1471v1</id>
    <updated>2010-05-10T08:49:56Z</updated>
    <published>2010-05-10T08:49:56Z</published>
    <title>Classification via Incoherent Subspaces</title>
    <summary>  This article presents a new classification framework that can extract
individual features per class. The scheme is based on a model of incoherent
subspaces, each one associated to one class, and a model on how the elements in
a class are represented in this subspace. After the theoretical analysis an
alternate projection algorithm to find such a collection is developed. The
classification performance and speed of the proposed method is tested on the AR
and YaleB databases and compared to that of Fisher's LDA and a recent approach
based on on $\ell_1$ minimisation. Finally connections of the presented scheme
to already existing work are discussed and possible ways of extensions are
pointed out.
</summary>
    <author>
      <name>Karin Schnass</name>
    </author>
    <author>
      <name>Pierre Vandergheynst</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">22 pages, 2 figures, 4 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1005.1471v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1005.1471v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1005.2715v1</id>
    <updated>2010-05-16T00:31:19Z</updated>
    <published>2010-05-16T00:31:19Z</published>
    <title>On the Subspace of Image Gradient Orientations</title>
    <summary>  We introduce the notion of Principal Component Analysis (PCA) of image
gradient orientations. As image data is typically noisy, but noise is
substantially different from Gaussian, traditional PCA of pixel intensities
very often fails to estimate reliably the low-dimensional subspace of a given
data population. We show that replacing intensities with gradient orientations
and the $\ell_2$ norm with a cosine-based distance measure offers, to some
extend, a remedy to this problem. Our scheme requires the eigen-decomposition
of a covariance matrix and is as computationally efficient as standard $\ell_2$
PCA. We demonstrate some of its favorable properties on robust subspace
estimation.
</summary>
    <author>
      <name>Georgios Tzimiropoulos</name>
    </author>
    <author>
      <name>Stefanos Zafeiriou</name>
    </author>
    <link href="http://arxiv.org/abs/1005.2715v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1005.2715v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1005.4020v1</id>
    <updated>2010-05-21T17:30:08Z</updated>
    <published>2010-05-21T17:30:08Z</published>
    <title>Image Segmentation by Using Threshold Techniques</title>
    <summary>  This paper attempts to undertake the study of segmentation image techniques
by using five threshold methods as Mean method, P-tile method, Histogram
Dependent Technique (HDT), Edge Maximization Technique (EMT) and visual
Technique and they are compared with one another so as to choose the best
technique for threshold segmentation techniques image. These techniques applied
on three satellite images to choose base guesses for threshold segmentation
image.
</summary>
    <author>
      <name>Salem Saleh Al-amri</name>
    </author>
    <author>
      <name>N. V. Kalyankar</name>
    </author>
    <author>
      <name>Khamitkar S. D.</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">http://www.journalofcomputing.org</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Computing, Volume 2, Issue 5, May 2010</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1005.4020v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1005.4020v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1005.4034v1</id>
    <updated>2010-05-21T18:03:44Z</updated>
    <published>2010-05-21T18:03:44Z</published>
    <title>Face Synthesis (FASY) System for Generation of a Face Image from Human
  Description</title>
    <summary>  This paper aims at generating a new face based on the human like description
using a new concept. The FASY (FAce SYnthesis) System is a Face Database
Retrieval and new Face generation System that is under development. One of its
main features is the generation of the requested face when it is not found in
the existing database, which allows a continuous growing of the database also.
</summary>
    <author>
      <name>Santanu Halder</name>
    </author>
    <author>
      <name>Debotosh Bhattacharjee</name>
    </author>
    <author>
      <name>Mita Nasipuri</name>
    </author>
    <author>
      <name>Dipak Kumar Basu</name>
    </author>
    <author>
      <name>Mahantapas Kundu</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ICIIS 2008</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1005.4034v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1005.4034v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1006.4175v1</id>
    <updated>2010-06-21T20:59:43Z</updated>
    <published>2010-06-21T20:59:43Z</published>
    <title>Optimization of Weighted Curvature for Image Segmentation</title>
    <summary>  Minimization of boundary curvature is a classic regularization technique for
image segmentation in the presence of noisy image data. Techniques for
minimizing curvature have historically been derived from descent methods which
could be trapped in a local minimum and therefore required a good
initialization. Recently, combinatorial optimization techniques have been
applied to the optimization of curvature which provide a solution that achieves
nearly a global optimum. However, when applied to image segmentation these
methods required a meaningful data term. Unfortunately, for many images,
particularly medical images, it is difficult to find a meaningful data term.
Therefore, we propose to remove the data term completely and instead weight the
curvature locally, while still achieving a global optimum.
</summary>
    <author>
      <name>Noha El-Zehiry</name>
    </author>
    <author>
      <name>Leo Grady</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages , 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1006.4175v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1006.4175v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1006.5920v1</id>
    <updated>2010-06-30T16:54:43Z</updated>
    <published>2010-06-30T16:54:43Z</published>
    <title>A Two Stage Classification Approach for Handwritten Devanagari
  Characters</title>
    <summary>  The paper presents a two stage classification approach for handwritten
devanagari characters The first stage is using structural properties like
shirorekha, spine in character and second stage exploits some intersection
features of characters which are fed to a feedforward neural network. Simple
histogram based method does not work for finding shirorekha, vertical bar
(Spine) in handwritten devnagari characters. So we designed a differential
distance based technique to find a near straight line for shirorekha and spine.
This approach has been tested for 50000 samples and we got 89.12% success
</summary>
    <author>
      <name>Sandhya Arora</name>
    </author>
    <author>
      <name>Debotosh Bhattacharjee</name>
    </author>
    <author>
      <name>Mita Nasipuri</name>
    </author>
    <author>
      <name>Latesh Malik</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ICCIMA 2007</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1006.5920v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1006.5920v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1006.5924v1</id>
    <updated>2010-06-30T17:09:39Z</updated>
    <published>2010-06-30T17:09:39Z</published>
    <title>A novel approach for handwritten Devnagari character recognition</title>
    <summary>  In this paper a method for recognition of handwritten devanagari characters
is described. Here, feature vector is constituted by accumulated directional
gradient changes in different segments, number of intersections points for the
character, type of spine present and type of shirorekha present in the
character. One Multi-layer Perceptron with conjugate-gradient training is used
to classify these feature vectors. This method is applied to a database with
1000 sample characters and the recognition rate obtained is 88.12%
</summary>
    <author>
      <name>Sandhya Arora</name>
    </author>
    <author>
      <name>Latesh Malik</name>
    </author>
    <author>
      <name>Debotosh Bhattacharjee</name>
    </author>
    <author>
      <name>Mita Nasipuri</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ICSIP 2006</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1006.5924v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1006.5924v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1006.5942v1</id>
    <updated>2010-06-30T18:01:47Z</updated>
    <published>2010-06-30T18:01:47Z</published>
    <title>FPGA Based Assembling of Facial Components for Human Face Construction</title>
    <summary>  This paper aims at VLSI realization for generation of a new face from textual
description. The FASY (FAce SYnthesis) System is a Face Database Retrieval and
new Face generation System that is under development. One of its main features
is the generation of the requested face when it is not found in the existing
database. The new face generation system works in three steps - searching
phase, assembling phase and tuning phase. In this paper the tuning phase using
hardware description language and its implementation in a Field Programmable
Gate Array (FPGA) device is presented.
</summary>
    <author>
      <name>Santanu Halder</name>
    </author>
    <author>
      <name>Debotosh Bhattacharjee</name>
    </author>
    <author>
      <name>Mita Nasipuri</name>
    </author>
    <author>
      <name>Dipak Kumar Basu</name>
    </author>
    <author>
      <name>Mahantapas Kundu</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IJRTE 1(1):541-545(2009)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1006.5942v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1006.5942v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1007.0547v1</id>
    <updated>2010-07-04T12:19:16Z</updated>
    <published>2010-07-04T12:19:16Z</published>
    <title>A Fast Decision Technique for Hierarchical Hough Transform for Line
  Detection</title>
    <summary>  Many techniques have been proposed to speedup the performance of classic
Hough Transform. These techniques are primarily based on converting the voting
procedure to a hierarchy based voting method. These methods use approximate
decision-making process. In this paper, we propose a fast decision making
process that enhances the speed and reduces the space requirements.
Experimental results demonstrate that the proposed algorithm is much faster
than a similar Fast Hough Transform.
</summary>
    <author>
      <name>Chandan Singh</name>
    </author>
    <author>
      <name>Nitin Bhatia</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, published at IEEE conference on Signal and Image Processing
  - 2006</arxiv:comment>
    <link href="http://arxiv.org/abs/1007.0547v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1007.0547v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1007.0626v1</id>
    <updated>2010-07-05T07:33:45Z</updated>
    <published>2010-07-05T07:33:45Z</published>
    <title>Fusion of Wavelet Coefficients from Visual and Thermal Face Images for
  Human Face Recognition - A Comparative Study</title>
    <summary>  In this paper we present a comparative study on fusion of visual and thermal
images using different wavelet transformations. Here, coefficients of discrete
wavelet transforms from both visual and thermal images are computed separately
and combined. Next, inverse discrete wavelet transformation is taken in order
to obtain fused face image. Both Haar and Daubechies (db2) wavelet transforms
have been used to compare recognition results. For experiments IRIS
Thermal/Visual Face Database was used. Experimental results using Haar and
Daubechies wavelets show that the performance of the approach presented here
achieves maximum success rate of 100% in many cases.
</summary>
    <author>
      <name>M. K. Bhowmik</name>
    </author>
    <author>
      <name>Debotosh Bhattacharjee</name>
    </author>
    <author>
      <name>M. Nasipuri</name>
    </author>
    <author>
      <name>D. K. Basu</name>
    </author>
    <author>
      <name>M. Kundu</name>
    </author>
    <link href="http://arxiv.org/abs/1007.0626v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1007.0626v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1007.3881v2</id>
    <updated>2010-10-16T17:01:02Z</updated>
    <published>2010-07-22T13:22:50Z</published>
    <title>Orthogonal multifilters image processing of astronomical images from
  scanned photographic plates</title>
    <summary>  In this paper orthogonal multifilters for astronomical image processing are
presented. We obtained new orthogonal multifilters based on the orthogonal
wavelet of Haar and Daubechies. Recently, multiwavelets have been introduced as
a more powerful multiscale analysis tool. It adds several degrees of freedom in
multifilter design and makes it possible to have several useful properties such
as symmetry, orthogonality, short support, and a higher number of vanishing
moments simultaneously. Multifilter decomposition of scanned photographic
plates with astronomical images is made.
</summary>
    <author>
      <name>Vasil Kolev</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, The ACM proceedings of CompSysTech 2010</arxiv:comment>
    <link href="http://arxiv.org/abs/1007.3881v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1007.3881v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1008.3346v1</id>
    <updated>2010-08-19T16:38:35Z</updated>
    <published>2010-08-19T16:38:35Z</published>
    <title>A Miniature-Based Image Retrieval System</title>
    <summary>  Due to the rapid development of World Wide Web (WWW) and imaging technology,
more and more images are available in the Internet and stored in databases.
Searching the related images by the querying image is becoming tedious and
difficult. Most of the images on the web are compressed by methods based on
discrete cosine transform (DCT) including Joint Photographic Experts
Group(JPEG) and H.261. This paper presents an efficient content-based image
indexing technique for searching similar images using discrete cosine transform
features. Experimental results demonstrate its superiority with the existing
techniques.
</summary>
    <author>
      <name>Md. Saiful Islam</name>
    </author>
    <author>
      <name>Md. Haider Ali</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 4 figures, 4 tables</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Dhaka University Journal of Science,Vol. 57, No. 2, pp. 187-191,
  July 2009</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1008.3346v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1008.3346v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1009.0854v1</id>
    <updated>2010-09-04T17:44:06Z</updated>
    <published>2010-09-04T17:44:06Z</published>
    <title>Fast Color Space Transformations Using Minimax Approximations</title>
    <summary>  Color space transformations are frequently used in image processing,
graphics, and visualization applications. In many cases, these transformations
are complex nonlinear functions, which prohibits their use in time-critical
applications. In this paper, we present a new approach called Minimax
Approximations for Color-space Transformations (MACT).We demonstrate MACT on
three commonly used color space transformations. Extensive experiments on a
large and diverse image set and comparisons with well-known multidimensional
lookup table interpolation methods show that MACT achieves an excellent balance
among four criteria: ease of implementation, memory usage, accuracy, and
computational speed.
</summary>
    <author>
      <name>M. Emre Celebi</name>
    </author>
    <author>
      <name>Hassan Kingravi</name>
    </author>
    <author>
      <name>Fatih Celiker</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1049/iet-ipr.2008.0172</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1049/iet-ipr.2008.0172" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IET Image Processing 4 (2010) 70-80</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1009.0854v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1009.0854v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.2; I.4.m" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1009.0957v1</id>
    <updated>2010-09-05T23:49:38Z</updated>
    <published>2010-09-05T23:49:38Z</published>
    <title>Distance Measures for Reduced Ordering Based Vector Filters</title>
    <summary>  Reduced ordering based vector filters have proved successful in removing
long-tailed noise from color images while preserving edges and fine image
details. These filters commonly utilize variants of the Minkowski distance to
order the color vectors with the aim of distinguishing between noisy and
noise-free vectors. In this paper, we review various alternative distance
measures and evaluate their performance on a large and diverse set of images
using several effectiveness and efficiency criteria. The results demonstrate
that there are in fact strong alternatives to the popular Minkowski metrics.
</summary>
    <author>
      <name>M. Emre Celebi</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1049/iet-ipr.2009.0056</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1049/iet-ipr.2009.0056" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IET Image Processing 3 (2009) 249-260</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1009.0957v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1009.0957v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.4.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1009.0958v1</id>
    <updated>2010-09-05T23:53:27Z</updated>
    <published>2010-09-05T23:53:27Z</published>
    <title>Real-Time Implementation of Order-Statistics Based Directional Filters</title>
    <summary>  Vector filters based on order-statistics have proved successful in removing
impulsive noise from color images while preserving edges and fine image
details. Among these filters, the ones that involve the cosine distance
function (directional filters) have particularly high computational
requirements, which limits their use in time critical applications. In this
paper, we introduce two methods to speed up these filters. Experiments on a
diverse set of color images show that the proposed methods provide substantial
computational gains without significant loss of accuracy.
</summary>
    <author>
      <name>M. Emre Celebi</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1049/iet-ipr:20080080</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1049/iet-ipr:20080080" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IET Image Processing 3 (2009) 1-9</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1009.0958v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1009.0958v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.4.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1009.0959v1</id>
    <updated>2010-09-06T00:02:35Z</updated>
    <published>2010-09-06T00:02:35Z</published>
    <title>Cost-Effective Implementation of Order-Statistics Based Vector Filters
  Using Minimax Approximations</title>
    <summary>  Vector operators based on robust order statistics have proved successful in
digital multichannel imaging applications, particularly color image filtering
and enhancement, in dealing with impulsive noise while preserving edges and
fine image details. These operators often have very high computational
requirements which limits their use in time-critical applications. This paper
introduces techniques to speed up vector filters using the minimax
approximation theory. Extensive experiments on a large and diverse set of color
images show that proposed approximations achieve an excellent balance among
ease of implementation, accuracy, and computational speed.
</summary>
    <author>
      <name>M. Emre Celebi</name>
    </author>
    <author>
      <name>Hassan A. Kingravi</name>
    </author>
    <author>
      <name>Rastislav Lukac</name>
    </author>
    <author>
      <name>Fatih Celiker</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1364/JOSAA.26.001518</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1364/JOSAA.26.001518" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of the Optical Society of America A 26 (2009) 1518-1524</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1009.0959v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1009.0959v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.4.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1009.0961v1</id>
    <updated>2010-09-06T00:13:25Z</updated>
    <published>2010-09-06T00:13:25Z</published>
    <title>A Fast Switching Filter for Impulsive Noise Removal from Color Images</title>
    <summary>  In this paper, we present a fast switching filter for impulsive noise removal
from color images. The filter exploits the HSL color space, and is based on the
peer group concept, which allows for the fast detection of noise in a
neighborhood without resorting to pairwise distance computations between each
pixel. Experiments on large set of diverse images demonstrate that the proposed
approach is not only extremely fast, but also gives excellent results in
comparison to various state-of-the-art filters.
</summary>
    <author>
      <name>M. Emre Celebi</name>
    </author>
    <author>
      <name>Hassan A. Kingravi</name>
    </author>
    <author>
      <name>Bakhtiyar Uddin</name>
    </author>
    <author>
      <name>Y. Alp Aslandogan</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.2352/J.ImagingSci.Technol.(2007)51:2(155)</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.2352/J.ImagingSci.Technol.(2007)51:2(155)" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Imaging Science and Technology 51 (2007) 155-165</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1009.0961v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1009.0961v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.4.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1009.4004v2</id>
    <updated>2011-12-19T02:31:16Z</updated>
    <published>2010-09-21T06:32:52Z</published>
    <title>A family of statistical symmetric divergences based on Jensen's
  inequality</title>
    <summary>  We introduce a novel parametric family of symmetric information-theoretic
distances based on Jensen's inequality for a convex functional generator. In
particular, this family unifies the celebrated Jeffreys divergence with the
Jensen-Shannon divergence when the Shannon entropy generator is chosen. We then
design a generic algorithm to compute the unique centroid defined as the
minimum average divergence. This yields a smooth family of centroids linking
the Jeffreys to the Jensen-Shannon centroid. Finally, we report on our
experimental results.
</summary>
    <author>
      <name>Frank Nielsen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 2 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1009.4004v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1009.4004v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1010.3467v1</id>
    <updated>2010-10-18T02:31:21Z</updated>
    <published>2010-10-18T02:31:21Z</published>
    <title>Fast Inference in Sparse Coding Algorithms with Applications to Object
  Recognition</title>
    <summary>  Adaptive sparse coding methods learn a possibly overcomplete set of basis
functions, such that natural image patches can be reconstructed by linearly
combining a small subset of these bases. The applicability of these methods to
visual object recognition tasks has been limited because of the prohibitive
cost of the optimization algorithms required to compute the sparse
representation. In this work we propose a simple and efficient algorithm to
learn basis functions. After training, this model also provides a fast and
smooth approximator to the optimal representation, achieving even better
accuracy than exact sparse coding algorithms on visual object recognition
tasks.
</summary>
    <author>
      <name>Koray Kavukcuoglu</name>
    </author>
    <author>
      <name>Marc'Aurelio Ranzato</name>
    </author>
    <author>
      <name>Yann LeCun</name>
    </author>
    <link href="http://arxiv.org/abs/1010.3467v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1010.3467v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1011.3023v4</id>
    <updated>2013-11-20T16:42:37Z</updated>
    <published>2010-11-12T20:15:25Z</published>
    <title>Classification with Scattering Operators</title>
    <summary>  A scattering vector is a local descriptor including multiscale and
multi-direction co-occurrence information. It is computed with a cascade of
wavelet decompositions and complex modulus. This scattering representation is
locally translation invariant and linearizes deformations. A supervised
classification algorithm is computed with a PCA model selection on scattering
vectors. State of the art results are obtained for handwritten digit
recognition and texture classification.
</summary>
    <author>
      <name>Joan Bruna</name>
    </author>
    <author>
      <name>Stéphane Mallat</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages. CVPR 2011</arxiv:comment>
    <link href="http://arxiv.org/abs/1011.3023v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1011.3023v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1011.4321v1</id>
    <updated>2010-11-18T22:20:45Z</updated>
    <published>2010-11-18T22:20:45Z</published>
    <title>A Fuzzy Clustering Model for Fuzzy Data with Outliers</title>
    <summary>  In this paper a fuzzy clustering model for fuzzy data with outliers is
proposed. The model is based on Wasserstein distance between interval valued
data which is generalized to fuzzy data. In addition, Keller's approach is used
to identify outliers and reduce their influences. We have also defined a
transformation to change our distance to the Euclidean distance. With the help
of this approach, the problem of fuzzy clustering of fuzzy data is reduced to
fuzzy clustering of crisp data. In order to show the performance of the
proposed clustering algorithm, two simulation experiments are discussed.
</summary>
    <author>
      <name>M. H. Fazel Zarandi</name>
    </author>
    <author>
      <name>Zahra S. Razaee</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, Journal paper</arxiv:comment>
    <link href="http://arxiv.org/abs/1011.4321v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1011.4321v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1012.2491v1</id>
    <updated>2010-12-11T21:48:51Z</updated>
    <published>2010-12-11T21:48:51Z</published>
    <title>Affine Invariant, Model-Based Object Recognition Using Robust Metrics
  and Bayesian Statistics</title>
    <summary>  We revisit the problem of model-based object recognition for intensity images
and attempt to address some of the shortcomings of existing Bayesian methods,
such as unsuitable priors and the treatment of residuals with a non-robust
error norm. We do so by using a refor- mulation of the Huber metric and
carefully chosen prior distributions. Our proposed method is invariant to
2-dimensional affine transforma- tions and, because it is relatively easy to
train and use, it is suited for general object matching problems.
</summary>
    <author>
      <name>Vasileios Zografos</name>
    </author>
    <author>
      <name>Bernard Buxton</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/11559573_51</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/11559573_51" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Image Analysis and Recognition Lecture Notes in Computer Science,
  2005, Volume 3656/2005, 407-414</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1012.2491v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1012.2491v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1012.3802v1</id>
    <updated>2010-12-17T03:27:54Z</updated>
    <published>2010-12-17T03:27:54Z</published>
    <title>Detecting Image Forgeries using Geometric Cues</title>
    <summary>  This chapter presents a framework for detecting fake regions by using various
methods including watermarking technique and blind approaches. In particular,
we describe current categories on blind approaches which can be divided into
five: pixel-based techniques, format-based techniques, camera-based techniques,
physically-based techniques and geometric-based techniques. Then we take a
second look on the geometric-based techniques and further categorize them in
detail. In the following section, the state-of-the-art methods involved in the
geometric technique are elaborated.
</summary>
    <author>
      <name>Lin Wu</name>
    </author>
    <author>
      <name>Yang Wang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, 10 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1012.3802v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1012.3802v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1012.3951v1</id>
    <updated>2010-12-17T18:23:35Z</updated>
    <published>2010-12-17T18:23:35Z</published>
    <title>Diffusion-geometric maximally stable component detection in deformable
  shapes</title>
    <summary>  Maximally stable component detection is a very popular method for feature
analysis in images, mainly due to its low computation cost and high
repeatability. With the recent advance of feature-based methods in geometric
shape analysis, there is significant interest in finding analogous approaches
in the 3D world. In this paper, we formulate a diffusion-geometric framework
for stable component detection in non-rigid 3D shapes, which can be used for
geometric feature detection and description. A quantitative evaluation of our
method on the SHREC'10 feature detection benchmark shows its potential as a
source of high-quality features.
</summary>
    <author>
      <name>Roee Litman</name>
    </author>
    <author>
      <name>Alex M. Bronstein</name>
    </author>
    <author>
      <name>Michael M. Bronstein</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.cag.2011.03.011</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.cag.2011.03.011" rel="related"/>
    <link href="http://arxiv.org/abs/1012.3951v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1012.3951v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.4.7; I.4.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1012.5933v1</id>
    <updated>2010-12-29T13:11:41Z</updated>
    <published>2010-12-29T13:11:41Z</published>
    <title>Affine-invariant diffusion geometry for the analysis of deformable 3D
  shapes</title>
    <summary>  We introduce an (equi-)affine invariant diffusion geometry by which surfaces
that go through squeeze and shear transformations can still be properly
analyzed. The definition of an affine invariant metric enables us to construct
an invariant Laplacian from which local and global geometric structures are
extracted. Applications of the proposed framework demonstrate its power in
generalizing and enriching the existing set of tools for shape analysis.
</summary>
    <author>
      <name>Dan Raviv</name>
    </author>
    <author>
      <name>Alexander M. Bronstein</name>
    </author>
    <author>
      <name>Michael M. Bronstein</name>
    </author>
    <author>
      <name>Ron Kimmel</name>
    </author>
    <author>
      <name>Nir Sochen</name>
    </author>
    <link href="http://arxiv.org/abs/1012.5933v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1012.5933v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1101.2243v1</id>
    <updated>2010-12-12T20:49:00Z</updated>
    <published>2010-12-12T20:49:00Z</published>
    <title>Illustrating Color Evolution and Color Blindness by the Decoding Model
  of Color Vision</title>
    <summary>  A symmetrical model of color vision, the decoding model as a new version of
zone model, was introduced. The model adopts new continuous-valued logic and
works in a way very similar to the way a 3-8 decoder in a numerical circuit
works. By the decoding model, Young and Helmholtz's tri-pigment theory and
Hering's opponent theory are unified more naturally; opponent process, color
evolution, and color blindness are illustrated more concisely. According to the
decoding model, we can obtain a transform from RGB system to HSV system, which
is formally identical to the popular transform for computer graphics provided
by Smith (1978). Advantages, problems, and physiological tests of the decoding
model are also discussed.
</summary>
    <author>
      <name>Chenguang Lu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 9 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1101.2243v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1101.2243v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1101.2312v1</id>
    <updated>2011-01-12T10:16:11Z</updated>
    <published>2011-01-12T10:16:11Z</published>
    <title>Automatic segmentation of HeLa cell images</title>
    <summary>  In this work, the possibilities for segmentation of cells from their
background and each other in digital image were tested, combined and improoved.
Lot of images with young, adult and mixture cells were able to prove the
quality of described algorithms. Proper segmentation is one of the main task of
image analysis and steps order differ from work to work, depending on input
images. Reply for biologicaly given question was looking for in this work,
including filtration, details emphasizing, segmentation and sphericity
computing. Order of algorithms and way to searching for them was also
described. Some questions and ideas for further work were mentioned in the
conclusion part.
</summary>
    <author>
      <name>Jan Urban</name>
    </author>
    <link href="http://arxiv.org/abs/1101.2312v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1101.2312v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1101.4301v1</id>
    <updated>2011-01-22T16:41:20Z</updated>
    <published>2011-01-22T16:41:20Z</published>
    <title>Diffusion framework for geometric and photometric data fusion in
  non-rigid shape analysis</title>
    <summary>  In this paper, we explore the use of the diffusion geometry framework for the
fusion of geometric and photometric information in local and global shape
descriptors. Our construction is based on the definition of a diffusion process
on the shape manifold embedded into a high-dimensional space where the
embedding coordinates represent the photometric information. Experimental
results show that such data fusion is useful in coping with different
challenges of shape analysis where pure geometric and pure photometric methods
fail.
</summary>
    <author>
      <name>Artiom Kovnatsky</name>
    </author>
    <author>
      <name>Michael M. Bronstein</name>
    </author>
    <author>
      <name>Alexander M. Bronstein</name>
    </author>
    <author>
      <name>Ron Kimmel</name>
    </author>
    <link href="http://arxiv.org/abs/1101.4301v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1101.4301v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.1587v2</id>
    <updated>2011-03-10T18:46:23Z</updated>
    <published>2011-03-08T17:50:56Z</published>
    <title>All Roads Lead To Rome</title>
    <summary>  This short article presents a class of projection-based solution algorithms
to the problem considered in the pioneering work on compressed sensing -
perfect reconstruction of a phantom image from 22 radial lines in the frequency
domain. Under the framework of projection-based image reconstruction, we will
show experimentally that several old and new tools of nonlinear filtering
(including Perona-Malik diffusion, nonlinear diffusion, Translation-Invariant
thresholding and SA-DCT thresholding) all lead to perfect reconstruction of the
phantom image.
</summary>
    <author>
      <name>Xin Li</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 1 figure, submitted</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE SPM'2011 as a Column Paper for DSP Tips&amp;Tricks</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1103.1587v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.1587v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.3440v1</id>
    <updated>2011-03-17T15:52:15Z</updated>
    <published>2011-03-17T15:52:15Z</published>
    <title>Off-Line Handwritten Signature Identification Using Rotated Complex
  Wavelet Filters</title>
    <summary>  In this paper, a new method for handwritten signature identification based on
rotated complex wavelet filters is proposed. We have proposed to use the
rotated complex wavelet filters (RCWF) and dual tree complex wavelet
transform(DTCWT) together to derive signature feature extraction, which
captures information in twelve different directions. In identification phase,
Canberra distance measure is used. The proposed method is compared with
discrete wavelet transform (DWT). From experimental results it is found that
signature identification rate of proposed method is superior over DWT
</summary>
    <author>
      <name>M. S. Shirdhonkar</name>
    </author>
    <author>
      <name>Manesh Kokare</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IJCSI International Journal of Computer Science Issues, Vol. 8,
  Issue 1, January 2011 ISSN (Online): 1694-0814</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1103.3440v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.3440v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1104.0579v1</id>
    <updated>2011-04-04T14:14:47Z</updated>
    <published>2011-04-04T14:14:47Z</published>
    <title>Image Retrieval Method Using Top-surf Descriptor</title>
    <summary>  This report presents the results and details of a content-based image
retrieval project using the Top-surf descriptor. The experimental results are
preliminary, however, it shows the capability of deducing objects from parts of
the objects or from the objects that are similar. This paper uses a dataset
consisting of 1200 images of which 800 images are equally divided into 8
categories, namely airplane, beach, motorbike, forest, elephants, horses, bus
and building, while the other 400 images are randomly picked from the Internet.
The best results achieved are from building category.
</summary>
    <author>
      <name>Ye Ji</name>
    </author>
    <link href="http://arxiv.org/abs/1104.0579v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1104.0579v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1104.1472v1</id>
    <updated>2011-04-08T03:15:43Z</updated>
    <published>2011-04-08T03:15:43Z</published>
    <title>Gaussian Affine Feature Detector</title>
    <summary>  A new method is proposed to get image features' geometric information. Using
Gaussian as an input signal, a theoretical optimal solution to calculate
feature's affine shape is proposed. Based on analytic result of a feature
model, the method is different from conventional iterative approaches. From the
model, feature's parameters such as position, orientation, background
luminance, contrast, area and aspect ratio can be extracted. Tested with
synthesized and benchmark data, the method achieves or outperforms existing
approaches in term of accuracy, speed and stability. The method can detect
small, long or thin objects precisely, and works well under general conditions,
such as for low contrast, blurred or noisy images.
</summary>
    <author>
      <name>Xiaopeng Xu</name>
    </author>
    <author>
      <name>Xiaochun Zhang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">A paper about two dimension image signal detection, including
  position, length, width, height, orentation</arxiv:comment>
    <link href="http://arxiv.org/abs/1104.1472v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1104.1472v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1104.1485v1</id>
    <updated>2011-04-08T05:18:15Z</updated>
    <published>2011-04-08T05:18:15Z</published>
    <title>Fuzzy Rules and Evidence Theory for Satellite Image Analysis</title>
    <summary>  Design of a fuzzy rule based classifier is proposed. The performance of the
classifier for multispectral satellite image classification is improved using
Dempster- Shafer theory of evidence that exploits information of the
neighboring pixels. The classifiers are tested rigorously with two known images
and their performance are found to be better than the results available in the
literature. We also demonstrate the improvement of performance while using D-S
theory along with fuzzy rule based classifiers over the basic fuzzy rule based
classifiers for all the test cases.
</summary>
    <author>
      <name>Arijit Laha</name>
    </author>
    <author>
      <name>J. Das</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, International Conference on Advances in Pattern Recognition
  2003 (ICAPR03)</arxiv:comment>
    <link href="http://arxiv.org/abs/1104.1485v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1104.1485v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1104.2171v1</id>
    <updated>2011-04-12T11:20:06Z</updated>
    <published>2011-04-12T11:20:06Z</published>
    <title>From a Modified Ambrosio-Tortorelli to a Randomized Part Hierarchy Tree</title>
    <summary>  We demonstrate the possibility of coding parts, features that are higher
level than boundaries, using a modified AT field after augmenting the
interaction term of the AT energy with a non-local term and weakening the
separation into boundary/not-boundary phases. The iteratively extracted parts
using the level curves with double point singularities are organized as a
proper binary tree. Inconsistencies due to non-generic configurations for level
curves as well as due to visual changes such as occlusion are successfully
handled once the tree is endowed with a probabilistic structure. The work is a
step in establishing the AT function as a bridge between low and high level
visual processing.
</summary>
    <author>
      <name>Sibel Tari</name>
    </author>
    <author>
      <name>Murat Genctav</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Scale Space and Variational Methods 2011</arxiv:comment>
    <link href="http://arxiv.org/abs/1104.2171v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1104.2171v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1104.3742v1</id>
    <updated>2011-04-19T13:36:15Z</updated>
    <published>2011-04-19T13:36:15Z</published>
    <title>Hue Histograms to Spatiotemporal Local Features for Action Recognition</title>
    <summary>  Despite the recent developments in spatiotemporal local features for action
recognition in video sequences, local color information has so far been
ignored. However, color has been proved an important element to the success of
automated recognition of objects and scenes. In this paper we extend the
space-time interest point descriptor STIP to take into account the color
information on the features' neighborhood. We compare the performance of our
color-aware version of STIP (which we have called HueSTIP) with the original
one.
</summary>
    <author>
      <name>Fillipe Souza</name>
    </author>
    <author>
      <name>Eduardo Valle</name>
    </author>
    <author>
      <name>Guillermo Chávez</name>
    </author>
    <author>
      <name>Arnaldo Araújo</name>
    </author>
    <link href="http://arxiv.org/abs/1104.3742v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1104.3742v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1104.4295v1</id>
    <updated>2011-04-21T15:45:52Z</updated>
    <published>2011-04-21T15:45:52Z</published>
    <title>Improving digital signal interpolation: L2-optimal kernels with
  kernel-invariant interpolation speed</title>
    <summary>  Interpolation is responsible for digital signal resampling and can
significantly degrade the original signal quality if not done properly. For
many years, optimal interpolation algorithms were sought within constrained
classes of interpolation kernel functions. We derive a new family of
unconstrained L2-optimal interpolation kernels, and compare their properties to
the previously known. Although digital images are used to illustrate this work,
our L2-optimal kernels can be applied to interpolate any digital signals.
</summary>
    <author>
      <name>Oleg S. Pianykh</name>
    </author>
    <link href="http://arxiv.org/abs/1104.4295v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1104.4295v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1105.0821v1</id>
    <updated>2011-05-04T13:40:16Z</updated>
    <published>2011-05-04T13:40:16Z</published>
    <title>Considerations and Results in Multimedia and DVB Application Development
  on Philips Nexperia Platform</title>
    <summary>  This paper presents some experiments regarding applications development on
high performance media processors included in Philips Nexperia Family. The
PNX1302 dedicated DVB-T kit used has some limitations. Our work has succeeded
to overcome these limitations and to make possible a general-purpose use of
this kit. For exemplification two typical applications, important both for
multimedia and DVB, are analyzed: MPEG2 video stream decoding and MP3 audio
decoding. These original implementations are compared (in speed, memory
requirements and costs) with Philips Nexperia Library.
</summary>
    <author>
      <name>Radu Arsinte</name>
    </author>
    <author>
      <name>Ciprian Ilioaei</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3 pages, 1 figure</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Scientific Bulletin of the "Politehnica" University Timi\c{s}oara,
  Transaction on Electronics and Telecomunications, Tom 49(63), Fascicola 2,
  2004, pag. 138-141</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1105.0821v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1105.0821v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1105.3828v2</id>
    <updated>2013-02-02T07:28:58Z</updated>
    <published>2011-05-19T09:50:01Z</published>
    <title>An Algorithmic Solution to the Five-Point Pose Problem Based on the
  Cayley Representation of Rotations</title>
    <summary>  We give a new algorithmic solution to the well-known five-point relative pose
problem. Our approach does not deal with the famous cubic constraint on an
essential matrix. Instead, we use the Cayley representation of rotations in
order to obtain a polynomial system from epipolar constraints. Solving that
system, we directly get relative rotation and translation parameters of the
cameras in terms of roots of a 10th degree polynomial.
</summary>
    <author>
      <name>Evgeniy Martyushev</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1105.3828v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1105.3828v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1105.5307v1</id>
    <updated>2011-05-26T14:31:58Z</updated>
    <published>2011-05-26T14:31:58Z</published>
    <title>Efficient Learning of Sparse Invariant Representations</title>
    <summary>  We propose a simple and efficient algorithm for learning sparse invariant
representations from unlabeled data with fast inference. When trained on short
movies sequences, the learned features are selective to a range of orientations
and spatial frequencies, but robust to a wide range of positions, similar to
complex cells in the primary visual cortex. We give a hierarchical version of
the algorithm, and give guarantees of fast convergence under certain
conditions.
</summary>
    <author>
      <name>Karol Gregor</name>
    </author>
    <author>
      <name>Yann LeCun</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages + 6 supplement pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1105.5307v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1105.5307v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1105.6060v1</id>
    <updated>2011-05-30T18:30:51Z</updated>
    <published>2011-05-30T18:30:51Z</published>
    <title>Alignment of Microtubule Imagery</title>
    <summary>  This work discusses preliminary work aimed at simulating and visualizing the
growth process of a tiny structure inside the cell---the microtubule.
Difficulty of recording the process lies in the fact that the tissue
preparation method for electronic microscopes is highly destructive to live
cells. Here in this paper, our approach is to take pictures of microtubules at
different time slots and then appropriately combine these images into a
coherent video. Experimental results are given on real data.
</summary>
    <author>
      <name>Feiyang Yu</name>
    </author>
    <author>
      <name>Ard Oerlemans</name>
    </author>
    <author>
      <name>Erwin M. Bakker</name>
    </author>
    <link href="http://arxiv.org/abs/1105.6060v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1105.6060v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1106.0107v1</id>
    <updated>2011-06-01T07:22:04Z</updated>
    <published>2011-06-01T07:22:04Z</published>
    <title>Handwritten Character Recognition of South Indian Scripts: A Review</title>
    <summary>  Handwritten character recognition is always a frontier area of research in
the field of pattern recognition and image processing and there is a large
demand for OCR on hand written documents. Even though, sufficient studies have
performed in foreign scripts like Chinese, Japanese and Arabic characters, only
a very few work can be traced for handwritten character recognition of Indian
scripts especially for the South Indian scripts. This paper provides an
overview of offline handwritten character recognition in South Indian Scripts,
namely Malayalam, Tamil, Kannada and Telungu.
</summary>
    <author>
      <name>John Jomy</name>
    </author>
    <author>
      <name>K. V. Pramod</name>
    </author>
    <author>
      <name>Balakrishnan Kannan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Paper presented on the "National Conference on Indian Language
  Computing", Kochi, February 19-20, 2011. 6 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1106.0107v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1106.0107v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1106.5341v1</id>
    <updated>2011-06-27T09:47:28Z</updated>
    <published>2011-06-27T09:47:28Z</published>
    <title>Pose Estimation from a Single Depth Image for Arbitrary Kinematic
  Skeletons</title>
    <summary>  We present a method for estimating pose information from a single depth image
given an arbitrary kinematic structure without prior training. For an arbitrary
skeleton and depth image, an evolutionary algorithm is used to find the optimal
kinematic configuration to explain the observed image. Results show that our
approach can correctly estimate poses of 39 and 78 degree-of-freedom models
from a single depth image, even in cases of significant self-occlusion.
</summary>
    <author>
      <name>Daniel L. Ly</name>
    </author>
    <author>
      <name>Ashutosh Saxena</name>
    </author>
    <author>
      <name>Hod Lipson</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2 pages, 2 figures, RGB-D workshop in Robotics: Science and Systems
  (RSS 2011)</arxiv:comment>
    <link href="http://arxiv.org/abs/1106.5341v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1106.5341v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1106.5571v1</id>
    <updated>2011-06-28T06:08:38Z</updated>
    <published>2011-06-28T06:08:38Z</published>
    <title>Mobile Augmented Reality Applications</title>
    <summary>  Augmented reality have undergone considerable improvement in past years. Many
special techniques and hardware devices were developed, but the crucial
breakthrough came with the spread of intelligent mobile phones. This enabled
mass spread of augmented reality applications. However mobile devices have
limited hardware capabilities, which narrows down the methods usable for scene
analysis. In this article we propose an augmented reality application which is
using cloud computing to enable using of more complex computational methods
such as neural networks. Our goal is to create an affordable augmented reality
application suitable which will help car designers in by 'virtualizing' car
modifications.
</summary>
    <author>
      <name>David Prochazka</name>
    </author>
    <author>
      <name>Michael Stencl</name>
    </author>
    <author>
      <name>Ondrej Popelka</name>
    </author>
    <author>
      <name>Jiri Stastny</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of Mendel 2011: 17th International Conference on Soft
  Computing, pp. 469-476, ISBN 978-80-214-4302-0</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1106.5571v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1106.5571v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1107.1058v1</id>
    <updated>2011-07-06T08:43:38Z</updated>
    <published>2011-07-06T08:43:38Z</published>
    <title>Online Vehicle Detection For Estimating Traffic Status</title>
    <summary>  We propose a traffic congestion estimation system based on unsupervised
on-line learning algorithm. The system does not rely on background extraction
or motion detection. It extracts local features inside detection regions of
variable size which are drawn on lanes in advance. The extracted features are
then clustered into two classes using K-means and Gaussian Mixture Models(GMM).
A Bayes classifier is used to detect vehicles according to the previous cluster
information which keeps updated whenever system is running by on-line EM
algorithm. Experimental result shows that our system can be adapted to various
traffic scenes for estimating traffic status.
</summary>
    <author>
      <name>Ranch Y. Q. Lai</name>
    </author>
    <link href="http://arxiv.org/abs/1107.1058v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1107.1058v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1107.1081v1</id>
    <updated>2011-07-06T10:02:42Z</updated>
    <published>2011-07-06T10:02:42Z</published>
    <title>Spatial Features for Multi-Font/Multi-Size Kannada Numerals and Vowels
  Recognition</title>
    <summary>  This paper presents multi-font/multi-size Kannada numerals and vowels
recognition based on spatial features. Directional spatial features viz stroke
density, stroke length and the number of stokes in an image are employed as
potential features to characterize the printed Kannada numerals and vowels.
Based on these features 1100 numerals and 1400 vowels are classified with
Multi-class Support Vector Machines (SVM). The proposed system achieves the
recognition accuracy as 98.45% and 90.64% for numerals and vowels respectively.
</summary>
    <author>
      <name>B. V. Dhandra</name>
    </author>
    <author>
      <name>Mallikarjun Hangarge</name>
    </author>
    <author>
      <name>Gururaj Mukarambi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 4 Figures, 4 Tables, "International Conference on
  Communication, Computation, Control and Nanotechnology (2010)"</arxiv:comment>
    <link href="http://arxiv.org/abs/1107.1081v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1107.1081v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1107.2336v1</id>
    <updated>2011-07-12T16:21:06Z</updated>
    <published>2011-07-12T16:21:06Z</published>
    <title>A Variation of the Box-Counting Algorithm Applied to Colour Images</title>
    <summary>  The box counting method for fractal dimension estimation had not been applied
to large or colour images thus far due to the processing time required. In this
letter we present a fast, easy to implement and very easily expandable to any
number of dimensions variation, the box merging method. It is applied here in
RGB images which are considered as sets in 5-D space.
</summary>
    <author>
      <name>N. S. Nikolaidis</name>
    </author>
    <author>
      <name>I. N. Nikolaidis</name>
    </author>
    <author>
      <name>C. C. Tsouros</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1107.2336v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1107.2336v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="28A78, 28A80" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1107.2693v1</id>
    <updated>2011-07-13T22:46:58Z</updated>
    <published>2011-07-13T22:46:58Z</published>
    <title>A Fuzzy View on k-Means Based Signal Quantization with Application in
  Iris Segmentation</title>
    <summary>  This paper shows that the k-means quantization of a signal can be interpreted
both as a crisp indicator function and as a fuzzy membership assignment
describing fuzzy clusters and fuzzy boundaries. Combined crisp and fuzzy
indicator functions are defined here as natural generalizations of the ordinary
crisp and fuzzy indicator functions, respectively. An application to iris
segmentation is presented together with a demo program.
</summary>
    <author>
      <name>Nicolaie Popescu-Bodorin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4, pages, 3 figures, 17th Telecommunications Forum TELFOR 2009,
  Belgrade, Serbia</arxiv:comment>
    <link href="http://arxiv.org/abs/1107.2693v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1107.2693v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68U10, 68T10" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.4.6; I.5.1; I.5.3; I.5.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1107.4958v1</id>
    <updated>2011-07-25T14:20:34Z</updated>
    <published>2011-07-25T14:20:34Z</published>
    <title>Efficient and Accurate Gaussian Image Filtering Using Running Sums</title>
    <summary>  This paper presents a simple and efficient method to convolve an image with a
Gaussian kernel. The computation is performed in a constant number of
operations per pixel using running sums along the image rows and columns. We
investigate the error function used for kernel approximation and its relation
to the properties of the input signal. Based on natural image statistics we
propose a quadratic form kernel error function so that the output image l2
error is minimized. We apply the proposed approach to approximate the Gaussian
kernel by linear combination of constant functions. This results in very
efficient Gaussian filtering method. Our experiments show that the proposed
technique is faster than state of the art methods while preserving a similar
accuracy.
</summary>
    <author>
      <name>Elhanan Elboher</name>
    </author>
    <author>
      <name>Michael Werman</name>
    </author>
    <link href="http://arxiv.org/abs/1107.4958v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1107.4958v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1107.5349v1</id>
    <updated>2011-07-26T22:29:35Z</updated>
    <published>2011-07-26T22:29:35Z</published>
    <title>Multi Layer Analysis</title>
    <summary>  This thesis presents a new methodology to analyze one-dimensional signals
trough a new approach called Multi Layer Analysis, for short MLA. It also
provides some new insights on the relationship between one-dimensional signals
processed by MLA and tree kernels, test of randomness and signal processing
techniques. The MLA approach has a wide range of application to the fields of
pattern discovery and matching, computational biology and many other areas of
computer science and signal processing. This thesis includes also some
applications of this approach to real problems in biology and seismology.
</summary>
    <author>
      <name>Luca Pinello</name>
    </author>
    <link href="http://arxiv.org/abs/1107.5349v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1107.5349v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1108.0007v1</id>
    <updated>2011-07-29T20:06:59Z</updated>
    <published>2011-07-29T20:06:59Z</published>
    <title>A Invertible Dimension Reduction of Curves on a Manifold</title>
    <summary>  In this paper, we propose a novel lower dimensional representation of a shape
sequence. The proposed dimension reduction is invertible and computationally
more efficient in comparison to other related works. Theoretically, the
differential geometry tools such as moving frame and parallel transportation
are successfully adapted into the dimension reduction problem of high
dimensional curves. Intuitively, instead of searching for a global flat
subspace for curve embedding, we deployed a sequence of local flat subspaces
adaptive to the geometry of both of the curve and the manifold it lies on. In
practice, the experimental results of the dimension reduction and
reconstruction algorithms well illustrate the advantages of the proposed
theoretical innovation.
</summary>
    <author>
      <name>Sheng Yi</name>
    </author>
    <author>
      <name>Hamid Krim</name>
    </author>
    <author>
      <name>Larry K. Norris</name>
    </author>
    <link href="http://arxiv.org/abs/1108.0007v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1108.0007v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1108.1169v1</id>
    <updated>2011-08-04T19:00:14Z</updated>
    <published>2011-08-04T19:00:14Z</published>
    <title>Learning Representations by Maximizing Compression</title>
    <summary>  We give an algorithm that learns a representation of data through
compression. The algorithm 1) predicts bits sequentially from those previously
seen and 2) has a structure and a number of computations similar to an
autoencoder. The likelihood under the model can be calculated exactly, and
arithmetic coding can be used directly for compression. When training on digits
the algorithm learns filters similar to those of restricted boltzman machines
and denoising autoencoders. Independent samples can be drawn from the model by
a single sweep through the pixels. The algorithm has a good compression
performance when compared to other methods that work under random ordering of
pixels.
</summary>
    <author>
      <name>Karol Gregor</name>
    </author>
    <author>
      <name>Yann LeCun</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1108.1169v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1108.1169v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1108.3525v1</id>
    <updated>2011-08-17T17:06:41Z</updated>
    <published>2011-08-17T17:06:41Z</published>
    <title>Hamiltonian Streamline Guided Feature Extraction with Applications to
  Face Detection</title>
    <summary>  We propose a new feature extraction method based on two dynamical systems
induced by intensity landscape: the negative gradient system and the
Hamiltonian system. We build features based on the Hamiltonian streamlines.
These features contain nice global topological information about the intensity
landscape, and can be used for object detection. We show that for training
images of same size, our feature space is much smaller than that generated by
Haar-like features. The training time is extremely short, and detection speed
and accuracy is similar to Haar-like feature based classifiers.
</summary>
    <author>
      <name>Yingjie Miao</name>
    </author>
    <author>
      <name>Jason J. Corso</name>
    </author>
    <link href="http://arxiv.org/abs/1108.3525v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1108.3525v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1108.4315v1</id>
    <updated>2011-08-22T13:49:57Z</updated>
    <published>2011-08-22T13:49:57Z</published>
    <title>Edge detection based on morphological amoebas</title>
    <summary>  Detecting the edges of objects within images is critical for quality image
processing. We present an edge-detecting technique that uses morphological
amoebas that adjust their shape based on variation in image contours. We
evaluate the method both quantitatively and qualitatively for edge detection of
images, and compare it to classic morphological methods. Our amoeba-based
edge-detection system performed better than the classic edge detectors.
</summary>
    <author>
      <name>Won Yeol Lee</name>
    </author>
    <author>
      <name>Young Woo Kim</name>
    </author>
    <author>
      <name>Se Yun Kim</name>
    </author>
    <author>
      <name>Jae Young Lim</name>
    </author>
    <author>
      <name>Dong Hoon Lim</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1179/1743131X11Y.0000000013</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1179/1743131X11Y.0000000013" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in The Imaging Science Journal</arxiv:comment>
    <link href="http://arxiv.org/abs/1108.4315v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1108.4315v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1108.5710v1</id>
    <updated>2011-08-29T19:06:30Z</updated>
    <published>2011-08-29T19:06:30Z</published>
    <title>Generalized Fast Approximate Energy Minimization via Graph Cuts:
  Alpha-Expansion Beta-Shrink Moves</title>
    <summary>  We present alpha-expansion beta-shrink moves, a simple generalization of the
widely-used alpha-beta swap and alpha-expansion algorithms for approximate
energy minimization. We show that in a certain sense, these moves dominate both
alpha-beta-swap and alpha-expansion moves, but unlike previous generalizations
the new moves require no additional assumptions and are still solvable in
polynomial-time. We show promising experimental results with the new moves,
which we believe could be used in any context where alpha-expansions are
currently employed.
</summary>
    <author>
      <name>Mark Schmidt</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Paris - Rocquencourt</arxiv:affiliation>
    </author>
    <author>
      <name>Karteek Alahari</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Paris - Rocquencourt</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Conference on Uncertainty in Artificial Intelligence (2011)</arxiv:comment>
    <link href="http://arxiv.org/abs/1108.5710v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1108.5710v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1108.5720v1</id>
    <updated>2011-08-29T19:28:13Z</updated>
    <published>2011-08-29T19:28:13Z</published>
    <title>Conjugate Variables as a Resource in Signal and Image Processing</title>
    <summary>  In this paper we develop a new technique to model joint distributions of
signals. Our technique is based on quantum mechanical conjugate variables. We
show that the transition probability of quantum states leads to a distance
function on the signals. This distance function obeys the triangle inequality
on all quantum states and becomes a metric on pure quantum states. Treating
signals as conjugate variables allows us to create a new approach to segment
them.
  Keywords: Quantum information, transition probability, Euclidean distance,
Fubini-study metric, Bhattacharyya coefficients, conjugate variable,
signal/sensor fusion, signal and image segmentation.
</summary>
    <author>
      <name>Michael Nölle</name>
    </author>
    <author>
      <name>Martin Suda</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">22 pages, 2 tables, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1108.5720v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1108.5720v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
    <category term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1109.0090v1</id>
    <updated>2011-09-01T04:47:08Z</updated>
    <published>2011-09-01T04:47:08Z</published>
    <title>An Efficient Codebook Initialization Approach for LBG Algorithm</title>
    <summary>  In VQ based image compression technique has three major steps namely (i)
Codebook Design, (ii) VQ Encoding Process and (iii) VQ Decoding Process. The
performance of VQ based image compression technique depends upon the
constructed codebook. A widely used technique for VQ codebook design is the
Linde-Buzo-Gray (LBG) algorithm. However the performance of the standard LBG
algorithm is highly dependent on the choice of the initial codebook. In this
paper, we have proposed a simple and very effective approach for codebook
initialization for LBG algorithm. The simulation results show that the proposed
scheme is computationally efficient and gives expected performance as compared
to the standard LBG algorithm.
</summary>
    <author>
      <name>Arup Kumar Pal</name>
    </author>
    <author>
      <name>Anup Sar</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5121/ijcsea.2011.1407</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5121/ijcsea.2011.1407" rel="related"/>
    <link href="http://arxiv.org/abs/1109.0090v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1109.0090v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1109.1068v1</id>
    <updated>2011-09-06T05:34:28Z</updated>
    <published>2011-09-06T05:34:28Z</published>
    <title>An Automatic Clustering Technique for Optimal Clusters</title>
    <summary>  This paper proposes a simple, automatic and efficient clustering algorithm,
namely, Automatic Merging for Optimal Clusters (AMOC) which aims to generate
nearly optimal clusters for the given datasets automatically. The AMOC is an
extension to standard k-means with a two phase iterative procedure combining
certain validation techniques in order to find optimal clusters with automation
of merging of clusters. Experiments on both synthetic and real data have proved
that the proposed algorithm finds nearly optimal clustering structures in terms
of number of clusters, compactness and separation.
</summary>
    <author>
      <name>K. Karteeka Pavan</name>
    </author>
    <author>
      <name>Allam Appa Rao</name>
    </author>
    <author>
      <name>A. V. Dattatreya Rao</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5121/ijcsea.2011.1412</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5121/ijcsea.2011.1412" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 5 figures, 2 tables</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International journal of Computer Sciene Engineering and
  Applications, Vol., No.4, 2011, pp 133-144</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1109.1068v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1109.1068v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62H30" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.5.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1109.3126v1</id>
    <updated>2011-09-14T16:24:26Z</updated>
    <published>2011-09-14T16:24:26Z</published>
    <title>A Non-Iterative Solution to the Four-Point Three-Views Pose Problem in
  Case of Collinear Cameras</title>
    <summary>  We give a non-iterative solution to a particular case of the four-point
three-views pose problem when three camera centers are collinear. Using the
well-known Cayley representation of orthogonal matrices, we derive from the
epipolar constraints a system of three polynomial equations in three variables.
The eliminant of that system is a multiple of a 36th degree univariate
polynomial. The true (unique) solution to the problem can be expressed in terms
of one of real roots of that polynomial. Experiments on synthetic data confirm
that our method is robust enough even in case of planar configurations.
</summary>
    <author>
      <name>Evgeniy Martyushev</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1109.3126v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1109.3126v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1109.3850v1</id>
    <updated>2011-09-18T07:48:36Z</updated>
    <published>2011-09-18T07:48:36Z</published>
    <title>On the digital homology groups of digital images</title>
    <summary>  In this article we study the digital homology groups of digital images which
are based on the singular homology groups of topological spaces in algebraic
topology. Specifically, we define a digitally standard $n$-simplex, a digitally
singular $n$-simplex, and the digital homology groups of digital images with
$k$-adjacency relations. We then construct a covariant functor from a category
of digital images and digitally continuous functions to the one of abelian
groups and group homomorphisms, and investigate some fundamental and
interesting properties of digital homology groups of digital images, such as
the digital version of the dimension axiom which is one of the
Eilenberg-Steenrod axioms.
</summary>
    <author>
      <name>Dae-Woong Lee</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1109.3850v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1109.3850v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1109.4683v1</id>
    <updated>2011-09-22T00:55:32Z</updated>
    <published>2011-09-22T00:55:32Z</published>
    <title>Detachable Object Detection: Segmentation and Depth Ordering From
  Short-Baseline Video</title>
    <summary>  We describe an approach for segmenting an image into regions that correspond
to surfaces in the scene that are partially surrounded by the medium. It
integrates both appearance and motion statistics into a cost functional, that
is seeded with occluded regions and minimized efficiently by solving a linear
programming problem. Where a short observation time is insufficient to
determine whether the object is detachable, the results of the minimization can
be used to seed a more costly optimization based on a longer sequence of video
data. The result is an entirely unsupervised scheme to detect and segment an
arbitrary and unknown number of objects. We test our scheme to highlight the
potential, as well as limitations, of our approach.
</summary>
    <author>
      <name>Alper Ayvaci</name>
    </author>
    <author>
      <name>Stefano Soatto</name>
    </author>
    <link href="http://arxiv.org/abs/1109.4683v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1109.4683v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1109.4744v1</id>
    <updated>2011-09-22T09:26:23Z</updated>
    <published>2011-09-22T09:26:23Z</published>
    <title>Probabilistic prototype models for attributed graphs</title>
    <summary>  This contribution proposes a new approach towards developing a class of
probabilistic methods for classifying attributed graphs. The key concept is
random attributed graph, which is defined as an attributed graph whose nodes
and edges are annotated by random variables. Every node/edge has two random
processes associated with it- occurence probability and the probability
distribution over the attribute values. These are estimated within the maximum
likelihood framework. The likelihood of a random attributed graph to generate
an outcome graph is used as a feature for classification. The proposed approach
is fast and robust to noise.
</summary>
    <author>
      <name>S. Deepak Srinivasan</name>
    </author>
    <author>
      <name>Klaus Obermayer</name>
    </author>
    <link href="http://arxiv.org/abs/1109.4744v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1109.4744v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1110.0872v1</id>
    <updated>2011-10-04T23:58:55Z</updated>
    <published>2011-10-04T23:58:55Z</published>
    <title>Non-Gaussian Scale Space Filtering with 2 by 2 Matrix of Linear Filters</title>
    <summary>  Construction of a scale space with a convolution filter has been studied
extensively in the past. It has been proven that the only convolution kernel
that satisfies the scale space requirements is a Gaussian type. In this paper,
we consider a matrix of convolution filters introduced in [1] as a building
kernel for a scale space, and shows that we can construct a non-Gaussian scale
space with a $2\times 2$ matrix of filters. The paper derives sufficient
conditions for the matrix of filters for being a scale space kernel, and
present some numerical demonstrations.
</summary>
    <author>
      <name>Toshiro Kubota</name>
    </author>
    <link href="http://arxiv.org/abs/1110.0872v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1110.0872v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1110.3194v1</id>
    <updated>2011-10-14T13:02:36Z</updated>
    <published>2011-10-14T13:02:36Z</published>
    <title>Controlled Total Variation regularization for inverse problems</title>
    <summary>  This paper provides a new algorithm for solving inverse problems, based on
the minimization of the $L^2$ norm and on the control of the Total Variation.
It consists in relaxing the role of the Total Variation in the classical Total
Variation minimization approach, which permits us to get better approximation
to the inverse problems. The numerical results on the deconvolution problem
show that our method outperforms some previous ones.
</summary>
    <author>
      <name>Qiyu Jin</name>
    </author>
    <author>
      <name>Ion Grama</name>
    </author>
    <author>
      <name>Quansheng Liu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 10 figures and 2 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1110.3194v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1110.3194v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1110.5404v1</id>
    <updated>2011-10-25T03:54:51Z</updated>
    <published>2011-10-25T03:54:51Z</published>
    <title>Face Recognition Based on SVM and 2DPCA</title>
    <summary>  The paper will present a novel approach for solving face recognition problem.
Our method combines 2D Principal Component Analysis (2DPCA), one of the
prominent methods for extracting feature vectors, and Support Vector Machine
(SVM), the most powerful discriminative method for classification. Experiments
based on proposed method have been conducted on two public data sets FERET and
AT&amp;T; the results show that the proposed method could improve the
classification rates.
</summary>
    <author>
      <name>Thai Hoang Le</name>
    </author>
    <author>
      <name>Len Bui</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 7 figures, 2 tables, International Journal of Signal
  Processing, Image Processing and Pattern Recognition Vol. 4, No. 3,
  September, 2011</arxiv:comment>
    <link href="http://arxiv.org/abs/1110.5404v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1110.5404v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.0885v1</id>
    <updated>2011-11-03T15:46:47Z</updated>
    <published>2011-11-03T15:46:47Z</published>
    <title>Graph Regularized Nonnegative Matrix Factorization for Hyperspectral
  Data Unmixing</title>
    <summary>  Spectral unmixing is an important tool in hyperspectral data analysis for
estimating endmembers and abundance fractions in a mixed pixel. This paper
examines the applicability of a recently developed algorithm called graph
regularized nonnegative matrix factorization (GNMF) for this aim. The proposed
approach exploits the intrinsic geometrical structure of the data besides
considering positivity and full additivity constraints. Simulated data based on
the measured spectral signatures, is used for evaluating the proposed
algorithm. Results in terms of abundance angle distance (AAD) and spectral
angle distance (SAD) show that this method can effectively unmix hyperspectral
data.
</summary>
    <author>
      <name>Roozbeh Rajabi</name>
    </author>
    <author>
      <name>Mahdi Khodadadzadeh</name>
    </author>
    <author>
      <name>Hassan Ghassemian</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, conference</arxiv:comment>
    <link href="http://arxiv.org/abs/1111.0885v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.0885v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.1014v1</id>
    <updated>2011-11-03T23:50:36Z</updated>
    <published>2011-11-03T23:50:36Z</published>
    <title>Sparsity and Robustness in Face Recognition</title>
    <summary>  This report concerns the use of techniques for sparse signal representation
and sparse error correction for automatic face recognition. Much of the recent
interest in these techniques comes from the paper "Robust Face Recognition via
Sparse Representation" by Wright et al. (2009), which showed how, under certain
technical conditions, one could cast the face recognition problem as one of
seeking a sparse representation of a given input face image in terms of a
"dictionary" of training images and images of individual pixels. In this
report, we have attempted to clarify some frequently encountered questions
about this work and particularly, on the validity of using sparse
representation techniques for face recognition.
</summary>
    <author>
      <name>John Wright</name>
    </author>
    <author>
      <name>Arvind Ganesh</name>
    </author>
    <author>
      <name>Allen Yang</name>
    </author>
    <author>
      <name>Zihan Zhou</name>
    </author>
    <author>
      <name>Yi Ma</name>
    </author>
    <link href="http://arxiv.org/abs/1111.1014v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.1014v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.1311v1</id>
    <updated>2011-11-05T14:09:05Z</updated>
    <published>2011-11-05T14:09:05Z</published>
    <title>Covariant fractional extension of the modified Laplace-operator used in
  3D-shape recovery</title>
    <summary>  Extending the Liouville-Caputo definition of a fractional derivative to a
nonlocal covariant generalization of arbitrary bound operators acting on
multidimensional Riemannian spaces an appropriate approach for the 3D shape
recovery of aperture afflicted 2D slide sequences is proposed. We demonstrate,
that the step from a local to a nonlocal algorithm yields an order of magnitude
in accuracy and by using the specific fractional approach an additional factor
2 in accuracy of the derived results.
</summary>
    <author>
      <name>Richard Herrmann</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.2478/s13540-012-0024-1</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.2478/s13540-012-0024-1" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 3 figures, draft for proceedings IFAC FDA12 in Nanjing,
  China</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Fract. Calc. Appl. Anal. (2012) Vol. 15 Num. 2, 332--343</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1111.1311v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.1311v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.2391v1</id>
    <updated>2011-11-10T04:28:08Z</updated>
    <published>2011-11-10T04:28:08Z</published>
    <title>A Novel Approach to Texture classification using statistical feature</title>
    <summary>  Texture is an important spatial feature which plays a vital role in content
based image retrieval. The enormous growth of the internet and the wide use of
digital data have increased the need for both efficient image database creation
and retrieval procedure. This paper describes a new approach for texture
classification by combining statistical texture features of Local Binary
Pattern and Texture spectrum. Since most significant information of a texture
often appears in the high frequency channels, the features are extracted by the
computation of LBP and Texture Spectrum and Legendre Moments. Euclidean
distance is used for similarity measurement. The experimental result shows that
97.77% classification accuracy is obtained by the proposed method.
</summary>
    <author>
      <name>B. Vijayalakshmi</name>
    </author>
    <author>
      <name>V. Subbiah Bharathi</name>
    </author>
    <link href="http://arxiv.org/abs/1111.2391v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.2391v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.3818v1</id>
    <updated>2011-11-16T14:37:07Z</updated>
    <published>2011-11-16T14:37:07Z</published>
    <title>Good Pairs of Adjacency Relations in Arbitrary Dimensions</title>
    <summary>  In this text we show, that the notion of a "good pair" that was introduced in
the paper "Digital Manifolds and the Theorem of Jordan-Brouwer" has actually
known models. We will show, how to choose cubical adjacencies, the
generalizations of the well known 4- and 8-neighborhood to arbitrary
dimensions, in order to find good pairs. Furthermore, we give another proof for
the well known fact that the Khalimsky-topology implies good pairs. The outcome
is consistent with the known theory as presented by T.Y. Kong, A. Rosenfeld,
G.T. Herman and M. Khachan et.al and gives new insights in higher dimensions.
</summary>
    <author>
      <name>Martin Hünniger</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">29 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1111.3818v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.3818v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.4290v1</id>
    <updated>2011-11-18T06:34:07Z</updated>
    <published>2011-11-18T06:34:07Z</published>
    <title>A Single Euler Number Feature for Multi-font Multi-size Kannada Numeral
  Recognition</title>
    <summary>  In this paper a novel approach is proposed based on single Euler number
feature which is free from thinning and size normalization for multi-font and
multi-size Kannada numeral recognition system. A nearest neighbor
classification is used for classification of Kannada numerals by considering
the Euclidian distance. A total 1500 numeral images with different font sizes
between (10..84) are tested for algorithm efficiency and the overall the
classification accuracy is found to be 99.00% .The said method is thinning
free, fast, and showed encouraging results on varying font styles and sizes of
Kannada numerals.
</summary>
    <author>
      <name>B. V. Dhandra</name>
    </author>
    <author>
      <name>R. G. Benne</name>
    </author>
    <author>
      <name>Mallikarjun Hangarge</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 1 figure, 5 tables, "Recent Trends in Information
  Technology(RTIT-2009)"</arxiv:comment>
    <link href="http://arxiv.org/abs/1111.4290v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.4290v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.4654v1</id>
    <updated>2011-11-20T17:41:01Z</updated>
    <published>2011-11-20T17:41:01Z</published>
    <title>A self-portrait of young Leonardo</title>
    <summary>  One of the most famous drawings by Leonardo da Vinci is a self-portrait in
red chalk, where he looks quite old. In fact, there is a sketch in one of his
notebooks, partially covered by written notes, that can be a self-portrait of
the artist when he was young. The use of image processing, to remove the
handwritten text and improve the image, allows a comparison of the two
portraits.
</summary>
    <author>
      <name>Amelia Carolina Sparavigna</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Image processing, digital restoration, Leonardo da Vinci</arxiv:comment>
    <link href="http://arxiv.org/abs/1111.4654v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.4654v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.6276v2</id>
    <updated>2011-11-29T01:51:23Z</updated>
    <published>2011-11-27T17:09:17Z</published>
    <title>Compressed sensing of astronomical images: orthogonal wavelets domains</title>
    <summary>  A simple approach for orthogonal wavelets in compressed sensing (CS)
applications is presented. We compare efficient algorithm for different
orthogonal wavelet measurement matrices in CS for image processing from scanned
photographic plates (SPP). Some important characteristics were obtained for
astronomical image processing of SPP. The best orthogonal wavelet choice for
measurement matrix construction in CS for image compression of images of SPP is
given. The image quality measure for linear and nonlinear image compression
method is defined.
</summary>
    <author>
      <name>Vasil Kolev</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, The ACM proceedings of CompSysTech 2011</arxiv:comment>
    <link href="http://arxiv.org/abs/1111.6276v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.6276v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.IM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.data-an" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1112.1120v1</id>
    <updated>2011-12-05T23:25:07Z</updated>
    <published>2011-12-05T23:25:07Z</published>
    <title>Classification with Invariant Scattering Representations</title>
    <summary>  A scattering transform defines a signal representation which is invariant to
translations and Lipschitz continuous relatively to deformations. It is
implemented with a non-linear convolution network that iterates over wavelet
and modulus operators. Lipschitz continuity locally linearizes deformations.
Complex classes of signals and textures can be modeled with low-dimensional
affine spaces, computed with a PCA in the scattering domain. Classification is
performed with a penalized model selection. State of the art results are
obtained for handwritten digit recognition over small training sets, and for
texture classification.
</summary>
    <author>
      <name>Joan Bruna</name>
    </author>
    <author>
      <name>Stéphane Mallat</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 2 figures; IVMSP Workshop, 2011 IEEE 10th</arxiv:comment>
    <link href="http://arxiv.org/abs/1112.1120v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1112.1120v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.FA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1112.4060v1</id>
    <updated>2011-12-17T14:50:50Z</updated>
    <published>2011-12-17T14:50:50Z</published>
    <title>A real time vehicles detection algorithm for vision based sensors</title>
    <summary>  A vehicle detection plays an important role in the traffic control at
signalised intersections. This paper introduces a vision-based algorithm for
vehicles presence recognition in detection zones. The algorithm uses linguistic
variables to evaluate local attributes of an input image. The image attributes
are categorised as vehicle, background or unknown features. Experimental
results on complex traffic scenes show that the proposed algorithm is effective
for a real-time vehicles detection.
</summary>
    <author>
      <name>Bartłomiej Płaczek</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-642-15907-7_26</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-642-15907-7_26" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The final publication is available at http://www.springerlink.com</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">P{\l}aczek B., A real time vehicles detection algorithm for vision
  based sensors, Lecture Notes in Computer Science 6375, Springer-Verlag,
  Berlin Heidelberg, 2010, pp. 211-218</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1112.4060v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1112.4060v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1112.6291v1</id>
    <updated>2011-12-29T12:34:43Z</updated>
    <published>2011-12-29T12:34:43Z</published>
    <title>Descriptor learning for omnidirectional image matching</title>
    <summary>  Feature matching in omnidirectional vision systems is a challenging problem,
mainly because complicated optical systems make the theoretical modelling of
invariance and construction of invariant feature descriptors hard or even
impossible. In this paper, we propose learning invariant descriptors using a
training set of similar and dissimilar descriptor pairs. We use the
similarity-preserving hashing framework, in which we are trying to map the
descriptor data to the Hamming space preserving the descriptor similarity on
the training set. A neural network is used to solve the underlying optimization
problem. Our approach outperforms not only straightforward descriptor matching,
but also state-of-the-art similarity-preserving hashing methods.
</summary>
    <author>
      <name>Jonathan Masci</name>
    </author>
    <author>
      <name>Davide Migliore</name>
    </author>
    <author>
      <name>Michael M. Bronstein</name>
    </author>
    <author>
      <name>Jürgen Schmidhuber</name>
    </author>
    <link href="http://arxiv.org/abs/1112.6291v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1112.6291v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1201.1417v1</id>
    <updated>2011-11-29T06:24:33Z</updated>
    <published>2011-11-29T06:24:33Z</published>
    <title>Picture Collage with Genetic Algorithm and Stereo vision</title>
    <summary>  In this paper, a salient region extraction method for creating picture
collage based on stereo vision is proposed. Picture collage is a kind of visual
image summary to arrange all input images on a given canvas, allowing overlay,
to maximize visible visual information. The salient regions of each image are
firstly extracted and represented as a depth map. The output picture collage
shows as many visible salient regions (without being overlaid by others) from
all images as possible. A very efficient Genetic algorithm is used here for the
optimization. The experimental results showed the superior performance of the
proposed method.
</summary>
    <author>
      <name>Hesam Ekhtiyar</name>
    </author>
    <author>
      <name>Mahdi Sheida</name>
    </author>
    <author>
      <name>Mahmood Amintoosi</name>
    </author>
    <link href="http://arxiv.org/abs/1201.1417v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1201.1417v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1201.2050v1</id>
    <updated>2012-01-10T13:41:56Z</updated>
    <published>2012-01-10T13:41:56Z</published>
    <title>Adaptive Noise Reduction Scheme for Salt and Pepper</title>
    <summary>  In this paper, a new adaptive noise reduction scheme for images corrupted by
impulse noise is presented. The proposed scheme efficiently identifies and
reduces salt and pepper noise. MAG (Mean Absolute Gradient) is used to identify
pixels which are most likely corrupted by salt and pepper noise that are
candidates for further median based noise reduction processing. Directional
filtering is then applied after noise reduction to achieve a good tradeoff
between detail preservation and noise removal. The proposed scheme can remove
salt and pepper noise with noise density as high as 90% and produce better
result in terms of qualitative and quantitative measures of images.
</summary>
    <author>
      <name>Tina Gebreyohannes</name>
    </author>
    <author>
      <name>Dong-Yoon Kim</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1201.2050v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1201.2050v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1201.3109v1</id>
    <updated>2012-01-15T17:42:07Z</updated>
    <published>2012-01-15T17:42:07Z</published>
    <title>Automatic system for counting cells with elliptical shape</title>
    <summary>  This paper presents a new method for automatic quantification of ellipse-like
cells in images, an important and challenging problem that has been studied by
the computer vision community. The proposed method can be described by two main
steps. Initially, image segmentation based on the k-means algorithm is
performed to separate different types of cells from the background. Then, a
robust and efficient strategy is performed on the blob contour for touching
cells splitting. Due to the contour processing, the method achieves excellent
results of detection compared to manual detection performed by specialists.
</summary>
    <author>
      <name>Wesley Nunes Gonçalves</name>
    </author>
    <author>
      <name>Odemir Martinez Bruno</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Learning and NonLinear Models, Volume 9, Issue 1, 2011</arxiv:comment>
    <link href="http://arxiv.org/abs/1201.3109v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1201.3109v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1201.3803v1</id>
    <updated>2012-01-16T07:33:56Z</updated>
    <published>2012-01-16T07:33:56Z</published>
    <title>Image Labeling and Segmentation using Hierarchical Conditional Random
  Field Model</title>
    <summary>  The use of hierarchical Conditional Random Field model deal with the problem
of labeling images . At the time of labeling a new image, selection of the
nearest cluster and using the related CRF model to label this image. When one
give input image, one first use the CRF model to get initial pixel labels then
finding the cluster with most similar images. Then at last relabeling the input
image by the CRF model associated with this cluster. This paper presents a
approach to label and segment specific image having correct information.
</summary>
    <author>
      <name>Manoj K. Vairalkar</name>
    </author>
    <author>
      <name>Sonali. Nimbhorkar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">08 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1201.3803v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1201.3803v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.0549v1</id>
    <updated>2012-01-29T19:19:33Z</updated>
    <published>2012-01-29T19:19:33Z</published>
    <title>Comparing Background Subtraction Algorithms and Method of Car Counting</title>
    <summary>  In this paper, we compare various image background subtraction algorithms
with the ground truth of cars counted. We have given a sample of thousand
images, which are the snap shots of current traffic as records at various
intersections and highways. We have also counted an approximate number of cars
that are visible in these images. In order to ascertain the accuracy of
algorithms to be used for the processing of million images, we compare them on
many metrics that includes (i) Scalability (ii) Accuracy (iii) Processing time.
</summary>
    <author>
      <name>Gautam S. Thakur</name>
    </author>
    <author>
      <name>Mohsen Ali</name>
    </author>
    <author>
      <name>Pan Hui</name>
    </author>
    <author>
      <name>Ahmed Helmy</name>
    </author>
    <link href="http://arxiv.org/abs/1202.0549v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.0549v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.1585v1</id>
    <updated>2012-02-08T03:07:39Z</updated>
    <published>2012-02-08T03:07:39Z</published>
    <title>Robust seed selection algorithm for k-means type algorithms</title>
    <summary>  Selection of initial seeds greatly affects the quality of the clusters and in
k-means type algorithms. Most of the seed selection methods result different
results in different independent runs. We propose a single, optimal, outlier
insensitive seed selection algorithm for k-means type algorithms as extension
to k-means++. The experimental results on synthetic, real and on microarray
data sets demonstrated that effectiveness of the new algorithm in producing the
clustering results
</summary>
    <author>
      <name>K. Karteeka Pavan</name>
    </author>
    <author>
      <name>Allam Appa Rao</name>
    </author>
    <author>
      <name>A. V. Dattatreya Rao</name>
    </author>
    <author>
      <name>G. R. Sridhar</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5121/ijcsit.2011.3513</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5121/ijcsit.2011.3513" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages, 5 tables, 9figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Science and Technology (IJCSIT),
  Vol 3, No 5, Oct 2011 pp 147-163</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1202.1585v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.1585v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="62H30" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.5.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.2528v1</id>
    <updated>2012-02-12T13:40:11Z</updated>
    <published>2012-02-12T13:40:11Z</published>
    <title>Using Covariance Matrices as Feature Descriptors for Vehicle Detection
  from a Fixed Camera</title>
    <summary>  A method is developed to distinguish between cars and trucks present in a
video feed of a highway. The method builds upon previously done work using
covariance matrices as an accurate descriptor for regions. Background
subtraction and other similar proven image processing techniques are used to
identify the regions where the vehicles are most likely to be, and a distance
metric comparing the vehicle inside the region to a fixed library of vehicles
is used to determine the class of vehicle.
</summary>
    <author>
      <name>Kevin Mader</name>
    </author>
    <author>
      <name>Gil Reese</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Written as part of the requirements for the SC/EC520 course in
  Digital Image Processing at Boston University</arxiv:comment>
    <link href="http://arxiv.org/abs/1202.2528v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.2528v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.3884v1</id>
    <updated>2012-02-17T11:41:28Z</updated>
    <published>2012-02-17T11:41:28Z</published>
    <title>A feature extraction technique based on character geometry for character
  recognition</title>
    <summary>  This paper describes a geometry based technique for feature extraction
applicable to segmentation-based word recognition systems. The proposed system
extracts the geometric features of the character contour. This features are
based on the basic line types that forms the character skeleton. The system
gives a feature vector as its output. The feature vectors so generated from a
training set, were then used to train a pattern recognition engine based on
Neural Networks so that the system can be benchmarked.
</summary>
    <author>
      <name>Dinesh Dileep Gaurav</name>
    </author>
    <author>
      <name>Renu Ramesh</name>
    </author>
    <link href="http://arxiv.org/abs/1202.3884v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.3884v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.4495v1</id>
    <updated>2012-02-20T23:48:38Z</updated>
    <published>2012-02-20T23:48:38Z</published>
    <title>Stochastic-Based Pattern Recognition Analysis</title>
    <summary>  In this work we review the basic principles of stochastic logic and propose
its application to probabilistic-based pattern-recognition analysis. The
proposed technique is intrinsically a parallel comparison of input data to
various pre-stored categories using Bayesian techniques. We design smart
pulse-based stochastic-logic blocks to provide an efficient pattern recognition
analysis. The proposed rchitecture is applied to a specific navigation problem.
The resulting system is orders of magnitude faster than processor-based
solutions.
</summary>
    <author>
      <name>V. Canals</name>
    </author>
    <author>
      <name>A. Morro</name>
    </author>
    <author>
      <name>J. L. Rosselló</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.patrec.2010.07.008</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.patrec.2010.07.008" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Published in Pattern Recognition Letters in 2010</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1202.4495v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.4495v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1203.0265v1</id>
    <updated>2012-02-29T17:57:12Z</updated>
    <published>2012-02-29T17:57:12Z</published>
    <title>Image Fusion and Re-Modified SPIHT for Fused Image</title>
    <summary>  This paper presents the Discrete Wavelet based fusion techniques for
combining perceptually important image features. SPIHT (Set Partitioning in
Hierarchical Trees) algorithm is an efficient method for lossy and lossless
coding of fused image. This paper presents some modifications on the SPIHT
algorithm. It is based on the idea of insignificant correlation of wavelet
coefficient among the medium and high frequency sub bands. In RE-MSPIHT
algorithm, wavelet coefficients are scaled prior to SPIHT coding based on the
sub band importance, with the goal of minimizing the MSE.
</summary>
    <author>
      <name>S. Chitra</name>
    </author>
    <author>
      <name>J. B. Bhattacharjee</name>
    </author>
    <author>
      <name>B. Thilakavathi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Ann. Univ. Tibiscus Comp. Sci. Series VII/2 (2009), 143-158</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1203.0265v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1203.0265v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1203.1513v2</id>
    <updated>2012-03-08T10:29:32Z</updated>
    <published>2012-03-05T17:12:42Z</published>
    <title>Invariant Scattering Convolution Networks</title>
    <summary>  A wavelet scattering network computes a translation invariant image
representation, which is stable to deformations and preserves high frequency
information for classification. It cascades wavelet transform convolutions with
non-linear modulus and averaging operators. The first network layer outputs
SIFT-type descriptors whereas the next layers provide complementary invariant
information which improves classification. The mathematical analysis of wavelet
scattering networks explains important properties of deep convolution networks
for classification.
  A scattering representation of stationary processes incorporates higher order
moments and can thus discriminate textures having the same Fourier power
spectrum. State of the art classification results are obtained for handwritten
digits and texture discrimination, using a Gaussian kernel SVM and a generative
PCA classifier.
</summary>
    <author>
      <name>Joan Bruna</name>
    </author>
    <author>
      <name>Stéphane Mallat</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages double column, 9 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1203.1513v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1203.1513v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1203.1765v1</id>
    <updated>2012-03-08T12:07:27Z</updated>
    <published>2012-03-08T12:07:27Z</published>
    <title>A comparative evaluation of two algorithms of detection of masses on
  mammograms</title>
    <summary>  In this paper, we implement and carry out the comparison of two methods of
computer-aided-detection of masses on mammograms. The two algorithms basically
consist of 3 steps each: segmentation, binarization and noise suppression using
different techniques for each step. A database of 60 images was used to compare
the performance of the two algorithms in terms of general detection efficiency,
conservation of size and shape of detected masses.
</summary>
    <author>
      <name>Guillaume Kom</name>
    </author>
    <author>
      <name>Alain Tiedeu</name>
    </author>
    <author>
      <name>Martin Kom</name>
    </author>
    <author>
      <name>John Ngundam</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5121/sipij.2012.3102</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5121/sipij.2012.3102" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 5 figures, 1 table, Vol.3, No.1, February 2012,pp19-27;
  Signal &amp; Image Processing : An International Journal (SIPIJ),2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1203.1765v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1203.1765v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1203.3114v1</id>
    <updated>2012-03-14T15:31:16Z</updated>
    <published>2012-03-14T15:31:16Z</published>
    <title>Integrated three-dimensional reconstruction using reflectance fields</title>
    <summary>  A method to obtain three-dimensional data of real-world objects by
integrating their material properties is presented. The material properties are
defined by capturing the Reflectance Fields of the real-world objects. It is
shown, unlike conventional reconstruction methods, the method is able to use
the reflectance information to recover surface depth for objects having a
non-Lambertian surface reflectance. It is, for recovering 3D data of objects
exhibiting an anisotropic BRDF with an error less than 0.3%.
</summary>
    <author>
      <name>Maria-Luisa Sosas</name>
    </author>
    <author>
      <name>Miguel-Octavio Arias</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 3 figures; Published in IJCSI Journal, Volume 9, Issue 1,
  No. 3, January 2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1203.3114v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1203.3114v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1203.3230v1</id>
    <updated>2012-03-14T22:46:29Z</updated>
    <published>2012-03-14T22:46:29Z</published>
    <title>Reconstruction error in a motion capture system</title>
    <summary>  Marker-based motion capture (MoCap) systems can be composed by several dozens
of cameras with the purpose of reconstructing the trajectories of hundreds of
targets. With a large amount of cameras it becomes interesting to determine the
optimal reconstruction strategy. For such aim it is of fundamental importance
to understand the information provided by different camera measurements and how
they are combined, i.e. how the reconstruction error changes by considering
different cameras. In this work, first, an approximation of the reconstruction
error variance is derived. The results obtained in some simulations suggest
that the proposed strategy allows to obtain a good approximation of the real
error variance with significant reduction of the computational time.
</summary>
    <author>
      <name>Andrea Masiero</name>
    </author>
    <author>
      <name>Angelo Cenedese</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1203.3230v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1203.3230v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.1198v1</id>
    <updated>2012-04-05T12:28:11Z</updated>
    <published>2012-04-05T12:28:11Z</published>
    <title>A Complete Workflow for Development of Bangla OCR</title>
    <summary>  Developing a Bangla OCR requires bunch of algorithm and methods. There were
many effort went on for developing a Bangla OCR. But all of them failed to
provide an error free Bangla OCR. Each of them has some lacking. We discussed
about the problem scope of currently existing Bangla OCR's. In this paper, we
present the basic steps required for developing a Bangla OCR and a complete
workflow for development of a Bangla OCR with mentioning all the possible
algorithms required.
</summary>
    <author>
      <name>Farjana Yeasmin Omee</name>
    </author>
    <author>
      <name>Shiam Shabbir Himel</name>
    </author>
    <author>
      <name>Md. Abu Naser Bikas</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Applications, Volume 21, No.9,
  May 2011</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1204.1198v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.1198v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.1611v1</id>
    <updated>2012-04-07T08:17:40Z</updated>
    <published>2012-04-07T08:17:40Z</published>
    <title>Vision-based Human Gender Recognition: A Survey</title>
    <summary>  Gender is an important demographic attribute of people. This paper provides a
survey of human gender recognition in computer vision. A review of approaches
exploiting information from face and whole body (either from a still image or
gait sequence) is presented. We highlight the challenges faced and survey the
representative methods of these approaches. Based on the results, good
performance have been achieved for datasets captured under controlled
environments, but there is still much work that can be done to improve the
robustness of gender recognition under real-life environments.
</summary>
    <author>
      <name>Choon Boon Ng</name>
    </author>
    <author>
      <name>Yong Haur Tay</name>
    </author>
    <author>
      <name>Bok Min Goi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">30 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1204.1611v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.1611v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.1811v1</id>
    <updated>2012-04-09T06:44:42Z</updated>
    <published>2012-04-09T06:44:42Z</published>
    <title>Skin-color based videos categorization</title>
    <summary>  On dedicated websites, people can upload videos and share it with the rest of
the world. Currently these videos are cat- egorized manually by the help of the
user community. In this paper, we propose a combination of color spaces with
the Bayesian network approach for robust detection of skin color followed by an
automated video categorization. Exper- imental results show that our method can
achieve satisfactory performance for categorizing videos based on skin color.
</summary>
    <author>
      <name>Rehanullah Khan</name>
    </author>
    <author>
      <name>Asad Maqsood</name>
    </author>
    <author>
      <name>Zeeshan Khan</name>
    </author>
    <author>
      <name>Muhammad Ishaq</name>
    </author>
    <author>
      <name>Arsalan Arif</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Science Issues (IJCSI), Volume 9,
  Issue 1, No 3, January 2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1204.1811v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.1811v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.2062v1</id>
    <updated>2012-04-10T07:10:06Z</updated>
    <published>2012-04-10T07:10:06Z</published>
    <title>SVD-EBP Algorithm for Iris Pattern Recognition</title>
    <summary>  This paper proposes a neural network approach based on Error Back Propagation
(EBP) for classification of different eye images. To reduce the complexity of
layered neural network the dimensions of input vectors are optimized using
Singular Value Decomposition (SVD). The main of this work is to provide for
best method for feature extraction and classification. The details of this
combined system named as SVD-EBP system, and results thereof are presented in
this paper.
  Keywords- Singular value decomposition(SVD), Error back Propagation(EBP).
</summary>
    <author>
      <name>Babasaheb G. Patil</name>
    </author>
    <author>
      <name>Shaila Subbaraman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Dec2011-volume2.Issue 12 (IJACSA)</arxiv:comment>
    <link href="http://arxiv.org/abs/1204.2062v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.2062v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.2741v1</id>
    <updated>2012-04-12T14:47:41Z</updated>
    <published>2012-04-12T14:47:41Z</published>
    <title>Simultaneous Object Detection, Tracking, and Event Recognition</title>
    <summary>  The common internal structure and algorithmic organization of object
detection, detection-based tracking, and event recognition facilitates a
general approach to integrating these three components. This supports
multidirectional information flow between these components allowing object
detection to influence tracking and event recognition and event recognition to
influence tracking and object detection. The performance of the combination can
exceed the performance of the components in isolation. This can be done with
linear asymptotic complexity.
</summary>
    <author>
      <name>Andrei Barbu</name>
    </author>
    <author>
      <name>Aaron Michaux</name>
    </author>
    <author>
      <name>Siddharth Narayanaswamy</name>
    </author>
    <author>
      <name>Jeffrey Mark Siskind</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Advances in Cognitive Systems, Vol. 2, pp. 203-220, 2012</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1204.2741v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.2741v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.3618v1</id>
    <updated>2012-04-13T20:16:11Z</updated>
    <published>2012-04-13T20:16:11Z</published>
    <title>Compensating Interpolation Distortion by Using New Optimized Modular
  Method</title>
    <summary>  A modular method was suggested before to recover a band limited signal from
the sample and hold and linearly interpolated (or, in general, an
nth-order-hold) version of the regular samples. In this paper a novel approach
for compensating the distortion of any interpolation based on modular method
has been proposed. In this method the performance of the modular method is
optimized by adding only some simply calculated coefficients. This approach
causes drastic improvement in terms of signal-to-noise ratios with fewer
modules compared to the classical modular method. Simulation results clearly
confirm the improvement of the proposed method and also its superior robustness
against additive noise.
</summary>
    <author>
      <name>Mohammad Tofighi</name>
    </author>
    <author>
      <name>Ali Ayremlou</name>
    </author>
    <author>
      <name>Farokh Marvasti</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages. Journal paper</arxiv:comment>
    <link href="http://arxiv.org/abs/1204.3618v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.3618v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.3968v1</id>
    <updated>2012-04-18T03:48:38Z</updated>
    <published>2012-04-18T03:48:38Z</published>
    <title>Convolutional Neural Networks Applied to House Numbers Digit
  Classification</title>
    <summary>  We classify digits of real-world house numbers using convolutional neural
networks (ConvNets). ConvNets are hierarchical feature learning neural networks
whose structure is biologically inspired. Unlike many popular vision approaches
that are hand-designed, ConvNets can automatically learn a unique set of
features optimized for a given task. We augmented the traditional ConvNet
architecture by learning multi-stage features and by using Lp pooling and
establish a new state-of-the-art of 94.85% accuracy on the SVHN dataset (45.2%
error improvement). Furthermore, we analyze the benefits of different pooling
methods and multi-stage features in ConvNets. The source code and a tutorial
are available at eblearn.sf.net.
</summary>
    <author>
      <name>Pierre Sermanet</name>
    </author>
    <author>
      <name>Soumith Chintala</name>
    </author>
    <author>
      <name>Yann LeCun</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 6 figures, 2 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1204.3968v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.3968v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.3999v1</id>
    <updated>2012-05-17T18:15:45Z</updated>
    <published>2012-05-17T18:15:45Z</published>
    <title>Optimal Weights Mixed Filter for Removing Mixture of Gaussian and
  Impulse Noises</title>
    <summary>  According to the character of Gaussian, we modify the Rank-Ordered Absolute
Differences (ROAD) to Rank-Ordered Absolute Differences of mixture of Gaussian
and impulse noises (ROADG). It will be more effective to detect impulse noise
when the impulse is mixed with Gaussian noise. Combining rightly the ROADG with
Optimal Weights Filter (OWF), we obtain a new method to deal with the mixed
noise, called Optimal Weights Mixed Filter (OWMF). The simulation results show
that the method is effective to remove the mixed noise.
</summary>
    <author>
      <name>Qiyu Jin</name>
    </author>
    <author>
      <name>Ion Grama</name>
    </author>
    <author>
      <name>Quansheng Liu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 3 figures and 3 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1205.3999v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.3999v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.4463v2</id>
    <updated>2012-12-30T00:58:09Z</updated>
    <published>2012-05-20T22:07:27Z</published>
    <title>Pilgrims Face Recognition Dataset -- HUFRD</title>
    <summary>  In this work, we define a new pilgrims face recognition dataset, called HUFRD
dataset. The new developed dataset presents various pilgrims' images taken from
outside the Holy Masjid El-Harram in Makkah during the 2011-2012 Hajj and Umrah
seasons. Such dataset will be used to test our developed facial recognition and
detection algorithms, as well as assess in the missing and found recognition
system \cite{crowdsensing}.
</summary>
    <author>
      <name>Salah A. Aly</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 13 images, 1 table of a new HUFRD work</arxiv:comment>
    <link href="http://arxiv.org/abs/1205.4463v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.4463v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.4831v1</id>
    <updated>2012-05-22T08:00:45Z</updated>
    <published>2012-05-22T08:00:45Z</published>
    <title>Gray Level Co-Occurrence Matrices: Generalisation and Some New Features</title>
    <summary>  Gray Level Co-occurrence Matrices (GLCM) are one of the earliest techniques
used for image texture analysis. In this paper we defined a new feature called
trace extracted from the GLCM and its implications in texture analysis are
discussed in the context of Content Based Image Retrieval (CBIR). The
theoretical extension of GLCM to n-dimensional gray scale images are also
discussed. The results indicate that trace features outperform Haralick
features when applied to CBIR.
</summary>
    <author>
      <name>Bino Sebastian V</name>
    </author>
    <author>
      <name>A. Unnikrishnan</name>
    </author>
    <author>
      <name>Kannan Balakrishnan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1205.4831v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.4831v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.0238v1</id>
    <updated>2012-06-01T16:20:41Z</updated>
    <published>2012-06-01T16:20:41Z</published>
    <title>Rapid Feature Extraction for Optical Character Recognition</title>
    <summary>  Feature extraction is one of the fundamental problems of character
recognition. The performance of character recognition system is depends on
proper feature extraction and correct classifier selection. In this article, a
rapid feature extraction method is proposed and named as Celled Projection (CP)
that compute the projection of each section formed through partitioning an
image. The recognition performance of the proposed method is compared with
other widely used feature extraction methods that are intensively studied for
many different scripts in literature. The experiments have been conducted using
Bangla handwritten numerals along with three different well known classifiers
which demonstrate comparable results including 94.12% recognition accuracy
using celled projection.
</summary>
    <author>
      <name>M. Zahid Hossain</name>
    </author>
    <author>
      <name>M. Ashraful Amin</name>
    </author>
    <author>
      <name>Hong Yan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.0238v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.0238v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.5.2; I.7.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.2437v1</id>
    <updated>2012-06-12T04:23:38Z</updated>
    <published>2012-06-12T04:23:38Z</published>
    <title>A Novel Windowing Technique for Efficient Computation of MFCC for
  Speaker Recognition</title>
    <summary>  In this paper, we propose a novel family of windowing technique to compute
Mel Frequency Cepstral Coefficient (MFCC) for automatic speaker recognition
from speech. The proposed method is based on fundamental property of discrete
time Fourier transform (DTFT) related to differentiation in frequency domain.
Classical windowing scheme such as Hamming window is modified to obtain
derivatives of discrete time Fourier transform coefficients. It has been
mathematically shown that the slope and phase of power spectrum are inherently
incorporated in newly computed cepstrum. Speaker recognition systems based on
our proposed family of window functions are shown to attain substantial and
consistent performance improvement over baseline single tapered Hamming window
as well as recently proposed multitaper windowing technique.
</summary>
    <author>
      <name>Md. Sahidullah</name>
    </author>
    <author>
      <name>Goutam Saha</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/LSP.2012.2235067</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/LSP.2012.2235067" rel="related"/>
    <link href="http://arxiv.org/abs/1206.2437v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.2437v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.2807v1</id>
    <updated>2012-06-13T13:49:23Z</updated>
    <published>2012-06-13T13:49:23Z</published>
    <title>An efficient hierarchical graph based image segmentation</title>
    <summary>  Hierarchical image segmentation provides region-oriented scalespace, i.e., a
set of image segmentations at different detail levels in which the
segmentations at finer levels are nested with respect to those at coarser
levels. Most image segmentation algorithms, such as region merging algorithms,
rely on a criterion for merging that does not lead to a hierarchy, and for
which the tuning of the parameters can be difficult. In this work, we propose a
hierarchical graph based image segmentation relying on a criterion popularized
by Felzenzwalb and Huttenlocher. We illustrate with both real and synthetic
images, showing efficiency, ease of use, and robustness of our method.
</summary>
    <author>
      <name>Silvio Jamil F. Guimarães</name>
    </author>
    <author>
      <name>Jean Cousty</name>
    </author>
    <author>
      <name>Yukiko Kenmochi</name>
    </author>
    <author>
      <name>Laurent Najman</name>
    </author>
    <link href="http://arxiv.org/abs/1206.2807v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.2807v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.4609v1</id>
    <updated>2012-06-18T14:45:17Z</updated>
    <published>2012-06-18T14:45:17Z</published>
    <title>On multi-view feature learning</title>
    <summary>  Sparse coding is a common approach to learning local features for object
recognition. Recently, there has been an increasing interest in learning
features from spatio-temporal, binocular, or other multi-observation data,
where the goal is to encode the relationship between images rather than the
content of a single image. We provide an analysis of multi-view feature
learning, which shows that hidden variables encode transformations by detecting
rotation angles in the eigenspaces shared among multiple image warps. Our
analysis helps explain recent experimental results showing that
transformation-specific features emerge when training complex cell models on
videos. Our analysis also shows that transformation-invariant features can
emerge as a by-product of learning representations of transformations.
</summary>
    <author>
      <name>Roland Memisevic</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Frankfurt</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICML2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.4609v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.4609v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.4866v1</id>
    <updated>2012-06-21T13:14:59Z</updated>
    <published>2012-06-21T13:14:59Z</published>
    <title>Portraits of Julius Caesar: a proposal for 3D analysis</title>
    <summary>  Here I suggest the use of a 3D scanning and rendering to create some virtual
copies of ancient artifacts to study and compare them. In particular, this
approach could be interesting for some roman marble busts, two of which are
portraits of Julius Caesar, and the third is a realistic portrait of a man
recently found at Arles, France. The comparison of some images indicates that a
three-dimensional visualization is necessary.
</summary>
    <author>
      <name>Amelia Carolina Sparavigna</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Key-words: Image processing, 3D Scanner, 3D visualization, Ancient
  Rome, Julius Caesar</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.4866v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.4866v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.6437v1</id>
    <updated>2012-06-27T19:59:59Z</updated>
    <published>2012-06-27T19:59:59Z</published>
    <title>Large Scale Variational Bayesian Inference for Structured Scale Mixture
  Models</title>
    <summary>  Natural image statistics exhibit hierarchical dependencies across multiple
scales. Representing such prior knowledge in non-factorial latent tree models
can boost performance of image denoising, inpainting, deconvolution or
reconstruction substantially, beyond standard factorial "sparse" methodology.
We derive a large scale approximate Bayesian inference algorithm for linear
models with non-factorial (latent tree-structured) scale mixture priors.
Experimental results on a range of denoising and inpainting problems
demonstrate substantially improved performance compared to MAP estimation or to
inference with factorial priors.
</summary>
    <author>
      <name>Young Jun Ko</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Ecole Polytechnique Federale de Lausanne</arxiv:affiliation>
    </author>
    <author>
      <name>Matthias Seeger</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Ecole Polytechnique Federale de Lausanne</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.6437v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.6437v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.0805v3</id>
    <updated>2013-03-30T05:25:58Z</updated>
    <published>2012-07-03T14:32:20Z</published>
    <title>Anatomical Structure Segmentation in Liver MRI Images</title>
    <summary>  Segmentation of medical images is a challenging task owing to their
complexity. A standard segmentation problem within Magnetic Resonance Imaging
(MRI) is the task of labeling voxels according to their tissue type. Image
segmentation provides volumetric quantification of liver area and thus helps in
the diagnosis of disorders, such as Hepatitis, Cirrhosis, Jaundice,
Hemochromatosis etc.This work deals with comparison of segmentation by applying
Level Set Method,Fuzzy Level Information C-Means Clustering Algorithm and
Gradient Vector Flow Snake Algorithm.The results are compared using the
parameters such as Number of pixels correctly classified, and percentage of
area segmented.
</summary>
    <author>
      <name>G. Geethu Lakshmi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Withdrawn by author for final modification</arxiv:comment>
    <link href="http://arxiv.org/abs/1207.0805v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.0805v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.1522v1</id>
    <updated>2012-07-06T04:58:52Z</updated>
    <published>2012-07-06T04:58:52Z</published>
    <title>Multimodal similarity-preserving hashing</title>
    <summary>  We introduce an efficient computational framework for hashing data belonging
to multiple modalities into a single representation space where they become
mutually comparable. The proposed approach is based on a novel coupled siamese
neural network architecture and allows unified treatment of intra- and
inter-modality similarity learning. Unlike existing cross-modality similarity
learning approaches, our hashing functions are not limited to binarized linear
projections and can assume arbitrarily complex forms. We show experimentally
that our method significantly outperforms state-of-the-art hashing approaches
on multimedia retrieval tasks.
</summary>
    <author>
      <name>Jonathan Masci</name>
    </author>
    <author>
      <name>Michael M. Bronstein</name>
    </author>
    <author>
      <name>Alexander A. Bronstein</name>
    </author>
    <author>
      <name>Jürgen Schmidhuber</name>
    </author>
    <link href="http://arxiv.org/abs/1207.1522v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.1522v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.2922v1</id>
    <updated>2012-07-12T11:11:35Z</updated>
    <published>2012-07-12T11:11:35Z</published>
    <title>ROI Segmentation for Feature Extraction from Human Facial Images</title>
    <summary>  Human Computer Interaction (HCI) is the biggest goal of computer vision
researchers. Features form the different facial images are able to provide a
very deep knowledge about the activities performed by the different facial
movements. In this paper we presented a technique for feature extraction from
various regions of interest with the help of Skin color segmentation technique,
Thresholding, knowledge based technique for face recognition.
</summary>
    <author>
      <name> Surbhi</name>
    </author>
    <author>
      <name>Vishal Arora</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 2 figures; International Journal of Research in Computer
  Science, pp. 61-64 (2012)</arxiv:comment>
    <link href="http://arxiv.org/abs/1207.2922v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.2922v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.3510v2</id>
    <updated>2012-12-18T22:15:36Z</updated>
    <published>2012-07-15T14:50:17Z</published>
    <title>HMRF-EM-image: Implementation of the Hidden Markov Random Field Model
  and its Expectation-Maximization Algorithm</title>
    <summary>  In this project, we study the hidden Markov random field (HMRF) model and its
expectation-maximization (EM) algorithm. We implement a MATLAB toolbox named
HMRF-EM-image for 2D image segmentation using the HMRF-EM framework. This
toolbox also implements edge-prior-preserving image segmentation, and can be
easily reconfigured for other problems, such as 3D image segmentation.
</summary>
    <author>
      <name>Quan Wang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This work originally appears as the final project of Prof. Birsen
  Yazici's course Detection and Estimation Theory at RPI</arxiv:comment>
    <link href="http://arxiv.org/abs/1207.3510v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.3510v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.3607v1</id>
    <updated>2012-07-16T09:23:06Z</updated>
    <published>2012-07-16T09:23:06Z</published>
    <title>Fusing image representations for classification using support vector
  machines</title>
    <summary>  In order to improve classification accuracy different image representations
are usually combined. This can be done by using two different fusing schemes.
In feature level fusion schemes, image representations are combined before the
classification process. In classifier fusion, the decisions taken separately
based on individual representations are fused to make a decision. In this paper
the main methods derived for both strategies are evaluated. Our experimental
results show that classifier fusion performs better. Specifically Bayes belief
integration is the best performing strategy for image classification task.
</summary>
    <author>
      <name>Can Demirkesen</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">BIT Lab, LJK</arxiv:affiliation>
    </author>
    <author>
      <name>Hocine Cherifi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">BIT Lab, Le2i</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/IVCNZ.2009.5378367</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/IVCNZ.2009.5378367" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Image and Vision Computing New Zealand, 2009. IVCNZ '09. 24th
  International Conference, Wellington : Nouvelle-Z\'elande (2009)</arxiv:comment>
    <link href="http://arxiv.org/abs/1207.3607v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.3607v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.5007v1</id>
    <updated>2012-07-20T17:37:27Z</updated>
    <published>2012-07-20T17:37:27Z</published>
    <title>Multisegmentation through wavelets: Comparing the efficacy of Daubechies
  vs Coiflets</title>
    <summary>  In this paper, we carry out a comparative study of the efficacy of wavelets
belonging to Daubechies and Coiflet family in achieving image segmentation
through a fast statistical algorithm.The fact that wavelets belonging to
Daubechies family optimally capture the polynomial trends and those of Coiflet
family satisfy mini-max condition, makes this comparison interesting. In the
context of the present algorithm, it is found that the performance of Coiflet
wavelets is better, as compared to Daubechies wavelet.
</summary>
    <author>
      <name>Madhur Srivastava</name>
    </author>
    <author>
      <name>Yashwant Yashu</name>
    </author>
    <author>
      <name>Satish K. Singh</name>
    </author>
    <author>
      <name>Prasanta K. Panigrahi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings in Signal Processing and Real Time Operating System (
  SPRTOS), March 26 - 27 , 2011</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1207.5007v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.5007v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.6774v1</id>
    <updated>2012-07-29T13:07:09Z</updated>
    <published>2012-07-29T13:07:09Z</published>
    <title>A Survey Of Activity Recognition And Understanding The Behavior In Video
  Survelliance</title>
    <summary>  This paper presents a review of human activity recognition and behaviour
understanding in video sequence. The key objective of this paper is to provide
a general review on the overall process of a surveillance system used in the
current trend. Visual surveillance system is directed on automatic
identification of events of interest, especially on tracking and classification
of moving objects. The processing step of the video surveillance system
includes the following stages: Surrounding model, object representation, object
tracking, activity recognition and behaviour understanding. It describes
techniques that use to define a general set of activities that are applicable
to a wide range of scenes and environments in video sequence.
</summary>
    <author>
      <name>A. R. Revathi</name>
    </author>
    <author>
      <name>Dhananjay Kumar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 5 figures, 5 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1207.6774v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.6774v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1208.0378v1</id>
    <updated>2012-08-02T00:54:02Z</updated>
    <published>2012-08-02T00:54:02Z</published>
    <title>Fast Planar Correlation Clustering for Image Segmentation</title>
    <summary>  We describe a new optimization scheme for finding high-quality correlation
clusterings in planar graphs that uses weighted perfect matching as a
subroutine. Our method provides lower-bounds on the energy of the optimal
correlation clustering that are typically fast to compute and tight in
practice. We demonstrate our algorithm on the problem of image segmentation
where this approach outperforms existing global optimization techniques in
minimizing the objective and is competitive with the state of the art in
producing high-quality segmentations.
</summary>
    <author>
      <name>Julian Yarkony</name>
    </author>
    <author>
      <name>Alexander T. Ihler</name>
    </author>
    <author>
      <name>Charless C. Fowlkes</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This is the extended version of a paper to appear at the 12th
  European Conference on Computer Vision (ECCV 2012)</arxiv:comment>
    <link href="http://arxiv.org/abs/1208.0378v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1208.0378v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1208.3687v1</id>
    <updated>2012-08-17T20:38:56Z</updated>
    <published>2012-08-17T20:38:56Z</published>
    <title>Information-theoretic Dictionary Learning for Image Classification</title>
    <summary>  We present a two-stage approach for learning dictionaries for object
classification tasks based on the principle of information maximization. The
proposed method seeks a dictionary that is compact, discriminative, and
generative. In the first stage, dictionary atoms are selected from an initial
dictionary by maximizing the mutual information measure on dictionary
compactness, discrimination and reconstruction. In the second stage, the
selected dictionary atoms are updated for improved reconstructive and
discriminative power using a simple gradient ascent algorithm on mutual
information. Experiments using real datasets demonstrate the effectiveness of
our approach for image classification tasks.
</summary>
    <author>
      <name>Qiang Qiu</name>
    </author>
    <author>
      <name>Vishal M. Patel</name>
    </author>
    <author>
      <name>Rama Chellappa</name>
    </author>
    <link href="http://arxiv.org/abs/1208.3687v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1208.3687v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1208.3901v2</id>
    <updated>2012-11-26T16:49:30Z</updated>
    <published>2012-08-19T22:21:19Z</published>
    <title>Trace transform based method for color image domain identification</title>
    <summary>  Context categorization is a fundamental pre-requisite for multi-domain
multimedia content analysis applications in order to manage contextual
information in an efficient manner. In this paper, we introduce a new color
image context categorization method (DITEC) based on the trace transform. The
problem of dimensionality reduction of the obtained trace transform signal is
addressed through statistical descriptors that keep the underlying information.
These extracted features offer a highly discriminant behavior for content
categorization. The theoretical properties of the method are analyzed and
validated experimentally through two different datasets.
</summary>
    <author>
      <name>Igor G. Olaizola</name>
    </author>
    <author>
      <name>Marco Quartulli</name>
    </author>
    <author>
      <name>Julian Florez</name>
    </author>
    <author>
      <name>Basilio Sierra</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper has been momentaneously withdrawn</arxiv:comment>
    <link href="http://arxiv.org/abs/1208.3901v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1208.3901v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1208.5365v1</id>
    <updated>2012-08-27T11:20:49Z</updated>
    <published>2012-08-27T11:20:49Z</published>
    <title>A Missing and Found Recognition System for Hajj and Umrah</title>
    <summary>  This note describes an integrated recognition system for identifying missing
and found objects as well as missing, dead, and found people during Hajj and
Umrah seasons in the two Holy cities of Makkah and Madina in the Kingdom of
Saudi Arabia. It is assumed that the total estimated number of pilgrims will
reach 20 millions during the next decade. The ultimate goal of this system is
to integrate facial recognition and object identification solutions into the
Hajj and Umrah rituals. The missing and found computerized system is part of
the CrowdSensing system for Hajj and Umrah crowd estimation, management and
safety.
</summary>
    <author>
      <name>Salah A. Aly</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">website available via http://www.mfhajj.com</arxiv:comment>
    <link href="http://arxiv.org/abs/1208.5365v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1208.5365v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.1558v1</id>
    <updated>2012-09-07T14:52:02Z</updated>
    <published>2012-09-07T14:52:02Z</published>
    <title>A Comparative Study between Moravec and Harris Corner Detection of Noisy
  Images Using Adaptive Wavelet Thresholding Technique</title>
    <summary>  In this paper a comparative study between Moravec and Harris Corner Detection
has been done for obtaining features required to track and recognize objects
within a noisy image. Corner detection of noisy images is a challenging task in
image processing. Natural images often get corrupted by noise during
acquisition and transmission. As Corner detection of these noisy images does
not provide desired results, hence de-noising is required. Adaptive wavelet
thresholding approach is applied for the same.
</summary>
    <author>
      <name>Nilanjan Dey</name>
    </author>
    <author>
      <name>Pradipti Nandi</name>
    </author>
    <author>
      <name>Nilanjana Barman</name>
    </author>
    <author>
      <name>Debolina Das</name>
    </author>
    <author>
      <name>Subhabrata Chakraborty</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 13 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Engineering Research and Applications
  (IJERA) Vol. 2, Issue 1, Jan-Feb 2012, pp.599-606</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1209.1558v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.1558v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.2295v2</id>
    <updated>2012-09-12T07:31:14Z</updated>
    <published>2012-09-11T12:01:08Z</published>
    <title>Multimodal diffusion geometry by joint diagonalization of Laplacians</title>
    <summary>  We construct an extension of diffusion geometry to multiple modalities
through joint approximate diagonalization of Laplacian matrices. This naturally
extends classical data analysis tools based on spectral geometry, such as
diffusion maps and spectral clustering. We provide several synthetic and real
examples of manifold learning, retrieval, and clustering demonstrating that the
joint diffusion geometry frequently better captures the inherent structure of
multi-modal data. We also show that many previous attempts to construct
multimodal spectral clustering can be seen as particular cases of joint
approximate diagonalization of the Laplacians.
</summary>
    <author>
      <name>Davide Eynard</name>
    </author>
    <author>
      <name>Klaus Glashoff</name>
    </author>
    <author>
      <name>Michael M. Bronstein</name>
    </author>
    <author>
      <name>Alexander M. Bronstein</name>
    </author>
    <link href="http://arxiv.org/abs/1209.2295v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.2295v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.2903v1</id>
    <updated>2012-09-13T14:15:16Z</updated>
    <published>2012-09-13T14:15:16Z</published>
    <title>A Novel Approach of Harris Corner Detection of Noisy Images using
  Adaptive Wavelet Thresholding Technique</title>
    <summary>  In this paper we propose a method of corner detection for obtaining features
which is required to track and recognize objects within a noisy image. Corner
detection of noisy images is a challenging task in image processing. Natural
images often get corrupted by noise during acquisition and transmission. Though
Corner detection of these noisy images does not provide desired results, hence
de-noising is required. Adaptive wavelet thresholding approach is applied for
the same.
</summary>
    <author>
      <name>Nilanjan Dey</name>
    </author>
    <author>
      <name>Pradipti Nandi</name>
    </author>
    <author>
      <name>Nilanjana Barman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 10 figures. arXiv admin note: substantial text overlap with
  arXiv:1209.1558</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Science &amp; Technology(IJCST) Vol.
  2, ISSUE 4, OCT. - DEC. 2011</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1209.2903v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.2903v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.4420v1</id>
    <updated>2012-09-20T04:20:40Z</updated>
    <published>2012-09-20T04:20:40Z</published>
    <title>An Efficient Color Face Verification Based on 2-Directional
  2-Dimensional Feature Extraction</title>
    <summary>  A novel and uniform framework for face verification is presented in this
paper. First of all, a 2-directional 2-dimensional feature extraction method is
adopted to extract client-specific template - 2D discrimant projection matrix.
Then the face skin color information is utilized as an additive feature to
enhance decision making strategy that makes use of not only 2D grey feature but
also 2D skin color feature. A fusion decision of both is applied to experiment
the performance on the XM2VTS database according to Lausanne protocol.
Experimental results show that the framework achieves high verification
accuracy and verification speed.
</summary>
    <author>
      <name>Lan-Ting LI</name>
    </author>
    <link href="http://arxiv.org/abs/1209.4420v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.4420v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.5039v1</id>
    <updated>2012-09-23T07:52:01Z</updated>
    <published>2012-09-23T07:52:01Z</published>
    <title>Creation of Digital Test Form for Prepress Department</title>
    <summary>  The main problem in colour management in prepress department is lack of
availability of literature on colour management and knowledge gap between
prepress department and press department. So a digital test from has been
created by Adobe Photoshop to analyse the ICC profile and to create a new
profile and this analysed data is used to study about various grey scale of RGB
and CMYK images. That helps in conversion of image from RGB to CMYK in prepress
department.
</summary>
    <author>
      <name>Jaswinder Singh Dilawari</name>
    </author>
    <author>
      <name>Ravinder Khanna</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 Pages,4 Figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">(IJCSIS) International Journal of Computer Science and Information
  Security, Vol. 10, No. 9, September 2012 (IJCSIS) International Journal of
  Computer Science and Information Security, Vol. 10, No. 9, September 2012</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1209.5039v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.5039v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.5041v1</id>
    <updated>2012-09-23T09:15:20Z</updated>
    <published>2012-09-23T09:15:20Z</published>
    <title>An Implementation of Computer Graphics as Prepress Image Enhancement
  Process</title>
    <summary>  The production of a printed product involves three stages: prepress, the
printing process (press) itself, and finishing (post press). There are various
types of equipments (printers, scanners) and various qualities image are
present in the market. These give different color rendering each time during
reproduction. So, a color key tool has been developed keeping Color Management
Scheme (CMS) in mind so that during reproduction no color rendering takes place
irrespective of use of any device and resolution level has also been improved.
</summary>
    <author>
      <name>Jaswinder Singh Dilawari</name>
    </author>
    <author>
      <name>Ravinder Khanna</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 Pages,8 Figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1209.5041v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.5041v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.5417v1</id>
    <updated>2012-09-24T20:47:27Z</updated>
    <published>2012-09-24T20:47:27Z</published>
    <title>Model based neuro-fuzzy ASR on Texas processor</title>
    <summary>  In this paper an algorithm for recognizing speech has been proposed. The
recognized speech is used to execute related commands which use the MFCC and
two kind of classifiers, first one uses MLP and second one uses fuzzy inference
system as a classifier. The experimental results demonstrate the high gain and
efficiency of the proposed algorithm. We have implemented this system based on
graphical design and tested on a fix point digital signal processor (DSP) of
600 MHz, with reference DM6437-EVM of Texas instrument.
</summary>
    <author>
      <name>Hesam Ekhtiyar</name>
    </author>
    <author>
      <name>Mehdi Sheida</name>
    </author>
    <author>
      <name>Somaye Sobati Moghadam</name>
    </author>
    <link href="http://arxiv.org/abs/1209.5417v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.5417v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.5756v1</id>
    <updated>2012-09-25T20:11:23Z</updated>
    <published>2012-09-25T20:11:23Z</published>
    <title>Environmental Sounds Spectrogram Classification using Log-Gabor Filters
  and Multiclass Support Vector Machines</title>
    <summary>  This paper presents novel approaches for efficient feature extraction using
environmental sound magnitude spectrogram. We propose approach based on the
visual domain. This approach included three methods. The first method is based
on extraction for each spectrogram a single log-Gabor filter followed by mutual
information procedure. In the second method, the spectrogram is passed by the
same steps of the first method but with an averaged bank of 12 log-Gabor
filter. The third method consists of spectrogram segmentation into three
patches, and after that for each spectrogram patch we applied the second
method. The classification results prove that the second method is the most
efficient in our environmental sound classification system.
</summary>
    <author>
      <name>Sameh Souli</name>
    </author>
    <author>
      <name>Zied Lachiri</name>
    </author>
    <link href="http://arxiv.org/abs/1209.5756v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.5756v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.6037v1</id>
    <updated>2012-09-26T19:25:56Z</updated>
    <published>2012-09-26T19:25:56Z</published>
    <title>Reproduction of Images by Gamut Mapping and Creation of New Test Charts
  in Prepress Process</title>
    <summary>  With the advent of digital images the problem of keeping picture
visualization uniformity arises because each printing or scanning device has
its own color chart. So, universal color profiles are made by ICC to bring
uniformity in various types of devices. Keeping that color profile in mind
various new color charts are created and calibrated with the help of standard
IT8 test charts available in the market. The main objective to color
reproduction is to produce the identical picture at device output. For that
principles for gamut mapping has been designed
</summary>
    <author>
      <name>Jaswinder Singh Dilawari</name>
    </author>
    <author>
      <name>Ravinder Khanna</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 Pages,10 Figures; International Journal of Scientific and
  Engineering Research,Volume 3, Issue 10, October 2012 Edition</arxiv:comment>
    <link href="http://arxiv.org/abs/1209.6037v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.6037v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.0026v1</id>
    <updated>2012-09-28T20:29:37Z</updated>
    <published>2012-09-28T20:29:37Z</published>
    <title>Coupled quasi-harmonic bases</title>
    <summary>  The use of Laplacian eigenbases has been shown to be fruitful in many
computer graphics applications. Today, state-of-the-art approaches to shape
analysis, synthesis, and correspondence rely on these natural harmonic bases
that allow using classical tools from harmonic analysis on manifolds. However,
many applications involving multiple shapes are obstacled by the fact that
Laplacian eigenbases computed independently on different shapes are often
incompatible with each other. In this paper, we propose the construction of
common approximate eigenbases for multiple shapes using approximate joint
diagonalization algorithms. We illustrate the benefits of the proposed approach
on tasks from shape editing, pose transfer, correspondence, and similarity.
</summary>
    <author>
      <name>A. Kovnatsky</name>
    </author>
    <author>
      <name>M. M. Bronstein</name>
    </author>
    <author>
      <name>A. M. Bronstein</name>
    </author>
    <author>
      <name>K. Glashoff</name>
    </author>
    <author>
      <name>R. Kimmel</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 9 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1210.0026v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.0026v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.0347v1</id>
    <updated>2012-10-01T10:38:08Z</updated>
    <published>2012-10-01T10:38:08Z</published>
    <title>Enhanced Techniques for PDF Image Segmentation and Text Extraction</title>
    <summary>  Extracting text objects from the PDF images is a challenging problem. The
text data present in the PDF images contain certain useful information for
automatic annotation, indexing etc. However variations of the text due to
differences in text style, font, size, orientation, alignment as well as
complex structure make the problem of automatic text extraction extremely
difficult and challenging job. This paper presents two techniques under
block-based classification. After a brief introduction of the classification
methods, two methods were enhanced and results were evaluated. The performance
metrics for segmentation and time consumption are tested for both the models.
</summary>
    <author>
      <name>D. Sasirekha</name>
    </author>
    <author>
      <name>E. Chandra</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1210.0347v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.0347v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.0818v1</id>
    <updated>2012-10-02T16:03:58Z</updated>
    <published>2012-10-02T16:03:58Z</published>
    <title>Multibiometric: Feature Level Fusion Using FKP Multi-Instance biometric</title>
    <summary>  This paper proposed the use of multi-instance feature level fusion as a means
to improve the performance of Finger Knuckle Print (FKP) verification. A
log-Gabor filter has been used to extract the image local orientation
information, and represent the FKP features. Experiments are performed using
the FKP database, which consists of 7,920 images. Results indicate that the
multi-instance verification approach outperforms higher performance than using
any single instance. The influence on biometric performance using feature level
fusion under different fusion rules have been demonstrated in this paper.
</summary>
    <author>
      <name>Harbi AlMahafzah</name>
    </author>
    <author>
      <name>Mohammad Imran</name>
    </author>
    <author>
      <name>H. S. Sheshadri</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages paper</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IJCSI International Journal of Computer Science Issues, Vol. 9,
  Issue 4, No 3, July 2012</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1210.0818v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.0818v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.0829v1</id>
    <updated>2012-10-02T16:26:39Z</updated>
    <published>2012-10-02T16:26:39Z</published>
    <title>A Survey of Multibiometric Systems</title>
    <summary>  Most biometric systems deployed in real-world applications are unimodal.
Using unimodal biometric systems have to contend with a variety of problems
such as: Noise in sensed data; Intra-class variations; Inter-class
similarities; Non-universality; Spoof attacks. These problems have addressed by
using multibiometric systems, which expected to be more reliable due to the
presence of multiple, independent pieces of evidence.
</summary>
    <author>
      <name>Harbi AlMahafzah</name>
    </author>
    <author>
      <name>Maen Zaid AlRwashdeh</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5120/6182-8612</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5120/6182-8612" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Application volume 43 No 15
  April 2012</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1210.0829v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.0829v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.0866v1</id>
    <updated>2012-10-02T18:08:54Z</updated>
    <published>2012-10-02T18:08:54Z</published>
    <title>Classification of Hepatic Lesions using the Matching Metric</title>
    <summary>  In this paper we present a methodology of classifying hepatic (liver) lesions
using multidimensional persistent homology, the matching metric (also called
the bottleneck distance), and a support vector machine. We present our
classification results on a dataset of 132 lesions that have been outlined and
annotated by radiologists. We find that topological features are useful in the
classification of hepatic lesions. We also find that two-dimensional persistent
homology outperforms one-dimensional persistent homology in this application.
</summary>
    <author>
      <name>Aaron Adcock</name>
    </author>
    <author>
      <name>Daniel Rubin</name>
    </author>
    <author>
      <name>Gunnar Carlsson</name>
    </author>
    <link href="http://arxiv.org/abs/1210.0866v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.0866v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.AT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.2474v1</id>
    <updated>2012-10-09T02:57:12Z</updated>
    <published>2012-10-09T02:57:12Z</published>
    <title>Level Set Estimation from Compressive Measurements using Box Constrained
  Total Variation Regularization</title>
    <summary>  Estimating the level set of a signal from measurements is a task that arises
in a variety of fields, including medical imaging, astronomy, and digital
elevation mapping. Motivated by scenarios where accurate and complete
measurements of the signal may not available, we examine here a simple
procedure for estimating the level set of a signal from highly incomplete
measurements, which may additionally be corrupted by additive noise. The
proposed procedure is based on box-constrained Total Variation (TV)
regularization. We demonstrate the performance of our approach, relative to
existing state-of-the-art techniques for level set estimation from compressive
measurements, via several simulation examples.
</summary>
    <author>
      <name>Akshay Soni</name>
    </author>
    <author>
      <name>Jarvis Haupt</name>
    </author>
    <link href="http://arxiv.org/abs/1210.2474v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.2474v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.3404v2</id>
    <updated>2012-10-15T20:47:33Z</updated>
    <published>2012-10-12T00:31:46Z</published>
    <title>A polygon-based interpolation operator for super-resolution imaging</title>
    <summary>  We outline the super-resolution reconstruction problem posed as a
maximization of probability. We then introduce an interpolation method based on
polygonal pixel overlap, express it as a linear operator, and use it to improve
reconstruction. Polygon interpolation outperforms the simpler bilinear
interpolation operator and, unlike Gaussian modeling of pixels, requires no
parameter estimation. A free software implementation that reproduces the
results shown is provided.
</summary>
    <author>
      <name>Stéfan J. van der Walt</name>
    </author>
    <author>
      <name>B. M. Herbst</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages; update typo in abstract</arxiv:comment>
    <link href="http://arxiv.org/abs/1210.3404v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.3404v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.6157v1</id>
    <updated>2012-10-23T07:57:24Z</updated>
    <published>2012-10-23T07:57:24Z</published>
    <title>Novel Architecture for 3D model in virtual communities from detected
  face</title>
    <summary>  In this research paper we suggest how to extract a face from an image, modify
it, characterize it in terms of high-level properties, and apply it to the
creation of a personalized avatar. In this research work we tested, we
implemented the algorithm on several hundred facial images, including many
taken under uncontrolled acquisition conditions, and found to exhibit
satisfactory performance for immediate practical use.
</summary>
    <author>
      <name>Vibekananda Dutta</name>
    </author>
    <author>
      <name>Dr Nishtha Kesswani</name>
    </author>
    <author>
      <name>Deepti Gahalot</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">http://www.ijascse.in/publications-2012--2</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1210.6157v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.6157v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.7403v1</id>
    <updated>2012-10-28T05:27:55Z</updated>
    <published>2012-10-28T05:27:55Z</published>
    <title>Resolution Enhancement of Range Images via Color-Image Segmentation</title>
    <summary>  We report a method for super-resolution of range images. Our approach
leverages the interpretation of LR image as sparse samples on the HR grid.
Based on this interpretation, we demonstrate that our recently reported
approach, which reconstructs dense range images from sparse range data by
exploiting a registered colour image, can be applied for the task of resolution
enhancement of range images. Our method only uses a single colour image in
addition to the range observation in the super-resolution process. Using the
proposed approach, we demonstrate super-resolution results for large factors
(e.g. 4) with good localization accuracy.
</summary>
    <author>
      <name>Arnav Bhavsar</name>
    </author>
    <link href="http://arxiv.org/abs/1210.7403v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.7403v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.7631v1</id>
    <updated>2012-10-29T11:53:35Z</updated>
    <published>2012-10-29T11:53:35Z</published>
    <title>The fortresses of Ejin: an example of outlining a site from satellite
  images</title>
    <summary>  From 1960's to 1970's, the Chinese Army built some fortified artificial
hills. Some of them are located in the Inner Mongolia, Western China. These
large fortresses are surrounded by moats. For some of them it is still possible
to see earthworks, trenches and ditches, the planning of which could have a
symbolic meaning. We can argue this result form their digital outlining,
obtained after an image processing of satellite images, based on edge
detection.
</summary>
    <author>
      <name>Amelia Carolina Sparavigna</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Keywords: Satellite Imagery, Image processing, GIS, fortresses, China</arxiv:comment>
    <link href="http://arxiv.org/abs/1210.7631v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.7631v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.0191v1</id>
    <updated>2012-10-25T23:21:46Z</updated>
    <published>2012-10-25T23:21:46Z</published>
    <title>Performance Evaluation of Random Set Based Pedestrian Tracking
  Algorithms</title>
    <summary>  The paper evaluates the error performance of three random finite set based
multi-object trackers in the context of pedestrian video tracking. The
evaluation is carried out using a publicly available video dataset of 4500
frames (town centre street) for which the ground truth is available. The input
to all pedestrian tracking algorithms is an identical set of head and body
detections, obtained using the Histogram of Oriented Gradients (HOG) detector.
The tracking error is measured using the recently proposed OSPA metric for
tracks, adopted as the only known mathematically rigorous metric for measuring
the distance between two sets of tracks. A comparative analysis is presented
under various conditions.
</summary>
    <author>
      <name>Branko Ristic</name>
    </author>
    <author>
      <name>Jamie Sherrah</name>
    </author>
    <author>
      <name>Ángel F. García-Fernández</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1211.0191v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.0191v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.1482v4</id>
    <updated>2013-01-16T03:05:42Z</updated>
    <published>2012-11-07T08:19:04Z</published>
    <title>Gender Recognition in Walk Gait through 3D Motion by Quadratic Bezier
  Curve and Statistical Techniques</title>
    <summary>  Motion capture is the process of recording the movement of objects or people.
It is used in military, entertainment, sports, and medical applications, and
for validation of computer vision[2] and robotics. In filmmaking and video game
development, it refers to recording actions of human actors, and using that
information to animate digital character models in 2D or 3D computer animation.
When it includes face and fingers or captures subtle
</summary>
    <author>
      <name>Sajid Ali</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">wrongly uploaded</arxiv:comment>
    <link href="http://arxiv.org/abs/1211.1482v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.1482v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.1800v1</id>
    <updated>2012-11-08T09:24:21Z</updated>
    <published>2012-11-08T09:24:21Z</published>
    <title>A Comparative study of Arabic handwritten characters invariant feature</title>
    <summary>  This paper is practically interested in the unchangeable feature of Arabic
handwritten character. It presents results of comparative study achieved on
certain features extraction techniques of handwritten character, based on Hough
transform, Fourier transform, Wavelet transform and Gabor Filter. Obtained
results show that Hough Transform and Gabor filter are insensible to the
rotation and translation, Fourier Transform is sensible to the rotation but
insensible to the translation, in contrast to Hough Transform and Gabor filter,
Wavelets Transform is sensitive to the rotation as well as to the translation.
</summary>
    <author>
      <name>Hamdi Hassen</name>
    </author>
    <author>
      <name>Maher khemakhem</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">(IJACSA) International Journal of Advanced Computer Science and
  Applications, Vol. 2, No. 12, 2011</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1211.1800v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.1800v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.2116v1</id>
    <updated>2012-11-09T12:59:11Z</updated>
    <published>2012-11-09T12:59:11Z</published>
    <title>Localisation of Numerical Date Field in an Indian Handwritten Document</title>
    <summary>  This paper describes a method to localise all those areas which may
constitute the date field in an Indian handwritten document. Spatial patterns
of the date field are studied from various handwritten documents and an
algorithm is developed through statistical analysis to identify those sets of
connected components which may constitute the date. Common date patterns
followed in India are considered to classify the date formats in different
classes. Reported results demonstrate promising performance of the proposed
approach
</summary>
    <author>
      <name>S Arunkumar</name>
    </author>
    <author>
      <name>Pallab Kumar Sahu</name>
    </author>
    <author>
      <name>Sudeep Gorai</name>
    </author>
    <author>
      <name>Kalyan Ghosh</name>
    </author>
    <link href="http://arxiv.org/abs/1211.2116v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.2116v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.4307v1</id>
    <updated>2012-11-19T05:44:24Z</updated>
    <published>2012-11-19T05:44:24Z</published>
    <title>Efficient Superimposition Recovering Algorithm</title>
    <summary>  In this article, we address the issue of recovering latent transparent layers
from superimposition images. Here, we assume we have the estimated
transformations and extracted gradients of latent layers. To rapidly recover
high-quality image layers, we propose an Efficient Superimposition Recovering
Algorithm (ESRA) by extending the framework of accelerated gradient method. In
addition, a key building block (in each iteration) in our proposed method is
the proximal operator calculating. Here we propose to employ a dual approach
and present our Parallel Algorithm with Constrained Total Variation (PACTV)
method. Our recovering method not only reconstructs high-quality layers without
color-bias problem, but also theoretically guarantees good convergence
performance.
</summary>
    <author>
      <name>Han Li</name>
    </author>
    <author>
      <name>Kun Gai</name>
    </author>
    <author>
      <name>Pinghua Gong</name>
    </author>
    <author>
      <name>Changshui Zhang</name>
    </author>
    <link href="http://arxiv.org/abs/1211.4307v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.4307v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.4385v1</id>
    <updated>2012-11-19T12:21:49Z</updated>
    <published>2012-11-19T12:21:49Z</published>
    <title>Artificial Neural Network Based Optical Character Recognition</title>
    <summary>  Optical Character Recognition deals in recognition and classification of
characters from an image. For the recognition to be accurate, certain
topological and geometrical properties are calculated, based on which a
character is classified and recognized. Also, the Human psychology perceives
characters by its overall shape and features such as strokes, curves,
protrusions, enclosures etc. These properties, also called Features are
extracted from the image by means of spatial pixel-based calculation. A
collection of such features, called Vectors, help in defining a character
uniquely, by means of an Artificial Neural Network that uses these Feature
Vectors.
</summary>
    <author>
      <name>Vivek Shrivastava</name>
    </author>
    <author>
      <name>Navdeep Sharma</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5121/sipij.2012.3506</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5121/sipij.2012.3506" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Signal &amp; Image Processing : An International Journal (SIPIJ) Vol.3,
  No.5, October 2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1211.4385v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.4385v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.4503v1</id>
    <updated>2012-11-19T17:13:26Z</updated>
    <published>2012-11-19T17:13:26Z</published>
    <title>An Effective Fingerprint Classification and Search Method</title>
    <summary>  This paper presents an effective fingerprint classification method designed
based on a hierarchical agglomerative clustering technique. The performance of
the technique was evaluated in terms of several real-life datasets and a
significant improvement in reducing the misclassification error has been
noticed. This paper also presents a query based faster fingerprint search
method over the clustered fingerprint databases. The retrieval accuracy of the
search method has been found effective in light of several real-life databases.
</summary>
    <author>
      <name>Monowar H. Bhuyan</name>
    </author>
    <author>
      <name>D. K. Bhattacharyya</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 8 figures, 6 tables, referred journal publication</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Science and Network Security,
  Vol. 9, No.11, pp. 39-48, 2009</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1211.4503v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.4503v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68U35" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.5.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.4860v1</id>
    <updated>2012-11-20T20:54:30Z</updated>
    <published>2012-11-20T20:54:30Z</published>
    <title>Domain Adaptations for Computer Vision Applications</title>
    <summary>  A basic assumption of statistical learning theory is that train and test data
are drawn from the same underlying distribution. Unfortunately, this assumption
doesn't hold in many applications. Instead, ample labeled data might exist in a
particular `source' domain while inference is needed in another, `target'
domain. Domain adaptation methods leverage labeled data from both domains to
improve classification on unseen data in the target domain. In this work we
survey domain transfer learning methods for various application domains with
focus on recent work in Computer Vision.
</summary>
    <author>
      <name>Oscar Beijbom</name>
    </author>
    <link href="http://arxiv.org/abs/1211.4860v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.4860v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.5556v1</id>
    <updated>2012-11-23T17:13:07Z</updated>
    <published>2012-11-23T17:13:07Z</published>
    <title>Improving Perceptual Color Difference using Basic Color Terms</title>
    <summary>  We suggest a new color distance based on two observations. First, perceptual
color differences were designed to be used to compare very similar colors. They
do not capture human perception for medium and large color differences well.
Thresholding was proposed to solve the problem for large color differences,
i.e. two totally different colors are always the same distance apart. We show
that thresholding alone cannot improve medium color differences. We suggest to
alleviate this problem using basic color terms. Second, when a color distance
is used for edge detection, many small distances around the just noticeable
difference may account for false edges. We suggest to reduce the effect of
small distances.
</summary>
    <author>
      <name>Ofir Pele</name>
    </author>
    <author>
      <name>Michael Werman</name>
    </author>
    <link href="http://arxiv.org/abs/1211.5556v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.5556v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.0030v1</id>
    <updated>2012-11-30T22:35:19Z</updated>
    <published>2012-11-30T22:35:19Z</published>
    <title>Viewpoint Invariant Object Detector</title>
    <summary>  Object Detection is the task of identifying the existence of an object class
instance and locating it within an image. Difficulties in handling high
intra-class variations constitute major obstacles to achieving high performance
on standard benchmark datasets (scale, viewpoint, lighting conditions and
orientation variations provide good examples). Suggested model aims at
providing more robustness to detecting objects suffering severe distortion due
to &lt; 60{\deg} viewpoint changes. In addition, several model computational
bottlenecks have been resolved leading to a significant increase in the model
performance (speed and space) without compromising the resulting accuracy.
Finally, we produced two illustrative applications showing the potential of the
object detection technology being deployed in real life applications; namely
content-based image search and content-based video search.
</summary>
    <author>
      <name>Osama Khalil</name>
    </author>
    <author>
      <name>Andrew Habib</name>
    </author>
    <link href="http://arxiv.org/abs/1212.0030v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.0030v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.0134v1</id>
    <updated>2012-12-01T16:59:07Z</updated>
    <published>2012-12-01T16:59:07Z</published>
    <title>Fingertip Detection: A Fast Method with Natural Hand</title>
    <summary>  Many vision based applications have used fingertips to track or manipulate
gestures in their applications. Gesture identification is a natural way to pass
the signals to the machine, as the human express its feelings most of the time
with hand expressions. Here a novel time efficient algorithm has been described
for fingertip detection. This method is invariant to hand direction and in
preprocessing it cuts only hand part from the full image, hence further
computation would be much faster than processing full image. Binary silhouette
of the input image is generated using HSV color space based skin filter and
hand cropping done based on intensity histogram of the hand image
</summary>
    <author>
      <name>J. L. Raheja</name>
    </author>
    <author>
      <name>Karen Das</name>
    </author>
    <author>
      <name>Ankit Chaudhary</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Embedded Systems and Computer
  Engineering, 2011</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1212.0134v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.0134v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.0142v2</id>
    <updated>2013-04-02T18:05:46Z</updated>
    <published>2012-12-01T18:13:03Z</published>
    <title>Pedestrian Detection with Unsupervised Multi-Stage Feature Learning</title>
    <summary>  Pedestrian detection is a problem of considerable practical interest. Adding
to the list of successful applications of deep learning methods to vision, we
report state-of-the-art and competitive results on all major pedestrian
datasets with a convolutional network model. The model uses a few new twists,
such as multi-stage features, connections that skip layers to integrate global
shape information with local distinctive motif information, and an unsupervised
method based on convolutional sparse coding to pre-train the filters at each
stage.
</summary>
    <author>
      <name>Pierre Sermanet</name>
    </author>
    <author>
      <name>Koray Kavukcuoglu</name>
    </author>
    <author>
      <name>Soumith Chintala</name>
    </author>
    <author>
      <name>Yann LeCun</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1212.0142v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.0142v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.0402v1</id>
    <updated>2012-12-03T14:45:31Z</updated>
    <published>2012-12-03T14:45:31Z</published>
    <title>UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild</title>
    <summary>  We introduce UCF101 which is currently the largest dataset of human actions.
It consists of 101 action classes, over 13k clips and 27 hours of video data.
The database consists of realistic user uploaded videos containing camera
motion and cluttered background. Additionally, we provide baseline action
recognition results on this new dataset using standard bag of words approach
with overall performance of 44.5%. To the best of our knowledge, UCF101 is
currently the most challenging dataset of actions due to its large number of
classes, large number of clips and also unconstrained nature of such clips.
</summary>
    <author>
      <name>Khurram Soomro</name>
    </author>
    <author>
      <name>Amir Roshan Zamir</name>
    </author>
    <author>
      <name>Mubarak Shah</name>
    </author>
    <link href="http://arxiv.org/abs/1212.0402v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.0402v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.0888v1</id>
    <updated>2012-12-04T21:59:35Z</updated>
    <published>2012-12-04T21:59:35Z</published>
    <title>Unmixing of Hyperspectral Data Using Robust Statistics-based NMF</title>
    <summary>  Mixed pixels are presented in hyperspectral images due to low spatial
resolution of hyperspectral sensors. Spectral unmixing decomposes mixed pixels
spectra into endmembers spectra and abundance fractions. In this paper using of
robust statistics-based nonnegative matrix factorization (RNMF) for spectral
unmixing of hyperspectral data is investigated. RNMF uses a robust cost
function and iterative updating procedure, so is not sensitive to outliers.
This method has been applied to simulated data using USGS spectral library,
AVIRIS and ROSIS datasets. Unmixing results are compared to traditional NMF
method based on SAD and AAD measures. Results demonstrate that this method can
be used efficiently for hyperspectral unmixing purposes.
</summary>
    <author>
      <name>Roozbeh Rajabi</name>
    </author>
    <author>
      <name>Hassan Ghassemian</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, conference</arxiv:comment>
    <link href="http://arxiv.org/abs/1212.0888v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.0888v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.2546v1</id>
    <updated>2012-12-11T17:29:04Z</updated>
    <published>2012-12-11T17:29:04Z</published>
    <title>A Learning Framework for Morphological Operators using Counter-Harmonic
  Mean</title>
    <summary>  We present a novel framework for learning morphological operators using
counter-harmonic mean. It combines concepts from morphology and convolutional
neural networks. A thorough experimental validation analyzes basic
morphological operators dilation and erosion, opening and closing, as well as
the much more complex top-hat transform, for which we report a real-world
application from the steel industry. Using online learning and stochastic
gradient descent, our system learns both the structuring element and the
composition of operators. It scales well to large datasets and online settings.
</summary>
    <author>
      <name>Jonathan Masci</name>
    </author>
    <author>
      <name>Jesús Angulo</name>
    </author>
    <author>
      <name>Jürgen Schmidhuber</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to ISMM'13</arxiv:comment>
    <link href="http://arxiv.org/abs/1212.2546v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.2546v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.3034v1</id>
    <updated>2012-12-13T01:55:15Z</updated>
    <published>2012-12-13T01:55:15Z</published>
    <title>Multi-target tracking algorithms in 3D</title>
    <summary>  Ladars provide a unique capability for identification of objects and motions
in scenes with fixed 3D field of view (FOV). This paper describes algorithms
for multi-target tracking in 3D scenes including the preprocessing
(mathematical morphology and Parzen windows), labeling of connected components,
sorting of targets by selectable attributes (size, length of track, velocity),
and handling of target states (acquired, coasting, re-acquired and tracked) in
order to assemble the target trajectories. This paper is derived from working
algorithms coded in Matlab, which were tested and reviewed by others, and does
not speculate about usage of general formulas or frameworks.
</summary>
    <author>
      <name>Rastislav Telgarsky</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 2 figures, conference proceedings</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Scientific Issues, MATHEMATICA IV, Ruzomberok 2012</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1212.3034v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.3034v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65D18, 68W05" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4; I.2.10; I.4.7; I.4.8; I.4.9; I.5.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.4608v1</id>
    <updated>2012-12-19T09:40:09Z</updated>
    <published>2012-12-19T09:40:09Z</published>
    <title>Perceptually Motivated Shape Context Which Uses Shape Interiors</title>
    <summary>  In this paper, we identify some of the limitations of current-day shape
matching techniques. We provide examples of how contour-based shape matching
techniques cannot provide a good match for certain visually similar shapes. To
overcome this limitation, we propose a perceptually motivated variant of the
well-known shape context descriptor. We identify that the interior properties
of the shape play an important role in object recognition and develop a
descriptor that captures these interior properties. We show that our method can
easily be augmented with any other shape matching algorithm. We also show from
our experiments that the use of our descriptor can significantly improve the
retrieval rates.
</summary>
    <author>
      <name>Vittal Premachandran</name>
    </author>
    <author>
      <name>Ramakrishna Kakarala</name>
    </author>
    <link href="http://arxiv.org/abs/1212.4608v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.4608v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.5877v2</id>
    <updated>2013-03-29T02:49:46Z</updated>
    <published>2012-12-24T08:58:02Z</published>
    <title>Blinking Molecule Tracking</title>
    <summary>  We discuss a method for tracking individual molecules which globally
optimizes the likelihood of the connections between molecule positions fast and
with high reliability even for high spot densities and blinking molecules. Our
method works with cost functions which can be freely chosen to combine costs
for distances between spots in space and time and which can account for the
reliability of positioning a molecule. To this end, we describe a top-down
polyhedral approach to the problem of tracking many individual molecules. This
immediately yields an effective implementation using standard linear
programming solvers. Our method can be applied to 2D and 3D tracking.
</summary>
    <author>
      <name>Andreas Karrenbauer</name>
    </author>
    <author>
      <name>Dominik Wöll</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12th International Symposium on Experimental Algorithms 2013</arxiv:comment>
    <link href="http://arxiv.org/abs/1212.5877v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.5877v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.0435v1</id>
    <updated>2013-01-03T12:16:25Z</updated>
    <published>2013-01-03T12:16:25Z</published>
    <title>Investigating the performance of Correspondence Algorithms in Vision
  based Driver-assistance in Indoor Environment</title>
    <summary>  This paper presents the experimental comparison of fourteen stereo matching
algorithms in variant illumination conditions. Different adaptations of global
and local stereo matching techniques are chosen for evaluation The variant
strength and weakness of the chosen correspondence algorithms are explored by
employing the methodology of the prediction error strategy. The algorithms are
gauged on the basis of their performance on real world data set taken in
various indoor lighting conditions and at different times of the day
</summary>
    <author>
      <name>F. Mahmood</name>
    </author>
    <author>
      <name>Syed. M. B. Haider</name>
    </author>
    <author>
      <name>F. Kunwar</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5120/9718-3663</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5120/9718-3663" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 9 figures,Published with International Journal of Computer
  Applications (IJCA)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IJCA 60(9):6-12, 2012</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1301.0435v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.0435v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.0612v1</id>
    <updated>2012-12-12T15:59:10Z</updated>
    <published>2012-12-12T15:59:10Z</published>
    <title>Adaptive Foreground and Shadow Detection inImage Sequences</title>
    <summary>  This paper presents a novel method of foreground segmentation that
distinguishes moving objects from their moving cast shadows in monocular image
sequences. The models of background, edge information, and shadow are set up
and adaptively updated. A Bayesian belief network is proposed to describe the
relationships among the segmentation label, background, intensity, and edge
information. The notion of Markov random field is used to encourage the spatial
connectivity of the segmented regions. The solution is obtained by maximizing
the posterior possibility density of the segmentation field.
</summary>
    <author>
      <name>Yang Wang</name>
    </author>
    <author>
      <name>Tele Tan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the Eighteenth Conference on Uncertainty in
  Artificial Intelligence (UAI2002)</arxiv:comment>
    <link href="http://arxiv.org/abs/1301.0612v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.0612v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.1671v1</id>
    <updated>2013-01-08T20:56:17Z</updated>
    <published>2013-01-08T20:56:17Z</published>
    <title>Causal graph-based video segmentation</title>
    <summary>  Numerous approaches in image processing and computer vision are making use of
super-pixels as a pre-processing step. Among the different methods producing
such over-segmentation of an image, the graph-based approach of Felzenszwalb
and Huttenlocher is broadly employed. One of its interesting properties is that
the regions are computed in a greedy manner in quasi-linear time. The algorithm
may be trivially extended to video segmentation by considering a video as a 3D
volume, however, this can not be the case for causal segmentation, when
subsequent frames are unknown. We propose an efficient video segmentation
approach that computes temporally consistent pixels in a causal manner, filling
the need for causal and real time applications.
</summary>
    <author>
      <name>Camille Couprie</name>
    </author>
    <author>
      <name>Clément Farabet</name>
    </author>
    <author>
      <name>Yann LeCun</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1301.1671v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.1671v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.2351v1</id>
    <updated>2013-01-10T22:57:01Z</updated>
    <published>2013-01-10T22:57:01Z</published>
    <title>Application of Hopfield Network to Saccades</title>
    <summary>  Human eye movement mechanisms (saccades) are very useful for scene analysis,
including object representation and pattern recognition. In this letter, a
Hopfield neural network to emulate saccades is proposed. The network uses an
energy function that includes location and identification tasks. Computer
simulation shows that the network performs those tasks cooperatively. The
result suggests that the network is applicable to shift-invariant pattern
recognition.
</summary>
    <author>
      <name>Teruyoshi Washizawa</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/72.286896</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/72.286896" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 6 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE Transactions on NEURAL NETWORKS, vol.4, no.6, pp-995-997,
  NOVEMBER 1993</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1301.2351v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.2351v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.2820v3</id>
    <updated>2013-03-13T22:48:38Z</updated>
    <published>2013-01-13T20:49:30Z</published>
    <title>Clustering Learning for Robotic Vision</title>
    <summary>  We present the clustering learning technique applied to multi-layer
feedforward deep neural networks. We show that this unsupervised learning
technique can compute network filters with only a few minutes and a much
reduced set of parameters. The goal of this paper is to promote the technique
for general-purpose robotic vision systems. We report its use in static image
datasets and object tracking datasets. We show that networks trained with
clustering learning can outperform large networks trained for many hours on
complex datasets.
</summary>
    <author>
      <name>Eugenio Culurciello</name>
    </author>
    <author>
      <name>Jordan Bates</name>
    </author>
    <author>
      <name>Aysegul Dundar</name>
    </author>
    <author>
      <name>Jose Carrasco</name>
    </author>
    <author>
      <name>Clement Farabet</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Code for this paper is available here:
  https://github.com/culurciello/CL_paper1_code</arxiv:comment>
    <link href="http://arxiv.org/abs/1301.2820v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.2820v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.3385v2</id>
    <updated>2013-01-16T14:56:44Z</updated>
    <published>2013-01-15T15:34:07Z</published>
    <title>Recurrent Online Clustering as a Spatio-Temporal Feature Extractor in
  DeSTIN</title>
    <summary>  This paper presents a basic enhancement to the DeSTIN deep learning
architecture by replacing the explicitly calculated transition tables that are
used to capture temporal features with a simpler, more scalable mechanism. This
mechanism uses feedback of state information to cluster over a space comprised
of both the spatial input and the current state. The resulting architecture
achieves state-of-the-art results on the MNIST classification benchmark.
</summary>
    <author>
      <name>Steven R. Young</name>
    </author>
    <author>
      <name>Itamar Arel</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3 pages, 2 figures, Submitted to ICLR 2013</arxiv:comment>
    <link href="http://arxiv.org/abs/1301.3385v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.3385v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.3457v2</id>
    <updated>2013-04-10T18:32:07Z</updated>
    <published>2013-01-15T19:18:52Z</published>
    <title>A Geometric Descriptor for Cell-Division Detection</title>
    <summary>  We describe a method for cell-division detection based on a geometric-driven
descriptor that can be represented as a 5-layers processing network, based
mainly on wavelet filtering and a test for mirror symmetry between pairs of
pixels. After the centroids of the descriptors are computed for a sequence of
frames, the two-steps piecewise constant function that best fits the sequence
of centroids determines the frame where the division occurs.
</summary>
    <author>
      <name>Marcelo Cicconet</name>
    </author>
    <author>
      <name>Italo Lima</name>
    </author>
    <author>
      <name>Davi Geiger</name>
    </author>
    <author>
      <name>Kris Gunsalus</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper has been withdrawn by the author since the review process
  for the conference to which it was applied ended</arxiv:comment>
    <link href="http://arxiv.org/abs/1301.3457v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.3457v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.3572v2</id>
    <updated>2013-03-14T18:18:17Z</updated>
    <published>2013-01-16T03:31:30Z</published>
    <title>Indoor Semantic Segmentation using depth information</title>
    <summary>  This work addresses multi-class segmentation of indoor scenes with RGB-D
inputs. While this area of research has gained much attention recently, most
works still rely on hand-crafted features. In contrast, we apply a multiscale
convolutional network to learn features directly from the images and the depth
information. We obtain state-of-the-art on the NYU-v2 depth dataset with an
accuracy of 64.5%. We illustrate the labeling of indoor scenes in videos
sequences that could be processed in real-time using appropriate hardware such
as an FPGA.
</summary>
    <author>
      <name>Camille Couprie</name>
    </author>
    <author>
      <name>Clément Farabet</name>
    </author>
    <author>
      <name>Laurent Najman</name>
    </author>
    <author>
      <name>Yann LeCun</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1301.3572v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.3572v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.3755v1</id>
    <updated>2013-01-16T17:05:57Z</updated>
    <published>2013-01-16T17:05:57Z</published>
    <title>Gradient Driven Learning for Pooling in Visual Pipeline Feature
  Extraction Models</title>
    <summary>  Hyper-parameter selection remains a daunting task when building a pattern
recognition architecture which performs well, particularly in recently
constructed visual pipeline models for feature extraction. We re-formulate
pooling in an existing pipeline as a function of adjustable pooling map weight
parameters and propose the use of supervised error signals from gradient
descent to tune the established maps within the model. This technique allows us
to learn what would otherwise be a design choice within the model and
specialize the maps to aggregate areas of invariance for the task presented.
Preliminary results show moderate potential gains in classification accuracy
and highlight areas of importance within the intermediate feature
representation space.
</summary>
    <author>
      <name>Derek Rose</name>
    </author>
    <author>
      <name>Itamar Arel</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3 pages, 2 figures, submitted to ICLR2013 workshop</arxiv:comment>
    <link href="http://arxiv.org/abs/1301.3755v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.3755v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1302.0077v1</id>
    <updated>2013-02-01T05:08:58Z</updated>
    <published>2013-02-01T05:08:58Z</published>
    <title>Sparse MRI for motion correction</title>
    <summary>  MR image sparsity/compressibility has been widely exploited for imaging
acceleration with the development of compressed sensing. A sparsity-based
approach to rigid-body motion correction is presented for the first time in
this paper. A motion is sought after such that the compensated MR image is
maximally sparse/compressible among the infinite candidates. Iterative
algorithms are proposed that jointly estimate the motion and the image content.
The proposed method has a lot of merits, such as no need of additional data and
loose requirement for the sampling sequence. Promising results are presented to
demonstrate its performance.
</summary>
    <author>
      <name>Zai Yang</name>
    </author>
    <author>
      <name>Cishen Zhang</name>
    </author>
    <author>
      <name>Lihua Xie</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in Proceedings of ISBI 2013. 4 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1302.0077v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1302.0077v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.bio-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.med-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1302.1690v1</id>
    <updated>2013-02-07T10:17:07Z</updated>
    <published>2013-02-07T10:17:07Z</published>
    <title>A Fast Learning Algorithm for Image Segmentation with Max-Pooling
  Convolutional Networks</title>
    <summary>  We present a fast algorithm for training MaxPooling Convolutional Networks to
segment images. This type of network yields record-breaking performance in a
variety of tasks, but is normally trained on a computationally expensive
patch-by-patch basis. Our new method processes each training image in a single
pass, which is vastly more efficient.
  We validate the approach in different scenarios and report a 1500-fold
speed-up. In an application to automated steel defect detection and
segmentation, we obtain excellent performance with short training times.
</summary>
    <author>
      <name>Jonathan Masci</name>
    </author>
    <author>
      <name>Alessandro Giusti</name>
    </author>
    <author>
      <name>Dan Cireşan</name>
    </author>
    <author>
      <name>Gabriel Fricout</name>
    </author>
    <author>
      <name>Jürgen Schmidhuber</name>
    </author>
    <link href="http://arxiv.org/abs/1302.1690v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1302.1690v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1302.1700v1</id>
    <updated>2013-02-07T10:33:47Z</updated>
    <published>2013-02-07T10:33:47Z</published>
    <title>Fast Image Scanning with Deep Max-Pooling Convolutional Neural Networks</title>
    <summary>  Deep Neural Networks now excel at image classification, detection and
segmentation. When used to scan images by means of a sliding window, however,
their high computational complexity can bring even the most powerful hardware
to its knees. We show how dynamic programming can speedup the process by orders
of magnitude, even when max-pooling layers are present.
</summary>
    <author>
      <name>Alessandro Giusti</name>
    </author>
    <author>
      <name>Dan C. Cireşan</name>
    </author>
    <author>
      <name>Jonathan Masci</name>
    </author>
    <author>
      <name>Luca M. Gambardella</name>
    </author>
    <author>
      <name>Jürgen Schmidhuber</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 2 figures, 3 tables, 21 references, submitted to ICIP 2013</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Conference on Image Processing (ICIP) 2013,
  Melbourne</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1302.1700v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1302.1700v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1302.5056v1</id>
    <updated>2013-01-15T18:47:11Z</updated>
    <published>2013-01-15T18:47:11Z</published>
    <title>Pooling-Invariant Image Feature Learning</title>
    <summary>  Unsupervised dictionary learning has been a key component in state-of-the-art
computer vision recognition architectures. While highly effective methods exist
for patch-based dictionary learning, these methods may learn redundant features
after the pooling stage in a given early vision architecture. In this paper, we
offer a novel dictionary learning scheme to efficiently take into account the
invariance of learned features after the spatial pooling stage. The algorithm
is built on simple clustering, and thus enjoys efficiency and scalability. We
discuss the underlying mechanism that justifies the use of clustering
algorithms, and empirically show that the algorithm finds better dictionaries
than patch-based methods with the same dictionary size.
</summary>
    <author>
      <name>Yangqing Jia</name>
    </author>
    <author>
      <name>Oriol Vinyals</name>
    </author>
    <author>
      <name>Trevor Darrell</name>
    </author>
    <link href="http://arxiv.org/abs/1302.5056v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1302.5056v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1302.5894v1</id>
    <updated>2013-02-24T10:49:39Z</updated>
    <published>2013-02-24T10:49:39Z</published>
    <title>Four Side Distance: A New Fourier Shape Signature</title>
    <summary>  Shape is one of the main features in content based image retrieval (CBIR).
This paper proposes a new shape signature. In this technique, features of each
shape are extracted based on four sides of the rectangle that covers the shape.
The proposed technique is Fourier based and it is invariant to translation,
scaling and rotation. The retrieval performance between some commonly used
Fourier based signatures and the proposed four sides distance (FSD) signature
has been tested using MPEG-7 database. Experimental results are shown that the
FSD signature has better performance compared with those signatures.
</summary>
    <author>
      <name>Sonya Eini</name>
    </author>
    <author>
      <name>Abdolah Chalechale</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 7 figures, International Journal of Advanced Studies in
  Computers, Science and Engineering</arxiv:comment>
    <link href="http://arxiv.org/abs/1302.5894v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1302.5894v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1302.5957v1</id>
    <updated>2013-02-24T21:38:20Z</updated>
    <published>2013-02-24T21:38:20Z</published>
    <title>Shape Characterization via Boundary Distortion</title>
    <summary>  In this paper, we derive new shape descriptors based on a directional
characterization. The main idea is to study the behavior of the shape
neighborhood under family of transformations. We obtain a description invariant
with respect to rotation, reflection, translation and scaling. A well-defined
metric is then proposed on the associated feature space. We show the continuity
of this metric. Some results on shape retrieval are provided on two databases
to show the accuracy of the proposed shape metric.
</summary>
    <author>
      <name>Xavier Descombes</name>
    </author>
    <author>
      <name>Serguei Komech</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1302.5957v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1302.5957v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1302.7082v1</id>
    <updated>2013-02-28T04:50:31Z</updated>
    <published>2013-02-28T04:50:31Z</published>
    <title>K Means Segmentation of Alzheimers Disease in PET scan datasets: An
  implementation</title>
    <summary>  The Positron Emission Tomography (PET) scan image requires expertise in the
segmentation where clustering algorithm plays an important role in the
automation process. The algorithm optimization is concluded based on the
performance, quality and number of clusters extracted. This paper is proposed
to study the commonly used K Means clustering algorithm and to discuss a brief
list of toolboxes for reproducing and extending works presented in medical
image analysis. This work is compiled using AForge .NET framework in windows
environment and MATrix LABoratory (MATLAB 7.0.1)
</summary>
    <author>
      <name>A. Meena</name>
    </author>
    <author>
      <name>K. Raja</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">International Joint Conference on Advances in Signal Processing and
  Information Technology, SPIT2012</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">LNICST, ISSN:1867 To 8211 pp. 158 To 162, 2012</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1302.7082v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1302.7082v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1303.0634v1</id>
    <updated>2013-03-04T08:06:07Z</updated>
    <published>2013-03-04T08:06:07Z</published>
    <title>Indian Sign Language Recognition Using Eigen Value Weighted Euclidean
  Distance Based Classification Technique</title>
    <summary>  Sign Language Recognition is one of the most growing fields of research
today. Many new techniques have been developed recently in these fields. Here
in this paper, we have proposed a system using Eigen value weighted Euclidean
distance as a classification technique for recognition of various Sign
Languages of India. The system comprises of four parts: Skin Filtering, Hand
Cropping, Feature Extraction and Classification. Twenty four signs were
considered in this paper, each having ten samples, thus a total of two hundred
forty images was considered for which recognition rate obtained was 97 percent.
</summary>
    <author>
      <name>Joyeeta Singha</name>
    </author>
    <author>
      <name>Karen Das</name>
    </author>
    <link href="http://arxiv.org/abs/1303.0634v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1303.0634v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1303.0635v1</id>
    <updated>2013-03-04T08:09:22Z</updated>
    <published>2013-03-04T08:09:22Z</published>
    <title>Recognition of Facial Expression Using Eigenvector Based Distributed
  Features and Euclidean Distance Based Decision Making Technique</title>
    <summary>  In this paper, an Eigenvector based system has been presented to recognize
facial expressions from digital facial images. In the approach, firstly the
images were acquired and cropping of five significant portions from the image
was performed to extract and store the Eigenvectors specific to the
expressions. The Eigenvectors for the test images were also computed, and
finally the input facial image was recognized when similarity was obtained by
calculating the minimum Euclidean distance between the test image and the
different expressions.
</summary>
    <author>
      <name>Jeemoni Kalita</name>
    </author>
    <author>
      <name>Karen Das</name>
    </author>
    <link href="http://arxiv.org/abs/1303.0635v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1303.0635v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1303.4840v1</id>
    <updated>2013-03-20T04:59:08Z</updated>
    <published>2013-03-20T04:59:08Z</published>
    <title>Asynchronous Cellular Operations on Gray Images Extracting Topographic
  Shape Features and Their Relations</title>
    <summary>  A variety of operations of cellular automata on gray images is presented. All
operations are of a wave-front nature finishing in a stable state. They are
used to extract shape descripting gray objects robust to a variety of pattern
distortions. Topographic terms are used: "lakes", "dales", "dales of dales". It
is shown how mutual object relations like "above" can be presented in terms of
gray image analysis and how it can be used for character classification and for
gray pattern decomposition. Algorithms can be realized with a parallel
asynchronous architecture. Keywords: Pattern Recognition, Mathematical
Morphology, Cellular Automata, Wave-front Algorithms, Gray Image Analysis,
Topographical Shape Descriptors, Asynchronous Parallel Processors, Holes,
Cavities, Concavities, Graphs.
</summary>
    <author>
      <name>Igor Polkovnikov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages, 37 figures, 10 function classes</arxiv:comment>
    <link href="http://arxiv.org/abs/1303.4840v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1303.4840v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1303.4866v1</id>
    <updated>2013-03-20T08:15:07Z</updated>
    <published>2013-03-20T08:15:07Z</published>
    <title>A Robust Rapid Approach to Image Segmentation with Optimal Thresholding
  and Watershed Transform</title>
    <summary>  This paper describes a novel method for partitioning image into meaningful
segments. The proposed method employs watershed transform, a well-known image
segmentation technique. Along with that, it uses various auxiliary schemes such
as Binary Gradient Masking, dilation which segment the image in proper way. The
algorithm proposed in this paper considers all these methods in effective way
and takes little time. It is organized in such a manner so that it operates on
input image adaptively. Its robustness and efficiency makes it more convenient
and suitable for all types of images.
</summary>
    <author>
      <name>Ankit R. Chadha</name>
    </author>
    <author>
      <name>Neha S. Satam</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5120/10949-5908</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5120/10949-5908" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Applications (2013)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1303.4866v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1303.4866v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1303.6926v1</id>
    <updated>2013-03-27T18:57:12Z</updated>
    <published>2013-03-27T18:57:12Z</published>
    <title>A Comparative Analysis on the Applicability of Entropy in remote sensing</title>
    <summary>  Entropy is the measure of uncertainty in any data and is adopted for
maximisation of mutual information in many remote sensing operations. The
availability of wide entropy variations motivated us for an investigation over
the suitability preference of these versions to specific operations.
Methodologies were implemented in Matlab and were enhanced with entropy
variations. Evaluation of various implementations was based on different
statistical parameters with reference to the study area The popular available
versions like Tsalli's, Shanon's, and Renyi's entropies were analysed in
context of various remote sensing operations namely thresholding, clustering
and registration.
</summary>
    <author>
      <name>Dr. S. K. Katiyar</name>
    </author>
    <author>
      <name>Arun P. V.</name>
    </author>
    <link href="http://arxiv.org/abs/1303.6926v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1303.6926v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.0019v1</id>
    <updated>2013-03-29T20:32:04Z</updated>
    <published>2013-03-29T20:32:04Z</published>
    <title>Age group and gender recognition from human facial images</title>
    <summary>  This work presents an automatic human gender and age group recognition system
based on human facial images. It makes an extensive experiment with row pixel
intensity valued features and Discrete Cosine Transform (DCT) coefficient
features with Principal Component Analysis and k-Nearest Neighbor
classification to identify the best recognition approach. The final results
show approaches using DCT coefficient outperform their counter parts resulting
in a 99% correct gender recognition rate and 68% correct age group recognition
rate (considering four distinct age groups) in unseen test images. Detailed
experimental settings and obtained results are clearly presented and explained
in this report.
</summary>
    <author>
      <name>Tizita Nesibu Shewaye</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, October, 2012</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Ethiopian Society of Electrical Engineers 6th Scientific
  Conference on Electrical Engineering (CEE-2012)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1304.0019v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.0019v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.1022v1</id>
    <updated>2013-04-03T17:34:20Z</updated>
    <published>2013-04-03T17:34:20Z</published>
    <title>A software for aging faces applied to ancient marble busts</title>
    <summary>  The study and development of software able to show the effect of aging of
faces is one of the tasks of face recognition technologies. Some software
solutions are used for investigations, some others to show the effects of drugs
on healthy appearance, however some other applications can be proposed for the
analysis of visual arts. Here we use a freely available software, which is
providing interesting results, for the comparison of ancient marble busts. An
analysis of Augustus busts is proposed.
</summary>
    <author>
      <name>Amelia Carolina Sparavigna</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Image processing. Aging faces. Freely available software. Ancient
  marble busts. Augustus</arxiv:comment>
    <link href="http://arxiv.org/abs/1304.1022v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.1022v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.1568v1</id>
    <updated>2013-04-04T22:07:27Z</updated>
    <published>2013-04-04T22:07:27Z</published>
    <title>Multiscale Fractal Descriptors Applied to Texture Classification</title>
    <summary>  This work proposes the combination of multiscale transform with fractal
descriptors employed in the classification of gray-level texture images. We
apply the space-scale transform (derivative + Gaussian filter) over the
Bouligand-Minkowski fractal descriptors, followed by a threshold over the
filter response, aiming at attenuating noise effects caused by the final part
of this response. The method is tested in the classification of a well-known
data set (Brodatz) and compared with other classical texture descriptor
techniques. The results demonstrate the advantage of the proposed approach,
achieving a higher success rate with a reduced amount of descriptors.
</summary>
    <author>
      <name>João Batista Florindo</name>
    </author>
    <author>
      <name>Odemir Martinez Bruno</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1088/1742-6596/410/1/012022</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1088/1742-6596/410/1/012022" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 4 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Physics: Conference Series, 410, 012022, 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1304.1568v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.1568v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.1930v1</id>
    <updated>2013-04-06T19:24:40Z</updated>
    <published>2013-04-06T19:24:40Z</published>
    <title>Client-Driven Content Extraction Associated with Table</title>
    <summary>  The goal of the project is to extract content within table in document images
based on learnt patterns. Real-world users i.e., clients first provide a set of
key fields within the table which they think are important. These are first
used to represent the graph where nodes are labelled with semantics including
other features and edges are attributed with relations. Attributed relational
graph (ARG) is then employed to mine similar graphs from a document image. Each
mined graph will represent an item within the table, and hence a set of such
graphs will compose a table. We have validated the concept by using a
real-world industrial problem.
</summary>
    <author>
      <name>K. C. Santosh</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LORIA</arxiv:affiliation>
    </author>
    <author>
      <name>Abdel Belaïd</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LORIA</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Machine Vision Applications (2013)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1304.1930v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.1930v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.5212v1</id>
    <updated>2013-04-18T18:41:47Z</updated>
    <published>2013-04-18T18:41:47Z</published>
    <title>Object Tracking in Videos: Approaches and Issues</title>
    <summary>  Mobile object tracking has an important role in the computer vision
applications. In this paper, we use a tracked target-based taxonomy to present
the object tracking algorithms. The tracked targets are divided into three
categories: points of interest, appearance and silhouette of mobile objects.
Advantages and limitations of the tracking approaches are also analyzed to find
the future directions in the object tracking domain.
</summary>
    <author>
      <name>Duc Phu Chau</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Sophia Antipolis</arxiv:affiliation>
    </author>
    <author>
      <name>François Bremond</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Sophia Antipolis</arxiv:affiliation>
    </author>
    <author>
      <name>Monique Thonnat</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Sophia Antipolis</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">The International Workshop "Rencontres UNS-UD" (RUNSUD) (2013)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1304.5212v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.5212v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.6933v2</id>
    <updated>2013-04-26T08:35:18Z</updated>
    <published>2013-04-25T15:14:42Z</published>
    <title>Digit Recognition in Handwritten Weather Records</title>
    <summary>  This paper addresses the automatic recognition of handwritten temperature
values in weather records. The localization of table cells is based on line
detection using projection profiles. Further, a stroke-preserving line removal
method which is based on gradient images is proposed. The presented digit
recognition utilizes features which are extracted using a set of filters and a
Support Vector Machine classifier. It was evaluated on the MNIST and the USPS
dataset and our own database with about 17,000 RGB digit images. An accuracy of
99.36% per digit is achieved for the entire system using a set of 84 weather
records.
</summary>
    <author>
      <name>Manuel Keglevic</name>
    </author>
    <author>
      <name>Robert Sablatnig</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Part of the OAGM/AAPR 2013 proceedings (arXiv:1304.1876), 8 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1304.6933v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.6933v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.6990v1</id>
    <updated>2013-04-25T19:44:26Z</updated>
    <published>2013-04-25T19:44:26Z</published>
    <title>Euclidean Upgrade from a Minimal Number of Segments</title>
    <summary>  In this paper, we propose an algebraic approach to upgrade a projective
reconstruction to a Euclidean one, and aim at computing the rectifying
homography from a minimal number of 9 segments of known length. Constraints are
derived from these segments which yield a set of polynomial equations that we
solve by means of Gr\"obner bases. We explain how a solver for such a system of
equations can be constructed from simplified template data. Moreover, we
present experiments that demonstrate that the given problem can be solved in
this way.
</summary>
    <author>
      <name>Tanja Schilling</name>
    </author>
    <author>
      <name>Tomas Pajdla</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Part of the OAGM/AAPR 2013 proceedings (arXiv:1304.1876)</arxiv:comment>
    <link href="http://arxiv.org/abs/1304.6990v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.6990v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.7153v1</id>
    <updated>2013-04-26T13:10:22Z</updated>
    <published>2013-04-26T13:10:22Z</published>
    <title>A Convex Approach for Image Hallucination</title>
    <summary>  In this paper we propose a global convex approach for image hallucination.
Altering the idea of classical multi image super resolution (SU) systems to
single image SU, we incorporate aligned images to hallucinate the output. Our
work is based on the paper of Tappen et al. where they use a non-convex model
for image hallucination. In comparison we formulate a convex primal
optimization problem and derive a fast converging primal-dual algorithm with a
global optimal solution. We use a database with face images to incorporate
high-frequency details to the high-resolution output. We show that we can
achieve state-of-the-art results by using a convex approach.
</summary>
    <author>
      <name>Peter Innerhofer</name>
    </author>
    <author>
      <name>Thomas Pock</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">submitted to \"OAGM-AAPR 2013, 8 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1304.7153v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.7153v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.7184v1</id>
    <updated>2013-04-26T14:33:52Z</updated>
    <published>2013-04-26T14:33:52Z</published>
    <title>Reading Ancient Coin Legends: Object Recognition vs. OCR</title>
    <summary>  Standard OCR is a well-researched topic of computer vision and can be
considered solved for machine-printed text. However, when applied to
unconstrained images, the recognition rates drop drastically. Therefore, the
employment of object recognition-based techniques has become state of the art
in scene text recognition applications. This paper presents a scene text
recognition method tailored to ancient coin legends and compares the results
achieved in character and word recognition experiments to a standard OCR
engine. The conducted experiments show that the proposed method outperforms the
standard OCR engine on a set of 180 cropped coin legend words.
</summary>
    <author>
      <name>Albert Kavelar</name>
    </author>
    <author>
      <name>Sebastian Zambanini</name>
    </author>
    <author>
      <name>Martin Kampel</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Part of the OAGM/AAPR 2013 proceedings (arXiv:1304.1876)</arxiv:comment>
    <link href="http://arxiv.org/abs/1304.7184v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.7184v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.7399v1</id>
    <updated>2013-04-27T19:24:30Z</updated>
    <published>2013-04-27T19:24:30Z</published>
    <title>Bingham Procrustean Alignment for Object Detection in Clutter</title>
    <summary>  A new system for object detection in cluttered RGB-D images is presented. Our
main contribution is a new method called Bingham Procrustean Alignment (BPA) to
align models with the scene. BPA uses point correspondences between oriented
features to derive a probability distribution over possible model poses. The
orientation component of this distribution, conditioned on the position, is
shown to be a Bingham distribution. This result also applies to the classic
problem of least-squares alignment of point sets, when point features are
orientation-less, and gives a principled, probabilistic way to measure pose
uncertainty in the rigid alignment problem. Our detection system leverages BPA
to achieve more reliable object detections in clutter.
</summary>
    <author>
      <name>Jared Glover</name>
    </author>
    <author>
      <name>Sanja Popovic</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to IROS 2013</arxiv:comment>
    <link href="http://arxiv.org/abs/1304.7399v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.7399v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1305.0020v1</id>
    <updated>2013-04-30T20:28:37Z</updated>
    <published>2013-04-30T20:28:37Z</published>
    <title>Image Compression By Embedding Five Modulus Method Into JPEG</title>
    <summary>  The standard JPEG format is almost the optimum format in image compression.
The compression ratio in JPEG sometimes reaches 30:1. The compression ratio of
JPEG could be increased by embedding the Five Modulus Method (FMM) into the
JPEG algorithm. The novel algorithm gives twice the time as the standard JPEG
algorithm or more. The novel algorithm was called FJPEG (Five-JPEG). The
quality of the reconstructed image after compression is approximately
approaches the JPEG. Standard test images have been used to support and
implement the suggested idea in this paper and the error metrics have been
computed and compared with JPEG.
</summary>
    <author>
      <name>Firas A. Jassim</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5121/sipij.2013.4203</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5121/sipij.2013.4203" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 6 tables, 6 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Signal &amp; Image Processing : An International Journal (SIPIJ)
  Vol.4, No.2, April 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1305.0020v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1305.0020v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1305.3939v1</id>
    <updated>2013-05-16T21:25:54Z</updated>
    <published>2013-05-16T21:25:54Z</published>
    <title>Analysis Of Interest Points Of Curvelet Coefficients Contributions Of
  Microscopic Images And Improvement Of Edges</title>
    <summary>  This paper focuses on improved edge model based on Curvelet coefficients
analysis. Curvelet transform is a powerful tool for multiresolution
representation of object with anisotropic edge. Curvelet coefficients
contributions have been analyzed using Scale Invariant Feature Transform
(SIFT), commonly used to study local structure in images. The permutation of
Curvelet coefficients from original image and edges image obtained from
gradient operator is used to improve original edges. Experimental results show
that this method brings out details on edges when the decomposition scale
increases.
</summary>
    <author>
      <name>A. Djimeli</name>
    </author>
    <author>
      <name>D. Tchiotsop</name>
    </author>
    <author>
      <name>R. Tchinda</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5121/sipij.2013.4201</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5121/sipij.2013.4201" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 7 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Signal &amp; Image Processing : An International Journal (SIPIJ)
  Vol.4, No.2, April 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1305.3939v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1305.3939v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1305.4298v1</id>
    <updated>2013-05-18T20:45:40Z</updated>
    <published>2013-05-18T20:45:40Z</published>
    <title>Blockwise SURE Shrinkage for Non-Local Means</title>
    <summary>  In this letter, we investigate the shrinkage problem for the non-local means
(NLM) image denoising. In particular, we derive the closed-form of the optimal
blockwise shrinkage for NLM that minimizes the Stein's unbiased risk estimator
(SURE). We also propose a constant complexity algorithm allowing fast blockwise
shrinkage. Simulation results show that the proposed blockwise shrinkage method
improves NLM performance in attaining higher peak signal noise ratio (PSNR) and
structural similarity index (SSIM), and makes NLM more robust against parameter
changes. Similar ideas can be applicable to other patchwise image denoising
techniques.
</summary>
    <author>
      <name>Yue Wu</name>
    </author>
    <author>
      <name>Brian Tracey</name>
    </author>
    <author>
      <name>Premkumar Natarajan</name>
    </author>
    <author>
      <name>Joseph P. Noonan</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.sigpro.2014.01.007</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.sigpro.2014.01.007" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Signal Processing 103 (2014): 45-59</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1305.4298v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1305.4298v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1305.5160v1</id>
    <updated>2013-05-22T15:00:43Z</updated>
    <published>2013-05-22T15:00:43Z</published>
    <title>A novel automatic thresholding segmentation method with local adaptive
  thresholds</title>
    <summary>  A novel method for segmenting bright objects from dark background for
grayscale image is proposed. The concept of this method can be stated simply
as: to pick out the local-thinnest bands on the grayscale grade-map. It turns
out to be a threshold-based method with local adaptive thresholds, where each
local threshold is determined by requiring the average normal-direction
gradient on the object boundary to be local minimal. The method is highly
automatic and the segmentation mimics a man's natural expectation even the
object boundaries are fuzzy.
</summary>
    <author>
      <name>Bo Xiao</name>
    </author>
    <author>
      <name>Yuefeng Jing</name>
    </author>
    <author>
      <name>Yonghong Guan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1305.5160v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1305.5160v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1305.6883v1</id>
    <updated>2013-05-29T17:58:04Z</updated>
    <published>2013-05-29T17:58:04Z</published>
    <title>Rotation invariants of two dimensional curves based on iterated
  integrals</title>
    <summary>  We introduce a novel class of rotation invariants of two dimensional curves
based on iterated integrals. The invariants we present are in some sense
complete and we describe an algorithm to calculate them, giving explicit
computations up to order six. We present an application to online
(stroke-trajectory based) character recognition. This seems to be the first
time in the literature that the use of iterated integrals of a curve is
proposed for (invariant) feature extraction in machine learning applications.
</summary>
    <author>
      <name>Joscha Diehl</name>
    </author>
    <link href="http://arxiv.org/abs/1305.6883v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1305.6883v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1306.1462v1</id>
    <updated>2013-06-06T16:30:57Z</updated>
    <published>2013-06-06T16:30:57Z</published>
    <title>K-Algorithm A Modified Technique for Noise Removal in Handwritten
  Documents</title>
    <summary>  OCR has been an active research area since last few decades. OCR performs the
recognition of the text in the scanned document image and converts it into
editable form. The OCR process can have several stages like pre-processing,
segmentation, recognition and post processing. The pre-processing stage is a
crucial stage for the success of OCR, which mainly deals with noise removal. In
the present paper, a modified technique for noise removal named as K-Algorithm
has been proposed, which has two stages as filtering and binarization. The
proposed technique shows improvised results in comparison to median filtering
technique.
</summary>
    <author>
      <name>Kanika Bansal</name>
    </author>
    <author>
      <name>Rajiv Kumar</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5121/ijist.2013.3301</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5121/ijist.2013.3301" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Information Sciences and Techniques, May
  2013, Volume 3, Number 3</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1306.1462v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1306.1462v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1306.1676v1</id>
    <updated>2013-06-07T09:55:29Z</updated>
    <published>2013-06-07T09:55:29Z</published>
    <title>Algebraic foundations of split hypercomplex nonlinear adaptive filtering</title>
    <summary>  A split hypercomplex learning algorithm for the training of nonlinear finite
impulse response adaptive filters for the processing of hypercomplex signals of
any dimension is proposed. The derivation strictly takes into account the laws
of hypercomplex algebra and hypercomplex calculus, some of which have been
neglected in existing learning approaches (e.g. for quaternions). Already in
the case of quaternions we can predict improvements in performance of
hypercomplex processes. The convergence of the proposed algorithms is
rigorously analyzed.
  Keywords: Quaternionic adaptive filtering, Hypercomplex adaptive filtering,
Nonlinear adaptive filtering, Hypercomplex Multilayer Perceptron, Clifford
geometric algebra
</summary>
    <author>
      <name>Eckhard Hitzer</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1002/mma.2660</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1002/mma.2660" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 1 figure</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Mathematical Methods in the Applied Sciences, Volume 36, Issue 9,
  pages 1042-1055, June 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1306.1676v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1306.1676v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.RA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="60G35, 15A66" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1306.2159v1</id>
    <updated>2013-06-10T10:35:26Z</updated>
    <published>2013-06-10T10:35:26Z</published>
    <title>Image segmentation by optimal and hierarchical piecewise constant
  approximations</title>
    <summary>  Piecewise constant image approximations of sequential number of segments or
clusters of disconnected pixels are treated. The method of majorizing of
optimal approximation sequence by hierarchical sequence of image approximations
is proposed. A generalization for multidimensional case of color and
multispectral images is foreseen.
</summary>
    <author>
      <name>M. Kharinov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 5 formulas, 3 figures, 1 table, submitted to the Eleventh
  International Conference on Pattern Recognition and Image Analysis September
  23-28, 2013, Samara, Russia</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. of the 11-th. Int. Conf. (PRIA-11-2013), Russia, Samara,
  September 23-28, 2013. Vol. 1, pp. 213-216</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1306.2159v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1306.2159v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1306.2624v1</id>
    <updated>2013-06-11T19:41:45Z</updated>
    <published>2013-06-11T19:41:45Z</published>
    <title>Stopping Criterion for the Mean Shift Iterative Algorithm</title>
    <summary>  Image segmentation is a critical step in computer vision tasks constituting
an essential issue for pattern recognition and visual interpretation. In this
paper, we propose a new stopping criterion for the mean shift iterative
algorithm by using images defined in Zn ring, with the goal of reaching a
better segmentation. We carried out also a study on the weak and strong of
equivalence classes between two images. An analysis on the convergence with
this new stopping criterion is carried out too.
</summary>
    <author>
      <name>Yasel Garcés Suárez</name>
    </author>
    <author>
      <name>Esley Torres</name>
    </author>
    <author>
      <name>Osvaldo Pereira</name>
    </author>
    <author>
      <name>Claudia Pérez</name>
    </author>
    <author>
      <name>Roberto Rogríguez</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Have 8 pages. Is the first version of the more general paper</arxiv:comment>
    <link href="http://arxiv.org/abs/1306.2624v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1306.2624v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.RA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1306.3032v1</id>
    <updated>2013-06-13T06:28:07Z</updated>
    <published>2013-06-13T06:28:07Z</published>
    <title>A Face-like Structure Detection on Planet and Satellite Surfaces using
  Image Processing</title>
    <summary>  This paper demonstrates that face-like structures are everywhere, and can be
de-tected automatically even with computers. Huge amount of satellite images of
the Earth, the Moon, the Mars are explored and many interesting face-like
structure are detected. Throughout this fact, we believe that science and
technologies can alert people not to easily become an occultist.
</summary>
    <author>
      <name>Kazutaka Kurihara</name>
    </author>
    <author>
      <name>Masakazu Takasu</name>
    </author>
    <author>
      <name>Kazuhiro Sasao</name>
    </author>
    <author>
      <name>Hal Seki</name>
    </author>
    <author>
      <name>Takayuki Narabu</name>
    </author>
    <author>
      <name>Mitsuo Yamamoto</name>
    </author>
    <author>
      <name>Satoshi Iida</name>
    </author>
    <author>
      <name>Hiroyuki Yamamoto</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ACE 2013, LNCS 8253, Springer, pp. 564-567, 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1306.3032v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1306.3032v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1306.4345v1</id>
    <updated>2013-06-18T20:38:07Z</updated>
    <published>2013-06-18T20:38:07Z</published>
    <title>An Overview of the Research on Texture Based Plant Leaf Classification</title>
    <summary>  Plant classification has a broad application prospective in agriculture and
medicine, and is especially significant to the biology diversity research. As
plants are vitally important for environmental protection, it is more important
to identify and classify them accurately. Plant leaf classification is a
technique where leaf is classified based on its different morphological
features. The goal of this paper is to provide an overview of different aspects
of texture based plant leaf classification and related things. At last we will
be concluding about the efficient method i.e. the method that gives better
performance compared to the other methods.
</summary>
    <author>
      <name>Vishakha Metre</name>
    </author>
    <author>
      <name>Jayshree Ghorpade</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages,5 figures and 3 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1306.4345v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1306.4345v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1306.6263v2</id>
    <updated>2016-04-21T00:04:34Z</updated>
    <published>2013-06-26T14:56:00Z</published>
    <title>Persian Heritage Image Binarization Competition (PHIBC 2012)</title>
    <summary>  The first competition on the binarization of historical Persian documents and
manuscripts (PHIBC 2012) has been organized in conjunction with the first
Iranian conference on pattern recognition and image analysis (PRIA 2013). The
main objective of PHIBC 2012 is to evaluate performance of the binarization
methodologies, when applied on the Persian heritage images. This paper provides
a report on the methodology and performance of the three submitted algorithms
based on evaluation measures has been used.
</summary>
    <author>
      <name>Seyed Morteza Ayatollahi</name>
    </author>
    <author>
      <name>Hossein Ziaei Nafchi</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/PRIA.2013.6528442</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/PRIA.2013.6528442" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 2 figures, conference</arxiv:comment>
    <link href="http://arxiv.org/abs/1306.6263v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1306.6263v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.0998v3</id>
    <updated>2014-07-01T00:24:20Z</updated>
    <published>2013-07-03T12:59:53Z</published>
    <title>A Unified Framework of Elementary Geometric Transformation
  Representation</title>
    <summary>  As an extension of projective homology, stereohomology is proposed via an
extension of Desargues theorem and the extended Desargues configuration.
Geometric transformations such as reflection, translation, central symmetry,
central projection, parallel projection, shearing, central dilation, scaling,
and so on are all included in stereohomology and represented as
Householder-Chen elementary matrices. Hence all these geometric transformations
are called elementary. This makes it possible to represent these elementary
geometric transformations in homogeneous square matrices independent of a
particular choice of coordinate system.
</summary>
    <author>
      <name>F. Lu</name>
    </author>
    <author>
      <name>Z. Chen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">26 pages, 11 figures, 1 table, 21 referneces</arxiv:comment>
    <link href="http://arxiv.org/abs/1307.0998v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.0998v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.2440v1</id>
    <updated>2013-07-09T13:14:11Z</updated>
    <published>2013-07-09T13:14:11Z</published>
    <title>Image Fusion Technologies In Commercial Remote Sensing Packages</title>
    <summary>  Several remote sensing software packages are used to the explicit purpose of
analyzing and visualizing remotely sensed data, with the developing of remote
sensing sensor technologies from last ten years. Accord-ing to literature, the
remote sensing is still the lack of software tools for effective information
extraction from remote sensing data. So, this paper provides a state-of-art of
multi-sensor image fusion technologies as well as review on the quality
evaluation of the single image or fused images in the commercial remote sensing
pack-ages. It also introduces program (ALwassaiProcess) developed for image
fusion and classification.
</summary>
    <author>
      <name>Firouz Abdullah Al-Wassai</name>
    </author>
    <author>
      <name>N. V. Kalyankar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Keywords: Commercial Processing Systems, Image Fusion, quality
  evaluation</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Global Research in Computer Science, 4 (5), May 2013,
  44-50</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1307.2440v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.2440v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.3043v2</id>
    <updated>2013-09-13T15:48:23Z</updated>
    <published>2013-07-11T10:07:19Z</published>
    <title>A two-layer Conditional Random Field for the classification of partially
  occluded objects</title>
    <summary>  Conditional Random Fields (CRF) are among the most popular techniques for
image labelling because of their flexibility in modelling dependencies between
the labels and the image features. This paper proposes a novel CRF-framework
for image labeling problems which is capable to classify partially occluded
objects. Our approach is evaluated on aerial near-vertical images as well as on
urban street-view images and compared with another methods.
</summary>
    <author>
      <name>Sergey Kosov</name>
    </author>
    <author>
      <name>Pushmeet Kohli</name>
    </author>
    <author>
      <name>Franz Rottensteiner</name>
    </author>
    <author>
      <name>Christian Heipke</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Conference Submission</arxiv:comment>
    <link href="http://arxiv.org/abs/1307.3043v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.3043v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.3271v1</id>
    <updated>2013-07-11T21:01:23Z</updated>
    <published>2013-07-11T21:01:23Z</published>
    <title>Fuzzy Fibers: Uncertainty in dMRI Tractography</title>
    <summary>  Fiber tracking based on diffusion weighted Magnetic Resonance Imaging (dMRI)
allows for noninvasive reconstruction of fiber bundles in the human brain. In
this chapter, we discuss sources of error and uncertainty in this technique,
and review strategies that afford a more reliable interpretation of the
results. This includes methods for computing and rendering probabilistic
tractograms, which estimate precision in the face of measurement noise and
artifacts. However, we also address aspects that have received less attention
so far, such as model selection, partial voluming, and the impact of
parameters, both in preprocessing and in fiber tracking itself. We conclude by
giving impulses for future research.
</summary>
    <author>
      <name>Thomas Schultz</name>
    </author>
    <author>
      <name>Anna Vilanova</name>
    </author>
    <author>
      <name>Ralph Brecheisen</name>
    </author>
    <author>
      <name>Gordon Kindlmann</name>
    </author>
    <link href="http://arxiv.org/abs/1307.3271v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.3271v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.6549v1</id>
    <updated>2013-07-19T10:57:31Z</updated>
    <published>2013-07-19T10:57:31Z</published>
    <title>Making Laplacians commute</title>
    <summary>  In this paper, we construct multimodal spectral geometry by finding a pair of
closest commuting operators (CCO) to a given pair of Laplacians. The CCOs are
jointly diagonalizable and hence have the same eigenbasis. Our construction
naturally extends classical data analysis tools based on spectral geometry,
such as diffusion maps and spectral clustering. We provide several synthetic
and real examples of applications in dimensionality reduction, shape analysis,
and clustering, demonstrating that our method better captures the inherent
structure of multi-modal data.
</summary>
    <author>
      <name>Michael M. Bronstein</name>
    </author>
    <author>
      <name>Klaus Glashoff</name>
    </author>
    <author>
      <name>Terry A. Loring</name>
    </author>
    <link href="http://arxiv.org/abs/1307.6549v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.6549v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.SP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.6962v2</id>
    <updated>2013-12-01T20:46:41Z</updated>
    <published>2013-07-26T09:06:44Z</published>
    <title>Reduced egomotion estimation drift using omnidirectional views</title>
    <summary>  Estimation of camera motion from a given image sequence becomes degraded as
the length of the sequence increases. In this letter, this phenomenon is
demonstrated and an approach to increase the estimation accuracy is proposed.
The proposed method uses an omnidirectional camera in addition to the
perspective one and takes advantage of its enlarged view by exploiting the
correspondences between the omnidirectional and perspective images. Simulated
and real image experiments show that the proposed approach improves the
estimation accuracy.
</summary>
    <author>
      <name>Yalin Bastanlar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Another publisher does not want this article to be shared at
  arxiv.org in order to publish it</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Electronic Letters on Computer Vision and Image Analysis,
  vol.13(3), p.1-12, 2014</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1307.6962v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.6962v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.7848v1</id>
    <updated>2013-07-30T07:18:20Z</updated>
    <published>2013-07-30T07:18:20Z</published>
    <title>An Integrated System for 3D Gaze Recovery and Semantic Analysis of Human
  Attention</title>
    <summary>  This work describes a computer vision system that enables pervasive mapping
and monitoring of human attention. The key contribution is that our methodology
enables full 3D recovery of the gaze pointer, human view frustum and associated
human centered measurements directly into an automatically computed 3D model in
real-time. We apply RGB-D SLAM and descriptor matching methodologies for the 3D
modeling, localization and fully automated annotation of ROIs (regions of
interest) within the acquired 3D model. This innovative methodology will open
new avenues for attention studies in real world environments, bringing new
potential into automated processing for human factors technologies.
</summary>
    <author>
      <name>Lucas Paletta</name>
    </author>
    <author>
      <name>Katrin Santner</name>
    </author>
    <author>
      <name>Gerald Fritz</name>
    </author>
    <link href="http://arxiv.org/abs/1307.7848v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.7848v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.8233v1</id>
    <updated>2013-07-31T06:24:28Z</updated>
    <published>2013-07-31T06:24:28Z</published>
    <title>A Prototyping Environment for Integrated Artificial Attention Systems</title>
    <summary>  Artificial visual attention systems aim to support technical systems in
visual tasks by applying the concepts of selective attention observed in humans
and other animals. Such systems are typically evaluated against ground truth
obtained from human gaze-data or manually annotated test images. When applied
to robotics, the systems are required to be adaptable to the target system.
Here, we describe a flexible environment based on a robotic middleware layer
allowing the development and testing of attention-guided vision systems. In
such a framework, the systems can be tested with input from various sources,
different attention algorithms at the core, and diverse subsequent tasks.
</summary>
    <author>
      <name>Jan Tünnermann</name>
    </author>
    <author>
      <name>Markus Hennig</name>
    </author>
    <author>
      <name>Michael Silbernagel</name>
    </author>
    <author>
      <name>Bärbel Mertsching</name>
    </author>
    <link href="http://arxiv.org/abs/1307.8233v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.8233v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.8405v1</id>
    <updated>2013-07-31T17:53:10Z</updated>
    <published>2013-07-31T17:53:10Z</published>
    <title>Who and Where: People and Location Co-Clustering</title>
    <summary>  In this paper, we consider the clustering problem on images where each image
contains patches in people and location domains. We exploit the correlation
between people and location domains, and proposed a semi-supervised
co-clustering algorithm to cluster images. Our algorithm updates the
correlation links at the runtime, and produces clustering in both domains
simultaneously. We conduct experiments in a manually collected dataset and a
Flickr dataset. The result shows that the such correlation improves the
clustering performance.
</summary>
    <author>
      <name>Zixuan Wang</name>
    </author>
    <author>
      <name>Jinyun Yan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2013 IEEE International Conference on Image Processing</arxiv:comment>
    <link href="http://arxiv.org/abs/1307.8405v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.8405v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1308.2292v1</id>
    <updated>2013-08-10T08:19:02Z</updated>
    <published>2013-08-10T08:19:02Z</published>
    <title>Fast image segmentation and restoration using parametric curve evolution
  with junctions and topology changes</title>
    <summary>  Curve evolution schemes for image segmentation based on a region based
contour model allowing for junctions, vector-valued images and topology changes
are introduced. Together with an a posteriori denoising in the segmented
homogeneous regions this leads to a fast and efficient method for image
segmentation and restoration. An uneven spread of mesh points is avoided by
using the tangential degrees of freedom. Several numerical simulations on
artificial test problems and on real images illustrate the performance of the
method.
</summary>
    <author>
      <name>Heike Benninghoff</name>
    </author>
    <author>
      <name>Harald Garcke</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">26 pages, 16 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1308.2292v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1308.2292v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="94A08, 68U10, 65K10, 35K55, 49Q10" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1308.4902v1</id>
    <updated>2013-08-22T15:38:15Z</updated>
    <published>2013-08-22T15:38:15Z</published>
    <title>A review on handwritten character and numeral recognition for Roman,
  Arabic, Chinese and Indian scripts</title>
    <summary>  There are a lot of intensive researches on handwritten character recognition
(HCR) for almost past four decades. The research has been done on some of
popular scripts such as Roman, Arabic, Chinese and Indian. In this paper we
present a review on HCR work on the four popular scripts. We have summarized
most of the published paper from 2005 to recent and also analyzed the various
methods in creating a robust HCR system. We also added some future direction of
research on HCR.
</summary>
    <author>
      <name>Aini Najwa Azmi</name>
    </author>
    <author>
      <name>Dewi Nasien</name>
    </author>
    <author>
      <name>Siti Mariyam Shamsuddin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of advanced studies in Computers, Science &amp;
  Engineering (IJASCSE), Volume 2, Issue 4, 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1308.4902v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1308.4902v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1308.5315v1</id>
    <updated>2013-08-24T11:07:05Z</updated>
    <published>2013-08-24T11:07:05Z</published>
    <title>Edge-detection applied to moving sand dunes on Mars</title>
    <summary>  Here we discuss the application of an edge detection filter, the Sobel filter
of GIMP, to the recently discovered motion of some sand dunes on Mars. The
filter allows a good comparison of an image HiRISE of 2007 and an image of 1999
recorded by the Mars Global Surveyor of the dunes in the Nili Patera caldera,
measuring therefore the motion of the dunes on a longer period of time than
that previously investigated.
</summary>
    <author>
      <name>Amelia Carolina Sparavigna</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.18483/ijSci.251</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.18483/ijSci.251" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Keywords: Edge detection, Sobel filter, GIMP, Image processing,
  Google Mars, Dune motion, Mars Reconnaissance Orbiter, Mars Global Surveyor;
  Ref.14 available at
  http://www.scribd.com/doc/162390676/Moving-Sand-Dunes-on-Mars</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Sciences, 2013, 2(8):102-104</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1308.5315v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1308.5315v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1308.5876v1</id>
    <updated>2013-08-27T13:57:16Z</updated>
    <published>2013-08-27T13:57:16Z</published>
    <title>Hierarchized block wise image approximation by greedy pursuit strategies</title>
    <summary>  An approach for effective implementation of greedy selection methodologies,
to approximate an image partitioned into blocks, is proposed. The method is
specially designed for approximating partitions on a transformed image. It
evolves by selecting, at each iteration step, i) the elements for approximating
each of the blocks partitioning the image and ii) the hierarchized sequence in
which the blocks are approximated to reach the required global condition on
sparsity.
</summary>
    <author>
      <name>Laura Rebollo-Neira</name>
    </author>
    <author>
      <name>Ryszard Maciol</name>
    </author>
    <author>
      <name>Shabnam Bibi</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/LSP.2013.2283510</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/LSP.2013.2283510" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages. An example and the computing routines for implementing the
  approach are available on
  http://www.nonlinear-approx.info/examples/node0.html</arxiv:comment>
    <link href="http://arxiv.org/abs/1308.5876v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1308.5876v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68U10, 94A08" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.1.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1309.0123v2</id>
    <updated>2013-10-02T01:53:49Z</updated>
    <published>2013-08-31T14:29:52Z</published>
    <title>A Robust Alternating Direction Method for Constrained Hybrid Variational
  Deblurring Model</title>
    <summary>  In this work, a new constrained hybrid variational deblurring model is
developed by combining the non-convex first- and second-order total variation
regularizers. Moreover, a box constraint is imposed on the proposed model to
guarantee high deblurring performance. The developed constrained hybrid
variational model could achieve a good balance between preserving image details
and alleviating ringing artifacts. In what follows, we present the
corresponding numerical solution by employing an iteratively reweighted
algorithm based on alternating direction method of multipliers. The
experimental results demonstrate the superior performance of the proposed
method in terms of quantitative and qualitative image quality assessments.
</summary>
    <author>
      <name>Ryan Wen Liu</name>
    </author>
    <author>
      <name>Tian Xu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1309.0123v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1309.0123v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65K10, 68U10" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.4.4; G.1.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1309.3418v1</id>
    <updated>2013-09-13T10:12:22Z</updated>
    <published>2013-09-13T10:12:22Z</published>
    <title>A Novel Approach in detecting pose orientation of a 3D face required for
  face</title>
    <summary>  In this paper we present a novel approach that takes as input a 3D image and
gives as output its pose i.e. it tells whether the face is oriented with
respect the X, Y or Z axes with angles of rotation up to 40 degree. All the
experiments have been performed on the FRAV3D Database. After applying the
proposed algorithm to the 3D facial surface we have obtained i.e. on 848 3D
face images our method detected the pose correctly for 566 face images,thus
giving an approximately 67 % of correct pose detection.
</summary>
    <author>
      <name>Parama Bagchi</name>
    </author>
    <author>
      <name>Debotosh Bhattacharjee</name>
    </author>
    <author>
      <name>Mita Nasipuri</name>
    </author>
    <author>
      <name>Dipak Kumar Basu</name>
    </author>
    <link href="http://arxiv.org/abs/1309.3418v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1309.3418v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1309.3425v1</id>
    <updated>2013-09-13T11:28:29Z</updated>
    <published>2013-09-13T11:28:29Z</published>
    <title>A method for nose-tip based 3D face registration using maximum intensity
  algorithm</title>
    <summary>  In this paper we present a novel technique of registering 3D images across
pose. In this context, we have taken into account the images which are aligned
across X, Y and Z axes. We have first determined the angle across which the
image is rotated with respect to X, Y and Z axes and then translation is
performed on the images. After testing the proposed method on 472 images from
the FRAV3D database, the method correctly registers 358 images thus giving a
performance rate of 75.84%.
</summary>
    <author>
      <name>Parama Bagchi</name>
    </author>
    <author>
      <name>Debotosh Bhattacharjee</name>
    </author>
    <author>
      <name>Mita Nasipuri</name>
    </author>
    <author>
      <name>Dipak kr. Basu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1309.3425v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1309.3425v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.0310v1</id>
    <updated>2013-10-01T14:15:48Z</updated>
    <published>2013-10-01T14:15:48Z</published>
    <title>A Novel Georeferenced Dataset for Stereo Visual Odometry</title>
    <summary>  In this work, we present a novel dataset for assessing the accuracy of stereo
visual odometry. The dataset has been acquired by a small-baseline stereo rig
mounted on the top of a moving car. The groundtruth is supplied by a consumer
grade GPS device without IMU. Synchronization and alignment between GPS
readings and stereo frames are recovered after the acquisition. We show that
the attained groundtruth accuracy allows to draw useful conclusions in
practice. The presented experiments address influence of camera calibration,
baseline distance and zero-disparity features to the achieved reconstruction
performance.
</summary>
    <author>
      <name>Ivan Krešo</name>
    </author>
    <author>
      <name>Marko Ševrović</name>
    </author>
    <author>
      <name>Siniša Šegvić</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Part of the Proceedings of the Croatian Computer Vision Workshop,
  CCVW 2013, Year 1</arxiv:comment>
    <link href="http://arxiv.org/abs/1310.0310v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.0310v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.2050v1</id>
    <updated>2013-10-08T09:04:34Z</updated>
    <published>2013-10-08T09:04:34Z</published>
    <title>A State Of the Art Report on Research in Multiple RGB-D sensor Setups</title>
    <summary>  That the Microsoft Kinect, an RGB-D sensor, transformed the gaming and end
consumer sector has been anticipated by the developers. That it also impacted
in rigorous computer vision research has probably been a surprise to the whole
community. Shortly before the commercial deployment of its successor, Kinect
One, the research literature fills with resumees and state-of-the art papers to
summarize the development over the past 3 years. This particular report
describes significant research projects which have built on sensoring setups
that include two or more RGB-D sensors in one scene.
</summary>
    <author>
      <name>Kai Berger</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1310.2050v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.2050v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.2053v1</id>
    <updated>2013-10-08T09:16:56Z</updated>
    <published>2013-10-08T09:16:56Z</published>
    <title>The role of RGB-D benchmark datasets: an overview</title>
    <summary>  The advent of the Microsoft Kinect three years ago stimulated not only the
computer vision community for new algorithms and setups to tackle well-known
problems in the community but also sparked the launch of several new benchmark
datasets to which future algorithms can be compared 019 to. This review of the
literature and industry developments concludes that the current RGB-D benchmark
datasets can be useful to determine the accuracy of a variety of applications
of a single or multiple RGB-D sensors.
</summary>
    <author>
      <name>Kai Berger</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1310.2053v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.2053v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.3452v1</id>
    <updated>2013-10-13T06:58:57Z</updated>
    <published>2013-10-13T06:58:57Z</published>
    <title>Dense Scattering Layer Removal</title>
    <summary>  We propose a new model, together with advanced optimization, to separate a
thick scattering media layer from a single natural image. It is able to handle
challenging underwater scenes and images taken in fog and sandstorm, both of
which are with significantly reduced visibility. Our method addresses the
critical issue -- this is, originally unnoticeable impurities will be greatly
magnified after removing the scattering media layer -- with transmission-aware
optimization. We introduce non-local structure-aware regularization to properly
constrain transmission estimation without introducing the halo artifacts. A
selective-neighbor criterion is presented to convert the unconventional
constrained optimization problem to an unconstrained one where the latter can
be efficiently solved.
</summary>
    <author>
      <name>Qiong Yan</name>
    </author>
    <author>
      <name>Li Xu</name>
    </author>
    <author>
      <name>Jiaya Jia</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 10 figures, Siggraph Asia 2013 Technial Briefs</arxiv:comment>
    <link href="http://arxiv.org/abs/1310.3452v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.3452v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.4.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.3717v1</id>
    <updated>2013-10-14T15:19:45Z</updated>
    <published>2013-10-14T15:19:45Z</published>
    <title>Misfire Detection in IC Engine using Kstar Algorithm</title>
    <summary>  Misfire in an IC Engine continues to be a problem leading to reduced fuel
efficiency, increased power loss and emissions containing heavy concentration
of hydrocarbons. Misfiring creates a unique vibration pattern attributed to a
particular cylinder. Useful features can be extracted from these patterns and
can be analyzed to detect misfire. Statistical features from these vibration
signals were extracted. Out of these, useful features were identified using the
J48 decision tree algorithm and selected features were used for classification
using the Kstar algorithm. In this paper performance analysis of Kstar
algorithm is presented.
</summary>
    <author>
      <name>Anish Bahri</name>
    </author>
    <author>
      <name>V Sugumaran</name>
    </author>
    <author>
      <name>S Babu Devasenapati</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 Pages, 8 Figures, 4 Tables. International Journal of Research in
  Mechanical Engineering, 2013</arxiv:comment>
    <link href="http://arxiv.org/abs/1310.3717v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.3717v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.6376v1</id>
    <updated>2013-10-23T20:10:36Z</updated>
    <published>2013-10-23T20:10:36Z</published>
    <title>Can Facial Uniqueness be Inferred from Impostor Scores?</title>
    <summary>  In Biometrics, facial uniqueness is commonly inferred from impostor
similarity scores. In this paper, we show that such uniqueness measures are
highly unstable in the presence of image quality variations like pose, noise
and blur. We also experimentally demonstrate the instability of a recently
introduced impostor-based uniqueness measure of [Klare and Jain 2013] when
subject to poor quality facial images.
</summary>
    <author>
      <name>Abhishek Dutta</name>
    </author>
    <author>
      <name>Raymond Veldhuis</name>
    </author>
    <author>
      <name>Luuk Spreeuwers</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">A 6 page paper presented in the Biometric Technologies in Forensic
  Science (BTFS) 2013 Conference, Oct 14-15 2013, Nijmegen, Netherlands. Full
  proceeding is available at http://www.ru.nl/clst/btfs/btfs-2013/</arxiv:comment>
    <link href="http://arxiv.org/abs/1310.6376v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.6376v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.6808v1</id>
    <updated>2013-10-25T02:37:44Z</updated>
    <published>2013-10-25T02:37:44Z</published>
    <title>Gender Classification Using Gradient Direction Pattern</title>
    <summary>  A novel methodology for gender classification is presented in this paper. It
extracts feature from local region of a face using gray color intensity
difference. The facial area is divided into sub-regions and GDP histogram
extracted from those regions are concatenated into a single vector to represent
the face. The classification accuracy obtained by using support vector machine
has outperformed all traditional feature descriptors for gender classification.
It is evaluated on the images collected from FERET database and obtained very
high accuracy.
</summary>
    <author>
      <name>Mohammad shahidul Islam</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3 pages, 5 figures, 3 tables, SCI journal</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Sci.Int(Lahore),25(4),797-799,2013 ISSN 1013-5316; CODEN: SINTE 8</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1310.6808v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.6808v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.5.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.7114v1</id>
    <updated>2013-10-26T14:21:06Z</updated>
    <published>2013-10-26T14:21:06Z</published>
    <title>Efficient Information Theoretic Clustering on Discrete Lattices</title>
    <summary>  We consider the problem of clustering data that reside on discrete, low
dimensional lattices. Canonical examples for this setting are found in image
segmentation and key point extraction. Our solution is based on a recent
approach to information theoretic clustering where clusters result from an
iterative procedure that minimizes a divergence measure. We replace costly
processing steps in the original algorithm by means of convolutions. These
allow for highly efficient implementations and thus significantly reduce
runtime. This paper therefore bridges a gap between machine learning and signal
processing.
</summary>
    <author>
      <name>Christian Bauckhage</name>
    </author>
    <author>
      <name>Kristian Kersting</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper has been presented at the workshop LWA 2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1310.7114v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.7114v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.7443v1</id>
    <updated>2013-09-16T23:07:39Z</updated>
    <published>2013-09-16T23:07:39Z</published>
    <title>On Convergent Finite Difference Schemes for Variational - PDE Based
  Image Processing</title>
    <summary>  We study an adaptive anisotropic Huber functional based image restoration
scheme. By using a combination of L2-L1 regularization functions, an adaptive
Huber functional based energy minimization model provides denoising with edge
preservation in noisy digital images. We study a convergent finite difference
scheme based on continuous piecewise linear functions and use a variable
splitting scheme, namely the Split Bregman, to obtain the discrete minimizer.
Experimental results are given in image denoising and comparison with additive
operator splitting, dual fixed point, and projected gradient schemes illustrate
that the best convergence rates are obtained for our algorithm.
</summary>
    <author>
      <name>V. B. S. Prasath</name>
    </author>
    <author>
      <name>Juan C. Moreno</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">23 pages, 12 figures, 2 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1310.7443v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.7443v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65N06, 65N22, 68U10" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.4.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1311.2102v1</id>
    <updated>2013-11-08T22:49:07Z</updated>
    <published>2013-11-08T22:49:07Z</published>
    <title>An Experimental Comparison of Trust Region and Level Sets</title>
    <summary>  High-order (non-linear) functionals have become very popular in segmentation,
stereo and other computer vision problems. Level sets is a well established
general gradient descent framework, which is directly applicable to
optimization of such functionals and widely used in practice. Recently, another
general optimization approach based on trust region methodology was proposed
for regional non-linear functionals. Our goal is a comprehensive experimental
comparison of these two frameworks in regard to practical efficiency,
robustness to parameters, and optimality. We experiment on a wide range of
problems with non-linear constraints on segment volume, appearance and shape.
</summary>
    <author>
      <name>Lena Gorelick</name>
    </author>
    <author>
      <name>Ismail BenAyed</name>
    </author>
    <author>
      <name>Frank R. Schmidt</name>
    </author>
    <author>
      <name>Yuri Boykov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1311.2102v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1311.2102v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1311.2191v2</id>
    <updated>2014-06-27T19:11:43Z</updated>
    <published>2013-11-09T17:53:22Z</published>
    <title>Neighborhood filters and the decreasing rearrangement</title>
    <summary>  Nonlocal filters are simple and powerful techniques for image denoising. In
this paper, we give new insights into the analysis of one kind of them, the
Neighborhood filter, by using a classical although not very common
transformation: the decreasing rearrangement of a function (the image).
Independently of the dimension of the image, we reformulate the Neighborhood
filter and its iterative variants as an integral operator defined in a
one-dimensional space. The simplicity of this formulation allows to perform a
detailed analysis of its properties. Among others, we prove that the filter
behaves asymptotically as a shock filter combined with a border diffusive term,
responsible for the staircaising effect and the loss of contrast.
</summary>
    <author>
      <name>Gonzalo Galiano</name>
    </author>
    <author>
      <name>Julián Velasco</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s10851-014-0522-3</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s10851-014-0522-3" rel="related"/>
    <link href="http://arxiv.org/abs/1311.2191v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1311.2191v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68U10" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
