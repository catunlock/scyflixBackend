<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3Dall%3Acs.HC%26id_list%3D%26start%3D0%26max_results%3D500" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=all:cs.HC&amp;id_list=&amp;start=0&amp;max_results=500</title>
  <id>http://arxiv.org/api/MoP1FokqEk3TFxHYJuMj5V5h/+I</id>
  <updated>2017-10-08T00:00:00-04:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">2546</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">500</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/0708.0598v2</id>
    <updated>2008-02-03T19:41:44Z</updated>
    <published>2007-08-04T02:38:19Z</published>
    <title>An Application of Chromatic Prototypes</title>
    <summary>  This paper has been withdrawn.
</summary>
    <author>
      <name>Matthew McCool</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper has been withdrawn</arxiv:comment>
    <link href="http://arxiv.org/abs/0708.0598v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0708.0598v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0809.0461v1</id>
    <updated>2008-09-02T17:25:25Z</updated>
    <published>2008-09-02T17:25:25Z</published>
    <title>The Semiotic Machine</title>
    <summary>  A semiotic model of the user interface in human-computer interaction.
Algorithmic sign, semotics, algorithmic art.
</summary>
    <author>
      <name>Eric Engle</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">28 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/0809.0461v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0809.0461v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0508042v2</id>
    <updated>2006-06-29T06:46:34Z</updated>
    <published>2005-08-04T22:49:38Z</published>
    <title>OpenVanilla - A Non-Intrusive Plug-In Framework of Text Services</title>
    <summary>  This paper has been withdrawn by the author, because it was merged into
cs.HC/0508041
</summary>
    <author>
      <name>Tien-chien Chiang</name>
    </author>
    <author>
      <name> Deng-Liu</name>
    </author>
    <author>
      <name>Kang-min Liu</name>
    </author>
    <author>
      <name>Weizhong Yang</name>
    </author>
    <author>
      <name>Pek-tiong Tan</name>
    </author>
    <author>
      <name>Mengjuei Hsieh</name>
    </author>
    <author>
      <name>Tsung-hsiang Chang</name>
    </author>
    <author>
      <name>Wen-Lien Hsu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper has been withdrawn</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0508042v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0508042v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0409041v1</id>
    <updated>2004-09-23T19:08:17Z</updated>
    <published>2004-09-23T19:08:17Z</published>
    <title>Four Principles Fundamental to Design Practice for Human Centred Systems</title>
    <summary>  A Survey of the principal literature on Human Centred Design reveals the four
most referenced principles. These are discussed with reference to the
application of a particular website, and a user survey is constructed based
upon the four principles.
</summary>
    <author>
      <name>Vita Hinze-Hoare</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0409041v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0409041v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0611042v1</id>
    <updated>2006-11-09T21:10:32Z</updated>
    <published>2006-11-09T21:10:32Z</published>
    <title>CSCR:Computer Supported Collaborative Research</title>
    <summary>  It is suggested that a new area of CSCR (Computer Supported Collaborative
Research) is distinguished from CSCW and CSCL and that the demarcation between
the three areas could do with greater clarification and prescription.
</summary>
    <author>
      <name>Vita Hinze-Hoare</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3 Pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0611042v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0611042v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0908.1191v1</id>
    <updated>2009-08-08T21:13:27Z</updated>
    <published>2009-08-08T21:13:27Z</published>
    <title>Embedded Spreadsheet Modelling</title>
    <summary>  In larger accounting firms, specialist modellers typically sit in separate
teams. This paper will look at the advantages of embedding a specialist
modeller within a Corporate Finance Team.
</summary>
    <author>
      <name>Angela Collins</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 Pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2009 95-99
  ISBN 978-1-905617-89-0</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0908.1191v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0908.1191v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1004.0256v1</id>
    <updated>2010-04-01T23:42:11Z</updated>
    <published>2010-04-01T23:42:11Z</published>
    <title>From Playability to a Hierarchical Game Usability Model</title>
    <summary>  This paper presents a brief review of current game usability models. This
leads to the conception of a high-level game development-centered usability
model that integrates current usability approaches in game industry and game
research.
</summary>
    <author>
      <name>Lennart E. Nacke</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/1639601.1639609</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/1639601.1639609" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1004.0256v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1004.0256v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="97Rxx" scheme="http://arxiv.org/schemas/atom"/>
    <category term="K.8.0; H.5.1; J.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.07310v1</id>
    <updated>2015-05-26T15:45:00Z</updated>
    <published>2015-05-26T15:45:00Z</published>
    <title>Use of Laplacian Projection Technique for Summarizing Likert Scale
  Annotations</title>
    <summary>  Summarizing Likert scale ratings from human annotators is an important step
for collecting human judgments. In this project we study a novel, graph
theoretic method for this purpose. We also analyze a few interesting properties
for this approach using real annotation datasets.
</summary>
    <author>
      <name>M. Iftekhar Tanveer</name>
    </author>
    <link href="http://arxiv.org/abs/1505.07310v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.07310v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.05737v2</id>
    <updated>2015-11-24T01:42:21Z</updated>
    <published>2015-11-18T11:25:50Z</published>
    <title>Designing for Collaborative Sensemaking: Leveraging Human Cognition For
  Complex Tasks</title>
    <summary>  My research aims to design systems for complex sensemaking by remotely
located non-expert collaborators (crowds), to solve computationally hard
problems like crimes.
</summary>
    <author>
      <name>Nitesh Goyal</name>
    </author>
    <author>
      <name>Susan R. Fussell</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Conference. Companion of 15th IFIP TC 13 Human-Computer Interaction
  INTERACT 2015</arxiv:comment>
    <link href="http://arxiv.org/abs/1511.05737v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.05737v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.05922v1</id>
    <updated>2016-12-18T14:58:37Z</updated>
    <published>2016-12-18T14:58:37Z</published>
    <title>Super Event Driven System OOP GUI Design</title>
    <summary>  This article presents a new proposal design of GUI and new technology in
programming Namely "Super Technology" which can be applied for supporting the
proposal design of GUI
</summary>
    <author>
      <name>Mahmoud Samir Fayed</name>
    </author>
    <author>
      <name>Ehab Aziz Khalil</name>
    </author>
    <link href="http://arxiv.org/abs/1612.05922v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.05922v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.01796v1</id>
    <updated>2017-09-06T12:10:11Z</updated>
    <published>2017-09-06T12:10:11Z</published>
    <title>Interakt---A Multimodal Multisensory Interactive Cognitive Assessment
  Tool</title>
    <summary>  Cognitive assistance may be valuable in applications for doctors and
therapists that reduce costs and improve quality in healthcare systems. Use
cases and scenarios include the assessment of dementia. In this paper, we
present our approach to the (semi-)automatic assessment of dementia.
</summary>
    <author>
      <name>Daniel Sonntag</name>
    </author>
    <link href="http://arxiv.org/abs/1709.01796v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.01796v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.09733v1</id>
    <updated>2017-09-07T19:25:48Z</updated>
    <published>2017-09-07T19:25:48Z</published>
    <title>NIME: A Community of Communities</title>
    <summary>  Commentary on the article Fourteen Years of NIME: The Value and Meaning of
Community in Interactive Music Research by A. Marquez-Borbon and P. Stapleton.
</summary>
    <author>
      <name>Michael J. Lyons</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.6084/m9.figshare.5386786</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.6084/m9.figshare.5386786" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">A NIME Reader: Fifteen Years of New Interfaces for Musical
  Expression, A.R. Jensenius and M.J. Lyons (eds.), Springer, pp.477-478, 2017</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1709.09733v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.09733v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.2.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0601021v1</id>
    <updated>2006-01-07T11:06:23Z</updated>
    <published>2006-01-07T11:06:23Z</published>
    <title>Lighting Control using Pressure-Sensitive Touchpads</title>
    <summary>  We introduce a novel approach to control physical lighting parameters by
means of a pressure-sensitive touchpad. The two-dimensional area of the
touchpad is subdivided into 5 virtual sliders, each controlling the intensity
of a color (red, green, blue, yellow, and white). The physical interaction
methodology is modeled directly after ubiquitous mechanical sliders and dimmers
which tend to be used for intensity/volume control. Our abstraction to a
pressure-sensitive touchpad provides advantages and introduces additional
benefits over such existing devices.
</summary>
    <author>
      <name>Alexander Haubold</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0601021v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0601021v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="B.4.2; H.5.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0604102v1</id>
    <updated>2006-04-25T19:32:03Z</updated>
    <published>2006-04-25T19:32:03Z</published>
    <title>HCI and Educational Metrics as Tools for VLE Evaluation</title>
    <summary>  The general set of HCI and Educational principles are considered and a
classification system constructed. A frequency analysis of principles is used
to obtain the most significant set. Metrics are devised to provide objective
measures of these principles and a consistent testing regime devised. These
principles are used to analyse Blackboard and Moodle.
</summary>
    <author>
      <name>Vita Hinze-Hoare</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0604102v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0604102v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0611158v2</id>
    <updated>2007-02-02T08:10:20Z</updated>
    <published>2006-11-30T13:28:29Z</published>
    <title>Articulation entre élaboration de solutions et argumentation
  polyphonique</title>
    <summary>  In this paper, we propose an analytical framework that aims to bring out the
nature of participants' contributions to co-design meetings, in a way that
synthesises content and function dimensions, together with the dimension of
dialogicality. We term the resulting global vision of contribution, the
"interactive profile".
</summary>
    <author>
      <name>Michael Baker</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA</arxiv:affiliation>
    </author>
    <author>
      <name>Françoise Détienne</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA</arxiv:affiliation>
    </author>
    <author>
      <name>Kristine Lundt</name>
    </author>
    <author>
      <name>Arnauld Séjourné</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Dans EPIQUE'2003 (2003)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0611158v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0611158v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0702003v1</id>
    <updated>2007-02-01T09:02:38Z</updated>
    <published>2007-02-01T09:02:38Z</published>
    <title>Expert Programming Knowledge: a Schema-Based Approach</title>
    <summary>  The topic of this chapter is the role of expert programming knowledge in the
understanding activity. In the "schema-based approach", the role of semantic
structures is emphasized whereas, in the "control-flow approach", the role of
syntactic structures is emphasized. Data which support schema-based models of
understanding are presented. Data which are more consistent with the
"control-flow approach" allow to discuss the limits of the former kind of
models.
</summary>
    <author>
      <name>Françoise Détienne</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Psychology of ProgrammingAcademic Press (Ed.) (1990) 205-222</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0702003v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0702003v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0705.0025v1</id>
    <updated>2007-05-01T15:44:17Z</updated>
    <published>2007-05-01T15:44:17Z</published>
    <title>Can the Internet cope with stress?</title>
    <summary>  When will the Internet become aware of itself? In this note the problem is
approached by asking an alternative question: Can the Internet cope with
stress? By extrapolating the psychological difference between coping and
defense mechanisms a distributed software experiment is outlined which could
reject the hypothesis that the Internet is not a conscious entity.
</summary>
    <author>
      <name>Andreas Martin Lisewski</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/0705.0025v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0705.0025v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0707.3638v1</id>
    <updated>2007-07-24T20:19:47Z</updated>
    <published>2007-07-24T20:19:47Z</published>
    <title>The Review and Analysis of Human Computer Interaction (HCI) Principles</title>
    <summary>  The History of HCI is briefly reviewed together with three HCI models and
structure including CSCW, CSCL and CSCR. It is shown that a number of
authorities consider HCI to be a fragmented discipline with no agreed set of
unifying design principles. An analysis of usability criteria based upon
citation frequency of authors is performed in order to discover the eight most
recognised HCI principles.
</summary>
    <author>
      <name>V. Hinze-Hoare</name>
    </author>
    <link href="http://arxiv.org/abs/0707.3638v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0707.3638v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0708.0877v1</id>
    <updated>2007-08-07T19:53:24Z</updated>
    <published>2007-08-07T19:53:24Z</published>
    <title>A Portal Analysis for the Design of a Collaborative Research Environment
  for Students and Supervisors (CRESS) within the CSCR Domain</title>
    <summary>  In a previous paper the CSCR domain was defined. Here this is taken to the
next stage where we consider the design of a particular Collaborative Research
Environment to support Students and Supervisors CRESS. Following the CSCR
structure a preliminary design for CRESS has been established and a portal
framework analysis is undertaken in order to determine the most appropriate set
of tools for its implementation.
</summary>
    <author>
      <name>V. Hinze-Hoare</name>
    </author>
    <link href="http://arxiv.org/abs/0708.0877v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0708.0877v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0708.1624v1</id>
    <updated>2007-08-12T19:58:37Z</updated>
    <published>2007-08-12T19:58:37Z</published>
    <title>Designing a Collaborative Research Environment for Students and their
  Supervisors (CRESS)</title>
    <summary>  In a previous paper the CSCR domain was defined. Here this is taken to the
next stage where the design of a particular Collaborative Research Environment
to support Students and Supervisors (CRESS) is considered. Following the CSCR
structure this paper deals with an analysis of 13 collaborative working
environments to determine a preliminary design for CRESS in order to discover
the most appropriate set of tools for its implementation.
</summary>
    <author>
      <name>V. Hinze-Hoare</name>
    </author>
    <link href="http://arxiv.org/abs/0708.1624v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0708.1624v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0709.0178v2</id>
    <updated>2008-10-05T10:19:14Z</updated>
    <published>2007-09-03T09:32:28Z</published>
    <title>Effective Generation of Subjectively Random Binary Sequences</title>
    <summary>  We present an algorithm for effectively generating binary sequences which
would be rated by people as highly likely to have been generated by a random
process, such as flipping a fair coin.
</summary>
    <author>
      <name>Yasmine B. Sanderson</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Introduction and Section 6 revised</arxiv:comment>
    <link href="http://arxiv.org/abs/0709.0178v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0709.0178v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.10; I.6.8; J.4; G.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0802.3476v1</id>
    <updated>2008-02-24T01:34:36Z</updated>
    <published>2008-02-24T01:34:36Z</published>
    <title>Fun Boy Three Were Wrong: it is what you do, not the way that you do it</title>
    <summary>  I revisit some classic publications on modularity, to show what problems its
pioneers wanted to solve. These problems occur with spreadsheets too: to
recognise them may help us avoid them.
</summary>
    <author>
      <name>Jocelyn Paine</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 Pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2007 105-116
  ISBN 978-905617-58-6</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0802.3476v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0802.3476v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.1.7; D.2.1; D.2.11; D.3.2; D.3.3; H.4.1; K.6.4; K.8.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0803.0166v1</id>
    <updated>2008-03-03T01:40:31Z</updated>
    <published>2008-03-03T01:40:31Z</published>
    <title>Spreadsheet Validation and Analysis through Content Visualization</title>
    <summary>  Visualizing spreadsheet content provides analytic insight and visual
validation of large amounts of spreadsheet data. Oculus Excel Visualizer is a
point and click data visualization experiment which directly visualizes Excel
data and re-uses the layout and formatting already present in the spreadsheet.
</summary>
    <author>
      <name>Richard Brath</name>
    </author>
    <author>
      <name>Michael Peters</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 Pages, 11 Colour Figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2006 175-183
  ISBN:1-905617-08-9</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0803.0166v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0803.0166v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.2.4; D.2.5; H.4.1; K.6.4; K.8.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0811.1974v1</id>
    <updated>2008-11-12T20:31:34Z</updated>
    <published>2008-11-12T20:31:34Z</published>
    <title>Magic Fairy Tales as Source for Interface Metaphors</title>
    <summary>  The work is devoted to a problem of search of metaphors for interactive
systems and systems based on Virtual Reality (VR) environments. The analysis of
magic fairy tales as a source of metaphors for interface and virtual reality is
offered. Some results of design process based on magic metaphors are
considered.
</summary>
    <author>
      <name>Vladimir L. Averbukh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/0811.1974v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0811.1974v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.1.m" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0908.0932v1</id>
    <updated>2009-08-06T18:52:41Z</updated>
    <published>2009-08-06T18:52:41Z</published>
    <title>The Medical Algorithms Project</title>
    <summary>  The Medical Algorithms Project, a web-based resource located at
www.medal.org, is the world's largest collection of medical-related
spreadsheets, consisting of over 13,500 Excel spreadsheets each encoding a
medical algorithm from 45 different areas of medical practice. This free
resource is in use worldwide with over 106,000 registered users as of March 1,
2009.
</summary>
    <author>
      <name>M. Sriram Iyengar</name>
    </author>
    <author>
      <name>John R. Svirbely</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 Pages, 2 Colour Figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2009 113-118
  ISBN 978-1-905617-89-0</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0908.0932v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0908.0932v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0908.1186v1</id>
    <updated>2009-08-08T20:38:12Z</updated>
    <published>2009-08-08T20:38:12Z</published>
    <title>Checks and Controls in Spreadsheets</title>
    <summary>  Spreadsheets that are informally created are harder to test than they should
be. Simple cross-foot checks or being easily readable are modest but attainable
goals for every spreadsheet developer. This paper lists some tips on building
self-checking into a spreadsheet in order to provide more confidence to the
reader that a spreadsheet is robust.
</summary>
    <author>
      <name>Patrick O'Beirne</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 Pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2009 1-7 ISBN
  978-1-905617-89-0</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0908.1186v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0908.1186v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0912.2479v2</id>
    <updated>2010-01-12T15:20:14Z</updated>
    <published>2009-12-13T06:10:42Z</published>
    <title>Pervasive Emotions in Pervasive Computing Environments</title>
    <summary>  This submission has been withdrawn by arXiv admin. It is a verbatim copy of
arXiv:0912.1810 with only the author name and title changed.
</summary>
    <author>
      <name>Vishal Goyal</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This submission has been withdrawn by arXiv admin. It is a verbatim
  copy of arXiv:0912.1810 with only the author name and title changed</arxiv:comment>
    <link href="http://arxiv.org/abs/0912.2479v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0912.2479v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1001.0420v1</id>
    <updated>2010-01-03T23:42:53Z</updated>
    <published>2010-01-03T23:42:53Z</published>
    <title>The Role of Head-Up Display in Computer- Assisted Instruction</title>
    <summary>  We investigated the role of HUDs in CAI. HUDs have been used in various
situations in daily lives by recent downsizing and cost down of the display
devices. CAI is one of the promising applications for HUDs. We have developed
an HUD-based CAI system for effectively presenting instructions of the
equipment in the transportable earth station. This chapter described HUDs in
CAI from a viewpoint of human-computer interaction based on the development
experience.
</summary>
    <author>
      <name>Kikuo Asai</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">www.sciyo.com</arxiv:comment>
    <link href="http://arxiv.org/abs/1001.0420v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1001.0420v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1003.2456v1</id>
    <updated>2010-03-12T01:19:20Z</updated>
    <published>2010-03-12T01:19:20Z</published>
    <title>Piecemeal Journey To 'HALCYON' World Of Pervasive Computing : From past
  progress to future challenges</title>
    <summary>  Although 'Halcyon' means serene environment which pervasive computing aims
at, we have tried to present a different interpretation of this word. Through
our approach, we look at it in context of achieving future 'calm technology'.
The paper gives a general overview of the state of pervasive computing today,
proposes the 'HALCYON Model' and outlines the 'social' challenges faced by
system designers.
</summary>
    <author>
      <name>Rolly Seth</name>
    </author>
    <author>
      <name>Rishi Kapoor</name>
    </author>
    <author>
      <name>Hameed Al-Qaheri</name>
    </author>
    <author>
      <name>Sugata Sanyal</name>
    </author>
    <link href="http://arxiv.org/abs/1003.2456v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1003.2456v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1007.3633v1</id>
    <updated>2010-07-21T12:39:09Z</updated>
    <published>2010-07-21T12:39:09Z</published>
    <title>Alternatives to Mobile Keypad Design: Improved Text Feed</title>
    <summary>  In this paper we tried to focus on some of the problems with the mobile
keypad and text entering in these devices, and tried to give some possible
suggestions. We mainly took some of the basic Human Computer Interaction
principles and some general issues into consideration.
</summary>
    <author>
      <name>Satish Narayana Srirama</name>
    </author>
    <author>
      <name>M. A. A. Faruque</name>
    </author>
    <author>
      <name>M. A. S. Munni</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6th International Conference on Computer and Information Technology
  (ICCIT2003), 19-21 December, 2003</arxiv:comment>
    <link href="http://arxiv.org/abs/1007.3633v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1007.3633v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1009.5701v1</id>
    <updated>2010-09-28T21:31:16Z</updated>
    <published>2010-09-28T21:31:16Z</published>
    <title>Changing User Attitudes to Reduce Spreadsheet Risk</title>
    <summary>  A business case study on how three simple guidelines:
  1. Make it easy to check (and maintain) 2. Make it safe to use 3. Keep
business logic out of code changed user attitudes and improved spreadsheet
quality in a financial services organisation.
</summary>
    <author>
      <name>Dermot Balson</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 Pages; ISBN 978-1-905404-50-6</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2010 133-137</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1009.5701v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1009.5701v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1112.2302v1</id>
    <updated>2011-12-10T20:30:52Z</updated>
    <published>2011-12-10T20:30:52Z</published>
    <title>A Door into Another World</title>
    <summary>  Is it possible to design programs which each user can change according to his
preferences? Not an illusion of such a thing that adaptive interface provides
but really an interface ruled by users. What is the main problem of such design
and what is the solution to this problem? This short article gives a glimpse
into the theory discussed in the book "The World of Movable Objects".
</summary>
    <author>
      <name>Sergey Andreyev</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1112.2302v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1112.2302v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.2; D.2.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.6517v1</id>
    <updated>2012-02-29T11:17:10Z</updated>
    <published>2012-02-29T11:17:10Z</published>
    <title>Eye Pupil Location Using Webcam</title>
    <summary>  Three different algorithms used for eye pupil location were described and
tested. Algorithm efficiency comparison was based on human faces images taken
from the BioID database. Moreover all the eye localisation methods were
implemented in a dedicated application supporting eye movement based computer
control. In this case human face images were acquired by a webcam and processed
in a real-time.
</summary>
    <author>
      <name>Michal Ciesla</name>
    </author>
    <author>
      <name>Przemyslaw Koziol</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 11 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1202.6517v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.6517v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.4944v1</id>
    <updated>2012-05-22T15:28:50Z</updated>
    <published>2012-05-22T15:28:50Z</published>
    <title>Emotion Detection from Text</title>
    <summary>  Emotion can be expressed in many ways that can be seen such as facial
expression and gestures, speech and by written text. Emotion Detection in text
documents is essentially a content - based classification problem involving
concepts from the domains of Natural Language Processing as well as Machine
Learning. In this paper emotion recognition based on textual data and the
techniques used in emotion detection are discussed.
</summary>
    <author>
      <name>Shiv Naresh Shivhare</name>
    </author>
    <author>
      <name>Saritha Khethawat</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1205.4944v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.4944v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.0578v1</id>
    <updated>2012-09-04T09:44:07Z</updated>
    <published>2012-09-04T09:44:07Z</published>
    <title>Social Cheesecake: An UX-driven designed interface for managing contacts</title>
    <summary>  Social network management interfaces should consider separation of contexts
and tie strength. This paper shows the design process upon building the Social
Cheesecake, an interface that addresses both issues. Paper and screen
prototyping were used in the design process. Paper prototype interactions
helped to explore the metaphors in the domain, while screen prototype
consolidated the model. The prototype was finally built using HTML5 and
Javascript.
</summary>
    <author>
      <name>Alicia Díez</name>
    </author>
    <author>
      <name>Antonio Tapiador</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Preprint of IADIS WWW/Internet 2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1209.0578v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.0578v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1308.4965v1</id>
    <updated>2013-08-21T17:53:37Z</updated>
    <published>2013-08-21T17:53:37Z</published>
    <title>A proposal for a Chinese keyboard for cellphones, smartphones, ipads and
  tablets</title>
    <summary>  In this paper, we investigate the possibility to use two tilings of the
hyperbolic plane as basic frame for devising a way to input texts in Chinese
characters into messages of cellphones, smartphones, ipads and tablets.
</summary>
    <author>
      <name>Maurice Margenstern</name>
    </author>
    <author>
      <name>Lan Wu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">28 pages, 40 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1308.4965v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1308.4965v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="69U99, 94A99" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.1.2; H.5.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1311.3371v1</id>
    <updated>2013-11-14T03:12:54Z</updated>
    <published>2013-11-14T03:12:54Z</published>
    <title>Android Note Manager Application for People with Visual Impairment</title>
    <summary>  With the outburst of smart-phones today, the market is exploding with various
mobile applications. This paper proposes an application using which visually
impaired people can type a note in Grade 1 Braille and save it in the external
memory of their smart-phone. The application also shows intelligence by
activating reminders and/or calling certain contacts based on the content in
the notes.
</summary>
    <author>
      <name>Gayatri Venugopal</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5121/ijmnct.2013.3502</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5121/ijmnct.2013.3502" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1311.3371v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1311.3371v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1311.5434v1</id>
    <updated>2013-11-21T15:00:46Z</updated>
    <published>2013-11-21T15:00:46Z</published>
    <title>The Well-tempered Compiler? The Aesthetics of Program Auralization</title>
    <summary>  In this chapter we are concerned with external auditory representations of
programs, also known as program auralization. As program auralization systems
tend to use musical representations they are necessarily affected by artistic
and aesthetic considerations. Therefore, it is instructive to explore program
auralization in the light of aesthetic computing principles.
</summary>
    <author>
      <name>Paul Vickers</name>
    </author>
    <author>
      <name>James L Alty</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">in Aesthetic Computing (P. A. Fishwick, ed.), ch. 17, pp. 335-354,
  Boston, MA: MIT Press, 2006</arxiv:comment>
    <link href="http://arxiv.org/abs/1311.5434v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1311.5434v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.4354v1</id>
    <updated>2014-05-17T06:01:03Z</updated>
    <published>2014-05-17T06:01:03Z</published>
    <title>Touch Survey: Comparison with Paper and Web Questionnaires</title>
    <summary>  We developed a prototype of touch-based survey tool for tablets and conducted
an experiment to compare interaction patterns of touch-based, PC-based, and
paper-based questionnaires. Our findings suggest that a touch-based interface
allows users to complete ranking questions easily, quickly, and accurately
although it can increase the time to complete a location input task for
well-known, prominent locations.
</summary>
    <author>
      <name>Tomoyo Sasao</name>
    </author>
    <author>
      <name>Shin'ichi Konomi</name>
    </author>
    <author>
      <name>Masatoshi Arikawa</name>
    </author>
    <author>
      <name>Hideyuki Fujita</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1405.4354v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.4354v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.03403v2</id>
    <updated>2015-08-30T13:28:19Z</updated>
    <published>2015-03-11T16:20:51Z</published>
    <title>Bublz! : Playing with Bubbles to Develop Mathematical Thinking</title>
    <summary>  We encounter mathematical problems in various forms in our lives, thus making
mathematical thinking an important human ability. In this paper, we present
Bublz!, a simple, click-driven game for children to engage in and develop
mathematical thinking in an enjoyable manner.
</summary>
    <author>
      <name>Dhruv Chand</name>
    </author>
    <author>
      <name>Karthik Gopalakrishnan</name>
    </author>
    <author>
      <name>Nisha KK</name>
    </author>
    <author>
      <name>Mudit Sinha</name>
    </author>
    <author>
      <name>Shreya Sriram</name>
    </author>
    <link href="http://arxiv.org/abs/1503.03403v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.03403v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.HO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="K.3.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.01305v1</id>
    <updated>2015-07-05T23:53:59Z</updated>
    <published>2015-07-05T23:53:59Z</published>
    <title>Mixsourcing: a remix framework as a form of crowdsourcing</title>
    <summary>  In this paper, we introduce the concept of mixsourcing as a modality of
crowdsourcing focused on using remixing as a framework to get people to perform
creative tasks. We explore this idea through the design of a system that helped
us identify the promises and challenges of this peer-production modality.
</summary>
    <author>
      <name>Sarah Hallacher</name>
    </author>
    <author>
      <name>Jenny Rodenhouse</name>
    </author>
    <author>
      <name>Andres Monroy-Hernandez</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In CHI 2013 Extended Abstracts on Human Factors in Computing Systems
  (CHI EA '13)</arxiv:comment>
    <link href="http://arxiv.org/abs/1507.01305v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.01305v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1509.01662v1</id>
    <updated>2015-09-05T04:28:39Z</updated>
    <published>2015-09-05T04:28:39Z</published>
    <title>Tightly-Held and Ephemeral Psychometrics: Password and Passphrase
  Authentication Utilizing User-Supplied Constructs of Self</title>
    <summary>  This research investigates the role of passwords and passphrases as valid
authentication methodologies. Specifically, this research dispels earlier work
that ignores information-theoretic lessons learned from cognitive and social
psychology and psycholinguistics, and extends and enriches the current password
security model.
</summary>
    <author>
      <name>Christopher S. Pilson</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1509.01662v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1509.01662v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.1.1; H.1.2; K.6.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.00244v1</id>
    <updated>2015-10-01T14:10:25Z</updated>
    <published>2015-10-01T14:10:25Z</published>
    <title>RDF Knowledge Graph Visualization From a Knowledge Extraction System</title>
    <summary>  In this paper, we present a system to visualize RDF knowledge graphs. These
graphs are obtained from a knowledge extraction system designed by
GEOLSemantics. This extraction is performed using natural language processing
and trigger detection. The user can visualize subgraphs by selecting some
ontology features like concepts or individuals. The system is also
multilingual, with the use of the annotated ontology in English, French, Arabic
and Chinese.
</summary>
    <author>
      <name>Fadhela Kerdjoudj</name>
    </author>
    <author>
      <name>Olivier Curé</name>
    </author>
    <link href="http://arxiv.org/abs/1510.00244v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.00244v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.01665v2</id>
    <updated>2015-10-19T16:07:15Z</updated>
    <published>2015-10-06T17:00:34Z</published>
    <title>Smartphones in Mental Health: Detecting Depressive and Manic Episodes</title>
    <summary>  An observational study with patients diagnosed with bipolar disorder
investigates whether data from smartphone sensors can be used to recognize
bipolar disorder episodes and detect behavior changes that can signal an onset
of an episode using objective data.
</summary>
    <author>
      <name>Venet Osmani</name>
    </author>
    <author>
      <name>Agnes Gruenerbl</name>
    </author>
    <author>
      <name>Gernot Bahle</name>
    </author>
    <author>
      <name>Christian Haring</name>
    </author>
    <author>
      <name>Paul Lukowicz</name>
    </author>
    <author>
      <name>Oscar Mayora</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/MPRV.2015.54</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/MPRV.2015.54" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE Pervasive Computing, vol.14, no. 3, pp. 10-13, July-Sept.
  2015</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1510.01665v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.01665v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.05901v3</id>
    <updated>2016-04-12T13:47:25Z</updated>
    <published>2016-03-18T16:09:09Z</published>
    <title>Emotion Classification from Noisy Speech - A Deep Learning Approach</title>
    <summary>  This paper investigates the performance of Deep Learning for speech emotion
classification when the speech is compounded with noise. It reports on the
classification accuracy and concludes with the future directions for achieving
greater robustness for emotion recognition from noisy speech.
</summary>
    <author>
      <name>Rajib Rana</name>
    </author>
    <link href="http://arxiv.org/abs/1603.05901v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.05901v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.01331v1</id>
    <updated>2016-04-05T17:00:59Z</updated>
    <published>2016-04-05T17:00:59Z</published>
    <title>A smartphone-based vision simulator</title>
    <summary>  Simulators, as tools that can clearly bring out the effect of impairment, are
invaluable in the design and development process of an assistive device.
Simulators are vital in meeting high standards of accessibility. Described is
our work on a smartphone-based vision simulator for diabetic retinopathy that
is economic, portable, flexible and easy-to-use.
</summary>
    <author>
      <name>Pragathi Praveena</name>
    </author>
    <author>
      <name>Jobin J Kavalam</name>
    </author>
    <author>
      <name>Namita Jacob</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3 pages, 4 image, 3rd International Conference on Biomedical
  Engineering and Assistive Technologies</arxiv:comment>
    <link href="http://arxiv.org/abs/1604.01331v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.01331v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.05572v1</id>
    <updated>2016-04-19T14:01:57Z</updated>
    <published>2016-04-19T14:01:57Z</published>
    <title>Does Anonymity Increase the Chance to Get Feedback?</title>
    <summary>  To generate a hypothesis about the effects of anonymity on user participation
in online communities, comments on Youtube were analysed for effects of the
change from allowing pseudonyms to Google+ with its real name policy. Small
differences were detected, leading to the hypothesis that the option to remain
anonymous leads to a less active environment for getting feedback, with less
polite and less rude comments on the expense of neutral ones.
</summary>
    <author>
      <name>Malte Paskuda</name>
    </author>
    <author>
      <name>Myriam Lewkowicz</name>
    </author>
    <link href="http://arxiv.org/abs/1604.05572v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.05572v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.09432v1</id>
    <updated>2016-05-30T22:05:36Z</updated>
    <published>2016-05-30T22:05:36Z</published>
    <title>Evaluating Crowdsourcing Participants in the Absence of Ground-Truth</title>
    <summary>  Given a supervised/semi-supervised learning scenario where multiple
annotators are available, we consider the problem of identification of
adversarial or unreliable annotators.
</summary>
    <author>
      <name>Ramanathan Subramanian</name>
    </author>
    <author>
      <name>Romer Rosales</name>
    </author>
    <author>
      <name>Glenn Fung</name>
    </author>
    <author>
      <name>Jennifer Dy</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 5 figures, Workshop on Human Computation for Science and
  Computational Sustainability, NIPS 2012, Lake Tahoe, NV. 7 Dec 2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1605.09432v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.09432v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.02427v1</id>
    <updated>2016-06-08T07:14:24Z</updated>
    <published>2016-06-08T07:14:24Z</published>
    <title>VIF: Virtual Interactive Fiction (with a twist)</title>
    <summary>  Nowadays computer science can create digital worlds that deeply immerse
users; it can also process in real time brain activity to infer their inner
states. What marvels can we achieve with such technologies? Go back to
displaying text. And unfold a story that follows and molds users as never
before.
</summary>
    <author>
      <name>Jérémy Frey</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Potioc, UB</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Pervasive Play - CHI '16 Workshop, May 2016, San Jose, United States</arxiv:comment>
    <link href="http://arxiv.org/abs/1606.02427v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.02427v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.02661v1</id>
    <updated>2016-08-08T23:51:47Z</updated>
    <published>2016-08-08T23:51:47Z</published>
    <title>ActiveCrowd: A Framework for Optimized Multi-Task Allocation in Mobile
  Crowdsensing Systems</title>
    <summary>  Worker selection is a key issue in Mobile Crowd Sensing (MCS). While previous
worker selection approaches mainly focus on selecting a proper subset of
workers for a single MCS task, multi-task-oriented worker selection is
essential and useful for the efficiency of large-scale MCS platforms. This
paper proposes ActiveCrowd, a worker selection framework for multi-task MCS
environments.
</summary>
    <author>
      <name>Bin Guo</name>
    </author>
    <author>
      <name>Yan Liu</name>
    </author>
    <author>
      <name>Wenle Wu</name>
    </author>
    <author>
      <name>Zhiwen Yu</name>
    </author>
    <author>
      <name>Qi Han</name>
    </author>
    <link href="http://arxiv.org/abs/1608.02661v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.02661v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.00754v1</id>
    <updated>2016-09-02T21:47:47Z</updated>
    <published>2016-09-02T21:47:47Z</published>
    <title>A heuristic extending the Squarified treemapping algorithm</title>
    <summary>  A heuristic extending the Squarified Treemap technique for the representation
of hierarchical information as treemaps is presented. The original technique
gives high quality treemap views, since items are laid out with rectangles that
approximate squares, allowing easy comparison and selection operations. New key
steps, with a low computational impact, have been introduced to yield treemaps
with even better aspect ratios and higher homogeneity among items.
</summary>
    <author>
      <name>Antonio Cesarano</name>
    </author>
    <author>
      <name>FIlomena Ferrucci</name>
    </author>
    <author>
      <name>Mario Torre</name>
    </author>
    <link href="http://arxiv.org/abs/1609.00754v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.00754v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1610.07577v1</id>
    <updated>2016-10-20T10:38:12Z</updated>
    <published>2016-10-20T10:38:12Z</published>
    <title>A new content format for immersive experiences</title>
    <summary>  The arrival of head-mounted displays (HMDs) to the consumer market requires a
novel content format that is, first, adapted to the specificities of immersive
displays and, second, that takes into account the current reality of
multi-display media consumption. We review the requirements for such content
format and report on existing initiatives, some of our own, towards
implementing such content format.
</summary>
    <author>
      <name>Joan Llobera</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">position paper, Hot3d workshop at ICME 2016, Seattle</arxiv:comment>
    <link href="http://arxiv.org/abs/1610.07577v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1610.07577v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1611.00872v1</id>
    <updated>2016-11-03T03:53:25Z</updated>
    <published>2016-11-03T03:53:25Z</published>
    <title>A Decision Support System for Inbound Marketers: An Empirical Use of
  Latent Dirichlet Allocation Topic Model to Guide Infographic Designers</title>
    <summary>  Infographic is a type of information presentation that inbound marketers use.
I suggest a method that can allow the infographic designers to benchmark their
design against the previous viral infographics to measure whether a given
design decision can help or hurt the probability of the design becoming viral.
</summary>
    <author>
      <name>Meisam Hejazi Nia</name>
    </author>
    <link href="http://arxiv.org/abs/1611.00872v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1611.00872v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.06114v1</id>
    <updated>2016-12-19T10:42:57Z</updated>
    <published>2016-12-19T10:42:57Z</published>
    <title>A real-time framework for visual feedback of articulatory data using
  statistical shape models</title>
    <summary>  We present a novel open-source framework for visualizing electromagnetic
articulography (EMA) data in real-time, with a modular framework and
anatomically accurate tongue and palate models derived by multilinear subspace
learning.
</summary>
    <author>
      <name>Kristy James</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">DFKI</arxiv:affiliation>
    </author>
    <author>
      <name>Alexander Hewer</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">DFKI</arxiv:affiliation>
    </author>
    <author>
      <name>Ingmar Steiner</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">DFKI</arxiv:affiliation>
    </author>
    <author>
      <name>Stefanie Wuhrer</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">MORPHEO</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17th Annual Conference of the International Speech Communication
  Association (Interspeech), Oct 2016, San Francisco, United States</arxiv:comment>
    <link href="http://arxiv.org/abs/1612.06114v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.06114v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1702.05250v1</id>
    <updated>2017-02-17T08:20:37Z</updated>
    <published>2017-02-17T08:20:37Z</published>
    <title>Intelligent User Interfaces - A Tutorial</title>
    <summary>  IUIs aim to incorporate intelligent automated capabilities in human computer
interaction, where the net impact is a human-computer interaction that improves
performance or usability in critical ways. It also involves designing and
implementing an artificial intelligence (AI) component that effectively
leverages human skills and capabilities, so that human performance with an
application excels. IUIs embody capabilities that have traditionally been
associated more strongly with humans than with computers: how to perceive,
interpret, learn, use language, reason, plan, and decide.
</summary>
    <author>
      <name>Daniel Sonntag</name>
    </author>
    <link href="http://arxiv.org/abs/1702.05250v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1702.05250v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.04574v1</id>
    <updated>2017-03-14T14:07:19Z</updated>
    <published>2017-03-14T14:07:19Z</published>
    <title>Causes of discomfort in stereoscopic content: a review</title>
    <summary>  This paper reviews the causes of discomfort in viewing stereoscopic content.
These include objective factors, such as misaligned images, as well as
subjective factors, such as excessive disparity. Different approaches to the
measurement of visual discomfort are also reviewed, in relation to the
underlying physiological and psychophysical processes. The importance of
understanding these issues, in the context of new display technologies, is
emphasized.
</summary>
    <author>
      <name>Kasim Terzic</name>
    </author>
    <author>
      <name>Miles Hansard</name>
    </author>
    <link href="http://arxiv.org/abs/1703.04574v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.04574v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1704.03521v1</id>
    <updated>2017-04-09T20:18:25Z</updated>
    <published>2017-04-09T20:18:25Z</published>
    <title>Responsive Graphical User Interface (ReGUI) and its Implementation in
  MATLAB</title>
    <summary>  In this paper we introduce the responsive graphical user interface (ReGUI)
approach to creating applications, and demonstrate how this approach can be
implemented in MATLAB. The same general technique can be used in other
programming languages.
</summary>
    <author>
      <name>Matej Mikulszky</name>
    </author>
    <author>
      <name>Jana Pocsova</name>
    </author>
    <author>
      <name>Andrea Mojzisova</name>
    </author>
    <author>
      <name>Igor Podlubny</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1704.03521v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1704.03521v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.2.2; H.5.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.03973v1</id>
    <updated>2017-05-10T23:22:43Z</updated>
    <published>2017-05-10T23:22:43Z</published>
    <title>Transreality puzzle as new genres of entertainment technology</title>
    <summary>  The author considers a class of mechatronic puzzles falling in the
mixed-reality category, present examples of such devices, and propose a way to
categorize them. Close relationships of such devices with the Tangible User
Interface are described. The device designed by the author as an illustration
of a mixed reality puzzle is presented.
</summary>
    <author>
      <name>Ilya V Osipov</name>
    </author>
    <link href="http://arxiv.org/abs/1705.03973v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.03973v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.08205v1</id>
    <updated>2017-06-26T02:07:11Z</updated>
    <published>2017-06-26T02:07:11Z</published>
    <title>Metrics for Bengali Text Entry Research</title>
    <summary>  With the intention of bringing uniformity to Bengali text entry research,
here we present a new approach for calculating the most popular English text
entry evaluation metrics for Bengali. To demonstrate our approach, we conducted
a user study where we evaluated four popular Bengali text entry techniques.
</summary>
    <author>
      <name>Sayan Sarcar</name>
    </author>
    <author>
      <name>Ahmed Sabbir Arif</name>
    </author>
    <author>
      <name>Ali Mazalek</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper has been accepted and presented as a position paper at ACM
  CHI 2015 workshop on "Text entry on the edge"</arxiv:comment>
    <link href="http://arxiv.org/abs/1706.08205v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.08205v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.03751v1</id>
    <updated>2017-07-05T13:50:20Z</updated>
    <published>2017-07-05T13:50:20Z</published>
    <title>New Symbols for Base-16 and Base-256 Numerals</title>
    <summary>  A new system of hexadecimal and base-256 numerals is proposed whose digit
shapes are based on binary numerals. The proposed numerals are implemented in
open source fonts and integrated into popular editors (Notepad++ and Eclipse)
to prove the concept.
</summary>
    <author>
      <name>MacKenzie Cumings</name>
    </author>
    <author>
      <name>Valdis Vītoliņš</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Science &amp; Engineering Technology
  (2017) pp. 205-212. ISSN 2229-3345</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1707.03751v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.03751v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.08011v1</id>
    <updated>2017-07-25T14:19:23Z</updated>
    <published>2017-07-25T14:19:23Z</published>
    <title>Machine Intelligence, New Interfaces, and the Art of the Soluble</title>
    <summary>  Position: (1) Partial solutions to machine intelligence can lead to systems
which may be useful creating interesting and expressive musical works. (2) An
appropriate general goal for this field is augmenting human expression. (3) The
study of the aesthetics of human augmentation in musical performance is in its
infancy.
</summary>
    <author>
      <name>Michael J. Lyons</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.6084/m9.figshare.5242045.v1</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.6084/m9.figshare.5242045.v1" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">CHI 2015 Workshop on Collaborating with Intelligent Machines:
  Interfaces for Creative Sound, April 18, 2015, Seoul, Republic of Korea</arxiv:comment>
    <link href="http://arxiv.org/abs/1707.08011v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.08011v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.1.2; H.5.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.05006v1</id>
    <updated>2017-08-16T09:40:53Z</updated>
    <published>2017-08-16T09:40:53Z</published>
    <title>A Survey of Augmented Reality Navigation</title>
    <summary>  Navigation has been a popular area of research in both academia and industry.
Combined with maps, and different localization technologies, navigation systems
have become robust and more usable. By combining navigation with augmented
reality, it can be improved further to become realistic and user friendly. This
paper surveys existing researches carried out in this area, describes existing
techniques for building augmented reality navigation systems, and the problems
faced.
</summary>
    <author>
      <name>Gaurav Bhorkar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Seminar on Software Systems, Technologies and Security, Spring 2016,
  Aalto University</arxiv:comment>
    <link href="http://arxiv.org/abs/1708.05006v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.05006v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.08957v1</id>
    <updated>2017-09-26T12:03:36Z</updated>
    <published>2017-09-26T12:03:36Z</published>
    <title>Beyond Accessibility: Lifting Perceptual Limitations for Everyone</title>
    <summary>  We propose that accessibility research can lay the foundation for technology
that can be used to augment the perception of everyone. To show how this can be
achieved, we present three case studies of our research in which we demonstrate
our approaches for impaired colour vision, situational visual impairments and
situational hearing impairment.
</summary>
    <author>
      <name>Michael Mauderer</name>
    </author>
    <author>
      <name>Garreth W. Tigwell</name>
    </author>
    <author>
      <name>Benjamin M. Gorman</name>
    </author>
    <author>
      <name>David R. Flatla</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1709.08957v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.08957v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0911.2603v1</id>
    <updated>2009-11-13T12:48:42Z</updated>
    <published>2009-11-13T12:48:42Z</published>
    <title>Cybermatter</title>
    <summary>  In this paper we examine several aspects of the impact of Cyberworld onto our
Reality conceptions, and their social implications.
</summary>
    <author>
      <name>Daniel Stern</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Seventh International Computer Ethics Conference (CEPE 2007)</arxiv:comment>
    <link href="http://arxiv.org/abs/0911.2603v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0911.2603v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1602.00251v2</id>
    <updated>2017-01-26T15:53:55Z</updated>
    <published>2016-01-31T14:22:47Z</published>
    <title>Do we have privacy in the digital world?</title>
    <summary>  Not really.
</summary>
    <author>
      <name>Kaveh Bakhtiyari</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.13140/RG.2.1.2492.5203/2</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.13140/RG.2.1.2492.5203/2" rel="related"/>
    <link href="http://arxiv.org/abs/1602.00251v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1602.00251v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9812015v1</id>
    <updated>1998-12-11T23:05:51Z</updated>
    <published>1998-12-11T23:05:51Z</published>
    <title>Adaptive Interaction Using the Adaptive Agent Oriented Software
  Architecture (AAOSA)</title>
    <summary>  User interfaces that adapt their characteristics to those of the user are
referred to as adaptive interfaces. We propose Adaptive Agent Oriented Software
Architecture (AAOSA) as a new way of designing adaptive interfaces. AAOSA is a
new approach to software design based on an agent-oriented architecture. In
this approach agents are considered adaptively communicating concurrent modules
which are divided into a white box module responsible for the communications
and learning, and a black box which is responsible for the independent
specialized processes of the agent. A distributed learning policy that makes
use of this architecture is used for purposes of system adaptability.
</summary>
    <author>
      <name>Babak Hodjat</name>
    </author>
    <author>
      <name>Makoto Amamiya</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/9812015v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9812015v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.2.2; I.2.7; J.7; I.2.11" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9903019v2</id>
    <updated>1999-03-31T22:44:35Z</updated>
    <published>1999-03-30T21:28:07Z</published>
    <title>Workflow Automation with Lotus Notes for the Governmental Administrative
  Information System</title>
    <summary>  The paper presents an introductory overview of the workflow automation area,
outlining the main types, basic technologies, the essential features of
workflow applications. Two sorts of process models for the definition of
workflows (according to the conversation-based and activity-based
methodologies) are sketched. Later on, the nature of Lotus Notes and its
capabilities (as an environment for workflow management systems development)
are indicated. Concluding, the experience of automating administrative
workflows (developing a Subsystem of Inter-institutional Document Management of
the VADIS project) is briefly outlined.
</summary>
    <author>
      <name>Saulius Maskeliunas</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Institute of Mathematics &amp; Informatics, Vilnius</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/9903019v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9903019v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.4.1; H.5.3; J.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0101029v1</id>
    <updated>2001-01-26T07:27:02Z</updated>
    <published>2001-01-26T07:27:02Z</published>
    <title>Tap Tips: Lightweight Discovery of Touchscreen Targets</title>
    <summary>  We describe tap tips, a technique for providing touch-screen target location
hints. Tap tips are lightweight in that they are non-modal, appear only when
needed, require a minimal number of user gestures, and do not add to the
standard touchscreen gesture vocabulary. We discuss our implementation of tap
tips in an electronic guidebook system and some usability test results.
</summary>
    <author>
      <name>Paul M. Aoki</name>
    </author>
    <author>
      <name>Amy Hurst</name>
    </author>
    <author>
      <name>Allison Woodruff</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/634067.634208</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/634067.634208" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Extended Abstracts, ACM SIGCHI Conf. on Human Factors in Computing
  Systems, Seattle, WA, March 2001, 237-238. ACM Press.</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0101029v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0101029v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.2; H.5.4; I.3.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0101035v2</id>
    <updated>2001-02-02T04:48:43Z</updated>
    <published>2001-01-28T07:14:46Z</published>
    <title>The Guidebook, the Friend, and the Room: Visitor Experience in a
  Historic House</title>
    <summary>  In this paper, we describe an electronic guidebook prototype and report on a
study of its use in a historic house. Supported by mechanisms in the guidebook,
visitors constructed experiences that had a high degree of interaction with
three entities: the guidebook, their companions, and the house and its
contents. For example, we found that most visitors played audio descriptions
played through speakers (rather than using headphones or reading textual
descriptions) to facilitate communication with their companions.
</summary>
    <author>
      <name>Allison Woodruff</name>
    </author>
    <author>
      <name>Paul M. Aoki</name>
    </author>
    <author>
      <name>Amy Hurst</name>
    </author>
    <author>
      <name>Margaret H. Szymanski</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/634067.634229</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/634067.634229" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Extended Abstracts, ACM SIGCHI Conf. on Human Factors in Computing
  Systems, Seattle, WA, March 2001, 273-274. ACM Press.</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0101035v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0101035v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.1; H.5.2; J.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0110006v1</id>
    <updated>2001-10-02T12:08:41Z</updated>
    <published>2001-10-02T12:08:41Z</published>
    <title>Electronic Commerce, Consumer Search and Retailing Cost Reduction</title>
    <summary>  This paper explains four things in a unified way. First, how e-commerce can
generate price equilibria where physical shops either compete with virtual
shops for consumers with Internet access, or alternatively, sell only to
consumers with no Internet access. Second, how these price equilibria might
involve price dispersion on-line. Third, why prices may be higher on-line.
Fourth, why established firms can, but need not, be more reluctant than newly
created firm to adopt e-commerce. For this purpose we develop a model where
e-commerce reduces consumers' search costs, involves trade-offs for consumers,
and reduces retailing costs.
</summary>
    <author>
      <name>Pedro Pereira</name>
    </author>
    <author>
      <name>Cristina Mazón</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">29th TPRC Conference, 2001</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0110006v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0110006v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="K.4.m Miscellaneous" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0204030v4</id>
    <updated>2002-08-21T18:21:46Z</updated>
    <published>2002-04-12T15:07:46Z</published>
    <title>Fast Hands-free Writing by Gaze Direction</title>
    <summary>  We describe a method for text entry based on inverse arithmetic coding that
relies on gaze direction and which is faster and more accurate than using an
on-screen keyboard.
  These benefits are derived from two innovations: the writing task is matched
to the capabilities of the eye, and a language model is used to make
predictable words and phrases easier to write.
</summary>
    <author>
      <name>David J. Ward</name>
    </author>
    <author>
      <name>David J. C. MacKay</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1038/418838a</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1038/418838a" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3 pages. Final version</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Nature 418, 2002 p. 838 (22nd August 2002) www.nature.com</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0204030v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0204030v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.2;K.4.2;H.1.1;H.5.1;I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0207013v1</id>
    <updated>2002-07-04T16:02:41Z</updated>
    <published>2002-07-04T16:02:41Z</published>
    <title>A Compact Graph Model of Handwritten Images: Integration into
  Authentification and Recognition</title>
    <summary>  A novel algorithm for creating a mathematical model of curved shapes is
introduced. The core of the algorithm is based on building a graph
representation of the contoured image, which occupies less storage space than
produced by raster compression techniques. Different advanced applications of
the mathematical model are discussed: recognition of handwritten characters and
verification of handwritten text and signatures for authentification purposes.
Reducing the storage requirements due to the efficient mathematical model
results in faster retrieval and processing times. The experimental outcomes in
compression of contoured images and recognition of handwritten numerals are
given.
</summary>
    <author>
      <name>Denis V. Popel</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 6 figures, 1 tables, SSPR'02</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">SSPR 2002</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0207013v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0207013v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.2.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0210014v1</id>
    <updated>2002-10-16T07:42:30Z</updated>
    <published>2002-10-16T07:42:30Z</published>
    <title>Current state of the Sonix -- the IBR-2 instrument control software and
  plans for future developments</title>
    <summary>  The Sonix is the main control software for the IBR-2 instruments. This is a
modular configurable and flexible system created using the Varman (real time
database) and the X11/OS9 graphical package in the OS-9 environment. In the
last few years we were mostly focused on making this system more reliable and
user friendly. Because the VME hardware and software upgrade is rather
expensive we would like to replace existing VME + OS9 control computers with
the PC+Windows XP ones in the future. This could be done with the help of
VME-PCI adapters.
</summary>
    <author>
      <name>A. S. Kirilov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Invited talk at NOBUGS2002 Conference, NIST, Gaithersburg, MD NOBUGS
  abstract identifier NOBUGS2002/015 5 pages, pdf, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0210014v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0210014v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.2.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0304001v1</id>
    <updated>2003-03-31T22:49:29Z</updated>
    <published>2003-03-31T22:49:29Z</published>
    <title>Design Guidelines for Landmarks to Support Navigation in Virtual
  Environments</title>
    <summary>  Unfamiliar, large-scale virtual environments are difficult to navigate. This
paper presents design guidelines to ease navigation in such virtual
environments. The guidelines presented here focus on the design and placement
of landmarks in virtual environments. Moreover, the guidelines are based
primarily on the extensive empirical literature on navigation in the real
world. A rationale for this approach is provided by the similarities between
navigational behavior in real and virtual environments.
</summary>
    <author>
      <name>Norman G. Vinson</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 1 figure</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the SIGCHI conference on Human factors in computing
  systems: the CHI is the limit, p.278-285, May 15-20, 1999, Pittsburgh,
  Pennsylvania, United States</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0304001v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0304001v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.4; I.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0305003v1</id>
    <updated>2003-05-05T11:32:59Z</updated>
    <published>2003-05-05T11:32:59Z</published>
    <title>The Ubiquitous Interactor - Device Independent Access to Mobile Services</title>
    <summary>  The Ubiquitous Interactor (UBI) addresses the problems of design and
development that arise around services that need to be accessed from many
different devices. In UBI, the same service can present itself with different
user interfaces on different devices. This is done by separating interaction
between users and services from presentation. The interaction is kept the same
for all devices, and different presentation information is provided for
different devices. This way, tailored user interfaces for many different
devices can be created without multiplying development and maintenance work. In
this paper we describe the system design of UBI, the system implementation, and
two services implemented for the system: a calendar service and a stockbroker
service.
</summary>
    <author>
      <name>Stina Nylander</name>
    </author>
    <author>
      <name>Markus Bylund</name>
    </author>
    <author>
      <name>Annika Waern</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0305003v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0305003v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0306087v1</id>
    <updated>2003-06-14T05:42:43Z</updated>
    <published>2003-06-14T05:42:43Z</published>
    <title>OO Model of the STAR offline production "Event Display" and its
  implementation based on Qt-ROOT</title>
    <summary>  The paper presents the "Event Display" package for the STAR offline
production as a special visualization tool to debug the reconstruction code.
This can be achieved if an author of the algorithm / code may build his/her own
custom Event Display alone from the base software blocks and re-used some
well-designed, easy to learn user-friendly patterns. For STAR offline
production Event Display ROOT with Qt lower level interface was chosen as the
base tools.
</summary>
    <author>
      <name>Valeri Fine</name>
    </author>
    <author>
      <name>Jerome Lauret</name>
    </author>
    <author>
      <name>Victor Perevoztchikov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3 pages, 4 figures, Computing in High Energy Physics, CHEP2003, La
  Jolla California, USA, March 24-28</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0306087v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0306087v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.7; D.1.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0310013v1</id>
    <updated>2003-10-08T14:07:42Z</updated>
    <published>2003-10-08T14:07:42Z</published>
    <title>WebTeach in practice: the entrance test to the Engineering faculty in
  Florence</title>
    <summary>  We present the WebTeach project, formed by a web interface to database for
test management, a wiki site for the diffusion of teaching material and student
forums, and a suite for the generation of multiple-choice mathematical quiz
with automatic elaboration of forms. This system has been massively tested for
the entrance test to the Engineering Faculty of the University of Florence,
Italy
</summary>
    <author>
      <name>Franco Bagnoli</name>
    </author>
    <author>
      <name>Fabio Franci</name>
    </author>
    <author>
      <name>Francesco Mugelli</name>
    </author>
    <author>
      <name>Andrea Sterbini</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0310013v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0310013v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="K.3.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0311006v1</id>
    <updated>2003-11-07T02:17:34Z</updated>
    <published>2003-11-07T02:17:34Z</published>
    <title>How Push-To-Talk Makes Talk Less Pushy</title>
    <summary>  This paper presents an exploratory study of college-age students using
two-way, push-to-talk cellular radios. We describe the observed and reported
use of cellular radio by the participants. We discuss how the half-duplex,
lightweight cellular radio communication was associated with reduced
interactional commitment, which meant the cellular radios could be used for a
wide range of conversation styles. One such style, intermittent conversation,
is characterized by response delays. Intermittent conversation is surprising in
an audio medium, since it is typically associated with textual media such as
instant messaging. We present design implications of our findings.
</summary>
    <author>
      <name>Allison Woodruff</name>
    </author>
    <author>
      <name>Paul M. Aoki</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/958160.958187</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/958160.958187" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. ACM SIGGROUP Conf. on Supporting Group Work, Sanibel Island,
  FL, Nov. 2003, 170-179. ACM Press.</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0311006v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0311006v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.4.3; H.5.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0312010v1</id>
    <updated>2003-12-04T05:26:51Z</updated>
    <published>2003-12-04T05:26:51Z</published>
    <title>Designing of a Community-based Translation Center</title>
    <summary>  Interfaces that support multi-lingual content can reach a broader community.
We wish to extend the reach of CITIDEL, a digital library for computing
education materials, to support multiple languages. By doing so, we hope that
it will increase the number of users, and in turn the number of resources. This
paper discusses three approaches to translation (automated translation,
developer-based, and community-based), and a brief evaluation of these
approaches. It proposes a design for an online community translation center
where volunteers help translate interface components and educational materials
available in CITIDEL.
</summary>
    <author>
      <name>Kathleen McDevitt</name>
    </author>
    <author>
      <name>Manuel A. Perez-Quinones</name>
    </author>
    <author>
      <name>Olga I. Padilla-Falto</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0312010v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0312010v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.2; H.3.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0312017v1</id>
    <updated>2003-12-09T03:44:07Z</updated>
    <published>2003-12-09T03:44:07Z</published>
    <title>An Exploratory Study of Mobile Computing Use by Knowledge Workers</title>
    <summary>  This paper describes some preliminary results from a 20-week study on the use
of Compaq iPAQ Personal Digital Assistants (PDAs) by 10 senior developers,
analysts, technical managers, and senior organisational managers. The goal of
the study was to identify what applications were used, how and where they were
used, the problems and issues that arose, and how use of the iPAQs changed over
the study period. The paper highlights some interesting uses of the iPAQs, and
identifies some of the characteristics of successful mobile applications.
</summary>
    <author>
      <name>Paul Prekop</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in: Proceedings of the 2003 Australasian Computer Human
  Interaction Conference (OzCHI 2003), University of Queensland, Australia,
  November 26-28 2003</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0312017v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0312017v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H1.2;H5.2;J1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0401007v1</id>
    <updated>2004-01-12T18:45:47Z</updated>
    <published>2004-01-12T18:45:47Z</published>
    <title>Design of a Community-based Translation Center</title>
    <summary>  Interfaces that support multi-lingual content can reach a broader community.
We wish to extend the reach of CITIDEL, a digital library for computing
education materials, to support multiple languages. By doing so, we hope that
it will increase the number of users, and in turn the number of resources. This
paper discusses three approaches to translation (automated translation,
developer-based, and community-based), and a brief evaluation of these
approaches. It proposes a design for an online community translation center
where volunteers help translate interface components and educational materials
available in CITIDEL.
</summary>
    <author>
      <name>K. McDevitt</name>
    </author>
    <author>
      <name>M. A. Pérez-Quiñones</name>
    </author>
    <author>
      <name>O. I. Padilla-Falto</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0401007v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0401007v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.7; J.5; H.1.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0402036v1</id>
    <updated>2004-02-16T21:56:03Z</updated>
    <published>2004-02-16T21:56:03Z</published>
    <title>Towards a Model-Based Framework for Integrating Usability and Software
  Engineering Life Cycles</title>
    <summary>  In this position paper we propose a process model that provides a development
infrastructure in which the usability engineering and software engineering life
cycles co-exist in complementary roles. We describe the motivation, hurdles,
rationale, arguments, and implementation plan for the need, specification, and
the usefulness of such a model.
</summary>
    <author>
      <name>Pardha S. Pyla</name>
    </author>
    <author>
      <name>Manuel A. Perez-Quinones</name>
    </author>
    <author>
      <name>James D. Arthur</name>
    </author>
    <author>
      <name>H. Rex Hartson</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This document contains 8 pages with 5 figures. This appeared in
  Bridging the SE &amp; HCI Communities Workshop in INTERACT 2003
  (http://www.se-hci.org/bridging/interact)</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0402036v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0402036v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.0; K.6.1; K.6.3; D.2.9" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0405078v1</id>
    <updated>2004-05-23T09:53:12Z</updated>
    <published>2004-05-23T09:53:12Z</published>
    <title>Generative Programming of Graphical User Interfaces</title>
    <summary>  Generative Programming (GP) is a computing paradigm allowing automatic
creation of entire software families utilizing the configuration of elementary
and reusable components. GP can be projected on different technologies, e.g.
C++-templates, Java-Beans, Aspect-Oriented Programming (AOP), or Frame
technology. This paper focuses on Frame Technology, which aids the possible
implementation and completion of software components. The purpose of this paper
is to introduce the GP paradigm in the area of GUI application generation. It
demonstrates how automatically customized executable applications with GUI
parts can be generated from an abstract specification.
</summary>
    <author>
      <name>Max Schlee</name>
    </author>
    <author>
      <name>Jean Vanderdonckt</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 12 figures, ACM Conference on Visual Interfaces AVI'2004</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0405078v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0405078v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.2.1, D.2.2, H.2.4, I.3.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0405109v1</id>
    <updated>2004-05-28T02:59:54Z</updated>
    <published>2004-05-28T02:59:54Z</published>
    <title>Conversation Analysis and the User Experience</title>
    <summary>  We provide two case studies in the application of ideas drawn from
conversation analysis to the design of technologies that enhance the experience
of human conversation. We first present a case study of the design of an
electronic guidebook, focusing on how conversation analytic principles played a
role in the design process. We then discuss how the guidebook project has
inspired our continuing work in social, mobile audio spaces. In particular, we
describe some as yet unrealized concepts for adaptive audio spaces.
</summary>
    <author>
      <name>Allison Woodruff</name>
    </author>
    <author>
      <name>Paul M. Aoki</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Workshop on Exploring Experience Methods Across Disciplines, ACM
  SIGCHI Conf. on Human Factors in Computing Systems (CHI 2004), Vienna,
  Austria, Apr. 2004.</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0405109v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0405109v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.2; H.1.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0510034v1</id>
    <updated>2005-10-14T01:03:55Z</updated>
    <published>2005-10-14T01:03:55Z</published>
    <title>COMODI: On the Graphical User Interface</title>
    <summary>  We propose a series of features for the graphical user interface (GUI) of the
COmputational MOdule Integrator (COMODI) \cite{Synasc05a}\cite{COMODI}. In view
of the special requirements that a COMODI type of framework for scientific
computing imposes and inspiring from existing solutions that provide advanced
graphical visual programming environments, we identify those elements and
associated behaviors that will have to find their way into the first release of
COMODI.
</summary>
    <author>
      <name>Zsolt I. Lázár</name>
    </author>
    <author>
      <name>Andreea Fanea</name>
    </author>
    <author>
      <name>Dragoş Petraşcu</name>
    </author>
    <author>
      <name>Vladiela Ciobotariu-Boer</name>
    </author>
    <author>
      <name>Bazil Pârv</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 5 figures, to be published as proceedings of SYNASC 2005</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0510034v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0510034v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.2.13; D.2.12; D.2.11; D.2.9; D.2.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0601025v1</id>
    <updated>2006-01-09T13:52:32Z</updated>
    <published>2006-01-09T13:52:32Z</published>
    <title>Prop-Based Haptic Interaction with Co-location and Immersion: an
  Automotive Application</title>
    <summary>  Most research on 3D user interfaces aims at providing only a single sensory
modality. One challenge is to integrate several sensory modalities into a
seamless system while preserving each modality's immersion and performance
factors. This paper concerns manipulation tasks and proposes a visuo-haptic
system integrating immersive visualization, tactile force and tactile feedback
with co-location. An industrial application is presented.
</summary>
    <author>
      <name>Michael Ortega</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rhône-Alpes</arxiv:affiliation>
    </author>
    <author>
      <name>Sabine Coquillart</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rhône-Alpes</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Dans HAVE 2005 - IEEE International Workshop on Haptic Audio
  Visual Environments and their Applications</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0601025v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0601025v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0604103v1</id>
    <updated>2006-04-25T19:53:19Z</updated>
    <published>2006-04-25T19:53:19Z</published>
    <title>Further Evaluationh of VLEs using HCI and Educational Metrics</title>
    <summary>  Under consideration are the general set of Human computer Interaction (HCI)
and Educational principles from prominent authors in the field and the
construction of a system for evaluating Virtual Learning Environments (VLEs)
with respect to the application of these HCI and Educational Principles. A
frequency analysis of principles is used to obtain the most significant set.
Metrics are devised to provide objective measures of these principles and a
consistent testing regime is introduced. These principles are used to analyse
the University VLE Blackboard. An open source VLE is also constructed with
similar content to Blackboard courses so that a systematic comparison can be
made. HCI and Educational metrics are determined for each VLE.
</summary>
    <author>
      <name>Vita Hinze-Hoare</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0604103v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0604103v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0605147v1</id>
    <updated>2006-05-30T15:32:41Z</updated>
    <published>2006-05-30T15:32:41Z</published>
    <title>Utilisation de la linguistique en reconnaissance de la parole : un
  état de l'art</title>
    <summary>  To transcribe speech, automatic speech recognition systems use statistical
methods, particularly hidden Markov model and N-gram models. Although these
techniques perform well and lead to efficient systems, they approach their
maximum possibilities. It seems thus necessary, in order to outperform current
results, to use additional information, especially bound to language. However,
introducing such knowledge must be realized taking into account specificities
of spoken language (hesitations for example) and being robust to possible
misrecognized words. This document presents a state of the art of these
researches, evaluating the impact of the insertion of linguistic information on
the quality of the transcription.
</summary>
    <author>
      <name>Stéphane Huet</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IRISA / INRIA Rennes, IRISA / INRIA Rennes</arxiv:affiliation>
    </author>
    <author>
      <name>Pascale Sébillot</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IRISA / INRIA Rennes</arxiv:affiliation>
    </author>
    <author>
      <name>Guillaume Gravier</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IRISA / INRIA Rennes</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/cs/0605147v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0605147v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0606107v1</id>
    <updated>2006-06-26T15:58:40Z</updated>
    <published>2006-06-26T15:58:40Z</published>
    <title>Human Information Processing with the Personal Memex</title>
    <summary>  In this report, we describe the work done in a project that explored the
human information processing aspects of a personal memex (a memex to organize
personal information). In the project, we considered the use of the personal
memex, focusing on information recall, by three populations: people with Mild
Cognitive Impairment, those diagnosed with Macular Degeneration, and a
high-functioning population. The outcomes of the project included human
information processing-centered design guidelines for the memex interface, a
low-fidelity prototype, and an annotated bibliography for human information
processing, usability and design literature relating to the memex and the
populations we explored.
</summary>
    <author>
      <name>Ingrid Burbey</name>
    </author>
    <author>
      <name>Gyuhyun Kwon</name>
    </author>
    <author>
      <name>Uma Murthy</name>
    </author>
    <author>
      <name>Nicholas Polys</name>
    </author>
    <author>
      <name>Prince Vincent</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0606107v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0606107v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0607072v1</id>
    <updated>2006-07-14T16:00:40Z</updated>
    <published>2006-07-14T16:00:40Z</published>
    <title>Effect of Interface Style in Peer Review Comments for UML Designs</title>
    <summary>  This paper presents our evaluation of using a Tablet-PC to provide
peer-review comments in the first year Computer Science course. Our exploration
consisted of an evaluation of how students write comments on other students'
assignments using three different methods: pen and paper, a Tablet-PC, and a
desktop computer. Our ultimate goal is to explore the effect that interface
style (Tablet vs. Desktop) has on the quality and quantity of the comments
provided.
</summary>
    <author>
      <name>Scott A. Turner</name>
    </author>
    <author>
      <name>Manuel A. Perez-Quinones</name>
    </author>
    <author>
      <name>Stephen H. Edwards</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0607072v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0607072v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.1; H.4; H.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0611014v1</id>
    <updated>2006-11-03T14:34:57Z</updated>
    <published>2006-11-03T14:34:57Z</published>
    <title>Interactive Problem Solving in Prolog</title>
    <summary>  This paper presents an environment for solving Prolog problems which has been
implemented as a module for the virtual laboratory VILAB. During the problem
solving processes the learners get fast adaptive feedback. As a result
analysing the learner's actions the system suggests the use of suitable
auxiliary predicates which will also be checked for proper implementation. The
focus of the environment has been set on robustness and the integration in
VILAB.
</summary>
    <author>
      <name>Erik Braun</name>
    </author>
    <author>
      <name>Rainer Luetticke</name>
    </author>
    <author>
      <name>Ingo Gloeckner</name>
    </author>
    <author>
      <name>Hermann Helbig</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 1 figure, accepted for publication: Interactive computer
  aided learning (ICL) 2006, International Conference in Villach (Austria).
  Paper was not published because the authors were not able to participate on
  the conference</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0611014v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0611014v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="K.3.1; K.3.2; D.1.6; I.2.6; H.5.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0611151v2</id>
    <updated>2007-02-01T09:05:31Z</updated>
    <published>2006-11-29T16:22:18Z</published>
    <title>Collaborative design : managing task interdependencies and multiple
  perspectives</title>
    <summary>  This paper focuses on two characteristics of collaborative design with
respect to cooperative work: the importance of work interdependencies linked to
the nature of design problems; and the fundamental function of design
cooperative work arrangement which is the confrontation and combination of
perspectives. These two intrinsic characteristics of the design work stress
specific cooperative processes: coordination processes in order to manage task
interdependencies, establishment of common ground and negotiation mechanisms in
order to manage the integration of multiple perspectives in design.
</summary>
    <author>
      <name>Françoise Détienne</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Interacting With Computers 18, 1 (2006) 1-20</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0611151v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0611151v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0611152v2</id>
    <updated>2007-02-01T09:03:34Z</updated>
    <published>2006-11-29T16:24:20Z</published>
    <title>Viewpoints in co-design: a field study in concurrent engineering</title>
    <summary>  We present a field study aimed at analysing the use of viewpoints in
co-design meetings. A viewpoint is a representation characterised by a certain
combination of constraints. Three types of viewpoints are distinguished:
prescribed viewpoint, discipline-specific viewpoint and integrated viewpoint.
The contribution of our work consists in characterising the viewpoints of
various stakeholders involved in co-design ("design office" disciplines, and
production and maintenance disciplines), the dynamics of viewpoints
confrontation and the cooperative modes that enable these different viewpoints
to be integrated.
</summary>
    <author>
      <name>Françoise Détienne</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA</arxiv:affiliation>
    </author>
    <author>
      <name>Géraldine Martin</name>
    </author>
    <author>
      <name>Elisabeth Lavigne</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Design Studies 26, 3 (2005) 215-241</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0611152v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0611152v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0612010v2</id>
    <updated>2007-02-01T09:04:37Z</updated>
    <published>2006-12-01T11:43:08Z</published>
    <title>Articulation entre composantes verbale et graphico-gestuelle de
  l'interaction dans des réunions de conception architecturale</title>
    <summary>  This study is focused on the role of external representations, e.g.,
skteches, in collaborative architectural design. In particular, we analyse (1)
the use of graphico-gestural modalities and, (2) the articulation modes between
graphico-gestural and verbal modalities in design interaction. We have
elaborated a first classification which distinguishes between two modes of
articulation, articulation in integrated activities versus articulation in
parallel activities.
</summary>
    <author>
      <name>Willemien Visser</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rocquencourt, INRIA</arxiv:affiliation>
    </author>
    <author>
      <name>Françoise Détienne</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rocquencourt, INRIA</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Dans SCAN'05 (2005)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0612010v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0612010v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0612016v2</id>
    <updated>2007-03-02T12:47:49Z</updated>
    <published>2006-12-04T13:48:22Z</published>
    <title>Memory of past designs: distinctive roles in individual and collective
  design</title>
    <summary>  Empirical studies on design have emphasised the role of memory of past
solutions. Design involves the use of generic knowledge as well as episodic
knowledge about past designs for analogous problems : in this way, it involves
the reuse of past designs. We analyse this mechanism of reuse from a
socio-cognitive viewpoint. According to a purely cognitive approach, reuse
involves cognitive mechanisms linked to the problem solving activity itself.
Our socio-cognitive approach accounts for these phenomena as well as reuse
mechanisms linked to cooperation, in particular coordination, and
confrontation/integration of viewpoints.
</summary>
    <author>
      <name>Françoise Détienne</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Cognitive Technology Journal 1, 8 (2003) 16-24</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0612016v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0612016v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0612021v2</id>
    <updated>2007-03-04T20:14:42Z</updated>
    <published>2006-12-04T16:27:32Z</published>
    <title>Multimodality and parallelism in design interaction: co-designers'
  alignment and coalitions</title>
    <summary>  This paper presents an analysis of various forms of articulation between
graphico-gestural and verbal modalities in parallel interactions between
designers in a collaborative design situation. Based on our methodological
framework, we illustrate several forms of multimodal articulations, that is,
integrated and non-integrated, through extracts from a corpus on an
architectural design meeting. These modes reveal alignment or disalignment
between designers, with respect to the focus of their activities. They also
show different forms of coalition.
</summary>
    <author>
      <name>Françoise Détienne</name>
    </author>
    <author>
      <name>Willemien Visser</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Dans COOP'2006 Volume 137 (2006) 118-131</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0612021v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0612021v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0612022v1</id>
    <updated>2006-12-04T16:28:44Z</updated>
    <published>2006-12-04T16:28:44Z</published>
    <title>Both Generic Design and Different Forms of Designing</title>
    <summary>  This paper defends an augmented cognitively oriented "generic-design
hypothesis": There are both significant similarities between the design
activities implemented in different situations and crucial differences between
these and other cognitive activities; yet, characteristics of a design
situation (i.e., related to the designers, the artefact, and other task
variables influencing these two) introduce specificities in the corresponding
design activities and cognitive structures that are used. We thus combine the
generic-design hypothesis with that of different "forms" of designing. In this
paper, outlining a number of directions that need further elaboration, we
propose a series of candidate dimensions underlying such forms of design.
</summary>
    <author>
      <name>Willemien Visser</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rocquencourt</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Dans Wonderground, the 2006 DRS (Design Research Society)
  International Conference (2006)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0612022v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0612022v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0701199v2</id>
    <updated>2007-05-24T20:45:24Z</updated>
    <published>2007-01-31T16:36:43Z</published>
    <title>A Virtual Logo Keyboard for People with Motor Disabilities</title>
    <summary>  In our society, people with motor impairments are oftentimes socially
excluded from their environment. This is unfortunate because every human being
should have the possibility to obtain the necessary conditions to live a normal
life. Although there is technology to assist people with motor impairments, few
systems are targeted for programming environments. We have created a system,
called Logo Keyboard, to assist people with motor disabilities to program with
the Logo programming language. With this special keyboard we can help more
people to get involved into computer programming and to develop projects in
different areas.
</summary>
    <author>
      <name>Stephane Norte</name>
    </author>
    <author>
      <name>Fernando G. Lobo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0701199v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0701199v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.2; K.3.1; K.4.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0702004v1</id>
    <updated>2007-02-01T09:03:19Z</updated>
    <published>2007-02-01T09:03:19Z</published>
    <title>What model(s) for program understanding?</title>
    <summary>  The first objective of this paper is to present and discuss various types of
models of program understanding. They are discussed in relation to models of
text understanding. The second objective of this paper is to assess the effect
of purpose for reading, or more specifically programming task, on the cognitive
processes involved and representations constructed in program understanding.
This is done in the theoretical framework of van Dijk and Kintsch's model of
text understanding (1983).
</summary>
    <author>
      <name>Françoise Détienne</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Dans UCIS'96, Conference on Using Complex Information Systems
  (1996)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0702004v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0702004v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0702005v1</id>
    <updated>2007-02-01T09:03:59Z</updated>
    <published>2007-02-01T09:03:59Z</published>
    <title>An empirical study of software reuse by experts in object-oriented
  design</title>
    <summary>  This paper presents an empirical study of the software reuse activity by
expert designers in the context of object-oriented design. Our study focuses on
the three following aspects of reuse : (1) the interaction between some design
processes, e.g. constructing a problem representation, searching for and
evaluating solutions, and reuse processes, i.e. retrieving and using previous
solutions, (2) the mental processes involved in reuse, e.g. example-based
retrieval or bottom-up versus top-down expanding of the solution, and (3) the
mental representations constructed throughout the reuse activity, e.g. dynamic
versus static representations. Some implications of these results for the
specification of software reuse support environments are discussed.
</summary>
    <author>
      <name>Jean-Marie Burkhardt</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA, LEI</arxiv:affiliation>
    </author>
    <author>
      <name>Françoise Détienne</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Dans INTERACT'95 (1995)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0702005v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0702005v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0704.2542v1</id>
    <updated>2007-04-19T14:27:25Z</updated>
    <published>2007-04-19T14:27:25Z</published>
    <title>Narratives within immersive technologies</title>
    <summary>  The main goal of this project is to research technical advances in order to
enhance the possibility to develop narratives within immersive mediated
environments. An important part of the research is concerned with the question
of how a script can be written, annotated and realized for an immersive
context. A first description of the main theoretical framework and the ongoing
work and a first script example is provided. This project is part of the
program for presence research, and it will exploit physiological feedback and
Computational Intelligence within virtual reality.
</summary>
    <author>
      <name>Joan Llobera</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/0704.2542v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0704.2542v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0704.3643v1</id>
    <updated>2007-04-27T00:42:22Z</updated>
    <published>2007-04-27T00:42:22Z</published>
    <title>Sabbath Day Home Automation: "It's Like Mixing Technology and Religion"</title>
    <summary>  We present a qualitative study of 20 American Orthodox Jewish families' use
of home automation for religious purposes. These lead users offer insight into
real-life, long-term experience with home automation technologies. We discuss
how automation was seen by participants to contribute to spiritual experience
and how participants oriented to the use of automation as a religious custom.
We also discuss the relationship of home automation to family life. We draw
design implications for the broader population, including surrender of control
as a design resource, home technologies that support long-term goals and
lifestyle choices, and respite from technology.
</summary>
    <author>
      <name>Allison Woodruff</name>
    </author>
    <author>
      <name>Sally Augustin</name>
    </author>
    <author>
      <name>Brooke Foucault</name>
    </author>
    <link href="http://arxiv.org/abs/0704.3643v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0704.3643v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0708.1725v2</id>
    <updated>2009-08-20T14:55:41Z</updated>
    <published>2007-08-13T15:00:37Z</published>
    <title>Design: One, but in different forms</title>
    <summary>  This overview paper defends an augmented cognitively oriented generic-design
hypothesis: there are both significant similarities between the design
activities implemented in different situations and crucial differences between
these and other cognitive activities; yet, characteristics of a design
situation (related to the design process, the designers, and the artefact)
introduce specificities in the corresponding cognitive activities and
structures that are used, and in the resulting designs. We thus augment the
classical generic-design hypothesis with that of different forms of designing.
We review the data available in the cognitive design research literature and
propose a series of candidates underlying such forms of design, outlining a
number of directions requiring further elaboration.
</summary>
    <author>
      <name>Willemien Visser</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LTCI</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.destud.2008.11.004</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.destud.2008.11.004" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Design Studies 30, 3 (2009) 187-223</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0708.1725v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0708.1725v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0709.0370v1</id>
    <updated>2007-09-04T09:20:03Z</updated>
    <published>2007-09-04T09:20:03Z</published>
    <title>An Integrated Simulation System for Human Factors Study</title>
    <summary>  It has been reported that virtual reality can be a useful tool for ergonomics
study. The proposed integrated simulation system aims at measuring operator's
performance in an interactive way for 2D control panel design. By incorporating
some sophisticated virtual reality hardware/software, the system allows natural
human-system and/or human-human interaction in a simulated virtual environment;
enables dynamic objective measurement of human performance; and evaluates the
quality of the system design in human factors perspective based on the
measurement. It can also be for operation training for some 2D control panels.
</summary>
    <author>
      <name>Ying Wang</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">DIE</arxiv:affiliation>
    </author>
    <author>
      <name>Wei Zhang</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">DIE</arxiv:affiliation>
    </author>
    <author>
      <name>Fouad Bennis</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IRCCyN</arxiv:affiliation>
    </author>
    <author>
      <name>Damien Chablat</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IRCCyN</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Dans The Institute of Industrial Engineers Annual Conference - The
  Institute of Industrial Engineers Annual Conference, Orlando : \'Etats-Unis
  d'Am\'erique (2006)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0709.0370v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0709.0370v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0709.0426v1</id>
    <updated>2007-09-04T13:23:40Z</updated>
    <published>2007-09-04T13:23:40Z</published>
    <title>Do oral messages help visual search?</title>
    <summary>  A preliminary experimental study is presented, that aims at eliciting the
contribution of oral messages to facilitating visual search tasks on crowded
visual displays. Results of quantitative and qualitative analyses suggest that
appropriate verbal messages can improve both target selection time and
accuracy. In particular, multimodal messages including a visual presentation of
the isolated target together with absolute spatial oral information on its
location in the displayed scene seem most effective. These messages also got
top-ranking ratings from most subjects.
</summary>
    <author>
      <name>Noëlle Carbonell</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rocquencourt / INRIA Lorraine - LORIA</arxiv:affiliation>
    </author>
    <author>
      <name>Suzanne Kieffer</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rocquencourt / INRIA Lorraine - LORIA</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">26 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Advances in Natural Multimodal Dialogue Systems, Dordrecht (NL)
  Springer (Ed.) (2005) pp. 131-157</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0709.0426v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0709.0426v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0709.1056v3</id>
    <updated>2007-09-17T21:08:35Z</updated>
    <published>2007-09-07T11:59:22Z</published>
    <title>A Sudoku Game for People with Motor Impairments</title>
    <summary>  Computer games are motivating and beneficial in learning different
educational skills. Most people use their fingers, hands, and arms when using a
computer game. However, for people with motor disabilities this task can be a
barrier. We present a new Sudoku game for people whose motion is impaired,
called Sudoku 4ALL. With this special interface a person can control the game
with the voice or with a single switch. Our research aims to cautiously search
for issues that might be appropriate for computational support and to build
enabling technologies that increase individuals' functional independence in a
game environment.
</summary>
    <author>
      <name>Stephane Norte</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0709.1056v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0709.1056v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.2; K.4.2; K.8.0" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0710.0847v1</id>
    <updated>2007-10-03T17:36:07Z</updated>
    <published>2007-10-03T17:36:07Z</published>
    <title>Emotion capture based on body postures and movements</title>
    <summary>  In this paper we present a preliminary study for designing interactive
systems that are sensible to human emotions based on the body movements. To do
so, we first review the literature on the various approaches for defining and
characterizing human emotions. After justifying the adopted characterization
space for emotions, we then focus on the movement characteristics that must be
captured by the system for being able to recognize the human emotions.
</summary>
    <author>
      <name>Alexis Clay</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIPSI</arxiv:affiliation>
    </author>
    <author>
      <name>Nadine Couture</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIPSI</arxiv:affiliation>
    </author>
    <author>
      <name>Laurence Nigay</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CLIPS - IMAG</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">22 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the International Conference on Computing and
  e-systems 2007 (TIGERA'07), Hammamet : Tunisie (2007)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0710.0847v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0710.0847v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0710.4999v2</id>
    <updated>2007-11-08T08:56:00Z</updated>
    <published>2007-10-26T06:32:22Z</published>
    <title>L'analyse de l'expertise du point de vue de l'ergonomie cognitive</title>
    <summary>  This paper presents a review of methods for collecting and analysing data on
complex activities. Starting with methods developed for design, we examine the
possibility to transpose them to other complex activities, especially
activities referring to sensorial expertise. R\'esum\'e Ce texte pr\'esente une
revue de m\'ethodes pour recueillir et analyser des donn\'ees sur des
actvit\'es complexes. A partir de m\'ethodes d\'evelopp\'ees pour des
actvit\'es de conception, nous examinons la possibilit\'e de les transposer \`a
d'autres actvit\'es complexes, notamment des actvit\'es faisant \`a appel \`a
des expertises sensorielles.
</summary>
    <author>
      <name>Willemien Visser</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rocquencourt</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Dans Les expertises sensorielles : Nature et acquisition (2006)
  1-12</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0710.4999v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0710.4999v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0712.2183v1</id>
    <updated>2007-12-13T16:43:56Z</updated>
    <published>2007-12-13T16:43:56Z</published>
    <title>Apports des démarches d'inspection et des tests d'usage dans
  l'évaluation de l'accessibilité de E-services</title>
    <summary>  This article proposes to describe and compare the contributions of various
techniques of evaluation of the accessibility of E-services carried out
starting from (i) methods of inspection (on the basis of traditional ergonomic
criteria and accessibility) and (ii) of tests of use. It show that these are
the latter which show the best rate of identification of the problems of uses
for the poeple with disabilities
</summary>
    <author>
      <name>Marc-Eric Bobiller-Chaumon</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">GRePS</arxiv:affiliation>
    </author>
    <author>
      <name>Françoise Sandoz-Guermond</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIESP</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Dans Actes du congr\`es ERGO IA'2006 - ERGO'IA : L'humain comme
  facteur de performance des syst\`emes complexes, Biarritz : France (2006)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0712.2183v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0712.2183v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0712.3215v1</id>
    <updated>2007-12-19T15:54:07Z</updated>
    <published>2007-12-19T15:54:07Z</published>
    <title>L'accessibilité des E-services aux personnes non-voyantes :
  difficultés d'usage et recommandations</title>
    <summary>  While taking into account handicapped people in the design of technologies
represents a social and political stake that becomes important (in particular
with the recent law on equal rights for all the citizens, March 2004), this
paper aims at evaluating the level of accessibility of two sites of E-services
thanks to tests of use and proposing a set of recommendations in order to
increase usability for the largest amount of people.
</summary>
    <author>
      <name>Françoise Sandoz-Guermond</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIESP</arxiv:affiliation>
    </author>
    <author>
      <name>Marc-Eric Bobiller-Chaumon</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">GRePS</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Dans International Conference Proceedings of IHM'2006 - IIHM :
  Interaction Homme Machine, Montr\'eal : Canada (2006)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0712.3215v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0712.3215v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0712.3433v1</id>
    <updated>2007-12-19T23:31:55Z</updated>
    <published>2007-12-19T23:31:55Z</published>
    <title>AccelKey Selection Method for Mobile Devices</title>
    <summary>  Portable Electronic Devices usually utilize a small screen with limited
viewing area and a keyboard with a limited number of keys. This makes it
difficult to perform quick searches in data arrays containing more than dozen
items such an address book or song list. In this article we present a new data
selection method which allows the user to quickly select an entry from a list
using 4-way navigation device such as joystick, trackball or 4-way key pad.
This method allows for quick navigation using just one hand, without looking at
the screen.
</summary>
    <author>
      <name>Vadim Zaliva</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 12 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0712.3433v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0712.3433v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0801.1033v1</id>
    <updated>2008-01-07T16:05:46Z</updated>
    <published>2008-01-07T16:05:46Z</published>
    <title>The What, Who, Where, When, Why and How of Context-Awareness</title>
    <summary>  The understanding of context and context-awareness is very important for the
areas of handheld and ubiquitous computing. Unfortunately, at present, there
has not been a satisfactory definition of these two concepts that would lead to
a more effective communication in humancomputer interaction. As a result, on
the one hand, application designers are not able to choose what context to use
in their applications and on the other, they cannot determine the type of
context-awareness behaviours their applications should exhibit. In this work,
we aim to provide answers to some fundamental questions that could enlighten us
on the definition of context and its functionality.
</summary>
    <author>
      <name>George Tsibidis</name>
    </author>
    <author>
      <name>Theodoros N. Arvanitis</name>
    </author>
    <author>
      <name>Chris Baber</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted manuscript at the CHI 2000, April 3-2000, The Hague, The
  Netherlands</arxiv:comment>
    <link href="http://arxiv.org/abs/0801.1033v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0801.1033v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0801.3114v1</id>
    <updated>2008-01-21T00:33:15Z</updated>
    <published>2008-01-21T00:33:15Z</published>
    <title>Thinking is Bad: Implications of Human Error Research for Spreadsheet
  Research and Practice</title>
    <summary>  In the spreadsheet error community, both academics and practitioners
generally have ignored the rich findings produced by a century of human error
research. These findings can suggest ways to reduce errors; we can then test
these suggestions empirically. In addition, research on human error seems to
suggest that several common prescriptions and expectations for reducing errors
are likely to be incorrect. Among the key conclusions from human error research
are that thinking is bad, that spreadsheets are not the cause of spreadsheet
errors, and that reducing errors is extremely difficult.
</summary>
    <author>
      <name>Raymond R. Panko</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages including references</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. European Spreadsheet Risks Int. Grp. 2007 69-80 ISBN
  978-905617-58-6</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0801.3114v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0801.3114v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.1; H.4.1; K.6.4; D.2.5; D.2.9; K.8.1; K.3; K.6.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0801.4274v1</id>
    <updated>2008-01-28T13:55:55Z</updated>
    <published>2008-01-28T13:55:55Z</published>
    <title>Computational Models of Spreadsheet Development: Basis for Educational
  Approaches</title>
    <summary>  Among the multiple causes of high error rates in spreadsheets, lack of proper
training and of deep understanding of the computational model upon which
spreadsheet computations rest might not be the least issue. The paper addresses
this problem by presenting a didactical model focussing on cell interaction,
thus exceeding the atomicity of cell computations. The approach is motivated by
an investigation how different spreadsheet systems handle certain computational
issues implied from moving cells, copy-paste operations, or recursion.
</summary>
    <author>
      <name>Karin Hodnigg</name>
    </author>
    <author>
      <name>Markus Clermont</name>
    </author>
    <author>
      <name>Roland T. Mittermeir</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 Pages, 4 figures, includes references</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. European Spreadsheet Risks Int. Grp. 2004 153-168 ISBN 1
  902724 94 1</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0801.4274v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0801.4274v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0802.3478v1</id>
    <updated>2008-02-24T01:57:01Z</updated>
    <published>2008-02-24T01:57:01Z</published>
    <title>It Ain't What You View, But The Way That You View It: documenting
  spreadsheets with Excelsior, semantic wikis, and literate programming</title>
    <summary>  I describe preliminary experiments in documenting Excelsior versions of
spreadsheets using semantic wikis and literate programming. The objective is to
create well-structured and comprehensive documentation, easy to use by those
unfamiliar with the spreadsheets documented. I discuss why so much
documentation is hard to use, and briefly explain semantic wikis and literate
programming; although parts of the paper are Excelsior-specific, these sections
may be of more general interest.
</summary>
    <author>
      <name>Jocelyn Paine</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 Pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2007 131-142
  ISBN 978-905617-58-6</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0802.3478v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0802.3478v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.1; H.4.1; K.6.4; D.2.9" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0802.3480v1</id>
    <updated>2008-02-24T02:10:03Z</updated>
    <published>2008-02-24T02:10:03Z</published>
    <title>Why Task-Based Training is Superior to Traditional Training Methods</title>
    <summary>  The risks of spreadsheet use do not just come from the misuse of formulae. As
such, training needs to go beyond this technical aspect of spreadsheet use and
look at the spreadsheet in its full business context. While standard training
is by and large unable to do this, task-based training is perfectly suited to a
contextual approach to training.
</summary>
    <author>
      <name>Kath McGuire</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 Pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2007 191-196
  ISBN 978-905617-58-6</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0802.3480v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0802.3480v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.2.4; D.2.5; H.4.1; K.6.4; K.8.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0803.0165v1</id>
    <updated>2008-03-03T01:34:30Z</updated>
    <published>2008-03-03T01:34:30Z</published>
    <title>Documenting Spreadsheets</title>
    <summary>  This paper discusses spreadsheets documentation and new means to achieve this
end by using Excel's built-in "Comment" function. By structuring comments, they
can be used as an essential tool to fully explain spreadsheet. This will
greatly facilitate spreadsheet change control, risk management and auditing. It
will fill a crucial gap in corporate governance by adding essential information
that can be managed in order to satisfy internal controls and accountability
standards.
</summary>
    <author>
      <name>Raymond Payette</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 Pages, 15 screen shots</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2006 163-173
  ISBN:1-905617-08-9</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0803.0165v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0803.0165v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.2.4; D.2.5; H.4.1; K.6.4; K.8.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0803.1862v1</id>
    <updated>2008-03-12T22:09:59Z</updated>
    <published>2008-03-12T22:09:59Z</published>
    <title>Exploring Human Factors in Spreadsheet Development</title>
    <summary>  In this paper we consider human factors and their impact on spreadsheet
development in strategic decision-making. This paper brings forward research
from many disciplines both directly related to spreadsheets and a broader
spectrum from psychology to industrial processing. We investigate how human
factors affect a simplified development cycle and what the potential
consequences are.
</summary>
    <author>
      <name>Simon Thorne</name>
    </author>
    <author>
      <name>David Ball</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 3 figures, 2 tables</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2005 161-172
  ISBN:1-902724-16-X</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0803.1862v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0803.1862v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.2.4; D.2.5; H.4.1; K.6.4; K.8.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0803.3186v1</id>
    <updated>2008-03-21T15:38:25Z</updated>
    <published>2008-03-21T15:38:25Z</published>
    <title>Towards a human eye behavior model by applying Data Mining Techniques on
  Gaze Information from IEC</title>
    <summary>  In this paper, we firstly present what is Interactive Evolutionary
Computation (IEC) and rapidly how we have combined this artificial intelligence
technique with an eye-tracker for visual optimization. Next, in order to
correctly parameterize our application, we present results from applying data
mining techniques on gaze information coming from experiments conducted on
about 80 human individuals.
</summary>
    <author>
      <name>Denis Pallez</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">I3S</arxiv:affiliation>
    </author>
    <author>
      <name>Laurent Brisson</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">I3S</arxiv:affiliation>
    </author>
    <author>
      <name>Thierry Baccino</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LPEQ</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Dans Proceedings of the Third International Conference on Human
  Centered Processes - Human Centered Processes, Delft : Pays-Bas (2008)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0803.3186v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0803.3186v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0804.0937v1</id>
    <updated>2008-04-06T23:20:15Z</updated>
    <published>2008-04-06T23:20:15Z</published>
    <title>Issues in Strategic Decision Modelling</title>
    <summary>  [Spreadsheet] Models are invaluable tools for strategic planning. Models help
key decision makers develop a shared conceptual understanding of complex
decisions, identify sensitivity factors and test management scenarios.
Different modelling approaches are specialist areas in themselves. Model
development can be onerous, expensive, time consuming, and often bewildering.
It is also an iterative process where the true magnitude of the effort, time
and data required is often not fully understood until well into the process.
This paper explores the traditional approaches to strategic planning modelling
commonly used in organisations and considers the application of a real-options
approach to match and benefit from the increasing uncertainty in today's
rapidly changing world.
</summary>
    <author>
      <name>Paula Jennings</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 Pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. European Spreadsheet Risks Int. Grp. 2003 111-116 ISBN 1
  86166 199 1</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0804.0937v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0804.0937v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.2.4; D.2.5; H.4.1; K.6.4; K.8.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0804.0941v1</id>
    <updated>2008-04-07T00:20:24Z</updated>
    <published>2008-04-07T00:20:24Z</published>
    <title>Reducing Overconfidence in Spreadsheet Development</title>
    <summary>  Despite strong evidence of widespread errors, spreadsheet developers rarely
subject their spreadsheets to post-development testing to reduce errors. This
may be because spreadsheet developers are overconfident in the accuracy of
their spreadsheets. This conjecture is plausible because overconfidence is
present in a wide variety of human cognitive domains, even among experts. This
paper describes two experiments in overconfidence in spreadsheet development.
The first is a pilot study to determine the existence of overconfidence. The
second tests a manipulation to reduce overconfidence and errors. The
manipulation is modestly successful, indicating that overconfidence reduction
is a promising avenue to pursue.
</summary>
    <author>
      <name>Raymond R. Panko</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. European Spreadsheet Risks Int. Grp. 2003 49-66 ISBN 1 86166
  199 1</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0804.0941v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0804.0941v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.1; H.4.1; K.6.4; D.2.5; D.2.9; K.8.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0804.4885v1</id>
    <updated>2008-04-30T18:44:52Z</updated>
    <published>2008-04-30T18:44:52Z</published>
    <title>SimDialog: A visual game dialog editor</title>
    <summary>  SimDialog is a visual editor for dialog in computer games. This paper
presents the design of SimDialog, illustrating how script writers and
non-programmers can easily create dialog for video games with complex branching
structures and dynamic response characteristics. The system creates dialog as a
directed graph. This allows for play using the dialog with a state-based cause
and effect system that controls selection of non-player character responses and
can provide a basic scoring mechanism for games.
</summary>
    <author>
      <name>C. Owen</name>
    </author>
    <author>
      <name>F. Biocca</name>
    </author>
    <author>
      <name>C. Bohil</name>
    </author>
    <author>
      <name>J. Conley</name>
    </author>
    <link href="http://arxiv.org/abs/0804.4885v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0804.4885v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0805.2189v1</id>
    <updated>2008-05-15T00:27:15Z</updated>
    <published>2008-05-15T00:27:15Z</published>
    <title>Visual Checking of Spreadsheets</title>
    <summary>  The difference between surface and deep structures of a spreadsheet is a
major cause of difficulty in checking spreadsheets. After a brief survey of
current methods of checking (or debugging) spreadsheets, new visual methods of
showing the deep structures are presented. Illustrations are given on how these
visual methods can be employed in various interactive local and global
debugging strategies.
</summary>
    <author>
      <name>Ying Chen</name>
    </author>
    <author>
      <name>Hock Chuan Chan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 Pages, 5 Figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2000 75-85
  ISBN:1 86166 158 4</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0805.2189v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0805.2189v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0806.0172v1</id>
    <updated>2008-06-01T21:01:15Z</updated>
    <published>2008-06-01T21:01:15Z</published>
    <title>EuSpRIG TEAM work:Tools, Education, Audit, Management</title>
    <summary>  Research on spreadsheet errors began over fifteen years ago. During that
time, there has been ample evidence demonstrating that spreadsheet errors are
common and nontrivial. Quite simply, spreadsheet error rates are comparable to
error rates in other human cognitive activities and are caused by fundamental
limitations in human cognition, not mere sloppiness. Nor does ordinary "being
careful" eliminate errors or reduce them to acceptable levels.
</summary>
    <author>
      <name>David Chadwick</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 Pages, 1 Figure</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2003 1-6 ISBN
  1 86166 199 1</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0806.0172v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0806.0172v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0806.0182v1</id>
    <updated>2008-06-01T23:14:22Z</updated>
    <published>2008-06-01T23:14:22Z</published>
    <title>Training Gamble leads to Corporate Grumble?</title>
    <summary>  Fifteen years of research studies have concluded unanimously that spreadsheet
errors are both common and non-trivial. Now we must seek ways to reduce
spreadsheet errors. Several approaches have been suggested, some of which are
promising and others, while appealing because they are easy to do, are not
likely to be effective. To date, only one technique, cell-by-cell code
inspection, has been demonstrated to be effective. We need to conduct further
research to determine the degree to which other techniques can reduce
spreadsheet errors.
</summary>
    <author>
      <name>David R. Chadwick</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 Pages, 4 Figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2002 1-11
  ISBN 1 86166 182</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0806.0182v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0806.0182v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0807.2628v1</id>
    <updated>2008-07-16T18:31:14Z</updated>
    <published>2008-07-16T18:31:14Z</published>
    <title>Un cadre de conception pour réunir les modèles d'interaction et
  l'ingénierie des interfaces</title>
    <summary>  We present HIC (Human-system Interaction Container), a general framework for
the integration of advanced interaction in the software development process. We
show how this framework allows to reconcile the software development methods
(such MDA, MDE) with the architectural models of software design such as MVC or
PAC. We illustrate our approach thanks to two different types of implementation
for this concept in two different business areas: one software design pattern,
MVIC (Model View Interaction Control) and one architectural model, IM
(Interaction Middleware).
</summary>
    <author>
      <name>Jérôme Lard</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LRI</arxiv:affiliation>
    </author>
    <author>
      <name>Frédéric Landragin</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LaTTice</arxiv:affiliation>
    </author>
    <author>
      <name>Olivier Grisvard</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">ATOL</arxiv:affiliation>
    </author>
    <author>
      <name>David Faure</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Ing\'enierie des Syst\`emes d'Information (ISI) 12, 6 (2007) 67-91</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0807.2628v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0807.2628v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0807.2993v1</id>
    <updated>2008-07-18T15:45:47Z</updated>
    <published>2008-07-18T15:45:47Z</published>
    <title>Establishing and Measuring Standard Spreadsheet Practices for End-Users</title>
    <summary>  This paper offers a brief review of cognitive verbs typically used in the
literature to describe standard spreadsheet practices. The verbs identified are
then categorised in terms of Bloom's Taxonomy of Hierarchical Levels, and then
rated and arranged to distinguish some of their qualities and characteristics.
Some measurement items are then evaluated to see how well computerised test
question items validate or reinforce training or certification. The paper
considers how establishing standard practices in spreadsheet training and
certification can help reduce some of the risks associated with spreadsheets,
and help promote productivity.
</summary>
    <author>
      <name>Garry Cleere</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 Pages, 5 Tables, 9 Colour Figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2008 1-15
  ISBN 978-905617-69-2</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0807.2993v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0807.2993v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0807.2997v1</id>
    <updated>2008-07-18T16:00:34Z</updated>
    <published>2008-07-18T16:00:34Z</published>
    <title>Reducing Spreadsheet Risk with FormulaDataSleuth</title>
    <summary>  A new MS Excel application has been developed which seeks to reduce the risks
associated with the development, operation and auditing of Excel spreadsheets.
FormulaDataSleuth provides a means of checking spreadsheet formulas and data as
they are developed or used, enabling the users to identify actual or potential
errors quickly and thereby halt their propagation. In this paper, we will
describe, with examples, how the application works and how it can be applied to
reduce the risks associated with Excel spreadsheets.
</summary>
    <author>
      <name>Bill Bekenn</name>
    </author>
    <author>
      <name>Ray Hooper</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 12 colour figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2008 33-44
  ISBN 978-905617-69-2</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0807.2997v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0807.2997v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0807.3186v1</id>
    <updated>2008-07-20T20:58:37Z</updated>
    <published>2008-07-20T20:58:37Z</published>
    <title>New Guidelines For Spreadsheets</title>
    <summary>  Current prescriptions for spreadsheet style specify modular separation of
data, calcu1ation and output, based on the notion that writing a spreadsheet is
like writing a computer program. Instead of a computer programming style, this
article examines rules of style for text, graphics, and mathematics. Much
'common wisdom' in spreadsheets contradicts rules for these well-developed
arts. A case is made here for a new style for spreadsheets that emphasises
readability. The new style is described in detail with an example, and
contrasted with the programming style.
</summary>
    <author>
      <name>John F. Raffensperger</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 5 figures, 1 table</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2001 61-76
  ISBN:1 86166 179 7</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0807.3186v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0807.3186v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0807.4623v1</id>
    <updated>2008-07-29T10:15:38Z</updated>
    <published>2008-07-29T10:15:38Z</published>
    <title>AceWiki: Collaborative Ontology Management in Controlled Natural
  Language</title>
    <summary>  AceWiki is a prototype that shows how a semantic wiki using controlled
natural language - Attempto Controlled English (ACE) in our case - can make
ontology management easy for everybody. Sentences in ACE can automatically be
translated into first-order logic, OWL, or SWRL. AceWiki integrates the OWL
reasoner Pellet and ensures that the ontology is always consistent. Previous
results have shown that people with no background in logic are able to add
formal knowledge to AceWiki without being instructed or trained in advance.
</summary>
    <author>
      <name>Tobias Kuhn</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings of the 3rd Semantic Wiki Workshop, CEUR Workshop
  Proceedings, 2008</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0807.4623v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0807.4623v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.2; I.2.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0809.1019v1</id>
    <updated>2008-09-05T12:59:06Z</updated>
    <published>2008-09-05T12:59:06Z</published>
    <title>Moving and resizing of the screen objects</title>
    <summary>  The shape and size of the objects, which we see on the screen, when the
application is running, are defined at the design time. By using some sort of
adaptive interface, developers give users a chance to resize these objects or
on rare occasion even change, but all these changes are predetermined by a
developer; user can't go out of the designer's scenario. Making each and all
elements moveable / resizable and giving users the full control of these
processes, changes the whole idea of applications; programs become user-driven
and significantly increase the effectiveness of users' work. This article is
about the instrument to turn any screen object into moveable / resizable.
</summary>
    <author>
      <name>Sergey Andreyev</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages, 13 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0809.1019v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0809.1019v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0809.3571v1</id>
    <updated>2008-09-21T11:06:23Z</updated>
    <published>2008-09-21T11:06:23Z</published>
    <title>Evaluation of an Intelligent Assistive Technology for Voice Navigation
  of Spreadsheets</title>
    <summary>  An integral part of spreadsheet auditing is navigation. For sufferers of
Repetitive Strain Injury who need to use voice recognition technology this
navigation can be highly problematic. To counter this the authors have
developed an intelligent voice navigation system, iVoice, which replicates
common spreadsheet auditing behaviours through simple voice commands. This
paper outlines the iVoice system and summarizes the results of a study to
evaluate iVoice when compared to a leading voice recognition technology.
</summary>
    <author>
      <name>Derek Flood</name>
    </author>
    <author>
      <name>Kevin Mc Daid</name>
    </author>
    <author>
      <name>Fergal Mc Caffery</name>
    </author>
    <author>
      <name>Brian Bishop</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 Pages, 2 Colour Figures, 4 Tables</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2008 69-78
  ISBN 978-905617-69-2</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0809.3571v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0809.3571v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0809.3595v1</id>
    <updated>2008-09-21T17:45:08Z</updated>
    <published>2008-09-21T17:45:08Z</published>
    <title>Controlling End User Computing Applications - a case study</title>
    <summary>  We report the results of a project to control the use of end user computing
tools for business critical applications in a banking environment. Several
workstreams were employed in order to bring about a cultural change within the
bank towards the use of spreadsheets and other end-user tools, covering policy
development, awareness and skills training, inventory monitoring, user
licensing, key risk metrics and mitigation approaches. The outcomes of these
activities are discussed, and conclusions are drawn as to the need for
appropriate organisational models to guide the use of these tools.
</summary>
    <author>
      <name>Jamie Chambers</name>
    </author>
    <author>
      <name>John Hamill</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 Pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2008 153-161
  ISBN 978-905617-69-2</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0809.3595v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0809.3595v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0810.3076v1</id>
    <updated>2008-10-17T07:19:39Z</updated>
    <published>2008-10-17T07:19:39Z</published>
    <title>Combining Semantic Wikis and Controlled Natural Language</title>
    <summary>  We demonstrate AceWiki that is a semantic wiki using the controlled natural
language Attempto Controlled English (ACE). The goal is to enable easy creation
and modification of ontologies through the web. Texts in ACE can automatically
be translated into first-order logic and other languages, for example OWL.
Previous evaluation showed that ordinary people are able to use AceWiki without
being instructed.
</summary>
    <author>
      <name>Tobias Kuhn</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings of the Poster and Demonstration Session at the 7th
  International Semantic Web Conference (ISWC2008), CEUR Workshop Proceedings,
  Volume 401, 2008</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0810.3076v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0810.3076v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.2; I.2.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0812.0874v1</id>
    <updated>2008-12-04T07:35:48Z</updated>
    <published>2008-12-04T07:35:48Z</published>
    <title>Stroke Fragmentation based on Geometry Features and HMM</title>
    <summary>  Stroke fragmentation is one of the key steps in pen-based interaction. In
this letter, we present a unified HMM-based stroke fragmentation technique that
can do segment point location and primitive type determination simultaneously.
The geometry features included are used to evaluate local features, and the HMM
model is utilized to measure the global drawing context. Experiments prove that
the model can efficiently represent smooth curves as well as strokes made up of
arbitrary lines and circular arcs.
</summary>
    <author>
      <name>Guihuan Feng</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IRCCyN</arxiv:affiliation>
    </author>
    <author>
      <name>Christian Viard-Gaudin</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IRCCyN</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/0812.0874v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0812.0874v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0901.0498v1</id>
    <updated>2009-01-05T15:11:32Z</updated>
    <published>2009-01-05T15:11:32Z</published>
    <title>Towards the characterization of individual users through Web analytics</title>
    <summary>  We perform an analysis of the way individual users navigate in the Web. We
focus primarily in the temporal patterns of they return to a given page. The
return probability as a function of time as well as the distribution of time
intervals between consecutive visits are measured and found to be independent
of the level of activity of single users. The results indicate a rich variety
of individual behaviors and seem to preclude the possibility of defining a
characteristic frequency for each user in his/her visits to a single site.
</summary>
    <author>
      <name>Bruno Goncalves</name>
    </author>
    <author>
      <name>Jose J. Ramasco</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-642-02469-6_102</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-642-02469-6_102" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 4 figures. To appear in Proceeding of Complex'09</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Complex Sciences, 2247-2254 (2009)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0901.0498v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0901.0498v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.soc-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0903.4261v1</id>
    <updated>2009-03-25T08:43:19Z</updated>
    <published>2009-03-25T08:43:19Z</published>
    <title>On-Line Tests</title>
    <summary>  This paper presents an interactive implementation which makes the link
between a human operator and a system of a administration of a relational
databases MySQL. This application conceived as a multimedia presentations is
illustrative for the way in which the transfer and the remaking of the
information between the human operator, the module of data processing and the
database which stores the informations can be solved (with help of the PHP
language and the web use).
</summary>
    <author>
      <name>Florentina Anica Pintea</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, exposed on 4th International Conference "Actualities and
  Perspectives on Hardware and Software" - APHS2007, Timisoara, Romania</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Ann. Univ. Tibiscus Comp. Sci. Series V (2007), 77-84</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0903.4261v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0903.4261v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0905.4864v1</id>
    <updated>2009-05-29T13:49:44Z</updated>
    <published>2009-05-29T13:49:44Z</published>
    <title>Computer Based Interpretation of the Students' Evaluation of the
  Teaching Staff</title>
    <summary>  The goal of this paper is to offer a full support for universities and
quality assessment committees in retrieving the feedback from their students
regarding to their teaching staff. The computer based application presented
before ([Cri07]) collects data from the students. Another part of the
application, presented in this paper, processes this data and presents the
statistical results concerning each teacher.
</summary>
    <author>
      <name>Tiberiu Marius Karnyanszky</name>
    </author>
    <author>
      <name>Ovidiu Crista</name>
    </author>
    <author>
      <name>Catalin Tuican</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, exposed on 5th International Conference "Actualities and
  Perspectives on Hardware and Software" - APHS2009, Timisoara, Romania</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Ann. Univ. Tibiscus Comp. Sci. Series VII(2009),181-188</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0905.4864v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0905.4864v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0906.3224v1</id>
    <updated>2009-06-17T16:07:01Z</updated>
    <published>2009-06-17T16:07:01Z</published>
    <title>Personal applications, based on moveable / resizable elements</title>
    <summary>  All the modern day applications have the interface, absolutely defined by the
developers. The use of adaptive interface or dynamic layout allows some
variations, but even all of them are predetermined on the design stage, because
the best reaction (from designer's view) on any possible users' movement was
hardcoded. But there is a different world of applications, totally constructed
on moveable / resizable elements; such applications turn the full control to
the users. The crucial thing in such programs is that not something but
everything must become moveable and resizable. This article describes the
features of such applications and the algorithm behind their design.
</summary>
    <author>
      <name>Sergey Andreyev</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 12 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0906.3224v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0906.3224v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0906.4125v1</id>
    <updated>2009-06-22T20:31:45Z</updated>
    <published>2009-06-22T20:31:45Z</published>
    <title>A Refined Experience Sampling Method to Capture Mobile User Experience</title>
    <summary>  This paper reviews research methods used to understand the user experience of
mobile technology. The paper presents an improvement of the Experience Sampling
Method and case studies supporting its design. The paper concludes with an
agenda of future work for improving research in this field.
  Keywords: Research methods, topology, case study, contrasting graph,
Experience Sampling Method
</summary>
    <author>
      <name>Mauro Cherubini</name>
    </author>
    <author>
      <name>Nuria Oliver</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Cherubini, M., and Oliver, N. A refined experience sampling method to
  capture mobile user experience. In Presented at the International Workshop of
  Mobile User Experience Research part of CHI'2009 (Boston, MA, USA, April 4-9
  2009), Y. Nakhimovsky, D. Eckles, and J. Riegelsberger, Eds. 12 pages, 5
  figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0906.4125v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0906.4125v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0907.1245v1</id>
    <updated>2009-07-07T15:59:02Z</updated>
    <published>2009-07-07T15:59:02Z</published>
    <title>How Controlled English can Improve Semantic Wikis</title>
    <summary>  The motivation of semantic wikis is to make acquisition, maintenance, and
mining of formal knowledge simpler, faster, and more flexible. However, most
existing semantic wikis have a very technical interface and are restricted to a
relatively low level of expressivity. In this paper, we explain how AceWiki
uses controlled English - concretely Attempto Controlled English (ACE) - to
provide a natural and intuitive interface while supporting a high degree of
expressivity. We introduce recent improvements of the AceWiki system and user
studies that indicate that AceWiki is usable and useful.
</summary>
    <author>
      <name>Tobias Kuhn</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings of the Fourth Semantic Wiki Workshop (SemWiki
  2009), co-located with 6th European Semantic Web Conference (ESWC 2009), CEUR
  Workshop Proceedings, Volume 464, 2009</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0907.1245v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0907.1245v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.2; I.2.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0907.1251v1</id>
    <updated>2009-07-07T16:15:21Z</updated>
    <published>2009-07-07T16:15:21Z</published>
    <title>How to Evaluate Controlled Natural Languages</title>
    <summary>  This paper presents a general framework how controlled natural languages can
be evaluated and compared on the basis of user experiments. The subjects are
asked to classify given statements (in the language to be tested) as either
true or false with respect to a certain situation that is shown in a graphical
notation called "ontographs". A first experiment has been conducted that
applies this framework to the language Attempto Controlled English (ACE).
</summary>
    <author>
      <name>Tobias Kuhn</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">In Pre-Proceedings of the Workshop on Controlled Natural Language
  (CNL 2009), CEUR Workshop Proceedings, Volume 448, 2009</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0907.1251v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0907.1251v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.2; I.2.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0908.0928v1</id>
    <updated>2009-08-06T18:33:10Z</updated>
    <published>2009-08-06T18:33:10Z</published>
    <title>Automated Spreadsheet Development</title>
    <summary>  Few major commercial or economic decisions are made today which are not
underpinned by analysis using spreadsheets. It is virtually impossible to avoid
making mistakes during their drafting and some of these errors remain, unseen
and uncorrected, until something turns the spotlight on them. By then it may be
too late. The challenge is to find a way of creating spreadsheets which will
preserve the benefit of their power and flexibility while making their creation
more transparent and safer. Full documentation and documented version and
quality control, section by section, of the eventual spreadsheet would be a
bonus. And if the whole process could be made quicker, too, that would be a
further bonus.
</summary>
    <author>
      <name>Angus Dunn</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 Pages, 3 Colour Figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2009 39-46
  ISBN 978-1-905617-89-0</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0908.0928v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0908.0928v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0908.3361v1</id>
    <updated>2009-08-24T05:34:57Z</updated>
    <published>2009-08-24T05:34:57Z</published>
    <title>WebNC: efficient sharing of web applications</title>
    <summary>  WebNC is a system for efficiently sharing, retrieving and viewing web
applications. Unlike existing screencasting and screensharing tools, WebNC is
optimized to work with web pages where a lot of scrolling happens. WebNC uses a
tile-based encoding to capture, transmit and deliver web applications, and
relies only on dynamic HTML and JavaScript. The resulting webcasts require very
little bandwidth and are viewable on any modern web browser including Firefox
and Internet Explorer as well as browsers on the iPhone and Android platforms.
</summary>
    <author>
      <name>Laurent Denoue</name>
    </author>
    <author>
      <name>Scott Carter</name>
    </author>
    <author>
      <name>John Adcock</name>
    </author>
    <author>
      <name>Gene Golovchinsky</name>
    </author>
    <author>
      <name>Andreas Girgensohn</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented at WWW 2009, Madrid, Spain</arxiv:comment>
    <link href="http://arxiv.org/abs/0908.3361v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0908.3361v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0908.3523v1</id>
    <updated>2009-08-25T01:37:59Z</updated>
    <published>2009-08-25T01:37:59Z</published>
    <title>Cognitive Dimensions Analysis of Interfaces for Information Seeking</title>
    <summary>  Cognitive Dimensions is a framework for analyzing human-computer interaction.
It is used for meta-analysis, that is, for talking about characteristics of
systems without getting bogged down in details of a particular implementation.
In this paper, I discuss some of the dimensions of this theory and how they can
be applied to analyze information seeking interfaces. The goal of this analysis
is to introduce a useful vocabulary that practitioners and researchers can use
to describe systems, and to guide interface design toward more usable and
useful systems
</summary>
    <author>
      <name>Gene Golovchinsky</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to HCIR'09 http://cuaslis.org/hcir2009/</arxiv:comment>
    <link href="http://arxiv.org/abs/0908.3523v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0908.3523v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0909.2455v1</id>
    <updated>2009-09-13T23:51:59Z</updated>
    <published>2009-09-13T23:51:59Z</published>
    <title>End User Computing in AIB Capital Markets: A Management Summary</title>
    <summary>  This paper is a management summary of how the area of End User Computing
(EUC) has been addressed by AIB Capital Markets. The development of an
effective policy is described, as well as the process by which a register of
critical EUC applications was assembled and how those applications were brought
into a controlled environment. A number of findings are included as well as
recommendations for others who would seek to run a similar project.
</summary>
    <author>
      <name>Andrew McGeady</name>
    </author>
    <author>
      <name>Joseph McGouran</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 Pages. Referenced &amp; submitted by GJC in Sept 2009</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2008 25-31
  ISBN 978-905617-69-2</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0909.2455v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0909.2455v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0909.3158v1</id>
    <updated>2009-09-17T13:05:49Z</updated>
    <published>2009-09-17T13:05:49Z</published>
    <title>The quantitative side of the Repertory Grid Technique: some concerns</title>
    <summary>  User experience (UX) evaluation is gaining increased interest lately, both
from academia and industry. In this paper we argue that UX evaluation needs to
fulfill two important requirements: scalability, i.e. the ability to provide
useful feedback in different stages of the design, and diversity, i.e. the
ability to reflect the di-versity of opinions that may exist in different
users. We promote the use of the Repertory Grid Technique as a promising UX
evaluation technique and discuss some of our concerns regarding the
quantitative side of its use.
</summary>
    <author>
      <name>Evangelos Karapanos</name>
    </author>
    <author>
      <name>Jean-Bernard Martens</name>
    </author>
    <link href="http://arxiv.org/abs/0909.3158v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0909.3158v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0911.0039v2</id>
    <updated>2009-12-09T05:35:43Z</updated>
    <published>2009-10-30T23:31:38Z</published>
    <title>Beyond the Drawing Board: Toward More Effective Use of Whiteboard
  Content</title>
    <summary>  We developed a system that augments traditional office whiteboards with
computation for the purposes of retrieving, reusing, and sharing whiteboard
content. Our system automatically captures changes to whiteboard images,
detects significant changes, and identifies potential collaborative activities.
Users then browse and search the collection of images captured from their
camera or shared from other users' cameras based on aspects such as location,
time, collaboration, etc. We report on the results of a formative study and on
an evaluation of effectiveness of our system, and discuss additional
functionality that can be built on our framework.
</summary>
    <author>
      <name>Gene Golovchinsky</name>
    </author>
    <author>
      <name>Scott Carter</name>
    </author>
    <author>
      <name>Jacob Biehl</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Modified acknowledgments</arxiv:comment>
    <link href="http://arxiv.org/abs/0911.0039v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0911.0039v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0911.1647v1</id>
    <updated>2009-11-09T11:49:50Z</updated>
    <published>2009-11-09T11:49:50Z</published>
    <title>An extendible User-Command Framework based on tagging system</title>
    <summary>  Memorizing the user commands has been a problem since long. In this study we
try to propose solutions to overcome two problems - the problem of selecting
appropriate commands names during application development and the problem of
memorizing these command names. The proposed solution includes a framework in
which the applications can plug into, to get their application commands and
corresponding tags in to the new command execution application.We also propose
a mechanism where user can generate her own set of tags for a command and share
those with peers.
</summary>
    <author>
      <name>Ajinkya Kale</name>
    </author>
    <author>
      <name>Ananth Chakravarthy</name>
    </author>
    <author>
      <name>Nitin Jadhav</name>
    </author>
    <link href="http://arxiv.org/abs/0911.1647v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0911.1647v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0911.5404v1</id>
    <updated>2009-11-28T16:06:49Z</updated>
    <published>2009-11-28T16:06:49Z</published>
    <title>Laser Actuated Presentation System</title>
    <summary>  We present here a pattern sensitive PowerPoint presentation scheme. The
presentation is actuated by simple patterns drawn on the presentation screen by
a laser pointer. A specific pattern corresponds to a particular command
required to operate the presentation. Laser spot on the screen is captured by a
RGB webcam with a red filter mounted, and its location is identified at the
blue layer of each captured frame by estimating the mean position of the pixels
whose intensity is above a given threshold value. Measured Reliability,
Accuracy and Latency of our system are 90%, 10 pixels (in the worst case) and
38 ms respectively.
</summary>
    <author>
      <name>Atul Chowdhary</name>
    </author>
    <author>
      <name>Vivek Agrawal</name>
    </author>
    <author>
      <name>Subhajit Karmakar</name>
    </author>
    <author>
      <name>Sandip Sarkar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 20 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0911.5404v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0911.5404v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0911.5652v1</id>
    <updated>2009-11-30T14:19:48Z</updated>
    <published>2009-11-30T14:19:48Z</published>
    <title>Modeling Human Interaction to Design a Human-Computer Dialog System</title>
    <summary>  This article presents the Cogni-CISMeF project, which aims at improving the
health information search engine CISMeF, by including a conversational agent
that interacts with the user in natural language. To study the cognitive
processes involved during information search, a bottom-up methodology was
adopted. An experiment has been set up to obtain human dialogs related to such
searches. The analysis of these dialogs underlines the establishment of a
common ground and accommodation effects to the user. A model of artificial
agent is proposed, that guides the user by proposing examples, assistance and
choices.
</summary>
    <author>
      <name>Alain Loisel</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LITIS</arxiv:affiliation>
    </author>
    <author>
      <name>Nathalie Chaignaud</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LITIS</arxiv:affiliation>
    </author>
    <author>
      <name>Jean-Philippe Kotowicz</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LITIS</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Conference on Entreprise Information System,
  ICEIS'08, Barcelone : Spain (2008)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0911.5652v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0911.5652v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0912.4882v1</id>
    <updated>2009-12-24T15:29:12Z</updated>
    <published>2009-12-24T15:29:12Z</published>
    <title>Interagir avec un contenu opératique : le projet d'opéra virtuel
  interactif Virtualis</title>
    <summary>  In this article, we present the interactive opera project on CD-ROM
Virtualis. This project includes a scientific dimension as well as artistic. It
gave us the opportunity to design a model of the opera performance using
formalisms from organization sciences. Moreover, our investigation on
interactions between a user and opera contents led us to use models of
relationships between entities based on physical forces, where the user is in a
way absent. We detail some aspects of a reading but also writing environment on
artistic complex contents between text, music and graphics.
</summary>
    <author>
      <name>Alain Bonardi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">STMS</arxiv:affiliation>
    </author>
    <author>
      <name>Francis Rousseaux</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">STMS, CRESTIC</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Revue d'Interaction Homme Machine 2, 1 (2001) /</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0912.4882v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0912.4882v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1001.3150v1</id>
    <updated>2010-01-18T21:17:38Z</updated>
    <published>2010-01-18T21:17:38Z</published>
    <title>Gaze and Gestures in Telepresence: multimodality, embodiment, and roles
  of collaboration</title>
    <summary>  This paper proposes a controlled experiment to further investigate the
usefulness of gaze awareness and gesture recognition in the support of
collaborative work at a distance. We propose to redesign experiments conducted
several years ago with more recent technology that would: a) enable to better
study of the integration of communication modalities, b) allow users to freely
move while collaborating at a distance and c) avoid asymmetries of
communication between collaborators.
</summary>
    <author>
      <name>Mauro Cherubini</name>
    </author>
    <author>
      <name>Rodrigo de Oliveira</name>
    </author>
    <author>
      <name>Nuria Oliver</name>
    </author>
    <author>
      <name>Christian Ferran</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Position paper, International Workshop New Frontiers in Telepresence
  2010, part of CSCW2010, Savannah, GA, USA, 7th of February, 2010.
  http://research.microsoft.com/en-us/events/nft2010/</arxiv:comment>
    <link href="http://arxiv.org/abs/1001.3150v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1001.3150v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1001.3967v1</id>
    <updated>2010-01-22T11:35:57Z</updated>
    <published>2010-01-22T11:35:57Z</published>
    <title>Spreadsheet good practice: is there any such thing?</title>
    <summary>  Various techniques for developing spreadsheet models greatly improve the
chance that the end result will not contain basic mechanical errors. However,
for every discipline in which a given technique is useful, there is likely to
be another in which the same technique works badly. As a result, the author
urges that EuSpRIG does not succumb to internal or external pressures to
champion a particular set of "best practices", because no such set is optimal
in all spreadsheet applications.
</summary>
    <author>
      <name>David Colver</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 Pages, 3 Colour Figures. Referenced &amp; Submitted by GJC in Jan 2010</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2004 ISBN 1
  902724 94 1</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1001.3967v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1001.3967v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1003.4924v1</id>
    <updated>2010-03-25T14:45:28Z</updated>
    <published>2010-03-25T14:45:28Z</published>
    <title>Common Frame of reference in collaborative virtual environments and
  their impact on presence</title>
    <summary>  Virtual collaborative environment are 3D shared spaces in which people can
work together. To collaborate through these systems, users must have a shared
comprehension of the environment. The objective of this experimental study was
to determine if visual stable landmarks improve the construction of a common
representation of the virtual environment and thus facilitate collaboration.
This seems to increase the awareness of the partner's presence.
</summary>
    <author>
      <name>Amine Chellali</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IRCCyN</arxiv:affiliation>
    </author>
    <author>
      <name>Cédric Dumas</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IRCCyN</arxiv:affiliation>
    </author>
    <author>
      <name>Isabelle Milleville-Pennel</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IRCCyN</arxiv:affiliation>
    </author>
    <author>
      <name>Eric Nouri</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IRCCyN</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">The 10th Annual International Workshop on Presence, Barcelone :
  Spain (2007)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1003.4924v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1003.4924v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1004.0243v1</id>
    <updated>2010-04-01T21:52:36Z</updated>
    <published>2010-04-01T21:52:36Z</published>
    <title>Psychophysiological Correlations with Gameplay Experience Dimensions</title>
    <summary>  In this paper, we report a case study using two easy-to-deploy
psychophysiological measures - electrodermal activity (EDA) and heart rate (HR)
- and correlating them with a gameplay experience questionnaire (GEQ) in an
attempt to establish this mixed-methods approach for rapid application in a
commercial game development context. Results indicate that there is a
statistically significant correlation (p &lt; 0.01) between measures of
psychophysiological arousal (HR, EDA) and self-reported UX in games (GEQ), with
some variation between the EDA and HR measures. Results are consistent across
three major commercial First-Person Shooter (FPS) games.
</summary>
    <author>
      <name>Anders Drachen</name>
    </author>
    <author>
      <name>Lennart E. Nacke</name>
    </author>
    <author>
      <name>Georgios Yannakakis</name>
    </author>
    <author>
      <name>Anja Lee Pedersen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">CHI 2010 Workshop: Brain, Body, and Bytes</arxiv:comment>
    <link href="http://arxiv.org/abs/1004.0243v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1004.0243v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91E30" scheme="http://arxiv.org/schemas/atom"/>
    <category term="K.8.0; J.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1004.0258v1</id>
    <updated>2010-04-01T23:48:23Z</updated>
    <published>2010-04-01T23:48:23Z</published>
    <title>Trends and Techniques in Visual Gaze Analysis</title>
    <summary>  Visualizing gaze data is an effective way for the quick interpretation of eye
tracking results. This paper presents a study investigation benefits and
limitations of visual gaze analysis among eye tracking professionals and
researchers. The results were used to create a tool for visual gaze analysis
within a Master's project.
</summary>
    <author>
      <name>Sophie Stellmach</name>
    </author>
    <author>
      <name>Lennart E. Nacke</name>
    </author>
    <author>
      <name>Raimund Dachselt</name>
    </author>
    <author>
      <name>Craig A. Lindley</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">pages 89-93, The 5th Conference on Communication by Gaze Interaction
  - COGAIN 2009: Gaze Interaction For Those Who Want It Most, ISBN:
  978-87-643-0475-6</arxiv:comment>
    <link href="http://arxiv.org/abs/1004.0258v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1004.0258v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="00A66" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.1; I.4.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1004.0438v1</id>
    <updated>2010-04-03T11:21:26Z</updated>
    <published>2010-04-03T11:21:26Z</published>
    <title>User-driven applications</title>
    <summary>  User-driven applications are the programs, in which the full control is given
to the users. Designers of such programs are responsible only for developing an
instrument for solving some task, but they do not enforce users to work with
this instrument according with the predefined scenario. Users' control of the
applications means that only users decide at any moment WHAT, WHEN, and HOW
must appear on the screen. Such applications can be constructed only on the
basis of moveable / resizable elements. Programs, based on such elements, have
very interesting features and open absolutely new possibilities. This article
describes the design of the user-driven applications and shows the consequences
of switching to such type of programs on the samples from different areas.
</summary>
    <author>
      <name>Sergey Andreyev</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">33 pages, 11 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1004.0438v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1004.0438v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1005.3182v2</id>
    <updated>2010-06-07T07:43:43Z</updated>
    <published>2010-05-18T13:03:47Z</published>
    <title>Haptics in computer music : a paradigm shift</title>
    <summary>  With an historical point of view combined with a bibliographic overview, the
article discusses the idea that haptic force feedback transducers correspond
with a paradigm shift in our real-time tools for creating music. So doing, il
shows that computer music may be regarded as a major field of research and
application for haptics.
</summary>
    <author>
      <name>Nicolas Castagné</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">ACROE</arxiv:affiliation>
    </author>
    <author>
      <name>Claude Cadoz</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">ACROE, ICA</arxiv:affiliation>
    </author>
    <author>
      <name>Jean-Loup Florens</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">ACROE</arxiv:affiliation>
    </author>
    <author>
      <name>Annie Luciani</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">ACROE, ICA</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Document accompagn\'e du poster</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EuroHaptics 2004, Munich : Germany (2004)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1005.3182v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1005.3182v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1005.4028v1</id>
    <updated>2010-05-21T17:46:45Z</updated>
    <published>2010-05-21T17:46:45Z</published>
    <title>Internet Banking System Prototype</title>
    <summary>  Internet Banking System refers to systems that enable bank customers to
access accounts and general information on bank products and services through a
personal computer or other intelligent device. Internet banking products and
services can include detailed account information for corporate customers as
well as account summery and transfer money. Ultimately, the products and
services obtained through Internet Banking may mirror products and services
offered through other bank delivery channels. In this paper, Internet Banking
System Prototype has been proposed in order to illustrate the services which is
provided by the Bank online services.
</summary>
    <author>
      <name>Rami Alnaqeib</name>
    </author>
    <author>
      <name>Hamdan. O. Alanazi</name>
    </author>
    <author>
      <name>Hamid. A. Jalab</name>
    </author>
    <author>
      <name>M. A. Zaidan</name>
    </author>
    <author>
      <name>Ali K. Hmood</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">http://www.journalofcomputing.org</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Computing, Volume 2, Issue 5, May 2010</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1005.4028v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1005.4028v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1009.5918v1</id>
    <updated>2010-09-29T15:38:54Z</updated>
    <published>2010-09-29T15:38:54Z</published>
    <title>Usability testing: a review of some methodological and technical aspects
  of the method</title>
    <summary>  The aim of this paper is to review some work conducted in the field of user
testing that aims at specifying or clarifying the test procedures and at
defining and developing tools to help conduct user tests. The topics that have
been selected were considered relevant for evaluating applications in the field
of medical and health care informatics. These topics are: the number of
participants that should take part in a user test, the test procedure, remote
usability evaluation, usability testing tools, and evaluating mobile
applications.
</summary>
    <author>
      <name>J. M. Christian Bastien</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">InterPsy-ETIC</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.ijmedinf.2008.12.004</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.ijmedinf.2008.12.004" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Medical Informatics 79 (2010) e18-e23</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1009.5918v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1009.5918v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1010.3325v1</id>
    <updated>2010-10-16T06:16:08Z</updated>
    <published>2010-10-16T06:16:08Z</published>
    <title>Wireless Sensor Network based Future of Telecom Applications</title>
    <summary>  A system and method for enabling human beings to communicate by way of their
monitored brain activity. The brain activity of an individual is monitored and
transmitted to a remote location (e.g. by satellite). At the remote location,
the monitored brain activity is compared with pre-recorded normalized brain
activity curves, waveforms, or patterns to determine if a match or substantial
match is found. If such a match is found, then the computer at the remote
location determines that the individual was attempting to communicate the word,
phrase, or thought corresponding to the matched stored normalized signal.
</summary>
    <author>
      <name>Arun Dua</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages,4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1010.3325v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1010.3325v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1011.2538v1</id>
    <updated>2010-11-11T00:28:34Z</updated>
    <published>2010-11-11T00:28:34Z</published>
    <title>mVideoCast: Mobile, real time ROI detection and streaming</title>
    <summary>  A variety of applications are emerging to support streaming video from mobile
devices. However, many tasks can benefit from streaming specific content rather
than the full video feed which may include irrelevant, private, or distracting
content. We describe a system that allows users to capture and stream targeted
video content captured with a mobile device. The application incorporates a
variety of automatic and interactive techniques to identify and segment desired
content in the camera view, allowing the user to publish a more focused video.
</summary>
    <author>
      <name>Scott Carter</name>
    </author>
    <author>
      <name>Laurent Denoue</name>
    </author>
    <author>
      <name>John Adcock</name>
    </author>
    <link href="http://arxiv.org/abs/1011.2538v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1011.2538v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1012.0467v1</id>
    <updated>2010-12-02T16:01:21Z</updated>
    <published>2010-12-02T16:01:21Z</published>
    <title>MT4j - A Cross-platform Multi-touch Development Framework</title>
    <summary>  This article describes requirements and challenges of crossplatform
multi-touch software engineering, and presents the open source framework
Multi-Touch for Java (MT4j) as a solution. MT4j is designed for rapid
development of graphically rich applications on a variety of contemporary
hardware, from common PCs and notebooks to large-scale ambient displays, as
well as different operating systems. The framework has a special focus on
making multi-touch software development easier and more efficient. Architecture
and abstractions used by MT4j are described, and implementations of several
common use cases are presented.
</summary>
    <author>
      <name>Uwe Laufs</name>
    </author>
    <author>
      <name>Christopher Ruff</name>
    </author>
    <author>
      <name>Jan Zibuschka</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ACM EICS 2010, Workshop: Engineering patterns for multi-touch
  interfaces (2010), p. 52-57</arxiv:comment>
    <link href="http://arxiv.org/abs/1012.0467v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1012.0467v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.2; D.2.11; D.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1012.4559v1</id>
    <updated>2010-12-21T07:39:45Z</updated>
    <published>2010-12-21T07:39:45Z</published>
    <title>A Force-Directed Method for Large Crossing Angle Graph Drawing</title>
    <summary>  Recent empirical research has indicated that human graph reading performance
improves when crossing angles increase. However, crossing angle has not been
used as an aesthetic criterion for graph drawing algorithms so far. In this
paper, we introduce a force-directed method that aims to construct graph
drawings with large crossing angles. Experiments indicate that our method
significantly increases crossing angles. Surprisingly, the experimental results
further demonstrate that the resulting drawings produced by our method have
fewer edge crossings, a shorter total edge length and more uniform edge
lengths, compared to classical spring algorithms.
</summary>
    <author>
      <name>Peter Eades</name>
    </author>
    <author>
      <name>Weidong Huang</name>
    </author>
    <author>
      <name>Seok-Hee Hong</name>
    </author>
    <link href="http://arxiv.org/abs/1012.4559v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1012.4559v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1101.0234v1</id>
    <updated>2010-12-31T12:06:11Z</updated>
    <published>2010-12-31T12:06:11Z</published>
    <title>Dynamic Feature Description in Human Action Recognition</title>
    <summary>  This work aims to present novel description methods for human action
recognition. Generally, a video sequence can be represented as a collection of
spatial temporal words by detecting space-time interest points and describing
the unique features around the detected points (Bag of Words representation).
Interest points as well as the cuboids around them are considered informative
for feature description in terms of both the structural distribution of
interest points and the information content inside the cuboids. Our proposed
description approaches are based on this idea and making the feature
descriptors more discriminative.
</summary>
    <author>
      <name>Ruoyun Gao</name>
    </author>
    <author>
      <name>Michael S. Lew</name>
    </author>
    <author>
      <name>Ling Shao</name>
    </author>
    <link href="http://arxiv.org/abs/1101.0234v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1101.0234v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.0405v1</id>
    <updated>2011-03-02T12:10:26Z</updated>
    <published>2011-03-02T12:10:26Z</published>
    <title>Analysis of the User Acceptance for Implementing ISO/IEC 27001:2005 in
  Turkish Public Organizations</title>
    <summary>  This study aims to develop a model for the user acceptance for implementing
the information security standard (i.e. ISO 27001) in Turkish public
organizations. The results of the surveys performed in Turkey reveal that the
legislation on information security public which organizations have to obey is
significantly related with the user acceptance during ISO 27001 implementation
process. The fundamental components of our user acceptance model are perceived
usefulness, attitude towards use, social norms, and performance expectancy.
</summary>
    <author>
      <name>Tolga Mataracioglu</name>
    </author>
    <author>
      <name>Sevgi Ozkan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1103.0405v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.0405v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1105.1293v1</id>
    <updated>2011-05-06T15:04:27Z</updated>
    <published>2011-05-06T15:04:27Z</published>
    <title>Eigengestures for natural human computer interface</title>
    <summary>  We present the application of Principal Component Analysis for data acquired
during the design of a natural gesture interface. We investigate the concept of
an eigengesture for motion capture hand gesture data and present the
visualisation of principal components obtained in the course of conducted
experiments. We also show the influence of dimensionality reduction on
reconstructed gesture data quality.
</summary>
    <author>
      <name>Piotr Gawron</name>
    </author>
    <author>
      <name>Przemysław Głomb</name>
    </author>
    <author>
      <name>Jarosław Adam Miszczak</name>
    </author>
    <author>
      <name>Zbigniew Puchała</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-642-23169-8_6</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-642-23169-8_6" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 3 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Advances in Intelligent and Soft Computing, 2011, Volume 103/2011,
  49-56</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1105.1293v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1105.1293v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1105.2890v1</id>
    <updated>2011-05-14T11:43:51Z</updated>
    <published>2011-05-14T11:43:51Z</published>
    <title>Improving Usability of Interactive Graphics Specification and
  Implementation with Picking Views and Inverse Transformations</title>
    <summary>  Specifying and programming graphical interactions are difficult tasks,
notably because designers have difficulties to express the dynamics of the
interaction. This paper shows how the MDPC architecture improves the usability
of the specification and the implementation of graphical interaction. The
architecture is based on the use of picking views and inverse transforms from
the graphics to the data. With three examples of graphical interaction, we show
how to express them with the architecture, how to implement them, and how this
improves programming usability. Moreover, we show that it enables implementing
graphical interaction without a scene graph. This kind of code prevents from
errors due to cache consistency management.
</summary>
    <author>
      <name>Stéphane Conversy</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IRIT</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/1105.2890v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1105.2890v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1106.0868v1</id>
    <updated>2011-06-05T01:11:08Z</updated>
    <published>2011-06-05T01:11:08Z</published>
    <title>Python GUI Scripting Interface for Running Atomic Physics Applications</title>
    <summary>  We create a Python GUI scripting interface working under Windows in addition
to (UNIX/Linux). The GUI has been built around the Python open-source
programming language. We use the Python's GUI library that so called Python
Mega Widgets (PMW) and based on Tkinter Python module
(http://www.freenetpages.co.uk/hp/alan.gauld/tutgui.htm). The new GUI was
motivated primarily by the desire of more updated operations, more flexibility
incorporating future and current improvements in producing atomic data.
Furthermore it will be useful for a variety of applications of atomic physics,
plasma physics and astrophysics and will help in calculating various atomic
properties.
</summary>
    <author>
      <name>Amani Tahat</name>
    </author>
    <author>
      <name>Mofleh Tahat</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 2 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">The Python Papers Source Codes 3: 2, 2011</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1106.0868v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1106.0868v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1106.5308v1</id>
    <updated>2011-06-27T06:24:34Z</updated>
    <published>2011-06-27T06:24:34Z</published>
    <title>Clasificarea distribuita a mesajelor de e-mail</title>
    <summary>  A basic component in Internet applications is the electronic mail and its
various implications. The paper proposes a mechanism for automatically
classifying emails and create dynamic groups that belong to these messages.
Proposed mechanisms will be based on natural language processing techniques and
will be designed to facilitate human-machine interaction in this direction.
</summary>
    <author>
      <name>Florin Pop</name>
    </author>
    <author>
      <name>Diana Petrescu</name>
    </author>
    <author>
      <name>Ştefan Trauşan-Matu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ISSN 1453-1305</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">A Treia Conferin\c{t}\u{a} Na\c{t}ional\u{a} de Interac\c{t}iune
  Om-Calculator 2006, Informatica Economica, vol. X, Bucuresti, pp. 79-82, 2006</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1106.5308v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1106.5308v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1109.5323v1</id>
    <updated>2011-09-25T04:41:35Z</updated>
    <published>2011-09-25T04:41:35Z</published>
    <title>Squiggle - A Glyph Recognizer for Gesture Input</title>
    <summary>  Squiggle is a template-based glyph recognizer in the lineage of `$1
Recognizer' and `Protractor'. It seeks a good fit linear affine mapping between
the input and template glyphs which are represented as a list of milestone
points along the glyph path. The algorithm can recognize input glyphs invariant
of rotation, scaling, skew, and reflection symmetries. In practice the
algorithm is fast and robust enough to recognize user-generated glyphs as they
are being drawn in real time, and to project `shadows' of the matching
templates as feedback.
</summary>
    <author>
      <name>Jeremy Lee</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1109.5323v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1109.5323v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.2; I.4.7; I.5.5; G.1.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1109.6288v1</id>
    <updated>2011-09-28T18:35:51Z</updated>
    <published>2011-09-28T18:35:51Z</published>
    <title>Using Stereoscopic 3D Technologies for the Diagnosis and Treatment of
  Amblyopia in Children</title>
    <summary>  The 3D4Amb project aims at developing a system based on the stereoscopic 3D
techonlogy, like the NVIDIA 3D Vision, for the diagnosis and treatment of
amblyopia in young children. It exploits the active shutter technology to
provide binocular vision, i.e. to show different images to the amblyotic (or
lazy) and the normal eye. It would allow easy diagnosis of amblyopia and its
treatment by means of interactive games or other entertainment activities. It
should not suffer from the compliance problems of the classical treatment, it
is suitable to domestic use, and it could at least partially substitute
occlusion or patching of the normal eye.
</summary>
    <author>
      <name>Angelo Gargantini</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Extended version of the HEALTHINF 2011 paper</arxiv:comment>
    <link href="http://arxiv.org/abs/1109.6288v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1109.6288v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1112.1742v1</id>
    <updated>2011-12-08T00:45:06Z</updated>
    <published>2011-12-08T00:45:06Z</published>
    <title>HandsInAir: A Wearable System for Remote Collaboration</title>
    <summary>  We present HandsInAir, a real-time collaborative wearable system for remote
collaboration. The system is developed to support real world scenarios in which
a remote mobile helper guides a local mobile worker performing a physical task.
HandsInAir implements a novel approach to support mobility of remote
collaborators. This approach allows the helper to perform gestures without
having to touch tangible objects, requiring little environment support. The
system consists of two parts: the helper part and the worker part. The two
parts are connected via a wireless network and the collaboration partners
communicate with each other via audio and visual links. In this paper, we
review related work, describe technical implementation of the system and
envision future work for further improvements.
</summary>
    <author>
      <name>Weidong Huang</name>
    </author>
    <author>
      <name>Leila Alem</name>
    </author>
    <author>
      <name>Jalal Albasri</name>
    </author>
    <link href="http://arxiv.org/abs/1112.1742v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1112.1742v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1112.4190v1</id>
    <updated>2011-12-18T21:17:38Z</updated>
    <published>2011-12-18T21:17:38Z</published>
    <title>An Empirical Study on End-users Productivity Using Model-based
  Spreadsheets</title>
    <summary>  Spreadsheets are widely used, and studies have shown that most end-user
spreadsheets contain nontrivial errors. To improve end-users productivity,
recent research proposes the use of a model-driven engineering approach to
spreadsheets. In this paper we conduct the first systematic empirical study to
assess the effectiveness and efficiency of this approach. A set of spreadsheet
end users worked with two different model-based spreadsheets, and we present
and analyze here the results achieved.
</summary>
    <author>
      <name>Laura Beckwith</name>
    </author>
    <author>
      <name>Jácome Cunha</name>
    </author>
    <author>
      <name>João Paulo Fernandes</name>
    </author>
    <author>
      <name>João Saraiva</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 Pages, 9 Colour Figures, 2 Tables; Proc. European Spreadsheet
  Risks Int. Grp. (EuSpRIG) 2011, ISBN 978-0-9566256-9-4</arxiv:comment>
    <link href="http://arxiv.org/abs/1112.4190v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1112.4190v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1201.3172v2</id>
    <updated>2012-02-02T23:51:49Z</updated>
    <published>2012-01-16T07:57:34Z</published>
    <title>Assessing the Value of 3D Reconstruction in Building Construction</title>
    <summary>  3-dimensional (3D) reconstruction is an emerging field in image processing
and computer vision that aims to create 3D visualizations/ models of objects/
scenes from image sets. However, its commercial applications and benefits are
yet to be fully explored. In this paper, we describe ongoing work towards
assessing the value of 3D reconstruction in the building construction domain.
We present preliminary results from a user study, where our objective is to
understand the use of visual information in building construction in order to
determine problems with the use of visual information and identify potential
benefits and scenarios for the use of 3D reconstruction.
</summary>
    <author>
      <name>Uma Murthy</name>
    </author>
    <author>
      <name>David Boardman</name>
    </author>
    <author>
      <name>Chirag Garg</name>
    </author>
    <link href="http://arxiv.org/abs/1201.3172v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1201.3172v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.4.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1201.6251v1</id>
    <updated>2012-01-27T18:30:11Z</updated>
    <published>2012-01-27T18:30:11Z</published>
    <title>Real-time jam-session support system</title>
    <summary>  We propose a method for the problem of real time chord accompaniment of
improvised music. Our implementation can learn an underlying structure of the
musical performance and predict next chord. The system uses Hidden Markov Model
to find the most probable chord sequence for the played melody and then a
Variable Order Markov Model is used to a) learn the structure (if any) and b)
predict next chord. We implemented our system in Java and MAX/Msp and compared
and evaluated using objective (prediction accuracy) and subjective
(questionnaire) evaluation methods.
</summary>
    <author>
      <name>Panagiotis Tigas</name>
    </author>
    <link href="http://arxiv.org/abs/1201.6251v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1201.6251v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.3926v1</id>
    <updated>2012-02-17T15:03:54Z</updated>
    <published>2012-02-17T15:03:54Z</published>
    <title>Exploring Geometric Shapes with Touch</title>
    <summary>  We propose a new technique to help users to explore geometric shapes without
vision. This technique is based on a guidance using directional cues with a pin
array. This is an alternative to the usual technique that consists of raising
the pins corresponding to dark pixels around the cursor. In this paper we
compare the exploration of geometric shapes with our new technique in unimanual
and bimanual conditions. The users made fewer errors in unimanual condition
than in bimanual condition. However they did not explore the shapes more
quickly and there was no difference in confidence in their answer.
</summary>
    <author>
      <name>Thomas Pietrzak</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Lille - Nord Europe</arxiv:affiliation>
    </author>
    <author>
      <name>Andrew Crossan</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">GIST</arxiv:affiliation>
    </author>
    <author>
      <name>Stephen A. Brewster</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">GIST</arxiv:affiliation>
    </author>
    <author>
      <name>Benoît Martin</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LITA</arxiv:affiliation>
    </author>
    <author>
      <name>Isabelle Pecci</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LITA</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-642-03655-2_18</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-642-03655-2_18" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Interact 2009 (2009)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1202.3926v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.3926v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.6104v1</id>
    <updated>2012-02-28T02:04:04Z</updated>
    <published>2012-02-28T02:04:04Z</published>
    <title>On the Convergence of Collaboration and Knowledge Management</title>
    <summary>  Collaboration technology typically focuses on collaboration and group
processes (cooperation, communication, coordination and coproduction).
Knowledge Management (KM) technology typically focuses on content (creation,
storage, sharing and use of data, information and knowledge). Yet, to achieve
their common goals, teams and organizations need both KM and collaboration
technology to make that more effective and efficient. This paper is interested
in knowledge management and collaboration regarding their convergence and their
integration. First, it contributes to a better understanding of the knowledge
management and collaboration concepts. Second, it focuses on KM and
collaboration convergence by presenting the different interpretation of this
convergence. Third, this paper proposes a generic framework of collaborative
knowledge management.
</summary>
    <author>
      <name>Nesrine Ben yahia</name>
    </author>
    <author>
      <name>Narjès Bellamine</name>
    </author>
    <author>
      <name>Henda Ben Ghézala</name>
    </author>
    <link href="http://arxiv.org/abs/1202.6104v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.6104v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.4332v1</id>
    <updated>2012-04-19T12:10:10Z</updated>
    <published>2012-04-19T12:10:10Z</published>
    <title>Designing generalisation evaluation function through human-machine
  dialogue</title>
    <summary>  Automated generalisation has known important improvements these last few
years. However, an issue that still deserves more study concerns the automatic
evaluation of generalised data. Indeed, many automated generalisation systems
require the utilisation of an evaluation function to automatically assess
generalisation outcomes. In this paper, we propose a new approach dedicated to
the design of such a function. This approach allows an imperfectly defined
evaluation function to be revised through a man-machine dialogue. The user
gives its preferences to the system by comparing generalisation outcomes.
Machine Learning techniques are then used to improve the evaluation function.
An experiment carried out on buildings shows that our approach significantly
improves generalisation evaluation functions defined by users.
</summary>
    <author>
      <name>Patrick Taillandier</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">UMMISCO</arxiv:affiliation>
    </author>
    <author>
      <name>Julien Gaffuri</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">COGIT</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">GIScience, Zurich : Switzerland (2010)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1204.4332v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.4332v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.6325v2</id>
    <updated>2012-06-03T08:45:46Z</updated>
    <published>2012-04-27T20:10:16Z</published>
    <title>CELL: Connecting Everyday Life in an archipeLago</title>
    <summary>  We explore the design of a seamless broadcast communication system that
brings together the distributed community of remote secondary education
schools. In contrast to higher education, primary and secondary education
establishments should remain distributed, in order to maintain a balance of
urban and rural life in the developing and the developed world. We plan to
deploy an ambient and social interactive TV platform (physical installation,
authoring tools, interactive content) that supports social communication in a
positive way. In particular, we present the physical design and the conceptual
model of the system.
</summary>
    <author>
      <name>Konstantinos Chorianopoulos</name>
    </author>
    <author>
      <name>Vassiliki Tsaknaki</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper has been withdrawn by the author due to some errors</arxiv:comment>
    <link href="http://arxiv.org/abs/1204.6325v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.6325v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.0751v1</id>
    <updated>2012-05-03T16:09:07Z</updated>
    <published>2012-05-03T16:09:07Z</published>
    <title>Integrated Development Environment Gesture for modeling workflow
  diagrams</title>
    <summary>  The current software development tools show the same form of interaction as
when they started back, in the mid 70's. However, since the appearance of
visual languages and due to their own nature, they can be handled by tools
which have different input methods to conventional ones. By incorporating new
motion detection technology, it is intended that new forms of interaction are
established. Interactions which respond to the free movement of hands,
therefore the software's developer will have a substantial improvement in the
user experience.
</summary>
    <author>
      <name>Carlos Alberto Fernandez-y-Fernandez</name>
    </author>
    <author>
      <name>Jose Angel Quintanar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, ISBN: 978-607-607-082-6</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Congreso Internacional de Investigacion e Innovacion en Ingenieria
  de Software (Conisoft 2012), Guadalajara, Jalisco, April 25-27, 2012</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1205.0751v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.0751v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.2476v1</id>
    <updated>2012-05-11T10:46:50Z</updated>
    <published>2012-05-11T10:46:50Z</published>
    <title>Open Data Visualization: Keeping Traces of the Exploration Process</title>
    <summary>  This paper describes a system to support the visual exploration of Open Data.
During his/her interactive experience with the graphics, the user can easily
store the current complete state of the visualization application (called a
viewpoint). Next, he/she can compose sequences of these viewpoints (called
scenarios) that can easily be reloaded. This feature allows to keep traces of a
former exploration process, which can be useful in single user (to support
investigation carried out in multiple sessions) as well as in collaborative
setting (to share points of interest identified in the data set).
</summary>
    <author>
      <name>Benoît Otjacques</name>
    </author>
    <author>
      <name>Mickaël Stefas</name>
    </author>
    <author>
      <name>Maël Cornil</name>
    </author>
    <author>
      <name>Fernand Feltz</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented at the First International Workshop On Open Data, WOD-2012
  (http://arxiv.org/abs/1204.3726)</arxiv:comment>
    <link href="http://arxiv.org/abs/1205.2476v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.2476v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.3205v1</id>
    <updated>2012-05-14T21:47:06Z</updated>
    <published>2012-05-14T21:47:06Z</published>
    <title>Cumulative Revision Map</title>
    <summary>  Unlike static documents, version-controlled documents are edited by one or
more authors over a certain period of time. Examples include large scale
computer code, papers authored by a team of scientists, and online discussion
boards. Such collaborative revision process makes traditional document modeling
and visualization techniques inappropriate. In this paper we propose a new
visualization technique for version-controlled documents that reveals
interesting authoring patterns in papers, computer code and Wikipedia articles.
The revealed authoring patterns are useful for the readers, participants in the
authoring process, and supervisors.
</summary>
    <author>
      <name>Seungyeon Kim</name>
    </author>
    <author>
      <name>Joshua V. Dillon</name>
    </author>
    <author>
      <name>Guy Lebanon</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages, 8 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1205.3205v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.3205v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.1968v4</id>
    <updated>2012-10-02T07:54:53Z</updated>
    <published>2012-06-09T20:04:38Z</published>
    <title>A novel 2.5D approach for interfacing with web applications</title>
    <summary>  Web applications need better user interface to be interactive and attractive.
A new approach/concept of dimensional enhancement - 2.5D "a 2D display of a
virtual 3D environment", which can be implemented in social networking sites
and further in other system applications.
</summary>
    <author>
      <name>Saurabh Sarkar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">An approach offering a new idea for Human Computer Interaction,
  including 3 pages and 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.1968v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.1968v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.4206v1</id>
    <updated>2012-06-19T13:36:59Z</updated>
    <published>2012-06-19T13:36:59Z</published>
    <title>Correlating Pedestrian Flows and Search Engine Queries</title>
    <summary>  An important challenge for ubiquitous computing is the development of
techniques that can characterize a location vis-a-vis the richness and
diversity of urban settings. In this paper we report our work on correlating
urban pedestrian flows with Google search queries. Using longitudinal data we
show pedestrian flows at particular locations can be correlated with the
frequency of Google search terms that are semantically relevant to those
locations. Our approach can identify relevant content, media, and
advertisements for particular locations.
</summary>
    <author>
      <name>Vassilis Kostakos</name>
    </author>
    <author>
      <name>Simo Hosio</name>
    </author>
    <author>
      <name>Jorge Goncalves</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1371/journal.pone.0063980</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1371/journal.pone.0063980" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 1 figure, 1 table</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">PLoS ONE 8(5): e63980, 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1206.4206v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.4206v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.m" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.1821v1</id>
    <updated>2012-07-07T18:58:39Z</updated>
    <published>2012-07-07T18:58:39Z</published>
    <title>Beyond Experience Sampling: Evaluating Personal Informatics with
  Technology-Assisted Reconstruction</title>
    <summary>  Experience Sampling has been considered the golden standard of in-situ
measurement, yet, at the expense of high burden to participants. In this paper
we propose Technology-Assisted Reconstruction (TAR), a methodological approach
that combines passive logging of users' behaviors with use of these data in
assisting the reconstruction of behaviors and experiences. Through a number of
recent and ongoing projects we will discuss how TAR may be employed for the
evaluation of personal informatics systems, but also, conversely, how ideas
from the field of personal informatics may contribute towards the development
of new methodologies for in-situ evaluation.
</summary>
    <author>
      <name>Evangelos Karapanos</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">In adjunct proceedings of the conference on Human factors in
  computing systems (CHI 2012), Workshop on Personal Informatics in Practice:
  Improving Quality of Life Through Data. Austin, Canada</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1207.1821v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.1821v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.3155v1</id>
    <updated>2012-09-14T11:27:30Z</updated>
    <published>2012-09-14T11:27:30Z</published>
    <title>Augmenting Customer Journey Maps with quantitative empirical data: a
  case on EEG and eye tracking</title>
    <summary>  This paper introduces the use of electroencephalography (EEG) and eye
tracking in exploring customer experiences in service design. These tools are
expected to allow designers to generate customer journeys from empirical data
leading to new visualization methods and therefore improvements in service
design deliverables.
</summary>
    <author>
      <name>Rui Alves</name>
    </author>
    <author>
      <name>Veranika Lim</name>
    </author>
    <author>
      <name>Evangelos Niforatos</name>
    </author>
    <author>
      <name>Monchu Chen</name>
    </author>
    <author>
      <name>Evangelos Karapanos</name>
    </author>
    <author>
      <name>Nuno Jardim Nunes</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2 pages, 3 figures. Published in DIS2012, in Newcastle, UK</arxiv:comment>
    <link href="http://arxiv.org/abs/1209.3155v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.3155v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.4982v1</id>
    <updated>2012-09-22T10:36:11Z</updated>
    <published>2012-09-22T10:36:11Z</published>
    <title>Using multimodal speech production data to evaluate articulatory
  animation for audiovisual speech synthesis</title>
    <summary>  The importance of modeling speech articulation for high-quality audiovisual
(AV) speech synthesis is widely acknowledged. Nevertheless, while
state-of-the-art, data-driven approaches to facial animation can make use of
sophisticated motion capture techniques, the animation of the intraoral
articulators (viz. the tongue, jaw, and velum) typically makes use of simple
rules or viseme morphing, in stark contrast to the otherwise high quality of
facial modeling. Using appropriate speech production data could significantly
improve the quality of articulatory animation for AV synthesis.
</summary>
    <author>
      <name>Ingmar Steiner</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Lorraine - LORIA, Trinity College Dublin</arxiv:affiliation>
    </author>
    <author>
      <name>Korin Richmond</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CSTR</arxiv:affiliation>
    </author>
    <author>
      <name>Slim Ouni</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Lorraine - LORIA</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">3rd International Symposium on Facial Analysis and Animation
  (2012)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1209.4982v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.4982v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.2959v1</id>
    <updated>2012-10-10T15:42:23Z</updated>
    <published>2012-10-10T15:42:23Z</published>
    <title>Psychophysical Responses Comparison in Spatial Visual, Audiovisual, and
  Auditory BCI-Spelling Paradigms</title>
    <summary>  The paper presents a pilot study conducted with spatial visual, audiovisual
and auditory brain-computer-interface (BCI) based speller paradigms. The
psychophysical experiments are conducted with healthy subjects in order to
evaluate a difficulty and a possible response accuracy variability. We also
present preliminary EEG results in offline BCI mode. The obtained results
validate a thesis, that spatial auditory only paradigm performs as good as the
traditional visual and audiovisual speller BCI tasks.
</summary>
    <author>
      <name>Moonjeong Chang</name>
    </author>
    <author>
      <name>Nozomu Nishikawa</name>
    </author>
    <author>
      <name>Zhenyu Cai</name>
    </author>
    <author>
      <name>Shoji Makino</name>
    </author>
    <author>
      <name>Tomasz M. Rutkowski</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The 6th International Conference on Soft Computing and Intelligent
  Systems and The 13th International Symposium on Advanced Intelligent Systems,
  2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1210.2959v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.2959v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.1634v2</id>
    <updated>2012-11-12T23:55:25Z</updated>
    <published>2012-11-07T18:40:58Z</published>
    <title>Annotations for Supporting Collaboration through Artifacts</title>
    <summary>  Shared artifacts and environments play a prominent role in shaping the
collaboration between their users. This article describes this role and
explains how annotations can provide a bridge between direct communication and
collaboration through artifacts. The various functions of annotations are
discussed through examples that represent some of the important trends in
annotation research. Ultimately, some of the research issues are briefly
discussed, followed by my perspective on the future of asynchronous distributed
collaborative systems with respect to annotations.
</summary>
    <author>
      <name>Syavash Nobarany</name>
    </author>
    <link href="http://arxiv.org/abs/1211.1634v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.1634v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.2412v1</id>
    <updated>2012-11-11T12:36:36Z</updated>
    <published>2012-11-11T12:36:36Z</published>
    <title>Work Integrated Learning (WIL) In Virtual Reality (VR)</title>
    <summary>  The focus of this report is to initially discuss the concepts WIL and VR,
their main characteristics and current applications. Moreover, the pros and
cons of VWIL are also analyzed. Finally, the report presents some
recommendation including further researches into areas where VWIL has potential
to be successful in the future.
</summary>
    <author>
      <name>Waleed Abdullah Al Shehri</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IJCSI International Journal of Computer Science Issues, Vol. 9,
  Issue 5, No 2, September 2012 ISSN (Online): 1694-0814 www.IJCSI.org</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1211.2412v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.2412v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.6411v1</id>
    <updated>2012-11-24T01:21:25Z</updated>
    <published>2012-11-24T01:21:25Z</published>
    <title>New Heuristics for Interfacing Human Motor System using Brain Waves</title>
    <summary>  There are many new forms of interfacing human users to machines. We persevere
here electric mechanical form of interaction between human and machine. The
emergence of brain-computer interface allows mind-to-movement systems. The
story of the Pied Piper inspired us to devise some new heuristics for
interfacing human motor system using brain waves by combining head helmet and
LumbarMotionMonitor For the simulation we use java GridGain Brain responses of
classified subjects during training indicates that Probe can be the best
stimulus to rely on in distinguishing between knowledgeable and not
knowledgeable
</summary>
    <author>
      <name>Mohammed El-Dosuky</name>
    </author>
    <author>
      <name>Ahmed EL-Bassiouny</name>
    </author>
    <author>
      <name>Taher Hamza</name>
    </author>
    <author>
      <name>Magdy Rashad</name>
    </author>
    <link href="http://arxiv.org/abs/1211.6411v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.6411v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.6799v1</id>
    <updated>2012-11-29T02:34:28Z</updated>
    <published>2012-11-29T02:34:28Z</published>
    <title>Context Visualization for Social Bookmark Management</title>
    <summary>  We present the design of a new social bookmark manager, named GalViz, as part
of the interface of the GiveA-Link system. Unlike the interfaces of traditional
social tagging tools, which usually display information in a list view, GalViz
visualizes tags, resources, social links, and social context in an interactive
network, combined with the tag cloud. Evaluations through a scenario case study
and log analysis provide evidence of the effectiveness of our design.
</summary>
    <author>
      <name>Lilian Weng</name>
    </author>
    <author>
      <name>Filippo Menczer</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 3 figures, 1 table</arxiv:comment>
    <link href="http://arxiv.org/abs/1211.6799v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.6799v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.0573v1</id>
    <updated>2012-12-12T15:56:34Z</updated>
    <published>2012-12-12T15:56:34Z</published>
    <title>Coordinates: Probabilistic Forecasting of Presence and Availability</title>
    <summary>  We present methods employed in Coordinate, a prototype service that supports
collaboration and communication by learning predictive models that provide
forecasts of users s AND availability.We describe how data IS collected about
USER activity AND proximity FROM multiple devices, IN addition TO analysis OF
the content OF users, the time of day, and day of week. We review applications
of presence forecasting embedded in the Priorities application and then present
details of the Coordinate service that was informed by the earlier efforts.
</summary>
    <author>
      <name>Eric J. Horvitz</name>
    </author>
    <author>
      <name>Paul Koch</name>
    </author>
    <author>
      <name>Carl Kadie</name>
    </author>
    <author>
      <name>Andy Jacobs</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Appears in Proceedings of the Eighteenth Conference on Uncertainty in
  Artificial Intelligence (UAI2002)</arxiv:comment>
    <link href="http://arxiv.org/abs/1301.0573v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.0573v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1302.1649v1</id>
    <updated>2013-02-07T06:47:54Z</updated>
    <published>2013-02-07T06:47:54Z</published>
    <title>Eye-GUIDE (Eye-Gaze User Interface Design) Messaging for
  Physically-Impaired People</title>
    <summary>  Eye-GUIDE is an assistive communication tool designed for the paralyzed or
physically impaired people who were unable to move parts of their bodies
especially people whose communications are limited only to eye movements. The
prototype consists of a camera and a computer. Camera captures images then it
will be send to the computer, where the computer will be the one to interpret
the data. Thus, Eye-GUIDE focuses on camera-based gaze tracking. The proponent
designed the prototype to perform simple tasks and provides graphical user
interface in order the paralyzed or physically impaired person can easily use
it.
</summary>
    <author>
      <name>Rommel Anacan</name>
    </author>
    <author>
      <name>James Greggory Alcayde</name>
    </author>
    <author>
      <name>Retchel Antegra</name>
    </author>
    <author>
      <name>Leah Luna</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5121/ijdps.2013.4104</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5121/ijdps.2013.4104" rel="related"/>
    <link href="http://arxiv.org/abs/1302.1649v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1302.1649v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1302.2759v1</id>
    <updated>2013-02-12T11:17:20Z</updated>
    <published>2013-02-12T11:17:20Z</published>
    <title>Exploration of Recent Advances in the Field of Brain Computer Interfaces</title>
    <summary>  A new approach for implementing number of expressions, emotions and, actions
to operate objects through the thoughts of brain using a Non-Invasive Brain
Computing Interface (BCI) technique has been proposed. In this paper a survey
on brain and its operations are presented. The steps involved in the brain
signal processing are discussed. The current systems are able to present few
expressions and emotions on a single device. The proposed system provides the
extended number of expressions on multiple numbers of objects.
</summary>
    <author>
      <name>M. Rajyalakshmi</name>
    </author>
    <author>
      <name>T. Kameswara Rao</name>
    </author>
    <author>
      <name>T. V. Prasad</name>
    </author>
    <link href="http://arxiv.org/abs/1302.2759v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1302.2759v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.ET" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.1332v1</id>
    <updated>2013-04-04T11:43:09Z</updated>
    <published>2013-04-04T11:43:09Z</published>
    <title>What really happened on September 15th 2008? Getting The Most from Your
  Personal Information with Memacs</title>
    <summary>  Combining and summarizing meta-data from various kinds of data sources is one
possible solution to the data fragmentation we are suffering from. Multiple
projects have addressed this issue already. This paper presents a new approach
named Memacs. It automatically generates a detailed linked diary of our digital
artifacts scattered across local files of multiple formats as well as data
silos of the internet. Being elegantly simple and open, Memacs uses already
existing visualization features of GNU Emacs and Org-mode to provide a
promising platform for life-logging, Quantified Self movement, and people
looking for advanced Personal Information Management (PIM) in general.
</summary>
    <author>
      <name>Karl Voit</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 3 figures, 21 references</arxiv:comment>
    <link href="http://arxiv.org/abs/1304.1332v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.1332v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68N99" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3; H.3.2; H.4.1; H.5.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.3940v2</id>
    <updated>2013-05-09T10:48:55Z</updated>
    <published>2013-04-14T19:48:07Z</published>
    <title>Unveiling the link between logical fallacies and web persuasion</title>
    <summary>  In the last decade Human-Computer Interaction (HCI) has started to focus
attention on forms of persuasive interaction where computer technologies have
the goal of changing users behavior and attitudes according to a predefined
direction. In this work, we hypothesize a strong connection between logical
fallacies (forms of reasoning which are logically invalid but cognitively
effective) and some common persuasion strategies adopted within web
technologies. With the aim of empirically evaluating our hypothesis, we carried
out a pilot study on a sample of 150 e-commerce websites.
</summary>
    <author>
      <name>Antonio Lieto</name>
    </author>
    <author>
      <name>Fabiana Vernero</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 3 figures, in proceedings of the WebSci'13 Conference,
  Paris, 2013</arxiv:comment>
    <link href="http://arxiv.org/abs/1304.3940v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.3940v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.m" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1306.1746v1</id>
    <updated>2013-06-06T16:07:23Z</updated>
    <published>2013-06-06T16:07:23Z</published>
    <title>Condition Driven Adaptive Music Generation for Computer Games</title>
    <summary>  The video game industry has grown to a multi-billion dollar, worldwide
industry. The background music tends adaptively in reference to the specific
game content during the game length of the play. Adaptive music should be
further explored by looking at the particular condition in the game; such
condition is driven by generating a specific music in the background which best
fits in with the active game content throughout the length of the gameplay.
This research paper outlines the use of condition driven adaptive music
generation for audio and video to dynamically incorporate adaptively.
</summary>
    <author>
      <name>Alamgir Naushad</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5120/10652-5416</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5120/10652-5416" rel="related"/>
    <link href="http://arxiv.org/abs/1306.1746v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1306.1746v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.1943v1</id>
    <updated>2013-07-08T04:41:39Z</updated>
    <published>2013-07-08T04:41:39Z</published>
    <title>Proof in Context -- Web Editing with Rich, Modeless Contextual Feedback</title>
    <summary>  The Agora system is a prototypical Wiki for formal mathematics: a web-based
system for collaborating on formal mathematics, intended to support informal
documentation of formal developments. This system requires a reusable proof
editor component, both for collaborative editing of documents, and for
embedding in the resulting documents. This paper describes the design of
Agora's asynchronous editor, that is generic enough to support different tools
working on editor content and providing contextual information, with
interactive theorem proverss being a special, but important, case described in
detail for the Coq theorem prover.
</summary>
    <author>
      <name>Carst Tankink</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Institute for Computing and Information Science, Radboud University Nijmegen</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.118.3</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.118.3" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings UITP 2012, arXiv:1307.1528</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 118, 2013, pp. 42-56</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1307.1943v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.1943v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.2018v1</id>
    <updated>2013-07-08T10:16:00Z</updated>
    <published>2013-07-08T10:16:00Z</published>
    <title>OntoFM: A Personal Ontology-based File Manager for the Desktop</title>
    <summary>  Personal ontologies have been proposed as a means to support the semantic
management of user information. Assuming that a personal ontology system is in
use, new tools have to be developed at user interface level to exploit the
enhanced capabilities offered by the system. In this work, we present an
ontology-based file manager that allows semantic searching on the user's
personal information space. The file manager exploits the ontology relations to
present files associated with specific concepts, proposes new related concepts
to users, and helps them explore the information space and locate the required
file.
</summary>
    <author>
      <name>Jenny Rompa</name>
    </author>
    <author>
      <name>Giorgos Lepouras</name>
    </author>
    <author>
      <name>Costas Vassilakis</name>
    </author>
    <author>
      <name>Christos Tryfonopoulos</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ISWC 2011 Demo</arxiv:comment>
    <link href="http://arxiv.org/abs/1307.2018v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.2018v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1308.0322v1</id>
    <updated>2013-08-01T19:58:28Z</updated>
    <published>2013-08-01T19:58:28Z</published>
    <title>Social Data Mining through Distributed Mobile Sensing</title>
    <summary>  In this article, we present a distributed framework for collecting and
analyzing environmental and location data recorded by human users (carriers)
with the use of portable sensors. We demonstrate the data mining analysis
potential among the recorded environmental and location variables, as well as
the potential for classification analysis of human activities. We recognize
that the success of such an experimental framework relies on the adoption rate
by its candidate user network; thus, we have built our experimental prototype
on top of hardware equipment already embedded within the potential users'
everyday routine - i.e. hardware sensors installed on modern mobile phones.
Finally, we present preliminary analysis results on our collected data sample,
as well as potential further work directions and proposed use case scenarios.
</summary>
    <author>
      <name>John Gekas</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1308.0322v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1308.0322v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1308.3745v1</id>
    <updated>2013-08-17T00:33:54Z</updated>
    <published>2013-08-17T00:33:54Z</published>
    <title>Computational Properties of Fiction Writing and Collaborative Work</title>
    <summary>  From the earliest days of computing, there have been tools to help shape
narrative. Spell-checking, word counts, and readability analysis, give today's
novelists tools that Dickens, Austen, and Shakespeare could only have dreamt
of. However, such tools have focused on the word, or phrase levels. In the last
decade, research focus has shifted to support for collaborative editing of
documents. This work considers more sophisticated attempts to visualise the
semantics, pace and rhythm within a narrative through data mining. We describe
real life applications in two related domains.
</summary>
    <author>
      <name>Joseph Reddington</name>
    </author>
    <author>
      <name>Fionn Murtagh</name>
    </author>
    <author>
      <name>Douglas Cowie</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1308.3745v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1308.3745v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91C20, 62H30, 76M27" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.5; H.1.2; H.3.3; I.5.3; I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1308.6368v1</id>
    <updated>2013-08-29T05:40:45Z</updated>
    <published>2013-08-29T05:40:45Z</published>
    <title>Incremental Grid-like Layout Using Soft and Hard Constraints</title>
    <summary>  We explore various techniques to incorporate grid-like layout conventions
into a force-directed, constraint-based graph layout framework. In doing so we
are able to provide high-quality layout---with predominantly axis-aligned
edges---that is more flexible than previous grid-like layout methods and which
can capture layout conventions in notations such as SBGN (Systems Biology
Graphical Notation). Furthermore, the layout is easily able to respect
user-defined constraints and adapt to interaction in online systems and diagram
editors such as Dunnart.
</summary>
    <author>
      <name>Steve Kieffer</name>
    </author>
    <author>
      <name>Tim Dwyer</name>
    </author>
    <author>
      <name>Kim Marriott</name>
    </author>
    <author>
      <name>Michael Wybrow</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to Graph Drawing 2013</arxiv:comment>
    <link href="http://arxiv.org/abs/1308.6368v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1308.6368v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.1758v1</id>
    <updated>2013-10-07T12:45:48Z</updated>
    <published>2013-10-07T12:45:48Z</published>
    <title>GENIUS: Generating Usable User Interfaces</title>
    <summary>  In this report we describe the implementation and approach developed during
the GENIUS Project. The GENIUS project is about the generation of usable user
interfaces. It tries to cope with issues related to automatic generation where,
usually end-user complain about the poor quality (in term of usability) of
generated UI. To solve this issue GENIUS relies on Model-Driven Engineering
principles and several MDE tools. Notably, it consists in a set of metamodels
specific to the interaction, a set of model transformation embedding usability
criteria and an environment for model execution/ interpretation.
</summary>
    <author>
      <name>Jean-Sebastien Sottet</name>
    </author>
    <author>
      <name>Alain Vagner</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Public Research Center Henri Tudor- Technical Report of the FNR's
  project GENIUS</arxiv:comment>
    <link href="http://arxiv.org/abs/1310.1758v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.1758v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.3111v1</id>
    <updated>2013-10-11T12:56:08Z</updated>
    <published>2013-10-11T12:56:08Z</published>
    <title>Keyboard for inputting Chinese language</title>
    <summary>  As the structure of Chinese characters are very different, it is very
difficult to input Chinese characters into computer quickly and conveniently.
The conventional keyboard does not support the pictorial characters in Chinese
language. There are 3000 to 6000 commonly used pictorial Chinese characters
(Hanzi).
  There are a few existing systems which include "PinYin" (phonetic) system, a
combination of the PinYin system and character form techniques, whole character
encoding, stroke input encoding, and stoke form encoding. Each of the methods
have their own advantages and disadvantages. This article describes two
inventions on inputting Chinese language through a standard keyboard.
</summary>
    <author>
      <name>Umakant Mishra</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.2139/ssrn.932271</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.2139/ssrn.932271" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published in TRIZsite Journal, Apr 2005, also available in
  http://papers.ssrn.com/abstract=932271</arxiv:comment>
    <link href="http://arxiv.org/abs/1310.3111v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.3111v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.3165v1</id>
    <updated>2013-10-11T15:21:05Z</updated>
    <published>2013-10-11T15:21:05Z</published>
    <title>10 Inventions on Key Guides and Keyboard Templates</title>
    <summary>  A keyboard has many function keys and each function key can have multiple
functions when used with control, shift and alt keys, it is difficult for a
user to remember the functionality of the function keys. We need a mechanism to
indicate the operations assigned to each function key for different software
programs. A keyboard guide or template is used for this purpose.
  This article illustrates 10 inventions on keyboard key guide and function key
templates selected from US patent database. Various mechanisms of keyboard
templates have been proposed, including static, dynamic, manual, mechanical,
onscreen display and others.
</summary>
    <author>
      <name>Umakant Mishra</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.2139/ssrn.932276</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.2139/ssrn.932276" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published in TRIZsite Journal, June 2005, also available at
  http://papers.ssrn.com/abstract=932276</arxiv:comment>
    <link href="http://arxiv.org/abs/1310.3165v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.3165v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.3849v1</id>
    <updated>2013-10-11T14:49:38Z</updated>
    <published>2013-10-11T14:49:38Z</published>
    <title>10 Inventions on laptop keyboards -A study based on US patents</title>
    <summary>  A desktop keyboard has several sections like character key section,
navigation key section, numeric key section, and function key section etc. each
consisting of several number of keys. However, a laptop computer does not have
so much of space to accommodate all these keys into the keyboard. There are
several considerations while designing a laptop keyboard.
  This article illustrates 10 inventions on keyboards for laptop and portable
computers. The inventions are selected from US patent database. The inventions
try to improve various aspects of a laptop keyboard, such as reducing size,
folding and concealing, ergonomic features, improving quality and reducing
cost.
</summary>
    <author>
      <name>Umakant Mishra</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.2139/ssrn.932274</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.2139/ssrn.932274" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published in TRIZsite Journal, May 2005, also available at
  http://papers.ssrn.com/abstract=932274. arXiv admin note: substantial text
  overlap with arXiv:1307.5426, arXiv:1310.3268, arXiv:1310.3070</arxiv:comment>
    <link href="http://arxiv.org/abs/1310.3849v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.3849v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1311.3672v1</id>
    <updated>2013-11-14T21:06:50Z</updated>
    <published>2013-11-14T21:06:50Z</published>
    <title>Hierarchical Model of Human Guidance Performance Based on Interaction
  Patterns in Behavior</title>
    <summary>  This paper describes a framework for the investigation and modeling of human
spatial guidance behavior in complex environments. The model is derived from
the concept of interaction patterns, which represent the invariances or
symmetries inherent in the interactions between an agent and its environment.
These patterns provide the basic elements needed for the formalization of
spatial behavior and determine a natural hierarchy that can be unified under a
hierarchical hidden Markov model.
</summary>
    <author>
      <name>Berenice Mettler</name>
    </author>
    <author>
      <name>Zhaodan Kong</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2nd International Conference on Application and Theory of Automation
  in Command and Control Systems (ICARUS)</arxiv:comment>
    <link href="http://arxiv.org/abs/1311.3672v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1311.3672v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1401.1690v1</id>
    <updated>2014-01-08T13:22:42Z</updated>
    <published>2014-01-08T13:22:42Z</published>
    <title>Tendencies, Dead-ends, and Promising Ways. From Interface Ideas to New
  Programs</title>
    <summary>  The mechanism of communication between users and devices is called interface.
From time to time changes in interface significantly improve our work with
computers even without any serious changes in programs themselves. Main ideas
in PCs interface were introduced many years ago and since then there are no
significant changes, while new devices show promising ways by using direct
manipulation of screen objects. Users' direct action with all the screen
objects of our ordinary PCs turns standard screens into touch screens of very
high resolution and not only changes the interface of familiar programs but
creates the new type of programs: user-driven applications.
</summary>
    <author>
      <name>Sergey Andreyev</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1401.1690v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1401.1690v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.2; D.2.2; H.1.2; I.3.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1401.5289v1</id>
    <updated>2014-01-21T12:21:48Z</updated>
    <published>2014-01-21T12:21:48Z</published>
    <title>Graphical Interface for Visually Impaired People Based on Bi-stable
  Solenoids</title>
    <summary>  In this paper a concept for hardware realization of graphic tactile display
for visually impaired peoples is presented. For realization of tactile
actuators bi-stable, solenoids and PIC based control board are used. The
selected algorithm for series activation of each row of display allows using
minimal number of active components to set and reset the solenoids. Finally, a
program algorithm of control board is discussed. The project is funded by
Bulgarian National Science Fund NSF Grant D ID 02 14, 2009 2013
</summary>
    <author>
      <name>Stanislav Simeonov</name>
    </author>
    <author>
      <name>Neli Simeonova</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.7321/jscse</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.7321/jscse" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 5 figures, The International Journal of Soft Computing and
  Software Engineering, ISSN:2251-7545</arxiv:comment>
    <link href="http://arxiv.org/abs/1401.5289v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1401.5289v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1401.7821v1</id>
    <updated>2014-01-30T12:29:46Z</updated>
    <published>2014-01-30T12:29:46Z</published>
    <title>Spatial Modelling Techniques in Microsoft Excel</title>
    <summary>  We begin by considering the expectations of the creators of VisiCalc, the
first spreadsheet. The emphasis is on the nature of the spreadsheet grid. The
grid is taken as a presentational method for showing a solution to a Sudoku
puzzle. We consider methods or approaches for the solution. We look at the
relationship between this model and academic papers on the methods for
describing and categorising end-user models generally. We consider whether the
type of model described here should be categorised separately. The complexity
of the model is reviewed in the context of commendations to minimise overly
sophisticated presentational constructs and formulae.
</summary>
    <author>
      <name>Stephen Allen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 5 colour figures, 1 table, Proc. European Spreadsheet Risks
  Int. Grp. (EuSpRIG) 2013, ISBN: 978-1-9054045-1-3</arxiv:comment>
    <link href="http://arxiv.org/abs/1401.7821v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1401.7821v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1402.0200v1</id>
    <updated>2014-02-02T15:15:30Z</updated>
    <published>2014-02-02T15:15:30Z</published>
    <title>SPHERE: Meaningful and Inclusive Sensor-Based Home Healthcare</title>
    <summary>  Given current demographic and health trends, and their economic implications,
home healthcare technology has become a fertile area for research and
development. Motivated by the need for a radical reform of healthcare
provision, SPHERE is a large-scale Interdisciplinary Research Collaboration
that aims to develop home sensor systems to monitor people's health and
wellbeing in the home. This paper outlines the unique circumstances of
designing healthcare technology for the home environment, with a particular
focus on how to ensure future systems are meaningful to and desirable for the
intended users.
</summary>
    <author>
      <name>Alison Burrows</name>
    </author>
    <author>
      <name>Rachel Gooberman-Hill</name>
    </author>
    <author>
      <name>Ian Craddock</name>
    </author>
    <author>
      <name>David Coyle</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented at the ACM CSCW 2014 workshop on Designing with Users for
  Domestic environments: Methods, Challenges, Lessons Learned</arxiv:comment>
    <link href="http://arxiv.org/abs/1402.0200v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1402.0200v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.m" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1402.0693v1</id>
    <updated>2014-02-04T11:13:56Z</updated>
    <published>2014-02-04T11:13:56Z</published>
    <title>A survey on Human Computer Interaction Mechanism Using Finger Tracking</title>
    <summary>  Human Computer Interaction (HCI) is a field in which developer makes a user
friendly system. User can interact with a computer system without using any
conventional peripheral devices. Marker is used to recognize hand movement
accurately &amp; successfully. Researchers establish the mechanism to interact with
computer system using computer vision. The interaction is better than normal
static keyboard and mouse. This paper represents most of innovative mechanisms
of the finger tracking used to interact with a computer system using computer
vision.
</summary>
    <author>
      <name>Kinjal N. Shah</name>
    </author>
    <author>
      <name>Kirit R. Rathod</name>
    </author>
    <author>
      <name>Shardul J. Agravat</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.14445/22312803/IJCTT-V7P148</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.14445/22312803/IJCTT-V7P148" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 8 figures, International Journal of Computer Trends and
  Technology (IJCTT)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IJCTT 7(3):174-177, January 2014</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1402.0693v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1402.0693v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1402.1243v1</id>
    <updated>2014-02-06T04:30:39Z</updated>
    <published>2014-02-06T04:30:39Z</published>
    <title>Destination Information Management System for Tourist</title>
    <summary>  The use of information and communication technology in our day to day
activities is now unavoidable. In tourism developments, destination information
and management systems are used to guide visitors and provide information to
both visitors and management of the tour sites. In this paper, information and
navigation system was designed for tourists, taking some Niger state of Nigeria
tourism destinations into account. The information management system was
designed using Java Applet (NetBeans IDE 6.1), Hypertext MarkUp Language
(HTML), Personal Home Page (PHP), Java script and MySQL as the back-end
integration database. Two different MySQL servers were used, the MySQL query
browser and the WAMP5 server to compare the effectiveness of the system
developed.
</summary>
    <author>
      <name>Shafii Muhammad Abdulhamid</name>
    </author>
    <author>
      <name>Gana Usman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages. Computer Science and Telecommunications 2010</arxiv:comment>
    <link href="http://arxiv.org/abs/1402.1243v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1402.1243v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1402.4724v1</id>
    <updated>2014-02-19T16:36:58Z</updated>
    <published>2014-02-19T16:36:58Z</published>
    <title>Breaking Barriers: Assistive Technology Tool as Educational Software to
  support Writing</title>
    <summary>  The preliminary report by Siriraj Hospital suggested that 6% of population
who are students in Thailand could be estimated to have learning disabilities.
It is therefore necessary for our institute to develop suitable ICT
technologies to assist the education of these learning disabilities children.
We therefore developed a program called Thai Word Prediction Program. Thai Word
Prediction program aims to assist students with learning disabilities in their
writing. After the usability engineering, we conducted the experiment with
students with learning disabilities at the School in Bangkok. Hence, the
results indicated that all three students with learning disabilities in this
study improved their ability of writing by 50%, 81.89% and 100% respectively.
</summary>
    <author>
      <name>Onintra Poobrasert</name>
    </author>
    <author>
      <name>Waragorn Gestubtim</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages. IJCA 2013</arxiv:comment>
    <link href="http://arxiv.org/abs/1402.4724v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1402.4724v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1403.4722v1</id>
    <updated>2014-03-19T07:40:55Z</updated>
    <published>2014-03-19T07:40:55Z</published>
    <title>Mouse Control using a Web Camera based on Colour Detection</title>
    <summary>  In this paper we present an approach for Human computer Interaction (HCI),
where we have tried to control the mouse cursor movement and click events of
the mouse using hand gestures. Hand gestures were acquired using a camera based
on colour detection technique. This method mainly focuses on the use of a Web
Camera to develop a virtual human computer interaction device in a cost
effective manner.
</summary>
    <author>
      <name>Abhik Banerjee</name>
    </author>
    <author>
      <name>Abhirup Ghosh</name>
    </author>
    <author>
      <name>Koustuvmoni Bharadwaj</name>
    </author>
    <author>
      <name>Hemanta Saikia</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.14445/22312803/IJCTT-V9P104</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.14445/22312803/IJCTT-V9P104" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 6 figures, 1 flowchart, "Published with International
  Journal of Computer Trends and Technology (IJCTT)"</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Trends and Technology (IJCTT)
  V9(1):15-20,March 2014.ISSN:2231-2803 Published by Seventh Sense Research
  Group</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1403.4722v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1403.4722v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1403.5058v1</id>
    <updated>2014-03-20T07:50:54Z</updated>
    <published>2014-03-20T07:50:54Z</published>
    <title>Towards an Interaction-based Integration of MKM Services into End-User
  Applications</title>
    <summary>  The Semantic Alliance (SAlly) Framework, first presented at MKM 2012, allows
integration of Mathematical Knowledge Management services into typical
applications and end-user workflows. From an architecture allowing invasion of
spreadsheet programs, it grew into a middle-ware connecting spreadsheet, CAD,
text and image processing environments with MKM services. The architecture
presented in the original paper proved to be quite resilient as it is still
used today with only minor changes.
  This paper explores extensibility challenges we have encountered in the
process of developing new services and maintaining the plugins invading
end-user applications. After an analysis of the underlying problems, I present
an augmented version of the SAlly architecture that addresses these issues and
opens new opportunities for document type agnostic MKM services.
</summary>
    <author>
      <name>Constantin Jucovschi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1403.5058v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1403.5058v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1403.6669v1</id>
    <updated>2014-03-26T13:53:26Z</updated>
    <published>2014-03-26T13:53:26Z</published>
    <title>Lost Again in Shibuya: Exploration and Awareness in a Labyrinth</title>
    <summary>  Existing digital technologies in urban settings tend to focus narrowly on
concerns around wayfinding, safety, and consumption. In this paper, we examine
pedestrian experiences based on the data collected through field observations
as well as intensive interviews with nine pedestrians in the Shibuya area of
Tokyo, and suggest an alternative approach to blending technologies and urban
activities. Our focus is on social and cognitive aspects of pedestrians who get
lost and explore a labyrinth of sidewalks. We use the data to discuss the
activities that are often ignored or inadequately supported by existing
systems.
</summary>
    <author>
      <name>Shin'ichi Konomi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1403.6669v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1403.6669v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.m" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.5248v1</id>
    <updated>2014-04-21T17:25:15Z</updated>
    <published>2014-04-21T17:25:15Z</published>
    <title>Intelligent Remote Control for TV Program based on Emotion in Arabic
  Speech</title>
    <summary>  Recommender systems for TV program have been studied for the realization of
personalized TV Electronic Program Guides. In this paper, we propose automatic
emotion Arabic speech recognition in order to achieve an intelligent remote
control. In addition, the TV can estimate our interests and preferences by
observing our behavior to watch and have a conversation on topics that might be
interesting to us.
</summary>
    <author>
      <name>M. Meddeb</name>
    </author>
    <author>
      <name>H. Karray</name>
    </author>
    <author>
      <name>Adel M. Alimi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 3 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Scientific Research &amp; Engineering
  Technology (IJSET), ISSN: (2277-1581) volume 1, 2014</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1404.5248v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.5248v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.6750v1</id>
    <updated>2014-04-27T13:57:05Z</updated>
    <published>2014-04-27T13:57:05Z</published>
    <title>10 Inventions on Command Buttons in a Graphical User Interface</title>
    <summary>  A command button may contain a textual label or a graphic image or both. It
may be static or animated. There can be many different features to make a
command button attractive and effective. As command button is a typical GUI
element, most improvement on GUI in general will also be applicable to command
buttons. Besides, there are also inventions to improve various aspects of
command buttons in specific. This article illustrates 10 selected inventions
from US patent database. Each invention is followed by a TRIZ based analysis in
brief.
</summary>
    <author>
      <name>Umakant Mishra</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.2139/ssrn.949240</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.2139/ssrn.949240" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Mishra, Umakant, 10 Inventions on Command Buttons in a Graphical
  User Interface, (December 6, 2006) Available at SSRN:
  http://ssrn.com/abstract=949240</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1404.6750v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.6750v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.6757v1</id>
    <updated>2014-04-27T14:29:01Z</updated>
    <published>2014-04-27T14:29:01Z</published>
    <title>Inventions on expressing emotions In Graphical User Interface</title>
    <summary>  The conventional GUI is more mechanical and does not recognize or communicate
emotions. The modern GUIs are trying to infer the likely emotional state and
personality of the user and communicate through a corresponding emotional
state.
  Emotions are expressed in graphical icons, sounds, pictures and other means.
The emotions are found to be useful in especially in communication software,
interactive learning systems, robotics and other adaptive environments. Various
mechanisms have been developed to express emotions through graphical user
interfaces. This article illustrates some interesting inventions selected from
US patent database.
</summary>
    <author>
      <name>Umakant Mishra</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.2139/ssrn.949250</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.2139/ssrn.949250" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 4 figures. Umakant Mishra, Inventions on Expressing Emotions
  in Graphical User Interface, (December 6, 2006), Available at SSRN:
  http://ssrn.com/abstract=949250</arxiv:comment>
    <link href="http://arxiv.org/abs/1404.6757v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.6757v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.6765v1</id>
    <updated>2014-04-27T15:18:54Z</updated>
    <published>2014-04-27T15:18:54Z</published>
    <title>Inventions on GUI for Eye Cursor Controls Systems</title>
    <summary>  Operating a GUI through eyeball is a complex mechanism and not used as often
as mouse or trackball. But there are situations where eye-mouse devices can
play a tremendous role especially where the hands of the user are not available
or busy to perform other activities. The difficulties of implementing an
eye-cursor control system are many. The article illustrates some inventions on
eye-cursor control system, which attempt to eliminate the difficulties of the
prior art mechanisms.
</summary>
    <author>
      <name>Umakant Mishra</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.2139/ssrn.1264687</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.2139/ssrn.1264687" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 4 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Mishra, Umakant, Inventions on GUI for Eye Cursor Control Systems
  (September 7, 2007), Available at SSRN: http://ssrn.com/abstract=1264687 or
  http://dx.doi.org/10.2139/ssrn.1264687</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1404.6765v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.6765v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.3758v1</id>
    <updated>2014-05-15T06:55:21Z</updated>
    <published>2014-05-15T06:55:21Z</published>
    <title>Search Interfaces for Mathematicians</title>
    <summary>  Access to mathematical knowledge has changed dramatically in recent years,
therefore changing mathematical search practices. Our aim with this study is to
scrutinize professional mathematicians' search behavior. With this
understanding we want to be able to reason why mathematicians use which tool
for what search problem in what phase of the search process. To gain these
insights we conducted 24 repertory grid interviews with mathematically inclined
people (ranging from senior professional mathematicians to non-mathematicians).
From the interview data we elicited patterns for the user group
"mathematicians" that can be applied when understanding design issues or
creating new designs for mathematical search interfaces.
</summary>
    <author>
      <name>Andrea Kohlhase</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">conference article "CICM'14: International Conference on Computer
  Mathematics 2014", DML-Track: Digital Math Libraries 17 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1405.3758v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.3758v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.5249v1</id>
    <updated>2014-05-20T22:08:32Z</updated>
    <published>2014-05-20T22:08:32Z</published>
    <title>Hidden Markov Model for Inferring Learner Task Using Mouse Movement</title>
    <summary>  One of the issues of e-learning web based application is to understand how
the learner interacts with an e-learning application to perform a given task.
This study proposes a methodology to analyze learner mouse movement in order to
infer the task performed. To do this, a Hidden Markov Model is used for
modeling the interaction of the learner with an e-learning application. The
obtained results show the ability of our model to analyze the interaction in
order to recognize the task performed by the learner.
</summary>
    <author>
      <name>Elbahi Anis</name>
    </author>
    <author>
      <name>Mohamed Ali Mahjoub</name>
    </author>
    <author>
      <name>Mohamed Nazih Omri</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Fourth International Conference on Information and Communication
  Technology and Accessibility (ICTA), 2013</arxiv:comment>
    <link href="http://arxiv.org/abs/1405.5249v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.5249v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1406.4803v1</id>
    <updated>2014-06-18T17:25:06Z</updated>
    <published>2014-06-18T17:25:06Z</published>
    <title>Reorganization of Links to Improve User Navigation</title>
    <summary>  Website can be easily design but to efficient user navigation is not a easy
task since user behavior is keep changing and developer view is quite different
from what user wants, so to improve navigation one way is reorganization of
website structure. For reorganization here proposed strategy is farthest first
traversal clustering algorithm perform clustering on two numeric parameters and
for finding frequent traversal path of user Apriori algorithm is used. Our aim
is to perform reorganization with fewer changes in website structure.
</summary>
    <author>
      <name>Deepshree A. Vadeyar</name>
    </author>
    <author>
      <name>Yogish H. K</name>
    </author>
    <link href="http://arxiv.org/abs/1406.4803v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1406.4803v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1407.0434v2</id>
    <updated>2014-07-14T12:18:54Z</updated>
    <published>2014-07-02T01:05:33Z</published>
    <title>Towards a Practical Architecture for India Centric Internet of Things</title>
    <summary>  An effective architecture for the Internet of Things (IoT), particularly for
an emerging nation like India with limited technology penetration at the
national scale, should be based on tangible technology advances in the present,
practical application scenarios of social and entrepreneurial value, and
ubiquitous capabilities that make the realization of IoT affordable and
sustainable. Humans, data, communication and devices play key roles in the IoT
ecosystem that we perceive. In a push towards this sustainable and practical
IoT Architecture for India, we synthesize ten design paradigms to consider.
</summary>
    <author>
      <name>Prasant Misra</name>
    </author>
    <author>
      <name>Yogesh Simmhan</name>
    </author>
    <author>
      <name>Jay Warrior</name>
    </author>
    <link href="http://arxiv.org/abs/1407.0434v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1407.0434v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1407.0843v1</id>
    <updated>2014-07-03T10:09:57Z</updated>
    <published>2014-07-03T10:09:57Z</published>
    <title>The Gamification Design Problem</title>
    <summary>  Under the assumptions that (i) gamification consists of various types of
users that experience game design elements differently; and (ii) gamification
is deployed in order to achieve some goal in the broadest sense, we pose the
gamification problem as that of assigning each user a game design element that
maximizes their expected contribution in order to achieve that goal. We show
that this problem reduces to a statistical learning problem and suggest matrix
factorization as one solution when user interaction data is given. The
hypothesis is that predictive models as intelligent tools for supporting users
in decision-making may also have potential to support the design process in
gamification.
</summary>
    <author>
      <name>Michael Meder</name>
    </author>
    <author>
      <name>Brijnesh-Johannes Jain</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, preprint</arxiv:comment>
    <link href="http://arxiv.org/abs/1407.0843v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1407.0843v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1408.1173v1</id>
    <updated>2014-08-06T03:16:21Z</updated>
    <published>2014-08-06T03:16:21Z</published>
    <title>A Review Paper on Oculus Rift-A Virtual Reality Headset</title>
    <summary>  Oculus rift: Virtual reality (VR) is a burgeoning field that has the inherent
potential of manipulating peoples mind with a superlative 3D experience. Oculus
rift is one such application that assists in achieving the same. With the
fleeting enhancements in VR it now seems very feasible to provide the user with
experiences that were earlier thought to be merely a dream or a nightmare.
</summary>
    <author>
      <name>Parth Rajesh Desai</name>
    </author>
    <author>
      <name>Pooja Nikhil Desai</name>
    </author>
    <author>
      <name>Komal Deepak Ajmera</name>
    </author>
    <author>
      <name>Khushbu Mehta</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages,7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1408.1173v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1408.1173v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1409.0128v1</id>
    <updated>2014-08-30T15:45:19Z</updated>
    <published>2014-08-30T15:45:19Z</published>
    <title>Through the Frosted Glass: Security Problems in a Translucent UI</title>
    <summary>  Translucency is now a common design element in at least one popular mobile
operating system. This raises security concerns as it can make it harder for
users to correctly identify and interpret trusted interaction elements. In this
paper, we demonstrate this security problem using the example of the Safari
browser in the latest iOS version on Apple tablets and phones (iOS7), and
discuss technical challenges of an attack as well as solutions to these
challenges. We conclude with a survey-based user study, where we seek to
quantify the security impact, and find that further investigation is warranted.
</summary>
    <author>
      <name>Arne Renkema-Padmos</name>
    </author>
    <author>
      <name>Jerome Baum</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1409.0128v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1409.0128v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1409.2208v1</id>
    <updated>2014-09-08T05:09:49Z</updated>
    <published>2014-09-08T05:09:49Z</published>
    <title>A wireless hand-held platform for robotic behavior control</title>
    <summary>  The need for customizable properties in autonomous robotic platforms, such as
in-home nursing care for the elderly and parallel implementations of
human-to-machine control interfaces creates an opportunity to introduce methods
deploying commonly available mobile devices running robotic command
applications in managed code. This paper will discuss a human-to-machine
interface and demonstrate a prototype consisting of a mobile device running a
configurable application communicating with a mobile robot using a managed,
type-safe language, C#.NET, over Bluetooth.
</summary>
    <author>
      <name>Christopher A. Tucker</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1409.2208v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1409.2208v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1409.3993v1</id>
    <updated>2014-09-13T21:43:45Z</updated>
    <published>2014-09-13T21:43:45Z</published>
    <title>Clear, Concise and Effective UI: Opinion and Suggestions</title>
    <summary>  The most important aspect of any Software is the operability for the intended
audience. This factor of operability is encompassed in the user interface,
which serves as the only window to the features of the system. It is thus
essential that the User Interface provided is robust, concise and lucid.
Presently there are no properly defined rules or guidelines for user interface
design enabling a perfect design, since such a system cannot be perceived. This
article aims at providing suggestions in the design of the User Interface,
which would make it easier for the user to navigate through the system features
and also the developers to guide the users towards better utilization of the
features.
</summary>
    <author>
      <name>Rishabh Jain</name>
    </author>
    <author>
      <name>Rupanta Rwiteej Dutta</name>
    </author>
    <author>
      <name>Rajat Tandon</name>
    </author>
    <link href="http://arxiv.org/abs/1409.3993v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1409.3993v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="00-01" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1409.5282v1</id>
    <updated>2014-09-18T12:25:04Z</updated>
    <published>2014-09-18T12:25:04Z</published>
    <title>Sonification Aesthetics and Listening for Network Situational Awareness</title>
    <summary>  This paper looks at the problem of using sonification to enable network
administrators to maintaining situational awareness about their network
environment. Network environments generate a lot of data and the need for
continuous monitoring means that sonification systems must be designed in such
a way as to maximise acceptance while minimising annoyance and listener
fatigue. It will be argued that solutions based on the concept of the
soundscape offer an ecological advantage over other sonification designs.
</summary>
    <author>
      <name>Paul Vickers</name>
    </author>
    <author>
      <name>Christopher Laing</name>
    </author>
    <author>
      <name>Mohamed Debashi</name>
    </author>
    <author>
      <name>Tom Fairfax</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.13140/2.1.4225.6648</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.13140/2.1.4225.6648" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Workshop paper presented at SoniHED --- Conference on Sonification of
  Health and Environmental Data, York, UK, 12 September, 2014</arxiv:comment>
    <link href="http://arxiv.org/abs/1409.5282v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1409.5282v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.2828v1</id>
    <updated>2014-10-10T16:12:20Z</updated>
    <published>2014-10-10T16:12:20Z</published>
    <title>A Study on Placement of Social Buttons in Web Pages</title>
    <summary>  With the explosion of social media in the last few years, web pages nowadays
include different social network buttons where users can express if they
support or recommend content. Those social buttons are very visual and their
presentations, along with the counters, mark the importance of the social
network and the interest on the content. In this paper, we analyze the presence
of four types of social buttons (Facebook, Twitter, Google+1, and LinkedIn) in
a large collection of web pages that we tracked over a period of time. We
report on the distribution and counts along with some characteristics per
domain. Finally, we outline some research directions.
</summary>
    <author>
      <name>Omar Alonso</name>
    </author>
    <author>
      <name>Vasilis Kandylas</name>
    </author>
    <link href="http://arxiv.org/abs/1410.2828v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.2828v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.5907v1</id>
    <updated>2014-10-22T03:36:53Z</updated>
    <published>2014-10-22T03:36:53Z</published>
    <title>Replacing the computer mouse</title>
    <summary>  In a few months the computer mouse will be half-a-century-old. It is known to
have many drawbacks, the main ones being: loss of productivity due to constant
switching between keyboard and mouse, and health issues such as RSI. Like the
keyboard, it is an unnatural human-computer interface. However the vast
majority of computer users still use computer mice nowadays.
  In this article, we explore computer mouse alternatives. Our research shows
that moving the mouse cursor can be done efficiently with camera-based head
tracking system such as the SmartNav device, and mouse clicks can be emulated
in many complementary ways. We believe that computer users can increase their
productivity and improve their long-term health by using these alternatives.
</summary>
    <author>
      <name>Franck Dernoncourt</name>
    </author>
    <link href="http://arxiv.org/abs/1410.5907v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.5907v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.8221v1</id>
    <updated>2014-10-30T01:08:18Z</updated>
    <published>2014-10-30T01:08:18Z</published>
    <title>PIDE for Asynchronous Interaction with Coq</title>
    <summary>  This paper describes the initial progress towards integrating the Coq proof
assistant with the PIDE architecture initially developed for Isabelle. The
architecture is aimed at asynchronous, parallel interaction with proof
assistants, and is tied in heavily with a plugin that allows the jEdit editor
to work with Isabelle.
  We have made some generalizations to the PIDE architecture to accommodate for
more provers than just Isabelle, and adapted Coq to understand the core
protocol: this delivered a working system in about two man-months.
</summary>
    <author>
      <name>Carst Tankink</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Inria Saclay - Île-de-France</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.167.9</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.167.9" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings UITP 2014, arXiv:1410.7850</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 167, 2014, pp. 73-83</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1410.8221v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.8221v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.4179v1</id>
    <updated>2014-12-13T02:11:44Z</updated>
    <published>2014-12-13T02:11:44Z</published>
    <title>What About Feedback?</title>
    <summary>  The role of immediate feedback in-group conversations has received scant
attention in the recent literature. While studies from the early 1990's
suggested that "added information" in the form of non-verbal cues would allow
video conferencing to "augment" the audio-only conference in terms of
effectiveness, stunningly little follow-on research has been done reflective of
the current state of computer mediated communication, video conferencing, "live
walls", etc. This article contrasts three studies of immediate feedback in
in-person settings as the basis for suggesting a new research program -
research to look at potential effects of augmenting video-conferencing with an
immediate feedback channel.
</summary>
    <author>
      <name>Terrence Letiche</name>
    </author>
    <author>
      <name>Michael Lissack</name>
    </author>
    <link href="http://arxiv.org/abs/1412.4179v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.4179v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.6378v1</id>
    <updated>2014-12-19T15:34:01Z</updated>
    <published>2014-12-19T15:34:01Z</published>
    <title>Wyrm, A Pythonic Toolbox for Brain-Computer Interfacing</title>
    <summary>  A Brain-Computer Interface (BCI) is a system that measures central nervous
system activity and translates the recorded data into an output suitable for a
computer to use as an input signal. Such a BCI system consists of three parts,
the signal acquisition, the signal processing and the feedback/stimulus
presentation. In this paper we present Wyrm, a signal processing toolbox for
BCI in Python. Wyrm is applicable to a broad range of neuroscientific problems
and capable for running online experiments in real time and off-line data
analysis and visualisation.
</summary>
    <author>
      <name>Bastian Venthur</name>
    </author>
    <author>
      <name>Benjamin Blankertz</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Part of the Proceedings of the 7th European Conference on Python in
  Science (EuroSciPy 2014), Pierre de Buyl and Nelle Varoquaux editors, (2014)</arxiv:comment>
    <link href="http://arxiv.org/abs/1412.6378v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.6378v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.7932v1</id>
    <updated>2014-12-26T12:50:07Z</updated>
    <published>2014-12-26T12:50:07Z</published>
    <title>Home Automation Using SSVEP &amp; Eye-Blink Detection Based Brain-Computer
  Interface</title>
    <summary>  In this paper, we present a novel brain computer interface based home
automation system using two responses - Steady State Visually Evoked Potential
(SSVEP) and the eye-blink artifact, which is augmented by a Bluetooth based
indoor localization system, to greatly increase the number of controllable
devices. The hardware implementation of this system to control a table lamp and
table fan using brain signals has also been discussed and state-of-the-art
results have been achieved.
</summary>
    <author>
      <name>Kratarth Goel</name>
    </author>
    <author>
      <name>Raunaq Vohra</name>
    </author>
    <author>
      <name>Anant Kamath</name>
    </author>
    <author>
      <name>Veeky Baths</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/SMC.2014.6974563</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/SMC.2014.6974563" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2 pages, 1 table, published at IEEE SMC 2014</arxiv:comment>
    <link href="http://arxiv.org/abs/1412.7932v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.7932v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1501.04156v1</id>
    <updated>2015-01-17T04:55:34Z</updated>
    <published>2015-01-17T04:55:34Z</published>
    <title>User involvement in the partner program of the educational social
  network</title>
    <summary>  The paper describes experiments to attract active online system users to the
partner program. The objective is to grow the number of users by involving
existing system users in viral mechanics. Several examples of user motivation
are given, along with the specific interface implementations and viral
mechanics. Viral K-factor was used as the metrics for the resulting system
growth assessment. Specific examples show both positive and negative outcomes.
Growth of the target system parameters is discussed.
</summary>
    <author>
      <name>Ilya V. Osipov</name>
    </author>
    <author>
      <name>Anna Y. Prasikova</name>
    </author>
    <author>
      <name>Alex A. Volinsky</name>
    </author>
    <link href="http://arxiv.org/abs/1501.04156v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1501.04156v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1501.05696v2</id>
    <updated>2015-08-29T14:35:18Z</updated>
    <published>2015-01-23T01:59:39Z</published>
    <title>Anima: Adaptive Personalized Software Keyboard</title>
    <summary>  We present a Software Keyboard for smart touchscreen devices that learns its
owner's unique dictionary in order to produce personalized typing predictions.
The learning process is accelerated by analysing user's past typed
communication. Moreover, personal temporal user behaviour is captured and
exploited in the prediction engine. Computational and storage issues are
addressed by dynamically forgetting words that the user no longer types. A
prototype implementation is available at Google Play Store.
</summary>
    <author>
      <name>Panos Sakkos</name>
    </author>
    <author>
      <name>Dimitrios Kotsakos</name>
    </author>
    <author>
      <name>Ioannis Katakis</name>
    </author>
    <author>
      <name>Dimitrios Gunopulos</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1501.05696v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1501.05696v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.04326v1</id>
    <updated>2015-02-15T16:05:21Z</updated>
    <published>2015-02-15T16:05:21Z</published>
    <title>Interface Transformation from Ruling to Obedience</title>
    <summary>  This article is about one feature which was partly introduced 30 years ago
with the development of multi windows operating systems. It is about the
movability of screen objects not according to some predetermined algorithm but
by the direct user action. Many years ago it was introduced on a very limited
basis and nothing was improved since then. Smartphones and tablets give direct
access to screen elements but on a very limited set of commands (scroll and
zoom). There is an easy to use algorithm which turns any screen object into
movable / resizable. This algorithm uses only mouse to turn screens of normal
PCs into touchscreens, but this simple change means a revolution in our work
with computers.
</summary>
    <author>
      <name>Sergey Andreyev</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1502.04326v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.04326v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.1.2; H.5.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.04744v1</id>
    <updated>2015-02-16T22:50:03Z</updated>
    <published>2015-02-16T22:50:03Z</published>
    <title>Where's My Drink? Enabling Peripheral Real World Interactions While
  Using HMDs</title>
    <summary>  Head Mounted Displays (HMDs) allow users to experience virtual reality with a
great level of immersion. However, even simple physical tasks like drinking a
beverage can be difficult and awkward while in a virtual reality experience. We
explore mixed reality renderings that selectively incorporate the physical
world into the virtual world for interactions with physical objects. We
conducted a user study comparing four rendering techniques that balances
immersion in a virtual world with ease of interaction with the physical world.
Finally, we discuss the pros and cons of each approach, suggesting guidelines
for future rendering techniques that bring physical objects into virtual
reality.
</summary>
    <author>
      <name>Pulkit Budhiraja</name>
    </author>
    <author>
      <name>Rajinder Sodhi</name>
    </author>
    <author>
      <name>Brett Jones</name>
    </author>
    <author>
      <name>Kevin Karsch</name>
    </author>
    <author>
      <name>Brian Bailey</name>
    </author>
    <author>
      <name>David Forsyth</name>
    </author>
    <link href="http://arxiv.org/abs/1502.04744v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.04744v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.03400v2</id>
    <updated>2015-08-30T13:33:54Z</updated>
    <published>2015-03-11T16:14:16Z</published>
    <title>Get 'em Moles! : Learning Spelling and Pronunciation through an
  Educational Game</title>
    <summary>  Get 'em Moles! is a single-player educational game inspired by the classic
arcade game Whac-A-Mole. Primarily designed for touchscreen devices, Get 'em
Moles! aims to teach English spelling and pronunciation through engaging game
play. This paper describes the game, design decisions in the form of elements
that support learning, preliminary play-testing results, and future work.
</summary>
    <author>
      <name>Dhruv Chand</name>
    </author>
    <author>
      <name>Karthik Gopalakrishnan</name>
    </author>
    <author>
      <name>Nisha KK</name>
    </author>
    <author>
      <name>Mudit Sinha</name>
    </author>
    <author>
      <name>Shreya Sriram</name>
    </author>
    <link href="http://arxiv.org/abs/1503.03400v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.03400v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="K.3.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.04375v2</id>
    <updated>2015-03-17T01:05:42Z</updated>
    <published>2015-03-15T02:48:08Z</published>
    <title>Optimization of Switch Keyboards</title>
    <summary>  Patients with motor control difficulties often "type" on a computer using a
switch keyboard to guide a scanning cursor to text elements. We show how to
optimize some parts of the design of switch keyboards by casting the design
problem as mixed integer programming. A new algorithm to find an optimized
design solution is approximately 3600 times faster than a previous algorithm,
which was also susceptible to finding a non-optimal solution. The optimization
requires a model of the probability of an entry error, and we show how to build
such a model from experimental data. Example optimized keyboards are
demonstrated.
</summary>
    <author>
      <name>Xiao Zhang</name>
    </author>
    <author>
      <name>Kan Fang</name>
    </author>
    <author>
      <name>Gregory Francis</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/2513383.2513394</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/2513383.2513394" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings of the 15th International ACM SIGACCESS Conference on
  Computers and Accessibility 2013</arxiv:comment>
    <link href="http://arxiv.org/abs/1503.04375v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.04375v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.08866v1</id>
    <updated>2015-03-30T22:35:03Z</updated>
    <published>2015-03-30T22:35:03Z</published>
    <title>Towards Data-Driven Hierarchical Surgical Skill Analysis</title>
    <summary>  This paper evaluates methods of hierarchical skill analysis developed in
aerospace to the problem of surgical skill assessment and modeling. The
analysis employs tool motion data of Fundamental of Laparoscopic Skills (FLS)
tasks collected from clinicians of various skill levels at three different
clinical teaching hospitals in the United States. Outcomes are evaluated based
on their ability to provide relevant information about the underlying processes
across the entire system hierarchy including control, guidance and planning.
</summary>
    <author>
      <name>Bin Li</name>
    </author>
    <author>
      <name>Berenice Mettler</name>
    </author>
    <author>
      <name>Timonthy M. Kowalewski</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">M2CAI 2014</arxiv:comment>
    <link href="http://arxiv.org/abs/1503.08866v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.08866v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.00747v1</id>
    <updated>2015-04-03T05:25:07Z</updated>
    <published>2015-04-03T05:25:07Z</published>
    <title>Software for Wearable Devices: Challenges and Opportunities</title>
    <summary>  Wearable devices are a new form of mobile computer system that provides
exclusive and user-personalized services. Wearable devices bring new issues and
challenges to computer science and technology. This paper summarizes the
development process and the categories of wearable devices. In addition, we
present new key issues arising in aspects of wearable devices, including
operating systems, database management system, network communication protocol,
application development platform, privacy and security, energy consumption,
human-computer interaction, software engineering, and big data.
</summary>
    <author>
      <name>He Jiang</name>
    </author>
    <author>
      <name>Xin Chen</name>
    </author>
    <author>
      <name>Shuwei Zhang</name>
    </author>
    <author>
      <name>Xin Zhang</name>
    </author>
    <author>
      <name>Weiqiang Kong</name>
    </author>
    <author>
      <name>Tao Zhang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 1 figure, for Compsac 2015</arxiv:comment>
    <link href="http://arxiv.org/abs/1504.00747v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.00747v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.01049v1</id>
    <updated>2015-04-04T20:34:11Z</updated>
    <published>2015-04-04T20:34:11Z</published>
    <title>3D visual analysis of seabed on smartphone</title>
    <summary>  We create a 'virtual-seabed' platform to realize the 3D visual analysis of
seabed on smartphone. The 3D seabed platform is based on a 'section-drilling'
model, implementing visualization and analysis of the integrated data of seabed
on the 3D browser on smartphone. Some 3D visual analysis functions are
developed. This work presents a thorough and interesting way of presenting
seabed data on smartphone, which raises many application possibilities. This
platform is another practical proof based on our WebVRGIS platform.
</summary>
    <author>
      <name>Zhihan Lv</name>
    </author>
    <author>
      <name>Tianyun Su</name>
    </author>
    <author>
      <name>Xiaoming Li</name>
    </author>
    <author>
      <name>Shengzhong Feng</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2015 IEEE Pacific Visualization Symposium (PacificVis)</arxiv:comment>
    <link href="http://arxiv.org/abs/1504.01049v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.01049v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.01051v1</id>
    <updated>2015-04-04T20:44:33Z</updated>
    <published>2015-04-04T20:44:33Z</published>
    <title>WebVRGIS Based City Bigdata 3D Visualization and Analysis</title>
    <summary>  This paper shows the WEBVRGIS platform overlying multiple types of data about
Shenzhen over a 3d globe. The amount of information that can be visualized with
this platform is overwhelming, and the GIS-based navigational scheme allows to
have great flexibility to access the different available data sources. For
example,visualising historical and forecasted passenger volume at stations
could be very helpful when overlaid with other social data.
</summary>
    <author>
      <name>Xiaoming Li</name>
    </author>
    <author>
      <name>Zhihan Lv</name>
    </author>
    <author>
      <name>Baoyun Zhang</name>
    </author>
    <author>
      <name>Weixi Wang</name>
    </author>
    <author>
      <name>Shengzhong Feng</name>
    </author>
    <author>
      <name>Jinxing Hu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2015 IEEE Pacific Visualization Symposium (PacificVis)</arxiv:comment>
    <link href="http://arxiv.org/abs/1504.01051v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.01051v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.3.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.03370v2</id>
    <updated>2015-07-29T08:40:22Z</updated>
    <published>2015-04-13T21:46:32Z</published>
    <title>Preprint Serious Game Based Dysphonic Rehabilitation Tool</title>
    <summary>  This is the preprint version of our paper on 2015 International Conference on
Virtual Rehabilitation (ICVR2015). The purpose of this work is designing and
implementing a rehabilitation software for dysphonic patients. Constant
training is a key factor for this type of therapy. The patient can play the
game as well as conduct the voice training simultaneously guided by therapists
at clinic or exercise independently at home. The voice information can be
recorded and extracted for evaluating the long-time rehabilitation progress.
</summary>
    <author>
      <name>Zhihan Lv</name>
    </author>
    <author>
      <name>Chantal Esteve</name>
    </author>
    <author>
      <name>Javier Chirivella</name>
    </author>
    <author>
      <name>Pablo Gagliardo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This is the preprint version of our paper on 2015 International
  Conference on Virtual Rehabilitation (ICVR2015)</arxiv:comment>
    <link href="http://arxiv.org/abs/1504.03370v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.03370v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.03371v2</id>
    <updated>2015-07-29T08:37:31Z</updated>
    <published>2015-04-13T21:52:07Z</published>
    <title>Preprint Imagining In-Air Interaction for Hemiplegia Sufferer</title>
    <summary>  This is the preprint version of our paper on 2015 International Conference on
Virtual Rehabilitation (ICVR2015). In this paper, we described the imagination
scenarios of a touch-less interaction technology for hemiplegia, which can
support either hand or foot interaction with the smartphone or head mounted
device (HMD). The computer vision interaction technology is implemented in our
previous work, which provides a core support for gesture interaction by
accurately detecting and tracking the hand or foot gesture. The patients
interact with the application using hand/foot gesture motion in the camera
view.
</summary>
    <author>
      <name>Zhihan Lv</name>
    </author>
    <author>
      <name>Haibo Li</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This is the preprint version of our paper on 2015 International
  Conference on Virtual Rehabilitation (ICVR2015)</arxiv:comment>
    <link href="http://arxiv.org/abs/1504.03371v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.03371v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.03731v1</id>
    <updated>2015-04-14T21:36:53Z</updated>
    <published>2015-04-14T21:36:53Z</published>
    <title>Safety enhancement through situation-aware user interfaces</title>
    <summary>  Due to their privileged position halfway between the physical and the cyber
universes, user interfaces may play an important role in preventing,
tolerating, and learning from scenarios potentially affecting mission safety
and the user's quality of experience. This vision is embodied here in the main
ideas and a proof-of-concepts implementation of user interfaces that combine
dynamic profiling with context- and situation-awareness and autonomic software
adaptation.
</summary>
    <author>
      <name>Vincenzo De Florio</name>
    </author>
    <author>
      <name>Chris Blondia</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published in the Proc. of the 7th Int.l IET System Safety Conference,
  Edinburgh, UK, 15-18 October 2012. IET</arxiv:comment>
    <link href="http://arxiv.org/abs/1504.03731v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.03731v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.00092v1</id>
    <updated>2015-05-01T05:18:57Z</updated>
    <published>2015-05-01T05:18:57Z</published>
    <title>On the Effect of Human-Computer Interfaces on Language Expression</title>
    <summary>  Language expression is known to be dependent on attributes intrinsic to the
author. To date, however, little attention has been devoted to the effect of
interfaces used to articulate language on its expression. Here we study a large
corpus of text written using different input devices and show that writers
unconsciously prefer different letters depending on the interplay between their
individual traits (e.g., hand laterality and injuries) and the layout of
keyboards. Our results show, for the first time, how the interplay between
technology and its users modifies language expression.
</summary>
    <author>
      <name>Dan Pelleg</name>
    </author>
    <author>
      <name>Elad Yom-Tov</name>
    </author>
    <author>
      <name>Evgeniy Gabrilovich</name>
    </author>
    <link href="http://arxiv.org/abs/1505.00092v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.00092v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.00111v1</id>
    <updated>2015-05-01T07:46:53Z</updated>
    <published>2015-05-01T07:46:53Z</published>
    <title>Mobile Crowd Sensing and Computing: When Participatory Sensing Meets
  Participatory Social Media</title>
    <summary>  With the development of mobile sensing and mobile social networking
techniques, Mobile Crowd Sensing and Computing (MCSC), which leverages
heterogeneous crowdsourced data for large-scale sensing, has become a leading
paradigm. Built on top of the participatory sensing vision, MCSC has two
characterizing features: (1) it leverages heterogeneous crowdsourced data from
two data sources: participatory sensing and participatory social media; and (2)
it presents the fusion of human and machine intelligence (HMI) in both the
sensing and computing process. This paper characterizes the unique features and
challenges of MCSC. We further present early efforts on MCSC to demonstrate the
benefits of aggregating heterogeneous crowdsourced data.
</summary>
    <author>
      <name>Bin Guo</name>
    </author>
    <author>
      <name>Chao Chen</name>
    </author>
    <author>
      <name>Daqing Zhang</name>
    </author>
    <author>
      <name>Zhiwen Yu</name>
    </author>
    <author>
      <name>Alvin Chin</name>
    </author>
    <link href="http://arxiv.org/abs/1505.00111v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.00111v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.00489v1</id>
    <updated>2015-05-03T22:45:19Z</updated>
    <published>2015-05-03T22:45:19Z</published>
    <title>The Distant Heart: Mediating Long-Distance Relationships through
  Connected Computational Jewelry</title>
    <summary>  In the world where increasingly mobility and long-distance relationships with
family, friends and loved-ones became commonplace, there exists a gap in
intimate interpersonal communication mediated by technology. Considering the
advances in the field of mediation of relationships through technology, as well
as prevalence of use of jewelry as love-tokens for expressing a wish to be
remembered and to evoke the presence of the loved-one, developments in the new
field of computational jewelry offer some truly exciting possibilities. In this
paper we investigate the role that the jewelry-like form factor of prototypes
can play in the context of studying effects of computational jewelry in
mediating long-distance relationships.
</summary>
    <author>
      <name>Yulia Silina</name>
    </author>
    <author>
      <name>Hamed Haddadi</name>
    </author>
    <link href="http://arxiv.org/abs/1505.00489v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.00489v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.01319v3</id>
    <updated>2015-11-10T10:02:28Z</updated>
    <published>2015-05-06T10:56:12Z</published>
    <title>The History of Mobile Augmented Reality</title>
    <summary>  This document summarizes the major milestones in mobile Augmented Reality
between 1968 and 2014. Major parts of the list were compiled by the member of
the Christian Doppler Laboratory for Handheld Augmented Reality in 2010 (author
list in alphabetical order) for the ISMAR society. Later in 2013 it was
updated, and more recent work was added during preparation of this report.
Permission is granted to copy and modify.
</summary>
    <author>
      <name>Clemens Arth</name>
    </author>
    <author>
      <name>Raphael Grasset</name>
    </author>
    <author>
      <name>Lukas Gruber</name>
    </author>
    <author>
      <name>Tobias Langlotz</name>
    </author>
    <author>
      <name>Alessandro Mulloni</name>
    </author>
    <author>
      <name>Daniel Wagner</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">43 pages, 18 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1505.01319v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.01319v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.04333v2</id>
    <updated>2015-06-16T21:32:30Z</updated>
    <published>2015-06-13T23:23:21Z</published>
    <title>Towards Scalable Visual Exploration of Very Large RDF Graphs</title>
    <summary>  In this paper, we outline our work on developing a disk-based infrastructure
for efficient visualization and graph exploration operations over very large
graphs. The proposed platform, called graphVizdb, is based on a novel technique
for indexing and storing the graph. Particularly, the graph layout is indexed
with a spatial data structure, i.e., an R-tree, and stored in a database. In
runtime, user operations are translated into efficient spatial operations
(i.e., window queries) in the backend.
</summary>
    <author>
      <name>Nikos Bikakis</name>
    </author>
    <author>
      <name>John Liagouris</name>
    </author>
    <author>
      <name>Maria Krommyda</name>
    </author>
    <author>
      <name>George Papastefanatos</name>
    </author>
    <author>
      <name>Timos Sellis</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12th Extended Semantic Web Conference (ESWC 2015)</arxiv:comment>
    <link href="http://arxiv.org/abs/1506.04333v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.04333v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.05573v1</id>
    <updated>2015-06-18T07:47:49Z</updated>
    <published>2015-06-18T07:47:49Z</published>
    <title>Emergence of synchrony in an Adaptive Interaction Model</title>
    <summary>  In a Human-Computer Interaction context, we aim to elaborate an adaptive and
generic interaction model in two different use cases: Embodied Conversational
Agents and Creative Musical Agents for musical improvisation. To reach this
goal, we'll try to use the concepts of adaptation and synchronization to
enhance the interactive abilities of our agents and guide the development of
our interaction model, and will try to make synchrony emerge from non-verbal
dimensions of interaction.
</summary>
    <author>
      <name>Kevin Sanlaville</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LTCI</arxiv:affiliation>
    </author>
    <author>
      <name>Gérard Assayag</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LTCI</arxiv:affiliation>
    </author>
    <author>
      <name>Frédéric Bevilacqua</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LTCI</arxiv:affiliation>
    </author>
    <author>
      <name>Catherine Pelachaud</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LTCI</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Intelligent Virtual Agents 2015 Doctoral Consortium, Aug 2015, Delft,
  Netherlands. IVA Doctoral Consortium, 2015</arxiv:comment>
    <link href="http://arxiv.org/abs/1506.05573v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.05573v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.01292v1</id>
    <updated>2015-07-05T22:56:01Z</updated>
    <published>2015-07-05T22:56:01Z</published>
    <title>ScratchR: Sharing User-generated Programmable Media</title>
    <summary>  In this paper, I describe a platform for sharing programmable media on the
web called ScratchR. As the backbone of an on-line community of creative
learners, ScratchR will give members access to an audience and inspirational
ideas from each other. ScratchR seeks to support different states of
participation: from passive consumption to active creation. This platform is
being evaluated with a group of middle-school students and a larger community
of beta testers.
</summary>
    <author>
      <name>Andrés Monroy-Hernández</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/1297277.1297315</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/1297277.1297315" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings of the 6th international conference on Interaction
  Design and Children (IDC 2007). ACM, New York, NY, USA, 167-168</arxiv:comment>
    <link href="http://arxiv.org/abs/1507.01292v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.01292v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.01299v1</id>
    <updated>2015-07-05T23:34:15Z</updated>
    <published>2015-07-05T23:34:15Z</published>
    <title>NewsPad: Designing for Collaborative Storytelling in Neighborhoods</title>
    <summary>  This paper introduces design explorations in neighborhood collaborative
storytelling. We focus on blogs and citizen journalism, which have been
celebrated as a means to meet the reporting needs of small local communities.
These bloggers have limited capacity and social media feeds seldom have the
context or readability of news stories. We present NewsPad, a content editor
that helps communities create structured stories, collaborate in real time,
recruit contributors, and syndicate the editing process. We evaluate NewsPad in
four pilot deployments and find that the design elicits collaborative story
creation.
</summary>
    <author>
      <name>J. Nathan Matias</name>
    </author>
    <author>
      <name>Andrés Monroy-Hernández</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/2559206.2581354</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/2559206.2581354" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">NewsPad: designing for collaborative storytelling in neighborhoods.
  In Proceedings of the extended abstracts of the 32nd annual ACM conference on
  Human factors in computing systems (CHI EA 2014)</arxiv:comment>
    <link href="http://arxiv.org/abs/1507.01299v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.01299v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.01882v1</id>
    <updated>2015-07-07T17:10:16Z</updated>
    <published>2015-07-07T17:10:16Z</published>
    <title>Demandance</title>
    <summary>  A demandance is a psychological "pull" exerted by a stimulus. It is closely
related to the theory of "affordance". I introduce the theory of demandance,
offer some motivating examples, briefly explore its psychological basis, and
examine some implications of the theory. I exemplify some of the positive and
negative implications of demandances for design, with special attention to
young children and the design of educational products and practices. I suggest
that demandance offers an approach to one of the persistent mysteries of the
theory of affordance, specifically: Given that there may be many affordances in
any particular setting, how do we choose which to actually act upon?
</summary>
    <author>
      <name>Jeff Shrager</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1507.01882v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.01882v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.02024v1</id>
    <updated>2015-08-09T14:14:33Z</updated>
    <published>2015-08-09T14:14:33Z</published>
    <title>Preprint Virtual Reality Based GIS Analysis Platform</title>
    <summary>  This is the preprint version of our paper on ICONIP2015. The proposed
platform supports the integrated VRGIS functions including 3D spatial analysis
functions, 3D visualization for spatial process and serves for 3D globe and
digital city. The 3D analysis and visualization of the concerned city massive
information are conducted in the platform. The amount of information that can
be visualized with this platform is overwhelming, and the GIS based
navigational scheme allows to have great flexibility to access the different
available data sources.
</summary>
    <author>
      <name>Weixi Wang</name>
    </author>
    <author>
      <name>Zhihan Lv</name>
    </author>
    <author>
      <name>Xiaoming Li</name>
    </author>
    <author>
      <name>Weiping Xu</name>
    </author>
    <author>
      <name>Baoyun Zhang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This is the preprint version of our paper on ICONIP2015</arxiv:comment>
    <link href="http://arxiv.org/abs/1508.02024v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.02024v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.03653v1</id>
    <updated>2015-04-25T01:08:32Z</updated>
    <published>2015-04-25T01:08:32Z</published>
    <title>AnimalCatcher: a digital camera to capture various reactions of animals</title>
    <summary>  People often have difficulty to take pictures of animals, since animals
usually do not react with cameras nor understand verbal directions. To solve
this problem, we developed a new interaction technique, AnimalCatcher, which
can attract animals' attention easily. The AnimalCatcher shoots various sounds
using directional speaker to capture various reactions of animals. This paper
describes concepts, implementation, and example pictures taken in a zoo.
</summary>
    <author>
      <name>Koji Tsukada</name>
    </author>
    <author>
      <name>Maho Oki</name>
    </author>
    <author>
      <name>Kazutaka Kurihara</name>
    </author>
    <author>
      <name>Yuko Furudate</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Written in Japanese, 6 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1508.03653v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.03653v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.07053v1</id>
    <updated>2015-08-27T23:03:17Z</updated>
    <published>2015-08-27T23:03:17Z</published>
    <title>SentenceRacer: A Game with a Purpose for Image Sentence Annotation</title>
    <summary>  Recently datasets that contain sentence descriptions of images have enabled
models that can automatically generate image captions. However, collecting
these datasets are still very expensive. Here, we present SentenceRacer, an
online game that gathers and verifies descriptions of images at no cost.
Similar to the game hangman, players compete to uncover words in a sentence
that ultimately describes an image. SentenceRacer both generates and verifies
that the sentences are accurate descriptions. We show that SentenceRacer
generates annotations of higher quality than those generated on Amazon
Mechanical Turk (AMT).
</summary>
    <author>
      <name>Kenji Hata</name>
    </author>
    <author>
      <name>Sherman Leung</name>
    </author>
    <author>
      <name>Ranjay Krishna</name>
    </author>
    <author>
      <name>Michael S. Bernstein</name>
    </author>
    <author>
      <name>Li Fei-Fei</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2 pages, 2 figures, 2 tables, potential CSCW poster submission</arxiv:comment>
    <link href="http://arxiv.org/abs/1508.07053v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.07053v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1509.00159v2</id>
    <updated>2015-09-07T15:55:27Z</updated>
    <published>2015-09-01T07:03:35Z</published>
    <title>Preprint Virtual Reality Assistant Technology for Learning Primary
  Geography</title>
    <summary>  This is the preprint version of our paper on ICWL2015. A virtual reality
based enhanced technology for learning primary geography is proposed, which
synthesizes several latest information technologies including virtual
reality(VR), 3D geographical information system(GIS), 3D visualization and
multimodal human-computer-interaction (HCI). The main functions of the proposed
system are introduced, i.e. Buffer analysis, Overlay analysis, Space convex
hull calculation, Space convex decomposition, 3D topology analysis and 3D space
intersection detection. The multimodal technologies are employed in the system
to enhance the immersive perception of the users.
</summary>
    <author>
      <name>Zhihan Lv</name>
    </author>
    <author>
      <name>Xiaoming Li</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This is the preprint version of our paper on ICWL2015</arxiv:comment>
    <link href="http://arxiv.org/abs/1509.00159v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1509.00159v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1509.05452v1</id>
    <updated>2015-09-17T21:52:12Z</updated>
    <published>2015-09-17T21:52:12Z</published>
    <title>Composing vibrotactile music: A multisensory experience with the
  Emoti-chair</title>
    <summary>  The Emoti-Chair is a novel technology to enhance entertainment through
vibrotactile stimulation. We assessed the experience of this technology in two
workshops. In the first workshop, deaf film-makers experimented with creating
vibetracks for a movie clip using a professional movie editing software. In the
second workshop, trained opera singers sang and felt their voice through the
Emoti-Chair. Participants in both workshops generally found the overall
experience to be exciting and they were motivated to use the Chair for upcoming
projects.
</summary>
    <author>
      <name>Anant Baijal</name>
    </author>
    <author>
      <name>Julia Kim</name>
    </author>
    <author>
      <name>Carmen Branje</name>
    </author>
    <author>
      <name>Frank Russo</name>
    </author>
    <author>
      <name>Deborah I. Fels</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/HAPTIC.2012.6183839</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/HAPTIC.2012.6183839" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE HAPTICS Symposium 2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1509.05452v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1509.05452v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1509.06774v1</id>
    <updated>2015-09-22T20:35:54Z</updated>
    <published>2015-09-22T20:35:54Z</published>
    <title>Preprint: Bringing immersive enjoyment to hyperbaric oxygen chamber
  users using virtual reality glasses</title>
    <summary>  This is the preprint version of our paper on REHAB2015. This paper proposed a
novel immersive entertainment system for the users of hyperbaric oxygen therapy
chamber. The system is a hybrid of hardware and software, the scheme is
described in this paper. The hardware is combined by a HMD (i.e. virtual
reality glasses shell), a smartphone and a waterproof bag. The software is able
to transfer the stereoscopic images of the 3D game to the screen of the
smartphone synchronously. The comparison and selection of the hardware are
discussed according to the practical running scene of the clinical hyperbaric
oxygen treatment. Finally, a preliminary guideline for designing this kind of
system is raised accordingly.
</summary>
    <author>
      <name>Zhihan Lv</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This is the preprint version of our paper on REHAB2015</arxiv:comment>
    <link href="http://arxiv.org/abs/1509.06774v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1509.06774v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1509.06776v1</id>
    <updated>2015-09-22T20:43:51Z</updated>
    <published>2015-09-22T20:43:51Z</published>
    <title>Preprint: Intuitive Evaluation of Kinect2 based Balance Measurement
  Software</title>
    <summary>  This is the preprint version of our paper on REHAB2015. A balance measurement
software based on Kinect2 sensor is evaluated by comparing to golden standard
balance measure platform intuitively. The software analysis the tracked body
data from the user by Kinect2 sensor and get user's center of mass(CoM) as well
as its motion route on a plane. The software is evaluated by several comparison
tests, the evaluation results preliminarily prove the reliability of the
software.
</summary>
    <author>
      <name>Zhihan Lv</name>
    </author>
    <author>
      <name>Vicente Penades</name>
    </author>
    <author>
      <name>Sonia Blasco</name>
    </author>
    <author>
      <name>Javier Chirivella</name>
    </author>
    <author>
      <name>Pablo Gagliardo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This is the preprint version of our paper on REHAB2015</arxiv:comment>
    <link href="http://arxiv.org/abs/1509.06776v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1509.06776v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1509.06783v1</id>
    <updated>2015-09-22T20:59:19Z</updated>
    <published>2015-09-22T20:59:19Z</published>
    <title>Preprint: Comparing Kinect2 based Balance Measurement Software to Wii
  Balance Board</title>
    <summary>  This is the preprint version of our paper on REHAB2015. A balance measurement
software based on Kinect2 sensor is evaluated by comparing to Wii balance board
in numerical analysis level, and further improved according to the
consideration of BFP (Body fat percentage) values of the user. Several person
with different body types are involved into the test. The algorithm is improved
by comparing the body type of the user to the 'golden- standard' body type. The
evaluation results of the optimized algorithm preliminarily prove the
reliability of the software.
</summary>
    <author>
      <name>Zhihan Lv</name>
    </author>
    <author>
      <name>Vicente Penades</name>
    </author>
    <author>
      <name>Sonia Blasco</name>
    </author>
    <author>
      <name>Javier Chirivella</name>
    </author>
    <author>
      <name>Pablo Gagliardo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This is the preprint version of our paper on REHAB2015</arxiv:comment>
    <link href="http://arxiv.org/abs/1509.06783v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1509.06783v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.00519v1</id>
    <updated>2015-10-02T08:14:24Z</updated>
    <published>2015-10-02T08:14:24Z</published>
    <title>Interface Between Market and Science</title>
    <summary>  At the beginning, programming was inspired by the search of the best
solutions. At that time some fundamental stones like famous languages and
object oriented and structured programming were laid. It was found later that
applications could generate huge profits; after it marketing departments
started to decide what was right and wrong. Programs are ruled by developers
but declared user-friendly; millions of users are going mad trying to get the
needed results from these applications. Research goes on and new results can be
opposite to business view. History shows that not science has to adjust to
business, but eventually business will have to adapt to the results of the
research work.
</summary>
    <author>
      <name>Sergey Andreyev</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1510.00519v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.00519v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.01050v1</id>
    <updated>2015-10-05T07:05:27Z</updated>
    <published>2015-10-05T07:05:27Z</published>
    <title>Learning about End-User Development for Smart Homes by "Eating Our Own
  Dog Food"</title>
    <summary>  SPOK is an End-User Development Environment that permits people to monitor,
control, and configure smart home services and devices. SPOK has been deployed
for more than 4 months in the homes of 5 project team members for testing and
refinement, prior to longitudinal experiments in the homes of families not
involved in the project. This article reports on the lessons learned in this
initial deployment.
</summary>
    <author>
      <name>Joelle Coutaz</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PRIMA</arxiv:affiliation>
    </author>
    <author>
      <name>James L. Crowley</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PRIMA</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">CHI 2015, Conference on Computer Human Interaction, Apr 2015,
  Seoul, South Korea. Workshop on End-User Development for IOT Era,.
  \&amp;lt;https://chi2015.acm.org/\&amp;gt;</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1510.01050v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.01050v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.01942v1</id>
    <updated>2015-10-07T13:47:12Z</updated>
    <published>2015-10-07T13:47:12Z</published>
    <title>Helping Domain Experts Build Speech Translation Systems</title>
    <summary>  We present a new platform, "Regulus Lite", which supports rapid development
and web deployment of several types of phrasal speech translation systems using
a minimal formalism. A distinguishing feature is that most development work can
be performed directly by domain experts. We motivate the need for platforms of
this type and discuss three specific cases: medical speech translation,
speech-to-sign-language translation and voice questionnaires. We briefly
describe initial experiences in developing practical systems.
</summary>
    <author>
      <name>Manny Rayner</name>
    </author>
    <author>
      <name>Alejandro Armando</name>
    </author>
    <author>
      <name>Pierrette Bouillon</name>
    </author>
    <author>
      <name>Sarah Ebling</name>
    </author>
    <author>
      <name>Johanna Gerlach</name>
    </author>
    <author>
      <name>Sonia Halimi</name>
    </author>
    <author>
      <name>Irene Strasly</name>
    </author>
    <author>
      <name>Nikos Tsourakis</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 1 figure, to appear in Proc. Future and Emerging Trends in
  Language Technology 2015, Seville, Spain</arxiv:comment>
    <link href="http://arxiv.org/abs/1510.01942v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.01942v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.05879v1</id>
    <updated>2015-10-20T13:16:07Z</updated>
    <published>2015-10-20T13:16:07Z</published>
    <title>What's the point? Frame-wise Pointing Gesture Recognition with
  Latent-Dynamic Conditional Random Fields</title>
    <summary>  We use Latent-Dynamic Conditional Random Fields to perform skeleton-based
pointing gesture classification at each time instance of a video sequence,
where we achieve a frame-wise pointing accuracy of roughly 83%. Subsequently,
we determine continuous time sequences of arbitrary length that form individual
pointing gestures and this way reliably detect pointing gestures at a false
positive detection rate of 0.63%.
</summary>
    <author>
      <name>Christian Wittner</name>
    </author>
    <author>
      <name>Boris Schauerte</name>
    </author>
    <author>
      <name>Rainer Stiefelhagen</name>
    </author>
    <link href="http://arxiv.org/abs/1510.05879v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.05879v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.05672v2</id>
    <updated>2016-01-28T21:12:54Z</updated>
    <published>2015-11-18T07:06:55Z</published>
    <title>Could We Distinguish Child Users from Adults Using Keystroke Dynamics?</title>
    <summary>  Significant portion of contemporary computer users are children, who are
vulnerable to threats coming from the Internet. To protect children from such
threats, in this study, we investigate how successfully typing data can be used
to distinguish children from adults. For this purpose, we collect a dataset
comprising keystroke data of 100 users and show that distinguishing child
Internet users from adults is possible using Keystroke Dynamics with equal
error rates less than 10 percent. However the error rates increase
significantly when there are impostors in the system.
</summary>
    <author>
      <name>Yasin Uzun</name>
    </author>
    <author>
      <name>Kemal Bicakci</name>
    </author>
    <author>
      <name>Yusuf Uzunay</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1511.05672v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.05672v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.07500v1</id>
    <updated>2015-11-23T22:49:08Z</updated>
    <published>2015-11-23T22:49:08Z</published>
    <title>Planning in the Wild: Modeling Tools for PDDL</title>
    <summary>  Even though there are sophisticated AI planning algorithms, many integrated,
large-scale projects do not use planning. One reason seems to be the missing
support by engineering tools such as syntax highlighting and visualization. We
propose myPDDL - a modular toolbox for efficiently creating PDDL domains and
problems. To evaluate myPDDL, we compare it to existing knowledge engineering
tools for PDDL and experimentally assess its usefulness for novice PDDL users.
</summary>
    <author>
      <name>Volker Strobel</name>
    </author>
    <author>
      <name>Alexandra Kirsch</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-319-11206-0_27</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-319-11206-0_27" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Strobel, Volker, and Alexandra Kirsch. "Planning in the Wild:
  Modeling Tools for PDDL." KI 2014: Advances in Artificial Intelligence.
  Springer International Publishing, 2014. 273-284</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1511.07500v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.07500v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1512.03199v1</id>
    <updated>2015-12-10T10:30:19Z</updated>
    <published>2015-12-10T10:30:19Z</published>
    <title>Graph-theoretic autofill</title>
    <summary>  Imagine a website that asks the user to fill in a web form and -- based on
the input values -- derives a relevant figure, for instance an expected salary,
a medical diagnosis or the market value of a house. How to deal with missing
input values at run-time? Besides using fixed defaults, a more sophisticated
approach is to use predefined dependencies (logical or correlational) between
different fields to autofill missing values in an iterative way. Directed
loopless graphs (in which cycles are allowed) are the ideal mathematical model
to formalize these dependencies. We present two new graph-theoretic approaches
to filling missing values at run-time.
</summary>
    <author>
      <name>Michael Mayer</name>
    </author>
    <author>
      <name>Dominic van der Zypen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1512.03199v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1512.03199v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="05C20" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.01497v1</id>
    <updated>2016-01-07T11:52:47Z</updated>
    <published>2016-01-07T11:52:47Z</published>
    <title>Family of 2-simplex cognitive tools and their application for
  decision-making and its justifications</title>
    <summary>  Urgency of application and development of cognitive graphic tools for usage
in intelligent systems of data analysis, decision making and its justifications
is given. Cognitive graphic tool "2-simplex prism" and examples of its usage
are presented. Specificity of program realization of cognitive graphics tools
invariant to problem areas is described. Most significant results are given and
discussed. Future investigations are connected with usage of new approach to
rendering, cross-platform realization, cognitive features improving and
expanding of n-simplex family.
</summary>
    <author>
      <name>Anna Yankovskaya</name>
    </author>
    <author>
      <name>Artem Yamshanov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 6 figures, conference</arxiv:comment>
    <link href="http://arxiv.org/abs/1601.01497v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.01497v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.01815v1</id>
    <updated>2016-01-08T10:13:55Z</updated>
    <published>2016-01-08T10:13:55Z</published>
    <title>Design and implementation of a user interface for a multi-device
  spatially-aware mobile system</title>
    <summary>  The aim of this thesis was the design and development of an interactive
system enhancing collaborative sensemaking. The system design was based on
related work research and preliminary user study. The system is based on
multiple spatially-aware mobile devices. The spatial awareness is established
with a motion tracking system. The information about position of tablets is
received by a server. The server communicates with the devices and manages the
content of each device. The implemented system supports managing the elements
of information across the devices basing on their relative spatial arrangement.
The evaluation of the system was done by a user study.
</summary>
    <author>
      <name>Przemysław Kucharski</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">PhD thesis, Lodz University of Technology, 2015</arxiv:comment>
    <link href="http://arxiv.org/abs/1601.01815v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.01815v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.04066v1</id>
    <updated>2016-01-15T01:04:23Z</updated>
    <published>2016-01-15T01:04:23Z</published>
    <title>Human Computer Symbiosis</title>
    <summary>  Human Computer Symbiosis is similar to Human Computer Interaction in the
sense that it is about how humans and computer interact with each other. For
this interaction to be made there needs to be a symbiotic relationship between
man and computer. Man can interact with computer in many ways, either just by
typing with the keyboard or surfing the web. The cyber-physical-socio space is
an important aspect to be looked into when referring to the interaction between
man and computer. This paper investigates various aspects related to human
computer symbiosis. Alongside the aspects related to the topic, this paper
would also look into the limitations of Human Computer Symbiosis and evaluate
some previously proposed solutions.
</summary>
    <author>
      <name>Eluyefa Olanrewaju Andrew</name>
    </author>
    <link href="http://arxiv.org/abs/1601.04066v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.04066v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.06359v1</id>
    <updated>2016-01-24T08:45:10Z</updated>
    <published>2016-01-24T08:45:10Z</published>
    <title>Usability Evaluation of Dwell-free Eye Typing Techniques</title>
    <summary>  Dwelling is an essential task to be performed to select keys from an
on-screen keyboard present in the eye typing interface. This selection task can
be performed by fixing eye gaze on a key for a prolonged time. Spending
sufficient amount of time on each key effectively decreases the overall eye
typing rate. To address the problem, researchers proposed mechanisms, which
diminish the dwell time. We conducted a within-subject usability evaluation of
four dwell-free eye typing techniques. The results of first-time usability
study, longitudinal study and subjective evaluation conducted with 15
participants confirm the superiority of controlled eye movement based advanced
eye typing method (Adv-EyeK) than the other three techniques.
</summary>
    <author>
      <name>Sayan Sarcar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 Pages (with reference), accepted in IDHF 2014 conference held in
  Kochi, Japan</arxiv:comment>
    <link href="http://arxiv.org/abs/1601.06359v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.06359v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1602.08358v1</id>
    <updated>2016-02-26T15:02:07Z</updated>
    <published>2016-02-26T15:02:07Z</published>
    <title>Remote Heart Rate Sensing and Projection to Renew Traditional Board
  Games and Foster Social Interactions</title>
    <summary>  While physiological sensors enter the mass market and reach the general
public, they are still mainly employed to monitor health -- whether it is for
medical purpose or sports. We describe an application that uses heart rate
feedback as an incentive for social interactions. A traditional board game has
been "augmented" through remote physiological sensing, using webcams.
Projection helped to conceal the technological aspects from users. We detail
how players reacted -- stressful situations could emerge when users are
deprived from their own signals -- and we give directions for game designers to
integrate physiological sensors.
</summary>
    <author>
      <name>Jérémy Frey</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Potioc, LaBRI, UB</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/2851581.2892391</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/2851581.2892391" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">CHI '16 Extended Abstracts, May 2016, San Jose, United States.
  2016</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1602.08358v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1602.08358v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1602.08750v1</id>
    <updated>2016-02-28T18:31:31Z</updated>
    <published>2016-02-28T18:31:31Z</published>
    <title>Filtering Video Noise as Audio with Motion Detection to Form a Musical
  Instrument</title>
    <summary>  Even though they differ in the physical domain, digital video and audio share
many characteristics. Both are temporal data streams often stored in buffers
with 8-bit values. This paper investigates a method for creating harmonic
sounds with a video signal as input. A musical instrument is proposed, that
utilizes video in both a sound synthesis method, and in a controller interface
for selecting musical notes at specific velocities. The resulting instrument
was informally determined by the author to sound both pleasant and interesting,
but hard to control, and therefore suited for synth pad sounds.
</summary>
    <author>
      <name>Carl Thomé</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Received the 2015 best paper award in the KTH Royal Institute of
  Technology course "Musical Communication and Music Technology"</arxiv:comment>
    <link href="http://arxiv.org/abs/1602.08750v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1602.08750v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.01367v1</id>
    <updated>2016-03-04T07:40:58Z</updated>
    <published>2016-03-04T07:40:58Z</published>
    <title>Motivating Healthy Water Intake through Prompting, Historical
  Information, and Implicit Feedback</title>
    <summary>  We describe Hydroprompt, a prototype for sensing and motivating healthy water
intake in work environments. In a 3-week field deployment of Hydroprompt, we
evaluate the effectiveness of three approaches to behavior change: historical
information enabling users to compare their water intake lev- els across
different times of day and days of week, implicit feedback providing subtle
cues to users on the current hydration levels, and explicit prompting at-
tempting to remind participants when hydration falls below acceptable levels or
when substantial amount of time has elapsed since the last sip.
</summary>
    <author>
      <name>Davide Neves</name>
    </author>
    <author>
      <name>Donovan Costa</name>
    </author>
    <author>
      <name>Marcio Oliveira</name>
    </author>
    <author>
      <name>Ruben Jardim</name>
    </author>
    <author>
      <name>Ruben Gouveia</name>
    </author>
    <author>
      <name>Evangelos Karapanos</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Adjunct Proceedings of Persuasive Technology 2016, Salzburg,
  Austria</arxiv:comment>
    <link href="http://arxiv.org/abs/1603.01367v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.01367v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.01369v1</id>
    <updated>2016-03-04T07:45:13Z</updated>
    <published>2016-03-04T07:45:13Z</published>
    <title>Designing for Different Stages in Behavior Change</title>
    <summary>  The behavior change process is a dynamic journey with different informational
and motivational needs across its different stages; yet current technologies
for behavior change are static. In our recent deployment of Habito, an activity
tracking mobile app, we found individuals "readiness" to behavior change (or
the stage of behavior change they were in) to be a strong predictor of
adoption. Individuals in the contemplation and preparation stages had an
adoption rate of 56%, whereas individuals in precontemplation, action or
maintenance stages had an adoption rate of only 20%. In this position paper we
argue for behavior change technologies that are tailored to the different
stages of behavior change.
</summary>
    <author>
      <name>Evangelos Karapanos</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings of the workshop "Personalization in Persuasive
  Technology", Persuasive Technology 2016, Salzburg, Austria</arxiv:comment>
    <link href="http://arxiv.org/abs/1603.01369v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.01369v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.04581v1</id>
    <updated>2016-03-15T07:36:10Z</updated>
    <published>2016-03-15T07:36:10Z</published>
    <title>Introspectibles: Tangible Interaction to Foster Introspection</title>
    <summary>  Digital devices are now ubiquitous and have the potential to be used to
support positive changes in human lives and promote psychological well-being.
This paper presents three interactive systems that we created focusing on
introspection activities, leveraging tangible interaction and spatial augmented
reality. More specifically, we describe anthropomorphic augmented avatars that
display the users' inner states using physiological sensors. We also present a
first prototype of an augmented sandbox specifically dedicated to promoting
mindfulness activities.
</summary>
    <author>
      <name>Renaud Gervais</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Potioc</arxiv:affiliation>
    </author>
    <author>
      <name>Joan Sol Roo</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Potioc</arxiv:affiliation>
    </author>
    <author>
      <name>Jérémy Frey</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">UB, Potioc</arxiv:affiliation>
    </author>
    <author>
      <name>Martin Hachet</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Potioc</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">in CHI '16 - SIGCHI Conference on Human Factors in Computing System -
  Computing and Mental Health Workshop, May 2016, San Jose, United States</arxiv:comment>
    <link href="http://arxiv.org/abs/1603.04581v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.04581v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.09533v1</id>
    <updated>2016-03-31T11:36:19Z</updated>
    <published>2016-03-31T11:36:19Z</published>
    <title>VapeTracker: Tracking Vapor Consumption to Help E-cigarette Users Quit</title>
    <summary>  Despite current controversy over e-cigarettes as a smoking cessation aid, we
present early work based on a web survey (N=249) that shows that some
e-cigarette users (46.2%) want to quit altogether, and that behavioral feedback
that can be tracked can fulfill that purpose. Based on our survey findings, we
designed VapeTracker, an early prototype that can attach to any e-cigarette
device to track vaping activity. We discuss our future research on vaping
cessation, addressing how to improve our VapeTracker prototype, ambient
feedback mechanisms, and the future inclusion of behavior change models to
support quitting e-cigarettes.
</summary>
    <author>
      <name>Abdallah El Ali</name>
    </author>
    <author>
      <name>Andrii Matviienko</name>
    </author>
    <author>
      <name>Yannick Feld</name>
    </author>
    <author>
      <name>Wilko Heuten</name>
    </author>
    <author>
      <name>Susanne Boll</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at CHI 2016 EA</arxiv:comment>
    <link href="http://arxiv.org/abs/1603.09533v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.09533v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.M" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.04389v1</id>
    <updated>2016-04-15T07:42:39Z</updated>
    <published>2016-04-15T07:42:39Z</published>
    <title>Composing applications with OntoCompo</title>
    <summary>  In this paper, we present an ontology-based approach to compose applications
while preserving their former look. Our composition process relies on the
manipulation of User Interfaces (UI) and on several ontologies describing
relationships between tasks, UI and Functionalities. Our tool, called
OntoCompo, supports compositions realized by the developer thanks to the
selection, extraction and positioning of UI elements to constitute the
newapplication.
</summary>
    <author>
      <name>Christian Brel</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">I3S, SPARKS</arxiv:affiliation>
    </author>
    <author>
      <name>Philippe Renevier-Gonin</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">SPARKS, I3S</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/2044354.2044384</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/2044354.2044384" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">d\'emonstration \`a la conf\'erence IHM 2011</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IHM 2011, 23\`eme Conf\'erence Francophone Sur l'Interaction Homme
  Machine, Oct 2011, Biot, France. ACM, pp.141-144, 2011, IHM '11 Proceedings
  of the 23rd Conference on l'Interaction Homme-Machine</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1604.04389v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.04389v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.05797v1</id>
    <updated>2016-04-20T02:54:21Z</updated>
    <published>2016-04-20T02:54:21Z</published>
    <title>Towards the Holodeck: Fully Immersive Virtual Reality Visualisation of
  Scientific and Engineering Data</title>
    <summary>  In this paper, we describe the development and operating principles of an
immersive virtual reality (VR) visualisation environment that is designed
around the use of consumer VR headsets in an existing wide area motion capture
suite. We present two case studies in the application areas of visualisation of
scientific and engineering data. Each of these case studies utilise a different
render engine, namely a custom engine for one case and a commercial game engine
for the other. The advantages and appropriateness of each approach are
discussed along with suggestions for future work.
</summary>
    <author>
      <name>Stefan Marks</name>
    </author>
    <author>
      <name>Javier E. Estevez</name>
    </author>
    <author>
      <name>Andy M. Connor</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/2683405.2683424</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/2683405.2683424" rel="related"/>
    <link href="http://arxiv.org/abs/1604.05797v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.05797v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.06158v1</id>
    <updated>2016-04-21T02:02:13Z</updated>
    <published>2016-04-21T02:02:13Z</published>
    <title>Augmented Body: Changing Interactive Body Play</title>
    <summary>  This paper investigates the player's body as a system capable of unfamiliar
interactive movement achieved through digital mediation in a playful
environment. Body interactions in both digital and non-digital environments can
be considered as a perceptually manipulative exploration of self. This implies
a player may alter how they perceive their body and its operations in order to
create a new playful and original experience. This paper therefore questions
how player interaction can change as their perception of their body changes
using augmentative technology.
</summary>
    <author>
      <name>Matthew Martin</name>
    </author>
    <author>
      <name>James Charlton</name>
    </author>
    <author>
      <name>Andy M. Connor</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/2677758.2677790</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/2677758.2677790" rel="related"/>
    <link href="http://arxiv.org/abs/1604.06158v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.06158v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.06159v1</id>
    <updated>2016-04-21T02:07:27Z</updated>
    <published>2016-04-21T02:07:27Z</published>
    <title>Social Play Spaces for Active Community Engagement</title>
    <summary>  This paper puts forward the perspective that social play spaces are
opportunities to utilise both technology and body for the benefit of community
culture and engagement. Co-located social gaming coupled with tangible
interfaces offer active participant engagement and the development of the local
video game scene. This paper includes a descriptive account of Rabble Room
Arcade, an experimental social event combining custom-built physical interface
devices and multiplayer video games.
</summary>
    <author>
      <name>Jenna Gavin</name>
    </author>
    <author>
      <name>Ben Kenobi</name>
    </author>
    <author>
      <name>Andy M. Connor</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/2677758.2677789</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/2677758.2677789" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: substantial text overlap with arXiv:1604.05793</arxiv:comment>
    <link href="http://arxiv.org/abs/1604.06159v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.06159v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.08284v1</id>
    <updated>2016-04-28T01:57:11Z</updated>
    <published>2016-04-28T01:57:11Z</published>
    <title>Talk&amp;Learn: Improving Conversation Experience and Creating Opportunities
  for Foreign Language Learning</title>
    <summary>  Existing Real-Time Translation Interfaces (RTTI) do not provide experience as
natural and efficient as monolingual communication. Also, such systems do not
provide functions supporting language learning. This results in the waste of
both time and potential language context. In order to overcome the above
limitations, we propose a solution named "Talk&amp;Learn". Its core idea is to
rearrange ("Delay-Match") the real-time videos and translated texts or
speeches, so as to gain better naturalness and efficiency. At the same time,
this will create extra free time for users. So we further propose to utilize
the free time for contextual language learning.
</summary>
    <author>
      <name>Yaohua Xie</name>
    </author>
    <link href="http://arxiv.org/abs/1604.08284v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.08284v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.07733v1</id>
    <updated>2016-05-25T04:57:42Z</updated>
    <published>2016-05-25T04:57:42Z</published>
    <title>On model architecture for a children's speech recognition interactive
  dialog system</title>
    <summary>  This report presents a general model of the architecture of information
systems for the speech recognition of children. It presents a model of the
speech data stream and how it works. The result of these studies and presented
veins architectural model shows that research needs to be focused on
acoustic-phonetic modeling in order to improve the quality of children's speech
recognition and the sustainability of the systems to noise and changes in
transmission environment. Another important aspect is the development of more
accurate algorithms for modeling of spontaneous child speech.
</summary>
    <author>
      <name>Radoslava Kraleva</name>
    </author>
    <author>
      <name>Velin Kralev</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 2 figures, in proc. of conference FMNS 2009, Blagoevgrad,
  Bulgaria</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Third International Scientific Conference "Mathematics and Natural
  Sciences", Vol. (1), pp. 106-111, 2009</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1605.07733v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.07733v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.07760v1</id>
    <updated>2016-05-25T07:26:02Z</updated>
    <published>2016-05-25T07:26:02Z</published>
    <title>Challenges in Mobile Multi-Device Ecosystems</title>
    <summary>  Coordinated multi-display environments from the desktop, second-screen to
gigapixel display walls are increasingly common. Personal and intimate mobile
and wearable devices such as head-mounted displays, smartwatches, smartphones
and tablets are rarely part of such multi-device ecosystems. With this paper,
we contribute to a better understanding about factors that impede the creation
and use of such mobile multi-device ecosystems. We base our findings on
literature research and an expert survey. Specifically, we present grounded
challenges relevant for the design, development and use of mobile multi-device
environments.
</summary>
    <author>
      <name>Jens Grubert</name>
    </author>
    <author>
      <name>Matthias Kranz</name>
    </author>
    <author>
      <name>Aaron Quigley</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1186/s13678-016-0007-y</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1186/s13678-016-0007-y" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">mUX: The Journal of Mobile User Experience, 5(1), 1-22, 2016</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1605.07760v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.07760v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.08035v1</id>
    <updated>2016-05-25T12:01:46Z</updated>
    <published>2016-05-25T12:01:46Z</published>
    <title>Notes on Pervasive Virtuality</title>
    <summary>  This paper summarizes current notes about a new mixed-reality paradigm that
we named as "pervasive virtuality". This paradigm has emerged recently in
industry and academia through different initiatives. In this paper we intend to
explore this new area by proposing a set of features that we identified as
important or helpful to realize pervasive virtuality in games and entertainment
applications.
</summary>
    <author>
      <name>Luis Valente</name>
    </author>
    <author>
      <name>Bruno Feijo</name>
    </author>
    <author>
      <name>Alexandre Ribeiro Silva</name>
    </author>
    <author>
      <name>Esteban Clua</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Tech report MCC01/16 (Monografias em Ci\^encia da Computa\c{c}\~ao,
  May 2016, PUC-Rio, ISSN 0103-9741), discussion paper in progress to IFIP ICEC
  2016</arxiv:comment>
    <link href="http://arxiv.org/abs/1605.08035v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.08035v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.02711v1</id>
    <updated>2016-06-08T14:21:53Z</updated>
    <published>2016-06-08T14:21:53Z</published>
    <title>ChinMotion Rapidly Enables 3D Computer Interaction after Tetraplegia</title>
    <summary>  Individuals with severe paralysis require hands-free interfaces to control
assistive devices that can improve their quality of life. We present
ChinMotion, an interface that noninvasively harnesses preserved chin, lip and
tongue sensorimotor function after tetraplegia to convey intuitive control
commands. After two hours of practice, ChinMotion enables superior
point-and-click performance over existing interfaces and it facilitates
accurate 3D control of a virtual robotic arm.
</summary>
    <author>
      <name>Ferran Galán</name>
    </author>
    <author>
      <name>Stuart N. Baker</name>
    </author>
    <author>
      <name>Monica A. Perez</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The .ps file contains main manuscript and supplementary information.
  The .ps file is accompanied with ancillary files (supplementary files)</arxiv:comment>
    <link href="http://arxiv.org/abs/1606.02711v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.02711v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.07487v2</id>
    <updated>2016-07-03T20:04:55Z</updated>
    <published>2016-06-23T21:36:36Z</published>
    <title>The VGLC: The Video Game Level Corpus</title>
    <summary>  Levels are a key component of many different video games, and a large body of
work has been produced on how to procedurally generate game levels. Recently,
Machine Learning techniques have been applied to video game level generation
towards the purpose of automatically generating levels that have the properties
of the training corpus. Towards that end we have made available a corpora of
video game levels in an easy to parse format ideal for different machine
learning and other game AI research purposes.
</summary>
    <author>
      <name>Adam James Summerville</name>
    </author>
    <author>
      <name>Sam Snodgrass</name>
    </author>
    <author>
      <name>Michael Mateas</name>
    </author>
    <author>
      <name>Santiago Ontañón</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in proceedings of the 7th Workshop on Procedural Content
  Generation</arxiv:comment>
    <link href="http://arxiv.org/abs/1606.07487v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.07487v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.08065v1</id>
    <updated>2016-06-26T18:40:57Z</updated>
    <published>2016-06-26T18:40:57Z</published>
    <title>Face Card: An Information-sharing Framework on Google Glass</title>
    <summary>  Wearable devices such as Google Glass can provide an efficient way to get
around users information. We present Face Card, a system builds on Google Glass
to provide information-sharing service with around people. With a look at
Google Glass, users can quickly get information of nearby and coming users.
Utilizing Bluetooth Low Energy (BLE) and proper user interface, Face Card
demonstrates the potential of being an efficient information sharing system
framework.
</summary>
    <author>
      <name>Weiren Wang</name>
    </author>
    <author>
      <name>Miseon Park</name>
    </author>
    <author>
      <name>Yuanzhe Fan</name>
    </author>
    <author>
      <name>Thad Starner</name>
    </author>
    <author>
      <name>Gregory D. Abowd</name>
    </author>
    <link href="http://arxiv.org/abs/1606.08065v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.08065v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.01752v1</id>
    <updated>2016-07-06T19:26:20Z</updated>
    <published>2016-07-06T19:26:20Z</published>
    <title>CrowdCafe - Mobile Crowdsourcing Platform</title>
    <summary>  In this paper we present a mobile crowdsourcing platform CrowdCafe, where
people can perform microtasks using their smartphones while they ride a bus,
travel by train, stand in a queue or wait for an appointment. These microtasks
are executed in exchange for rewards provided by local stores, such as coffee,
desserts and bus tickets. We present the concept, the implementation and the
evaluation by conducting a study with 52 participants, having 1108 tasks
completed.
</summary>
    <author>
      <name>Pavel Kucherbaev</name>
    </author>
    <author>
      <name>Azad Abad</name>
    </author>
    <author>
      <name>Stefano Tranquillini</name>
    </author>
    <author>
      <name>Florian Daniel</name>
    </author>
    <author>
      <name>Maurizio Marchese</name>
    </author>
    <author>
      <name>Fabio Casati</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Was published before as a part of the phd thesis by Pavel Kucherbaev
  http://eprints-phd.biblio.unitn.it/1716/</arxiv:comment>
    <link href="http://arxiv.org/abs/1607.01752v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.01752v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.00945v2</id>
    <updated>2016-10-27T01:03:25Z</updated>
    <published>2016-09-04T15:20:44Z</published>
    <title>MmmTurkey: A Crowdsourcing Framework for Deploying Tasks and Recording
  Worker Behavior on Amazon Mechanical Turk</title>
    <summary>  Internal HITs on Mechanical Turk can be programmatically restrictive, and as
a result, many requesters turn to using external HITs as a more flexible
alternative. However, creating such HITs can be redundant and time-consuming.
We present MmmTurkey, a framework that enables researchers to not only quickly
create and manage external HITs, but more significantly also capture and record
detailed worker behavioral data characterizing how each worker completes a
given task.
</summary>
    <author>
      <name>Brandon Dang</name>
    </author>
    <author>
      <name>Miles Hutson</name>
    </author>
    <author>
      <name>Matt Lease</name>
    </author>
    <link href="http://arxiv.org/abs/1609.00945v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.00945v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.01070v1</id>
    <updated>2016-09-05T09:17:38Z</updated>
    <published>2016-09-05T09:17:38Z</published>
    <title>Toward Crowdsourced User Studies for Software Evaluation</title>
    <summary>  This work-in-progress paper describes a vision, i.e., that of fast and
reliable software user experience studies conducted with the help from the
crowd. Commonly, user studies are controlled in-lab activities that require the
instruction, monitoring, interviewing and compensation of a number of
participants that are typically hard to recruit. The goal of this work is to
study which user study methods can instead be crowdsourced to generic audiences
to enable the conduct of user studies without the need for expensive lab
experiments. The challenge is understanding how to conduct crowdsourced studies
without giving up too many of the guarantees in-lab settings are able to
provide.
</summary>
    <author>
      <name>Florian Daniel</name>
    </author>
    <author>
      <name>Pavel Kucherbaev</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Works-in-Progress paper of HCOMP 2016, Austin, Texas</arxiv:comment>
    <link href="http://arxiv.org/abs/1609.01070v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.01070v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.01348v1</id>
    <updated>2016-09-05T22:52:02Z</updated>
    <published>2016-09-05T22:52:02Z</published>
    <title>Incentive Engineering Framework for Crowdsourcing Systems</title>
    <summary>  Significant effort has been made to understand user motivation and to elicit
user participation in crowdsourcing systems. However, incentive engineering,
i.e., designing incentives that can purposefully motivate users, is still an
open question and remains one of the key challenges of crowdsourcing
initiatives. In this work in progress, we propose a general and systematic
incentive engineering framework that system designers can use to implement
appropriate incentives in order to effect desirable user behaviours.
</summary>
    <author>
      <name>Nhat V. Q. Truong</name>
    </author>
    <author>
      <name>Sebastian Stein</name>
    </author>
    <author>
      <name>Long Tran-Thanh</name>
    </author>
    <author>
      <name>Nicholas R. Jennings</name>
    </author>
    <link href="http://arxiv.org/abs/1609.01348v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.01348v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.01614v1</id>
    <updated>2016-09-06T15:42:56Z</updated>
    <published>2016-09-06T15:42:56Z</published>
    <title>Modeling The Adaption Rule in Context-aware Systems</title>
    <summary>  Context awareness is increasingly gaining applicability in interactive
ubiquitous mobile computing systems. Each context-aware application has its own
set of behaviors to react to context modifications. This paper is concerned
with the context modeling and the development methodology for context-aware
systems. We proposed a rule-based approach and use the adaption tree to model
the adaption rule of context-aware systems. We illustrate this idea in an
arithmetic game application.
</summary>
    <author>
      <name>Mao Zheng</name>
    </author>
    <author>
      <name>Qian Xu</name>
    </author>
    <author>
      <name>Hao Fan</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5121/ijasuc.2016.7401</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5121/ijasuc.2016.7401" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 4 tables, 7 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Ad hoc, Sensor &amp; Ubiquitous Computing,
  Vol.7, No.3/4, August 2016, ISSN : 0976 - 1764 (Online); 0976 - 2205 (Print),</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1609.01614v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.01614v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.ET" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.02182v1</id>
    <updated>2016-09-07T20:41:57Z</updated>
    <published>2016-09-07T20:41:57Z</published>
    <title>Feedback and Timing in a Crowdsourcing Game</title>
    <summary>  The present research examines two problems inherent to the creation of
crowdsourcing games: how to give feedback when the right answer is not always
known by the game and how much time to give players without sacrificing data
quality. Taken together, the present research provides an important first step
in considering how to create fun, challenging crowdsourcing games that generate
quality data.
</summary>
    <author>
      <name>Gili Freedman</name>
    </author>
    <author>
      <name>Sukdith Punjasthitkul</name>
    </author>
    <author>
      <name>Max Seidman</name>
    </author>
    <author>
      <name>Mary Flanagan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented as Work in Progress Poster at Human Computation 2016</arxiv:comment>
    <link href="http://arxiv.org/abs/1609.02182v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.02182v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.03050v1</id>
    <updated>2016-09-10T13:22:14Z</updated>
    <published>2016-09-10T13:22:14Z</published>
    <title>Dropout Prediction in Crowdsourcing Markets</title>
    <summary>  Crowdsourcing environments have shown promise in solving diverse tasks in
limited cost and time. This type of business model involves both the expert and
non-expert workers. Interestingly, the success of such models depends on the
volume of the total number of workers. But, the survival of the fittest
controls the stability of these workers. Here, we show that the crowd workers
who fail to win jobs successively loose interest and might dropout over time.
Therefore, dropout prediction in such environments is a promising task. In this
paper, we establish that it is possible to predict the dropouts in a
crowdsourcing market from the success rate based on the arrival pattern of
workers.
</summary>
    <author>
      <name>Malay Bhattacharyya</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Works in Progress, Third AAAI Conference on Human Computation and
  Crowdsourcing (HCOMP 2015), San Diego, USA</arxiv:comment>
    <link href="http://arxiv.org/abs/1609.03050v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.03050v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68Txx" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.1.2; I.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.04657v1</id>
    <updated>2016-09-15T14:06:57Z</updated>
    <published>2016-09-15T14:06:57Z</published>
    <title>Results of a Collective Awareness Platforms Investigation</title>
    <summary>  In this paper we provide two introductory analyses of CAPs, based exclusively
on the analysis of documents found on the Internet. The first analysis allowed
us to investigate the world of CAPs, in particular for what concerned their
status (dead or alive), the scope of those platforms and the typology of users.
In order to develop a more accurate model of CAPs, and to understand more
deeply the motivation of the users and the type of expected payoff, we analysed
those CAPs from the above list that are still alive and we used two models
developed for what concerned the virtual community and the collective
intelligence.
</summary>
    <author>
      <name>Giovanna Pacini</name>
    </author>
    <author>
      <name>Franco Bagnoli</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-319-45982-0_2</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-319-45982-0_2" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">INSCI 2016, LNCS 9934, pp. 19-26, 2016</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1609.04657v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.04657v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1610.02445v1</id>
    <updated>2016-10-07T23:29:23Z</updated>
    <published>2016-10-07T23:29:23Z</published>
    <title>Instagram Post Data Analysis</title>
    <summary>  Because of the spread of the Internet, social platforms become big data
pools. From there we can learn about the trends, culture and hot topics. This
project focuses on analyzing the data from Instagram. It shows the relationship
of Instagram filter data with location and number of likes to give users filter
suggestion on achieving more likes based on their location. It also analyzes
the popular hashtags in different locations to show visual culture differences
between different cities.
</summary>
    <author>
      <name>Steve Chang</name>
    </author>
    <link href="http://arxiv.org/abs/1610.02445v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1610.02445v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1610.02857v1</id>
    <updated>2016-10-10T11:44:30Z</updated>
    <published>2016-10-10T11:44:30Z</published>
    <title>Accounting for Availability Biases in Information Visualization</title>
    <summary>  The availability heuristic is a strategy that people use to make quick
decisions but often lead to systematic errors. We propose three ways that
visualization could facilitate unbiased decision-making. First, visualizations
can alter the way our memory stores the events for later recall, so as to
improve users' long-term intuitions. Second, the known biases could lead to new
visualization guidelines. Third, we suggest the design of decision-making tools
that are inspired by heuristics, e.g. suggesting intuitive approximations,
rather than target to present exhaustive comparisons of all possible outcomes,
or automated solutions for choosing decisions.
</summary>
    <author>
      <name>Evanthia Dimara</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">AVIZ</arxiv:affiliation>
    </author>
    <author>
      <name>Pierre Dragicevic</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">AVIZ</arxiv:affiliation>
    </author>
    <author>
      <name>Anastasia Bezerianos</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LRI, ILDA</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE VIS 2014, 2014, Paris, France. 2014</arxiv:comment>
    <link href="http://arxiv.org/abs/1610.02857v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1610.02857v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1610.03704v1</id>
    <updated>2016-10-12T13:28:14Z</updated>
    <published>2016-10-12T13:28:14Z</published>
    <title>A low-cost indoor and outdoor terrestrial autonomous navigation model</title>
    <summary>  In this paper, a method for low-cost system design oriented to indoor and
outdoor autonomous navigation is illustrated. In order to provide a motivation
for the solution here presented, a brief discussion of the typical drawbacks of
state-of-the-art technologies is reported. Finally, an application of such a
method for the design of a navigation system for blindfolded people is shown.
</summary>
    <author>
      <name>Gianluca Susi</name>
    </author>
    <author>
      <name>Alessandro Cristini</name>
    </author>
    <author>
      <name>Mario Salerno</name>
    </author>
    <author>
      <name>Emiliano Daddario</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TELFOR.2014.7034499</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TELFOR.2014.7034499" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 3 figures, 2 tables. Presented at IEEE TELFOR 22nd
  Telecommunications Forum, Belgrade, Serbia, 2014</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE TELFOR 22nd Telecommunications Forum, Belgrade, Serbia, 2014</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1610.03704v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1610.03704v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="K.4.2; D.2.10; C.5.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1610.04758v1</id>
    <updated>2016-10-15T16:28:17Z</updated>
    <published>2016-10-15T16:28:17Z</published>
    <title>Sensing Emotions in Text Messages: An Application and Deployment Study
  of EmotionPush</title>
    <summary>  Instant messaging and push notifications play important roles in modern
digital life. To enable robust sense-making and rich context awareness in
computer mediated communications, we introduce EmotionPush, a system that
automatically conveys the emotion of received text with a colored push
notification on mobile devices. EmotionPush is powered by state-of-the-art
emotion classifiers and is deployed for Facebook Messenger clients on Android.
The study showed that the system is able to help users prioritize interactions.
</summary>
    <author>
      <name>Shih-Ming Wang</name>
    </author>
    <author>
      <name>Chun-Hui Li</name>
    </author>
    <author>
      <name>Yu-Chun Lo</name>
    </author>
    <author>
      <name>Ting-Hao K. Huang</name>
    </author>
    <author>
      <name>Lun-Wei Ku</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages. COLING 2016 Demo paper</arxiv:comment>
    <link href="http://arxiv.org/abs/1610.04758v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1610.04758v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.2; H.5.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1610.09743v1</id>
    <updated>2016-10-31T00:19:00Z</updated>
    <published>2016-10-31T00:19:00Z</published>
    <title>An Exploration of Graphical Password Authentication for Children</title>
    <summary>  In this paper, we explore graphical passwords as a child-friendly alternative
for user authentication. We evaluate the usability of three variants of the
PassTiles graphical password scheme for children, and explore the similarities
and differences in performance and preferences between children and adults
while using these schemes. Children were most successful at recalling passwords
containing images of distinct objects. Both children and adults prefer
graphical passwords to their existing schemes, but password memorization
strategies differ considerably between the two groups. Based on our findings,
we provide recommendations for designing more child-friendly authentication
schemes.
</summary>
    <author>
      <name>Hala Assal</name>
    </author>
    <author>
      <name>Ahsan Imran</name>
    </author>
    <author>
      <name>Sonia Chiasson</name>
    </author>
    <link href="http://arxiv.org/abs/1610.09743v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1610.09743v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="K.6.5; H.5.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.07714v1</id>
    <updated>2016-12-22T17:28:38Z</updated>
    <published>2016-12-22T17:28:38Z</published>
    <title>Understanding Tree: a tool to estimate one's understanding of knowledge</title>
    <summary>  People learn whenever and wherever possible, and whatever they like or
encounter--Mathematics, Drama, Art, Languages, Physics, Philosophy, and so on.
With the bursting of knowledge, evaluation of one's possession of knowledge
becomes increasingly difficult. There are a lot of demands to evaluate one's
understanding of a piece of knowledge. Assessment of understanding of knowledge
is conventionally through tests or interviews, but they have some limitations
such as low-efficiency and not-comprehensive. This paper proposes a method
called Understanding Tree to estimate one's understanding of knowledge, by
keeping track of his/her learning activities. It overcomes some limitations of
traditional methods, hence complements traditional methods.
</summary>
    <author>
      <name>Gangli Liu</name>
    </author>
    <link href="http://arxiv.org/abs/1612.07714v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.07714v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.M" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.09352v2</id>
    <updated>2017-09-20T15:35:43Z</updated>
    <published>2016-12-30T00:05:03Z</published>
    <title>Synthesis of Tongue Motion and Acoustics from Text using a Multimodal
  Articulatory Database</title>
    <summary>  We present an end-to-end text-to-speech (TTS) synthesis system that generates
audio and synchronized tongue motion directly from text. This is achieved by
adapting a 3D model of the tongue surface to an articulatory dataset and
training a statistical parametric speech synthesis system directly on the
tongue model parameters. We evaluate the model at every step by comparing the
spatial coordinates of predicted articulatory movements against the reference
data. The results indicate a global mean Euclidean distance of less than 2.8
mm, and our approach can be adapted to add an articulatory modality to
conventional TTS applications without the need for extra data.
</summary>
    <author>
      <name>Ingmar Steiner</name>
    </author>
    <author>
      <name>Sébastien Le Maguer</name>
    </author>
    <author>
      <name>Alexander Hewer</name>
    </author>
    <link href="http://arxiv.org/abs/1612.09352v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.09352v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.00487v1</id>
    <updated>2017-01-02T12:16:11Z</updated>
    <published>2017-01-02T12:16:11Z</published>
    <title>The leveled approach. Using and evaluating text mining tools
  AVResearcherXL and Texcavator for historical research on public perceptions
  of drugs</title>
    <summary>  We introduce our explorative historical leveled approach that we use to
understand drug debates in the Royal Dutch Library's digital newspaper archive.
In this approach we alternate between distant reading and close reading.
Furthermore, we use this approach to evaluate two text mining tools:
AVResearcherXL and Texcavator.
</summary>
    <author>
      <name>Berrie van der Molen</name>
    </author>
    <author>
      <name>Lars Buitinck</name>
    </author>
    <author>
      <name>Toine Pieters</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3 pages, extended abstract of a lightning talk delivered at the 2nd
  IFIP International Workshop on Computational History and Data-driven
  Humanities on 25 May 2016 (Trinity College Dublin, Ireland)</arxiv:comment>
    <link href="http://arxiv.org/abs/1701.00487v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.00487v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.06270v2</id>
    <updated>2017-01-24T19:24:11Z</updated>
    <published>2017-01-23T05:45:55Z</published>
    <title>Plexus: An Interactive Visualization Tool for Analyzing Public Emotions
  from Twitter Data</title>
    <summary>  Social media is often used by researchers as an approach to obtaining
real-time data on people's activities and thoughts. Twitter, as one of the most
popular social networking services nowadays, provides copious information
streams on various topics and events. Mining and analyzing Tweets enable us to
find public reactions and emotions to activities or objects. This paper
presents an interactive visualization tool that identifies and visualizes
people's emotions on any two related topics by streaming and processing data
from Twitter. The effectiveness of this visualization was evaluated and
demonstrated by a feasibility study with 14 participants.
</summary>
    <author>
      <name>Xiaodong Wu</name>
    </author>
    <author>
      <name>Lyn Bartram</name>
    </author>
    <author>
      <name>Chris Shaw</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 Pages, Conference ready</arxiv:comment>
    <link href="http://arxiv.org/abs/1701.06270v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.06270v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.08879v1</id>
    <updated>2017-01-31T00:24:10Z</updated>
    <published>2017-01-31T00:24:10Z</published>
    <title>Robotic Haptic Proxies for Collaborative Virtual Reality</title>
    <summary>  We propose a new approach for interaction in Virtual Reality (VR) using
mobile robots as proxies for haptic feedback. This approach allows VR users to
have the experience of sharing and manipulating tangible physical objects with
remote collaborators. Because participants do not directly observe the robotic
proxies, the mapping between them and the virtual objects is not required to be
direct. In this paper, we describe our implementation, various scenarios for
interaction, and a preliminary user study.
</summary>
    <author>
      <name>Zhenyi He</name>
    </author>
    <author>
      <name>Fengyuan Zhu</name>
    </author>
    <author>
      <name>Aaron Gaudette</name>
    </author>
    <author>
      <name>Ken Perlin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 page, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1701.08879v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.08879v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1702.02178v1</id>
    <updated>2017-02-07T19:42:17Z</updated>
    <published>2017-02-07T19:42:17Z</published>
    <title>Refining StreamBED Through Expert Interviews, Design Feedback, and a Low
  Fidelity Prototype</title>
    <summary>  StreamBED is an embodied VR training for citizen scientists to make
qualitative stream assessments. Early findings garnered positive feedback about
training qualitative assessment using a virtual representation of different
stream spaces, but presented field-specific challenges; novice biologists had
trouble interpreting qualitative protocols, and needed substantive guidance to
look for and interpret environment cues. In order to address these issues in
the redesign, this work uses research through design (RTD) methods to consider
feedback from expert stream biologists, firsthand stream monitoring experience,
discussions with education and game designers, and feedback from a low fidelity
prototype. The qualitative findings found that training should facilitate
personal narratives, maximize realism, and should use social dynamics to
scaffold learning.
</summary>
    <author>
      <name>Alina Striner</name>
    </author>
    <author>
      <name>Jennifer Preece</name>
    </author>
    <link href="http://arxiv.org/abs/1702.02178v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1702.02178v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1702.06236v1</id>
    <updated>2017-02-21T01:45:07Z</updated>
    <published>2017-02-21T01:45:07Z</published>
    <title>Transitioning Between Audience and Performer: Co-Designing Interactive
  Music Performances with Children</title>
    <summary>  Live interactions have the potential to meaningfully engage audiences during
musical performances, and modern technologies promise unique ways to facilitate
these interactions. This work presents findings from three co-design sessions
with children that investigated how audiences might want to interact with live
music performances, including design considerations and opportunities. Findings
from these sessions also formed a Spectrum of Audience Interactivity in live
musical performances, outlining ways to encourage interactivity in music
performances from the child perspective.
</summary>
    <author>
      <name>Alina Striner</name>
    </author>
    <author>
      <name>Brenna McNally</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3027063.3053171</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3027063.3053171" rel="related"/>
    <link href="http://arxiv.org/abs/1702.06236v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1702.06236v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1702.07099v2</id>
    <updated>2017-02-24T18:52:52Z</updated>
    <published>2017-02-23T05:22:16Z</published>
    <title>Carina: Interactive Million-Node Graph Visualization using Web Browser
  Technologies</title>
    <summary>  We are working on a scalable, interactive visualization system, called
Carina, for people to explore million-node graphs. By using latest web browser
technologies, Carina offers fast graph rendering via WebGL, and works across
desktop (via Electron) and mobile platforms. Different from most existing graph
visualization tools, Carina does not store the full graph in RAM, enabling it
to work with graphs with up to 69M edges. We are working to improve and
open-source Carina, to offer researchers and practitioners a new, scalable way
to explore and visualize large graph datasets.
</summary>
    <author>
      <name>Dezhi Fang</name>
    </author>
    <author>
      <name>Matthew Keezer</name>
    </author>
    <author>
      <name>Jacob Williams</name>
    </author>
    <author>
      <name>Kshitij Kulkarni</name>
    </author>
    <author>
      <name>Robert Pienta</name>
    </author>
    <author>
      <name>Duen Horng Chau</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3041021.3054234</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3041021.3054234" rel="related"/>
    <link href="http://arxiv.org/abs/1702.07099v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1702.07099v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1702.07480v1</id>
    <updated>2017-02-24T07:22:37Z</updated>
    <published>2017-02-24T07:22:37Z</published>
    <title>Automation in Human-Machine Networks: How Increasing Machine Agency
  Affects Human Agency</title>
    <summary>  Efficient human-machine networks require productive interaction between human
and machine actors. In this study, we address how a strengthening of machine
agency, for example through increasing levels of automation, affect the human
actors of the networks. Findings from case studies within air traffic
management, crisis management, and crowd evacuation are presented, exemplifying
how automation may strengthen the agency of human actors in the network through
responsibility sharing and task allocation, and serve as a needed prerequisite
of innovation and change.
</summary>
    <author>
      <name>Asbjørn Følstad</name>
    </author>
    <author>
      <name>Vegard Engen</name>
    </author>
    <author>
      <name>Ida Maria Haugstveit</name>
    </author>
    <author>
      <name>Brian Pickering</name>
    </author>
    <link href="http://arxiv.org/abs/1702.07480v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1702.07480v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.00549v1</id>
    <updated>2017-03-01T23:41:57Z</updated>
    <published>2017-03-01T23:41:57Z</published>
    <title>Statistical Verification of Computational Rapport Model</title>
    <summary>  Rapport plays an important role during communication because it can help
people understand each other's feelings or ideas and leads to a smooth
communication. Computational rapport model has been proposed based on theory in
previous work. But there lacks solid verification. In this paper, we apply
structural equation model (SEM) to the theoretical model on both dyads of
friend and stranger. The results indicate some unfavorable paths. Based on the
results and more literature, we modify the original model to integrate more
nonverbal behaviors, including gaze and smile. Fit indices and other
examination show the goodness of our new models, which can give us more insight
into rapport management during conversation.
</summary>
    <author>
      <name>Xuhai Xu</name>
    </author>
    <author>
      <name>Justine Cassell</name>
    </author>
    <link href="http://arxiv.org/abs/1703.00549v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.00549v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.00818v1</id>
    <updated>2017-03-02T15:01:59Z</updated>
    <published>2017-03-02T15:01:59Z</published>
    <title>Evaluating Singleplayer and Multiplayer in Human Computation Games</title>
    <summary>  Human computation games (HCGs) can provide novel solutions to intractable
computational problems, help enable scientific breakthroughs, and provide
datasets for artificial intelligence. However, our knowledge about how to
design and deploy HCGs that appeal to players and solve problems effectively is
incomplete. We present an investigatory HCG based on Super Mario Bros. We used
this game in a human subjects study to investigate how different social
conditions---singleplayer and multiplayer---and scoring
mechanics---collaborative and competitive---affect players' subjective
experiences, accuracy at the task, and the completion rate. In doing so, we
demonstrate a novel design approach for HCGs, and discuss the benefits and
tradeoffs of these mechanics in HCG design.
</summary>
    <author>
      <name>Kristin Siu</name>
    </author>
    <author>
      <name>Matthew Guzdial</name>
    </author>
    <author>
      <name>Mark O. Riedl</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 4 figures, 2 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1703.00818v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.00818v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.01377v1</id>
    <updated>2017-03-04T01:46:52Z</updated>
    <published>2017-03-04T01:46:52Z</published>
    <title>Learning styles: Literature versus machine learning</title>
    <summary>  Every teacher understands that different students benefit from different
activities. Recent advances in data processing allow us to detect and use
behavioral variability for adapting to a student. This approach allows us to
optimize learning process but does not focus on understanding it. Conversely,
classical findings in educational sciences allow us to understand the learner
but are hard to embed in a large scale adaptive system. In this study we design
and build a framework to investigate when the two approaches coincide.
</summary>
    <author>
      <name>Farah Bouassida</name>
    </author>
    <author>
      <name>Łukasz Kidziński</name>
    </author>
    <author>
      <name>Pierre Dillenbourg</name>
    </author>
    <link href="http://arxiv.org/abs/1703.01377v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.01377v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.02968v1</id>
    <updated>2017-03-08T18:16:21Z</updated>
    <published>2017-03-08T18:16:21Z</published>
    <title>Sigil3D: A Crowdsourcing Platform for Interactive 3D Content</title>
    <summary>  In this paper we propose applying the crowdsourcing approach to a software
platform that uses a modern and state-of-the-art 3D game engine. This platform
could facilitate the generation and manipulation of interactive 3D environments
by a community of users producing different content such as cultural heritage,
scientific virtual labs, games, novel art forms and virtual museums.
</summary>
    <author>
      <name>Andrea Barillari</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Intranet Standard GmbH, Munich, Germany</arxiv:affiliation>
    </author>
    <author>
      <name>Daniele Bernardini</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Intranet Standard GmbH, Munich, Germany</arxiv:affiliation>
    </author>
    <author>
      <name>Pierluigi Crescenzi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Università di Firenze, Italy</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">translated from the paper published in the conference proceedings for
  GARR 2017</arxiv:comment>
    <link href="http://arxiv.org/abs/1703.02968v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.02968v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.09847v2</id>
    <updated>2017-04-18T03:50:19Z</updated>
    <published>2017-03-29T00:27:01Z</published>
    <title>Designing Privacy for You : A User Centric Approach For Privacy</title>
    <summary>  Privacy directly concerns the user as the data owner (data- subject) and
hence privacy in systems should be implemented in a manner which concerns the
user (user-centered). There are many concepts and guidelines that support
development of privacy and embedding privacy into systems. However, none of
them approaches privacy in a user- centered manner. Through this research we
propose a framework that would enable developers and designers to grasp privacy
in a user-centered manner and implement it along with the software development
life cycle.
</summary>
    <author>
      <name>Awanthika Senarath</name>
    </author>
    <author>
      <name>Nalin A. G. Arachchilage</name>
    </author>
    <author>
      <name>Jill Slay</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, HCI International 2017 Vancouver, Canada</arxiv:comment>
    <link href="http://arxiv.org/abs/1703.09847v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.09847v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.03507v1</id>
    <updated>2017-05-09T19:34:17Z</updated>
    <published>2017-05-09T19:34:17Z</published>
    <title>Analysis of Information Technologies Used to Insure Working Efficiency
  of Personnel</title>
    <summary>  The work is devoted to a modern state, methods and tools of monitoring,
assessment and prediction of the indicators showing physical condition of a
person and his/her capabilities to perform work duties. The work contains an
analysis of existing gadgets and software that allow tracking physical
condition of personnel at the working place. The analysis showing significant
interconnections and factors that determine a necessary level of working
capacity and productivity of personnel allows organizing Work &amp; Rest Schedule
of employees in an effective manner.
</summary>
    <author>
      <name>V. Ya. Vilisov</name>
    </author>
    <author>
      <name>D. A. Dyatlova</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 2 figures, conference</arxiv:comment>
    <link href="http://arxiv.org/abs/1705.03507v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.03507v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.07490v1</id>
    <updated>2017-05-21T19:08:09Z</updated>
    <published>2017-05-21T19:08:09Z</published>
    <title>MindDesktop: a general purpose brain computer interface</title>
    <summary>  Recent advances in electroencephalography (EEG) and electromyography (EMG)
enable communication for people with severe disabilities. In this paper we
present a system that enables the use of regular computers using an
off-the-shelf EEG/EMG headset, providing a pointing device and virtual keyboard
that can be used to operate any Windows based system, minimizing the user
effort required for interacting with a personal computer. Effectiveness of the
proposed system is evaluated by a usability study, indicating decreasing
learning curve for completing various tasks. The proposed system is available
in the link provided.
</summary>
    <author>
      <name>Ori Ossmy</name>
    </author>
    <author>
      <name>Ofir Tam</name>
    </author>
    <author>
      <name>Rami Puzis</name>
    </author>
    <author>
      <name>Lior Rokach</name>
    </author>
    <author>
      <name>Ohad Inbar</name>
    </author>
    <author>
      <name>Yuval Elovici</name>
    </author>
    <link href="http://arxiv.org/abs/1705.07490v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.07490v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.01248v1</id>
    <updated>2017-06-05T09:23:47Z</updated>
    <published>2017-06-05T09:23:47Z</published>
    <title>Aiding autobiographic memory by using wearable devices</title>
    <summary>  In this paper, we investigate the effectiveness of two distinct techniques
(Special Moment Approach &amp; Spatial Frequency Approach) for reviewing the
lifelogs, which were collected by lifeloggers who were willing to use a
wearable camera and a bracelet simultaneously for two days. Generally, Special
moment approach is a technique for extracting episodic events and Spatial
frequency approach is a technique for associating visual with temporal and
location information, especially heat map is applied as the spatial data for
expressing frequency awareness. Based on that, the participants were asked to
fill in two post-study questionnaires for evaluating the effectiveness of those
two techniques and their combination. The preliminary result showed the
positive potential of exploring individual lifelogs using our approaches.
</summary>
    <author>
      <name>Jingyi Wang</name>
    </author>
    <author>
      <name>Jiro Tanaka</name>
    </author>
    <link href="http://arxiv.org/abs/1706.01248v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.01248v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.01523v1</id>
    <updated>2017-06-05T20:05:10Z</updated>
    <published>2017-06-05T20:05:10Z</published>
    <title>Cognitive Depletion in the Wild: a Case Study of NMR Spectroscopy
  Analysis</title>
    <summary>  NMR spectroscopy analysis is a detail-oriented analytic feat that typically
requires specific domain expertise and hours of concentration. This work
presents an ethnographic-style study of this analysis process in the context of
evaluating the symptoms of cognitive depletion. The repeated, non-trivial
decisions required by and the time-consuming nature of NMR spectroscopy
analysis make it an ideal, real-world scenario to study the symptoms of
cognitive depletion, its effect on workflow and performance, and potential
strategies for mitigating its deleterious effects.
</summary>
    <author>
      <name>Lyndsey Franklin</name>
    </author>
    <author>
      <name>Nathan Hodas</name>
    </author>
    <link href="http://arxiv.org/abs/1706.01523v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.01523v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.01919v1</id>
    <updated>2017-06-06T18:31:30Z</updated>
    <published>2017-06-06T18:31:30Z</published>
    <title>Understanding Cognitive Depletion in Novice NMR Analysts</title>
    <summary>  We present the results of a user study with novice NMR analysts (N=19)
involving a gamified simulation of the NMR analysis process. Participants
solved randomly generated spectrum puzzles for up to three hours. We used eye
tracking, event logging, and observations to record symptoms of cognitive
depletion while participants worked. Analysis of results indicate that we can
detect both signs of learning and signs of cognitive depletion in participants
over the course of the three hours. Participants' break strategies did not
predict or reflect game scores, but certain symptoms appear predictive of
breaks.
</summary>
    <author>
      <name>Lyndsey Franklin</name>
    </author>
    <author>
      <name>Kyungsik Han</name>
    </author>
    <author>
      <name>Zhuanyi Huang</name>
    </author>
    <author>
      <name>Dustin Arendt</name>
    </author>
    <author>
      <name>Nathan Hodas</name>
    </author>
    <link href="http://arxiv.org/abs/1706.01919v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.01919v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.05718v1</id>
    <updated>2017-06-18T20:25:47Z</updated>
    <published>2017-06-18T20:25:47Z</published>
    <title>An exploration to visualize finite element data with a DSL</title>
    <summary>  The scientific community use PDEs to model a range of problems. The people in
this domain are interested in visualizing their results, but existing
mechanisms for visualization can not handle the full richness of computations
in the domain. We did an exploration to see how Diderot, a domain specific
language for scientific visualization and image analysis, could be used to
solve this problem.
  We demonstrate our first and modest approach of visualizing FE data with
Diderot and provide examples. Using Diderot, we do a simple sampling and a
volume rendering of a FE field. These examples showcase Diderot's ability to
provide a visualization result for Firedrake. This paper describes the
extension of the Diderot language to include FE data.
</summary>
    <author>
      <name>Charisee Chiw</name>
    </author>
    <author>
      <name>Gordon Kindlmann</name>
    </author>
    <author>
      <name>John Reppy</name>
    </author>
    <link href="http://arxiv.org/abs/1706.05718v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.05718v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.10060v1</id>
    <updated>2017-06-30T08:35:06Z</updated>
    <published>2017-06-30T08:35:06Z</published>
    <title>Turned 70? It is time to start editing Wikipedia</title>
    <summary>  Success of Wikipedia would not be possible without the contributions of
millions of anonymous Internet users who edit articles, correct mistakes, add
links or pictures. At the same time Wikipedia editors are currently overworked
and there is always more tasks waiting to be completed than people willing to
volunteer. The paper explores the possibility of involving the elderly in the
Wikipedia editing process. Older adults were asked to complete various tasks on
Wikipedia. Based on the observations made during these activities as well as
in-depth interviews, a list of recommendation has been crafted. It turned out
that older adults are willing to contribute to Wikiepdia but substantial
changes have to be made in the Wikipedia editor.
</summary>
    <author>
      <name>Radoslaw Nielek</name>
    </author>
    <author>
      <name>Marta Lutostanska</name>
    </author>
    <author>
      <name>Wieslaw Kopec</name>
    </author>
    <author>
      <name>Adam Wierzbicki</name>
    </author>
    <link href="http://arxiv.org/abs/1706.10060v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.10060v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.02654v1</id>
    <updated>2017-07-09T22:45:43Z</updated>
    <published>2017-07-09T22:45:43Z</published>
    <title>Vision-Based Classification of Social Gestures in Videochat Sessions</title>
    <summary>  This paper describes the design and evaluation of the vision-based
classification of social gestures, such as handshake, hug, high-five, etc. This
is a component of the mediated social touch systems, which can be incorporated
into ShareTable and SqueezeBands system to achieve automated gestures
recognition and transmission of the touch between the users in real time. The
results from our pilot study show the recognition accuracy of each gestures,
and they indicate that significant future work is necessary to improve its
practical feasibility in the mediated social touch applications.
</summary>
    <author>
      <name>Yuan Yao</name>
    </author>
    <author>
      <name>Svetlana Yarosh</name>
    </author>
    <link href="http://arxiv.org/abs/1707.02654v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.02654v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.00076v1</id>
    <updated>2017-07-31T21:33:32Z</updated>
    <published>2017-07-31T21:33:32Z</published>
    <title>Capturing the Connections: Unboxing Internet of Things Devices</title>
    <summary>  Based upon a study of how to capture data from Internet of Things (IoT)
devices, this paper explores the challenges for data centric design
ethnography. Often purchased to perform specific tasks, IoT devices exist in a
complex ecosystem. This paper describes a study that used a variety of methods
to capture the interactions an IoT device engaged in when it was first setup.
The complexity of the study that is explored through the annotated
documentation across video and router activity, presents the ethnographic
challenges that designers face in an age of connected things.
</summary>
    <author>
      <name>Kami Vaniea</name>
    </author>
    <author>
      <name>Ella Tallyn</name>
    </author>
    <author>
      <name>Chris Speed</name>
    </author>
    <link href="http://arxiv.org/abs/1708.00076v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.00076v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.01944v1</id>
    <updated>2017-08-06T22:20:02Z</updated>
    <published>2017-08-06T22:20:02Z</published>
    <title>Rookie: A unique approach for exploring news archives</title>
    <summary>  News archives are an invaluable primary source for placing current events in
historical context. But current search engine tools do a poor job at uncovering
broad themes and narratives across documents. We present Rookie: a practical
software system which uses natural language processing (NLP) to help readers,
reporters and editors uncover broad stories in news archives. Unlike prior
work, Rookie's design emerged from 18 months of iterative development in
consultation with editors and computational journalists. This process lead to a
dramatically different approach from previous academic systems with similar
goals. Our efforts offer a generalizable case study for others building
real-world journalism software using NLP.
</summary>
    <author>
      <name>Abram Handler</name>
    </author>
    <author>
      <name>Brendan O'Connor</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented at KDD 2017: Data Science + Journalism workshop</arxiv:comment>
    <link href="http://arxiv.org/abs/1708.01944v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.01944v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.02895v1</id>
    <updated>2017-08-09T16:20:12Z</updated>
    <published>2017-08-09T16:20:12Z</published>
    <title>Interacting with Acoustic Simulation and Fabrication</title>
    <summary>  Incorporating accurate physics-based simulation into interactive design tools
is challenging. However, adding the physics accurately becomes crucial to
several emerging technologies. For example, in virtual/augmented reality
(VR/AR) videos, the faithful reproduction of surrounding audios is required to
bring the immersion to the next level. Similarly, as personal fabrication is
made possible with accessible 3D printers, more intuitive tools that respect
the physical constraints can help artists to prototype designs. One main hurdle
is the sheer amount of computation complexity to accurately reproduce the
real-world phenomena through physics-based simulation. In my thesis research, I
develop interactive tools that implement efficient physics-based simulation
algorithms for automatic optimization and intuitive user interaction.
</summary>
    <author>
      <name>Dingzeyu Li</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ACM UIST 2017 Doctoral Symposium</arxiv:comment>
    <link href="http://arxiv.org/abs/1708.02895v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.02895v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.03892v1</id>
    <updated>2017-08-13T11:55:02Z</updated>
    <published>2017-08-13T11:55:02Z</published>
    <title>EmoTxt: A Toolkit for Emotion Recognition from Text</title>
    <summary>  We present EmoTxt, a toolkit for emotion recognition from text, trained and
tested on a gold standard of about 9K question, answers, and comments from
online interactions. We provide empirical evidence of the performance of
EmoTxt. To the best of our knowledge, EmoTxt is the first open-source toolkit
supporting both emotion recognition from text and training of custom emotion
classification models.
</summary>
    <author>
      <name>Fabio Calefato</name>
    </author>
    <author>
      <name>Filippo Lanubile</name>
    </author>
    <author>
      <name>Nicole Novielli</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proc. 7th Affective Computing and Intelligent Interaction
  (ACII'17), San Antonio, TX, USA, Oct. 23-26, 2017</arxiv:comment>
    <link href="http://arxiv.org/abs/1708.03892v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.03892v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.04139v1</id>
    <updated>2017-08-10T21:03:21Z</updated>
    <published>2017-08-10T21:03:21Z</published>
    <title>PhyShare: Sharing Physical Interaction in Virtual Reality</title>
    <summary>  We present PhyShare, a new haptic user interface based on actuated robots.
Virtual reality has recently been gaining wide adoption, and an effective
haptic feedback in these scenarios can strongly support user's sensory in
bridging virtual and physical world. Since participants do not directly observe
these robotic proxies, we investigate the multiple mappings between physical
robots and virtual proxies that can utilize the resources needed to provide a
well rounded VR experience. PhyShare bots can act either as directly touchable
objects or invisible carriers of physical objects, depending on different
scenarios. They also support distributed collaboration, allowing remotely
located VR collaborators to share the same physical feedback.
</summary>
    <author>
      <name>Zhenyi He</name>
    </author>
    <author>
      <name>Fengyuan Zhu</name>
    </author>
    <author>
      <name>Ken Perlin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages. arXiv admin note: text overlap with arXiv:1701.08879</arxiv:comment>
    <link href="http://arxiv.org/abs/1708.04139v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.04139v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.05805v1</id>
    <updated>2017-08-19T05:04:05Z</updated>
    <published>2017-08-19T05:04:05Z</published>
    <title>Design Space of Programming Tools on Mobile Touchscreen Devices</title>
    <summary>  While mobile touchscreen devices are ubiquitous and present opportunities for
novel applications, they have seen little adoption as tools for computer
programming. In this literature survey, we bring together the diverse research
work on programming-related tasks supported by mobile touchscreen devices to
explore the design space for applying them to programming situations. We used
the Grounded theory approach to identify themes and classify previous work. We
present these themes and how each paper contributes to the theme, and we
outline the remaining challenges in and opportunities for using mobile
touchscreen devices in programming applications.
</summary>
    <author>
      <name>Poorna Talkad Sukumar</name>
    </author>
    <author>
      <name>Ronald Metoyer</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, includes one-page table</arxiv:comment>
    <link href="http://arxiv.org/abs/1708.05805v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.05805v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.2; D.2.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.07762v1</id>
    <updated>2017-08-25T14:36:07Z</updated>
    <published>2017-08-25T14:36:07Z</published>
    <title>Chisio: A Compound Graph Editing and Layout Framework</title>
    <summary>  We introduce a new free, open-source compound graph editing and layout
framework named Chisio, based on the Eclipse Graph Editing Framework (GEF) and
written in Java. Chisio can be used as a finished graph editor with its
easy-to-use graphical interface. The framework has an architecture suitable for
easy customization of the tool for end-user's specific needs as well. Chisio
comes with a variety of graph layout algorithms, most supporting compound
structures and non-uniform node dimensions. Furthermore, new algorithms are
straightforward to add, making Chisio an ideal test environment for layout
algorithm developers.
</summary>
    <author>
      <name>Cihan Kucukkececi</name>
    </author>
    <author>
      <name>Ugur Dogrusoz</name>
    </author>
    <author>
      <name>Esat Belviranli</name>
    </author>
    <author>
      <name>Alptug Dilek</name>
    </author>
    <link href="http://arxiv.org/abs/1708.07762v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.07762v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.09654v1</id>
    <updated>2017-08-31T10:25:28Z</updated>
    <published>2017-08-31T10:25:28Z</published>
    <title>Identifying Unsafe Videos on Online Public Media using Real-time
  Crowdsourcing</title>
    <summary>  Due to the significant growth of social networking and human activities
through the web in recent years, attention to analyzing big data using
real-time crowdsourcing has increased. This data may appear in the form of
streaming images, audio or videos. In this paper, we address the problem of
deciding the appropriateness of streaming videos in public media with the help
of crowdsourcing in real-time.
</summary>
    <author>
      <name>Sankar Kumar Mridha</name>
    </author>
    <author>
      <name>Braznev Sarkar</name>
    </author>
    <author>
      <name>Sujoy Chatterjee</name>
    </author>
    <author>
      <name>Malay Bhattacharyya</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Works-in-Progress, Fifth AAAI Conference on Human Computation and
  Crowdsourcing (HCOMP 2017), Quebec City, Canada</arxiv:comment>
    <link href="http://arxiv.org/abs/1708.09654v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.09654v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68Txx" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.1.2; I.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.00098v1</id>
    <updated>2017-08-31T22:15:12Z</updated>
    <published>2017-08-31T22:15:12Z</published>
    <title>AudExpCreator: A GUI-based Matlab tool for designing and creating
  auditory experiments with the Psychophysics Toolbox</title>
    <summary>  We present AudExpCreator, a GUI-based Matlab tool for designing and creating
auditory experiments. AudExpCreator allows users to generate auditory
experiments that run on Matlab's Psychophysics Toolbox without having to write
any code; rather, users simply follow instructions in GUIs to specify desired
design parameters. The software comprises five auditory study types, including
behavioral studies and integration with EEG and physiological response
collection systems. Advanced features permit more complicated experimental
designs as well as maintenance and update of previously created experiments.
AudExpCreator alleviates programming barriers while providing a free,
open-source alternative to commercial experimental design software.
</summary>
    <author>
      <name>Duc T. Nguyen</name>
    </author>
    <author>
      <name>Blair Kaneshiro</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1709.00098v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.00098v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.00111v1</id>
    <updated>2017-08-31T23:47:37Z</updated>
    <published>2017-08-31T23:47:37Z</published>
    <title>Good Usability Practices in Scientific Software Development</title>
    <summary>  Scientific software often presents very particular requirements regarding
usability, which is often completely overlooked in this setting. As
computational science has emerged as its own discipline, distinct from
theoretical and experimental science, it has put new requirements on future
scientific software developments. In this paper, we discuss the background of
these problems and introduce nine aspects of good usability. We also highlight
best practices for each aspect with an emphasis on applications in
computational science.
</summary>
    <author>
      <name>Francisco Queiroz</name>
    </author>
    <author>
      <name>Raniere Silva</name>
    </author>
    <author>
      <name>Jonah Miller</name>
    </author>
    <author>
      <name>Sandor Brockhauser</name>
    </author>
    <author>
      <name>Hans Fangohr</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.6084/m9.figshare.5331814.v3</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.6084/m9.figshare.5331814.v3" rel="related"/>
    <link href="http://arxiv.org/abs/1709.00111v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.00111v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.00293v1</id>
    <updated>2017-08-31T15:18:46Z</updated>
    <published>2017-08-31T15:18:46Z</published>
    <title>Revisited Experimental Comparison of Node-Link and Matrix
  Representations</title>
    <summary>  Visualizing network data is applicable in domains such as biology,
engineering, and social sciences. We report the results of a study comparing
the effectiveness of the two primary techniques for showing network data:
node-link diagrams and adjacency matrices. Specifically, an evaluation with a
large number of online participants revealed statistically significant
differences between the two visualizations. Our work adds to existing research
in several ways. First, we explore a broad spectrum of network tasks, many of
which had not been previously evaluated. Second, our study uses a large
dataset, typical of many real-life networks not explored by previous studies.
Third, we leverage crowdsourcing to evaluate many tasks with many participants.
</summary>
    <author>
      <name>Mershack Okoe</name>
    </author>
    <author>
      <name>Radu Jianu</name>
    </author>
    <author>
      <name>Stephen Kobourov</name>
    </author>
    <link href="http://arxiv.org/abs/1709.00293v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.00293v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.00965v1</id>
    <updated>2017-09-04T14:00:59Z</updated>
    <published>2017-09-04T14:00:59Z</published>
    <title>Feasibility of Corneal Imaging for Handheld Augmented Reality</title>
    <summary>  Smartphones are a popular device class for mobile Augmented Reality but
suffer from a limited input space. Around-device interaction techniques aim at
extending this input space using various sensing modalities. In this paper we
present our work towards extending the input area of mobile devices using
front-facing device-centered cameras that capture reflections in the cornea. As
current generation mobile devices lack high resolution front-facing cameras, we
study the feasibility of around-device interaction using corneal reflective
imaging based on a high resolution camera. We present a workflow, a technical
prototype and a feasibility evaluation.
</summary>
    <author>
      <name>Daniel Schneider</name>
    </author>
    <author>
      <name>Jens Grubert</name>
    </author>
    <link href="http://arxiv.org/abs/1709.00965v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.00965v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.00966v1</id>
    <updated>2017-09-04T14:01:45Z</updated>
    <published>2017-09-04T14:01:45Z</published>
    <title>Towards Around-Device Interaction using Corneal Imaging</title>
    <summary>  Around-device interaction techniques aim at extending the input space using
various sensing modalities on mobile and wearable devices. In this paper, we
present our work towards extending the input area of mobile devices using
front-facing device-centered cameras that capture reflections in the human eye.
As current generation mobile devices lack high resolution front-facing cameras
we study the feasibility of around-device interaction using corneal reflective
imaging based on a high resolution camera. We present a workflow, a technical
prototype and an evaluation, including a migration path from high resolution to
low resolution imagers. Our study indicates, that under optimal conditions a
spatial sensing resolution of 5 cm in the vicinity of a mobile phone is
possible.
</summary>
    <author>
      <name>Daniel Schneider</name>
    </author>
    <author>
      <name>Jens Grubert</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3132272.3134127</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3132272.3134127" rel="related"/>
    <link href="http://arxiv.org/abs/1709.00966v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.00966v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.01293v1</id>
    <updated>2017-09-05T09:04:05Z</updated>
    <published>2017-09-05T09:04:05Z</published>
    <title>Authoring and Living Next-Generation Location-Based Experiences</title>
    <summary>  Authoring location-based experiences involving multiple participants,
collaborating or competing in both indoor and outdoor mixed realities, is
extremely complex and bound to serious technical challenges. In this work, we
present the first results of the MAGELLAN European project and how these
greatly simplify this creative process using novel authoring, augmented reality
(AR) and indoor geolocalisation techniques.
</summary>
    <author>
      <name>Olivier Balet</name>
    </author>
    <author>
      <name>Boriana Koleva</name>
    </author>
    <author>
      <name>Jens Grubert</name>
    </author>
    <author>
      <name>Kwang Moo Yi</name>
    </author>
    <author>
      <name>Marco Gunia</name>
    </author>
    <author>
      <name>Angelos Katsis</name>
    </author>
    <author>
      <name>Julien Castet</name>
    </author>
    <link href="http://arxiv.org/abs/1709.01293v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.01293v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1710.01772v1</id>
    <updated>2017-10-04T19:19:39Z</updated>
    <published>2017-10-04T19:19:39Z</published>
    <title>CELIO: An application development framework for interactive spaces</title>
    <summary>  Developing applications for interactive space is different from developing
cross-platform applications for personal computing. Input, output, and
architectural variations in each interactive space introduce big overhead in
terms of cost and time for developing, deploying and maintaining applications
for interactive spaces. Often, these applications become on-off experience tied
to the deployed spaces. To alleviate this problem and enable rapid responsive
space design applications similar to responsive web design, we present CELIO
application development framework for interactive spaces. The framework is
micro services based and neatly decouples application and design specifications
from hardware and architecture specifications of an interactive space. In this
paper, we describe this framework and its implementation details. Also, we
briefly discuss the use cases developed using this framework.
</summary>
    <author>
      <name>Yedendra B. Shrinivasan</name>
    </author>
    <author>
      <name>Yunfeng Zhang</name>
    </author>
    <link href="http://arxiv.org/abs/1710.01772v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1710.01772v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/math/9901074v2</id>
    <updated>1999-01-20T16:40:05Z</updated>
    <published>1999-01-19T07:58:55Z</published>
    <title>Differential interactive games: The short-term predictions</title>
    <summary>  Procedures of the short-term predictions for processes in general 2-person
differential interactive games are proposed. Their effectiveness is discussed.
</summary>
    <author>
      <name>Denis V. Juriev</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">two minor remarks are added</arxiv:comment>
    <link href="http://arxiv.org/abs/math/9901074v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/math/9901074v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.HO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.HO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="90D25 (Primary) 90D05, 49N55, 34H05, 93C41, 93B52 (Secondary)" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9906027v1</id>
    <updated>1999-06-25T11:44:42Z</updated>
    <published>1999-06-25T11:44:42Z</published>
    <title>Human-Computer Conversation</title>
    <summary>  The article surveys a little of the history of the technology, sets out the
main current theoretical approaches in brief, and discusses the on-going
opposition between theoretical and empirical approaches. It illustrates the
situation with some discussion of CONVERSE, a system that won the Loebner prize
in 1997 and which displays features of both approaches.
</summary>
    <author>
      <name>Yorick Wilks</name>
    </author>
    <author>
      <name>Roberta Catizone</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/9906027v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9906027v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.7;H.1.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0706.3132v1</id>
    <updated>2007-06-21T12:04:40Z</updated>
    <published>2007-06-21T12:04:40Z</published>
    <title>EasyVoice: Integrating voice synthesis with Skype</title>
    <summary>  This paper presents EasyVoice, a system that integrates voice synthesis with
Skype. EasyVoice allows a person with voice disabilities to talk with another
person located anywhere in the world, removing an important obstacle that
affect these people during a phone or VoIP-based conversation.
</summary>
    <author>
      <name>Paulo A. Condado</name>
    </author>
    <author>
      <name>Fernando G. Lobo</name>
    </author>
    <link href="http://arxiv.org/abs/0706.3132v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0706.3132v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="K.4.2; H.4.3; H.5.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0809.3609v1</id>
    <updated>2008-09-21T19:37:28Z</updated>
    <published>2008-09-21T19:37:28Z</published>
    <title>Information and Data Quality in Spreadsheets</title>
    <summary>  The quality of the data in spreadsheets is less discussed than the structural
integrity of the formulas. Yet it is an area of great interest to the owners
and users of the spreadsheet. This paper provides an overview of Information
Quality (IQ) and Data Quality (DQ) with specific reference to how data is
sourced, structured, and presented in spreadsheets.
</summary>
    <author>
      <name>Patrick O'Beirne</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 Pages, 3 Tables, 1 Figure</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2008 171-185
  ISBN 978-905617-69-2</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0809.3609v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0809.3609v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1001.4104v1</id>
    <updated>2010-01-22T23:38:06Z</updated>
    <published>2010-01-22T23:38:06Z</published>
    <title>Inclusion Analysis</title>
    <summary>  Inclusion analysis is the name given by Operis to a black box testing
technique that it has found to make the checking of key financial ratios
calculated by spreadsheet models quicker, easier and more likely to find
omission errors than code inspection.
</summary>
    <author>
      <name>David Colver</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 Pages, 10 Tables in Colour</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. European Spreadsheet Risks Int. Grp. 2007 177-189 ISBN
  978-905617-58-6</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1001.4104v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1001.4104v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.0810v1</id>
    <updated>2013-10-01T21:27:29Z</updated>
    <published>2013-10-01T21:27:29Z</published>
    <title>RoboRun: A gamification approach to control flow learning for young
  students with TouchDevelop</title>
    <summary>  This demo paper introduces young students to writing code in a touch enabled
interactive maze game. Problem-based learning is given a gamified approach to
learning, while simultaneously introducing the TouchDevelop platform to build
basic first control flow algorithms and to learn about ordering and loops in
conditional statements.
</summary>
    <author>
      <name>Siri Vinay</name>
    </author>
    <author>
      <name>Manoj Vaseekharan</name>
    </author>
    <author>
      <name>Dean Mohamedally</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Promoto 2013 Workshop demo paper at SPLASH 2013</arxiv:comment>
    <link href="http://arxiv.org/abs/1310.0810v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.0810v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="97Q60" scheme="http://arxiv.org/schemas/atom"/>
    <category term="K.3.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1312.3724v1</id>
    <updated>2013-12-13T07:54:22Z</updated>
    <published>2013-12-13T07:54:22Z</published>
    <title>ARIANNA: pAth Recognition for Indoor Assisted NavigatioN with Augmented
  perception</title>
    <summary>  ARIANNA stands for pAth Recognition for Indoor Assisted Navigation with
Augmented perception. It is a flexible and low cost navigation system for vi-
sually impaired people. Arianna permits to navigate colored paths painted or
sticked on the floor revealing their directions through vibrational feedback on
commercial smartphones.
</summary>
    <author>
      <name>Pierluigi Gallo</name>
    </author>
    <author>
      <name>Ilenia Tinnirello</name>
    </author>
    <author>
      <name>Laura Giarré</name>
    </author>
    <author>
      <name>Domenico Garlisi</name>
    </author>
    <author>
      <name>Daniele Croce</name>
    </author>
    <author>
      <name>Adriano Fagiolini</name>
    </author>
    <link href="http://arxiv.org/abs/1312.3724v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1312.3724v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.7247v1</id>
    <updated>2014-04-29T06:27:57Z</updated>
    <published>2014-04-29T06:27:57Z</published>
    <title>Human Factors of Formal Methods</title>
    <summary>  This paper provides a brief introduction to the work that aims to apply the
achievements within the area of engineering psychology to the area of formal
methods, focusing on the specification phase of a system development process.
</summary>
    <author>
      <name>Maria Spichkova</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Preprint. Final version published in Proceedings of IADIS
  International Conference Interfaces and Human Computer Interaction 2012 (IHCI
  2012), 2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1404.7247v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.7247v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.8219v1</id>
    <updated>2014-10-30T01:07:58Z</updated>
    <published>2014-10-30T01:07:58Z</published>
    <title>A Logic-Independent IDE</title>
    <summary>  The author's MMT system provides a framework for defining and implementing
logical systems. By combining MMT with the jEdit text editor, we obtain a
logic-independent IDE. The IDE functionality includes advanced features such as
context-sensitive auto-completion, search, and change management.
</summary>
    <author>
      <name>Florian Rabe</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Jacobs University Bremen</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.167.7</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.167.7" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings UITP 2014, arXiv:1410.7850</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 167, 2014, pp. 48-60</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1410.8219v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.8219v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.4.1; D.2.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.8222v1</id>
    <updated>2014-10-30T01:08:32Z</updated>
    <published>2014-10-30T01:08:32Z</published>
    <title>System description: Isabelle/jEdit in 2014</title>
    <summary>  This is an updated system description for Isabelle/jEdit, according to the
official release Isabelle2014 (August 2014). The following new PIDE concepts
are explained: asynchronous print functions and document overlays, syntactic
and semantic completion, editor navigation, management of auxiliary files
within the document-model.
</summary>
    <author>
      <name>Makarius Wenzel</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Univ. Paris-Sud, Laboratoire LRI, UMR8623</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.167.10</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.167.10" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings UITP 2014, arXiv:1410.7850</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 167, 2014, pp. 84-94</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1410.8222v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.8222v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1501.07847v1</id>
    <updated>2015-01-30T17:13:50Z</updated>
    <published>2015-01-30T17:13:50Z</published>
    <title>Electronic Medication Prescribing Support System for Diagnosing Tropical
  Diseases</title>
    <summary>  This paper presents the development of an e-prescription system for
diagnosing tropical diseases.Results after testing the developed system by
medical experts indicated that the e-prescription systems is more efficient and
less susceptible to common errors associated with the conventional handwritten
medical prescription and can also go a long way to help to improve patients
health outcome in the health industry especially in the tropics.
</summary>
    <author>
      <name>Adebayo Omotosho</name>
    </author>
    <author>
      <name>Mikhail Olaniyi</name>
    </author>
    <author>
      <name>Justice Emuoyibofarhe</name>
    </author>
    <author>
      <name>Funbi Osobu</name>
    </author>
    <link href="http://arxiv.org/abs/1501.07847v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1501.07847v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.03584v1</id>
    <updated>2015-03-12T04:40:08Z</updated>
    <published>2015-03-12T04:40:08Z</published>
    <title>Human Factors in Software Reliability Engineering</title>
    <summary>  In this paper, we present our vision of the integration of human factors
engineering into the software development process. The aim of this approach is
to improve the quality of software and to deal with human errors in a
systematic way.
</summary>
    <author>
      <name>Maria Spichkova</name>
    </author>
    <author>
      <name>Huai Liu</name>
    </author>
    <author>
      <name>Mohsen Laali</name>
    </author>
    <author>
      <name>Heinz W. Schmidt</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Preprint, Workshop on Applications of Human Error Research to Improve
  Software Engineering (WAHESE) at ICSE 2015</arxiv:comment>
    <link href="http://arxiv.org/abs/1503.03584v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.03584v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.01282v1</id>
    <updated>2015-07-05T22:01:50Z</updated>
    <published>2015-07-05T22:01:50Z</published>
    <title>Empowering Kids to Create and Share Programmable Media</title>
    <summary>  This article reflects on the first eight months of existence of the Scratch
Online Community by discussing the design rationale and learning theories
underlying Scratch and its website.
</summary>
    <author>
      <name>Andrés Monroy-Hernández</name>
    </author>
    <author>
      <name>Mitchel Resnick</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/1340961.1340974</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/1340961.1340974" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">FEATURE: Empowering kids to create and share programmable media.
  interactions. issue 15, volume 2 (March 2008), pages 50-53</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Interactions 15, 2 (March 2008), 50-53</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1507.01282v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.01282v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.02271v2</id>
    <updated>2016-09-09T18:37:03Z</updated>
    <published>2016-09-08T04:49:31Z</published>
    <title>Ashwin: Plug-and-Play System for Machine-Human Image Annotation</title>
    <summary>  We present an end-to-end machine-human image annotation system where each
component can be attached in a plug-and-play fashion. These components include
Feature Extraction, Machine Classifier, Task Sampling and Crowd Consensus.
</summary>
    <author>
      <name>Anand Sriraman</name>
    </author>
    <author>
      <name>Mandar Kulkarni</name>
    </author>
    <author>
      <name>Rahul Kumar</name>
    </author>
    <author>
      <name>Kanika Kalra</name>
    </author>
    <author>
      <name>Purushotam Radadia</name>
    </author>
    <author>
      <name>Shirish Karande</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">HCOMP 2016 Demonstrations Track</arxiv:comment>
    <link href="http://arxiv.org/abs/1609.02271v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.02271v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1610.07365v1</id>
    <updated>2016-10-24T11:30:22Z</updated>
    <published>2016-10-24T11:30:22Z</published>
    <title>Introduction: Cognitive Issues in Natural Language Processing</title>
    <summary>  This special issue is dedicated to get a better picture of the relationships
between computational linguistics and cognitive science. It specifically raises
two questions: "what is the potential contribution of computational language
modeling to cognitive science?" and conversely: "what is the influence of
cognitive science in contemporary computational linguistics?"
</summary>
    <author>
      <name>Thierry Poibeau</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LaTTICe</arxiv:affiliation>
    </author>
    <author>
      <name>Shravan Vasishth</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1201/b21583-2</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1201/b21583-2" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Traitement Automatique des Langues, ATALA, 2014, Traitement
  Automatique des Langues et Sciences Cognitives, 55 (3), pp.7-19</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1610.07365v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1610.07365v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.03930v3</id>
    <updated>2017-10-03T09:18:04Z</updated>
    <published>2017-06-13T07:28:26Z</published>
    <title>Generative Models for Learning from Crowds</title>
    <summary>  In this paper, we propose generative probabilistic models for label
aggregation. We use Gibbs sampling and a novel variational inference algorithm
to perform the posterior inference. Empirical results show that our methods
consistently outperform state-of-the-art methods.
</summary>
    <author>
      <name>Chi Hong</name>
    </author>
    <link href="http://arxiv.org/abs/1706.03930v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.03930v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.07757v1</id>
    <updated>2017-04-14T14:54:14Z</updated>
    <published>2017-04-14T14:54:14Z</published>
    <title>Improved Human Emotion Recognition Using Symmetry of Facial Key Points
  with Dihedral Group</title>
    <summary>  This article describes how to deploy dihedral group theory to detect Facial
Key Points (FKP) symmetry to recognize emotions. The method can be applied in
many other areas which those have the same data texture.
</summary>
    <author>
      <name>Mehdi Ghayoumi</name>
    </author>
    <author>
      <name>Arvind Bansal</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IJASCSE Volume 6 Issue 01 2017</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1706.07757v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.07757v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9809119v1</id>
    <updated>1998-09-29T07:06:31Z</updated>
    <published>1998-09-29T07:06:31Z</published>
    <title>Droems: experimental mathematics, informatics and infinite dimensional
  geometry</title>
    <summary>  The article is devoted to a problem of elaboration of the real-time
interactive videosystems for accelerated nonverbal cognitive computer and
telecommunications. The proposed approach is based on the using of droems
(dynamically reconstructed objects of experimental mathematics) and
interpretational figures as pointers to them. Four paragraphs of the article
are devoted to (1) an exposition of basic notions of the interpretational
geometry, (2) the operator methods in the theory of interactive dynamical
videosystems, (3) the general concept of organization of the integrated
interactive real-time videocognitive systems, (4) the droems and processes of
their dynamical reconstruction, where the general notions are illustrated by a
concrete example related to the infinite dimensional geometry. The exposition
is presumably heuristic and conceptual (the first and the third paragraphs)
though some particular aspects such as content of the second and the fourth
paragraphs, which allow deeper formalization and detailing in present, are
exposed on the mathematical level of rigor.
</summary>
    <author>
      <name>Denis V. Juriev</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">bilingual version [English translation+Russian original]: 43 pages,
  AMSTEX</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/9809119v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9809119v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.RT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.1.2; I.3.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9811026v2</id>
    <updated>1999-09-08T15:36:39Z</updated>
    <published>1998-11-16T19:42:30Z</published>
    <title>Designing an interface to optimize reading with small display windows</title>
    <summary>  The electronic presentation of text in small display windows is mushrooming.
In the present paper, four ways of presenting text in a small display window
were examined and compared to a Normal Page condition: rapid serial visual
presentation (RSVP), RSVP with a Completion Meter, Sentence-by-Sentence
presentation, and Sentence-by-Sentence presentation with a Completion Meter.
Dependent measures were reading efficiency - speed and comprehension - and
preference. For designers of hardware or software with small display windows,
the results suggest the following: (1) Though RSVP is disliked by readers, the
present methods of allowing self-pacing and regressions in RSVP, unlike earlier
tested methods, are efficient and feasible. (2) Slower reading in RSVP should
be achieved by increasing pauses between sentences or by repeating sentences,
not by decreasing the within-sentence rate. (3) Completion meters do not
interfere with performance, and are usually preferred. (4) The space-saving
Sentence-by-Sentence format is as efficient and as preferred as the Normal Page
format.
</summary>
    <author>
      <name>Tarjin Rahman</name>
    </author>
    <author>
      <name>Paul Muter</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Human Factors 41 (1999) 106-117</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/9811026v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9811026v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.1.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0005028v1</id>
    <updated>2000-05-27T01:08:07Z</updated>
    <published>2000-05-27T01:08:07Z</published>
    <title>A method for command identification, using modified collision free
  hashing with addition &amp; rotation iterative hash functions (part 1)</title>
    <summary>  This paper proposes a method for identification of a user`s fixed string set
(which can be a command/instruction set for a terminal or microprocessor). This
method is fast and has very small memory requirements, compared to a
traditional full string storage and compare method. The user feeds characters
into a microcontroller via a keyboard or another microprocessor sends commands
and the microcontroller hashes the input in order to identify valid commands,
ensuring no collisions between hashed valid strings, while applying further
criteria to narrow collision between random and valid strings. The method
proposed narrows the possibility of the latter kind of collision, achieving
small code and memory-size utilization and very fast execution. Hashing is
achieved using additive &amp; rotating hash functions in an iterative form, which
can be very easily implemented in simple microcontrollers and microprocessors.
Such hash functions are presented and compared according to their efficiency
for a given string/command set, using the program found in the appendix.
</summary>
    <author>
      <name>Dimitrios Skraparlis</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">28 pages, includes code</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0005028v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0005028v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="B.4.2; H.5.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0101012v1</id>
    <updated>2001-01-16T12:18:12Z</updated>
    <published>2001-01-16T12:18:12Z</published>
    <title>Communities of Practice in the Distributed International Environment</title>
    <summary>  Modern commercial organisations are facing pressures which have caused them
to lose personnel. When they lose people, they also lose their knowledge.
Organisations also have to cope with the internationalisation of business
forcing collaboration and knowledge sharing across time and distance. Knowledge
Management (KM) claims to tackle these issues. This paper looks at an area
where KM does not offer sufficient support, that is, the sharing of knowledge
that is not easy to articulate.
  The focus in this paper is on Communities of Practice in commercial
organisations. We do this by exploring knowledge sharing in Lave and Wenger's
[1] theory of Communities of Practice and investigating how Communities of
Practice may translate to a distributed international environment. The paper
reports on two case studies that explore the functioning of Communities of
Practice across international boundaries.
</summary>
    <author>
      <name>Paul Hildreth</name>
    </author>
    <author>
      <name>Chris Kimble</name>
    </author>
    <author>
      <name>Peter Wright</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Available from
  http://www-users.cs.york.ac.uk/~kimble/research/publics.html</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Knowledge Management, 4(1), March 2000, pp 27 - 37</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0101012v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0101012v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0102028v1</id>
    <updated>2001-02-26T15:22:27Z</updated>
    <published>2001-02-26T15:22:27Z</published>
    <title>Communities of Practice: Going Virtual</title>
    <summary>  With the current trends towards downsizing, outsourcing and globalisation,
modern organisations are reducing the numbers of people they employ. In
addition, organisations now have to cope with the increasing
internationalisation of business forcing collaboration and knowledge sharing
across time and distance simultaneously. There is a need for new ways of
thinking about how knowledge is shared in distributed groups. In this paper we
explore a relatively new approach to knowledge sharing using Lave and Wenger's
(1991) theory of Communities of Practice (CoPs). We investigate whether CoPs
might translate to a geographically distributed international environment
through a case study that explores the functioning of a CoP across national
boundaries.
</summary>
    <author>
      <name>Chris Kimble</name>
    </author>
    <author>
      <name>Paul Hildreth</name>
    </author>
    <author>
      <name>Peter Wright</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Draft version available from
  http://www-users.cs.york.ac.uk/~kimble/research/publics.html</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Chapter 13 in Knowledge Management and Business Model Innovation,
  Idea Group Publishing, Hershey (USA)/London (UK), 2001. pp 220 - 234</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0102028v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0102028v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0111007v1</id>
    <updated>2001-11-05T19:02:47Z</updated>
    <published>2001-11-05T19:02:47Z</published>
    <title>Explaining Scenarios for Information Personalization</title>
    <summary>  Personalization customizes information access. The PIPE ("Personalization is
Partial Evaluation") modeling methodology represents interaction with an
information space as a program. The program is then specialized to a user's
known interests or information seeking activity by the technique of partial
evaluation. In this paper, we elaborate PIPE by considering requirements
analysis in the personalization lifecycle. We investigate the use of scenarios
as a means of identifying and analyzing personalization requirements. As our
first result, we show how designing a PIPE representation can be cast as a
search within a space of PIPE models, organized along a partial order. This
allows us to view the design of a personalization system, itself, as
specialized interpretation of an information space. We then exploit the
underlying equivalence of explanation-based generalization (EBG) and partial
evaluation to realize high-level goals and needs identified in scenarios; in
particular, we specialize (personalize) an information space based on the
explanation of a user scenario in that information space, just as EBG
specializes a theory based on the explanation of an example in that theory. In
this approach, personalization becomes the transformation of information spaces
to support the explanation of usage scenarios. An example application is
described.
</summary>
    <author>
      <name>Naren Ramakrishnan</name>
    </author>
    <author>
      <name>Mary Beth Rosson</name>
    </author>
    <author>
      <name>John M. Carroll</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0111007v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0111007v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.5; H.4.2; H.5.4; I.2.6; K.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0111024v1</id>
    <updated>2001-11-09T01:02:00Z</updated>
    <published>2001-11-09T01:02:00Z</published>
    <title>Building Multi-Platform User Interfaces with UIML</title>
    <summary>  There has been a widespread emergence of computing devices in the past few
years that go beyond the capabilities of traditional desktop computers.
However, users want to use the same kinds of applications and access the same
data and information on these appliances that they can access on their desktop
computers. The user interfaces for these platforms go beyond the traditional
interaction metaphors. It is a challenge to build User Interfaces (UIs) for
these devices of differing capabilities that allow the end users to perform the
same kinds of tasks. The User Interface Markup Language (UIML) is an XML-based
language that allows the canonical description of UIs for different platforms.
We describe the language features of UIML that facilitate the development of
multi-platform UIs. We also describe the key aspects of our approach that makes
UIML succeed where previous approaches failed, namely the division in the
representation of a UI, the use of a generic vocabulary, and an integrated
development environment specifically designed for transformation-based UI
development. Finally we describe the initial details of a multi-step usability
engineering process for building multi-platform UI using UIML.
</summary>
    <author>
      <name>Mir Farooq Ali</name>
    </author>
    <author>
      <name>Manuel A. Perez-Quinones</name>
    </author>
    <author>
      <name>Eric Shell</name>
    </author>
    <author>
      <name>Marc Abrams</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0111024v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0111024v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.2;H.5.4;I.3.6;D.2.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0111025v1</id>
    <updated>2001-11-09T01:10:00Z</updated>
    <published>2001-11-09T01:10:00Z</published>
    <title>A Multi-Step Process for Generating Multi-Platform User Interfaces using
  UIML</title>
    <summary>  There has been a widespread emergence of computing devices in the past few
years that go beyond the capabilities of traditional desktop computers. These
devices have varying input/output characteristics, modalities and interaction
mechanisms. However, users want to use the same kinds of applications and
access the same data and information on these appliances that they can access
on their desktop computers. The user interfaces for these devices and platforms
go beyond the traditional interaction metaphors. It is a challenge to build
User Interfaces (UIs) for these devices of differing capabilities that allow
the end users to perform the same kinds of tasks. The User Interface Markup
Language (UIML) is an XML-based language that allows the canonical description
of UIs for different platforms. We present a multi-step transformation-based
framework for building Multi-Platform User Interfaces using UIML. We describe
the language features of UIML that facilitate the development of multi-platform
UIs, the multi-step process involved in our framework and the transformations
needed to build the UIs.
</summary>
    <author>
      <name>Mir Farooq Ali</name>
    </author>
    <author>
      <name>Manuel A. Perez-Quinones</name>
    </author>
    <author>
      <name>Marc Abrams</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0111025v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0111025v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.2;H.5.4;I.3.6;D.2.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0205053v1</id>
    <updated>2002-05-21T02:55:20Z</updated>
    <published>2002-05-21T02:55:20Z</published>
    <title>Sotto Voce: Exploring the Interplay of Conversation and Mobile Audio
  Spaces</title>
    <summary>  In addition to providing information to individual visitors, electronic
guidebooks have the potential to facilitate social interaction between visitors
and their companions. However, many systems impede visitor interaction. By
contrast, our electronic guidebook, Sotto Voce, has social interaction as a
primary design goal. The system enables visitors to share audio information -
specifically, they can hear each other's guidebook activity using a
technologically mediated audio eavesdropping mechanism. We conducted a study of
visitors using Sotto Voce while touring a historic house. The results indicate
that visitors are able to use the system effectively, both as a conversational
resource and as an information appliance. More surprisingly, our results
suggest that the technologically mediated audio often cohered the visitors'
conversation and activity to a far greater degree than audio delivered through
the open air.
</summary>
    <author>
      <name>Paul M. Aoki</name>
    </author>
    <author>
      <name>Rebecca E. Grinter</name>
    </author>
    <author>
      <name>Amy Hurst</name>
    </author>
    <author>
      <name>Margaret H. Szymanski</name>
    </author>
    <author>
      <name>James D. Thornton</name>
    </author>
    <author>
      <name>Allison Woodruff</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/503376.503454</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/503376.503454" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. ACM SIGCHI Conference on Human Factors in Computing Systems,
  Minneapolis, MN, April 2002, 431-438. ACM Press.</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0205053v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0205053v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.1; H.5.2; H.5.3; H.5.5; J.5; K.3.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0205054v1</id>
    <updated>2002-05-21T03:07:01Z</updated>
    <published>2002-05-21T03:07:01Z</published>
    <title>Eavesdropping on Electronic Guidebooks: Observing Learning Resources in
  Shared Listening Environments</title>
    <summary>  We describe an electronic guidebook, Sotto Voce, that enables visitors to
share audio information by eavesdropping on each other's guidebook activity. We
have conducted three studies of visitors using electronic guidebooks in a
historic house: one study with open air audio played through speakers and two
studies with eavesdropped audio. An analysis of visitor interaction in these
studies suggests that eavesdropped audio provides more social and interactive
learning resources than open air audio played through speakers.
</summary>
    <author>
      <name>Allison Woodruff</name>
    </author>
    <author>
      <name>Paul M. Aoki</name>
    </author>
    <author>
      <name>Rebecca E. Grinter</name>
    </author>
    <author>
      <name>Amy Hurst</name>
    </author>
    <author>
      <name>Margaret H. Szymanski</name>
    </author>
    <author>
      <name>James D. Thornton</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">In David Bearman and Jennifer Trant (eds.), Museums and the Web
  2002: Selected Papers. (Proc. 6th International Conference on Museums and the
  Web, Boston, MA, April 2002.) Pittsburgh, PA: Archives &amp; Museum Informatics,
  2002, 21-30</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0205054v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0205054v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.1; H.5.2; H.5.3; H.5.5; J.5; K.3.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0205055v1</id>
    <updated>2002-05-21T03:16:49Z</updated>
    <published>2002-05-21T03:16:49Z</published>
    <title>Practical Strategies for Integrating a Conversation Analyst in an
  Iterative Design Process</title>
    <summary>  We present a case study of an iterative design process that includes a
conversation analyst. We discuss potential benefits of conversation analysis
for design, and we describe our strategies for integrating the conversation
analyst in the design process. Since the analyst on our team had no previous
exposure to design or engineering, and none of the other members of our team
had any experience with conversation analysis, we needed to build a foundation
for our interaction. One of our key strategies was to pair the conversation
analyst with a designer in a highly interactive collaboration. Our tactics have
been effective on our project, leading to valuable results that we believe we
could not have obtained using another method. We hope that this paper can serve
as a practical guide to those interested in establishing a productive and
efficient working relationship between a conversation analyst and the other
members of a design team.
</summary>
    <author>
      <name>Allison Woodruff</name>
    </author>
    <author>
      <name>Margaret H. Szymanski</name>
    </author>
    <author>
      <name>Rebecca E. Grinter</name>
    </author>
    <author>
      <name>Paul M. Aoki</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/778712.778748</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/778712.778748" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. ACM Conf. on Designing Interactive Systems, London, UK, June
  2002, 19-28. ACM Press.</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0205055v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0205055v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.2; H.5.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0304002v1</id>
    <updated>2003-04-01T05:15:05Z</updated>
    <published>2003-04-01T05:15:05Z</published>
    <title>The Mad Hatter&amp;acute;s Cocktail Party: A Social Mobile Audio Space
  Supporting Multiple Simultaneous Conversations</title>
    <summary>  This paper presents a mobile audio space intended for use by gelled social
groups. In face-to-face interactions in such social groups, conversational
floors change frequently, e.g., two participants split off to form a new
conversational floor, a participant moves from one conversational floor to
another, etc. To date, audio spaces have provided little support for such
dynamic regroupings of participants, either requiring that the participants
explicitly specify with whom they wish to talk or simply presenting all
participants as though they are in a single floor. By contrast, the audio space
described here monitors participant behavior to identify conversational floors
as they emerge. The system dynamically modifies the audio delivered to each
participant to enhance the salience of the participants with whom they are
currently conversing. We report a user study of the system, focusing on
conversation analytic results.
</summary>
    <author>
      <name>Paul M. Aoki</name>
    </author>
    <author>
      <name>Matthew Romaine</name>
    </author>
    <author>
      <name>Margaret H. Szymanski</name>
    </author>
    <author>
      <name>James D. Thornton</name>
    </author>
    <author>
      <name>Daniel Wilson</name>
    </author>
    <author>
      <name>Allison Woodruff</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/642611.642686</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/642611.642686" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. ACM SIGCHI Conf. on Human Factors in Computing Systems, Ft.
  Lauderdale, FL, Apr. 2003, 425-432. ACM Press.</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0304002v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0304002v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.4.3; H.5.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0309001v2</id>
    <updated>2003-09-02T04:12:12Z</updated>
    <published>2003-08-31T20:13:10Z</published>
    <title>Media Affordances of a Mobile Push-To-Talk Communication Service</title>
    <summary>  This paper presents an exploratory study of college-age students using
two-way, push-to-talk cellular radios. We describe the observed and reported
use of cellular radio by the participants, the activities and purposes for
which they adopted it, and their responses. We then examine these empirical
results using mediated communication theory. Cellular radios have a unique
combination of affordances relative to other media used by this age group,
including instant messaging (IM) and mobile phones; the results of our analysis
do suggest explanations for some observed phenomena but also highlight the
counter-intuitive nature of other phenomena. For example, although the radios
have many important dissimilarities with IM from the viewpoint of mediated
communication theory, the observed use patterns resembled those of IM to a
surprising degree.
</summary>
    <author>
      <name>Allison Woodruff</name>
    </author>
    <author>
      <name>Paul M. Aoki</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0309001v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0309001v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.4.3; H.5.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0312016v1</id>
    <updated>2003-12-08T16:25:46Z</updated>
    <published>2003-12-08T16:25:46Z</published>
    <title>Taking the Initiative with Extempore: Exploring Out-of-Turn Interactions
  with Websites</title>
    <summary>  We present the first study to explore the use of out-of-turn interaction in
websites. Out-of-turn interaction is a technique which empowers the user to
supply unsolicited information while browsing. This approach helps flexibly
bridge any mental mismatch between the user and the website, in a manner
fundamentally different from faceted browsing and site-specific search tools.
We built a user interface (Extempore) which accepts out-of-turn input via voice
or text; and employed it in a US congressional website, to determine if users
utilize out-of-turn interaction for information-finding tasks, and their
rationale for doing so. The results indicate that users are adept at discerning
when out-of-turn interaction is necessary in a particular task, and actively
interleaved it with browsing. However, users found cascading information across
information-finding subtasks challenging. Therefore, this work not only
improves our understanding of out-of-turn interaction, but also suggests
further opportunities to enrich browsing experiences for users.
</summary>
    <author>
      <name>Saverio Perugini</name>
    </author>
    <author>
      <name>Mary E. Pinney</name>
    </author>
    <author>
      <name>Naren Ramakrishnan</name>
    </author>
    <author>
      <name>Manuel A. Perez-Quinones</name>
    </author>
    <author>
      <name>Mary Beth Rosson</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Introduces out-of-turn interaction with websites: a technique which
  sustains, rather than curbs, the user-system dialog</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0312016v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0312016v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.2; H.5.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0402001v1</id>
    <updated>2004-01-31T20:09:39Z</updated>
    <published>2004-01-31T20:09:39Z</published>
    <title>Mobile Re-Finding of Web Information Using a Voice Interface</title>
    <summary>  Mobile access to information is a considerable problem for many users,
especially to information found on the Web. In this paper, we explore how a
voice-controlled service, accessible by telephone, could support mobile users'
needs for refinding specific information previously found on the Web. We
outline challenges in creating such a service and describe architectural and
user interfaces issues discovered in an exploratory prototype we built called
WebContext.
  We also present the results of a study, motivated by our experience with
WebContext, to explore what people remember about information that they are
trying to refind and how they express information refinding requests in a
collaborative conversation. As part of the study, we examine how
end-usercreated Web page annotations can be used to help support mobile
information re-finding. We observed the use of URLs, page titles, and
descriptions of page contents to help identify waypoints in the search process.
Furthermore, we observed that the annotations were utilized extensively,
indicating that explicitly added context by the user can play an important role
in re-finding.
</summary>
    <author>
      <name>Robert G. Capra</name>
    </author>
    <author>
      <name>Manuel A. Perez-Quinones</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0402001v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0402001v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.1.2; H.3.3; H.5.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0405045v1</id>
    <updated>2004-05-13T18:46:34Z</updated>
    <published>2004-05-13T18:46:34Z</published>
    <title>Culture and International Usability Testing: The Effects of Culture in
  Structured Interviews</title>
    <summary>  The global audience for software products includes members of different
countries, religions, and cultures: people who speak different languages, have
different life styles, and have different perceptions and expectations of any
given product. A major impediment in interface development is that there is
inadequate empirical evidence for the effects of culture in the usability
engineering methods used for developing user interfaces. This paper presents a
controlled study investigating the effects of culture on the effectiveness of
structured interviews in usability testing. The experiment consisted of
usability testing of a website with two independent groups of Indian
participants by two interviewers; one belonging to the Indian culture and the
other to the Anglo-American culture. Participants found more usability problems
and made more suggestions to an interviewer who was a member of the same
(Indian) culture than to the foreign (Anglo-American) interviewer. The results
of the study empirically establish that culture significantly affects the
efficacy of structured interviews during international user testing. The
implications of this work for usability engineering are discussed.
</summary>
    <author>
      <name>Ravikiran Vatrapu</name>
    </author>
    <author>
      <name>Manuel A. Perez-Quinones</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0405045v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0405045v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H5.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0405108v1</id>
    <updated>2004-05-28T02:53:46Z</updated>
    <published>2004-05-28T02:53:46Z</published>
    <title>"User Interfaces" and the Social Negotiation of Availability</title>
    <summary>  In current presence or availability systems, the method of presenting a
user's state often supposes an instantaneous notion of that state - for
example, a visualization is rendered or an inference is made about the
potential actions that might be consistent with a user's state. Drawing on
observational research on the use of existing communication technology, we
argue (as have others in the past) that determination of availability is often
a joint process, and often one that takes the form of a negotiation (whether
implicit or explicit). We briefly describe our current research on applying
machine learning to infer degrees of conversational engagement from observed
conversational behavior. Such inferences can be applied to facilitate the
implicit negotiation of conversational engagement - in effect, helping users to
weave together the act of contact with the act of determining availability.
</summary>
    <author>
      <name>Paul M. Aoki</name>
    </author>
    <author>
      <name>Allison Woodruff</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Workshop on Forecasting Presence and Availability, ACM SIGCHI
  Conf. on Human Factors in Computing Systems (CHI 2004), Vienna, Austria, Apr.
  2004.</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0405108v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0405108v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.2; H.4.3; H.1.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0409042v1</id>
    <updated>2004-09-23T19:29:26Z</updated>
    <published>2004-09-23T19:29:26Z</published>
    <title>A new architecture for making highly scalable applications</title>
    <summary>  An application is a logical image of the world on a computer. A scalable
application is an application that allows one to update that logical image at
run time. To put it in operational terms: an application is scalable if a
client can change between time T1 and time T2 - the logic of the application as
expressed by language L;
  - the structure and volume of the stored knowledge;
  - the user interface of the application; while clients working with the
application at time T1 will work with the changed application at time T2
without performing any special action between T1 and T2. In order to realize
such a scalable application a new architecture has been developed that fully
orbits around language. In order to verify the soundness of that architecture a
program has been build. Both architecture and program are called CommunSENS.
The main purpose of this paper is: - to list the relevant elements of the
architecture; - to give a visual presentation of how the program and its image
of the world look like; - to give a visual presentation of how the image can be
updated. Some relevant philosophical and practical backgrounds are included in
the appendixes.
</summary>
    <author>
      <name>Harry Fitié</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 7 figures, 5 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0409042v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0409042v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0410063v1</id>
    <updated>2004-10-25T02:17:35Z</updated>
    <published>2004-10-25T02:17:35Z</published>
    <title>INSPIRE: Evaluation of a Smart-Home System for Infotainment Management
  and Device Control</title>
    <summary>  This paper gives an overview of the assessment and evaluation methods which
have been used to determine the quality of the INSPIRE smart home system. The
system allows different home appliances to be controlled via speech, and
consists of speech and speaker recognition, speech understanding, dialogue
management, and speech output components. The performance of these components
is first assessed individually, and then the entire system is evaluated in an
interaction experiment with test users. Initial results of the assessment and
evaluation are given, in particular with respect to the transmission channel
impact on speech and speaker recognition, and the assessment of speech output
for different system metaphors.
</summary>
    <author>
      <name>Sebastian Moeller</name>
    </author>
    <author>
      <name>Jan Krebber</name>
    </author>
    <author>
      <name>Alexander Raake</name>
    </author>
    <author>
      <name>Paula Smeele</name>
    </author>
    <author>
      <name>Martin Rajman</name>
    </author>
    <author>
      <name>Mirek Melichar</name>
    </author>
    <author>
      <name>Vincenzo Pallotta</name>
    </author>
    <author>
      <name>Gianna Tsakou</name>
    </author>
    <author>
      <name>Basilis Kladis</name>
    </author>
    <author>
      <name>Anestis Vovos</name>
    </author>
    <author>
      <name>Jettie Hoonhout</name>
    </author>
    <author>
      <name>Dietmar Schuchardt</name>
    </author>
    <author>
      <name>Nikos Fakotakis</name>
    </author>
    <author>
      <name>Todor Ganchev</name>
    </author>
    <author>
      <name>Ilyas Potamitis</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Procedings of the LREC 2004 international conference, 26-28 May
  2004, Lisbon, Portugal. Pages 1603-1606</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0410063v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0410063v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.2;I.2.7;H.1.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0412074v1</id>
    <updated>2004-12-17T15:38:19Z</updated>
    <published>2004-12-17T15:38:19Z</published>
    <title>Threats of Human Error in a High-Performance Storage System: Problem
  Statement and Case Study</title>
    <summary>  System administration is a difficult, often tedious, job requiring many
skilled laborers. The data that is protected by system administrators is often
valued at or above the value of the institution maintaining that data. A number
of ethnographic studies have confirmed the skill of these operators, and the
difficulty of providing adequate tools. In an effort to minimize the
maintenance costs, an increasing portion of system administration is subject to
automation - particularly simple, routine tasks such as data backup. While such
tools reduce the risk of errors from carelessness, the same tools may result in
reduced skill and system familiarity in experienced workers. Care should be
taken to ensure that operators maintain system awareness without placing the
operator in a passive, monitoring role.
</summary>
    <author>
      <name>Elizabeth Haubert</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0412074v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0412074v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.1.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0505011v1</id>
    <updated>2005-05-04T16:17:54Z</updated>
    <published>2005-05-04T16:17:54Z</published>
    <title>SWiM: A Simple Window Mover</title>
    <summary>  As computers become more ubiquitous, traditional two-dimensional interfaces
must be replaced with interfaces based on a three-dimensional metaphor.
However, these interfaces must still be as simple and functional as their
two-dimensional predecessors. This paper introduces SWiM, a new interface for
moving application windows between various screens, such as wall displays,
laptop monitors, and desktop displays, in a three-dimensional physical
environment. SWiM was designed based on the results of initial "paper and
pencil" user tests of three possible interfaces. The results of these tests led
to a map-like interface where users select the destination display for their
application from various icons. If the destination is a mobile display it is
not displayed on the map. Instead users can select the screen's name from a
list of all possible destination displays. User testing of SWiM was conducted
to discover whether it is easy to learn and use. Users that were asked to use
SWiM without any instructions found the interface as intuitive to use as users
who were given a demonstration. The results show that SWiM combines simplicity
and functionality to create an interface that is easy to learn and easy to use.
</summary>
    <author>
      <name>Tony Chang</name>
    </author>
    <author>
      <name>Damon Cook</name>
    </author>
    <author>
      <name>Ramona Su</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0505011v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0505011v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0507019v1</id>
    <updated>2005-07-06T21:29:09Z</updated>
    <published>2005-07-06T21:29:09Z</published>
    <title>Making Space for Stories: Ambiguity in the Design of Personal
  Communication Systems</title>
    <summary>  Pervasive personal communication technologies offer the potential for
important social benefits for individual users, but also the potential for
significant social difficulties and costs. In research on face-to-face social
interaction, ambiguity is often identified as an important resource for
resolving social difficulties. In this paper, we discuss two design cases of
personal communication systems, one based on fieldwork of a commercial system
and another based on an unrealized design concept. The cases illustrate how
user behavior concerning a particular social difficulty, unexplained
unresponsiveness, can be influenced by technological issues that result in
interactional ambiguity. The cases also highlight the need to balance the
utility of ambiguity against the utility of usability and communicative
clarity.
</summary>
    <author>
      <name>Paul M. Aoki</name>
    </author>
    <author>
      <name>Allison Woodruff</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/1054972.1054998</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/1054972.1054998" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. ACM SIGCHI Conf. on Human Factors in Computing Systems,
  Portland, OR, Apr. 2005, 181-190. ACM Press.</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0507019v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0507019v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.4.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0508041v2</id>
    <updated>2006-06-29T06:41:15Z</updated>
    <published>2005-08-04T22:39:49Z</published>
    <title>OpenVanilla - A Non-Intrusive Plug-In Framework of Text Services</title>
    <summary>  Input method (IM) is a sine qua non for text entry of many Asian languages,
but its potential applications on other languages remain under-explored. This
paper proposes a philosophy of input method design by seeing it as a
nonintrusive plug-in text service framework. Such design allows new
functionalities of text processing to be attached onto a running application
without any tweaking of code. We also introduce OpenVanilla, a cross-platform
framework that is designed with the above-mentioned model in mind. Frameworks
like OpenVanilla have shown that an input method can be more than just a text
entry tool: it offers a convenient way for developing various text service and
language tools.
</summary>
    <author>
      <name>Tian-Jian Jiang</name>
    </author>
    <author>
      <name> Deng-Liu</name>
    </author>
    <author>
      <name>Kang-min Liu</name>
    </author>
    <author>
      <name>Weizhong Yang</name>
    </author>
    <author>
      <name>Pek-tiong Tan</name>
    </author>
    <author>
      <name>Mengjuei Hsieh</name>
    </author>
    <author>
      <name>Tsung-hsiang Chang</name>
    </author>
    <author>
      <name>Wen-Lien Hsu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0508041v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0508041v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0603121v1</id>
    <updated>2006-03-30T06:12:17Z</updated>
    <published>2006-03-30T06:12:17Z</published>
    <title>minimUML: A Minimalist Approach to UML Diagraming for Early Computer
  Science Education</title>
    <summary>  The Unified Modeling Language (UML) is commonly used in introductory Computer
Science to teach basic object-oriented design. However, there appears to be a
lack of suitable software to support this task. Many of the available programs
that support UML focus on developing code and not on enhancing learning. Those
that were designed for educational use sometimes have poor interfaces or are
missing common and important features, such as multiple selection and
undo/redo. There is a need for software that is tailored to an instructional
environment and has all the useful and needed functionality for that specific
task. This is the purpose of minimUML. minimUML provides a minimum amount of
UML, just what is commonly used in beginning programming classes, while
providing a simple, usable interface. In particular, minimUML was designed to
support abstract design while supplying features for exploratory learning and
error avoidance. In addition, it allows for the annotation of diagrams, through
text or freeform drawings, so students can receive feedback on their work.
minimUML was developed with the goal of supporting ease of use, supporting
novice students, and a requirement of no prior-training for its use.
</summary>
    <author>
      <name>Scott Turner</name>
    </author>
    <author>
      <name>Manuel A. Perez-Quinones</name>
    </author>
    <author>
      <name>Stephen H. Edwards</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">38 pages, 15 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0603121v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0603121v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="K.3.2; H.5.2; D.2.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0605122v1</id>
    <updated>2006-05-25T12:34:03Z</updated>
    <published>2006-05-25T12:34:03Z</published>
    <title>Modeling Hypermedia-Based Communication</title>
    <summary>  In this article, we explore two approaches to modeling hypermedia-based
communication. It is argued that the classical conveyor-tube framework is not
applicable to the case of computer- and Internet- mediated communication. We
then present a simple but very general system-theoretic model of the
communication process, propose its mathematical interpretation, and derive
several formulas, which qualitatively and quantitatively accord with data
obtained on-line. The devised theoretical results generalize and correct the
Zipf-Mandelbrot law and can be used in information system design. At the
paper's end, we give some conclusions and draw implications for future work.
</summary>
    <author>
      <name>V. V. Kryssanov</name>
    </author>
    <author>
      <name>K. Kakusho</name>
    </author>
    <author>
      <name>E. L. Kuleshov</name>
    </author>
    <author>
      <name>M. Minoh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">35 pages, 4 figures, 1 table. Preprint completed in 2004</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Information Sciences. 2005, Vol. 174/1-2, 37-53</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0605122v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0605122v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0606017v1</id>
    <updated>2006-06-05T03:39:09Z</updated>
    <published>2006-06-05T03:39:09Z</published>
    <title>From semiotics of hypermedia to physics of semiosis: A view from system
  theory</title>
    <summary>  Given that theoretical analysis and empirical validation is fundamental to
any model, whether conceptual or formal, it is surprising that these two tools
of scientific discovery are so often ignored in the contemporary studies of
communication. In this paper, we pursued the ideas of a) correcting and
expanding the modeling approaches of linguistics, which are otherwise
inapplicable (more precisely, which should not but are widely applied), to the
general case of hypermedia-based communication, and b) developing techniques
for empirical validation of semiotic models, which are nowadays routinely used
to explore (in fact, to conjecture about) internal mechanisms of complex
systems, yet on a purely speculative basis. This study thus offers two
experimentally tested substantive contributions: the formal representation of
communication as the mutually-orienting behavior of coupled autonomous systems,
and the mathematical interpretation of the semiosis of communication, which
together offer a concrete and parsimonious understanding of diverse
communication phenomena.
</summary>
    <author>
      <name>V. V. Kryssanov</name>
    </author>
    <author>
      <name>K. Kakusho</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">46 pages, 5 figures; 2003 preprint</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Semiotica. 2005, Vol.154-1/4, 11-38</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0606017v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0606017v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0608083v2</id>
    <updated>2006-09-14T03:57:25Z</updated>
    <published>2006-08-21T01:42:52Z</published>
    <title>Where's the "Party" in "Multi-Party"? Analyzing the Structure of
  Small-Group Sociable Talk</title>
    <summary>  Spontaneous multi-party interaction - conversation among groups of three or
more participants - is part of daily life. While automated modeling of such
interactions has received increased attention in ubiquitous computing research,
there is little applied research on the organization of this highly dynamic and
spontaneous sociable interaction within small groups. We report here on an
applied conversation analytic study of small-group sociable talk, emphasizing
structural and temporal aspects that can inform computational models. In
particular, we examine the mechanics of multiple simultaneous conversational
floors - how participants initiate a new floor amidst an on-going floor, and
how they subsequently show their affiliation with one floor over another. We
also discuss the implications of these findings for the design of "smart"
multi-party applications.
</summary>
    <author>
      <name>Paul M. Aoki</name>
    </author>
    <author>
      <name>Margaret H. Szymanski</name>
    </author>
    <author>
      <name>Luke Plurkowski</name>
    </author>
    <author>
      <name>James D. Thornton</name>
    </author>
    <author>
      <name>Allison Woodruff</name>
    </author>
    <author>
      <name>Weilie Yi</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/1180875.1180934</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/1180875.1180934" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. ACM Conf. on Computer Supported Cooperative Work, Banff,
  Alberta, Canada, Nov. 2006, 393-402. ACM Press.</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0608083v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0608083v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0611153v2</id>
    <updated>2007-02-01T09:02:33Z</updated>
    <published>2006-11-29T16:55:30Z</published>
    <title>Changing our view on design evaluation meetings methodology: a study of
  software technical review meetings</title>
    <summary>  By contrast to design meetings, design evaluation meetings (DEMs) have
generally been considered as situations in which, according to DEMs
methodologies, design activities are quite marginal. In a study of DEMs in
software development, i.e. in technical review meetings following a particular
review methodology, we showed: (i) the occurrence of design activities as part
of an argumentation process; (ii) the relative importance of cognitive
synchronisation as a prerequisite for evaluation; (iii) the important role
played in evaluation by argumentation that makes explicit the underlying design
rationale (DR). On the basis of our results, we discuss the potential for using
DR methodologies in this kind of meetings.
</summary>
    <author>
      <name>Patrick D'Astous</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA</arxiv:affiliation>
    </author>
    <author>
      <name>Françoise Détienne</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA</arxiv:affiliation>
    </author>
    <author>
      <name>Willemien Visser</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA</arxiv:affiliation>
    </author>
    <author>
      <name>Pierre Robillard</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Design Studies (2004)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0611153v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0611153v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0611159v2</id>
    <updated>2007-02-01T18:59:25Z</updated>
    <published>2006-11-30T09:50:30Z</published>
    <title>Cognitive Effort in Collective Software Design: Methodological
  Perspectives in Cognitive Ergonomics</title>
    <summary>  Empirical software engineering is concerned with measuring, or estimating,
both the effort put into the software process and the quality of its product.
We defend the idea that measuring process effort and product quality and
establishing a relation between the two cannot be performed without a model of
cognitive and collective activities involved in software design, and without
measurement of these activities. This is the object of our field, i.e.
Cognitive Ergonomics of design. After a brief presentation of its theoretical
and methodological foundations, we will discuss a cognitive approach to design
activities and its potential to provide new directions in ESE. Then we will
present and discuss an illustration of the methodological directions we have
proposed for the analysis and measurement of cognitive activities in the
context of collective software design. The two situations analysed are
technical review meetings, and Request For Comments-like procedures in Open
Source Software design.
</summary>
    <author>
      <name>Françoise Détienne</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA</arxiv:affiliation>
    </author>
    <author>
      <name>Jean-Marie Burkhardt</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA</arxiv:affiliation>
    </author>
    <author>
      <name>Willemien Visser</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Dans 2nd Workshop on Empirical Software Engineering (2003) 17-25</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0611159v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0611159v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0612005v2</id>
    <updated>2007-03-02T13:53:03Z</updated>
    <published>2006-11-30T22:43:22Z</published>
    <title>Quantitative Measurements of the Influence of Participant Roles during
  Peer Review Meetings</title>
    <summary>  Peer review meetings (PRMs) are formal meetings during which peers
systematically analyze artifacts to improve their quality and report on
non-conformities. This paper presents an approach based on protocol analysis
for quantifying the influence of participant roles during PRMs. Three views are
used to characterize the seven defined participant roles. The project view
defines three roles supervisor, procedure expert and developer. The meeting
view defines two roles: author and reviewer, and the task view defines the
roles reflecting direct and indirect interest in the artifact under review. The
analysis, based on log-linear modeling, shows that review activities have
different patterns, depending on their focus: form or content. The influence of
each role is analyzed with respect to this focus. Interpretation of the
quantitative data leads to the suggestion that PRMs could be improved by
creating three different types of reviews, each of which collects together
specific roles: form review, cognitive synchronization review and content
review.
</summary>
    <author>
      <name>Patrick D'Astous</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA</arxiv:affiliation>
    </author>
    <author>
      <name>Pierre Robillard</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA</arxiv:affiliation>
    </author>
    <author>
      <name>Françoise Détienne</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA</arxiv:affiliation>
    </author>
    <author>
      <name>Willemien Visser</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rocquencourt</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Empirical Software Engineering 6 (2001) 143-159</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0612005v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0612005v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0612006v1</id>
    <updated>2006-11-30T22:49:11Z</updated>
    <published>2006-11-30T22:49:11Z</published>
    <title>Evocation and elaboration of solutions: Different types of
  problem-solving actions. An empirical study on the design of an aerospace
  artifact</title>
    <summary>  An observational study was conducted on a professional designer working on a
design project in aerospace industry. The protocol data were analyzed in order
to gain insight into the actions the designer used for the development of a
solution to the corresponding problem. Different processes are described: from
the "simple" evocation of a solution existing in memory, to the elaboration of
a "new" solution out of mnesic entities without any clear link to the current
problem. Control is addressed in so far as it concerns the priority among the
different types of development processes: the progression from evocation of a
"standard" solution to elaboration of a "new" solution is supposed to
correspond to the resulting order, that is, the one in which the designer's
activity proceeds. Short discussions of * the double status of "problem" and
"solution," * the problem/solution knowledge units in memory and their access,
and * the different abstraction levels on which problem and solution
representations are developed, are illustrated by the results.
</summary>
    <author>
      <name>Willemien Visser</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rocquencourt</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Dans COGNITIVA 90. At the crossroads of Artificial Intelligence,
  Cognitive science, and Neuroscience (1991) 689-696</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0612006v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0612006v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0612008v2</id>
    <updated>2007-03-02T13:53:45Z</updated>
    <published>2006-12-01T11:42:02Z</published>
    <title>Design Strategies and Knowledge in Object-Oriented Programming: Effects
  of Experience</title>
    <summary>  An empirical study was conducted to analyse design strategies and knowledge
used in object-oriented software design. Eight professional programmers
experienced with procedural programming languages and either experienced or not
experienced in object-oriented design strategies related to two central aspects
of the object-oriented paradigm: (1) associating actions, i.e., execution
steps, of a complex plan to different objects and revising a complex plan, and
(2) defining simple plans at different levels in the class hierarchy. As
regards the development of complex plans elements attached to different
objects, our results show that, for beginners in OOP, the description of
objects and the description of actions are not always integrated in an early
design phase, particularly for the declarative problem whereas, for the
programmers experienced in OOP, the description of objects and the description
of actions tend to be integrated in their first drafts of solutions whichever
the problem type. The analysis of design strategies reveal the use of different
knowledge according to subjects' language experience: (1) schemas related to
procedural languages; actions are organized in an execution order, or (2)
schemas related to object-oriented languages; actions and objects are
integrated, and actions are organised around objects.
</summary>
    <author>
      <name>Françoise Détienne</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Human-Computer Interaction 10, 2-3 (1995) 129-170</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0612008v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0612008v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0612009v1</id>
    <updated>2006-12-01T11:42:44Z</updated>
    <published>2006-12-01T11:42:44Z</published>
    <title>Users' participation to the design process in an Open Source Software
  online community</title>
    <summary>  The objective of this research is to analyse the ways members of open-source
software communities participate in design. In particular we focus on how users
of an Open Source (OS) programming language (Python) participate in adding new
functionalities to the language. Indeed, in the OS communities, users are
highly skilled in computer sciences; they do not correspond to the common
representation of end-users and can potentially participate to the design
process. Our study characterizes the Python galaxy and analyses a formal
process to introduce new functionalities to the language called Python
Enhancement Proposal (PEP) from the idea of language evolution to the PEP
implementation. The analysis of a particular pushed-by-users PEP from one
application domain community (financial), shows: that the design process is
distributed and specialized between online and physical interactions spaces;
and there are some cross participants between users and developers communities
which may reveal boundary spanners roles.
</summary>
    <author>
      <name>Flore Barcellini</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rocquencourt</arxiv:affiliation>
    </author>
    <author>
      <name>Françoise Détienne</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rocquencourt</arxiv:affiliation>
    </author>
    <author>
      <name>Jean-Marie Burkhardt</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LEI</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Dans 18th Annual Workshop on Psychology of Programming Interest
  Group PPIG'05 (2006) 99-114</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0612009v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0612009v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0612017v2</id>
    <updated>2007-03-02T12:49:22Z</updated>
    <published>2006-12-04T13:49:09Z</published>
    <title>Confrontation of viewpoints in a concurrent engineering process</title>
    <summary>  We present an empirical study aimed at analysing the use of viewpoints in an
industrial Concurrent Engineering context. Our focus is on the viewpoints
expressed in the argumentative process taking place in evaluation meetings. Our
results show that arguments enabling a viewpoint or proposal to be defended are
often characterized by the use of constraints. One result involved the way in
which the proposals for solutions are assessed during these meetings. We have
revealed the existence of specific assessment modes in these meetings as well
as their combination. Then, we show that, even if some constraints are
apparently identically used by the different specialists involved in meetings,
various meanings and weightings are associated with these constraints by these
different specialists.
</summary>
    <author>
      <name>Géraldine Martin</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA</arxiv:affiliation>
    </author>
    <author>
      <name>Françoise Détienne</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA</arxiv:affiliation>
    </author>
    <author>
      <name>Elisabeth Lavigne</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Integrated design and manufacturing in mechanical
  engineeringKluwer Academic Publishers (Ed.) (2002)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0612017v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0612017v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0612018v2</id>
    <updated>2007-03-02T12:49:52Z</updated>
    <published>2006-12-04T13:50:07Z</published>
    <title>Mental Representations Constructed by Experts and Novices in
  Object-Oriented Program Comprehension</title>
    <summary>  Previous studies on program comprehension were carried out largely in the
context of procedural languages. Our purpose is to develop and evaluate a
cognitive model of object-oriented (OO) program understanding. Our model is
based on the van Dijk and Kintsch's model of text understanding (1983). One key
aspect of this theoretical approach is the distinction between two kinds of
representation the reader might construct from a text: the textbase and the
situation model. On the basis of results of an experiment we have conducted, we
evaluate the cognitive validity of this distinction in OO program
understanding. We examine how the construction of these two representations is
differentially affected by the programmer's expertise and how they evolve
differentially over time.
</summary>
    <author>
      <name>Jean-Marie Burkhardt</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA, LEI</arxiv:affiliation>
    </author>
    <author>
      <name>Françoise Détienne</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA</arxiv:affiliation>
    </author>
    <author>
      <name>Susan Wiedenbeck</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Dans Human-Computer Interaction, INTERACT'97 (1997)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0612018v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0612018v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0612023v2</id>
    <updated>2007-03-02T12:51:02Z</updated>
    <published>2006-12-04T18:45:55Z</published>
    <title>Reusing processes and documenting processes: toward an integrated
  framework</title>
    <summary>  This paper presents a cognitive typology of reuse processes, and a cognitive
typology of documenting processes. Empirical studies on design with reuse and
on software documenting provide evidence for a generalized cognitive model.
First, these studies emphasize the cyclical nature of design: cycles of
planning, writing and revising occur. Second, natural language documentation
follows the hierarchy of cognitive entities manipulated during design.
Similarly software reuse involves exploiting various types of knowledge
depending on the phase of design in which reuse is involved. We suggest that
these observations can be explained based on cognitive models of text
processing: the van Dijk and Kintsch (1983) model of text comprehension, and
the Hayes and Flower (1980) model of text production. Based on our generalized
cognitive model, we suggest a framework for documenting reusable components.
</summary>
    <author>
      <name>Françoise Détienne</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA</arxiv:affiliation>
    </author>
    <author>
      <name>Jean-François Rouet</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA, LEI</arxiv:affiliation>
    </author>
    <author>
      <name>Jean-Marie Burkhardt</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA, LEI</arxiv:affiliation>
    </author>
    <author>
      <name>Catherine Deleuze-Dordron</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Dans ECCE8 (1996) 139-144</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0612023v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0612023v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0612047v1</id>
    <updated>2006-12-07T23:41:51Z</updated>
    <published>2006-12-07T23:41:51Z</published>
    <title>Social Browsing on Flickr</title>
    <summary>  The new social media sites - blogs, wikis, del.icio.us and Flickr, among
others - underscore the transformation of the Web to a participatory medium in
which users are actively creating, evaluating and distributing information. The
photo-sharing site Flickr, for example, allows users to upload photographs,
view photos created by others, comment on those photos, etc. As is common to
other social media sites, Flickr allows users to designate others as
``contacts'' and to track their activities in real time. The contacts (or
friends) lists form the social network backbone of social media sites. We claim
that these social networks facilitate new ways of interacting with information,
e.g., through what we call social browsing. The contacts interface on Flickr
enables users to see latest images submitted by their friends. Through an
extensive analysis of Flickr data, we show that social browsing through the
contacts' photo streams is one of the primary methods by which users find new
images on Flickr. This finding has implications for creating personalized
recommendation systems based on the user's declared contacts lists.
</summary>
    <author>
      <name>Kristina Lerman</name>
    </author>
    <author>
      <name>Laurie Jones</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages; submitted to the International Conference on Weblogs and
  Social Media</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0612047v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0612047v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0612081v1</id>
    <updated>2006-12-18T07:53:34Z</updated>
    <published>2006-12-18T07:53:34Z</published>
    <title>Personal Information Ecosystems and Implications for Design</title>
    <summary>  Today, people use multiple devices to fulfill their information needs.
However, designers design each device individually, without accounting for the
other devices that users may also use. In many cases, the applications on all
these devices are designed to be functional replicates of each other. We argue
that this results in an over-reliance on data synchronization across devices,
version control nightmares, and increased burden of file management. In this
paper, we present the idea of a \textit{personal information ecosystem}, an
analogy to biological ecosystems, which allows us to discuss the
inter-relationships among these devices to fulfill the information needs of the
user. There is a need for designers to design devices as part of a complete
ecosystem, not as independent devices that simply share data replicated across
them. To help us understand this domain and to facilitate the dialogue and
study of such systems, we present the terminology, classifications of the
interdependencies among different devices, and resulting implications for
design.
</summary>
    <author>
      <name>Manas Tungare</name>
    </author>
    <author>
      <name>Pardha S. Pyla</name>
    </author>
    <author>
      <name>Manuel Pérez-Quiñones</name>
    </author>
    <author>
      <name>Steve Harrison</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0612081v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0612081v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0612090v1</id>
    <updated>2006-12-18T22:24:02Z</updated>
    <published>2006-12-18T22:24:02Z</published>
    <title>A Review of Papers that have a bearing on an Analysis of User
  Interactions in A Collaborative On-line Laboratory</title>
    <summary>  A number of papers have been reviewed in the areas of HCI, CSCW, CSCL. These
have been analyzed with a view to extract the ideas relevant to a consideration
of user interactions in a collaborative on line laboratory which is being under
development for use in the ITO BSc course at Southampton University. The
construction of new theoretical models is to be based upon principles of
collaborative HCI design and constructivist and situational educational theory.
An investigation of the review papers it is hoped will lead towards a
methodology/framework that can be used as guidance for collaborative learning
systems and these will need to be developed alongside the requirements as they
change during the development cycles. The primary outcome will be the analysis
and re-design of the online e-learning laboratory together with a measure of
its efficacy in the learning process.
</summary>
    <author>
      <name>Vita Hinze-Hoare</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0612090v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0612090v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0702001v1</id>
    <updated>2007-02-01T09:01:55Z</updated>
    <published>2007-02-01T09:01:55Z</published>
    <title>Measuring Cognitive Activities in Software Engineering</title>
    <summary>  This paper presents an approach to the study of cognitive activities in
collaborative software development. This approach has been developed by a
multidisciplinary team made up of software engineers and cognitive
psychologists. The basis of this approach is to improve our understanding of
software development by observing professionals at work. The goal is to derive
lines of conduct or good practices based on observations and analyses of the
processes that are naturally used by software engineers. The strategy involved
is derived from a standard approach in cognitive science. It is based on the
videotaping of the activities of software engineers, transcription of the
videos, coding of the transcription, defining categories from the coded
episodes and defining cognitive behaviors or dialogs from the categories. This
project presents two original contributions that make this approach generic in
software engineering. The first contribution is the introduction of a formal
hierarchical coding scheme, which will enable comparison of various types of
observations. The second is the merging of psychological and statistical
analysis approaches to build a cognitive model. The details of this new
approach are illustrated with the initial data obtained from the analysis of
technical review meetings.
</summary>
    <author>
      <name>Pierre Robillard</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA</arxiv:affiliation>
    </author>
    <author>
      <name>Patrick D'Astous</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA</arxiv:affiliation>
    </author>
    <author>
      <name>Françoise Détienne</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA</arxiv:affiliation>
    </author>
    <author>
      <name>Willemien Visser</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Dans ICSE98, 20th International Conference on Software Engineering
  (1998)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0702001v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0702001v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0702002v1</id>
    <updated>2007-02-01T09:02:17Z</updated>
    <published>2007-02-01T09:02:17Z</published>
    <title>The Effect of Object-Oriented Programming Expertise in Several
  Dimensions of Comprehension Strategies</title>
    <summary>  This study analyzes object-oriented (OO) program comprehension by experts and
novices. We examine the effect of expertise in three dimensions of
comprehension strategies: the scope of the comprehension, the top-down versus
bottom-up direction of the processes, and the guidance of the comprehension
activity. Overall, subjects were similar in the scope of their comprehension,
although the experts tended to consult more files. We found strong evidence of
top-down, inference-driven behaviors, as well as multiple guidance in expert
comprehension. We also found evidence of execution-based guidance and less use
of top-down processes in novice comprehension. Guidance by inheritance and
composition relationships in the OO program was not dominant, but nevertheless
played a substantial role in expert program comprehension. However, these
static relationships more closely tied to the OO nature of the program were
exploited poorly by novices. To conclude, these results are discussed with
respect to the literature on procedural program comprehension.
</summary>
    <author>
      <name>Jean-Marie Burkhardt</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA, LEI</arxiv:affiliation>
    </author>
    <author>
      <name>Françoise Détienne</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA</arxiv:affiliation>
    </author>
    <author>
      <name>Susan Wiedenbeck</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Dans IWPC'98, Sixth International Workshop on Program
  Comprehension (1998)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0702002v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0702002v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0702006v1</id>
    <updated>2007-02-01T09:05:13Z</updated>
    <published>2007-02-01T09:05:13Z</published>
    <title>Negotiation in collaborative assessment of design solutions: an
  empirical study on a Concurrent Engineering process</title>
    <summary>  In Concurrent engineering, design solutions are not only produced by
individuals specialized in a given field. Due to the team nature of the design
activity, solutions are negotiated. Our objective is to analyse the
argumentation processes leading to these negotiated solutions. These processes
take place in the meetings which group together specialists with a co-design
aim. We conducted cognitive ergonomics research work during the definition
phase of an aeronautical design project in which the participants work in
Concurrent Engineering. We recorded, retranscribed and analysed 7
multi-speciality meetings. These meetings were organised, as needed, to assess
the integration of the solutions of each speciality into a global solution. We
found that there are three main design proposal assessment modes which can be
combined in these meetings: (a) analytical assessment mode, (b) comparative
assessment mode (c) analogical assessment mode. Within these assessment modes,
different types of arguments are used. Furthermore we found a typical temporal
negotiation process.
</summary>
    <author>
      <name>Géraldine Martin</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA</arxiv:affiliation>
    </author>
    <author>
      <name>Françoise Détienne</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA</arxiv:affiliation>
    </author>
    <author>
      <name>Elisabeth Lavigne</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Dans CE'2000, International Conference on Concurrent Engineering
  (2000)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0702006v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0702006v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0703008v1</id>
    <updated>2007-03-02T12:50:12Z</updated>
    <published>2007-03-02T12:50:12Z</published>
    <title>Strategies in object-oriented design</title>
    <summary>  This paper presents a study aiming to analyse the design strategies of
experts in object-oriented programming. We report an experiment conducted with
four experts. Each subject solved three problems. Our results show that three
strategies may be used in program design according to the solution structure.
An object-centred strategy and a function-centred strategy are used when the
solution has a hierarchical structure with vertical communication between
objects. In this case, the plan which guides the design activity is
declarative. A procedure-centred strategy is used when the solution has a flat
structure with horizontal communication between objects. In this case, the plan
which guides the design activity is procedural. These results are discussed in
relation with results on design strategies in procedural design. Furthermore,
our results provide insight into the knowledge structures of experts in
object-oriented design. To conclude, we point out limitations of this study and
discuss implications of our results for Human-Computer Interaction systems, in
particular for systems assisting experts in their design activity.
</summary>
    <author>
      <name>Sophie Chatel</name>
    </author>
    <author>
      <name>Françoise Détienne</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Acta Psychologica 91 (1996) 245-269</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0703008v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0703008v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0703044v1</id>
    <updated>2007-03-09T16:55:23Z</updated>
    <published>2007-03-09T16:55:23Z</published>
    <title>BrlAPI: Simple, Portable, Concurrent, Application-level Control of
  Braille Terminals</title>
    <summary>  Screen readers can drive braille devices for allowing visually impaired users
to access computer environments, by providing them the same information as
sighted users. But in some cases, this view is not easy to use on a braille
device. In such cases, it would be much more useful to let applications provide
their own braille feedback, specially adapted to visually impaired users. Such
applications would then need the ability to output braille ; however, allowing
both screen readers and applications access a wide panel of braille devices is
not a trivial task. We present an abstraction layer that applications may use
to communicate with braille devices. They do not need to deal with the
specificities of each device, but can do so if necessary. We show how several
applications can communicate with one braille device concurrently, with BrlAPI
making sensible choices about which application eventually gets access to the
device. The description of a widely used implementation of BrlAPI is included.
</summary>
    <author>
      <name>Samuel Thibault</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Futurs</arxiv:affiliation>
    </author>
    <author>
      <name>Sebastien Hinderer</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Lorraine - LORIA</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Dans International Conference on Information and Communication
  Technology Accessibility (ICTA) (2007)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0703044v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0703044v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0703070v3</id>
    <updated>2007-05-02T19:04:48Z</updated>
    <published>2007-03-15T00:00:06Z</published>
    <title>Flexible Audio Streams</title>
    <summary>  Tremendous research effort was invested in audio browsers and machine
learning techniques to decode the structure of Web pages in order to put them
into an audio format. In this paper, we address a simpler and efficient
solution for the creation of an audio browser of VOICEXML generated from
RSS/Atom stream feeds. We developed a multimodal (audio and graphical) portal
application that offers RSS/Atom feeds. By utilizing sing our system, the user
can interact using voice or graphic commands, listen and watch digital content,
such as news, blogs feeds, podcasts, and even access email and personal
schedules. The portal system permits the use of security credentials
(user/password authentication) to collect secure RSS/Atom stream in the
multimodal browser to connect the user to specific personal services. A series
experiments have been conducted to evaluate the performance of the RSS reader
and navigator. Our system is extremely beneficial for a wide range of
applications, from interfaces for the visual impaired users to browsers for
mobile telephonic interfaces.
</summary>
    <author>
      <name>Paul Fodor</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0703070v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0703070v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0704.3662v1</id>
    <updated>2007-04-27T05:34:10Z</updated>
    <published>2007-04-27T05:34:10Z</published>
    <title>An Automated Evaluation Metric for Chinese Text Entry</title>
    <summary>  In this paper, we propose an automated evaluation metric for text entry. We
also consider possible improvements to existing text entry evaluation metrics,
such as the minimum string distance error rate, keystrokes per character, cost
per correction, and a unified approach proposed by MacKenzie, so they can
accommodate the special characteristics of Chinese text. Current methods lack
an integrated concern about both typing speed and accuracy for Chinese text
entry evaluation. Our goal is to remove the bias that arises due to human
factors. First, we propose a new metric, called the correction penalty (P),
based on Fitts' law and Hick's law. Next, we transform it into the approximate
amortized cost (AAC) of information theory. An analysis of the AAC of Chinese
text input methods with different context lengths is also presented.
</summary>
    <author>
      <name>Mike Tian-Jian Jiang</name>
    </author>
    <author>
      <name>James Zhan</name>
    </author>
    <author>
      <name>Jaimie Lin</name>
    </author>
    <author>
      <name>Jerry Lin</name>
    </author>
    <author>
      <name>Wen-Lien Hsu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Jiang, Mike Tian-Jian, et al. "Robustness analysis of adaptive
  chinese input methods." Advances in Text Input Methods (WTIM 2011) (2011): 53</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0704.3662v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0704.3662v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0705.0599v3</id>
    <updated>2007-06-21T13:32:58Z</updated>
    <published>2007-05-04T11:50:07Z</published>
    <title>NodeTrix: Hybrid Representation for Analyzing Social Networks</title>
    <summary>  The need to visualize large social networks is growing as hardware
capabilities make analyzing large networks feasible and many new data sets
become available. Unfortunately, the visualizations in existing systems do not
satisfactorily answer the basic dilemma of being readable both for the global
structure of the network and also for detailed analysis of local communities.
To address this problem, we present NodeTrix, a hybrid representation for
networks that combines the advantages of two traditional representations:
node-link diagrams are used to show the global structure of a network, while
arbitrary portions of the network can be shown as adjacency matrices to better
support the analysis of communities. A key contribution is a set of interaction
techniques. These allow analysts to create a NodeTrix visualization by dragging
selections from either a node-link or a matrix, flexibly manipulate the
NodeTrix representation to explore the dataset, and create meaningful summary
visualizations of their findings. Finally, we present a case study applying
NodeTrix to the analysis of the InfoVis 2004 coauthorship dataset to illustrate
the capabilities of NodeTrix as both an exploration tool and an effective means
of communicating results.
</summary>
    <author>
      <name>Nathalie Henry</name>
    </author>
    <author>
      <name>Jean-Daniel Fekete</name>
    </author>
    <author>
      <name>Michael Mcguffin</name>
    </author>
    <link href="http://arxiv.org/abs/0705.0599v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0705.0599v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0705.1395v1</id>
    <updated>2007-05-10T06:54:11Z</updated>
    <published>2007-05-10T06:54:11Z</published>
    <title>Subjective Evaluation of Forms in an Immersive Environment</title>
    <summary>  User's perception of product, by essence subjective, is a major topic in
marketing and industrial design. Many methods, based on users' tests, are used
so as to characterise this perception. We are interested in three main methods:
multidimensional scaling, semantic differential method, and preference mapping.
These methods are used to built a perceptual space, in order to position the
new product, to specify requirements by the study of user's preferences, to
evaluate some product attributes, related in particular to style (aesthetic).
These early stages of the design are primordial for a good orientation of the
project. In parallel, virtual reality tools and interfaces are more and more
efficient for suggesting to the user complex feelings, and creating in this way
various levels of perceptions. In this article, we present on an example the
use of multidimensional scaling, semantic differential method and preference
mapping for the subjective assessment of virtual products. These products,
which geometrical form is variable, are defined with a CAD model and are
proposed to the user with a spacemouse and stereoscopic glasses. Advantages and
limitations of such evaluation is next discussed..
</summary>
    <author>
      <name>Jean-François Petiot</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IRCCyN</arxiv:affiliation>
    </author>
    <author>
      <name>Damien Chablat</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IRCCyN</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Virtual Concept (2003) 1-6</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0705.1395v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0705.1395v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0706.1087v1</id>
    <updated>2007-06-07T21:23:40Z</updated>
    <published>2007-06-07T21:23:40Z</published>
    <title>On Anomalies in Annotation Systems</title>
    <summary>  Today's computer-based annotation systems implement a wide range of
functionalities that often go beyond those available in traditional
paper-and-pencil annotations. Conceptually, annotation systems are based on
thoroughly investigated psycho-sociological and pedagogical learning theories.
They offer a huge diversity of annotation types that can be placed in textual
as well as in multimedia format. Additionally, annotations can be published or
shared with a group of interested parties via well-organized repositories.
Although highly sophisticated annotation systems exist both conceptually as
well as technologically, we still observe that their acceptance is somewhat
limited. In this paper, we argue that nowadays annotation systems suffer from
several fundamental problems that are inherent in the traditional
paper-and-pencil annotation paradigm. As a solution, we propose to shift the
annotation paradigm for the implementation of annotation system.
</summary>
    <author>
      <name>Matthias R. Brust</name>
    </author>
    <author>
      <name>Steffen Rothkugel</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The Third International Workshop on E-learning and Mobile Learning on
  Telecommunications (ELETE 2007)</arxiv:comment>
    <link href="http://arxiv.org/abs/0706.1087v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0706.1087v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0706.1780v1</id>
    <updated>2007-06-12T20:06:38Z</updated>
    <published>2007-06-12T20:06:38Z</published>
    <title>Le travail collaboratif dans le cadre d'un projet architectural</title>
    <summary>  The analysis of the practices and the tendencies of the users at the time of
the search for information on Internet makes it possible to highlight several
points. The search for information becomes powerful after knowledge of the
typology of the various systems of research. This typology supports the
adoption of a methodology of research which one can characterize by pull
systems, intelligent agents, etc. In addition, the importance of the structure
of the electronic document, correctly elaborated in advance, will support a
higher relevance ratio to find information. In our article, the problems turn
around the study of the behavior of the users in situation of search for
information, as well as the constitution of a pole of documentary resources
within a framework of an architectural project. It is noted that the evolution
of the documentary resources is related to information technologies.
</summary>
    <author>
      <name>Marie-France Ango-Obiang</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">SITE, Loria</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Dans Innovation et tradition de l'association internationale
  Management Strat\'egique (2007)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0706.1780v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0706.1780v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0706.3165v1</id>
    <updated>2007-06-21T14:40:25Z</updated>
    <published>2007-06-21T14:40:25Z</published>
    <title>A solution for actors' viewpoints representation with collaborative
  product development</title>
    <summary>  As product complexity and marketing competition increase, a collaborative
product development is necessary for companies which develop high quality
products in short lead-times. To support product actors from different fields,
disciplines, and locations, wishing to exchange and share information, the
representation of the actors' viewpoints is the underlying requirement of the
collaborative product development. The actors' viewpoints approach was designed
to provide an organisational framework following the actors' perspectives in
the collaboration, and their relationships, could be explicitly gathered and
formatted. The approach acknowledges the inevitability of multiple integration
of product information as different views, promotes gathering of actors'
interests, and encourages retrieved adequate information while providing
support for integration through PLM and/or SCM collaboration. In this paper, a
solution for neutral viewpoints representation is proposed. The product,
process, and organisation information models are seriatim discussed. A series
of issues referring to the viewpoints representation are discussed in detail.
Based on XML standard, taking cyclone vessel as an example, an application case
of part of product information modelling is stated.
</summary>
    <author>
      <name>Hichem Geryville</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIESP</arxiv:affiliation>
    </author>
    <author>
      <name>Abdelaziz Bouras</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIESP</arxiv:affiliation>
    </author>
    <author>
      <name>Yacine Ouzrout</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIESP</arxiv:affiliation>
    </author>
    <author>
      <name>Nikolaos Sapidis</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-2-287-48370-7</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-2-287-48370-7" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ISBN: 2-287-48363-9</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Research in Interactive Design (2007) 39-40</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0706.3165v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0706.3165v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0707.1480v1</id>
    <updated>2007-07-10T16:01:30Z</updated>
    <published>2007-07-10T16:01:30Z</published>
    <title>IRVO: an Interaction Model for designing Collaborative Mixed Reality
  systems</title>
    <summary>  This paper presents an interaction model adapted to mixed reality
environments known as IRVO (Interacting with Real and Virtual Objects). IRVO
aims at modeling the interaction between one or more users and the Mixed
Reality system by representing explicitly the objects and tools involved and
their relationship. IRVO covers the design phase of the life cycle and models
the intended use of the system. In a first part, we present a brief review of
related HCI models. The second part is devoted to the IRVO model, its notation
and some examples. In the third part, we present how IRVO is used for designing
applications and in particular we show how this model can be integrated in a
Model-Based Approach (CoCSys) which is currently designed at our lab.
</summary>
    <author>
      <name>René Chalon</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">ICTT</arxiv:affiliation>
    </author>
    <author>
      <name>Bertrand T. David</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">ICTT</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Human Computer International 2005, U.S. CD (11/08/2005) 1-10</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0707.1480v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0707.1480v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0708.3341v1</id>
    <updated>2007-08-24T13:33:38Z</updated>
    <published>2007-08-24T13:33:38Z</published>
    <title>Browsing through 3D representations of unstructured picture collections:
  an empirical study</title>
    <summary>  The paper presents a 3D interactive representation of fairly large picture
collections which facilitates browsing through unstructured sets of icons or
pictures. Implementation of this representation implies choosing between two
visualization strategies: users may either manipulate the view (OV) or be
immersed in it (IV). The paper first presents this representation, then
describes an empirical study (17 participants) aimed at assessing the utility
and usability of each view. Subjective judgements in questionnaires and
debriefings were varied: 7 participants preferred the IV view, 4 the OV one,
and 6 could not choose between the two. Visual acuity and visual exploration
strategies seem to have exerted a greater influence on participants'
preferences than task performance or feeling of immersion.
</summary>
    <author>
      <name>Olivier Christmann</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rocquencourt / INRIA Lorraine - LORIA</arxiv:affiliation>
    </author>
    <author>
      <name>Noëlle Carbonell</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rocquencourt / INRIA Lorraine - LORIA</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Dans Proceedings of ACM Working Conference on Advanced Visual
  Interfaces (AVI 2006), Venezia, Italy, May 23-26, 2006 - ACM Working
  Conference on Advanced Visual Interfaces (AVI 2006), Venezia : Italie (2006)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0708.3341v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0708.3341v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0708.3505v1</id>
    <updated>2007-08-26T18:53:41Z</updated>
    <published>2007-08-26T18:53:41Z</published>
    <title>Gaze as a Supplementary Modality for Interacting with Ambient
  Intelligence Environments</title>
    <summary>  We present our current research on the implementation of gaze as an efficient
and usable pointing modality supplementary to speech, for interacting with
augmented objects in our daily environment or large displays, especially
immersive virtual reality environments, such as reality centres and caves. We
are also addressing issues relating to the use of gaze as the main interaction
input modality. We have designed and developed two operational user interfaces:
one for providing motor-disabled users with easy gaze-based access to map
applications and graphical software; the other for iteratively testing and
improving the usability of gaze-contingent displays.
</summary>
    <author>
      <name>Daniel Gepner</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rocquencourt / INRIA Lorraine - LORIA</arxiv:affiliation>
    </author>
    <author>
      <name>Jérôme Simonin</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rocquencourt / INRIA Lorraine - LORIA</arxiv:affiliation>
    </author>
    <author>
      <name>Noëlle Carbonell</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rocquencourt / INRIA Lorraine - LORIA</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Dans Universal Access to Ambient Interaction, Springer-Verlag,
  LNCS-LNAI Series, number 4555 - 12th International Conference on
  Human-Computer Interaction (HCI Internatinal 2007), Beijing : China (2007)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0708.3505v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0708.3505v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0708.3575v1</id>
    <updated>2007-08-27T11:53:35Z</updated>
    <published>2007-08-27T11:53:35Z</published>
    <title>How really effective are Multimodal Hints in enhancing Visual Target
  Spotting? Some evidence from a usability study</title>
    <summary>  The main aim of the work presented here is to contribute to computer science
advances in the multimodal usability area, in-as-much as it addresses one of
the major issues relating to the generation of effective oral system messages:
how to design messages which effectively help users to locate specific
graphical objects in information visualisations? An experimental study was
carried out to determine whether oral messages including coarse information on
the locations of graphical objects on the current display may facilitate target
detection tasks sufficiently for making it worth while to integrate such
messages in GUIs. The display spatial layout varied in order to test the
influence of visual presentation structure on the contribution of these
messages to facilitating visual search on crowded displays. Finally, three
levels of task difficulty were defined, based mainly on the target visual
complexity and the number of distractors in the scene. The findings suggest
that spatial information messages improve participants' visual search
performances significantly; they are more appropriate to radial structures than
to matrix, random and elleptic structures; and, they are particularly useful
for performing difficult visual search tasks.
</summary>
    <author>
      <name>Suzanne Kieffer</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rocquencourt / INRIA Lorraine - LORIA</arxiv:affiliation>
    </author>
    <author>
      <name>Noëlle Carbonell</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rocquencourt / INRIA Lorraine - LORIA</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal on Multimodal Interaction (JMUI), 1 (2007) 1-9</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0708.3575v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0708.3575v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0708.3740v1</id>
    <updated>2007-08-28T09:56:05Z</updated>
    <published>2007-08-28T09:56:05Z</published>
    <title>Plate-forme Magicien d'Oz pour l'étude de l'apport des ACAs à
  l'interaction</title>
    <summary>  In order to evaluate the contribution of Embodied (Animated) Conversational
Agents (ECAs) to the effectiveness and usability of human-computer interaction,
we developed a software platform meant to collect usage data. This platform,
which implements the wizard of Oz paradigm, makes it possible to simulate user
interfaces integrating ACAs for any Windows software application. It can also
save and "replay" a rich interaction trace including user and system events,
screen captures, users' speech and eye fixations. This platform has been used
to assess users' subjective judgements and reactions to a multimodal online
help system meant to facilitate the use of software for the general public
(Flash). The online help system is embodied using a 3D talking head (developed
by FT R&amp;D) which "says" oral help messages illustrated with Flash screen
copies.
</summary>
    <author>
      <name>Jérôme Simonin</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rocquencourt / INRIA Lorraine - LORIA</arxiv:affiliation>
    </author>
    <author>
      <name>Marius Hategan</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rocquencourt / INRIA Lorraine - LORIA</arxiv:affiliation>
    </author>
    <author>
      <name>Noëlle Carbonell</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rocquencourt / INRIA Lorraine - LORIA</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Dans Actes du Second Workshop sur les Agents Conversationnels
  anim\'es - Second Workshop sur les Agents Conversationnels anim\'es, Toulouse
  : France (2007)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0708.3740v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0708.3740v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0708.3742v1</id>
    <updated>2007-08-28T09:57:43Z</updated>
    <published>2007-08-28T09:57:43Z</published>
    <title>Interfaces adaptatives Adaptation dynamique à l'utilisateur courant</title>
    <summary>  We present a survey of recent research studies of the implementation of
adaptive user models in human-computer interaction. A classification of
research directions on adaptive user interfaces is first proposed; it takes
account of the user characteristics that are modelled, the distribution of
initiative and control of the system evolution between user and system, and the
role of dynamic adaptation. Then, a few representative research studies are
briefly presented to illustrate this classification. In the conclusion, some
major issues regarding the utility and usability of adaptive user interfaces
and the design of an appropriate methodology for assessing the ergonomic
quality of this new form of interaction are mentioned.
</summary>
    <author>
      <name>Jérôme Simonin</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rocquencourt / INRIA Lorraine - LORIA</arxiv:affiliation>
    </author>
    <author>
      <name>Noëlle Carbonell</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rocquencourt / INRIA Lorraine - LORIA</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Interfaces num\'eriques, Herm\`es Science (Ed.) (2007) 18 pages</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0708.3742v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0708.3742v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0708.4082v1</id>
    <updated>2007-08-30T06:39:15Z</updated>
    <published>2007-08-30T06:39:15Z</published>
    <title>Aides en ligne à l'utilisation de logiciels grand public : problèmes
  spécifiques de conception et solutions potentielles</title>
    <summary>  The observation that novice users seldom consult online help was made over
twenty years ago. This observation still holds nowadays, although online help
to the use of software for the general public has greatly improved in usability
during this period. The paper first demonstrates the necessity of online help
to the use of new software whatever the transparency of the user interface, as
whether online help systems are meant to compensate for interface design
weaknesses or actually do provide necessary assistance to the discovery of a
new software package functionalities is still an unsolved issue. The discussion
relies on results of empirical and experimental studies and theoretical
arguments. In the second part, we analyse the specific difficulties raised by
the design of effective online help systems for current software intended for
the general public so as to try and understand the reluctance of novice users
to use online help. In the last part, we present and discuss the possible
contributions of various approaches to solving this issue. Recent interaction
paradigms and techniques are considered, such as, static and dynamic
personalisation, contextual online help and new forms of multimodality.
</summary>
    <author>
      <name>Antonio Capobianco</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rocquencourt / INRIA Lorraine - LORIA</arxiv:affiliation>
    </author>
    <author>
      <name>Noëlle Carbonell</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rocquencourt / INRIA Lorraine - LORIA</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Intellectica 2006/2, 44 (2006) 87-120</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0708.4082v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0708.4082v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0710.0842v1</id>
    <updated>2007-10-03T17:23:59Z</updated>
    <published>2007-10-03T17:23:59Z</published>
    <title>Systèmes interactifs sensibles aux émotions : architecture
  logicielle</title>
    <summary>  We propose a software architecture for interactive systems which allows
integrating the user's emotion. Emotion can be involved in interaction at
several levels. In our application case - ballet dance - emotions is
explicitely manipulated by the interactive system to produce emotion-wise
output. Our architecture model to develop emotion-wise applications is based on
the PAC-Amodeus model. We add a branch to this model, divided into three
components: Data capture, analysis and cue extraction, and finally
interpretation of those cues. We show the different data flows between this
architecture's components depending on the entry point of the emotion branch
within the system. We then illustrate our model by describing our application
case: capturing a ballet dancer's movement to extract the emotions he expresses
and use these emotions to generate graphical content that is displayed on
stage.
</summary>
    <author>
      <name>Alexis Clay</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIPSI</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/0710.0842v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0710.0842v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0710.0859v1</id>
    <updated>2007-10-03T18:30:07Z</updated>
    <published>2007-10-03T18:30:07Z</published>
    <title>Assistance orale à la recherche visuelle - étude expérimentale de
  l'apport d'indications spatiales à la détection de cibles</title>
    <summary>  This paper describes an experimental study that aims at assessing the actual
contribution of voice system messages to visual search efficiency and comfort.
Messages which include spatial information on the target location are meant to
support search for familiar targets in collections of photographs (30 per
display). 24 participants carried out 240 visual search tasks in two conditions
differing from each other in initial target presentation only. The isolated
target was presented either simultaneously with an oral message (multimodal
presentation, MP), or without any message (visual presentation, VP). Averaged
target selection times were thrice longer and errors almost twice more frequent
in the VP condition than in the MP condition. In addition, the contribution of
spatial messages to visual search rapidity and accuracy was influenced by
display layout and task difficulty. Most results are statistically significant.
Besides, subjective judgments indicate that oral messages were well accepted.
</summary>
    <author>
      <name>Suzanne Kieffer</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rocquencourt / INRIA Lorraine - LORIA</arxiv:affiliation>
    </author>
    <author>
      <name>Noëlle Carbonell</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rocquencourt / INRIA Lorraine - LORIA</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">http://www.hcirn.com/res/period/rihm.php</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Revue d'Interaction Homme-Machine 7, 1 (2006) 30 p</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0710.0859v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0710.0859v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0711.1226v1</id>
    <updated>2007-11-08T09:29:57Z</updated>
    <published>2007-11-08T09:29:57Z</published>
    <title>Dynamic aspects of individual design activities. A cognitive ergonomics
  viewpoint</title>
    <summary>  This paper focuses on the use of knowledge possessed by designers. Data
collection was based on observations (by the cognitive ergonomics researcher)
and simultaneous verbalisations (by the designers) in empirical studies
conducted in the context of industrial design projects. The contribution of
this research is typical of cognitive ergonomics, in that it provides data on
actual activities implemented by designers in their actual work situation
(rather than on prescribed and/or idealised processes and methods). Data
presented concern global strategies (the way in which designers actually
organise their activity) and local strategies (reuse in design). Results from
cognitive ergonomics and other research that challenges the way in which people
are supposed to work with existing systems are generally not received warmly.
Abundant corroboration of such results is required before industry may consider
taking them into account. The opportunistic organisation of design activity is
taken here as an example of this reluctance. The results concerning this aspect
of design have been verified repeatedly, but only prototypes and experimental
systems implementing some of the requirements formulated on their basis, are
under development.
</summary>
    <author>
      <name>Willemien Visser</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rocquencourt</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Human behaviour in design Springer Verlag (Ed.) (2003) 87-96</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0711.1226v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0711.1226v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0711.2239v1</id>
    <updated>2007-11-14T16:18:42Z</updated>
    <published>2007-11-14T16:18:42Z</published>
    <title>Mise en place de scénarios pour la conception d'outils en Chirurgie
  Minimalement Invasive</title>
    <summary>  Nowadays, more and more surgical interventions are carried out in Minimally
Invasive Surgery, to make the post-operative constraints less painful for the
patient. Actually, new surgical tools or medical products are designed after
informal discussions between surgeons and designers. The user requirements
documents are the main document used by the mechanical designers to design and
improve the product. Medical terms, often used by surgeons and employed to
explain their needs, don't allow for an instantaneous understanding by
designers. Unfortunately, this relation causes a dysfunction in the definition
cycle of the product. Our aim is to work on the design process, its assistance
thanks to methods and tools and on its organisation for better understandings
and more complementarities between surgeons and designers. We propose on this
article a design method already tested in the informatics domain: User Centred
Design which takes the user into account more effectively in the process
design. We already propose a scenario oriented design method centred on the
user and represented as a scenario (Scenario-Based Design). We start in this
article by clarifying these concepts before detailing their implementation for
the design of a new surgical tool.
</summary>
    <author>
      <name>Guillaume Thomann</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LGS</arxiv:affiliation>
    </author>
    <author>
      <name>Jean Caelen</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIG</arxiv:affiliation>
    </author>
    <author>
      <name>Morgan Verdier</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LGS</arxiv:affiliation>
    </author>
    <author>
      <name>Brigitte Meillon</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIG</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Les Syst\`emes de Production, Lavoisier (Ed.) (2007) 93-107</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0711.2239v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0711.2239v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0711.2760v1</id>
    <updated>2007-11-17T20:08:41Z</updated>
    <published>2007-11-17T20:08:41Z</published>
    <title>Computer Supported Collaborative Research</title>
    <summary>  It is suggested that a new area of CSCR (Computer Supported Collaborative
Research) is distinguished from CSCW (Computer Supported Collaborative Work)
and CSCL (Computer Supported Collaborative Learning) and that the demarcation
between the three areas could do with greater clarification and prescription.
  Although the areas of Human Computer Interaction (HCI), CSCW, and CSCL are
now relatively well established, the related field of Computer Supported
Collaborative Research (CSCR) is new and little understood. An analysis of the
principles and issues behind CSCR is undertaken with a view to determining
precisely its nature and scope and to delineate it clearly from CSCW and CSCL.
This determination is such that it is generally applicable to the building,
design and evaluation of collaborative research environments.
  A particular instance of the CSCR domain is then examined in order to
determine the requirements of a collaborative research environment for students
and supervisors (CRESS).
</summary>
    <author>
      <name>Vita Hinze-Hoare</name>
    </author>
    <link href="http://arxiv.org/abs/0711.2760v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0711.2760v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0711.2811v1</id>
    <updated>2007-11-18T19:10:18Z</updated>
    <published>2007-11-18T19:10:18Z</published>
    <title>Une approche par les modèles pour le suivi de l'activité de
  construction d'un bâtiment. Bat'iViews : une interface multi-vues
  orientée gestion de chantier</title>
    <summary>  Cooperation between actors in design and construction activities in
architecture is an essential stake nowadays. In professional practices the
actors involved in construction projects use numerous tools. The project is
unique but the "views" that actors manipulate are various and sometimes
fundamentally different. Their common characteristic is that they partially
represent the cooperation context through a specific point of view.
"Bat'iViews" suggests to the actors a multi-view interface of the context and
enables to navigate through the different views. This proposition is based on a
model-driven approach. We distinguish between "context modelling" and modelling
of concepts represented in each "businessview". A model integrative
infrastructure allows us to develop the prototype and to manage user
interaction through the definition of models' transformations.
</summary>
    <author>
      <name>Gilles Halin</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CRAI</arxiv:affiliation>
    </author>
    <author>
      <name>Sylvain Kubicki</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CRAI</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/0711.2811v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0711.2811v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0711.2971v1</id>
    <updated>2007-11-19T16:36:02Z</updated>
    <published>2007-11-19T16:36:02Z</published>
    <title>IT services design to support coordination practices in the
  Luxembourguish AEC sector</title>
    <summary>  In the Architecture Engineering and Construction sector (AEC) cooperation
between actors is essential for project success. The configuration of actors'
organization takes different forms like the associated coordination mechanisms.
Our approach consists in analyzing these coordination mechanisms through the
identification of the "base practices" realized by the actors of a construction
project to cooperate. We also try with practitioners to highlight the "best
practices" of cooperation. Then we suggest here two prototypes of IT services
aiming to demonstrate the value added of IT to support cooperation. These
prototype tools allow us to sensitize the actors through terrain experiments
and then to bring inch by inch the Luxembourgish AEC sector towards electronic
cooperation.
</summary>
    <author>
      <name>Sylvain Kubicki</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">MAP / CRAI</arxiv:affiliation>
    </author>
    <author>
      <name>Annie Guerriéro</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">MAP / CRAI</arxiv:affiliation>
    </author>
    <author>
      <name>Damien Hanser</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">MAP / CRAI</arxiv:affiliation>
    </author>
    <author>
      <name>Gilles Halin</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">MAP / CRAI</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/0711.2971v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0711.2971v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0712.1759v1</id>
    <updated>2007-12-11T16:47:54Z</updated>
    <published>2007-12-11T16:47:54Z</published>
    <title>A Web-based System for Observing and Analyzing Computer Mediated
  Communications</title>
    <summary>  Tracking data of user's activities resulting from Computer Mediated
Communication (CMC) tools (forum, chat, etc.) is often carried out in an ad-hoc
manner, which either confines the reusability of data in different purposes or
makes data exploitation difficult. Our research works are biased toward
methodological challenges involved in designing and developing a generic system
for tracking user's activities while interacting with asynchronous
communication tools like discussion forums. We present in this paper, an
approach for building a Web-based system for observing and analyzing user
activity on any type of discussion forums.
</summary>
    <author>
      <name>Madeth May</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIESP</arxiv:affiliation>
    </author>
    <author>
      <name>Sébastien George</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIESP</arxiv:affiliation>
    </author>
    <author>
      <name>Patrick Prévôt</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIESP</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Dans Proceedings of the IEEE/WIC/ACM International Conference on
  Web Intelligence (WI 2006) - IEEE/WIC/ACM International Conference on Web
  Intelligence (WI 2006, Hong Kong : Chine (2006)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0712.1759v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0712.1759v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0712.1768v1</id>
    <updated>2007-12-11T16:59:19Z</updated>
    <published>2007-12-11T16:59:19Z</published>
    <title>Conceptions et usages des plates-formes de formation, Revue Sciences et
  Technologies de l'Information et de la Communication pour l'Éducation et la
  Formation</title>
    <summary>  Educative platforms are at the heart of the development of online education.
They can not only be reduced to technological aspects. Underlying models impact
teaching and learning from the preparing of lessons to the learning sessions.
Research related to these platforms are numerous and their stakes are
important. For these reasons, we launched a call to a special issue on "Designs
and uses of educative platforms" An educative platform is a computer system
designed to automate various functions relating to the organization of the
course, to the management of their content, to the monitoring of learners and
supervision of persons in charge of various formations (Office de la langue
fran\c{c}aise, 2005). So educative platforms are Learning Management Systems
(LMS) which are specific to education contexts.
</summary>
    <author>
      <name>Sébastien George</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIESP</arxiv:affiliation>
    </author>
    <author>
      <name>Alain Derycke</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">TRIGONE</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Sciences et Technologies de l'Information et de la Communication
  pour l'Education et la Formation 12 (2006) 51-64</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0712.1768v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0712.1768v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0712.1800v1</id>
    <updated>2007-12-11T19:30:46Z</updated>
    <published>2007-12-11T19:30:46Z</published>
    <title>Conception d'outils de communication spécifiques au contexte
  éducatif</title>
    <summary>  In a distance learning context, providing usual communication tools (forum,
chat, ...) is not always enough to create efficient interactions between
learners and to favour collective knowledge building. A solution consists in
setting-up collective activities which encourage learners to communicate. But,
even in that case, tools can sometimes become a barrier to communication. We
present in this paper examples of specific tools that are designed in order to
favour and to guide communications in an educational context, but also to
foster interactions during learning activities that are not inherently
collaborative. We describe synchronous communication tools (semi-structured
chat), asynchronous tools (temporally structured forum, contextual forum) and a
system which promotes mutual aid between learners.
</summary>
    <author>
      <name>Sébastien George</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIESP</arxiv:affiliation>
    </author>
    <author>
      <name>Cécile Bothorel</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">TECH/EASY</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Sciences et Technologies de l'Information et de la Communication
  pour l'Education et la Formation 13 (2007) 317-344</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0712.1800v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0712.1800v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0712.2168v1</id>
    <updated>2007-12-13T15:14:01Z</updated>
    <published>2007-12-13T15:14:01Z</published>
    <title>Study of conditions of use of E-services accessible to visually disabled
  persons</title>
    <summary>  The aim of this paper is to determine the expectations that French-speaking
disabled persons have for electronic administrative sites (utility). At the
same time, it is a matter of identifying the difficulties of use that the
manipulation of these E-services poses concretely for blind people (usability)
and of evaluating the psychosocial impacts on the way of life of these people
with specific needs. We show that the lack of numerical accessibility is likely
to accentuate the social exclusion of which these people are victim by
establishing a numerical glass ceiling.
</summary>
    <author>
      <name>Marc-Eric Bobiller-Chaumon</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">GRePS</arxiv:affiliation>
    </author>
    <author>
      <name>Michel Dubois</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIP - PC2S</arxiv:affiliation>
    </author>
    <author>
      <name>Françoise Sandoz-Guermond</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIESP</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages visible \`a http://ceur-ws.org/Vol-285</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Dans CEUR Workshop Proceedings - DEGAS'07 : Workshop of Design &amp;
  Evaluation of e-Government Applications and services, Rio de Janeiro :
  Br\'esil (2006)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0712.2168v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0712.2168v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0801.1925v1</id>
    <updated>2008-01-12T23:39:30Z</updated>
    <published>2008-01-12T23:39:30Z</published>
    <title>A Framework for Designing Teleconsultation Systems in Africa</title>
    <summary>  All of the countries within Africa experience a serious shortage of medical
professionals, particularly specialists, a problem that is only exacerbated by
high emigration of doctors with better prospects overseas. As a result, those
that remain in Africa, particularly those practicing in rural regions,
experience a shortage of specialists and other colleagues with whom to exchange
ideas. Telemedicine and teleconsultation are key areas that attempt to address
this problem by leveraging remote expertise for local problems. This paper
presents an overview of teleconsultation in the developing world, with a
particular focus on how lessons learned apply to Africa. By teleconsultation,
we are addressing non-real-time communication between health care professionals
for the purposes of providing expertise and informal recommendations, without
the real-time, interactive requirements typical of diagnosis and patient care,
which is impractical for the vast majority of existing medical practices. From
these previous experiences, we draw a set of guidelines and examine their
relevance to Ghana in particular. Based on 6 weeks of needs assessment, we
identify key variables that guide our framework, and then illustrate how our
framework is used to inform the iterative design of a prototype system.
</summary>
    <author>
      <name>Rowena Luk</name>
    </author>
    <author>
      <name>Melissa Ho</name>
    </author>
    <author>
      <name>Paul M. Aoki</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. Int'l Conf. on Health Informatics in Africa (HELINA),
  Bamako, Mali, Jan. 2007, 28(1-5)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0801.1925v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0801.1925v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0801.1927v1</id>
    <updated>2008-01-12T23:43:18Z</updated>
    <published>2008-01-12T23:43:18Z</published>
    <title>Asynchronous Remote Medical Consultation for Ghana</title>
    <summary>  Computer-mediated communication systems can be used to bridge the gap between
doctors in underserved regions with local shortages of medical expertise and
medical specialists worldwide. To this end, we describe the design of a
prototype remote consultation system intended to provide the social,
institutional and infrastructural context for sustained, self-organizing growth
of a globally-distributed Ghanaian medical community. The design is grounded in
an iterative design process that included two rounds of extended design
fieldwork throughout Ghana and draws on three key design principles (social
networks as a framework on which to build incentives within a self-organizing
network; optional and incremental integration with existing referral
mechanisms; and a weakly-connected, distributed architecture that allows for a
highly interactive, responsive system despite failures in connectivity). We
discuss initial experiences from an ongoing trial deployment in southern Ghana.
</summary>
    <author>
      <name>Rowena Luk</name>
    </author>
    <author>
      <name>Melissa Ho</name>
    </author>
    <author>
      <name>Paul M. Aoki</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/1357054.1357173</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/1357054.1357173" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/0801.1927v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0801.1927v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.m" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0801.3102v1</id>
    <updated>2008-01-20T19:15:50Z</updated>
    <published>2008-01-20T19:15:50Z</published>
    <title>Balancing transparency, efficiency and security in pervasive systems</title>
    <summary>  This chapter will survey pervasive computing with a look at how its
constraint for transparency affects issues of resource management and security.
The goal of pervasive computing is to render computing transparent, such that
computing resources are ubiquitously offered to the user and services are
proactively performed for a user without his or her intervention. The task of
integrating computing infrastructure into everyday life without making it
excessively invasive brings about tradeoffs between flexibility and robustness,
efficiency and effectiveness, as well as autonomy and reliability. As the
feasibility of ubiquitous computing and its real potential for mass
applications are still a matter of controversy, this chapter will look into the
underlying issues of resource management and authentication to discover how
these can be handled in a least invasive fashion. The discussion will be closed
by an overview of the solutions proposed by current pervasive computing
efforts, both in the area of generic platforms and for dedicated applications
such as pervasive education and healthcare.
</summary>
    <author>
      <name>Mark Wenstrom</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Pennsylvania State University</arxiv:affiliation>
    </author>
    <author>
      <name>Eloisa Bentivegna</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Pennsylvania State University</arxiv:affiliation>
    </author>
    <author>
      <name>Ali Hurson</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Pennsylvania State University</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">52 pages, to be published in Advances in Computers</arxiv:comment>
    <link href="http://arxiv.org/abs/0801.3102v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0801.3102v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.m" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0801.4423v1</id>
    <updated>2008-01-29T04:42:26Z</updated>
    <published>2008-01-29T04:42:26Z</published>
    <title>It's Not What You Have, But How You Use It: Compromises in Mobile Device
  Use</title>
    <summary>  As users begin to use many more devices for personal information management
(PIM) than just the traditional desktop computer, it is essential for HCI
researchers to understand how these devices are being used in the wild and
their roles in users' information environments. We conducted a study of 220
knowledge workers about their devices, the activities they performed on each,
and the groups of devices used together. Our findings indicate that several
devices are often used in groups; integrated multi-function portable devices
have begun to replace single-function devices for communication (e.g. email and
IM). Users use certain features opportunistically because they happen to be
carrying a multi-function device with them. The use of multiple devices and
multi-function devices is fraught with compromises as users must choose and
make trade-offs among various factors.
</summary>
    <author>
      <name>Manas Tungare</name>
    </author>
    <author>
      <name>Manuel Perez-Quinones</name>
    </author>
    <link href="http://arxiv.org/abs/0801.4423v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0801.4423v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0802.3477v1</id>
    <updated>2008-02-24T01:49:31Z</updated>
    <published>2008-02-24T01:49:31Z</published>
    <title>Concerning the Feasibility of Example-driven Modelling Techniques</title>
    <summary>  We report on a series of experiments concerning the feasibility of example
driven modelling. The main aim was to establish experimentally within an
academic environment: the relationship between error and task complexity using
a) Traditional spreadsheet modelling; b) example driven techniques. We report
on the experimental design, sampling, research methods and the tasks set for
both control and treatment groups. Analysis of the completed tasks allows
comparison of several different variables. The experimental results compare the
performance indicators for the treatment and control groups by comparing
accuracy, experience, training, confidence measures, perceived difficulty and
perceived completeness. The various results are thoroughly tested for
statistical significance using: the Chi squared test, Fisher's exact test for
significance, Cochran's Q test and McNemar's test on difficulty.
</summary>
    <author>
      <name>Simon R. Thorne</name>
    </author>
    <author>
      <name>David Ball</name>
    </author>
    <author>
      <name>Z. Lawson</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 Pages, 8 Figures, 1 Tables</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2007 117-130
  ISBN 978-905617-58-6</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0802.3477v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0802.3477v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.1; H.4.1; K.6.4; D.2.9" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0802.3479v1</id>
    <updated>2008-02-24T02:03:16Z</updated>
    <published>2008-02-24T02:03:16Z</published>
    <title>An Empirical Study of End-User Behaviour in Spreadsheet Error Detection
  &amp; Correction</title>
    <summary>  Very little is known about the process by which end-user developers detect
and correct spreadsheet errors. Any research pertaining to the development of
spreadsheet testing methodologies or auditing tools would benefit from
information on how end-users perform the debugging process in practice.
Thirteen industry-based professionals and thirty-four accounting &amp; finance
students took part in a current ongoing experiment designed to record and
analyse end-user behaviour in spreadsheet error detection and correction.
Professionals significantly outperformed students in correcting certain error
types. Time-based cell activity analysis showed that a strong correlation
exists between the percentage of cells inspected and the number of errors
corrected. The cell activity data was gathered through a purpose written VBA
Excel plug-in that records the time and detail of all cell selection and cell
change actions of individuals.
</summary>
    <author>
      <name>Brian Bishop</name>
    </author>
    <author>
      <name>Kevin McDaid</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 Pages, 3 Figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2007 165-176
  ISBN 978-905617-58-6</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0802.3479v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0802.3479v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.2.4; D.2.5; H.4.1; K.6.4; K.8.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0802.3481v1</id>
    <updated>2008-02-24T02:15:49Z</updated>
    <published>2008-02-24T02:15:49Z</published>
    <title>Establishing A Minimum Generic Skill Set For Risk Management Teaching In
  A Spreadsheet Training Course</title>
    <summary>  Past research shows that spreadsheet models are prone to such a high
frequency of errors and data security implications that the risk management of
spreadsheet development and spreadsheet use is of great importance to both
industry and academia. The underlying rationale for this paper is that
spreadsheet training courses should specifically address risk management in the
development process both from a generic and a domain-specific viewpoint. This
research specifically focuses on one of these namely those generic issues of
risk management that should be present in a training course that attempts to
meet good-practice within industry. A pilot questionnaire was constructed
showing a possible minimum set of risk management issues and sent to academics
and industry practitioners for feedback. The findings from this pilot survey
will be used to refine the questionnaire for sending to a larger body of
possible respondents. It is expected these findings will form the basis of a
risk management teaching approach to be trialled in a number of selected
ongoing spreadsheet training courses.
</summary>
    <author>
      <name>David Chadwick</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 Pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2007 197-208
  ISBN 978-905617-58-6</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0802.3481v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0802.3481v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.1; H.4.1; K.6.4; D.2.5; D.2.9; K.8.1; K.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0802.3483v1</id>
    <updated>2008-02-24T02:21:35Z</updated>
    <published>2008-02-24T02:21:35Z</published>
    <title>Voice-controlled Debugging of Spreadsheets</title>
    <summary>  Developments in Mobile Computing are putting pressure on the software
industry to research new modes of interaction that do not rely on the
traditional keyboard and mouse combination. Computer users suffering from
Repetitive Strain Injury also seek an alternative to keyboard and mouse devices
to reduce suffering in wrist and finger joints. Voice-control is an alternative
approach to spreadsheet development and debugging that has been researched and
used successfully in other domains. While voice-control technology for
spreadsheets is available its effectiveness has not been investigated. This
study is the first to compare the performance of a set of expert spreadsheet
developers that debugged a spreadsheet using voice-control technology and
another set that debugged the same spreadsheet using keyboard and mouse. The
study showed that voice, despite its advantages, proved to be slower and less
accurate. However, it also revealed ways in which the technology might be
improved to redress this imbalance.
</summary>
    <author>
      <name>Derek Flood</name>
    </author>
    <author>
      <name>Kevin Mc Daid</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 Pages, 4 Tables</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2007 155-164
  ISBN 978-905617-58-6</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0802.3483v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0802.3483v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.1; H.4.1; K.6.4; D.2.5; D.2.9; K.8.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0802.3919v1</id>
    <updated>2008-02-26T21:58:26Z</updated>
    <published>2008-02-26T21:58:26Z</published>
    <title>A Paradigm for Spreadsheet Engineering Methodologies</title>
    <summary>  Spreadsheet engineering methodologies are diverse and sometimes
contradictory. It is difficult for spreadsheet developers to identify a
spreadsheet engineering methodology that is appropriate for their class of
spreadsheet, with its unique combination of goals, type of problem, and
available time and resources. There is a lack of well-organized, proven
methodologies with known costs and benefits for well-defined spreadsheet
classes. It is difficult to compare and critically evaluate methodologies. We
present a paradigm for organizing and interpreting spreadsheet engineering
recommendations. It systematically addresses the myriad choices made when
developing a spreadsheet, and explicitly considers resource constraints and
other development parameters. This paradigm provides a framework for
evaluation, comparison, and selection of methodologies, and a list of essential
elements for developers or codifiers of new methodologies. This paradigm
identifies gaps in our knowledge that merit further research.
</summary>
    <author>
      <name>Thomas A. Grossman</name>
    </author>
    <author>
      <name>Ozgur Ozluk</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 Pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2004 23-33
  ISBN 1 902724 94 1</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0802.3919v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0802.3919v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.1.7; D.2.1; D.2.11; D.3.2; D.3.3; H.4.1; K.6.4; K.8.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0802.3924v1</id>
    <updated>2008-02-26T22:11:24Z</updated>
    <published>2008-02-26T22:11:24Z</published>
    <title>A Toolkit for Scalable Spreadsheet Visualization</title>
    <summary>  This paper presents a toolkit for spreadsheet visualization based on logical
areas, semantic classes and data modules. Logical areas, semantic classes and
data modules are abstract representations of spreadsheet programs that are
meant to reduce the auditing and comprehension effort, especially for large and
regular spreadsheets. The toolkit is integrated as a plug-in in the Gnumeric
spreadsheet system for Linux. It can process large, industry scale spreadsheet
programs in reasonable time and is tightly integrated with its host spreadsheet
system. Users can generate hierarchical and graph-based representations of
their spreadsheets. This allows them to spot conceptual similarities in
different regions of the spreadsheet, that would otherwise not fit on a screen.
As it is assumed that the learning effort for effective use of such a tool
should be kept low, we aim for intuitive handling of most of the tool's
functions.
</summary>
    <author>
      <name>Markus Clermont</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 Pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2004 95-106
  ISBN 1 902724 94 1</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0802.3924v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0802.3924v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.1.7; D.2.1; D.2.11; D.3.2; D.3.3; H.4.1; K.6.4; K.8.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0802.3939v1</id>
    <updated>2008-02-27T00:14:34Z</updated>
    <published>2008-02-27T00:14:34Z</published>
    <title>Using Layout Information for Spreadsheet Visualization</title>
    <summary>  This paper extends a spreadsheet visualization technique by using layout
information. The original approach identifies logically or semantically related
cells by relying exclusively on the content of cells for identifying semantic
classes. A disadvantage of semantic classes is that users have to supply
parameters which describe the possible shapes of these blocks. The correct
parametrization requires a certain degree of experience and is thus not
suitable for untrained users. To avoid this constraint, the approach reported
in this paper uses row/column-labels as well as common format information for
locating areas with common, recurring semantics. Heuristics are provided to
distinguish between cell groups with intended common semantics and cell groups
related in an ad-hoc manner.
</summary>
    <author>
      <name>Sabine Hipfl</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 3 colour figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2004 107-119
  ISBN 1 902724 94 1</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0802.3939v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0802.3939v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.2.4; D.2.5; H.4.1; K.6.4; K.8.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0803.0164v1</id>
    <updated>2008-03-03T01:25:41Z</updated>
    <published>2008-03-03T01:25:41Z</published>
    <title>Considering Functional Spreadsheet Operator Usage Suggests the Value of
  Example Driven Modelling for Decision Support Systems</title>
    <summary>  Most spreadsheet surveys both for reporting use and error focus on the
practical application of the spreadsheet in a particular industry. Typically
these studies will illustrate that a particular percentage of spreadsheets are
used for optimisation and a further percentage are used for 'What if' analysis.
Much less common is examining the classes of function, as defined by the
vendor, used by modellers to build their spreadsheet models. This alternative
analysis allows further insight into the programming nature of spreadsheets and
may assist researchers in targeting particular structures in spreadsheet
software for further investigation. Further, understanding the functional
make-up of spreadsheets allows effective evaluation of novel approaches from a
programming point of view. It allows greater insight into studies that report
what spreadsheets are used for since it is explicit which functional structures
are in use in spreadsheets. We conclude that a deeper understanding of the use
of operators and the operator's relationship to error would provide fresh
insight into the spreadsheet error problem. Considering functional spreadsheet
operator usage suggests the value of Example Driven Modelling for Decision
Support Systems
</summary>
    <author>
      <name>Simon Thorne</name>
    </author>
    <author>
      <name>David Ball</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 Pages, 6 Figures, 3 Tables</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">roc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2006 147-158
  ISBN:1-905617-08-9</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0803.0164v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0803.0164v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.1; H.4.1; K.6.4; D.2.5; D.2.9; K.8.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0803.0167v1</id>
    <updated>2008-03-03T01:49:03Z</updated>
    <published>2008-03-03T01:49:03Z</published>
    <title>Does an awareness of differing types of spreadsheet errors aid end-users
  in identifying spreadsheets errors?</title>
    <summary>  The research presented in this paper establishes a valid, and simplified,
revision of previous spreadsheet error classifications. This investigation is
concerned with the results of a web survey and two web-based gender and
domain-knowledge free spreadsheet error identification exercises. The
participants of the survey and exercises were a test group of professionals
(all of whom regularly use spreadsheets) and a control group of students from
the University of Greenwich (UK). The findings show that over 85% of users are
also the spreadsheet's developer, supporting the revised spreadsheet error
classification. The findings also show that spreadsheet error identification
ability is directly affected both by spreadsheet experience and by error-type
awareness. In particular, that spreadsheet error-type awareness significantly
improves the user's ability to identify, the more surreptitious, qualitative
error.
</summary>
    <author>
      <name>Michael Purser</name>
    </author>
    <author>
      <name>David Chadwick</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 Pages, 14 Tables and Figures, many in colour</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2006 185-204
  ISBN:1-905617-08-9</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0803.0167v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0803.0167v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.2.4; D.2.5; H.4.1; K.6.4; K.8.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0803.0168v1</id>
    <updated>2008-03-03T01:55:40Z</updated>
    <published>2008-03-03T01:55:40Z</published>
    <title>Comparison of Characteristics and Practices amongst Spreadsheet Users
  with Different Levels of Experience</title>
    <summary>  We developed an internet-based questionnaire on spreadsheet use that we
administered to a large number of users in several companies and organizations
to document how spreadsheets are currently being developed and used in
business. In this paper, we discuss the results drawn from of a comparison of
responses from individuals with the most experience and expertise with those
from individuals with the least. These results describe two views of
spreadsheet design and use in organizations, and reflect gaps between these two
groups and between these groups and the entire population of nearly 1600
respondents. Moreover, our results indicate that these gaps have multiple
dimensions: they reflect not only the context, skill, and practices of
individual users but also the policies of large organizations.
</summary>
    <author>
      <name>Kenneth R. Baker</name>
    </author>
    <author>
      <name>Stephen G. Powell</name>
    </author>
    <author>
      <name>Barry Lawson</name>
    </author>
    <author>
      <name>Lynn Foster-Johnson</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 Pages, 11 Tables</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2006 205-219
  ISBN:1-905617-08-9</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0803.0168v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0803.0168v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.1; H.4.1; K.6.4; D.2.5; D.2.9; K.8.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0803.0169v1</id>
    <updated>2008-03-03T02:00:53Z</updated>
    <published>2008-03-03T02:00:53Z</published>
    <title>An Investigation of the Incidence and Effect of Spreadsheet Errors
  Caused by the Hard Coding of Input Data Values into Formulas</title>
    <summary>  The hard coding of input data or constants into spreadsheet formulas is
widely recognised as poor spreadsheet model design. However, the importance of
avoiding such practice appears to be underestimated perhaps in light of the
lack of quantitative error at the time of occurrence and the recognition that
this design defect may never result in a bottom-line error. The paper examines
both the academic and practitioner view of such hard coding design flaws. The
practitioner or industry viewpoint is gained indirectly through a review of
commercial spreadsheet auditing software. The development of an automated
(electronic) means for detecting such hard coding is described together with a
discussion of some results obtained through analysis of a number of student and
practitioner spreadsheet models.
</summary>
    <author>
      <name>Paul J. Blayney</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 Pages, 5 Tables</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2006 22-230
  ISBN:1-905617-08-9</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0803.0169v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0803.0169v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.2.4; D.2.5; H.4.1; K.6.4; K.8.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0803.0515v1</id>
    <updated>2008-03-04T18:46:49Z</updated>
    <published>2008-03-04T18:46:49Z</published>
    <title>Intuitive Source Code Visualization Tools for Improving Student
  Comprehension: BRICS</title>
    <summary>  Even relatively simple code analysis can be a daunting task for many first
year students. Perceived complexity, coupled with foreign and harsh syntax,
often outstrips the ability for students to take in what they are seeing in
terms of their verbal memory. That is, first year students often lack the
experience to encode critical building blocks in source code, and their
interrelationships, into their own words. We believe this argues for the need
for IDEs to provide additional support for representations that would appeal
directly to visual memory. In this paper, we examine this need for intuitive
source code visualization tools that are easily accessible to novice
programmers, discuss the requirements for such a tool, and suggest a novel idea
that takes advantage of human peripheral vision to achieve stronger overall
code structure awareness.
</summary>
    <author>
      <name>Christopher Pearson</name>
    </author>
    <author>
      <name>Celina Gibbs</name>
    </author>
    <author>
      <name>Yvonne Coady</name>
    </author>
    <link href="http://arxiv.org/abs/0803.0515v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0803.0515v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0803.1104v1</id>
    <updated>2008-03-07T14:50:21Z</updated>
    <published>2008-03-07T14:50:21Z</published>
    <title>Optimizing Web Sites for Customer Retention</title>
    <summary>  With customer relationship management (CRM) companies move away from a mainly
product-centered view to a customer-centered view. Resulting from this change,
the effective management of how to keep contact with customers throughout
different channels is one of the key success factors in today's business world.
Company Web sites have evolved in many industries into an extremely important
channel through which customers can be attracted and retained. To analyze and
optimize this channel, accurate models of how customers browse through the Web
site and what information within the site they repeatedly view are crucial.
Typically, data mining techniques are used for this purpose. However, there
already exist numerous models developed in marketing research for traditional
channels which could also prove valuable to understanding this new channel. In
this paper we propose the application of an extension of the Logarithmic Series
Distribution (LSD) model repeat-usage of Web-based information and thus to
analyze and optimize a Web Site's capability to support one goal of CRM, to
retain customers. As an example, we use the university's blended learning web
portal with over a thousand learning resources to demonstrate how the model can
be used to evaluate and improve the Web site's effectiveness.
</summary>
    <author>
      <name>Michael Hahsler</name>
    </author>
    <link href="http://arxiv.org/abs/0803.1104v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0803.1104v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0803.1754v1</id>
    <updated>2008-03-12T11:47:41Z</updated>
    <published>2008-03-12T11:47:41Z</published>
    <title>A Novel Approach to Formulae Production and Overconfidence Measurement
  to Reduce Risk in Spreadsheet Modelling</title>
    <summary>  Research on formulae production in spreadsheets has established the practice
as high risk yet unrecognised as such by industry. There are numerous software
applications that are designed to audit formulae and find errors. However these
are all post creation, designed to catch errors before the spreadsheet is
deployed. As a general conclusion from EuSpRIG 2003 conference it was decided
that the time has come to attempt novel solutions based on an understanding of
human factors. Hence in this paper we examine one such possibility namely a
novel example driven modelling approach. We discuss a control experiment that
compares example driven modelling against traditional approaches over several
progressively more difficult tests. The results are very interesting and
certainly point to the value of further investigation of the example driven
potential. Lastly we propose a method for statistically analysing the problem
of overconfidence in spreadsheet modellers.
</summary>
    <author>
      <name>Simon Thorne</name>
    </author>
    <author>
      <name>David Ball</name>
    </author>
    <author>
      <name>Zoe Lawson</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 7 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2004 71-83
  ISBN 1 902724 94 1</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0803.1754v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0803.1754v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.1.7; D.2.1; D.2.11; D.3.2; D.3.3; H.4.1; K.6.4; K.8.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0803.1866v1</id>
    <updated>2008-03-12T22:30:10Z</updated>
    <published>2008-03-12T22:30:10Z</published>
    <title>Risk Management for Complex Calculations: EuSpRIG Best Practices in
  Hybrid Applications</title>
    <summary>  As the need for advanced, interactive mathematical models has increased,
user/programmers are increasingly choosing the MatLab scripting language over
spreadsheets. However, applications developed in these tools have high error
risk, and no best practices exist. We recommend that advanced, highly
mathematical applications incorporate these tools with spreadsheets into hybrid
applications, where developers can apply EuSpRIG best practices. Development of
hybrid applications can reduce the potential for errors, shorten development
time, and enable higher level operations. We believe that hybrid applications
are the future and over the course of this paper, we apply and extend
spreadsheet best practices to reduce or prevent risks in hybrid Excel/MatLab
applications.
</summary>
    <author>
      <name>Deborah Cernauskas</name>
    </author>
    <author>
      <name>Andrew Kumiega</name>
    </author>
    <author>
      <name>Ben VanVliet</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 8 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2007 25-36
  ISBN 978-905617-58-6</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0803.1866v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0803.1866v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.1; H.4.1; K.6.4; D.2.5; D.2.9; K.8.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0803.1875v1</id>
    <updated>2008-03-13T00:15:40Z</updated>
    <published>2008-03-13T00:15:40Z</published>
    <title>Breaking Out of the Cell: On The Benefits of a New Spreadsheet
  User-Interaction Paradigm</title>
    <summary>  Contemporary spreadsheets are plagued by a profusion of errors, auditing
difficulties, lack of uniform development methodologies, and barriers to easy
comprehension of the underlying business models they represent. This paper
presents a case that most of these difficulties stem from the fact that the
standard spreadsheet user-interaction paradigm - the 'cell-matrix' approach -
is appropriate for spreadsheet data presentation but has significant drawbacks
with respect to spreadsheet creation, maintenance and comprehension when
workbooks pass a minimal threshold of complexity. An alternative paradigm for
the automated generation of spreadsheets directly from plain-language business
model descriptions is presented along with its potential benefits. Sunsight
Modeller (TM), a working software system implementing the suggested paradigm,
is briefly described.
</summary>
    <author>
      <name>Ziv Hellman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 Pages, 2 Diagrams</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2005 113-124
  ISBN:1-902724-16-X</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0803.1875v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0803.1875v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.1; H.4.1; K.6.4; D.2.5; D.2.9; K.8.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0803.2527v1</id>
    <updated>2008-03-17T20:46:12Z</updated>
    <published>2008-03-17T20:46:12Z</published>
    <title>Controlling the Information Flow in Spreadsheets</title>
    <summary>  There is no denying that spreadsheets have become critical for all
operational processes including financial reporting, budgeting, forecasting,
and analysis. Microsoft Excel has essentially become a scratch pad and a data
browser that can quickly be put to use for information gathering and
decision-making. However, there is little control in how data comes into Excel,
and how it gets updated. The information supply chain feeding into Excel
remains ad hoc and without any centralized IT control. This paper discusses
some of the pitfalls of the data collection and maintenance process in Excel.
It then suggests service-oriented architecture (SOA) based information
gathering and control techniques to ameliorate the pitfalls of this scratch pad
while improving the integrity of data, boosting the productivity of the
business users, and building controls to satisfy the requirements of Section
404 of the Sarbanes-Oxley Act.
</summary>
    <author>
      <name>Vipin Samar</name>
    </author>
    <author>
      <name>Sangeeta Patni</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2005 125-134
  ISBN:1-902724-16-X</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0803.2527v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0803.2527v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.1; H.4.1; K.6.4; D.2.9" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0803.3394v1</id>
    <updated>2008-03-24T12:01:16Z</updated>
    <published>2008-03-24T12:01:16Z</published>
    <title>Facing the Facts</title>
    <summary>  Human error research on overconfidence supports the benefits of early
visibility of defects and disciplined development. If risk to the enterprise is
to be reduced, individuals need to become aware of the reality of the quality
of their work. Several cycles of inspection and defect removal are inevitable.
Software Quality Management measurements of defect density and removal
efficiency are applicable. Research of actual spreadsheet error rates shows
data consistent with other software depending on the extent to which the work
product was reviewed before inspection. The paper argues that the payback for
an investment in early review time is justified by the saving in project delay
and expensive errors in use.
  'If debugging is the process of removing bugs, then programming must be the
process of putting them in' - Anon.
</summary>
    <author>
      <name>Patrick O'Beirne</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 1 table, 1 figure</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2007 209-214
  ISBN 978-905617-58-6</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0803.3394v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0803.3394v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.2.4; D.2.5; H.4.1; K.6.4; K.8.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0804.0556v1</id>
    <updated>2008-04-03T13:40:02Z</updated>
    <published>2008-04-03T13:40:02Z</published>
    <title>RubberEdge: Reducing Clutching by Combining Position and Rate Control
  with Elastic Feedback</title>
    <summary>  Position control devices enable precise selection, but significant clutching
degrades performance. Clutching can be reduced with high control-display gain
or pointer acceleration, but there are human and device limits. Elastic rate
control eliminates clutching completely, but can make precise selection
difficult. We show that hybrid position-rate control can outperform position
control by 20% when there is significant clutching, even when using pointer
acceleration. Unlike previous work, our RubberEdge technique eliminates
trajectory and velocity discontinuities. We derive predictive models for
position control with clutching and hybrid control, and present a prototype
RubberEdge position-rate control device including initial user feedback.
</summary>
    <author>
      <name>Géry Casiez</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIFL, INRIA Lille - Nord Europe</arxiv:affiliation>
    </author>
    <author>
      <name>Daniel Vogel</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIFL, INRIA Lille - Nord Europe</arxiv:affiliation>
    </author>
    <author>
      <name>Qing Pan</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIFL, INRIA Lille - Nord Europe</arxiv:affiliation>
    </author>
    <author>
      <name>Christophe Chaillou</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Lille - Nord Europe</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/1294211.1294234</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/1294211.1294234" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Dans Proceedings of the 20th annual ACM symposium on User
  interface software and technology - Symposium on User Interface Software and
  Technology, Lille : France (2007)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0804.0556v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0804.0556v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0804.0943v1</id>
    <updated>2008-04-07T00:46:41Z</updated>
    <published>2008-04-07T00:46:41Z</published>
    <title>The Wall and The Ball: A Study of Domain Referent Spreadsheet Errors</title>
    <summary>  The Cell Error Rate in simple spreadsheets averages about 2% to 5%. This CER
has been measured in domain free environments. This paper compares the CERs
occurring in domain free and applied domain tasks. The applied domain task
requires the application of simple linear algebra to a costing problem. The
results show that domain referent knowledge influences participants' approaches
to spreadsheet creation and spreadsheet usage. The conclusion is that
spreadsheet error making is influenced by domain knowledge and domain
perception. Qualitative findings also suggest that spreadsheet error making is
a part of overall human behaviour, and ought to be analyzed against this wider
canvas.
</summary>
    <author>
      <name>Richard J. Irons</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2003 33-48
  ISBN 1 86166 199 1</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0804.0943v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0804.0943v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.1; H.4.1; K.6.4; D.2.5; D.2.9; K.8.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0804.2614v1</id>
    <updated>2008-04-16T14:43:31Z</updated>
    <published>2008-04-16T14:43:31Z</published>
    <title>Augmenting Actual Life Through MUVEs</title>
    <summary>  The necessity of supporting more and more social interaction (and not only
the mere information sharing) in online environments is the disruptive force
upon which phenomena ascribed to the Web2.0 paradigm continuously bud. People
interacting in online socio-technical environments mould technology on their
needs, seamlessly integrating it into their everyday life. MUVEs (Multi User
Virtual Environments) are no exception and, in several cases, represent the new
frontier in this field. In this work we analyze if and how MUVEs can be
considered a mean for augmenting communities (and more in general people) life.
We trace a framework of analysis based on four main observations, and through
these lenses we look at Second Life and at several projects we are currently
developing in that synthetic world.
</summary>
    <author>
      <name>Laura Anna Ripamonti</name>
    </author>
    <author>
      <name>Ines Di Loreto</name>
    </author>
    <author>
      <name>Dario Maggiorini</name>
    </author>
    <link href="http://arxiv.org/abs/0804.2614v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0804.2614v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0804.2851v1</id>
    <updated>2008-04-17T16:33:53Z</updated>
    <published>2008-04-17T16:33:53Z</published>
    <title>Identifying 'Hidden' Communities of Practice within Electronic Networks:
  Some Preliminary Premises</title>
    <summary>  This paper examines the possibility of discovering 'hidden' (potential)
Communities of Practice (CoPs) inside electronic networks, and then using this
knowledge to nurture them into a fully developed Virtual Community of Practice
(VCoP). Starting from the standpoint of the need to manage knowledge, it
discusses several questions related to this subject: the characteristics of
'hidden' communities; the relation between CoPs, Virtual Communities (VCs),
Distributed Communities of Practice (DCoPs) and Virtual Communities of Practice
(VCoPs); the methods used to search for 'hidden' CoPs; and the possible ways of
changing 'hidden' CoPs into fully developed VCoPs. The paper also presents some
preliminary findings from a semi-structured interview conducted in The Higher
Education Academy Psychology Network (UK). These findings are contrasted
against the theory discussed and some additional proposals are suggested at the
end.
</summary>
    <author>
      <name>Richard Ribeiro</name>
    </author>
    <author>
      <name>Chris Kimble</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">in Proceedings of 13th UKAIS Conference, (April 2008), Bournemouth,
  UK</arxiv:comment>
    <link href="http://arxiv.org/abs/0804.2851v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0804.2851v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.4; H.5.3; K.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0806.0189v1</id>
    <updated>2008-06-01T23:51:12Z</updated>
    <published>2008-06-01T23:51:12Z</published>
    <title>Investigating the use of Software Agents to Reduce The Risk of
  Undetected Errors in Strategic Spreadsheet Applications</title>
    <summary>  There is an overlooked iceberg of problems in end user computing.
Spreadsheets are developed by people who are very skilled in their main job
function, be it finance, procurement, or production planning, but often have
had no formal training in spreadsheet use. IT auditors focus on mainstream
information systems but regard spreadsheets as user problems, outside their
concerns. Internal auditors review processes, but not the tools that support
decision making in these processes.
  This paper highlights the gaps between risk management and end user awareness
in spreadsheet research. In addition the potential benefits of software agent
technologies to the management of risk in spreadsheets are explored. This paper
discusses the current research into end user computing and spreadsheet use
awareness.
</summary>
    <author>
      <name>Pat Cleary</name>
    </author>
    <author>
      <name>Dr David Ball</name>
    </author>
    <author>
      <name>Mukul Madahar</name>
    </author>
    <author>
      <name>Simon Thorne</name>
    </author>
    <author>
      <name>Christopher Gosling</name>
    </author>
    <author>
      <name>Karen Fernandez</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 Pages, 3 Tables, 3 Figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2003 147-159
  ISBN 1 86166 199 1</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0806.0189v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0806.0189v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0806.0314v1</id>
    <updated>2008-06-02T15:57:55Z</updated>
    <published>2008-06-02T15:57:55Z</published>
    <title>GuiLiner: A Configurable and Extensible Graphical User Interface for
  Scientific Analysis and Simulation Software</title>
    <summary>  The computer programs most users interact with daily are driven by a
graphical user interface (GUI). However, many scientific applications are used
with a command line interface (CLI) for the ease of development and increased
flexibility this mode provides. Scientific application developers would benefit
from being able to provide a GUI easily for their CLI programs, thus retaining
the advantages of both modes of interaction. GuiLiner is a generic, extensible
and flexible front-end designed to ``host'' a wide variety of data analysis or
simulation programs. Scientific application developers who produce a correctly
formatted XML file describing their program's options and some of its
documentation can immediately use GuiLiner to produce a carefully implemented
GUI for their analysis or simulation programs.
</summary>
    <author>
      <name>N. C. Manoukis</name>
    </author>
    <author>
      <name>E. C. Anderson</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages; for the current version of this software, please visit
  http://guiliner.sourceforge.net/</arxiv:comment>
    <link href="http://arxiv.org/abs/0806.0314v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0806.0314v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.2.2; H.1.2; I.3.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0807.2836v1</id>
    <updated>2008-07-17T17:22:55Z</updated>
    <published>2008-07-17T17:22:55Z</published>
    <title>Ordinateur porté support de réalité augmentée pour des
  activités de maintenance et de dépannage</title>
    <summary>  In this paper we present a case study of use of wearable computer within the
framework of activities of maintenance and repairing. Besides the study of
configuration of this wearable computer and its peripherals, we show the
integration of context, in-situ storage, traceability and regulation in these
activities. This case study is in the scope of a huge project called HMTD (Help
Me To Do) which aim is to apply MOCOCO (Mobility, COoperation,
COntextualisation) and IMERA (Mobile Interaction in the Augmented Real
Environment) principles for better use, maintenance and repairing of equipments
in the domestic, public and professional situations.
</summary>
    <author>
      <name>Olivier Champalle</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">ICTT, Liesp</arxiv:affiliation>
    </author>
    <author>
      <name>Bertrand David</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">ICTT, Liesp</arxiv:affiliation>
    </author>
    <author>
      <name>René Chalon</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">ICTT, Liesp</arxiv:affiliation>
    </author>
    <author>
      <name>Guillaume Masserey</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">ICTT, Liesp</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Ubimob'06 3e Journ\'ees Francophones Mobilit\'e et Ubiquit\'e, Paris
  : France (2006)</arxiv:comment>
    <link href="http://arxiv.org/abs/0807.2836v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0807.2836v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0807.3168v1</id>
    <updated>2008-07-20T17:28:25Z</updated>
    <published>2008-07-20T17:28:25Z</published>
    <title>Audit and Change Analysis of Spreadsheets</title>
    <summary>  Because spreadsheets have a large and growing importance in real-world work,
their contents need to be controlled and validated. Generally spreadsheets have
been difficult to verify, since data and executable information are stored
together. Spreadsheet applications with multiple authors are especially
difficult to verify, since controls over access are difficult to enforce.
Facing similar problems, traditional software engineering has developed
numerous tools and methodologies to control, verify and audit large
applications with multiple developers. We present some tools we have developed
to enable 1) the audit of selected, filtered, or all changes in a spreadsheet,
that is, when a cell was changed, its original and new contents and who made
the change, and 2) control of access to the spreadsheet file(s) so that
auditing is trustworthy. Our tools apply to OpenOffice.org calc spreadsheets,
which can generally be exchanged with Microsoft Excel.
</summary>
    <author>
      <name>John C. Nash</name>
    </author>
    <author>
      <name>Neil Smith</name>
    </author>
    <author>
      <name>Andy Adler</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 3 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2003 81-90
  ISBN 1 86166 199 1</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0807.3168v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0807.3168v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0807.3183v1</id>
    <updated>2008-07-20T20:29:38Z</updated>
    <published>2008-07-20T20:29:38Z</published>
    <title>Accuracy in Spreadsheet Modelling Systems</title>
    <summary>  Accuracy in spreadsheet modelling systems can be reduced due to difficulties
with the inputs, the model itself, or the spreadsheet implementation of the
model. When the "true" outputs from the system are unknowable, accuracy is
evaluated subjectively. Less than perfect accuracy can be acceptable depending
on the purpose of the model, problems with inputs, or resource constraints.
Users build modelling systems iteratively, and choose to allocate limited
resources to the inputs, the model, the spreadsheet implementation, and to
employing the system for business analysis. When making these choices, users
can suffer from expectation bias and diagnosis bias. Existing research results
tend to focus on errors in the spreadsheet implementation. Because industry has
tolerance for system inaccuracy, errors in spreadsheet implementations may not
be a serious concern. Spreadsheet productivity may be of more interest.
</summary>
    <author>
      <name>Thomas A. Grossman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 5 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2003 91-97
  ISBN 1 86166 199 1</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0807.3183v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0807.3183v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0807.3184v1</id>
    <updated>2008-07-20T20:43:05Z</updated>
    <published>2008-07-20T20:43:05Z</published>
    <title>Research Strategy and Scoping Survey on Spreadsheet Practices</title>
    <summary>  We propose a research strategy for creating and deploying prescriptive
recommendations for spreadsheet practice. Empirical data on usage can be used
to create a taxonomy of spreadsheet classes. Within each class, existing
practices and ideal practices can he combined into proposed best practices for
deployment. As a first step we propose a scoping survey to gather non-anecdotal
data on spreadsheet usage. The scoping survey will interview people who develop
spreadsheets. We will investigate the determinants of spreadsheet importance,
identify current industry practices, and document existing standards for
creation and use of spreadsheets. The survey will provide insight into user
attributes, spreadsheet importance, and current practices. Results will be
valuable in themselves, and will guide future empirical research.
</summary>
    <author>
      <name>Thomas A. Grossman</name>
    </author>
    <author>
      <name>Ozgur Ozluk</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 2 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2003 23-32
  ISBN 1 86166 199 1</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0807.3184v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0807.3184v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0807.4618v1</id>
    <updated>2008-07-29T09:54:44Z</updated>
    <published>2008-07-29T09:54:44Z</published>
    <title>AceWiki: A Natural and Expressive Semantic Wiki</title>
    <summary>  We present AceWiki, a prototype of a new kind of semantic wiki using the
controlled natural language Attempto Controlled English (ACE) for representing
its content. ACE is a subset of English with a restricted grammar and a formal
semantics. The use of ACE has two important advantages over existing semantic
wikis. First, we can improve the usability and achieve a shallow learning
curve. Second, ACE is more expressive than the formal languages of existing
semantic wikis. Our evaluation shows that people who are not familiar with the
formal foundations of the Semantic Web are able to deal with AceWiki after a
very short learning phase and without the help of an expert.
</summary>
    <author>
      <name>Tobias Kuhn</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To be published as: Proceedings of Semantic Web User Interaction at
  CHI 2008: Exploring HCI Challenges, CEUR Workshop Proceedings</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings of the Fifth International Workshop on Semantic Web
  User Interaction (SWUI 2008), CEUR Workshop Proceedings, Volume 543, 2009</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0807.4618v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0807.4618v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.2; I.2.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0809.3447v1</id>
    <updated>2008-09-19T19:56:15Z</updated>
    <published>2008-09-19T19:56:15Z</published>
    <title>An Exploratory Study of Calendar Use</title>
    <summary>  In this paper, we report on findings from an ethnographic study of how people
use their calendars for personal information management (PIM). Our participants
were faculty, staff and students who were not required to use or contribute to
any specific calendaring solution, but chose to do so anyway. The study was
conducted in three parts: first, an initial survey provided broad insights into
how calendars were used; second, this was followed up with personal interviews
of a few participants which were transcribed and content-analyzed; and third,
examples of calendar artifacts were collected to inform our analysis. Findings
from our study include the use of multiple reminder alarms, the reliance on
paper calendars even among regular users of electronic calendars, and wide use
of calendars for reporting and life-archival purposes. We conclude the paper
with a discussion of what these imply for designers of interactive calendar
systems and future work in PIM research.
</summary>
    <author>
      <name>Manas Tungare</name>
    </author>
    <author>
      <name>Manuel Perez-Quinones</name>
    </author>
    <author>
      <name>Alyssa Sams</name>
    </author>
    <link href="http://arxiv.org/abs/0809.3447v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0809.3447v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0809.3597v1</id>
    <updated>2008-09-21T18:05:42Z</updated>
    <published>2008-09-21T18:05:42Z</published>
    <title>Spreadsheets: Aiming the Accountant's Hammer to Hit the Nail on the Head</title>
    <summary>  Accounting and Finance (A&amp;F) Professionals are arguably the most loyal and
concentrated population of spreadsheet users. The work that they perform in
spreadsheets has the most significant impact on financial data and business
processes within global organizations today. Spreadsheets offer the flexibility
and ease of use of a desktop application, combined with the power to perform
complex data analysis. They are also the lowest cost business IT tool when
stacked up against other functional tools. As a result, spreadsheets are used
to support critical business processes in most organizations. In fact, research
indicates that over half of financial management reporting is performed with
spreadsheets by an accounting and finance professional. A disparity exists in
the business world between the importance of spreadsheets on financial data
(created by A&amp;F Professionals) and the resources devoted to: The development
and oversight of global spreadsheet standards; A recognized and accredited
certification in spreadsheet proficiency; Corporate sponsored and required
training; Awareness of emerging technologies as it relates to spreadsheet use.
This management paper focuses on the current topics relevant to the largest
user group (A&amp;F Professionals) of the most widely used financial software
application, spreadsheets, also known as the accountant's hammer.
</summary>
    <author>
      <name>Mbwana Alliy</name>
    </author>
    <author>
      <name>Patty Brown</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 Pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2008 163-170
  ISBN 978-905617-69-2</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0809.3597v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0809.3597v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0809.3612v1</id>
    <updated>2008-09-21T20:16:14Z</updated>
    <published>2008-09-21T20:16:14Z</published>
    <title>Overview and main results of the DidaTab project</title>
    <summary>  The DidaTab project (Didactics of Spreadsheet, teaching and learning
spreadsheets) is a three year project (2005-2007) funded by the French Ministry
of Research and dedicated to the study of personal and classroom uses of
spreadsheets in the French context, focussing on the processes of appropriation
and uses by secondary school students. In this paper, we present an overview of
the project, briefly report the studies performed in the framework of the
DidaTab project, and give the main results we obtained. We then explore the new
research tracks we intend to develop, more in connection with EuSpRIG. Our main
result is that the use of spreadsheet during secondary education (grade 6 to
12) is rather sparse for school work (and even more seldom at home) and that
student competencies are weak. Curricula have to be reviewed to include more
training of dynamics tabular tools (including databases queries) in order to
ensure sufficient mastery of computer tools that have became necessary in many
educational activities.
</summary>
    <author>
      <name>Francois-Marie Blondel</name>
    </author>
    <author>
      <name>Eric Bruillard</name>
    </author>
    <author>
      <name>Francoise Tort</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 Pages, 5 Figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2008 187-198
  ISBN 978-905617-69-2</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0809.3612v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0809.3612v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0810.4431v1</id>
    <updated>2008-10-24T11:50:03Z</updated>
    <published>2008-10-24T11:50:03Z</published>
    <title>An Eye Tracking Study into the Effects of Graph Layout</title>
    <summary>  Graphs are typically visualized as node-link diagrams. Although there is a
fair amount of research focusing on crossing minimization to improve
readability, little attention has been paid on how to handle crossings when
they are an essential part of the final visualizations. This requires us to
understand how people read graphs and how crossings affect reading performance.
  As an initial step to this end, a preliminary eye tracking experiment was
conducted. The specific purpose of this experiment was to test the effects of
crossing angles and geometric-path tendency on eye movements and performance.
Sixteen subjects performed both path search and node locating tasks with six
drawings. The results showed that small angles can slow down and trigger extra
eye movements, causing delays for path search tasks, whereas crossings have
little impact on node locating tasks. Geometric-path tendency indicates that a
path between two nodes can become harder to follow when many branches of the
path go toward the target node. The insights obtained are discussed with a view
to further confirmation in future work.
</summary>
    <author>
      <name>Weidong Huang</name>
    </author>
    <link href="http://arxiv.org/abs/0810.4431v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0810.4431v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0810.4884v2</id>
    <updated>2008-11-11T13:54:54Z</updated>
    <published>2008-10-27T17:42:05Z</published>
    <title>The adaptability of physiological systems optimizes performance: new
  directions in augmentation</title>
    <summary>  This paper contributes to the human-machine interface community in two ways:
as a critique of the closed-loop AC (augmented cognition) approach, and as a
way to introduce concepts from complex systems and systems physiology into the
field. Of particular relevance is a comparison of the inverted-U (or Gaussian)
model of optimal performance and multidimensional fitness landscape model.
Hypothetical examples will be given from human physiology and learning and
memory. In particular, a four-step model will be introduced that is proposed as
a better means to characterize multivariate systems during behavioral processes
with complex dynamics such as learning. Finally, the alternate approach
presented herein is considered as a preferable design alternate in
human-machine systems. It is within this context that future directions are
discussed.
</summary>
    <author>
      <name>Bradly Alicea</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 7 figures, 1 table (review, theoretical overview paper)</arxiv:comment>
    <link href="http://arxiv.org/abs/0810.4884v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0810.4884v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0904.0719v1</id>
    <updated>2009-04-04T15:08:43Z</updated>
    <published>2009-04-04T15:08:43Z</published>
    <title>Moveable objects and applications, based on them</title>
    <summary>  The inner views of all our applications are predetermined by the designers;
only some non-significant variations are allowed with the help of adaptive
interface. In several programs you can find some moveable objects, but it is an
extremely rare thing. However, the design of applications on the basis of
moveable and resizable objects opens an absolutely new way of programming; such
applications are much more effective in users' work, because each user can
adjust an application to his purposes. Programs, using adaptive interface, only
implement the designer's ideas of what would be the best reaction to any of the
users' doings or commands. Applications on moveable elements do not have such
predetermined system of rules; they are fully controlled by the users. This
article describes and demonstrates the new way of applications' design.
</summary>
    <author>
      <name>Sergey Andreyev</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 13 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0904.0719v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0904.0719v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0904.2096v1</id>
    <updated>2009-04-14T11:21:47Z</updated>
    <published>2009-04-14T11:21:47Z</published>
    <title>A Distributed Software Architecture for Collaborative Teleoperation
  based on a VR Platform and Web Application Interoperability</title>
    <summary>  Augmented Reality and Virtual Reality can provide to a Human Operator (HO) a
real help to complete complex tasks, such as robot teleoperation and
cooperative teleassistance. Using appropriate augmentations, the HO can
interact faster, safer and easier with the remote real world. In this paper, we
present an extension of an existing distributed software and network
architecture for collaborative teleoperation based on networked human-scaled
mixed reality and mobile platform. The first teleoperation system was composed
by a VR application and a Web application. However the 2 systems cannot be used
together and it is impossible to control a distant robot simultaneously. Our
goal is to update the teleoperation system to permit a heterogeneous
collaborative teleoperation between the 2 platforms. An important feature of
this interface is based on different Mobile platforms to control one or many
robots.
</summary>
    <author>
      <name>Christophe Domingues</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IBISC</arxiv:affiliation>
    </author>
    <author>
      <name>Samir Otmane</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IBISC</arxiv:affiliation>
    </author>
    <author>
      <name>Frédéric Davesne</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IBISC</arxiv:affiliation>
    </author>
    <author>
      <name>Malik Mallem</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IBISC</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">18th International Conference on Artificial Reality and
  Telexistence (ACM ICAT 2008), Yokohama : Japon (2008)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0904.2096v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0904.2096v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0905.0200v1</id>
    <updated>2009-05-02T11:42:50Z</updated>
    <published>2009-05-02T11:42:50Z</published>
    <title>A Vehicle for Research: Using Street Sweepers to Explore the Landscape
  of Environmental Community Action</title>
    <summary>  Researchers are developing mobile sensing platforms to facilitate public
awareness of environmental conditions. However, turning such awareness into
practical community action and political change requires more than just
collecting and presenting data. To inform research on mobile environmental
sensing, we conducted design fieldwork with government, private, and public
interest stakeholders. In parallel, we built an environmental air quality
sensing system and deployed it on street sweeping vehicles in a major U.S.
city; this served as a "research vehicle" by grounding our interviews and
affording us status as environmental action researchers. In this paper, we
present a qualitative analysis of the landscape of environmental action,
focusing on insights that will help researchers frame meaningful technological
interventions.
</summary>
    <author>
      <name>Paul M. Aoki</name>
    </author>
    <author>
      <name>R. J. Honicky</name>
    </author>
    <author>
      <name>Alan Mainwaring</name>
    </author>
    <author>
      <name>Chris Myers</name>
    </author>
    <author>
      <name>Eric Paulos</name>
    </author>
    <author>
      <name>Sushmita Subramanian</name>
    </author>
    <author>
      <name>Allison Woodruff</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/1518701.1518762</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/1518701.1518762" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. ACM SIGCHI Conf. on Human Factors in Computing Systems,
  Boston, MA, Apr. 2009, 375-384. ACM Press</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0905.0200v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0905.0200v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.m" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0905.0203v1</id>
    <updated>2009-05-02T11:54:52Z</updated>
    <published>2009-05-02T11:54:52Z</published>
    <title>ICTD for Healthcare in Ghana: Two Parallel Case Studies</title>
    <summary>  This paper examines two parallel case studies to promote remote medical
consultation in Ghana. These projects, initiated independently by different
researchers in different organizations, both deployed ICT solutions in the same
medical community in the same year. The Ghana Consultation Network currently
has over 125 users running a Web-based application over a delay-tolerant
network of servers. OneTouch MedicareLine is currently providing 1700 doctors
in Ghana with free mobile phone calls and text messages to other members of the
medical community. We present the consequences of (1) the institutional context
and identity of the investigators, as well as specific decisions made with
respect to (2) partnerships formed, (3) perceptions of technological
infrastructure, and (4) high-level design decisions. In concluding, we discuss
lessons learned and high-level implications for future ICTD research agendas.
</summary>
    <author>
      <name>Rowena Luk</name>
    </author>
    <author>
      <name>Matei Zaharia</name>
    </author>
    <author>
      <name>Melissa Ho</name>
    </author>
    <author>
      <name>Brian Levine</name>
    </author>
    <author>
      <name>Paul M. Aoki</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/ICTD.2009.5426714</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/ICTD.2009.5426714" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. IEEE/ACM Conf. on Information and Communication Technologies
  and Development, Doha, Qatar, Apr. 2009, 118-128. IEEE CS Press</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0905.0203v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0905.0203v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.m; J.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0905.0484v1</id>
    <updated>2009-05-04T20:32:22Z</updated>
    <published>2009-05-04T20:32:22Z</published>
    <title>Extended Bulgarian keyboard layouts</title>
    <summary>  The old Bulgarian keyboard standard BDS 5237-78 was developed for use mostly
on typewriter machines. The wide distribution of the computers forced the
update of this standard. On one hand this is because of the need to support
symbols such as the Bulgarian quotation marks, the Cyrillic letter I with grave
accent, the long dash, etc. On the other hand the so called "phonetic layout"
became popular and this layout is not standartized by BDS. In this work we are
analyzing the possibilities to improve the keyboard layout according to BDS
5237-78, as well as the traditional phonetic layout. At the same time we are
making a comparison with the new proposed Bulgarian keyboard layout standard
BDS 5237:2006. We are proposing an algorithm for placement of additional
symbols on the keys of the keyboard in a way that makes easy for the users to
find the symbols even when they are not inscripted on the keys. We are giving
formal definitions and illustrations of four keyboard layouts - three extended
keyboard layouts for typing in "Cyrillic" mode (BDS, traditional phonetic and
phonetic according to the new proposed BDS 5237:2006) and one extended layout
for typing in "Latin" mode.
</summary>
    <author>
      <name>Anton Zinoviev</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">32 pages, in Bulgarian</arxiv:comment>
    <link href="http://arxiv.org/abs/0905.0484v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0905.0484v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0906.2307v1</id>
    <updated>2009-06-12T13:47:46Z</updated>
    <published>2009-06-12T13:47:46Z</published>
    <title>Shopping Uncertainties in a Mobile and Social Context</title>
    <summary>  We conducted a qualitative user study with 77 consumers to investigate what
social aspects are relevant when supporting customers during their shopping
activities and particularly in situations when they are undecided. Twenty-five
respondents (32%) reported seeking extra information on web pages and forums,
in addition to asking their peers for advice (related to the nature of the item
to be bought). Moreover, from the remaining 52 subjects, only 6 (8%) were
confident enough to make prompt comparisons between items and an immediate
purchasing choice, while 17 respondents (22%) expressed the need for being away
from persuasive elements. The remaining 29 respondents (38%) reported having a
suboptimal strategy for making their shopping decisions (i.e. buying all items,
not buying, or choosing randomly). Therefore, the majority of our participants
(70% = 32% + 38%) had social and information needs when making purchasing
decisions. This result motivates the development of applications that would
allow consumers to ask shopping questions to their social network while
on-the-go.
</summary>
    <author>
      <name>Mauro Cherubini</name>
    </author>
    <author>
      <name>Rodrigo de Oliveira</name>
    </author>
    <author>
      <name>Nuria Oliver</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented in the Late Breaking Results category of Pervasive 2009.
  May 11-14, Nara, Japan. http://www.pervasive2009.org/</arxiv:comment>
    <link href="http://arxiv.org/abs/0906.2307v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0906.2307v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0907.5500v1</id>
    <updated>2009-07-31T10:06:29Z</updated>
    <published>2009-07-31T10:06:29Z</published>
    <title>Decoding Finger Flexion using amplitude modulation from band-specific
  ECoG</title>
    <summary>  EEG-BCIs have been well studied in the past decades and implemented into
several famous applications, like P300 speller and wheelchair controller.
However, these interfaces are indirect due to low spatial resolution of EEG.
Recently, direct ECoG-BCIs attract intensive attention because ECoG provides a
higher spatial resolution and signal quality. This makes possible localization
of the source of neural signals with respect to certain brain functions. In
this article, we present a realization of ECoG-BCIs for finger flexion
prediction provided by BCI competition IV. Methods for finger flexion
prediction including feature extraction and selection are provided in this
article. Results show that the predicted finger movement is highly correlated
with the true movement when we use band-specific amplitude modulation.
</summary>
    <author>
      <name>Nanying Liang</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Lorraine - LORIA</arxiv:affiliation>
    </author>
    <author>
      <name>Laurent Bougrain</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Lorraine - LORIA</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">European Symposium on Artificial Neural Networks (ESANN) (2009)
  467-472</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0907.5500v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0907.5500v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0908.0930v1</id>
    <updated>2009-08-06T18:41:34Z</updated>
    <published>2009-08-06T18:41:34Z</published>
    <title>Some Spreadsheet Poka-Yoke</title>
    <summary>  Whilst not all spreadsheet defects are structural in nature, poor layout
choices can compromise spreadsheet quality. These defects may be avoided at the
development stage by some simple mistake prevention and detection devices.
Poka-Yoke (Japanese for Mistake Proofing), which owes its genesis to the Toyota
Production System (the standard for manufacturing excellence throughout the
world) offers some principles that may be applied to reducing spreadsheet
defects. In this paper we examine spreadsheet structure and how it can lead to
defects and illustrate some basic spreadsheet Poka-Yokes to reduce them. These
include guidelines on how to arrange areas of cells so that whole rows and
columns can be inserted anywhere without causing errors, and rules for when to
use relative and absolute references with respect to what type of area is being
referred to.
</summary>
    <author>
      <name>Bill Bekenn</name>
    </author>
    <author>
      <name>Ray Hooper</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 Pages, 8 Colour Figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2009 83-94
  ISBN 978-1-905617-89-0</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0908.0930v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0908.0930v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0908.0935v1</id>
    <updated>2009-08-06T19:03:02Z</updated>
    <published>2009-08-06T19:03:02Z</published>
    <title>An Exploratory Analysis of the Impact of Named Ranges on the Debugging
  Performance of Novice Users</title>
    <summary>  This paper describes an exploratory empirical study of the effect of named
ranges on spreadsheet debugging performance. Named ranges are advocated in both
academia and industry, yet no experimental evidence has been cited to back up
these recommendations. This paper describes an exploratory experiment involving
21 participants that assesses the performance of novices debugging a
spreadsheet containing named ranges. The results are compared with the
performance of a different set of novices debugging the same spreadsheet
without named ranges. The findings suggest that novice users debug on average
significantly fewer errors if the spreadsheet contains named ranges. The
purpose of the investigative study is to derive a detailed and coherent set of
research questions regarding the impact of range names on the debugging
performance and behaviour of spreadsheet users. These will be answered through
future controlled experiments.
</summary>
    <author>
      <name>Ruth McKeever</name>
    </author>
    <author>
      <name>Kevin McDaid</name>
    </author>
    <author>
      <name>Brian Bishop</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 Pages, 4 Figures. Winner of the 2009 David Chadwick Prize for Best
  Student Paper</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2009 69-81
  ISBN 978-1-905617-89-0</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0908.0935v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0908.0935v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0908.1189v1</id>
    <updated>2009-08-08T21:02:41Z</updated>
    <published>2009-08-08T21:02:41Z</published>
    <title>Milestones for Teaching the Spreadsheet Program</title>
    <summary>  There are different manners of teaching a spreadsheet program. In any case,
it is intended that the teacher settles the objectives of the course and adapts
them to the particular audience he/she has to deal with. This paper aims at
providing any teacher whatever his/her specific objectives and his/her audience
with elements to help him/her building a course. It focuses mainly on two
important issues: 1 - select in all that may be said about such complex tools,
what is prior to know and to teach, i.e. what leads to autonomy in using but
also to autonomy in learning (because everything cannot be taught) and 2 - show
how concepts are closely related to good formatting considerations. A method
based on the "invariants of information processing" is outlined, partially
illustrated and an implementation is described throughout a course designed for
students preparing a master in Education Sciences.
</summary>
    <author>
      <name>Etienne Vandeput</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 Pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2009 133-143
  ISBN 978-1-905617-89-0</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0908.1189v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0908.1189v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0908.1580v1</id>
    <updated>2009-08-11T21:05:06Z</updated>
    <published>2009-08-11T21:05:06Z</published>
    <title>From error detection to behaviour observation: first results from screen
  capture analysis</title>
    <summary>  This paper deals with errors in using spreadsheets and analysis of automatic
recording of user interaction with spreadsheets. After a review of literature
devoted to spreadsheet errors, we advocate the importance of going from error
detection to interaction behaviour analysis. We explain how we analyze screen
captures and give the main results we have obtained using this specific
methodology with secondary school students (N=24). Transcription provides
general characteristics: time, sequence of performed tasks, unsuccessful
attempts and user preferences. Analysis reveals preferred modes of actions
(toolbar buttons or menu commands), ways of writing formulas, and typical
approaches in searching for solutions. Time, rhythm and density appear to be
promising indicators. We think such an approach (to analyze screen captures)
could be used with more advanced spreadsheet users.
</summary>
    <author>
      <name>Francoise Tort</name>
    </author>
    <author>
      <name>Francois-Marie Blondel</name>
    </author>
    <author>
      <name>Eric Bruillard</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 Pages; 4 Figures, 6 Tables; ISBN 978-1-905617-89-0</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2009 119-132</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0908.1580v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0908.1580v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0908.1584v1</id>
    <updated>2009-08-11T21:15:42Z</updated>
    <published>2009-08-11T21:15:42Z</published>
    <title>Reducing the Risk of Spreadsheet Usage - a Case Study</title>
    <summary>  The frequency with which spreadsheets are used and the associated risk is
well known. Many tools and techniques have been developed which help reduce
risks associate with creating and maintaining spreadsheet. However, little
consideration has been given to reducing the risks of routine usage by the
"consumers" - for example when entering and editing data. EASA's solution,
available commercially, ensures that any routine process involving spreadsheets
can be executed rapidly and without errors by the end-users, often with a
significant reduction in manual effort. Specifically, the technology enables
the rapid creation and deployment of web-based applications, connected to one
or more centralized spreadsheets; this ensures version control, easy and error
free usage, and security of intellectual property contained in spreadsheets.
</summary>
    <author>
      <name>Mel Glass</name>
    </author>
    <author>
      <name>David Ford</name>
    </author>
    <author>
      <name>Sebastian Dewhurst</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 Pages, 7 Figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2009 163-172
  ISBN 978-1-905617-89-0</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0908.1584v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0908.1584v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0908.3022v1</id>
    <updated>2009-08-20T21:31:20Z</updated>
    <published>2009-08-20T21:31:20Z</published>
    <title>An approach for the automated risk assessment of structural differences
  between spreadsheets (DiffXL)</title>
    <summary>  This paper outlines an approach to manage and quantify the risks associated
with changes made to spreadsheets. The methodology focuses on structural
differences between spreadsheets and suggests a technique by which a risk
analysis can be achieved in an automated environment. The paper offers an
example that demonstrates how contiguous ranges of data can be mapped into a
generic list of formulae, data and metadata. The example then shows that
comparison of these generic lists can establish the structural differences
between spreadsheets and quantify the level of risk that each change has
introduced. Lastly the benefits, drawbacks and limitations of the technique are
discussed in a commercial context.
</summary>
    <author>
      <name>John Hunt</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 Pages, Numerous Colour Diagrams &amp; Screenshots</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2009 ISBN
  978-1-905617-89-0</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0908.3022v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0908.3022v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0908.3362v1</id>
    <updated>2009-08-24T06:04:46Z</updated>
    <published>2009-08-24T06:04:46Z</published>
    <title>The Function of Gesture in an Architectural Design Meeting</title>
    <summary>  This text presents a cognitive-psychology analysis of spontaneous, co-speech
gestures in a face-to-face architectural design meeting (A1 in DTRS7). The
long-term objective is to formulate specifications for remote
collaborative-design systems, especially for supporting the use of different
semiotic modalities (multi-modal interaction). According to their function for
design, interaction, and collaboration, we distinguish different gesture
families: representational (entity designating or specifying), organisational
(management of discourse, interaction, or functional design actions),
focalising, discourse and interaction modulating, and disambiguating gestures.
Discussion and conclusion concern the following points. It is impossible to
attribute fixed functions to particular gesture forms. "Designating" gestures
may also have a design function. The gestures identified in A1 possess a
certain generic character. The gestures identified are neither systematically
irreplaceable, nor optional accessories to speech or drawing. We discuss the
possibilities for gesture in computer-supported collaborative software systems.
The paper closes on our contribution to gesture studies and cognitive design
research.
</summary>
    <author>
      <name>Willemien Visser</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LTCI</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">About: Designing. Analysing design meetings, Janet McDonnell and
  Peter Lloyd (Ed.) (2009) 269-284</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0908.3362v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0908.3362v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0909.0237v5</id>
    <updated>2009-11-08T01:54:35Z</updated>
    <published>2009-09-01T18:31:17Z</published>
    <title>Is the crowd's wisdom biased? A quantitative asessment of three online
  communities</title>
    <summary>  This paper presents a study of user voting on three websites: Imdb, Amazon
and BookCrossings. It reports on an expert evaluation of the voting mechanisms
of each website and a quantitative data analysis of users' aggregate voting
behavior. The results suggest that voting follows different patterns across the
websites, with higher barrier to vote introducing a more of one-off voters and
attracting mostly experts. The results also show that that one-off voters tend
to vote on popular items, while experts mostly vote for obscure, low-rated
items. The study concludes with design suggestions to address the "wisdom of
the crowd" bias.
</summary>
    <author>
      <name>Vassilis Kostakos</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/CSE.2009.491</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/CSE.2009.491" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages, 6 tagles</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Computational Science and Engineering, p. 251-255, 2009</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0909.0237v5" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0909.0237v5" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0909.1138v3</id>
    <updated>2009-11-02T01:46:35Z</updated>
    <published>2009-09-07T03:15:42Z</published>
    <title>User Experience, Software Interfaces, and The Unconscious</title>
    <summary>  Ideas about how to increase the unconscious participation in interaction
between 'a human' and 'a computer' are developed in this paper. Evidence of
impact of the unconscious functioning is presented. The unconscious is
characterised as being a responsive, contextual, and autonomous participant of
human-computer interaction. The unconscious participation occurs independently
of one's cognitive and educational levels and, if ignored, leads to learning
inefficiencies and compulsive behaviours, illustrations of which are provided.
Three practical approaches to a study of subjective user experience are
outlined as follows: (a) tracing operant conditioning effects of software, (b)
registering signs of brain activity psychological or information processing
meaning of which is well-explored and (c) exploring submodality interfaces.
Implications for improvement of current usability study methods, such as
eye-tracking, are generally considered. Conclusions consider advantages and
disadvantages of unconscious-embracing design and remind about a loss of human
evolutionary choices if unconscious participation is ignored, complicated or
blocked in interaction with computer interfaces and built environment.
</summary>
    <author>
      <name>Richard V. Diamond</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Under Review</arxiv:comment>
    <link href="http://arxiv.org/abs/0909.1138v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0909.1138v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="A.1; C.4; H.1.2; H.5.2; K.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0909.2185v1</id>
    <updated>2009-09-11T14:49:10Z</updated>
    <published>2009-09-11T14:49:10Z</published>
    <title>SeeReader: An (Almost) Eyes-Free Mobile Rich Document Viewer</title>
    <summary>  Reading documents on mobile devices is challenging. Not only are screens
small and difficult to read, but also navigating an environment using limited
visual attention can be difficult and potentially dangerous. Reading content
aloud using text-tospeech (TTS) processing can mitigate these problems, but
only for content that does not include rich visual information. In this paper,
we introduce a new technique, SeeReader, that combines TTS with automatic
content recognition and document presentation control that allows users to
listen to documents while also being notified of important visual content.
Together, these services allow users to read rich documents on mobile devices
while maintaining awareness of their visual environment.
</summary>
    <author>
      <name>Scott Carter</name>
    </author>
    <author>
      <name>Laurent Denoue</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Science Issues, Volume 1, pp36-41,
  August 2009</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">S. Carter and L. Denoue, "SeeReader: An (Almost) Eyes-Free Mobile
  Rich Document Viewer ", International Journal of Computer Science Issues,
  Volume 1, pp36-41, August 2009</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0909.2185v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0909.2185v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0910.5386v1</id>
    <updated>2009-10-28T14:31:53Z</updated>
    <published>2009-10-28T14:31:53Z</published>
    <title>A theoretical foundation for building Knowledge-work Support Systems</title>
    <summary>  In this paper we propose a novel approach aimed at building a new class of
information system platforms which we call the "Knowledge-work Support Systems"
or KwSS. KwSS can play a significant role in enhancing the IS support for
knowledge management processes, including those customarily identified as less
amenable to IS support. In our approach we try to enhance basic functionalities
provided by the computer-based information systems, namely, that of improving
the efficiency of the knowledge workers in accessing, processing and creating
useful information. The improvement, along with proper focus on cultural,
social and other aspects of the knowledge management processes, can enhance the
workers' efficiency significantly in performing high quality knowledge works.
In order to build the proposed approach, we develop several new concepts. The
approach analyzes the information availability and usage from the knowledge
workers and their works' perspectives and consequently brings forth more
transparency in various aspects of information life-cycle with respect to
knowledge management. KsSSes are technology platforms, which can be implemented
independently as well as in conjunction with other knowledge management and
data management technology platforms, to provide significant boost in the
knowledge capabilities of organizations.
</summary>
    <author>
      <name>Arijit Laha</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">40 pages, Created June 2008</arxiv:comment>
    <link href="http://arxiv.org/abs/0910.5386v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0910.5386v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0911.0838v2</id>
    <updated>2010-01-04T14:32:53Z</updated>
    <published>2009-11-04T19:45:55Z</published>
    <title>Research report : Collaborative Peer 2 Peer Edition: Avoiding Conflicts
  is Better than Solving Conflicts</title>
    <summary>  Collaborative edition is achieved by distinct sites that work independently
on (a copy of) a shared document. Conflicts may arise during this process and
must be solved by the collaborative editor. In pure Peer to Peer collaborative
editing, no centralization nor locks nor time-stamps are used which make
conflict resolution difficult. We propose an algorithm which relies on the
notion or semantics dependence and avoids the need of any integration
transformation to solve conflicts. Furthermore, it doesn't use any history file
recording operations performed since starting the edition process. We show how
to define editing operations for semi-structured documents i.e. XML-like trees,
that are enriched with informations derived for free from the editing process.
Then we define the semantics dependence relation required by the algorithm and
we present preliminary results obtained by a prototype implementation.
</summary>
    <author>
      <name>Stéphane Martin</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIF</arxiv:affiliation>
    </author>
    <author>
      <name>Denis Lugiez</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIF</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/0911.0838v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0911.0838v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0911.1288v1</id>
    <updated>2009-11-06T16:06:40Z</updated>
    <published>2009-11-06T16:06:40Z</published>
    <title>What is instrumentality in new digital msuical devices ? A contribution
  from cognitive linguistics and psychology</title>
    <summary>  As far as music is concerned, instruments have always been part of a cultural
?landscape? (on technical, expressive and symbolic levels). The present
contribution explores the changes brought about by the shift that occurred
during the 20th century, from mechanical to digital instruments (also named
?virtual instruments?). First and foremost, a short recall of some historical
steps of the technological developments that have renewed our relationship to
sound, music, and instruments will be presented. Second, an analysis of
different discourses and terminologies presently used in the domains of
musicology and computer music will account for the evolution of the notion of
instrumentality.
</summary>
    <author>
      <name>Caroline Cance</name>
    </author>
    <author>
      <name>Hugues Genevois</name>
    </author>
    <author>
      <name>Danièle Dubois</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">What is instrumentality in new digital musical devices ? A
  contribution from cognitive linguistics and psychology, Paris : France (2009)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0911.1288v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0911.1288v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0911.3644v1</id>
    <updated>2009-11-18T20:08:34Z</updated>
    <published>2009-11-18T20:08:34Z</published>
    <title>AnAmeter: The First Steps to Evaluating Adaptation</title>
    <summary>  This paper presents the online AnAmeter framework that helps characterize the
different types of adaptations a system features by helping the evaluator fill
in a simple form. The provided information is then processed to obtain a
quantitative evaluation of three parameters called global, semi-global and
local adaptation degrees. By characterizing and quantifying adaptation,
AnAmeter provides the first steps towards the evaluation of the quality of a
system's adaptation. AnAmeter is an open tool available as freeware on the web
and has been applied to a selection of well known systems. To build this
evaluation grid we also collected a number of systems that cover the full range
of adaptation types.
</summary>
    <author>
      <name>Franck Tarpin Bernard</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIESP</arxiv:affiliation>
    </author>
    <author>
      <name>Iza Marfisi-Schottman</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIESP</arxiv:affiliation>
    </author>
    <author>
      <name>Halima Habieb-Mammar</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">ICTT</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Sixth Workshop on User-Centred Design and Evaluation of Adaptive
  Systems, UMAP09 User Modeling, Adaptation, and Personalization, Trento :
  Italy (2009)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0911.3644v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0911.3644v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0912.0433v1</id>
    <updated>2009-12-02T15:16:27Z</updated>
    <published>2009-12-02T15:16:27Z</published>
    <title>On the issues of building Information Warehouses</title>
    <summary>  While performing knowledge-intensive tasks of professional nature, the
knowledge workers need to access and process large volume of information. Apart
from the quantity, they also require that the information received is of high
quality in terms of authenticity and details. This, in turn, requires that the
information delivered should also include argumentative support, exhibiting the
reasoning process behind their development and provenance to indicate their
lineage. In conventional document-centric practices for information management,
such details are difficult to capture, represent/archive and retrieve/deliver.
To achieve such capability we need to re-think some core issues of information
management from the above requirements perspective. In this paper we develop a
framework for comprehensive representation of information in archive, capturing
informational contents along with their context. We shall call it the
"Information Warehouse (IW)" framework of information archival. The IW is a
significant yet technologically realizable conceptual advancement which can
support efficiently some interesting classes of applications which can be very
useful to the knowledge workers.
</summary>
    <author>
      <name>Arijit Laha</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ACM Comptute 2010, January 22-23, 2010, Bangalore, India</arxiv:comment>
    <link href="http://arxiv.org/abs/0912.0433v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0912.0433v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0912.1810v1</id>
    <updated>2009-12-09T17:32:25Z</updated>
    <published>2009-12-09T17:32:25Z</published>
    <title>Emotions in Pervasive Computing Environments</title>
    <summary>  The ability of an intelligent environment to connect and adapt to real
internal sates, needs and behaviors' meaning of humans can be made possible by
considering users' emotional states as contextual parameters. In this paper, we
build on enactive psychology and investigate the incorporation of emotions in
pervasive systems. We define emotions, and discuss the coding of emotional
human markers by smart environments. In addition, we compare some existing
works and identify how emotions can be detected and modeled by a pervasive
system in order to enhance its service and response to users. Finally, we
analyze closely one XML-based language for representing and annotating emotions
known as EARL and raise two important issues which pertain to emotion
representation and modeling in XML-based languages.
</summary>
    <author>
      <name>Nevin Vunka Jungum</name>
    </author>
    <author>
      <name>Eric Laurent</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Science Issues, IJCSI Volume 6,
  Issue 1, pp8-22, November 2009</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">N. Vunka Jungum and E. LAURENT, "Emotions in Pervasive Computing
  Environments", International Journal of Computer Science Issues, IJCSI,
  Volume 6, pp8-22, November 2009</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0912.1810v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0912.1810v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0912.1838v1</id>
    <updated>2009-12-09T18:54:56Z</updated>
    <published>2009-12-09T18:54:56Z</published>
    <title>A Brief History of Context</title>
    <summary>  Context is a rich concept and is an elusive concept to define. The concept of
context has been studied by philosophers, linguists, psychologists, and
recently by computer scientists. Within each research community the term
context was interpreted in a certain way that is well-suited for their goals,
however no attempt was made to define context. In many areas of research in
computer science, notably on web-based services, human-computer interaction
(HCI), ubiquitous computing applications, and context-aware systems there is a
need to provide a formal operational definition of context. In this brief
survey an account of the early work on context, as well as the recent work on
many working definitions of context, context modeling, and a formalization of
context are given. An attempt is made to unify the different context models
within the formalization. A brief commentary on the usefulness of the
formalization in the development of context-aware and dependable systems is
included.
</summary>
    <author>
      <name>Kaiyu Wan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Science Issues, IJCSI Volume 6,
  Issue 2, pp33-43, November 2009</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">K. Wan, "A Brief History of Context", International Journal of
  Computer Science Issues, IJCSI, Volume 6, Issue 2, pp33-43, November 2009</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0912.1838v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0912.1838v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0912.2706v2</id>
    <updated>2010-01-21T15:32:07Z</updated>
    <published>2009-12-14T19:00:29Z</published>
    <title>On the theory of moveable objects</title>
    <summary>  User-driven applications belong to the new type of programs, in which users
get the full control of WHAT, WHEN, and HOW must appear on the screen. Such
programs can exist only if the screen view is organized not according with the
predetermined scenario, written by the developers, but if any screen object can
be moved, resized, and reconfigured by any user at any moment. This article
describes the algorithm, by which an object of an arbitrary shape can be turned
into moveable and resizable. It also explains some rules of such design and the
technique, which can be useful in many cases. Both the individual movements of
objects and their synchronous movements are analysed. After discussing the
individually moveable controls, different types of groups are analysed and the
arbitrary grouping of controls is considered.
</summary>
    <author>
      <name>Sergey Andreyev</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">30 pages, 12 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0912.2706v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0912.2706v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0912.5343v3</id>
    <updated>2010-02-22T11:26:37Z</updated>
    <published>2009-12-29T17:36:35Z</published>
    <title>Reconstructing Experiences through Sketching</title>
    <summary>  We present iScale, a survey tool for the retrospective elicitation of
longitudinal user experience data. iScale employs sketching in imposing a
process in the reconstruction of one's experiences with the aim to minimize
retrospection bias. Two versions, the Constructive and the Value-Account
iScale, were motivated by two distinct theories on how people reconstruct
emotional experiences from memory. These two versions were tested in two
separate studies. Study 1 aimed at providing qualitative insight into the use
of iScale and compared its performance to that of free-hand sketching. Study 2
compared the two versions of iScale to free recall, a control condition that
does not influence the reconstruction process. Significant differences between
iScale and free recall were found. Overall, iScale resulted in an increase in
the amount, the richness, and the test-retest reliability of recalled
information. These results provide support for the viability of retrospective
techniques as a cost-effective alternative to longitudinal studies.
</summary>
    <author>
      <name>Evangelos Karapanos</name>
    </author>
    <author>
      <name>Jean-Bernard Martens</name>
    </author>
    <author>
      <name>Marc Hassenzahl</name>
    </author>
    <link href="http://arxiv.org/abs/0912.5343v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0912.5343v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1001.0627v1</id>
    <updated>2010-01-05T20:55:50Z</updated>
    <published>2010-01-05T20:55:50Z</published>
    <title>The Labor Economics of Paid Crowdsourcing</title>
    <summary>  Crowdsourcing is a form of "peer production" in which work traditionally
performed by an employee is outsourced to an "undefined, generally large group
of people in the form of an open call." We present a model of workers supplying
labor to paid crowdsourcing projects. We also introduce a novel method for
estimating a worker's reservation wage--the smallest wage a worker is willing
to accept for a task and the key parameter in our labor supply model. It shows
that the reservation wages of a sample of workers from Amazon's Mechanical Turk
(AMT) are approximately log normally distributed, with a median wage of
$1.38/hour. At the median wage, the point elasticity of extensive labor supply
is 0.43. We discuss how to use our calibrated model to make predictions in
applied work. Two experimental tests of the model show that many workers
respond rationally to offered incentives. However, a non-trivial fraction of
subjects appear to set earnings targets. These "target earners" consider not
just the offered wage--which is what the rational model predicts--but also
their proximity to earnings goals. Interestingly, a number of workers clearly
prefer earning total amounts evenly divisible by 5, presumably because these
amounts make good targets.
</summary>
    <author>
      <name>John Horton</name>
    </author>
    <author>
      <name>Lydia Chilton</name>
    </author>
    <link href="http://arxiv.org/abs/1001.0627v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1001.0627v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1001.1685v1</id>
    <updated>2010-01-11T16:15:29Z</updated>
    <published>2010-01-11T16:15:29Z</published>
    <title>Assessing Cognitive Load on Web Search Tasks</title>
    <summary>  Assessing cognitive load on web search is useful for characterizing search
system features and search tasks with respect to their demands on the
searcher's mental effort. It is also helpful for examining how individual
differences among searchers (e.g. cognitive abilities) affect the search
process. We examined cognitive load from the perspective of primary and
secondary task performance. A controlled web search study was conducted with 48
participants. The primary task performance components were found to be
significantly related to both the objective and the subjective task difficulty.
However, the relationship between objective and subjective task difficulty and
the secondary task performance measures was weaker than expected. The results
indicate that the dual-task approach needs to be used with caution.
</summary>
    <author>
      <name>Jacek Gwizdka</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published in the special issue Hot Topic: Cognition and the Web</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Ergonomics Open Journal 2, 2009, 114-123</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1001.1685v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1001.1685v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
