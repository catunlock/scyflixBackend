<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3Dall%3Acs.MM%26id_list%3D%26start%3D0%26max_results%3D500" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=all:cs.MM&amp;id_list=&amp;start=0&amp;max_results=500</title>
  <id>http://arxiv.org/api/xENr0xkFqWbtZMjdDHqT/Ljis50</id>
  <updated>2017-10-08T00:00:00-04:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">1483</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">500</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/0809.0524v1</id>
    <updated>2008-09-02T21:48:28Z</updated>
    <published>2008-09-02T21:48:28Z</published>
    <title>Computer Art in the Former Soviet Bloc</title>
    <summary>  Documents early computer art in the Soviet bloc and describes Marxist art
theory.
</summary>
    <author>
      <name>Eric Engle</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">28 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/0809.0524v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0809.0524v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1105.0023v1</id>
    <updated>2011-04-29T21:34:21Z</updated>
    <published>2011-04-29T21:34:21Z</published>
    <title>Survey of Cognitive Radio Techniques in Wireless Network</title>
    <summary>  In this report, I surveyed the cognitive radio technique in wireless
networks. Researched several kinds of cognitive techniques about their
advantages and disadvantages.
</summary>
    <author>
      <name>Lu Lu</name>
    </author>
    <link href="http://arxiv.org/abs/1105.0023v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1105.0023v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1407.7337v1</id>
    <updated>2014-07-28T07:04:04Z</updated>
    <published>2014-07-28T07:04:04Z</published>
    <title>A Digital Watermarking Approach Based on DCT Domain Combining QR Code
  and Chaotic Theory</title>
    <summary>  This paper proposes a robust watermarking approach based on Discrete Cosine
Transform domain that combines Quick Response Code and chaotic system.
</summary>
    <author>
      <name>Qingbo Kang</name>
    </author>
    <author>
      <name>Ke Li</name>
    </author>
    <author>
      <name>Jichun Yang</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/WOCN.2014.6923098</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/WOCN.2014.6923098" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1407.7337v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1407.7337v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0409059v1</id>
    <updated>2004-09-30T19:08:55Z</updated>
    <published>2004-09-30T19:08:55Z</published>
    <title>From Digital Television to Internet?</title>
    <summary>  This paper provides a general technical overview of the Multimedia Home
Platform (MHP) specifications. MHP is a generic interface between digital
applications and user machines, whether they happen to be set top boxes,
digital TV sets or Multimedia PC's. MHP extends the DVB open standards.
Addressed are MHP architexture, System core and MHP Profiles.
</summary>
    <author>
      <name>Vita Hinze-Hoare</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0409059v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0409059v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0608119v1</id>
    <updated>2006-08-30T03:22:06Z</updated>
    <published>2006-08-30T03:22:06Z</published>
    <title>Security Analysis of A Chaos-based Image Encryption Algorithm</title>
    <summary>  The security of Fridrich Image Encryption Algorithm against brute-force
attack, statistical attack, known-plaintext attack and select-plaintext attack
is analyzed by investigating the properties of the involved chaotic maps and
diffusion functions. Based on the given analyses, some means are proposed to
strengthen the overall performance of the focused cryptosystem.
</summary>
    <author>
      <name>Shiguo Lian</name>
    </author>
    <author>
      <name>Jinsheng Sun</name>
    </author>
    <author>
      <name>Zhiquan Wang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages,4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0608119v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0608119v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0710.4821v1</id>
    <updated>2007-10-25T12:04:15Z</updated>
    <published>2007-10-25T12:04:15Z</published>
    <title>Multimedia Applications of Multiprocessor Systems-on-Chips</title>
    <summary>  This paper surveys the characteristics of multimedia systems. Multimedia
applications today are dominated by compression and decompression, but
multimedia devices must also implement many other functions such as security
and file management. We introduce some basic concepts of multimedia algorithms
and the larger set of functions that multimedia systems-on-chips must
implement.
</summary>
    <author>
      <name>Wayne Wolf</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted on behalf of EDAA (http://www.edaa.com/)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Dans Design, Automation and Test in Europe | Designers'Forum -
  DATE'05, Munich : Allemagne (2005)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0710.4821v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0710.4821v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0805.3538v1</id>
    <updated>2008-05-22T20:43:38Z</updated>
    <published>2008-05-22T20:43:38Z</published>
    <title>Covert Channels in SIP for VoIP signalling</title>
    <summary>  In this paper, we evaluate available steganographic techniques for SIP
(Session Initiation Protocol) that can be used for creating covert channels
during signaling phase of VoIP (Voice over IP) call. Apart from characterizing
existing steganographic methods we provide new insights by introducing new
techniques. We also estimate amount of data that can be transferred in
signalling messages for typical IP telephony call.
</summary>
    <author>
      <name>Wojciech Mazurczyk</name>
    </author>
    <author>
      <name>Krzysztof Szczypiorski</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-540-69403-8_9</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-540-69403-8_9" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0805.3538v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0805.3538v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0809.5154v1</id>
    <updated>2008-09-30T09:56:35Z</updated>
    <published>2008-09-30T09:56:35Z</published>
    <title>An Export Architecture for a Multimedia Authoring Environment</title>
    <summary>  In this paper, we propose an export architecture that provides a clear
separation of authoring services from publication services. We illustrate this
architecture with the LimSee3 authoring tool and several standard publication
formats: Timesheets, SMIL, and XHTML.
</summary>
    <author>
      <name>Jan Mikác</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rhône-Alpes / LIG Laboratoire d'Informatique de Grenoble</arxiv:affiliation>
    </author>
    <author>
      <name>Cécile Roisin</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rhône-Alpes / LIG Laboratoire d'Informatique de Grenoble</arxiv:affiliation>
    </author>
    <author>
      <name>Bao Le Duc</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">UPMC</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Dans DocEng'08 (2008) 28-31</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0809.5154v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0809.5154v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0903.4314v1</id>
    <updated>2009-03-25T12:16:29Z</updated>
    <published>2009-03-25T12:16:29Z</published>
    <title>Virtual Reality</title>
    <summary>  This paper is focused on the presentation of Virtual Reality principles
together with the main implementation methods and techniques. An overview of
the main development directions is included.
</summary>
    <author>
      <name>Dan L. Lacrama</name>
    </author>
    <author>
      <name>Dorina Fera</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, exposed on 4th International Conferences "Actualities and
  Perspectives on Hardware and Software" - APHS2007, Timisoara, Romania</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Ann. Univ. Tibiscus Comp. Sci. Series V (2007), 137-144</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0903.4314v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0903.4314v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0908.3082v1</id>
    <updated>2009-08-21T09:46:07Z</updated>
    <published>2009-08-21T09:46:07Z</published>
    <title>Component based platform for multimedia applications</title>
    <summary>  We propose a platform for distributed multimedia applications which
simplifies the development process and at the same time ensures application
portability, flexibility and performance. The platform is implemented using the
Netscape Portable Runtime (NSPR) and the Cross-Platform Component Object Model
(XPCOM).
</summary>
    <author>
      <name>Ovidiu Ratoi</name>
    </author>
    <author>
      <name>Piroska Haller</name>
    </author>
    <author>
      <name>Ioan Salomie</name>
    </author>
    <author>
      <name>Bela Genge</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7th IEEE RoEduNet International Conference, Cluj-Napoca, Romania,
  Aug. 2008, pp. 40-43, ISBN 978-973-662-393-6</arxiv:comment>
    <link href="http://arxiv.org/abs/0908.3082v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0908.3082v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0912.4880v1</id>
    <updated>2009-12-24T15:28:33Z</updated>
    <published>2009-12-24T15:28:33Z</published>
    <title>How Do Interactive Virtual Operas Shift Relationships between Music,
  Text and Image?</title>
    <summary>  In this paper we present the new genre of interactive operas implemented on
personal computers. They differ from traditional ones not only because they are
virtual, but mainly because they offer to composers and listeners new
perspectives of combinations and interactions between music, text and visual
aspects.
</summary>
    <author>
      <name>Alain Bonardi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">STMS</arxiv:affiliation>
    </author>
    <author>
      <name>Francis Rousseaux</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">STMS, CRESTIC</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Language, vision and music, John Benjamins Publishing Company
  (Ed.) (2002) 285-294</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0912.4880v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0912.4880v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.0026v1</id>
    <updated>2012-12-31T22:42:02Z</updated>
    <published>2012-12-31T22:42:02Z</published>
    <title>Bounding Lossy Compression using Lossless Codes at Reduced Precision</title>
    <summary>  An alternative approach to two-part 'critical compression' is presented.
Whereas previous results were based on summing a lossless code at reduced
precision with a lossy-compressed error or noise term, the present approach
uses a similar lossless code at reduced precision to establish absolute bounds
which constrain an arbitrary lossy data compression algorithm applied to the
original data.
</summary>
    <author>
      <name>John Scoville</name>
    </author>
    <link href="http://arxiv.org/abs/1301.0026v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.0026v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1409.4883v1</id>
    <updated>2014-09-17T07:33:46Z</updated>
    <published>2014-09-17T07:33:46Z</published>
    <title>Developing a Video Steganography Toolkit</title>
    <summary>  Although techniques for separate image and audio steganography are widely
known, relatively little has been described concerning the hiding of
information within video streams ("video steganography"). In this paper we
review the current state of the art in this field, and describe the key issues
we have encountered in developing a practical video steganography system. A
supporting video is also available online at
http://www.youtube.com/watch?v=YhnlHmZolRM
</summary>
    <author>
      <name>James Ridgway</name>
    </author>
    <author>
      <name>Mike Stannett</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1409.4883v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1409.4883v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.6656v1</id>
    <updated>2014-10-24T11:52:00Z</updated>
    <published>2014-10-24T11:52:00Z</published>
    <title>StegExpose - A Tool for Detecting LSB Steganography</title>
    <summary>  Steganalysis tools play an important part in saving time and providing new
angles of attack for forensic analysts. StegExpose is a solution designed for
use in the real world, and is able to analyse images for LSB steganography in
bulk using proven attacks in a time efficient manner. When steganalytic methods
are combined intelligently, they are able generate even more accurate results.
This is the prime focus of StegExpose.
</summary>
    <author>
      <name>Benedikt Boehm</name>
    </author>
    <link href="http://arxiv.org/abs/1410.6656v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.6656v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.06103v1</id>
    <updated>2015-02-21T13:19:34Z</updated>
    <published>2015-02-21T13:19:34Z</published>
    <title>Compressive sensing based velocity estimation in video data</title>
    <summary>  This paper considers the use of compressive sensing based algorithms for
velocity estimation of moving vehicles. The procedure is based on sparse
reconstruction algorithms combined with time-frequency analysis applied to
video data. This algorithm provides an accurate estimation of object's velocity
even in the case of a very reduced number of available video frames. The
influence of crucial parameters is analysed for different types of moving
vehicles.
</summary>
    <author>
      <name>Ana Miletic</name>
    </author>
    <author>
      <name>Nemanja Ivanovic</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1502.06103v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.06103v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.04958v1</id>
    <updated>2015-03-17T09:09:48Z</updated>
    <published>2015-03-17T09:09:48Z</published>
    <title>The blind detection for palette image watermarking without changing the
  color</title>
    <summary>  To hide a binary pattern in the palette image a steganographic scheme with
blind detection is considered. The embedding algorithm uses the Lehmer code by
palette color permutations for which the cover image palette is generally
required. The found transformation between the palette and RGB images allows to
extract the hidden data without any cover work.
</summary>
    <author>
      <name>V. N. Gorbachev</name>
    </author>
    <author>
      <name>E. M. Kaynarova</name>
    </author>
    <author>
      <name>I. K. Metelev</name>
    </author>
    <author>
      <name>O. V. Pavlovskaya</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1503.04958v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.04958v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1512.04354v1</id>
    <updated>2015-11-04T12:21:04Z</updated>
    <published>2015-11-04T12:21:04Z</published>
    <title>A proposal project for a blind image quality assessment by learning
  distortions from the full reference image quality assessments</title>
    <summary>  This short paper presents a perspective plan to build a null reference image
quality assessment. Its main goal is to deliver both the objective score and
the distortion map for a given distorted image without the knowledge of its
reference image.
</summary>
    <author>
      <name>Stéfane Paris</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">QGAR</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/QoMEX.2012.6263876</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/QoMEX.2012.6263876" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">International Workshop on Quality of Multimedia Experience, 2012,
  Melbourne, Australia</arxiv:comment>
    <link href="http://arxiv.org/abs/1512.04354v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1512.04354v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.04930v1</id>
    <updated>2016-05-16T20:12:02Z</updated>
    <published>2016-05-16T20:12:02Z</published>
    <title>Daala: A Perceptually-Driven Still Picture Codec</title>
    <summary>  Daala is a new royalty-free video codec based on perceptually-driven coding
techniques. We explore using its keyframe format for still picture coding and
show how it has improved over the past year. We believe the technology used in
Daala could be the basis of an excellent, royalty-free image format.
</summary>
    <author>
      <name>Jean-Marc Valin</name>
    </author>
    <author>
      <name>Nathan E. Egge</name>
    </author>
    <author>
      <name>Thomas Daede</name>
    </author>
    <author>
      <name>Timothy B. Terriberry</name>
    </author>
    <author>
      <name>Christopher Montgomery</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted for ICIP 2016, 5 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1605.04930v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.04930v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.06152v1</id>
    <updated>2016-06-20T14:52:47Z</updated>
    <published>2016-06-20T14:52:47Z</published>
    <title>A Note on Efficiency of Downsampling and Color Transformation in Image
  Quality Assessment</title>
    <summary>  Several existing and successful full reference image quality assessment (IQA)
models use linear color transformation and downsampling before measuring
similarity or quality of images. This paper indicates to the right order of
these two procedures and that the existing models have not chosen the more
efficient approach. In addition, efficiency of these metrics is not compared in
a fair basis in the literature.
</summary>
    <author>
      <name>Hossein Ziaei Nafchi</name>
    </author>
    <author>
      <name>Mohamed Cheriet</name>
    </author>
    <link href="http://arxiv.org/abs/1606.06152v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.06152v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1610.01955v1</id>
    <updated>2016-10-06T17:12:37Z</updated>
    <published>2016-10-06T17:12:37Z</published>
    <title>MoveSteg: A Method of Network Steganography Detection</title>
    <summary>  This article presents a new method for detecting a source point of time based
network steganography - MoveSteg. A steganography carrier could be an example
of multimedia stream made with packets. These packets are then delayed
intentionally to send hidden information using time based steganography
methods. The presented analysis describes a method that allows finding the
source of steganography stream in network that is under our management.
</summary>
    <author>
      <name>Krzysztof Szczypiorski</name>
    </author>
    <author>
      <name>Tomasz Tyl</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 7 figures, 3 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1610.01955v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1610.01955v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1702.05718v3</id>
    <updated>2017-06-21T08:13:53Z</updated>
    <published>2017-02-19T08:21:20Z</published>
    <title>Perceptual Compressive Sensing based on Contrast Sensitivity Function:
  Can we avoid non-visible redundancies acquisition?</title>
    <summary>  In this paper, we propose a novel CS approach in which the acquisition of
non-visible information is also avoided.
</summary>
    <author>
      <name>Seyed Hamid Safavi</name>
    </author>
    <author>
      <name>Farah Torkamani-Azar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted for publication in 25'th Iranian Conference on Electrical
  Engineering (ICEE2017)</arxiv:comment>
    <link href="http://arxiv.org/abs/1702.05718v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1702.05718v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.07788v1</id>
    <updated>2017-05-22T14:56:49Z</updated>
    <published>2017-05-22T14:56:49Z</published>
    <title>StegIbiza: Steganography in Club Music Implemented in Python</title>
    <summary>  This paper introduces the implementation of steganography method called
StegIbiza, which uses tempo modulation as hidden message carrier. With the use
of Python scripting language, a bit string was encoded and decoded using WAV
and MP3 files. Once the message was hidden into a music files, an internet
radio was created to evaluate broadcast possibilities. No dedicated music or
signal processing equipment was used in this StegIbiza implementation
</summary>
    <author>
      <name>Krzysztof Szczypiorski</name>
    </author>
    <author>
      <name>Wojciech Zydecki</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 4 figures, 1 table</arxiv:comment>
    <link href="http://arxiv.org/abs/1705.07788v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.07788v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0708.0598v2</id>
    <updated>2008-02-03T19:41:44Z</updated>
    <published>2007-08-04T02:38:19Z</published>
    <title>An Application of Chromatic Prototypes</title>
    <summary>  This paper has been withdrawn.
</summary>
    <author>
      <name>Matthew McCool</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper has been withdrawn</arxiv:comment>
    <link href="http://arxiv.org/abs/0708.0598v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0708.0598v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0410022v1</id>
    <updated>2004-10-11T12:34:02Z</updated>
    <published>2004-10-11T12:34:02Z</published>
    <title>RRL: A Rich Representation Language for the Description of Agent
  Behaviour in NECA</title>
    <summary>  In this paper, we describe the Rich Representation Language (RRL) which is
used in the NECA system. The NECA system generates interactions between two or
more animated characters. The RRL is an XML compliant framework for
representing the information that is exchanged at the interfaces between the
various NECA system modules. The full XML Schemas for the RRL are available at
http://www.ai.univie.ac.at/NECA/RRL
</summary>
    <author>
      <name>P. Piwek</name>
    </author>
    <author>
      <name>B. Krenn</name>
    </author>
    <author>
      <name>M. Schroeder</name>
    </author>
    <author>
      <name>M. Grice</name>
    </author>
    <author>
      <name>S. Baumann</name>
    </author>
    <author>
      <name>H. Pirker</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 4 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings of the AAMAS-02 Workshop ``Embodied conversational
  agents - let's specify and evaluate them!'', July 16 2002, Bologna, Italy.</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0410022v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0410022v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H5.1, H5.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0501044v1</id>
    <updated>2005-01-20T17:12:05Z</updated>
    <published>2005-01-20T17:12:05Z</published>
    <title>Augmented Segmentation and Visualization for Presentation Videos</title>
    <summary>  We investigate methods of segmenting, visualizing, and indexing presentation
videos by separately considering audio and visual data. The audio track is
segmented by speaker, and augmented with key phrases which are extracted using
an Automatic Speech Recognizer (ASR). The video track is segmented by visual
dissimilarities and augmented by representative key frames. An interactive user
interface combines a visual representation of audio, video, text, and key
frames, and allows the user to navigate a presentation video. We also explore
clustering and labeling of speaker data and present preliminary results.
</summary>
    <author>
      <name>Alexander Haubold</name>
    </author>
    <author>
      <name>John R. Kender</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0501044v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0501044v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.2.4;H.3.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0504106v1</id>
    <updated>2005-04-28T13:40:09Z</updated>
    <published>2005-04-28T13:40:09Z</published>
    <title>A Distributed Multimedia Communication System and its Applications to
  E-Learning</title>
    <summary>  In this paper we report on a multimedia communication system including a
VCoIP (Video Conferencing over IP) software with a distributed architecture and
its applications for teaching scenarios. It is a simple, ready-to-use scheme
for distributed presenting, recording and streaming multimedia content. We also
introduce and investigate concepts and experiments to IPv6 user and session
mobility, with the special focus on real-time video group communication.
</summary>
    <author>
      <name>Hans L. Cycon</name>
    </author>
    <author>
      <name>Thomas C. Schmidt</name>
    </author>
    <author>
      <name>Matthias Waehlisch</name>
    </author>
    <author>
      <name>Mark Palkow</name>
    </author>
    <author>
      <name>Henrik Regensburg</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Including 6 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE International Symposium on Consumer Electronics, Sept. 1-3,
  2004, Page(s):425 - 429</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0504106v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0504106v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="C.2.2; C.2.4; H.4.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0506070v1</id>
    <updated>2005-06-16T10:15:05Z</updated>
    <published>2005-06-16T10:15:05Z</published>
    <title>Data Visualization on Shared Usage Multi-Screen Environment</title>
    <summary>  The modern multimedia technologies based on the whole palette of hardware and
software facilities of real-time high-speed information processing, in a
combination with effective facilities of the remote access to information
resources, allow us to visualize diverse types of information. Data
visualization facilities &amp;#8211; is the face of the Automated Control System on
whom often judge about their efficiency. They take a special place, providing
visualization of the diverse information necessary for decision-making by a
final control link - the person allocated by certain powers.
</summary>
    <author>
      <name>Ph. D. Yuriy A. Chashkov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0506070v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0506070v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.1.1; H.5.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0603130v1</id>
    <updated>2006-03-31T19:36:03Z</updated>
    <published>2006-03-31T19:36:03Z</published>
    <title>Digital watermarking in the singular vector domain</title>
    <summary>  Many current watermarking algorithms insert data in the spatial or transform
domains like the discrete cosine, the discrete Fourier, and the discrete
wavelet transforms. In this paper, we present a data-hiding algorithm that
exploits the singular value decomposition (SVD) representation of the data. We
compute the SVD of the host image and the watermark and embed the watermark in
the singular vectors of the host image. The proposed method leads to an
imperceptible scheme for digital images, both in grey scale and color and is
quite robust against attacks like noise and JPEG compression.
</summary>
    <author>
      <name>Rashmi Agarwal</name>
    </author>
    <author>
      <name>M. S. Santhanam</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1142/S0219467808003131</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1142/S0219467808003131" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 21 figures, Elsevier class</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Image and Graphics, volume 8, page 351
  (2008)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0603130v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0603130v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0607087v1</id>
    <updated>2006-07-18T08:16:37Z</updated>
    <published>2006-07-18T08:16:37Z</published>
    <title>Un filtre temporel crédibiliste pour la reconnaissance d'actions
  humaines dans les vidéos</title>
    <summary>  In the context of human action recognition in video sequences, a temporal
belief filter is presented. It allows to cope with human action disparity and
low quality videos. The whole system of action recognition is based on the
Transferable Belief Model (TBM) proposed by P. Smets. The TBM allows to
explicitly model the doubt between actions. Furthermore, the TBM emphasizes the
conflict which is exploited for action recognition. The filtering performance
is assessed on real video sequences acquired by a moving camera and under
several unknown view angles.
</summary>
    <author>
      <name>Emmanuel Ramasso</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIS</arxiv:affiliation>
    </author>
    <author>
      <name>Michèle Rombaut</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIS</arxiv:affiliation>
    </author>
    <author>
      <name>Denis Pellerin</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIS</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0607087v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0607087v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0801.0625v1</id>
    <updated>2008-01-04T03:15:56Z</updated>
    <published>2008-01-04T03:15:56Z</published>
    <title>On the Robustness of the Delay-Based Fingerprint Embedding Scheme</title>
    <summary>  The delay-based fingerprint embedding was recently proposed to support more
users in secure media distribution scenario. In this embedding scheme, some
users are assigned the same fingerprint code with only different embedding
delay. The algorithm's robustness against collusion attacks is investigated.
However, its robustness against common desynchronization attacks, e.g.,
cropping and time shifting, is not considered. In this paper, desynchronization
attacks are used to break the delay-based fingerprint embedding algorithm. To
improve the robustness, two means are proposed to keep the embedded fingerprint
codes synchronized, i.e., adding a synchronization fingerprint and adopting the
relative delay to detect users. Analyses and experiments are given to show the
improvements.
</summary>
    <author>
      <name>Shiguo Lian</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages,6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0801.0625v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0801.0625v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.2.11; H.5.1; H.5.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0804.4865v1</id>
    <updated>2008-04-30T16:39:32Z</updated>
    <published>2008-04-30T16:39:32Z</published>
    <title>Characterizing Video Responses in Social Networks</title>
    <summary>  Video sharing sites, such as YouTube, use video responses to enhance the
social interactions among their users. The video response feature allows users
to interact and converse through video, by creating a video sequence that
begins with an opening video and followed by video responses from other users.
Our characterization is over 3.4 million videos and 400,000 video responses
collected from YouTube during a 7-day period. We first analyze the
characteristics of the video responses, such as popularity, duration, and
geography. We then examine the social networks that emerge from the video
response interactions.
</summary>
    <author>
      <name>Fabricio Benevenuto</name>
    </author>
    <author>
      <name>Fernando Duarte</name>
    </author>
    <author>
      <name>Tiago Rodrigues</name>
    </author>
    <author>
      <name>Virgilio Almeida</name>
    </author>
    <author>
      <name>Jussara Almeida</name>
    </author>
    <author>
      <name>Keith Ross</name>
    </author>
    <link href="http://arxiv.org/abs/0804.4865v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0804.4865v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.4; H.3.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0806.1543v1</id>
    <updated>2008-06-09T22:03:40Z</updated>
    <published>2008-06-09T22:03:40Z</published>
    <title>On the Superdistribution of Digital Goods</title>
    <summary>  Business models involving buyers of digital goods in the distribution process
are called superdistribution schemes. We review the state-of-the art of
research and application of superdistribution and propose systematic approach
to market mechanisms using super-distribution and technical system
architectures supporting it. The limiting conditions on such markets are of
economic, legal, technical, and psychological nature.
</summary>
    <author>
      <name>Andreas U. Schmidt</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Invited paper at the Wokshop 2008 International Workshop on
  Multimedia Security in Communication (MUSIC'08) To appear in: Proceedings of
  2008 Third International Conference on Communications and Networking in China
  (CHINACOM'08), August 25-27, 2008, Hangzhou, China</arxiv:comment>
    <link href="http://arxiv.org/abs/0806.1543v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0806.1543v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0808.0309v1</id>
    <updated>2008-08-03T10:17:03Z</updated>
    <published>2008-08-03T10:17:03Z</published>
    <title>A Reliable SVD based Watermarking Schem</title>
    <summary>  We propose a novel scheme for watermarking of digital images based on
singular value decomposition (SVD), which makes use of the fact that the SVD
subspace preserves significant amount of information of an image, as compared
to its singular value matrix, Zhang and Li (2005). The principal components of
the watermark are embedded in the original image, leaving the detector with a
complimentary set of singular vectors for watermark extraction. The above step
invariably ensures that watermark extraction from the embedded watermark image,
using a modified matrix, is not possible, thereby removing a major drawback of
an earlier proposed algorithm by Liu and Tan (2002).
</summary>
    <author>
      <name>Chirag Jain</name>
    </author>
    <author>
      <name>Siddharth Arora</name>
    </author>
    <author>
      <name>Prasanta K. Panigrahi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 Pages, 7 Figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0808.0309v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0808.0309v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0809.3485v1</id>
    <updated>2008-09-20T05:52:47Z</updated>
    <published>2008-09-20T05:52:47Z</published>
    <title>A First Step to Convolutive Sparse Representation</title>
    <summary>  In this paper an extension of the sparse decomposition problem is considered
and an algorithm for solving it is presented. In this extension, it is known
that one of the shifted versions of a signal s (not necessarily the original
signal itself) has a sparse representation on an overcomplete dictionary, and
we are looking for the sparsest representation among the representations of all
the shifted versions of s. Then, the proposed algorithm finds simultaneously
the amount of the required shift, and the sparse representation. Experimental
results emphasize on the performance of our algorithm.
</summary>
    <author>
      <name>Hamed Firouzi</name>
    </author>
    <author>
      <name>Massoud Babaie-Zadeh</name>
    </author>
    <author>
      <name>Aria Ghasemian</name>
    </author>
    <author>
      <name>Christian Jutten</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 Pages-In Proceeding of ICASSP 2008</arxiv:comment>
    <link href="http://arxiv.org/abs/0809.3485v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0809.3485v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0811.1959v1</id>
    <updated>2008-11-12T20:10:00Z</updated>
    <published>2008-11-12T20:10:00Z</published>
    <title>Characterization and collection of information from heterogeneous
  multimedia sources with users' parameters for decision support</title>
    <summary>  No single information source can be good enough to satisfy the divergent and
dynamic needs of users all the time. Integrating information from divergent
sources can be a solution to deficiencies in information content. We present
how Information from multimedia document can be collected based on associating
a generic database to a federated database. Information collected in this way
is brought into relevance by integrating the parameters of usage and user's
parameter for decision making. We identified seven different classifications of
multimedia document.
</summary>
    <author>
      <name>Charles A. B. Robert</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LORIA</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/0811.1959v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0811.1959v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0811.4700v1</id>
    <updated>2008-11-28T16:07:33Z</updated>
    <published>2008-11-28T16:07:33Z</published>
    <title>Trellis-coded quantization for public-key steganography</title>
    <summary>  This paper deals with public-key steganography in the presence of a passive
warden. The aim is to hide secret messages within cover-documents without
making the warden suspicious, and without any preliminar secret key sharing.
Whereas a practical attempt has been already done to provide a solution to this
problem, it suffers of poor flexibility (since embedding and decoding steps
highly depend on cover-signals statistics) and of little capacity compared to
recent data hiding techniques. Using the same framework, this paper explores
the use of trellis-coded quantization techniques (TCQ and turbo TCQ) to design
a more efficient public-key scheme. Experiments on audio signals show great
improvements considering Cachin's security criterion.
</summary>
    <author>
      <name>Gaëtan Le Guelvouit</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0811.4700v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0811.4700v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0812.2405v1</id>
    <updated>2008-12-12T15:56:42Z</updated>
    <published>2008-12-12T15:56:42Z</published>
    <title>A New Trend in Optimization on Multi Overcomplete Dictionary toward
  Inpainting</title>
    <summary>  Recently, great attention was intended toward overcomplete dictionaries and
the sparse representations they can provide. In a wide variety of signal
processing problems, sparsity serves a crucial property leading to high
performance. Inpainting, the process of reconstructing lost or deteriorated
parts of images or videos, is an interesting application which can be handled
by suitably decomposition of an image through combination of overcomplete
dictionaries. This paper addresses a novel technique of such a decomposition
and investigate that through inpainting of images. Simulations are presented to
demonstrate the validation of our approach.
</summary>
    <author>
      <name>SeyyedMajid Valiollahzadeh</name>
    </author>
    <author>
      <name>Mohammad Nazari</name>
    </author>
    <author>
      <name>Massoud Babaie-Zadeh</name>
    </author>
    <author>
      <name>Christian Jutten</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/0812.2405v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0812.2405v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0901.1407v1</id>
    <updated>2009-01-11T02:25:17Z</updated>
    <published>2009-01-11T02:25:17Z</published>
    <title>Condition for Energy Efficient Watermarking with Random Vector Model
  without WSS Assumption</title>
    <summary>  Energy efficient watermarking preserves the watermark energy after linear
attack as much as possible. We consider in this letter non-stationary signal
models and derive conditions for energy efficient watermarking under random
vector model without WSS assumption. We find that the covariance matrix of the
energy efficient watermark should be proportional to host covariance matrix to
best resist the optimal linear removal attacks. In WSS process our result
reduces to the well known power spectrum condition. Intuitive geometric
interpretation of the results are also discussed which in turn also provide
more simpler proof of the main results.
</summary>
    <author>
      <name>Bin Yan</name>
    </author>
    <author>
      <name>Zheming Lu</name>
    </author>
    <author>
      <name>Yinjing Guo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 2 figures, submitted to IEEE Signal Processing Letter for
  review</arxiv:comment>
    <link href="http://arxiv.org/abs/0901.1407v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0901.1407v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0903.3103v1</id>
    <updated>2009-03-18T08:17:05Z</updated>
    <published>2009-03-18T08:17:05Z</published>
    <title>Efficiently Learning a Detection Cascade with Sparse Eigenvectors</title>
    <summary>  In this work, we first show that feature selection methods other than
boosting can also be used for training an efficient object detector. In
particular, we introduce Greedy Sparse Linear Discriminant Analysis (GSLDA)
\cite{Moghaddam2007Fast} for its conceptual simplicity and computational
efficiency; and slightly better detection performance is achieved compared with
\cite{Viola2004Robust}. Moreover, we propose a new technique, termed Boosted
Greedy Sparse Linear Discriminant Analysis (BGSLDA), to efficiently train a
detection cascade. BGSLDA exploits the sample re-weighting property of boosting
and the class-separability criterion of GSLDA.
</summary>
    <author>
      <name>Chunhua Shen</name>
    </author>
    <author>
      <name>Sakrapee Paisitkriangkrai</name>
    </author>
    <author>
      <name>Jian Zhang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, conference version published in CVPR2009</arxiv:comment>
    <link href="http://arxiv.org/abs/0903.3103v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0903.3103v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0905.4205v1</id>
    <updated>2009-05-26T14:06:05Z</updated>
    <published>2009-05-26T14:06:05Z</published>
    <title>Development and Optimization of a Multimedia Product</title>
    <summary>  This article presents a new concept of a multimedia interactive product. It
is a multiuser versatile platform that can be used for different purposes. The
first implementation of the platform is a multiplayer game called Texas Hold
'em, which is a very popular community card game. The paper shows the product's
multimedia structure where Hardware and Software work together in creating a
realistic feeling for the users.
</summary>
    <author>
      <name>Cristian Anghel</name>
    </author>
    <author>
      <name>Vlad Muia</name>
    </author>
    <author>
      <name>Miodrag Stoianovici</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, exposed on 5th International Conference "Actualities and
  Perspectives on Hardware and Software" - APHS2009, Timisoara, Romania</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Ann. Univ. Tibiscus Comp. Sci. Series VII(2009), 31-36</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0905.4205v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0905.4205v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0906.0667v1</id>
    <updated>2009-06-03T09:31:34Z</updated>
    <published>2009-06-03T09:31:34Z</published>
    <title>Quality assessment of the MPEG-4 scalable video CODEC</title>
    <summary>  In this paper, the performance of the emerging MPEG-4 SVC CODEC is evaluated.
In the first part, a brief introduction on the subject of quality assessment
and the development of the MPEG-4 SVC CODEC is given. After that, the used test
methodologies are described in detail, followed by an explanation of the actual
test scenarios. The main part of this work concentrates on the performance
analysis of the MPEG-4 SVC CODEC - both objective and subjective.
</summary>
    <author>
      <name>Florian Niedermeier</name>
    </author>
    <author>
      <name>Michael Niedermeier</name>
    </author>
    <author>
      <name>Harald Kosch</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">published in a shorter version at ICIAP 2009 Conference</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0906.0667v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0906.0667v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0906.0866v1</id>
    <updated>2009-06-04T09:52:22Z</updated>
    <published>2009-06-04T09:52:22Z</published>
    <title>Web Publishing of the Files Obtained by Flash</title>
    <summary>  The aim of this article is to familiarize the user with the Web publishing of
the files obtained by Flash. The article contains an overview of Macromedia
Flash 5, as well as the running of a Playing Flash movie, information on Flash
and Generator, the publishing of Flash movies, a HTLM publishing for Flash
Player files and publishing by Generator templates.
</summary>
    <author>
      <name>Virgiliu Streian</name>
    </author>
    <author>
      <name>Adela Ionescu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, exposed on 5th International Conference "Actualities and
  Perspectives on Hardware and Software" - APHS2009, Timisoara, Romania</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Ann. Univ. Tibiscus Comp. Sci. Series VII(2009),349-358</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0906.0866v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0906.0866v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0906.4607v1</id>
    <updated>2009-06-25T05:40:46Z</updated>
    <published>2009-06-25T05:40:46Z</published>
    <title>A Bandwidth Characterization Tool For MPEG-2 File</title>
    <summary>  This paper proposes the design and development of MPEG 2 Video Decoder to
offer flexible and effective utilization of bandwidth services. The decoder is
capable of decoding the MPEG 2 bit stream on a single host machine. The present
decoder is designed to be simple, but yet effectively reconstruct the video
from MPEG 2 bit stream.
</summary>
    <author>
      <name>Sandeep. Kugali</name>
    </author>
    <author>
      <name>S. S. Manvi</name>
    </author>
    <author>
      <name>A. V. Sutagundar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, International Journal of Computer Science and Information
  Security (IJCSIS)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IJCSIS, June 2009 Issue, Vol. 2, No. 1</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0906.4607v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0906.4607v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0906.5073v1</id>
    <updated>2009-06-27T11:59:15Z</updated>
    <published>2009-06-27T11:59:15Z</published>
    <title>TTSS Packet Classification Algorithm to enhance Multimedia Applications
  in Network Processor based Router</title>
    <summary>  The objective of this paper is to implement the Trie based Tuple Space
Search(TTSS) packet classification algorithm for Network Processor(NP) based
router to enhance multimedia applications. The performance is evaluated using
Intel IXP2400 NP Simulator. The results demonstrate that, TTSS has better
performance than Tuple Space Search algorithm and is well suited to achieve
high speed packet classification to support multimedia applications.
</summary>
    <author>
      <name>R. Avudaiammal</name>
    </author>
    <author>
      <name>R. SivaSubramanian</name>
    </author>
    <author>
      <name>R. Pandian</name>
    </author>
    <author>
      <name>P. Seethalakshmi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 Pages, International Journal of Computer Science and Information
  Security (IJCSIS)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IJCSIS June 2009 Issue, Vol. 2, No. 1</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0906.5073v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0906.5073v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1001.0443v1</id>
    <updated>2010-01-04T05:44:57Z</updated>
    <published>2010-01-04T05:44:57Z</published>
    <title>Discovering Knowledge from Multi-modal Lecture Recordings</title>
    <summary>  Educational media mining is the process of converting raw media data from
educational systems to useful information that can be used to design learning
systems, answer research questions and allow personalized learning experiences.
Knowledge discovery encompasses a wide range of techniques ranging from
database queries to more recent developments in machine learning and language
technology. Educational media mining techniques are now being used in IT
Services research worldwide. Multi-modal Lecture Recordings is one of the
important types of educational media and this paper explores the research
challenges for mining lecture recordings for the efficient personalized
learning experiences. Keywords: Educational Media Mining; Lecture Recordings,
Multimodal Information System, Personalized Learning; Online Course Ware;
Skills and Competences;
</summary>
    <author>
      <name>Rajkumar Kannan</name>
    </author>
    <author>
      <name>Christian Guetl</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">First International Conference on Data Engineering and Management
  2008, India</arxiv:comment>
    <link href="http://arxiv.org/abs/1001.0443v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1001.0443v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.1; H.5.4; H.2.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1002.1168v1</id>
    <updated>2010-02-05T09:31:58Z</updated>
    <published>2010-02-05T09:31:58Z</published>
    <title>Shape-Adaptive Motion Estimation Algorithm for MPEG-4 Video Coding</title>
    <summary>  This paper presents a gradient based motion estimation algorithm based on
shape-motion prediction, which takes advantage of the correlation between
neighboring Binary Alpha Blocks (BABs), to match with the Mpeg-4 shape coding
case and speed up the estimation process. The PSNR and computation time
achieved by the proposed algorithm seem to be better than those obtained by
most popular motion estimation techniques.
</summary>
    <author>
      <name>F. Benboubker</name>
    </author>
    <author>
      <name>F. Abdi</name>
    </author>
    <author>
      <name>A. Ahaitouf</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 2, January 2010,
  http://ijcsi.org/articles/Shape-Adaptive-Motion-Estimation-Algorithm-for-MPEG-4-Video-Coding.php</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Science Issues, IJCSI, Vol. 7,
  Issue 1, No. 2, January 2010,
  http://ijcsi.org/articles/Shape-Adaptive-Motion-Estimation-Algorithm-for-MPEG-4-Video-Coding.php</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1002.1168v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1002.1168v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1004.1791v1</id>
    <updated>2010-04-11T11:11:59Z</updated>
    <published>2010-04-11T11:11:59Z</published>
    <title>Reversible Image data Hiding using Lifting wavelet Transform and
  Histogram Shifting</title>
    <summary>  A method of lossless data hiding in images using integer wavelet transform
and histogram shifting for gray scale images is proposed. The method shifts
part of the histogram, to create space for embedding the watermark information
bits. The method embeds watermark while maintaining the visual quality well.
The method is completely reversible. The original image and the watermark data
can be recovered without any loss.
</summary>
    <author>
      <name>S. Kurshid Jinna</name>
    </author>
    <author>
      <name>L. Ganesan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE Publication format, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IJCSIS, Vol. 7 No. 3, March 2010, 283-289</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1004.1791v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1004.1791v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1004.3275v1</id>
    <updated>2010-04-19T18:26:09Z</updated>
    <published>2010-04-19T18:26:09Z</published>
    <title>C Implementation &amp; comparison of companding &amp; silence audio compression
  techniques</title>
    <summary>  Just about all the newest living room audio-video electronics and PC
multimedia products being designed today will incorporate some form of
compressed digitized-audio processing capability. Audio compression reduces the
bit rate required to represent an analog audio signal while maintaining the
perceived audio quality. Discarding inaudible data reduces the storage,
transmission and compute requirements of handling high-quality audio files.
This paper covers wave audio file format &amp; algorithm of silence compression
method and companding method to compress and decompress wave audio file. Then
it compares the result of these two methods.
</summary>
    <author>
      <name>Kruti Dangarwala</name>
    </author>
    <author>
      <name>Jigar Shah</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Science Issues online at
  http://ijcsi.org/articles/C-Implementation-comparison-of-companding-silence-audio-compression-techniques.php</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IJCSI, Volume 7, Issue 2, March 2010</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1004.3275v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1004.3275v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1004.3556v1</id>
    <updated>2010-04-20T20:14:19Z</updated>
    <published>2010-04-20T20:14:19Z</published>
    <title>Policies and Economics of Digital Multimedia Transmission</title>
    <summary>  There are different Standards of digital multimedia transmission, for example
DVB in Europe and ISDB in Japan and DMB in Korea, with different delivery
system (example MPEG-2, MPEG-4).This paper describe an overview of Digital
Multimedia Transmission (DMT) technologies. The economic aspects of digital
content &amp; software solution industry as a strategic key in the future will be
discussed. The study then focuses on some important policy and technology
issues, such S-DMB, T-DMB, Digital Video Broadcasting Handheld (DVB-H) and
concludes DMT policies for convergence of telecommunications and broadcasting.
</summary>
    <author>
      <name>Mohsen Gerami</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Science Issues online at
  http://ijcsi.org/articles/Policies-and-Economics-of-Digital-Multimedia-Transmission.php</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IJCSI, Volume 7, Issue 2, March 2010</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1004.3556v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1004.3556v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1004.4241v1</id>
    <updated>2010-04-24T00:29:00Z</updated>
    <published>2010-04-24T00:29:00Z</published>
    <title>Error Concealment in Image Communication Using Edge Map Watermarking and
  Spatial Smoothing</title>
    <summary>  We propose a novel error concealment algorithm to be used at the receiver
side of a lossy image transmission system. Our algorithm involves hiding the
edge map of the original image at the transmitter within itself using a robust
watermarking scheme. At the receiver, wherever a lost block is detected, the
extracted edge information is used as border constraint for the spatial
smoothing employing the intact neighboring blocks in order to conceal errors.
Simulation results show the superiority of our technique over existing methods
even in case of high packet loss ratios in the communication network.
</summary>
    <author>
      <name>Shabnam Sodagari</name>
    </author>
    <author>
      <name>Peyman Hesami</name>
    </author>
    <author>
      <name>Alireza Nasiri Avanaki</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in Proceeding of ICCET 2010</arxiv:comment>
    <link href="http://arxiv.org/abs/1004.4241v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1004.4241v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1007.4134v1</id>
    <updated>2010-07-23T13:59:42Z</updated>
    <published>2010-07-23T13:59:42Z</published>
    <title>Human Daily Activities Indexing in Videos from Wearable Cameras for
  Monitoring of Patients with Dementia Diseases</title>
    <summary>  Our research focuses on analysing human activities according to a known
behaviorist scenario, in case of noisy and high dimensional collected data. The
data come from the monitoring of patients with dementia diseases by wearable
cameras. We define a structural model of video recordings based on a Hidden
Markov Model. New spatio-temporal features, color features and localization
features are proposed as observations. First results in recognition of
activities are promising.
</summary>
    <author>
      <name>Svebor Karaman</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LaBRI</arxiv:affiliation>
    </author>
    <author>
      <name>Jenny Benois-Pineau</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LaBRI</arxiv:affiliation>
    </author>
    <author>
      <name>Rémi Mégret</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IMS</arxiv:affiliation>
    </author>
    <author>
      <name>Vladislavs Dovgalecs</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IMS</arxiv:affiliation>
    </author>
    <author>
      <name>Jean-François Dartigues</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">ISPED</arxiv:affiliation>
    </author>
    <author>
      <name>Yann Gaëstel</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">ISPED</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/ICPR.2010.999</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/ICPR.2010.999" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ICPR 2010, Istanbul : Turquie (2010)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1007.4134v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1007.4134v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1009.1478v1</id>
    <updated>2010-09-08T08:23:47Z</updated>
    <published>2010-09-08T08:23:47Z</published>
    <title>A Block Based Scheme for Enhancing Low Luminated Images</title>
    <summary>  In this paper the background detection in images in poor lighting can be done
by the use of morphological filters. Lately contrast image enhancement
technique is used to detect the background in image which uses Weber's Law. The
proposed technique is more effective one in which the background detection in
image can be done in color images. The given image obtained in this method is
very effective one. More enhancement can be obtained while comparing the
results. In this technique compressed domain enhancement has been used for
better result.
</summary>
    <author>
      <name>A. Saradha Devi</name>
    </author>
    <author>
      <name>S. Suja Priyadharsini</name>
    </author>
    <author>
      <name>S. Athinarayanan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 5 figures, 2 national conferences</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Multimedia &amp; Its Applications(IJMA),
  Vol.2, No.3, August 2010</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1009.1478v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1009.1478v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1009.3785v1</id>
    <updated>2010-09-20T12:15:46Z</updated>
    <published>2010-09-20T12:15:46Z</published>
    <title>Improved Iterative Techniques to Compensate for Interpolation
  Distortions</title>
    <summary>  In this paper a novel hybrid approach for compensating the distortion of any
interpolation has been proposed. In this hybrid method, a modular approach was
incorporated in an iterative fashion. By using this approach we can get drastic
improvement with less computational complexity. The extension of the proposed
approach to two dimensions was also studied. Both the simulation results and
mathematical analyses confirmed the superiority of the hybrid method. The
proposed method was also shown to be robust against additive noise.
</summary>
    <author>
      <name>A. ParandehGheibi</name>
    </author>
    <author>
      <name>M. A. Akhaee</name>
    </author>
    <author>
      <name>A. Ayremlou</name>
    </author>
    <author>
      <name>M. A. Rahimian</name>
    </author>
    <author>
      <name>F. Marvasti</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted on Signal Processing, Elsevier</arxiv:comment>
    <link href="http://arxiv.org/abs/1009.3785v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1009.3785v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1010.2432v1</id>
    <updated>2010-10-12T16:13:21Z</updated>
    <published>2010-10-12T16:13:21Z</published>
    <title>Transmitting Video-on-Demand Effectively</title>
    <summary>  Now-a-days internet has become a vast source of entertainment &amp; new services
are available in quick succession which provides entertainment to the users.
One of this service i.e. Video-on-Demand is most hyped service in this context.
Transferring the video over the network with less error is the main objective
of the service providers. In this paper we present an algorithm for routing the
video to the user in an effective manner along with a method that ensures less
error rate than others.
</summary>
    <author>
      <name>Rachit Mohan Garg</name>
    </author>
    <author>
      <name>Shipra Kapoor</name>
    </author>
    <author>
      <name>Kapil Kumar</name>
    </author>
    <author>
      <name>Mohd. Dilshad Ansari</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Universal Journal of Computer Science and Engineering Technology
  (1) 1, October 2010, UniCSE</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1010.2432v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1010.2432v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1010.3951v1</id>
    <updated>2010-10-19T15:24:33Z</updated>
    <published>2010-10-19T15:24:33Z</published>
    <title>Alternatives to speech in low bit rate communication systems</title>
    <summary>  This paper describes a framework and a method with which speech communication
can be analyzed. The framework consists of a set of low bit rate, short-range
acoustic communication systems, such as speech, but that are quite different
from speech. The method is to systematically compare these systems according to
different objective functions such as data rate, computational overhead,
psychoacoustic effects and semantics. One goal of this study is to better
understand the nature of human communication. Another goal is to identify
acoustic communication systems that are more efficient than human speech for
some specific purposes.
</summary>
    <author>
      <name>Cristina Videira Lopes</name>
    </author>
    <author>
      <name>Pedro M. Q. Aguiar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1010.3951v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1010.3951v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1011.2753v1</id>
    <updated>2010-11-11T20:20:36Z</updated>
    <published>2010-11-11T20:20:36Z</published>
    <title>Compensating Interpolation Distortion by New Optimized Modular Method</title>
    <summary>  A modular method was suggested before to recover a band limited signal from
the sample and hold and linearly interpolated (or, in general, an
nth-order-hold) version of the regular samples. In this paper a novel approach
for compensating the distortion of any interpolation based on modular method
has been proposed. In this method the performance of the modular method is
optimized by adding only some simply calculated coefficients. This approach
causes drastic improvement in terms of SNRs with fewer modules compared to the
classical modular method. Simulation results clearly confirm the improvement of
the proposed method and also its superior robustness against additive noise.
</summary>
    <author>
      <name>Ali Ayremlou</name>
    </author>
    <author>
      <name>Mohammad Tofighi</name>
    </author>
    <author>
      <name>Farokh Marvasti</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to International Conference on Telecommunications(ICT) 2011</arxiv:comment>
    <link href="http://arxiv.org/abs/1011.2753v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1011.2753v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1011.5458v1</id>
    <updated>2010-11-24T18:58:53Z</updated>
    <published>2010-11-24T18:58:53Z</published>
    <title>Image Inpainting Using Sparsity of the Transform Domain</title>
    <summary>  In this paper, we propose a new image inpainting method based on the property
that much of the image information in the transform domain is sparse. We add a
redundancy to the original image by mapping the transform coefficients with
small amplitudes to zero and the resultant sparsity pattern is used as the side
information in the recovery stage. If the side information is not available,
the receiver has to estimate the sparsity pattern. At the end, the recovery is
done by consecutive projecting between two spatial and transform sets.
Experimental results show that our method works well for both structural and
texture images and outperforms other techniques in objective and subjective
performance measures.
</summary>
    <author>
      <name>H. Hosseini</name>
    </author>
    <author>
      <name>N. B. Marvasti</name>
    </author>
    <author>
      <name>F. Marvasti</name>
    </author>
    <link href="http://arxiv.org/abs/1011.5458v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1011.5458v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1012.0397v2</id>
    <updated>2011-04-29T20:06:42Z</updated>
    <published>2010-12-02T13:02:06Z</published>
    <title>A proposed Optimized Spline Interpolation</title>
    <summary>  The goal of this paper is to design compact support basis spline functions
that best approximate a given filter (e.g., an ideal Lowpass filter). The
optimum function is found by minimizing the least square problem ($\ell$2 norm
of the difference between the desired and the approximated filters) by means of
the calculus of variation; more precisely, the introduced splines give optimal
filtering properties with respect to their time support interval. Both
mathematical analysis and simulation results confirm the superiority of these
splines.
</summary>
    <author>
      <name>Ramtin Madani</name>
    </author>
    <author>
      <name>Ali Ayremlou</name>
    </author>
    <author>
      <name>Arash Amini</name>
    </author>
    <author>
      <name>Farrokh Marvasti</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">SampTA 2011, Accepted</arxiv:comment>
    <link href="http://arxiv.org/abs/1012.0397v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1012.0397v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1012.5573v1</id>
    <updated>2010-12-27T07:44:21Z</updated>
    <published>2010-12-27T07:44:21Z</published>
    <title>Image Sterilization to Prevent LSB-based Steganographic Transmission</title>
    <summary>  Sterilization is a very popular word used in biomedical testing (like removal
of all microorganisms on surface of an article or in fluid using appropriate
chemical products). Motivated by this biological analogy, we, for the first
time, introduce the concept of sterilization of an image, i.e., removing any
steganographic information embedded in the image. Experimental results show
that our technique succeeded in sterilizing around 76% to 91% of stego pixels
in an image on average, where data is embedded using LSB-based steganography.
</summary>
    <author>
      <name>Goutam Paul</name>
    </author>
    <author>
      <name>Imon Mukherjee</name>
    </author>
    <link href="http://arxiv.org/abs/1012.5573v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1012.5573v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1105.0011v1</id>
    <updated>2011-04-29T20:05:52Z</updated>
    <published>2011-04-29T20:05:52Z</published>
    <title>Optimized Spline Interpolation</title>
    <summary>  In this paper, we investigate the problem of designing compact support
interpolation kernels for a given class of signals. By using calculus of
variations, we simplify the optimization problem from an infinite nonlinear
problem to a finite dimensional linear case, and then find the optimum compact
support function that best approximates a given filter in the least square
sense (l2 norm). The benefit of compact support interpolants is the low
computational complexity in the interpolation process while the optimum compact
support interpolant gaurantees the highest achivable Signal to Noise Ratio
(SNR). Our simulation results confirm the superior performance of the proposed
splines compared to other conventional compact support interpolants such as
cubic spline.
</summary>
    <author>
      <name>Ramtin Madani</name>
    </author>
    <author>
      <name>Ali Ayremlou</name>
    </author>
    <author>
      <name>Arash Amini</name>
    </author>
    <author>
      <name>Farrokh Marvasti</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE Transactions on Signal Processing, Submitted</arxiv:comment>
    <link href="http://arxiv.org/abs/1105.0011v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1105.0011v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1105.2899v2</id>
    <updated>2014-01-23T13:33:06Z</updated>
    <published>2011-05-14T13:57:35Z</published>
    <title>Fast restoration of natural images corrupted by high-density impulse
  noise</title>
    <summary>  In this paper, we suggest a general model for the fixed-valued impulse noise
and propose a two-stage method for high density noise suppression while
preserving the image details. In the first stage, we apply an iterative impulse
detector, exploiting the image entropy, to identify the corrupted pixels and
then employ an Adaptive Iterative Mean filter to restore them. The filter is
adaptive in terms of the number of iterations, which is different for each
noisy pixel, according to the Euclidean distance from the nearest uncorrupted
pixel. Experimental results show that the proposed filter is fast and
outperforms the best existing techniques in both objective and subjective
performance measures.
</summary>
    <author>
      <name>Hossein Hosseini</name>
    </author>
    <author>
      <name>Farokh Marvasti</name>
    </author>
    <link href="http://arxiv.org/abs/1105.2899v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1105.2899v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1107.2859v1</id>
    <updated>2011-07-14T15:52:21Z</updated>
    <published>2011-07-14T15:52:21Z</published>
    <title>Label-Specific Training Set Construction from Web Resource for Image
  Annotation</title>
    <summary>  Recently many research efforts have been devoted to image annotation by
leveraging on the associated tags/keywords of web images as training labels. A
key issue to resolve is the relatively low accuracy of the tags. In this paper,
we propose a novel semi-automatic framework to construct a more accurate and
effective training set from these web media resources for each label that we
want to learn. Experiments conducted on a real-world dataset demonstrate that
the constructed training set can result in higher accuracy for image
annotation.
</summary>
    <author>
      <name>Jinhui Tang</name>
    </author>
    <author>
      <name>Shuicheng Yan</name>
    </author>
    <author>
      <name>Tat-Seng Chua</name>
    </author>
    <author>
      <name>Ramesh Jain</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1107.2859v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1107.2859v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1107.4661v1</id>
    <updated>2011-07-23T06:30:44Z</updated>
    <published>2011-07-23T06:30:44Z</published>
    <title>MediaWiki Grammar Recovery</title>
    <summary>  The paper describes in detail the recovery effort of one of the official
MediaWiki grammars. Over two hundred grammar transformation steps are reported
and annotated, leading to delivery of a level 2 grammar, semi-automatically
extracted from a community created semi-formal text using at least five
different syntactic notations, several non-enforced naming conventions,
multiple misspellings, obsolete parsing technology idiosyncrasies and other
problems commonly encountered in grammars that were not engineered properly.
Having a quality grammar will allow to test and validate it further, without
alienating the community with a separately developed grammar.
</summary>
    <author>
      <name>Vadim Zaytsev</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">47 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1107.4661v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1107.4661v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1108.6290v2</id>
    <updated>2011-09-01T07:35:06Z</updated>
    <published>2011-08-31T16:39:09Z</published>
    <title>Compression and Quantitative Analysis of Buffer Map Message in P2P
  Streaming System</title>
    <summary>  BM compression is a straightforward and operable way to reduce buffer message
length as well as to improve system performance. In this paper, we thoroughly
discuss the principles and protocol progress of different compression schemes,
and for the first time present an original compression scheme which can nearly
remove all redundant information from buffer message. Theoretical limit of
compression rates are deduced in the theory of information. Through the
analysis of information content and simulation with our measured BM trace of
UUSee, the validity and superiority of our compression scheme are validated in
term of compression ratio.
</summary>
    <author>
      <name>Chunxi Li</name>
    </author>
    <author>
      <name>Changjia Chen</name>
    </author>
    <author>
      <name>DahMing Chiu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13pages,12 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1108.6290v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1108.6290v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1109.0753v1</id>
    <updated>2011-09-04T20:03:32Z</updated>
    <published>2011-09-04T20:03:32Z</published>
    <title>Transmission of Successful Route Error Message(RERR) in Routing Aware
  Multiple Description Video Coding over Mobile Ad-Hoc Network</title>
    <summary>  Video transmission over mobile ad-hoc networks is becoming important as these
networks become more widely used in the wireless networks. We propose a
routing-aware multiple description video coding approach to support video
transmission over mobile ad-hoc networks with single and multiple path
transport. We build a model to estimate the packet loss probability of each
packet transmitted over the network based on the standard ad-hoc routing
messages and network parameters without losing the RERR message. We then
calculate the frame loss probability in order to eliminate error without any
loss of data.
</summary>
    <author>
      <name>Kinjal Shah</name>
    </author>
    <author>
      <name>Gagan Dua</name>
    </author>
    <author>
      <name>Dharmendar Sharma</name>
    </author>
    <author>
      <name>Priyanka Mishra</name>
    </author>
    <author>
      <name>Nitin Rakesh</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5121/ijma.2011.3305</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5121/ijma.2011.3305" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages,2 figures, 1 table for algorithm</arxiv:comment>
    <link href="http://arxiv.org/abs/1109.0753v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1109.0753v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1112.2040v1</id>
    <updated>2011-12-09T08:16:03Z</updated>
    <published>2011-12-09T08:16:03Z</published>
    <title>Recent Trends and Research Issues in Video Association Mining</title>
    <summary>  With the ever-growing digital libraries and video databases, it is
increasingly important to understand and mine the knowledge from video database
automatically. Discovering association rules between items in a large video
database plays a considerable role in the video data mining research areas.
Based on the research and development in the past years, application of
association rule mining is growing in different domains such as surveillance,
meetings, broadcast news, sports, archives, movies, medical data, as well as
personal and online media collections. The purpose of this paper is to provide
general framework of mining the association rules from video database. This
article is also represents the research issues in video association mining
followed by the recent trends.
</summary>
    <author>
      <name>Vijayakumar V</name>
    </author>
    <author>
      <name>Nedunchezhian R</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages; 1 Figure; 1 Table</arxiv:comment>
    <link href="http://arxiv.org/abs/1112.2040v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1112.2040v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1112.2044v1</id>
    <updated>2011-12-09T08:35:14Z</updated>
    <published>2011-12-09T08:35:14Z</published>
    <title>Modelling Gesture Based Ubiquitous Applications</title>
    <summary>  A cost effective, gesture based modelling technique called Virtual
Interactive Prototyping (VIP) is described in this paper. Prototyping is
implemented by projecting a virtual model of the equipment to be prototyped.
Users can interact with the virtual model like the original working equipment.
For capturing and tracking the user interactions with the model image and sound
processing techniques are used. VIP is a flexible and interactive prototyping
method that has much application in ubiquitous computing environments.
Different commercial as well as socio-economic applications and extension to
interactive advertising of VIP are also discussed.
</summary>
    <author>
      <name>Kurien Zacharia</name>
    </author>
    <author>
      <name>Eldo P. Elias</name>
    </author>
    <author>
      <name>Surekha Mariam Varghese</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5121/ijma.2011.3403</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5121/ijma.2011.3403" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages; The International Journal of Multimedia &amp; Its Applications
  (IJMA) Vol.3, No.4, November 2011</arxiv:comment>
    <link href="http://arxiv.org/abs/1112.2044v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1112.2044v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68U20, 68U05" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.2; I.3.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.1641v1</id>
    <updated>2012-05-08T09:27:29Z</updated>
    <published>2012-05-08T09:27:29Z</published>
    <title>Content based video retrieval systems</title>
    <summary>  With the development of multimedia data types and available bandwidth there
is huge demand of video retrieval systems, as users shift from text based
retrieval systems to content based retrieval systems. Selection of extracted
features play an important role in content based video retrieval regardless of
video attributes being under consideration. These features are intended for
selecting, indexing and ranking according to their potential interest to the
user. Good features selection also allows the time and space costs of the
retrieval process to be reduced. This survey reviews the interesting features
that can be extracted from video data for indexing and retrieval along with
similarity measurement methods. We also identify present research issues in
area of content based video retrieval systems.
</summary>
    <author>
      <name>B V Patel</name>
    </author>
    <author>
      <name>B B Meshram</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5121/iju.2012.3202</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5121/iju.2012.3202" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 Pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1205.1641v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.1641v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.4572v1</id>
    <updated>2012-05-21T11:57:55Z</updated>
    <published>2012-05-21T11:57:55Z</published>
    <title>A Novel Video Compression Approach Based on Underdetermined Blind Source
  Separation</title>
    <summary>  This paper develops a new video compression approach based on underdetermined
blind source separation. Underdetermined blind source separation, which can be
used to efficiently enhance the video compression ratio, is combined with
various off-the-shelf codecs in this paper. Combining with MPEG-2, video
compression ratio could be improved slightly more than 33%. As for combing with
H.264, 4X~12X more compression ratio could be achieved with acceptable PSNR,
according to different kinds of video sequences.
</summary>
    <author>
      <name>Jing Liu</name>
    </author>
    <author>
      <name>Fei Qiao</name>
    </author>
    <author>
      <name>Qi Wei</name>
    </author>
    <author>
      <name>Huazhong Yang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages with 4 figures and 1 table</arxiv:comment>
    <link href="http://arxiv.org/abs/1205.4572v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.4572v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.1; H.4.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.1866v1</id>
    <updated>2012-06-08T20:15:30Z</updated>
    <published>2012-06-08T20:15:30Z</published>
    <title>Perceptual quality comparison between single-layer and scalable videos
  at the same spatial, temporal and amplitude resolutions</title>
    <summary>  In this paper, the perceptual quality difference between scalable and
single-layer videos coded at the same spatial, temporal and amplitude
resolution (STAR) is investigated through a subjective test using a mobile
platform. Three source videos are considered and for each source video
single-layer and scalable video are compared at 9 different STARs. We utilize
paired comparison methods with and without tie option. Results collected from
10 subjects in the without "tie" option and 6 subjects in the with "tie" option
show that there is no significant quality difference between scalable and
singlelayer video when coded at the same STAR. An analysis of variance (ANOVA)
test is also performed to further confirm the finding.
</summary>
    <author>
      <name>Yuanyi Xue</name>
    </author>
    <author>
      <name>Yao Wang</name>
    </author>
    <link href="http://arxiv.org/abs/1206.1866v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.1866v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.2070v1</id>
    <updated>2012-08-15T16:00:06Z</updated>
    <published>2012-08-15T16:00:06Z</published>
    <title>Content-based Multi-media Retrieval Technology</title>
    <summary>  This paper gives a summary of the content-based Image Retrieval and
Content-based Audio Retrieval, which are two parts of the Content-based
Retrieval. Content-based Retrieval is the retrieval based on the features of
the content. Generally, it is a way to extract features of the media data and
find other data with the similar features from the database automatically.
Content-based Retrieval can not only work on discrete media like texts, but
also can be used on continuous media, such as video and audio.
</summary>
    <author>
      <name>Yi Wang</name>
    </author>
    <link href="http://arxiv.org/abs/1209.2070v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.2070v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.2855v1</id>
    <updated>2012-09-13T11:25:19Z</updated>
    <published>2012-09-13T11:25:19Z</published>
    <title>Investigating Streaming Techniques and Energy Efficiency of Mobile Video
  Services</title>
    <summary>  We report results from a measurement study of three video streaming services,
YouTube, Dailymotion and Vimeo on six different smartphones. We measure and
analyze the traffic and energy consumption when streaming different quality
videos over Wi-Fi and 3G. We identify five different techniques to deliver the
video and show that the use of a particular technique depends on the device,
player, quality, and service. The energy consumption varies dramatically
between devices, services, and video qualities depending on the streaming
technique used. As a consequence, we come up with suggestions on how to improve
the energy efficiency of mobile video streaming services.
</summary>
    <author>
      <name>Mohammad Ashraful Hoque</name>
    </author>
    <author>
      <name>Matti Siekkinen</name>
    </author>
    <author>
      <name>Jukka K. Nurminen</name>
    </author>
    <author>
      <name>Mika Aalto</name>
    </author>
    <link href="http://arxiv.org/abs/1209.2855v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.2855v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.0297v2</id>
    <updated>2012-10-06T03:52:57Z</updated>
    <published>2012-10-01T07:10:12Z</published>
    <title>Comparison of Speech Activity Detection Techniques for Speaker
  Recognition</title>
    <summary>  Speech activity detection (SAD) is an essential component for a variety of
speech processing applications. It has been observed that performances of
various speech based tasks are very much dependent on the efficiency of the
SAD. In this paper, we have systematically reviewed some popular SAD techniques
and their applications in speaker recognition. Speaker verification system
using different SAD technique are experimentally evaluated on NIST speech
corpora using Gaussian mixture model- universal background model (GMM-UBM)
based classifier for clean and noisy conditions. It has been found that two
Gaussian modeling based SAD is comparatively better than other SAD techniques
for different types of noises.
</summary>
    <author>
      <name>Md. Sahidullah</name>
    </author>
    <author>
      <name>Goutam Saha</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1210.0297v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.0297v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1302.1947v1</id>
    <updated>2013-02-08T05:18:49Z</updated>
    <published>2013-02-08T05:18:49Z</published>
    <title>A new compressive video sensing framework for mobile broadcast</title>
    <summary>  A new video coding method based on compressive sampling is proposed. In this
method, a video is coded using compressive measurements on video cubes. Video
reconstruction is performed by minimization of total variation (TV) of the
pixelwise DCT coefficients along the temporal direction. A new reconstruction
algorithm is developed from TVAL3, an efficient TV minimization algorithm based
on the alternating minimization and augmented Lagrangian methods. Video coding
with this method is inherently scalable, and has applications in mobile
broadcast.
</summary>
    <author>
      <name>Chengbo Li</name>
    </author>
    <author>
      <name>Hong Jiang</name>
    </author>
    <author>
      <name>Paul Wilford</name>
    </author>
    <author>
      <name>Yin Zhang</name>
    </author>
    <author>
      <name>Mike Scheutzow</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TBC.2012.2226509</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TBC.2012.2226509" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 12 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE Transactions on Broadcasting VOL 59 NO 1 MARCH 2013 pp. 197 -
  205</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1302.1947v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1302.1947v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1302.4233v1</id>
    <updated>2013-02-18T11:41:09Z</updated>
    <published>2013-02-18T11:41:09Z</published>
    <title>The Robust Digital Image Watermarking using Quantization and Fuzzy Logic
  Approach in DWT Domain</title>
    <summary>  In this paper a novel approach to embed watermark into the host image using
quantization with the help of Dynamic Fuzzy Inference System (DFIS) is
proposed. The cover image is decomposed up to 3- levels using quantization and
Discrete Wavelet Transform (DWT). A bitmap of size 64x64 pixels is embedded
into the host image using DFIS rule base. The DFIS is utilized to generate the
watermark weighting function to embed the imperceptible watermark. The
implemented watermarking algorithm is imperceptible and robust to some normal
attacks such as JPEG Compression, salt&amp;pepper noise, median filtering, rotation
and cropping.
  Keywords: Watermark, Quantization, Dynamic Fuzzy Inference System,
Imperceptible, Robust, JPEG Compression, Cropping.
</summary>
    <author>
      <name>Nallagarla Ramamurthy</name>
    </author>
    <author>
      <name>S. Varadarajan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 11 figures, IJCSN Journal</arxiv:comment>
    <link href="http://arxiv.org/abs/1302.4233v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1302.4233v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1303.2330v1</id>
    <updated>2013-03-10T15:29:26Z</updated>
    <published>2013-03-10T15:29:26Z</published>
    <title>Image compression using anti-forensics method</title>
    <summary>  A large number of image forensics methods are available which are capable of
identifying image tampering. But these techniques are not capable of addressing
the anti-forensics method which is able to hide the trace of image tampering.
In this paper anti-forensics method for digital image compression has been
proposed. This anti-forensics method is capable of removing the traces of image
compression. Additionally, technique is also able to remove the traces of
blocking artifact that are left by image compression algorithms that divide an
image into segments during compression process. This method is targeted to
remove the compression fingerprints of JPEG compression.
</summary>
    <author>
      <name>M. S. Sreelakshmi</name>
    </author>
    <author>
      <name>D. Venkataraman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages 8 figures IJCSEA journal</arxiv:comment>
    <link href="http://arxiv.org/abs/1303.2330v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1303.2330v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1303.4264v1</id>
    <updated>2013-03-18T14:36:53Z</updated>
    <published>2013-03-18T14:36:53Z</published>
    <title>StegTorrent: a Steganographic Method for the P2P File Sharing Service</title>
    <summary>  The paper proposes StegTorrent a new network steganographic method for the
popular P2P file transfer service-BitTorrent. It is based on modifying the
order of data packets in the peer-peer data exchange protocol. Unlike other
existing steganographic methods that modify the packets' order it does not
require any synchronization. Experimental results acquired from prototype
implementation proved that it provides high steganographic bandwidth of up to
270 b/s while introducing little transmission distortion and providing
difficult detectability.
</summary>
    <author>
      <name>Pawel Kopiczko</name>
    </author>
    <author>
      <name>Wojciech Mazurczyk</name>
    </author>
    <author>
      <name>Krzysztof Szczypiorski</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 7 figures, 1 table</arxiv:comment>
    <link href="http://arxiv.org/abs/1303.4264v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1303.4264v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.7324v1</id>
    <updated>2013-04-27T05:05:52Z</updated>
    <published>2013-04-27T05:05:52Z</published>
    <title>Adaptive Software Radio Steganography</title>
    <summary>  This paper presents an adaptable steganography (information hiding) method
for digital radio communication. Many radio steganography methods exist, but
most are defined at higher levels of the protocol stack and are thus protocol
dependent. In contrast, this method is defined at the physical layer, which
makes it widely applicable regardless of the protocols used at higher layers.
This approach is also adaptive; the covertness of the hidden channel is simple
to control via a single continuous parameter either manually or automatically.
Several variations are introduced, each with performance evaluated by
simulation. Results show this to be a feasible method with a reasonable
trade-off between performance and covertness.
</summary>
    <author>
      <name>David E. Robillard</name>
    </author>
    <link href="http://arxiv.org/abs/1304.7324v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.7324v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1305.4102v1</id>
    <updated>2013-04-11T14:30:46Z</updated>
    <published>2013-04-11T14:30:46Z</published>
    <title>Using Bias Optimization for Reversible Data Hiding Using Image
  Interpolation</title>
    <summary>  In this paper, we propose a reversible data hiding method in the spatial
domain for compressed grayscale images. The proposed method embeds secret bits
into a compressed thumbnail of the original image by using a novel
interpolation method and the Neighbour Mean Interpolation (NMI) technique as
scaling up to the original image occurs. Experimental results presented in this
paper show that the proposed method has significantly improved embedding
capacities over the approach proposed by Jung and Yoo.
</summary>
    <author>
      <name>Andrew Rudder</name>
    </author>
    <author>
      <name>Wayne Goodridge</name>
    </author>
    <author>
      <name>Shareeda Mohammed</name>
    </author>
    <link href="http://arxiv.org/abs/1305.4102v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1305.4102v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.6328v1</id>
    <updated>2013-07-24T08:32:38Z</updated>
    <published>2013-07-24T08:32:38Z</published>
    <title>Digital Watermarking for Image AuthenticationBased on Combined DCT, DWT
  and SVD Transformation</title>
    <summary>  This paper presents a hybrid digital image watermarking based on Discrete
Wavelet Transform (DWT), Discrete Cosine Transform (DCT) and Singular Value
Decomposition (SVD) in a zigzag order. From DWT we choose the high band to
embed the watermark that facilities to add more information, gives more
invisibility and robustness against some attacks. Such as geometric attack.
Zigzag method is applied to map DCT coefficients into four quadrants that
represent low, mid and high bands. Finally, SVD is applied to each quadrant.
</summary>
    <author>
      <name>Mohammad Ibrahim Khan</name>
    </author>
    <author>
      <name>Md. Maklachur Rahman</name>
    </author>
    <author>
      <name>Md. Iqbal Hasan Sarker</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 7 figures and 2 tables</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IJCSI International Journal of Computer Science Issues, Vol. 10,
  Issue 3, No 1, May 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1307.6328v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.6328v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1308.4263v1</id>
    <updated>2013-08-20T09:02:57Z</updated>
    <published>2013-08-20T09:02:57Z</published>
    <title>Compressive Sampling for the Packet Loss Recovery in Audio Multimedia
  Streaming</title>
    <summary>  The aim of this paper is to introduce a new schema, based on a Compressive
Sampling technique, for the recovery of lost data in multimedia streaming. The
audio streaming data are encapsuled in different packets by using an
interleaving technique. The Compressive Sampling technique is used to recover
audio information in case of lost packets. Experimental results are presented
on speech and musical audio signals to illustrate the performances and the
capabilities of the proposed methodology.
</summary>
    <author>
      <name>Angelo Ciaramella</name>
    </author>
    <author>
      <name>Giulio Giunta</name>
    </author>
    <link href="http://arxiv.org/abs/1308.4263v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1308.4263v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.5653v1</id>
    <updated>2013-10-09T10:24:07Z</updated>
    <published>2013-10-09T10:24:07Z</published>
    <title>Blind and robust images watermarking based on wavelet and edge insertion</title>
    <summary>  This paper gives a new scheme of watermarking technique related to insert the
mark by adding edge in HH sub-band of the host image after wavelet
decomposition. Contrary to most of the watermarking algorithms in wavelet
domain, our method is blind and results show that it is robust against the JPEG
and GIF compression, histogram and spectrum spreading, noise adding and small
rotation. Its robustness against compression is better than others watermarking
algorithms reported in the literature. The algorithm is flexible because its
capacity or robustness can be improved by modifying some parameters.
</summary>
    <author>
      <name>Henri Bruno Razafindradina</name>
    </author>
    <author>
      <name>Attoumani Mohamed Karim</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IJCIS, Vol.3, No. 3, September 2013, pp 23-30</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1310.5653v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.5653v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="Computer Science" scheme="http://arxiv.org/schemas/atom"/>
    <category term="K.6.5; C.2.0; D.4.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1312.5050v1</id>
    <updated>2013-12-18T06:41:12Z</updated>
    <published>2013-12-18T06:41:12Z</published>
    <title>Fake View Analytics in Online Video Services</title>
    <summary>  Online video-on-demand(VoD) services invariably maintain a view count for
each video they serve, and it has become an important currency for various
stakeholders, from viewers, to content owners, advertizers, and the online
service providers themselves. There is often significant financial incentive to
use a robot (or a botnet) to artificially create fake views. How can we detect
the fake views? Can we detect them (and stop them) using online algorithms as
they occur? What is the extent of fake views with current VoD service
providers? These are the questions we study in the paper. We develop some
algorithms and show that they are quite effective for this problem.
</summary>
    <author>
      <name>Liang Chen</name>
    </author>
    <author>
      <name>Yipeng Zhou</name>
    </author>
    <author>
      <name>Dah Ming Chiu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">25 pages, 15 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1312.5050v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1312.5050v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1401.5561v1</id>
    <updated>2014-01-22T05:58:55Z</updated>
    <published>2014-01-22T05:58:55Z</published>
    <title>A Study of Various Steganographic Techniques Used for Information Hiding</title>
    <summary>  Steganography derives from the Greek word steganos, meaning covered or
secret, and graphy (writing or drawing). Steganography is a technology where
modern data compression, information theory, spread spectrum, and cryptography
technologies are brought together to satisfy the need for privacy on the
Internet. This paper is an attempt to analyse the various techniques used in
steganography and to identify areas in which this technique can be applied, so
that the human race can be benefited at large.
</summary>
    <author>
      <name>C. P. Sumathi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Computer Science, SDNB Vaishnav College For Women, Chennai, India</arxiv:affiliation>
    </author>
    <author>
      <name>T. Santanam</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Computer Science, DG Vaishnav College For Men, Chennai, India</arxiv:affiliation>
    </author>
    <author>
      <name>G. Umamaheswari</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Computer Science, SDNB Vaishnav College For Women, Chennai, India</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 Pages, International Journal of Computer Science &amp; Engineering
  Survey (IJCSES) Vol.4, No.6, December 2013</arxiv:comment>
    <link href="http://arxiv.org/abs/1401.5561v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1401.5561v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1402.6034v1</id>
    <updated>2014-02-25T02:49:01Z</updated>
    <published>2014-02-25T02:49:01Z</published>
    <title>A DCT Approximation for Image Compression</title>
    <summary>  An orthogonal approximation for the 8-point discrete cosine transform (DCT)
is introduced. The proposed transformation matrix contains only zeros and ones;
multiplications and bit-shift operations are absent. Close spectral behavior
relative to the DCT was adopted as design criterion. The proposed algorithm is
superior to the signed discrete cosine transform. It could also outperform
state-of-the-art algorithms in low and high image compression scenarios,
exhibiting at the same time a comparable computational complexity.
</summary>
    <author>
      <name>R. J. Cintra</name>
    </author>
    <author>
      <name>F. M. Bayer</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/LSP.2011.2163394</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/LSP.2011.2163394" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 6 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE Signal Processing Letters, 18(10):579-582, October 2011</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1402.6034v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1402.6034v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1403.4158v1</id>
    <updated>2014-03-17T16:42:43Z</updated>
    <published>2014-03-17T16:42:43Z</published>
    <title>A Methodology for Implementation of MMS Client on Embedded Platforms</title>
    <summary>  MMS (Multimedia Messaging Service) is the next generation of messaging
services in multimedia mobile communications. MMS enables messaging with full
multimedia content including images, audios, videos, texts and data, from
client to client or e-mail. MMS is based on WAP technology, so it is technology
independent. This means that enabling messages from a GSM/GPRS network to be
sent to a TDMA or WCDMA network. In this paper a methodology for implementing
MMS client on embedded platforms especially on Wince OS is described.
</summary>
    <author>
      <name>A. A. Milani</name>
    </author>
    <author>
      <name>Reza Rahimi</name>
    </author>
    <link href="http://arxiv.org/abs/1403.4158v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1403.4158v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.1313v1</id>
    <updated>2014-03-31T14:19:04Z</updated>
    <published>2014-03-31T14:19:04Z</published>
    <title>Color to Gray and Back transformation for distributing color digital
  images</title>
    <summary>  The Color to Gray and Back transformation watermarking with a secrete key is
considered. Color is embedded into the bit planes of the luminosity component
of the YUV color space with the help of a block algorithm that allows using not
only the least significant bits. An application of the problem of distributing
color digital images from a data base among legitimate users is discussed. The
proposed protocol can protect original images from unauthorized copying.
</summary>
    <author>
      <name>V. N. Gorbachev</name>
    </author>
    <author>
      <name>E. M. Kaynarova</name>
    </author>
    <author>
      <name>I. K. Metelev</name>
    </author>
    <author>
      <name>E. S. Yakovleva</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 3 figures, submitted to The International Conference on
  Computer Graphics and Vision, GraphiCon'2013</arxiv:comment>
    <link href="http://arxiv.org/abs/1404.1313v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.1313v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.2237v1</id>
    <updated>2014-02-02T17:09:56Z</updated>
    <published>2014-02-02T17:09:56Z</published>
    <title>Steganography - coding and intercepting the information from encoded
  pictures in the absence of any initial information</title>
    <summary>  The work includes implementation and extraction algorithms capabilities test,
without any additional data (starting position, the number of bits used, gap
between the amount of data encoded) information from encoded files (mostly
images). The software is written using OpenMP standard [1], which allowed them
to run on parallel computers. Performance tests were carried out on computers,
Blue Gene/P [2], Blue Gene/Q [3] and the system consisting of four AMD Opteron
6272 [4]. Source code is available under GNU GPL v3 license and are available
in a repository OLib [5].
</summary>
    <author>
      <name>Monika Kwiatkowska</name>
    </author>
    <author>
      <name>Lukasz Swierczewski</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 5 figures, 5 tables, LVEE 2014 Conference Proceedings</arxiv:comment>
    <link href="http://arxiv.org/abs/1404.2237v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.2237v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.2592v1</id>
    <updated>2014-04-09T01:35:26Z</updated>
    <published>2014-04-09T01:35:26Z</published>
    <title>Reduction of Field Loss by a Video Processing System</title>
    <summary>  Streaming of 60 de-interlaced fields per second digital uncompressed video
with 720x480 resolution without a loss of video fields is one of the desired
technologies by scientists in biomechanics. If it is possible to stream digital
uncompressed video without dropped video fields, then a sophisticated computer
analysis of the transmitted via IEEE 1394a connection video is possible. Such
process is used in biomechanics when it is important to analyze athletes
performance via streaming digital uncompressed video to a computer and then
analyzing it using specific software such as Arial Performance Analysis
Systems.
</summary>
    <author>
      <name>Dr. Timur Mirzoev</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: substantial text overlap with arXiv:1404.2344</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Southeast Decision Sciences Institute. Conference Proceedings.
  SEDSI 2008</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1404.2592v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.2592v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.7335v1</id>
    <updated>2014-04-29T12:30:36Z</updated>
    <published>2014-04-29T12:30:36Z</published>
    <title>Antescofo Intermediate Representation</title>
    <summary>  We describe an intermediate language designed as a medium-level internal
representation of programs of the interactive music system Antescofo. This
representation is independent both of the Antescofo source language and of the
architecture of the execution platform. It is used in tasks such as
verification of timings, model-based conformance testing, static control-flow
analysis or simulation. This language is essentially a flat representation of
Antescofo's code, as a finite state machine extended with local and global
variables, with delays and with concurrent threads creation. It features a
small number of simple instructions which are either blocking (wait for
external event, signal or duration) or not (variable assignment, message
emission and control).
</summary>
    <author>
      <name>Florent Jacquemard</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Inria Paris-Rocquencourt, STMS</arxiv:affiliation>
    </author>
    <author>
      <name>Clément Poncelet Sanchez</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Inria Paris-Rocquencourt, STMS</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">RR-8520 (2014)</arxiv:comment>
    <link href="http://arxiv.org/abs/1404.7335v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.7335v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.3207v1</id>
    <updated>2014-05-12T16:45:21Z</updated>
    <published>2014-05-12T16:45:21Z</published>
    <title>An Adaptive Watermarking Process in Hadamard Transform</title>
    <summary>  An adaptive visible/invisible watermarking scheme is done to prevent the
privacy and preserving copyright protection of digital data using Hadamard
transform based on the scaling factor of the image. The value of scaling factor
depends on the control parameter. The scaling factor is calculated to embedded
the watermark. Depend upon the control parameter the visible and invisible
watermarking is determined. The proposed Hadamard transform domain method is
more robust again image/signal processing attacks. Furthermore, it also shows
that the proposed method confirm the efficiency through various performance
analysis and experimental results.
</summary>
    <author>
      <name>Parvathavarthini S.</name>
    </author>
    <author>
      <name>Shanthakumari R</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 Pages, 10 Figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1405.3207v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.3207v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.5119v1</id>
    <updated>2014-05-20T15:21:52Z</updated>
    <published>2014-05-20T15:21:52Z</published>
    <title>Steganalysis: Detecting LSB Steganographic Techniques</title>
    <summary>  Steganalysis means analysis of stego images. Like cryptanalysis, steganalysis
is used to detect messages often encrypted using secret key from stego images
produced by steganography techniques. Recently lots of new and improved
steganography techniques are developed and proposed by researchers which
require robust steganalysis techniques to detect the stego images having
minimum false alarm rate. This paper discusses about the different Steganalysis
techniques and help to understand how, where and when this techniques can be
used based on different situations.
</summary>
    <author>
      <name>Tanmoy Sarkar</name>
    </author>
    <author>
      <name>Sugata Sanyal</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1405.5119v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.5119v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.5948v1</id>
    <updated>2014-05-23T02:24:11Z</updated>
    <published>2014-05-23T02:24:11Z</published>
    <title>Low-complexity video encoder for smart eyes based on underdetermined
  blind signal separation</title>
    <summary>  This paper presents a low complexity video coding method based on
Underdetermined Blind Signal Separation (UBSS). The detailed coding framework
is designed. Three key techniques are proposed to enhance the compression ratio
and the quality of the decoded frames. The experiments validate that the
proposed method costs 30ms encoding time less than DISCOVER. The simulation
shows that this new method can save 50% energy compared with H.264.
</summary>
    <author>
      <name>Jing Liu</name>
    </author>
    <author>
      <name>Fei Qiao</name>
    </author>
    <author>
      <name>Zhijian Ou</name>
    </author>
    <author>
      <name>Huazhong Yang</name>
    </author>
    <link href="http://arxiv.org/abs/1405.5948v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.5948v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.6147v1</id>
    <updated>2014-05-08T08:04:21Z</updated>
    <published>2014-05-08T08:04:21Z</published>
    <title>Jpeg Image Compression Using Discrete Cosine Transform - A Survey</title>
    <summary>  Due to the increasing requirements for transmission of images in computer,
mobile environments, the research in the field of image compression has
increased significantly. Image compression plays a crucial role in digital
image processing, it is also very important for efficient transmission and
storage of images. When we compute the number of bits per image resulting from
typical sampling rates and quantization methods, we find that Image compression
is needed. Therefore development of efficient techniques for image compression
has become necessary .This paper is a survey for lossy image compression using
Discrete Cosine Transform, it covers JPEG compression algorithm which is used
for full-colour still image applications and describes all the components of
it.
</summary>
    <author>
      <name>A. M. Raid</name>
    </author>
    <author>
      <name>W. M. Khedr</name>
    </author>
    <author>
      <name>M. A. El-dosuky</name>
    </author>
    <author>
      <name>Wesam Ahmed</name>
    </author>
    <link href="http://arxiv.org/abs/1405.6147v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.6147v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1406.6012v1</id>
    <updated>2014-06-23T18:29:59Z</updated>
    <published>2014-06-23T18:29:59Z</published>
    <title>Designing Sound Collaboratively - Perceptually Motivated Audio Synthesis</title>
    <summary>  In this contribution, we will discuss a prototype that allows a group of
users to design sound collaboratively in real time using a multi-touch
tabletop. We make use of a machine learning method to generate a mapping from
perceptual audio features to synthesis parameters. This mapping is then used
for visualization and interaction. Finally, we discuss the results of a
comparative evaluation study.
</summary>
    <author>
      <name>Niklas Klügel</name>
    </author>
    <author>
      <name>Timo Becker</name>
    </author>
    <author>
      <name>Georg Groh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Extended version of submission to conference proceedings</arxiv:comment>
    <link href="http://arxiv.org/abs/1406.6012v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1406.6012v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1407.2221v1</id>
    <updated>2014-07-06T06:29:34Z</updated>
    <published>2014-07-06T06:29:34Z</published>
    <title>Sonic interaction with a virtual orchestra of factory machinery</title>
    <summary>  This paper presents an immersive application where users receive sound and
visual feedbacks on their interactions with a virtual environment. In this
application, the users play the part of conductors of an orchestra of factory
machines since each of their actions on interaction devices triggers a pair of
visual and audio responses. Audio stimuli were spatialized around the listener.
The application was exhibited during the 2013 Science and Music day and
designed to be used in a large immersive system with head tracking, shutter
glasses and a 10.2 loudspeaker configuration.
</summary>
    <author>
      <name>Laurent Simon</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIMSI</arxiv:affiliation>
    </author>
    <author>
      <name>Florian Nouviale</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INSA Rennes, INRIA - IRISA</arxiv:affiliation>
    </author>
    <author>
      <name>Ronan Gaugne</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">UR1</arxiv:affiliation>
    </author>
    <author>
      <name>Valérie Gouranton</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INSA Rennes, INRIA - IRISA</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Sonic Interaction for Virtual Environments, Minneapolis : United
  States (2014)</arxiv:comment>
    <link href="http://arxiv.org/abs/1407.2221v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1407.2221v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1407.2729v1</id>
    <updated>2014-07-10T09:07:03Z</updated>
    <published>2014-07-10T09:07:03Z</published>
    <title>Genetic Algorithm in Audio Steganography</title>
    <summary>  With the advancement of communication technology,data is exchanged digitally
over the network. At the other side the technology is also proven as a tool for
unauthorized access to attackers. Thus the security of data to be transmitted
digitally should get prime focus. Data hiding is the common approach to secure
data. In steganography technique, the existence of data is concealed. GA is an
emerging component of AI to provide suboptimal solutions. In this paper the use
of GA in Steganography is explored to find future scope of research.
</summary>
    <author>
      <name>Manisha Rana</name>
    </author>
    <author>
      <name>Rohit Tanwar</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.14445/22315381/IJETT-V13P206</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.14445/22315381/IJETT-V13P206" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages,2 figures Published with International Journal of Engineering
  Trends and Technology (IJETT). arXiv admin note: text overlap with
  arXiv:1003.4084, arXiv:1205.2800 by other authors without attribution</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IJETT, V13(1),29-34 July 2014</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1407.2729v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1407.2729v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1407.4735v1</id>
    <updated>2014-07-17T16:56:15Z</updated>
    <published>2014-07-17T16:56:15Z</published>
    <title>A Survey of Digital Watermarking Techniques and its Applications</title>
    <summary>  Digital media is the need of a people now a day as the alternate of paper
media.As the technology grown up digital media required protection while
transferring through internet or others mediums.Watermarking techniques have
been developed to fulfill this requirement.This paper aims to provide a
detailed survey of all watermarking techniques specially focuses on image
watermarking types and its applications in today world.
</summary>
    <author>
      <name>Lalit Kumar Saini</name>
    </author>
    <author>
      <name>Vishal Shrivastava</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 Pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IJCST V2(3): Page(70-73) May-June 2014</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1407.4735v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1407.4735v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1407.4865v4</id>
    <updated>2014-08-14T12:10:59Z</updated>
    <published>2014-07-18T01:37:21Z</published>
    <title>Robust Lossless Semi Fragile Information Protection in Images</title>
    <summary>  Internet security finds it difficult to keep the information secure and to
maintain the integrity of the data. Sending messages over the internet secretly
is one of the major tasks as it is widely used for passing the message.
</summary>
    <author>
      <name>Pushkar Dixit</name>
    </author>
    <author>
      <name>Nishant Singh</name>
    </author>
    <author>
      <name>Jay Prakash Gupta</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper has been withdrawn by the author due to a crucial error in
  diffusion process</arxiv:comment>
    <link href="http://arxiv.org/abs/1407.4865v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1407.4865v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1409.0915v1</id>
    <updated>2014-09-02T22:59:52Z</updated>
    <published>2014-09-02T22:59:52Z</published>
    <title>An Approach for Text Steganography Based on Markov Chains</title>
    <summary>  A text steganography method based on Markov chains is introduced, together
with a reference implementation. This method allows for information hiding in
texts that are automatically generated following a given Markov model. Other
Markov - based systems of this kind rely on big simplifications of the language
model to work, which produces less natural looking and more easily detectable
texts. The method described here is designed to generate texts within a good
approximation of the original language model provided.
</summary>
    <author>
      <name>H. Hernan Moraldo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented at 41 JAIIO - WSegI 2012</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">41 JAIIO - WSegI 2012, ISSN: 2313-9110, pages 21 - 35</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1409.0915v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1409.0915v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68P25, 94A60" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.4.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.2100v1</id>
    <updated>2014-10-08T13:24:06Z</updated>
    <published>2014-10-08T13:24:06Z</published>
    <title>A New Method for Estimating the Widths of JPEG Images</title>
    <summary>  Image width is important for image understanding. We propose a novel method
to estimate widths for JPEG images when their widths are not available. The key
idea is that the distance between two decoded MCUs (Minimum Coded Unit)
adjacent in the vertical direction is usually small, which is measured by the
average Euclidean distance between the pixels from the bottom row of the top
MCU and the top row of the bottom MCU. On PASCAL VOC 2010 challenge dataset and
USC-SIPI image database, experimental results show the high performance of the
proposed approach.
</summary>
    <author>
      <name>Wu Xianyan</name>
    </author>
    <author>
      <name>Han Qi</name>
    </author>
    <author>
      <name>Le Dan</name>
    </author>
    <author>
      <name>Niu Xiamu</name>
    </author>
    <link href="http://arxiv.org/abs/1410.2100v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.2100v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.2324v1</id>
    <updated>2014-10-09T00:53:11Z</updated>
    <published>2014-10-09T00:53:11Z</published>
    <title>Recommendation Scheme Based on Converging Properties for Contents
  Broadcasting</title>
    <summary>  Popular videos are often clicked by a mount of users in a short period. With
content recommendation, the popular contents could be broadcast to the
potential users in wireless network, to save huge transmitting resource. In
this paper, the contents propagation model is analyzed due to users' historical
behavior, location, and the converging properties in wireless data
transmission, with the users' communication log in the Chinese commercial
cellular network. And a recommendation scheme is proposed to achieve high
energy efficiency.
</summary>
    <author>
      <name>Jian Sun</name>
    </author>
    <author>
      <name>Xiaofeng Zhong</name>
    </author>
    <author>
      <name>Xuan Zhou</name>
    </author>
    <author>
      <name>Xiaolong Fu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages. This work is present at 2015 International Workshop on
  Networking Issues in Multimedia Entertainment (NIME'15)</arxiv:comment>
    <link href="http://arxiv.org/abs/1410.2324v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.2324v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1411.6928v1</id>
    <updated>2014-11-25T17:23:19Z</updated>
    <published>2014-11-25T17:23:19Z</published>
    <title>A Tag Identification Approach Based On Fragile Watermark</title>
    <summary>  This paper proposes a tag identify approach based on fragile Watermark that
based on Least significant bit of the replacement that we first use a special
way to initialize the cover to ensure that we can use random positions to embed
the information of tag. Using this way enhance the security of other to get the
right information of this tag. Finally as long as the covered information can
be decoded, the completeness and accuracy of the tag information can be
guaranteed. the result of simulation experiment show that this approach has
high sensitivity and security .
</summary>
    <author>
      <name>Jianbiao Lin</name>
    </author>
    <author>
      <name>Ke Ji</name>
    </author>
    <author>
      <name>Hui Lin</name>
    </author>
    <author>
      <name>Enyan Wu</name>
    </author>
    <author>
      <name>Xin Gao</name>
    </author>
    <link href="http://arxiv.org/abs/1411.6928v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1411.6928v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.4576v1</id>
    <updated>2014-12-15T13:19:24Z</updated>
    <published>2014-12-15T13:19:24Z</published>
    <title>Multi-Hypothesis Compressed Video Sensing Technique</title>
    <summary>  In this paper, we present a compressive sampling and Multi-Hypothesis (MH)
reconstruction strategy for video sequences which has a rather simple encoder,
while the decoding system is not that complex. We introduce a convex cost
function that incorporates the MH technique with the sparsity constraint and
the Tikhonov regularization. Consequently, we derive a new iterative algorithm
based on these criteria. This algorithm surpasses its counterparts (Elasticnet
and Tikhonov) in the recovery performance. Besides it is computationally much
faster than the Elasticnet and comparable to the Tikhonov. Our extensive
simulation results confirm these claims.
</summary>
    <author>
      <name>Masoumeh Azghani</name>
    </author>
    <author>
      <name>Mostafa Karimi</name>
    </author>
    <author>
      <name>Farokh Marvasti</name>
    </author>
    <link href="http://arxiv.org/abs/1412.4576v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.4576v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1501.01758v1</id>
    <updated>2015-01-08T08:08:50Z</updated>
    <published>2015-01-08T08:08:50Z</published>
    <title>Enhance Robustness of Image-in-Image Watermarking through Data
  Partitioning</title>
    <summary>  Vulnerability of watermarking schemes against intense signal processing
attacks is generally a major concern, particularly when there are techniques to
reproduce an acceptable copy of the original signal with no chance for
detecting the watermark. In this paper, we propose a two-layer, data
partitioning (DP) based, image in image watermarking method in the DCT domain
to improve the watermark detection performance. Truncated singular value
decomposition, binary wavelet decomposition and spatial scalability idea in
H.264/SVC are analyzed and employed as partitioning methods. It is shown that
the proposed scheme outperforms its two recent competitors in terms of both
data payload and robustness to intense attacks.
</summary>
    <author>
      <name>Hossein Bakhshi Golestani</name>
    </author>
    <author>
      <name>Shahrokh Ghaemmaghami</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 7 figures, IEEE TENCON2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1501.01758v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1501.01758v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1501.02659v1</id>
    <updated>2015-01-12T14:27:37Z</updated>
    <published>2015-01-12T14:27:37Z</published>
    <title>PacMap: Transferring PacMan to the Physical Realm</title>
    <summary>  This paper discusses the implementation of the pervasive game PacMap.
Openness and portability have been the main design objectives for PacMap. We
elaborate on programming techniques which may be applicable to a broad range of
location-based games that involve the movement of virtual characters over map
interfaces. In particular, we present techniques to execute shortest path
algorithms on spatial environments bypassing the restrictions imposed by
commercial mapping services. Last, we present ways to improve the movement and
enhance the intelligence of virtual characters taking into consideration the
actions and position of players in location-based games.
</summary>
    <author>
      <name>Thomas Chatzidimitris</name>
    </author>
    <author>
      <name>Damianos Gavalas</name>
    </author>
    <author>
      <name>Vlasios Kasapakis</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 3 figures, Proceedings of the International Conference on
  Pervasive Games (PERGAMES'2014), Rome, Italy, 27 October 2014</arxiv:comment>
    <link href="http://arxiv.org/abs/1501.02659v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1501.02659v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1501.07034v1</id>
    <updated>2015-01-28T08:58:20Z</updated>
    <published>2015-01-28T08:58:20Z</published>
    <title>Embedding of binary image in the Gray planes</title>
    <summary>  For watermarking of the digital grayscale image its Gray planes have been
used. With the help of the introduced representation over Gray planes the LSB
embedding method and detection have been discussed. It found that data, a
binary image, hidden in the Gray planes is more robust to JPEG lossy
compression than in the bit planes.
</summary>
    <author>
      <name>V. N. Gorbachev</name>
    </author>
    <author>
      <name>L. A. Denisov</name>
    </author>
    <author>
      <name>E. M. Kainarova</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 3 figures, Proceeding of 24rd International Conference on
  Computer Graphics and Vision GraphiCon'2014, Sept.30 - Oct.3,2014,
  Rostov-on-Don, Russia</arxiv:comment>
    <link href="http://arxiv.org/abs/1501.07034v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1501.07034v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.07551v1</id>
    <updated>2015-02-05T03:15:25Z</updated>
    <published>2015-02-05T03:15:25Z</published>
    <title>A Low-throughput Wavelet-based Steganography Audio Scheme</title>
    <summary>  This paper presents the preliminary of a novel scheme of steganography, and
introduces the idea of combining two secret keys in the operation. The first
secret key encrypts the text using a standard cryptographic scheme (e.g. IDEA,
SAFER+, etc.) prior to the wavelet audio decomposition. The way in which the
cipher text is embedded in the file requires another key, namely a stego-key,
which is associated with features of the audio wavelet analysis.
</summary>
    <author>
      <name>P. Carrion</name>
    </author>
    <author>
      <name>H. M. de Oliveira</name>
    </author>
    <author>
      <name>R. M. Campello de Souza</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2 pages, 1 figure, conference: 8th Brazilian Symposium on Information
  and Computer System Security, 2008, Gramado, RS, Brazil</arxiv:comment>
    <link href="http://arxiv.org/abs/1503.07551v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.07551v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.05226v1</id>
    <updated>2015-04-20T20:53:29Z</updated>
    <published>2015-04-20T20:53:29Z</published>
    <title>On the Security of a Revised Fragile Watermarking Scheme</title>
    <summary>  This paper analyzes a revised fragile watermarking scheme proposed by Botta
et al. which was developed as a revision of the watermarking scheme previously
proposed by Rawat et al. A new attack is presented that allows an attacker to
apply a valid watermark on tampered images, therefore circumventing the
protection that the watermarking scheme under study was supposed to offer.
Furthermore, the presented attack has very low computational and memory
requirements.
</summary>
    <author>
      <name>Daniel Caragata</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To be submitted to AEU INT J ELECTRON C</arxiv:comment>
    <link href="http://arxiv.org/abs/1504.05226v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.05226v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.05407v1</id>
    <updated>2015-05-20T14:46:51Z</updated>
    <published>2015-05-20T14:46:51Z</published>
    <title>Compressive Sensing of Large-Scale Images: An Assumption-Free Approach</title>
    <summary>  Cost-efficient compressive sensing of big media data with fast reconstructed
high-quality results is very challenging. In this paper, we propose a new
large-scale image compressive sensing method, composed of operator-based
strategy in the context of fixed point continuation method and weighted LASSO
with tree structure sparsity pattern. The main characteristic of our method is
free from any assumptions and restrictions. The feasibility of our method is
verified via simulations and comparisons with state-of-the-art algorithms.
</summary>
    <author>
      <name>Wei-Jie Liang</name>
    </author>
    <author>
      <name>Gang-Xuan Lin</name>
    </author>
    <author>
      <name>Chun-Shien Lu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1505.05407v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.05407v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.07757v1</id>
    <updated>2015-05-28T16:54:13Z</updated>
    <published>2015-05-28T16:54:13Z</published>
    <title>Micro protocol engineering for unstructured carriers: On the embedding
  of steganographic control protocols into audio transmissions</title>
    <summary>  Network steganography conceals the transfer of sensitive information within
unobtrusive data in computer networks. So-called micro protocols are
communication protocols placed within the payload of a network steganographic
transfer. They enrich this transfer with features such as reliability, dynamic
overlay routing, or performance optimization --- just to mention a few. We
present different design approaches for the embedding of hidden channels with
micro protocols in digitized audio signals under consideration of different
requirements. On the basis of experimental results, our design approaches are
compared, and introduced into a protocol engineering approach for micro
protocols.
</summary>
    <author>
      <name>Matthias Naumann</name>
    </author>
    <author>
      <name>Steffen Wendzel</name>
    </author>
    <author>
      <name>Wojciech Mazurczyk</name>
    </author>
    <author>
      <name>Jörg Keller</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages, 7 figures, 4 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1505.07757v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.07757v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.01501v1</id>
    <updated>2015-06-04T08:10:13Z</updated>
    <published>2015-06-04T08:10:13Z</published>
    <title>Optimum Decoder for an Additive Video Watermarking with Laplacian Noise
  in H.264</title>
    <summary>  In this paper, we investigate an additive video watermarking method in H.264
standard in presence of the Laplacian noise. In some applications, due to the
loss of some pixels or a region of a frame, we resort to Laplacian noise rather
than Gaussian one. The embedding is performed in the transform domain; while an
optimum and a sub-optimum decoder are derived for the proposed Laplacian model.
Simulation results show that the proposed watermarking scheme has suitable
performance with enough transparency required for watermarking applications.
</summary>
    <author>
      <name>Nematollah Zarmehi</name>
    </author>
    <author>
      <name>Morteza Banagar</name>
    </author>
    <author>
      <name>Mohammad Ali Akhaee</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/ISCISC.2013.6767352</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/ISCISC.2013.6767352" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">2013 10th International ISC Conference on Information Security and
  Cryptology (ISCISC),Aug. 2013, pp. 1-5</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1506.01501v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.01501v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.03681v1</id>
    <updated>2015-06-11T14:05:45Z</updated>
    <published>2015-06-11T14:05:45Z</published>
    <title>A Novel Approach for Image Steganography in Spatial Domain</title>
    <summary>  This paper presents a new approach for hiding information in digital image in
spatial domain. In this approach three bits of message is embedded in a pixel
using Lucas number system but only one bit plane is allowed for alternation.
The experimental results show that the proposed method has the larger capacity
of embedding data, high peak signal to noise ratio compared to existing methods
and is hardly detectable for steganolysis algorithm.
</summary>
    <author>
      <name>Fatema Akhter</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Global Journal of Computer Science and Technology, Volume 13,
  Issue 7, pp. 1-6 Year 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1506.03681v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.03681v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.08811v1</id>
    <updated>2015-05-23T21:43:59Z</updated>
    <published>2015-05-23T21:43:59Z</published>
    <title>A new approach for image compression using normal matrices</title>
    <summary>  In this paper, we present methods for image compression on the basis of
eigenvalue decomposition of normal matrices. The proposed methods are
convenient and self-explanatory, requiring fewer and easier computations as
compared to some existing methods. Through the proposed techniques, the image
is transformed to the space of normal matrices. Then, the properties of
spectral decomposition are dealt with to obtain compressed images. Experimental
results are provided to illustrate the validity of the methods.
</summary>
    <author>
      <name>E. Kokabifar</name>
    </author>
    <author>
      <name>G. B. Loghmani</name>
    </author>
    <author>
      <name>A. Latif</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: text overlap with arXiv:1506.01952</arxiv:comment>
    <link href="http://arxiv.org/abs/1506.08811v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.08811v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.01485v1</id>
    <updated>2015-08-06T18:39:19Z</updated>
    <published>2015-08-06T18:39:19Z</published>
    <title>Arabic Text Watermarking: A Review</title>
    <summary>  The using of the internet with its technologies and applications have been
increased rapidly. So, protecting the text from illegal use is too needed .
Text watermarking is used for this purpose. Arabic text has many
characteristics such existing of diacritics , kashida (extension character) and
points above or under its letters .Each of Arabic letters can take different
shapes with different Unicode. These characteristics are utilized in the
watermarking process. In this paper, several methods are discussed in the area
of Arabic text watermarking with its advantages and disadvantages .Comparison
of these methods is done in term of capacity, robustness and Imperceptibility.
</summary>
    <author>
      <name>Reem Ahmed Alotaibi</name>
    </author>
    <author>
      <name>Lamiaa A. Elrefaei</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 4 tables and 19 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Artificial Intelligence &amp; Applications
  (IJAIA) Vol. 6, No. 4, July 2015</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1508.01485v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.01485v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1509.03278v1</id>
    <updated>2015-09-10T19:01:14Z</updated>
    <published>2015-09-10T19:01:14Z</published>
    <title>A New Method For Digital Watermarking Based on Combination of DCT and
  PCA</title>
    <summary>  In the digital watermarking with DCT method,the watermark is located within a
range of DCT coefficients of the cover image. In this paper to use the
low-frequency band, a new method is proposed by using a combination of the DCT
and PCA transform. The proposed method is compared to other DCT methods, our
method is robust and keeps the quality of cover image, also increases capacity
of the watermarking.
</summary>
    <author>
      <name>Arash Saboori</name>
    </author>
    <author>
      <name>S. Abolfazl Hosseini</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TELFOR.2014.7034461</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TELFOR.2014.7034461" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Telecommunications Forum Telfor (TELFOR), 2014 22nd</arxiv:comment>
    <link href="http://arxiv.org/abs/1509.03278v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1509.03278v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.03090v1</id>
    <updated>2015-10-11T19:15:56Z</updated>
    <published>2015-10-11T19:15:56Z</published>
    <title>An Extension of Interactive Scores for Multimedia Scenarios with
  Temporal Relations for Micro and Macro Controls</title>
    <summary>  Software to design multimedia scenarios is usually based either on a fixed
timeline or on cue lists, but both models are unrelated temporally. On the
contrary, the formalism of interactive scores can describe multimedia scenarios
with flexible and fixed temporal relations among the objects of the scenario,
but cannot express neither temporal relations for micro controls nor signal
processing. We extend interactive scores with such relations and with sound
processing. We show some applications and we describe how they can be
implemented in Pure Data. Our implementation has low average relative jitter
even under high cpu load.
</summary>
    <author>
      <name>Mauricio Toro</name>
    </author>
    <author>
      <name>Myriam Desainte-Catherine</name>
    </author>
    <author>
      <name>Julien Castet</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">extended version of article presented in the Sound and Music
  Computing Conference 2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1510.03090v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.03090v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="C.3; D.1.6; H.5.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.00118v1</id>
    <updated>2015-10-31T12:30:52Z</updated>
    <published>2015-10-31T12:30:52Z</published>
    <title>A new chaos-based watermarking algorithm</title>
    <summary>  This paper introduces a new watermarking algorithm based on discrete chaotic
iterations. After defining some coefficients deduced from the description of
the carrier medium, chaotic discrete iterations are used to mix the watermark
and to embed it in the carrier medium. It can be proved that this procedure
generates topological chaos, which ensures that desired properties of a
watermarking algorithm are satisfied.
</summary>
    <author>
      <name>Jacques M. Bahi</name>
    </author>
    <author>
      <name>Christophe Guyeux</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">SECRYPT 2010, International Conference on Security and Cryptograph.
  Submitted as a regular paper, accepted as a short one. arXiv admin note: text
  overlap with arXiv:0810.4713, arXiv:1012.4620</arxiv:comment>
    <link href="http://arxiv.org/abs/1511.00118v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.00118v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.03398v1</id>
    <updated>2015-11-11T06:44:31Z</updated>
    <published>2015-11-11T06:44:31Z</published>
    <title>A GMM-Based Stair Quality Model for Human Perceived JPEG Images</title>
    <summary>  Based on the notion of just noticeable differences (JND), a stair quality
function (SQF) was recently proposed to model human perception on JPEG images.
Furthermore, a k-means clustering algorithm was adopted to aggregate JND data
collected from multiple subjects to generate a single SQF. In this work, we
propose a new method to derive the SQF using the Gaussian Mixture Model (GMM).
The newly derived SQF can be interpreted as a way to characterize the mean
viewer experience. Furthermore, it has a lower information criterion (BIC)
value than the previous one, indicating that it offers a better model. A
specific example is given to demonstrate the advantages of the new approach.
</summary>
    <author>
      <name>Sudeng Hu</name>
    </author>
    <author>
      <name>Haiqiang Wang</name>
    </author>
    <author>
      <name>C. -C. Jay Kuo</name>
    </author>
    <link href="http://arxiv.org/abs/1511.03398v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.03398v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.07004v1</id>
    <updated>2015-11-22T12:33:08Z</updated>
    <published>2015-11-22T12:33:08Z</published>
    <title>Understanding Music Playlists</title>
    <summary>  As music streaming services dominate the music industry, the playlist is
becoming an increasingly crucial element of music consumption. Con- sequently,
the music recommendation problem is often casted as a playlist generation prob-
lem. Better understanding of the playlist is there- fore necessary for
developing better playlist gen- eration algorithms. In this work, we analyse
two playlist datasets to investigate some com- monly assumed hypotheses about
playlists. Our findings indicate that deeper understanding of playlists is
needed to provide better prior infor- mation and improve machine learning
algorithms in the design of recommendation systems.
</summary>
    <author>
      <name>Keunwoo Choi</name>
    </author>
    <author>
      <name>George Fazekas</name>
    </author>
    <author>
      <name>Mark Sandler</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">International Conference on Machine Learning (ICML) 2015, Machine
  Learning for Music Discovery Workshop</arxiv:comment>
    <link href="http://arxiv.org/abs/1511.07004v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.07004v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.00299v1</id>
    <updated>2016-01-03T14:23:32Z</updated>
    <published>2016-01-03T14:23:32Z</published>
    <title>Capacity Enlargement Of The PVD Steganography Method Using The GLM
  Technique</title>
    <summary>  In most steganographic methods, increasing in the capacity leads to decrease
in the quality of the stego-image, so in this paper, we propose to combine two
existing techniques, Pixel value differencing and Gray Level Modification, to
come up with a hybrid steganography scheme which can hide more information
without having to compromise much on the quality of the stego-image.
Experimental results demonstrate that the proposed approach has larger capacity
while its results are imperceptible. In comparison with original PVD method
criterion of the quality is declined by 2% dB averagely while the capacity is
increased around 25%.
</summary>
    <author>
      <name>Mehdi Safarpour</name>
    </author>
    <author>
      <name>Mostafa Charmi</name>
    </author>
    <link href="http://arxiv.org/abs/1601.00299v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.00299v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.01386v1</id>
    <updated>2016-01-07T03:32:27Z</updated>
    <published>2016-01-07T03:32:27Z</published>
    <title>A New Image Steganographic Technique using Pattern based Bits Shuffling
  and Magic LSB for Grayscale Images</title>
    <summary>  Image Steganography is a growing research area of information security where
secret information is embedded in innocent-looking public communication. This
paper proposes a novel crystographic technique for grayscale images in spatial
domain. The secret data is encrypted and shuffled using pattern based bits
shuffling algorithm (PBSA) and a secret key. The encrypted data is then
embedded in the cover image using magic least significant bit (M-LSB) method.
Experimentally, the proposed method is evaluated by qualitative and
quantitative analysis which validates the effectiveness of the proposed method
in contrast to several state-of-the-art methods.
</summary>
    <author>
      <name>Khan Muhammad</name>
    </author>
    <author>
      <name>Jamil Ahmad</name>
    </author>
    <author>
      <name>Haleem Farman</name>
    </author>
    <author>
      <name>Zahoor Jan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">A short paper of 6 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Sindh University Research Journal-SURJ (Science Series) 47.4
  (2015)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1601.01386v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.01386v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.07232v1</id>
    <updated>2016-01-27T00:18:26Z</updated>
    <published>2016-01-27T00:18:26Z</published>
    <title>Robust Image Watermarking Using Non-Regular Wavelets</title>
    <summary>  An approach to watermarking digital images using non-regular wavelets is
advanced. Non-regular transforms spread the energy in the transform domain. The
proposed method leads at the same time to increased image quality and increased
robustness with respect to lossy compression. The approach provides robust
watermarking by suitably creating watermarked messages that have energy
compaction and frequency spreading. Our experimental results show that the
application of non-regular wavelets, instead of regular ones, can furnish a
superior robust watermarking scheme. The generated watermarked data is more
immune against non-intentional JPEG and JPEG2000 attacks.
</summary>
    <author>
      <name>R. J. Cintra</name>
    </author>
    <author>
      <name>T. V. Cooklev</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s11760-008-0070-7</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s11760-008-0070-7" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 11 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Signal, Image and Video Processing, September 2009, Volume 3,
  Issue 3, pp 241-250</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1601.07232v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.07232v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1602.01178v1</id>
    <updated>2016-02-03T03:32:31Z</updated>
    <published>2016-02-03T03:32:31Z</published>
    <title>GECKA3D: A 3D Game Engine for Commonsense Knowledge Acquisition</title>
    <summary>  Commonsense knowledge representation and reasoning is key for tasks such as
artificial intelligence and natural language understanding. Since commonsense
consists of information that humans take for granted, gathering it is an
extremely difficult task. In this paper, we introduce a novel 3D game engine
for commonsense knowledge acquisition (GECKA3D) which aims to collect
commonsense from game designers through the development of serious games.
GECKA3D integrates the potential of serious games and games with a purpose.
This provides a platform for the acquisition of re-usable and multi-purpose
knowledge, and also enables the development of games that can provide
entertainment value and teach players something meaningful about the actual
world they live in.
</summary>
    <author>
      <name>Erik Cambria</name>
    </author>
    <author>
      <name>Tam V. Nguyen</name>
    </author>
    <author>
      <name>Brian Cheng</name>
    </author>
    <author>
      <name>Kenneth Kwok</name>
    </author>
    <author>
      <name>Jose Sepulveda</name>
    </author>
    <link href="http://arxiv.org/abs/1602.01178v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1602.01178v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1602.04845v1</id>
    <updated>2016-02-15T21:30:54Z</updated>
    <published>2016-02-15T21:30:54Z</published>
    <title>High-Quality, Low-Delay Music Coding in the Opus Codec</title>
    <summary>  The IETF recently standardized the Opus codec as RFC6716. Opus targets a wide
range of real-time Internet applications by combining a linear prediction coder
with a transform coder. We describe the transform coder, with particular
attention to the psychoacoustic knowledge built into the format. The result
out-performs existing audio codecs that do not operate under real-time
constraints.
</summary>
    <author>
      <name>Jean-Marc Valin</name>
    </author>
    <author>
      <name>Gregory Maxwell</name>
    </author>
    <author>
      <name>Timothy B. Terriberry</name>
    </author>
    <author>
      <name>Koen Vos</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 135th AES Convention. Proceedings of the 135th AES
  Convention, October 2013</arxiv:comment>
    <link href="http://arxiv.org/abs/1602.04845v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1602.04845v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1602.05311v1</id>
    <updated>2016-02-17T05:50:50Z</updated>
    <published>2016-02-17T05:50:50Z</published>
    <title>A Full-Bandwidth Audio Codec With Low Complexity And Very Low Delay</title>
    <summary>  We propose an audio codec that addresses the low-delay requirements of some
applications such as network music performance. The codec is based on the
modified discrete cosine transform (MDCT) with very short frames and uses
gain-shape quantization to preserve the spectral envelope. The short frame
sizes required for low delay typically hinder the performance of transform
codecs. However, at 96 kbit/s and with only 4 ms algorithmic delay, the
proposed codec out-performs the ULD codec operating at the same rate. The total
complexity of the codec is small, at only 17 WMOPS for real-time operation at
48 kHz.
</summary>
    <author>
      <name>Jean-Marc Valin</name>
    </author>
    <author>
      <name>Timothy B. Terriberry</name>
    </author>
    <author>
      <name>Gregory Maxwell</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, Proceedings of EUSIPCO 2009</arxiv:comment>
    <link href="http://arxiv.org/abs/1602.05311v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1602.05311v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1602.05975v2</id>
    <updated>2016-04-07T18:26:09Z</updated>
    <published>2016-02-18T21:14:25Z</published>
    <title>The Daala Directional Deringing Filter</title>
    <summary>  This paper presents the deringing filter used in the Daala royalty-free video
codec. The filter is based on a non-linear conditional replacement filter and
is designed for vectorization efficiency. It takes into account the direction
of edges and patterns being filtered. The filter works by identifying the
direction of each block and then adaptively filtering along the identified
direction. In a second pass, the blocks are also filtered in a different
direction, with more conservative thresholds to avoid blurring edges. The
proposed deringing filter is shown to improve the quality of both Daala and the
Alliance for Open Media (AOM) AV1 video codec.
</summary>
    <author>
      <name>Jean-Marc Valin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1602.05975v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1602.05975v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.03129v1</id>
    <updated>2016-03-10T02:40:05Z</updated>
    <published>2016-03-10T02:40:05Z</published>
    <title>Daala: A Perceptually-Driven Next Generation Video Codec</title>
    <summary>  The Daala project is a royalty-free video codec that attempts to compete with
the best patent-encumbered codecs. Part of our strategy is to replace core
tools of traditional video codecs with alternative approaches, many of them
designed to take perceptual aspects into account, rather than optimizing for
simple metrics like PSNR. This paper documents some of our experiences with
these tools, which ones worked and which did not, and what we've learned from
them. The result is a codec which compares favorably with HEVC on still images,
and is on a path to do so for video as well.
</summary>
    <author>
      <name>Thomas J. Daede</name>
    </author>
    <author>
      <name>Nathan E. Egge</name>
    </author>
    <author>
      <name>Jean-Marc Valin</name>
    </author>
    <author>
      <name>Guillaume Martres</name>
    </author>
    <author>
      <name>Timothy B. Terriberry</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1603.03129v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.03129v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.04270v2</id>
    <updated>2016-10-03T08:34:11Z</updated>
    <published>2016-05-13T17:44:52Z</published>
    <title>A First Look at Quality of Mobile Live Streaming Experience: the Case of
  Periscope</title>
    <summary>  Live multimedia streaming from mobile devices is rapidly gaining popularity
but little is known about the QoE they provide. In this paper, we examine the
Periscope service. We first crawl the service in order to understand its usage
patterns. Then, we study the protocols used, the typical quality of experience
indicators, such as playback smoothness and latency, video quality, and the
energy consumption of the Android application.
</summary>
    <author>
      <name>Matti Siekkinen</name>
    </author>
    <author>
      <name>Enrico Masala</name>
    </author>
    <author>
      <name>Teemu Kämäräinen</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/2987443.2987472</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/2987443.2987472" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings of the ACM Internet Measurement Conference (IMC) 2016</arxiv:comment>
    <link href="http://arxiv.org/abs/1605.04270v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.04270v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.05118v1</id>
    <updated>2016-05-17T11:32:13Z</updated>
    <published>2016-05-17T11:32:13Z</published>
    <title>Lossless Compression in HEVC with Integer-to-Integer Transforms</title>
    <summary>  Many approaches have been proposed to support lossless coding within video
coding standards that are primarily designed for lossy coding. The simplest
approach is to just skip transform and quantization and directly entropy code
the prediction residual, which is used in HEVC version 1. However, this simple
approach is inefficient for compression. More efficient approaches include
processing the residual with DPCM prior to entropy coding. This paper explores
an alternative approach based on processing the residual with
integer-to-integer (i2i) transforms. I2i transforms map integers to integers,
however, unlike the integer transforms used in HEVC for lossy coding, they do
not increase the dynamic range at the output and can be used in lossless
coding. Experiments with the HEVC reference software show competitive results.
</summary>
    <author>
      <name>Fatih Kamisli</name>
    </author>
    <link href="http://arxiv.org/abs/1605.05118v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.05118v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.09486v1</id>
    <updated>2016-05-31T03:59:03Z</updated>
    <published>2016-05-31T03:59:03Z</published>
    <title>Drone Streaming with Wi-Fi Grid Aggregation for Virtual Tour</title>
    <summary>  To provide a live, active and high-quality virtual touring streaming
experience, we propose an unmanned drone stereoscopic streaming paradigm using
a control and streaming infrastructure of a 2.4GHz Wi-Fi grid. Our system
allows users to actively control the streaming captured by a drone, receive and
watch the streaming using a head mount display (HMD); a Wi-Fi grid is deployed
across the remote scene with multi-channel support to enable high-bitrate
stream- ing broadcast from the drones. The system adopt a joint view adaptation
and drone control scheme to enable fast viewer movement including both head
rotation and touring. We implement the prototype on Dji M100 quadcopter and HTC
Vive in a demo scene.
</summary>
    <author>
      <name>Chenglei Wu</name>
    </author>
    <author>
      <name>Zhi Wang</name>
    </author>
    <author>
      <name>Shiqiang Yang</name>
    </author>
    <link href="http://arxiv.org/abs/1605.09486v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.09486v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.02424v1</id>
    <updated>2016-06-08T07:08:10Z</updated>
    <published>2016-06-08T07:08:10Z</published>
    <title>Generic-Precision algorithm for DCT-Cordic architectures</title>
    <summary>  In this paper we propose a generic algorithm to calculate the rotation
parameters of CORDIC angles required for the Discrete Cosine Transform
algorithm (DCT). This leads us to increase the precision of calculation meeting
any accuracy.Our contribution is to use this decomposition in CORDIC based DCT
which is appropriate for domains which require high quality and top precision.
We then propose a hardware implementation of the novel transformation, and as
expected, a substantial improvement in PSNR quality is found.
</summary>
    <author>
      <name>Imen Ben Saad</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LAMSIN</arxiv:affiliation>
    </author>
    <author>
      <name>Younes Lahbib</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LAMSIN</arxiv:affiliation>
    </author>
    <author>
      <name>Yassine Hachaïchi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LAMSIN</arxiv:affiliation>
    </author>
    <author>
      <name>Sonia Mami</name>
    </author>
    <author>
      <name>Abdelkader Mami</name>
    </author>
    <link href="http://arxiv.org/abs/1606.02424v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.02424v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.00321v1</id>
    <updated>2016-07-01T17:19:27Z</updated>
    <published>2016-07-01T17:19:27Z</published>
    <title>Formal Definition of QoE Metrics</title>
    <summary>  This technical report formally defines the QoE metrics which are introduced
and discussed in the article "QoE Beyond the MOS: An In-Depth Look at QoE via
Better Metrics and their Relation to MOS" by Tobias Ho{\ss}feld, Poul E.
Heegaard, Martin Varela, Sebastian M\"oller, accepted for publication in the
Springer journal "Quality and User Experience". Matlab scripts for computing
the QoE metrics for given data sets are available in GitHub.
</summary>
    <author>
      <name>Tobias Hossfeld</name>
    </author>
    <author>
      <name>Poul E. Heegaard</name>
    </author>
    <author>
      <name>Martin Varela</name>
    </author>
    <author>
      <name>Sebastian Möller</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s41233-016-0002-1</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s41233-016-0002-1" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Quality and User Experience (2016) 1: 2</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1607.00321v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.00321v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.04868v2</id>
    <updated>2017-01-15T05:23:51Z</updated>
    <published>2016-08-17T06:24:46Z</published>
    <title>Towards Music Captioning: Generating Music Playlist Descriptions</title>
    <summary>  Descriptions are often provided along with recommendations to help users'
discovery. Recommending automatically generated music playlists (e.g.
personalised playlists) introduces the problem of generating descriptions. In
this paper, we propose a method for generating music playlist descriptions,
which is called as music captioning. In the proposed method, audio content
analysis and natural language processing are adopted to utilise the information
of each track.
</summary>
    <author>
      <name>Keunwoo Choi</name>
    </author>
    <author>
      <name>George Fazekas</name>
    </author>
    <author>
      <name>Brian McFee</name>
    </author>
    <author>
      <name>Kyunghyun Cho</name>
    </author>
    <author>
      <name>Mark Sandler</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2 pages, ISMIR 2016 Late-breaking/session extended abstract</arxiv:comment>
    <link href="http://arxiv.org/abs/1608.04868v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.04868v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.05054v1</id>
    <updated>2016-08-17T19:24:23Z</updated>
    <published>2016-08-17T19:24:23Z</published>
    <title>MT3S: Mobile Turkish Scene Text-to-Speech System for the Visually
  Impaired</title>
    <summary>  Reading text is one of the essential needs of the visually impaired people.
We developed a mobile system that can read Turkish scene and book text, using a
fast gradient-based multi-scale text detection algorithm for real-time
operation and Tesseract OCR engine for character recognition. We evaluated the
OCR accuracy and running time of our system on a new, publicly available mobile
Turkish scene text dataset we constructed and also compared with
state-of-the-art systems. Our system proved to be much faster, able to run on a
mobile device, with OCR accuracy comparable to the state-of-the-art.
</summary>
    <author>
      <name>Muhammet Bastan</name>
    </author>
    <author>
      <name>Hilal Kandemir</name>
    </author>
    <author>
      <name>Busra Canturk</name>
    </author>
    <link href="http://arxiv.org/abs/1608.05054v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.05054v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.07848v1</id>
    <updated>2016-09-26T05:09:32Z</updated>
    <published>2016-09-26T05:09:32Z</published>
    <title>Location-Based and Audience-Aware Storytelling</title>
    <summary>  While the daily user of digital, Internet-enabled devices has some explicit
control over what they read and see, the providers fulfilling searches,
offering options, and presenting material are using increasingly sophisticated
real-time algorithms that tune and target content for the particular user. They
redefine the historical relationships between tellers and users, providing a
responsiveness paralleled only by forms of live performance incorporating
elements of improvisation and audience interaction. The general accessibility
of algorithmically driven content delivery techniques suggests significant
untapped potential for new approaches to narrative beyond advertising and
commercially orientated customization.
</summary>
    <author>
      <name>Jeff Burke</name>
    </author>
    <author>
      <name>Jared J. Stein</name>
    </author>
    <link href="http://arxiv.org/abs/1609.07848v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.07848v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1611.04455v1</id>
    <updated>2016-11-14T16:48:12Z</updated>
    <published>2016-11-14T16:48:12Z</published>
    <title>Columbia MVSO Image Sentiment Dataset</title>
    <summary>  The Multilingual Visual Sentiment Ontology (MVSO) consists of 15,600 concepts
in 12 different languages that are strongly related to emotions and sentiments
expressed in images. These concepts are defined in the form of Adjective-Noun
Pair (ANP), which are crawled and discovered from online image forum Flickr. In
this work, we used Amazon Mechanical Turk as a crowd-sourcing platform to
collect human judgments on sentiments expressed in images that are uniformly
sampled over 3,911 English ANPs extracted from a tag-restricted subset of MVSO.
Our goal is to use the dataset as a benchmark for the evaluation of systems
that automatically predict sentiments in images or ANPs.
</summary>
    <author>
      <name>Vaidehi Dalmia</name>
    </author>
    <author>
      <name>Hongyi Liu</name>
    </author>
    <author>
      <name>Shih-Fu Chang</name>
    </author>
    <link href="http://arxiv.org/abs/1611.04455v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1611.04455v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.03461v1</id>
    <updated>2016-12-11T19:41:44Z</updated>
    <published>2016-12-11T19:41:44Z</published>
    <title>Low-complexity Pruned 8-point DCT Approximations for Image Encoding</title>
    <summary>  Two multiplierless pruned 8-point discrete cosine transform (DCT)
approximation are presented. Both transforms present lower arithmetic
complexity than state-of-the-art methods. The performance of such new methods
was assessed in the image compression context. A JPEG-like simulation was
performed, demonstrating the adequateness and competitiveness of the introduced
methods. Digital VLSI implementation in CMOS technology was also considered.
Both presented methods were realized in Berkeley Emulation Engine (BEE3).
</summary>
    <author>
      <name>V. A. Coutinho</name>
    </author>
    <author>
      <name>R. J. Cintra</name>
    </author>
    <author>
      <name>F. M. Bayer</name>
    </author>
    <author>
      <name>S. Kulasekera</name>
    </author>
    <author>
      <name>A. Madanayake</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/CONIELECOMP.2015.7086923</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/CONIELECOMP.2015.7086923" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 6 figures, 3 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1612.03461v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.03461v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.08350v1</id>
    <updated>2016-12-26T09:40:45Z</updated>
    <published>2016-12-26T09:40:45Z</published>
    <title>Streaming Virtual Reality Content</title>
    <summary>  The recent rise of interest in Virtual Reality (VR) came with the
availability of commodity commercial VR prod- ucts, such as the Head Mounted
Displays (HMD) created by Oculus and other vendors. To accelerate the user
adoption of VR headsets, content providers should focus on producing high
quality immersive content for these devices. Similarly, multimedia streaming
service providers should enable the means to stream 360 VR content on their
platforms. In this study, we try to cover different aspects related to VR
content representation, streaming, and quality assessment that will help
establishing the basic knowledge of how to build a VR streaming system.
</summary>
    <author>
      <name>Tarek El-Ganainy</name>
    </author>
    <author>
      <name>Mohamed Hefeeda</name>
    </author>
    <link href="http://arxiv.org/abs/1612.08350v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.08350v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1702.00817v1</id>
    <updated>2017-02-02T20:08:42Z</updated>
    <published>2017-02-02T20:08:42Z</published>
    <title>DCT-like Transform for Image Compression Requires 14 Additions Only</title>
    <summary>  A low-complexity 8-point orthogonal approximate DCT is introduced. The
proposed transform requires no multiplications or bit-shift operations. The
derived fast algorithm requires only 14 additions, less than any existing DCT
approximation. Moreover, in several image compression scenarios, the proposed
transform could outperform the well-known signed DCT, as well as
state-of-the-art algorithms.
</summary>
    <author>
      <name>F. M. Bayer</name>
    </author>
    <author>
      <name>R. J. Cintra</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1049/el.2012.1148</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1049/el.2012.1148" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 3 figures, 1 table</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Electronics Letters, Volume 48, Issue 15, pp. 919-921 (2012)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1702.00817v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1702.00817v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.00190v1</id>
    <updated>2017-03-01T09:22:47Z</updated>
    <published>2017-03-01T09:22:47Z</published>
    <title>Video transrating in AVC and HEVC transcoding</title>
    <summary>  HEVC (MPEG-H Part 2 and H.265) is a new coding technology which is expected
to be deployed on the market along with new video services in the near future.
HEVC is a successor of currently widely used AVC (MPEG-4 Part 10 and H.264). In
this paper, the quality coding gains obtained for the Cascaded Pixel Domain
Transcoder of AVC-coded material to HEVC standard are reported. Extensive
experiments showed that transcoding with bitrate reduction allows the
achievement of better rate-distortion performance than by compressing an
original video sequence with the use of AVC at the same (reduced) bitrate.
</summary>
    <author>
      <name>Krzysztof Wegner</name>
    </author>
    <author>
      <name>Tomasz Grajek</name>
    </author>
    <author>
      <name>Jakub Stankowski</name>
    </author>
    <author>
      <name>Marek Domanski</name>
    </author>
    <link href="http://arxiv.org/abs/1703.00190v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.00190v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.05778v1</id>
    <updated>2017-03-16T18:05:32Z</updated>
    <published>2017-03-16T18:05:32Z</published>
    <title>Medical Image Watermarking using 2D-DWT with Enhanced security and
  capacity</title>
    <summary>  Teleradiology enables medical images to be transferred over the computer
networks for many purposes including clinical interpretation, diagnosis,
archive, etc. In telemedicine, medical images can be manipulated while
transferring. In addition, medical information security requirements are
specified by the legislative rules, and concerned entities must adhere to them.
In this research, we propose a new scheme based on 2-dimensional Discrete
Wavelet Transform (2D DWT) to improve the robustness and authentication of
medical images. In addition, the current research improves security and
capacity of watermarking using encryption and compression in medical images.
The evaluation is performed on the personal dataset, which contains 194 CTI and
68 MRI cases.
</summary>
    <author>
      <name>Ali Sharifara</name>
    </author>
    <author>
      <name>Amir Ghaderi</name>
    </author>
    <link href="http://arxiv.org/abs/1703.05778v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.05778v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1704.02754v1</id>
    <updated>2017-04-10T08:25:36Z</updated>
    <published>2017-04-10T08:25:36Z</published>
    <title>A Synchronization Algorithm Based on Moving Average for Robust Audio
  Watermarking Scheme</title>
    <summary>  A synchronization code scheme based on moving average is proposed for robust
audio watermarking in the paper. Two proper positive integers are chosen to
compute the moving average sequence by sliding one sample every time. The
synchronization bits are embedded at crosses of the two moving average
sequences with the quantization index modulation. The experimental results show
that the proposed watermarking scheme maintains high audio quality and is
robust to common attacks such as additive white Gaussian noise, re-sampling,
low-pass filtering, random cropping, MP3 compression, jitter attack and time
scale modification. Simultaneously, the algorithm has high search efficiency
and low false alarm rate.
</summary>
    <author>
      <name>Zhang Jin-quan</name>
    </author>
    <author>
      <name>Han Bin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">23 pages, 7 tables,5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1704.02754v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1704.02754v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1704.02755v1</id>
    <updated>2017-04-10T08:26:19Z</updated>
    <published>2017-04-10T08:26:19Z</published>
    <title>Robust Audio Watermarking Algorithm Based on Moving Average and DCT</title>
    <summary>  Noise is often brought to host audio by common signal processing operation,
and it usually changes the high-frequency component of an audio signal. So
embedding watermark by adjusting low-frequency coefficient can improve the
robustness of a watermark scheme. Moving Average sequence is a low-frequency
feature of an audio signal. This work proposed a method which embedding
watermark into the maximal coefficient in discrete cosine transform domain of a
moving average sequence. Subjective and objective tests reveal that the
proposed watermarking scheme maintains highly audio quality, and
simultaneously, the algorithm is highly robust to common digital signal
processing operations, including additive noise, sampling rate change, bit
resolution transformation, MP3 compression, and random cropping, especially
low-pass filtering.
</summary>
    <author>
      <name>Jinquan Zhang</name>
    </author>
    <author>
      <name>Bin Han</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1704.02755v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1704.02755v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.08616v1</id>
    <updated>2017-05-24T05:47:23Z</updated>
    <published>2017-05-24T05:47:23Z</published>
    <title>A New Parallel Message-distribution Technique for Cost-based
  Steganography</title>
    <summary>  This paper presents two novel approaches to increase performance bounds of
image steganography under the criteria of minimizing distortion. First, in
order to efficiently use the images' capacities, we propose using parallel
images in the embedding stage. The result is then used to prove sub-optimality
of the message distribution technique used by all cost based algorithms
including HUGO, S-UNIWARD, and HILL. Second, a new distribution approach is
presented to further improve the security of these algorithms. Experiments show
that this distribution method avoids embedding in smooth regions and thus
achieves a better performance, measured by state-of-the-art steganalysis, when
compared with the current used distribution.
</summary>
    <author>
      <name>Mehdi Sharifzadeh</name>
    </author>
    <author>
      <name>Chirag Agarwal</name>
    </author>
    <author>
      <name>Mahdi Salarian</name>
    </author>
    <author>
      <name>Dan Schonfeld</name>
    </author>
    <link href="http://arxiv.org/abs/1705.08616v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.08616v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.01340v1</id>
    <updated>2017-07-05T12:02:42Z</updated>
    <published>2017-07-05T12:02:42Z</published>
    <title>Web Video in Numbers - An Analysis of Web-Video Metadata</title>
    <summary>  Web video is often used as a source of data in various fields of study. While
specialized subsets of web video, mainly earmarked for dedicated purposes, are
often analyzed in detail, there is little information available about the
properties of web video as a whole. In this paper we present insights gained
from the analysis of the metadata associated with more than 120 million videos
harvested from two popular web video platforms, vimeo and YouTube, in 2016 and
compare their properties with the ones found in commonly used video
collections. This comparison has revealed that existing collections do not (or
no longer) properly reflect the properties of web video "in the wild".
</summary>
    <author>
      <name>Luca Rossetto</name>
    </author>
    <author>
      <name>Heiko Schuldt</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Dataset available from http://download-dbis.dmi.unibas.ch/WWIN/</arxiv:comment>
    <link href="http://arxiv.org/abs/1707.01340v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.01340v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.01513v1</id>
    <updated>2017-07-05T18:02:29Z</updated>
    <published>2017-07-05T18:02:29Z</published>
    <title>On the steganographic image based approach to PDF files protection</title>
    <summary>  Digital images can be copied without authorization and have to be protected.
Two schemes for watermarking images in PDF document were considered. Both
schemes include a converter to extract images from PDF pages and return the
protected images back. Frequency and spatial domain embedding were used for
hiding a message presented by a binary pattern. We considered visible and
invisible watermarking and found that spatial domain LSB technique can be more
preferable than frequency embedding using DWT.
</summary>
    <author>
      <name>V. N. Gorbachev</name>
    </author>
    <author>
      <name>L. A. Denisov</name>
    </author>
    <author>
      <name>E. M. Kaynarova</name>
    </author>
    <author>
      <name>I. K. Metelev</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 8 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1707.01513v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.01513v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.02709v1</id>
    <updated>2017-07-10T06:30:59Z</updated>
    <published>2017-07-10T06:30:59Z</published>
    <title>An Augmented Autoregressive Approach to HTTP Video Stream Quality
  Prediction</title>
    <summary>  HTTP-based video streaming technologies allow for flexible rate selection
strategies that account for time-varying network conditions. Such rate changes
may adversely affect the user's Quality of Experience; hence online prediction
of the time varying subjective quality can lead to perceptually optimised
bitrate allocation policies. Recent studies have proposed to use dynamic
network approaches for continuous-time prediction; yet they do not consider
multiple video quality models as inputs nor consider forecasting ensembles.
Here we address the problem of predicting continuous-time subjective quality
using multiple inputs fed to a non-linear autoregressive network. By
considering multiple network configurations and by applying simple averaging
forecasting techniques, we are able to considerably improve prediction
performance and decrease forecasting errors.
</summary>
    <author>
      <name>Christos G. Bampis</name>
    </author>
    <author>
      <name>Alan C. Bovik</name>
    </author>
    <link href="http://arxiv.org/abs/1707.02709v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.02709v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.09538v1</id>
    <updated>2017-07-29T16:40:50Z</updated>
    <published>2017-07-29T16:40:50Z</published>
    <title>Benchmarking Multimodal Sentiment Analysis</title>
    <summary>  We propose a framework for multimodal sentiment analysis and emotion
recognition using convolutional neural network-based feature extraction from
text and visual modalities. We obtain a performance improvement of 10% over the
state of the art by combining visual, text and audio features. We also discuss
some major issues frequently ignored in multimodal sentiment analysis research:
the role of speaker-independent models, importance of the modalities and
generalizability. The paper thus serve as a new benchmark for further research
in multimodal sentiment analysis and also demonstrates the different facets of
analysis to be considered while performing such tasks.
</summary>
    <author>
      <name>Erik Cambria</name>
    </author>
    <author>
      <name>Devamanyu Hazarika</name>
    </author>
    <author>
      <name>Soujanya Poria</name>
    </author>
    <author>
      <name>Amir Hussain</name>
    </author>
    <author>
      <name>R. B. V. Subramaanyam</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted in CICLing 2017</arxiv:comment>
    <link href="http://arxiv.org/abs/1707.09538v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.09538v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.02991v1</id>
    <updated>2017-08-09T19:59:49Z</updated>
    <published>2017-08-09T19:59:49Z</published>
    <title>Robust Video Watermarking against H.264 and H.265 Compression Attacks</title>
    <summary>  This paper proposes a robust watermarking method for uncompressed video data
against H.264/AVC and H.265/HEVC compression standards. We embed the watermark
data in the mid-range transform coefficients of a block that is less similar to
its corresponding block in the previous and next frames. This idea makes the
watermark robust against the compression standards that use the inter
prediction technique. The last two video compression standards also use inter
prediction for motion compensation like previous video compression standards.
Therefore, the proposed method is also well suited with these standards.
Simulation results show the adequate robustness and transparency of our
watermarking scheme.
</summary>
    <author>
      <name>Nematollah Zarmehi</name>
    </author>
    <author>
      <name>Mohammad Javad Barikbin</name>
    </author>
    <link href="http://arxiv.org/abs/1708.02991v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.02991v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.05970v1</id>
    <updated>2017-08-20T14:22:48Z</updated>
    <published>2017-08-20T14:22:48Z</published>
    <title>An improved watermarking scheme for Internet applications</title>
    <summary>  In this paper, a data hiding scheme ready for Internet applications is
proposed. An existing scheme based on chaotic iterations is improved, to
respond to some major Internet security concerns, such as digital rights
management, communication over hidden channels, and social search engines. By
using Reed Solomon error correcting codes and wavelets domain, we show that
this data hiding scheme can be improved to solve issues and requirements raised
by these Internet fields.
</summary>
    <author>
      <name>Christophe Guyeux</name>
    </author>
    <author>
      <name>Jacques M. Bahi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of INTERNET'2010, 2nd Int. Conf. on Evolving Internet.
  Valencia (Spain), September 20-25, 2010. pp. 119-124</arxiv:comment>
    <link href="http://arxiv.org/abs/1708.05970v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.05970v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.08763v1</id>
    <updated>2017-09-26T00:37:58Z</updated>
    <published>2017-09-26T00:37:58Z</published>
    <title>Encoding Bitrate Optimization Using Playback Statistics for HTTP-based
  Adaptive Video Streaming</title>
    <summary>  HTTP video streaming is in wide use to deliver video over the Internet. With
HTTP adaptive steaming, a video playback dynamically selects a video stream
from a pre-encoded representation based on available bandwidth and viewport
(screen) size. The viewer's video quality is therefore influenced by the
encoded bitrates. We minimize the average delivered bitrate subject to a
quality lower bound on a per-chunk basis by modeling the probability that a
player selects a particular encoding. Through simulation and real-world
experiments, the proposed method saves 9.6% of bandwidth while average
delivered video quality comparing with state of the art while keeping average
delivered video quality.
</summary>
    <author>
      <name>Chao Chen</name>
    </author>
    <author>
      <name>Yao-Chung Lin</name>
    </author>
    <author>
      <name>Anil Kokaram</name>
    </author>
    <author>
      <name>Steve Benting</name>
    </author>
    <link href="http://arxiv.org/abs/1709.08763v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.08763v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1004.0256v1</id>
    <updated>2010-04-01T23:42:11Z</updated>
    <published>2010-04-01T23:42:11Z</published>
    <title>From Playability to a Hierarchical Game Usability Model</title>
    <summary>  This paper presents a brief review of current game usability models. This
leads to the conception of a high-level game development-centered usability
model that integrates current usability approaches in game industry and game
research.
</summary>
    <author>
      <name>Lennart E. Nacke</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/1639601.1639609</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/1639601.1639609" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1004.0256v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1004.0256v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="97Rxx" scheme="http://arxiv.org/schemas/atom"/>
    <category term="K.8.0; H.5.1; J.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.02435v2</id>
    <updated>2016-05-17T13:23:08Z</updated>
    <published>2015-05-10T21:04:48Z</published>
    <title>Cloud for Gaming</title>
    <summary>  Cloud for Gaming refers to the use of cloud computing technologies to build
large-scale gaming infrastructures, with the goal of improving scalability and
responsiveness, improve the user's experience and enable new business models.
</summary>
    <author>
      <name>Gabriele D'Angelo</name>
    </author>
    <author>
      <name>Stefano Ferretti</name>
    </author>
    <author>
      <name>Moreno Marzolla</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-319-08234-9_39-1</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-319-08234-9_39-1" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Encyclopedia of Computer Graphics and Games. Newton Lee (Editor).
  Springer International Publishing, 2015, ISBN 978-3-319-08234-9</arxiv:comment>
    <link href="http://arxiv.org/abs/1505.02435v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.02435v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="C.2.4; I.6.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.07990v1</id>
    <updated>2016-03-25T19:35:59Z</updated>
    <published>2016-03-25T19:35:59Z</published>
    <title>Modeling and Resource Allocation for HD Videos over WiMAX Broadband
  Wireless Networks</title>
    <summary>  Mobile video is considered a major upcoming application and revenue generator
for broadband wireless networks like WiMAX and LTE. Therefore, it is important
to design a proper resource allocation scheme for mobile video, since video
traffic is both throughput consuming and delay sensitive.
</summary>
    <author>
      <name>Abdel-Karim Al-Tamimi</name>
    </author>
    <author>
      <name>Raj Jain</name>
    </author>
    <author>
      <name>Chakchai So-In</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE Communication Society Multimedia Communications Technical
  Committee, E-letter Vol. 5, No. 3, May 2010</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1603.07990v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.07990v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.01058v1</id>
    <updated>2016-12-04T03:36:51Z</updated>
    <published>2016-12-04T03:36:51Z</published>
    <title>Algorithmic Songwriting with ALYSIA</title>
    <summary>  This paper introduces ALYSIA: Automated LYrical SongwrIting Application.
ALYSIA is based on a machine learning model using Random Forests, and we
discuss its success at pitch and rhythm prediction. Next, we show how ALYSIA
was used to create original pop songs that were subsequently recorded and
produced. Finally, we discuss our vision for the future of Automated
Songwriting for both co-creative and autonomous systems.
</summary>
    <author>
      <name>Margareta Ackerman</name>
    </author>
    <author>
      <name>David Loker</name>
    </author>
    <link href="http://arxiv.org/abs/1612.01058v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.01058v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.04574v1</id>
    <updated>2017-03-14T14:07:19Z</updated>
    <published>2017-03-14T14:07:19Z</published>
    <title>Causes of discomfort in stereoscopic content: a review</title>
    <summary>  This paper reviews the causes of discomfort in viewing stereoscopic content.
These include objective factors, such as misaligned images, as well as
subjective factors, such as excessive disparity. Different approaches to the
measurement of visual discomfort are also reviewed, in relation to the
underlying physiological and psychophysical processes. The importance of
understanding these issues, in the context of new display technologies, is
emphasized.
</summary>
    <author>
      <name>Kasim Terzic</name>
    </author>
    <author>
      <name>Miles Hansard</name>
    </author>
    <link href="http://arxiv.org/abs/1703.04574v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.04574v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.08675v1</id>
    <updated>2017-06-27T05:28:06Z</updated>
    <published>2017-06-27T05:28:06Z</published>
    <title>Proceedings of the First International Workshop on Deep Learning and
  Music</title>
    <summary>  Proceedings of the First International Workshop on Deep Learning and Music,
joint with IJCNN, Anchorage, US, May 17-18, 2017
</summary>
    <author>
      <name>Dorien Herremans</name>
    </author>
    <author>
      <name>Ching-Hua Chuan</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.13140/RG.2.2.22227.99364/1</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.13140/RG.2.2.22227.99364/1" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the First International Workshop on Deep Learning
  and Music, joint with IJCNN, Anchorage, US, May 17-18, 2017</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1706.08675v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.08675v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68Txx" scheme="http://arxiv.org/schemas/atom"/>
    <category term="C.1.3; H.5.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0002004v1</id>
    <updated>2000-02-04T18:42:13Z</updated>
    <published>2000-02-04T18:42:13Z</published>
    <title>Stochastic Model Checking for Multimedia</title>
    <summary>  Modern distributed systems include a class of applications in which
non-functional requirements are important. In particular, these applications
include multimedia facilities where real time constraints are crucial to their
correct functioning. In order to specify such systems it is necessary to
describe that events occur at times given by probability distributions and
stochastic automata have emerged as a useful technique by which such systems
can be specified and verified.
  However, stochastic descriptions are very general, in particular they allow
the use of general probability distribution functions, and therefore their
verification can be complex. In the last few years, model checking has emerged
as a useful verification tool for large systems.
  In this paper we describe two model checking algorithms for stochastic
automata. These algorithms consider how properties written in a simple
probabilistic real-time logic can be checked against a given stochastic
automaton.
</summary>
    <author>
      <name>Jeremy Bryans</name>
    </author>
    <author>
      <name>Howard Bowman</name>
    </author>
    <author>
      <name>John Derrick</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">35 pages; 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0002004v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0002004v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.3.1; F.4.1; G.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0109041v2</id>
    <updated>2001-09-27T23:06:04Z</updated>
    <published>2001-09-20T23:48:11Z</published>
    <title>Open Access beyond cable: The case of Interactive TV</title>
    <summary>  In this paper we analyze the development of interactive TV in the U.S. and
Western Europe. We argue that despite the nascent character of the market there
are important regulatory issues at stake, as exemplified by the AOL/TW merger
and the British Interactive Broadcasting case. Absent rules that provide for
non-discriminatory access to network components (including terminal equipment
specifications), dominant platform operators are likely to leverage ownership
of delivery infrastructure into market power over interactive TV services.
While integration between platform operator, service provider and terminal
vendor may facilitate the introduction of services in the short-term, the
lasting result will be a collection of fragmented "walled gardens" offering
limited content and applications. Would interactive TV develop under such
model, the exciting opportunities for broad-based innovation and extended
access to multiple information, entertainment and educational services opened
by the new generation of broadcasting technologies will be foregone
</summary>
    <author>
      <name>Hernan Galperin</name>
    </author>
    <author>
      <name>Francois Bar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">typos corrected, content changed section 3(a), new abstract</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0109041v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0109041v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="K.4.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0501014v3</id>
    <updated>2007-03-27T17:12:49Z</updated>
    <published>2005-01-08T15:55:30Z</published>
    <title>On the Design of Perceptual MPEG-Video Encryption Algorithms</title>
    <summary>  In this paper, some existing perceptual encryption algorithms of MPEG videos
are reviewed and some problems, especially security defects of two recently
proposed MPEG-video perceptual encryption schemes, are pointed out. Then, a
simpler and more effective design is suggested, which selectively encrypts
fixed-length codewords (FLC) in MPEG-video bitstreams under the control of
three perceptibility factors. The proposed design is actually an encryption
configuration that can work with any stream cipher or block cipher. Compared
with the previously-proposed schemes, the new design provides more useful
features, such as strict size-preservation, on-the-fly encryption and multiple
perceptibility, which make it possible to support more applications with
different requirements. In addition, four different measures are suggested to
provide better security against known/chosen-plaintext attacks.
</summary>
    <author>
      <name>Shujun Li</name>
    </author>
    <author>
      <name>Guanrong Chen</name>
    </author>
    <author>
      <name>Albert Cheung</name>
    </author>
    <author>
      <name>Bharat Bhargava</name>
    </author>
    <author>
      <name>Kwok-Tung Lo</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TCSVT.2006.888840</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TCSVT.2006.888840" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 5 figures, IEEEtran.cls</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE Transactions on Circuits and Systems for Video Technology,
  vol. 17, no. 2, pp. 214-223, 2007</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0501014v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0501014v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0508066v1</id>
    <updated>2005-08-13T14:46:16Z</updated>
    <published>2005-08-13T14:46:16Z</published>
    <title>Can Small Museums Develop Compelling, Educational and Accessible Web
  Resources? The Case of Accademia Carrara</title>
    <summary>  Due to the lack of budget, competence, personnel and time, small museums are
often unable to develop compelling, educational and accessible web resources
for their permanent collections or temporary exhibitions. In an attempt to
prove that investing in these types of resources can be very fruitful even for
small institutions, we will illustrate the case of Accademia Carrara, a museum
in Bergamo, northern Italy, which, for a current temporary exhibition on
Cezanne and Renoir's masterpieces from the Paul Guillaume collection, developed
a series of multimedia applications, including an accessible website, rich in
content and educational material [www.cezannerenoir.it].
</summary>
    <author>
      <name>Silvia Filippini-Fantoni</name>
    </author>
    <author>
      <name>Jonathan P. Bowen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 6 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">In James Hemsley, Vito Cappellini and Gerd Stanke (eds.), EVA 2005
  London Conference Proceedings, University College London, UK, 25-29 July
  2005, pages 18.1-18.14. ISBN: 0-9543146-6-2</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0508066v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0508066v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.5; H.3.7; H.4.3; H.5.1; H.5.2; H.5.3; H.5.4; K.3.1; K.4.0" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0509035v2</id>
    <updated>2007-10-24T15:45:10Z</updated>
    <published>2005-09-13T10:44:31Z</published>
    <title>Cryptanalysis of an MPEG-Video Encryption Scheme Based on Secret Huffman
  Tables</title>
    <summary>  This paper studies the security of a recently-proposed MPEG-video encryption
scheme based on secret Huffman tables. Our cryptanalysis shows that: 1) the key
space of the encryption scheme is not sufficiently large against
divide-and-conquer (DAC) attack and known-plaintext attack; 2) it is possible
to decrypt a cipher-video with a partially-known key, thus dramatically
reducing the complexity of the DAC brute-force attack in some cases; 3) its
security against the chosen-plaintext attack is very weak. Some experimental
results are included to support the cryptanalytic results with a brief discuss
on how to improve this MPEG-video encryption scheme.
</summary>
    <author>
      <name>Shujun Li</name>
    </author>
    <author>
      <name>Guanrong Chen</name>
    </author>
    <author>
      <name>Albert Cheung</name>
    </author>
    <author>
      <name>Kwok-Tung Lo</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-540-92957-4_78</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-540-92957-4_78" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 4 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Advances in Image and Video Technology - Third Pacific Rim
  Symposium, PSIVT 2009, Tokyo, Japan, January 13-16, 2009. Proceedings,
  Lecture Notes in Computer Science, vol. 5414, pp. 898-909, 2009</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0509035v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0509035v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0605002v3</id>
    <updated>2006-06-21T03:22:38Z</updated>
    <published>2006-04-30T13:35:54Z</published>
    <title>A Hybrid Quantum Encoding Algorithm of Vector Quantization for Image
  Compression</title>
    <summary>  Many classical encoding algorithms of Vector Quantization (VQ) of image
compression that can obtain global optimal solution have computational
complexity O(N). A pure quantum VQ encoding algorithm with probability of
success near 100% has been proposed, that performs operations 45sqrt(N) times
approximately. In this paper, a hybrid quantum VQ encoding algorithm between
classical method and quantum algorithm is presented. The number of its
operations is less than sqrt(N) for most images, and it is more efficient than
the pure quantum algorithm.
  Key Words: Vector Quantization, Grover's Algorithm, Image Compression,
Quantum Algorithm
</summary>
    <author>
      <name>Chao-Yang Pang</name>
    </author>
    <author>
      <name>Zheng-Wei Zhou</name>
    </author>
    <author>
      <name>Guang-Can Guo</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1088/1009-1963/15/12/044</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1088/1009-1963/15/12/044" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Modify on June 21. 10pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0605002v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0605002v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.1; F.2.1; F.2.2; F.1.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0606034v2</id>
    <updated>2007-01-12T13:11:09Z</updated>
    <published>2006-06-08T13:28:07Z</published>
    <title>A constructive and unifying framework for zero-bit watermarking</title>
    <summary>  In the watermark detection scenario, also known as zero-bit watermarking, a
watermark, carrying no hidden message, is inserted in content. The watermark
detector checks for the presence of this particular weak signal in content. The
article looks at this problem from a classical detection theory point of view,
but with side information enabled at the embedding side. This means that the
watermark signal is a function of the host content. Our study is twofold. The
first step is to design the best embedding function for a given detection
function, and the best detection function for a given embedding function. This
yields two conditions, which are mixed into one `fundamental' partial
differential equation. It appears that many famous watermarking schemes are
indeed solution to this `fundamental' equation. This study thus gives birth to
a constructive framework unifying solutions, so far perceived as very
different.
</summary>
    <author>
      <name>Teddy Furon</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IRISA</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">submitted to IEEE Trans. on Information Forensics and Security</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0606034v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0606034v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0609131v1</id>
    <updated>2006-09-24T09:55:57Z</updated>
    <published>2006-09-24T09:55:57Z</published>
    <title>A Fast Block Matching Algorithm for Video Motion Estimation Based on
  Particle Swarm Optimization and Motion Prejudgment</title>
    <summary>  In this paper, we propose a fast 2-D block-based motion estimation algorithm
called Particle Swarm Optimization - Zero-motion Prejudgment(PSO-ZMP) which
consists of three sequential routines: 1)Zero-motion prejudgment. The routine
aims at finding static macroblocks(MB) which do not need to perform remaining
search thus reduces the computational cost; 2)Predictive image coding and 3)PSO
matching routine. Simulation results obtained show that the proposed PSO-ZMP
algorithm achieves over 10 times of computation less than Diamond Search(DS)
and 5 times less than the recent proposed Adaptive Rood Pattern
Searching(ARPS). Meanwhile the PSNR performances using PSO-ZMP are very close
to that using DS and ARPS in some less-motioned sequences. While in some
sequences containing dense and complex motion contents, the PSNR performances
of PSO-ZMP are several dB lower than that using DS and ARPS but in an
acceptable degree.
</summary>
    <author>
      <name>Ran Ren</name>
    </author>
    <author>
      <name>Madan mohan Manokar</name>
    </author>
    <author>
      <name>Yaogang Shi</name>
    </author>
    <author>
      <name>Baoyu Zheng</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 12 figures, submitted to ACM Symposium of Applied
  Computing(SAC)</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0609131v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0609131v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0705.1925v1</id>
    <updated>2007-05-14T12:23:43Z</updated>
    <published>2007-05-14T12:23:43Z</published>
    <title>Double Sided Watermark Embedding and Detection with Perceptual Analysis</title>
    <summary>  In our previous work, we introduced a double-sided technique that utilizes
but not reject the host interference. Due to its nice property of utilizing but
not rejecting the host interference, it has a big advantage over the host
interference schemes in that the perceptual analysis can be easily implemented
for our scheme to achieve the locally bounded maximum embedding strength. Thus,
in this work, we detail how to implement the perceptual analysis in our
double-sided schemes since the perceptual analysis is very important for
improving the fidelity of watermarked contents. Through the extensive
performance comparisons, we can further validate the performance advantage of
our double-sided schemes.
</summary>
    <author>
      <name>Jidong Zhong</name>
    </author>
    <author>
      <name>Shangteng Huang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper is a supplement to a paper to be published in IEEE
  Transactions on Information Forensics and Security</arxiv:comment>
    <link href="http://arxiv.org/abs/0705.1925v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0705.1925v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0706.1141v1</id>
    <updated>2007-06-08T09:31:46Z</updated>
    <published>2007-06-08T09:31:46Z</published>
    <title>Multimedia Content Distribution in Hybrid Wireless Networks using
  Weighted Clustering</title>
    <summary>  Fixed infrastructured networks naturally support centralized approaches for
group management and information provisioning. Contrary to infrastructured
networks, in multi-hop ad-hoc networks each node acts as a router as well as
sender and receiver. Some applications, however, requires hierarchical
arrangements that-for practical reasons-has to be done locally and
self-organized. An additional challenge is to deal with mobility that causes
permanent network partitioning and re-organizations. Technically, these
problems can be tackled by providing additional uplinks to a backbone network,
which can be used to access resources in the Internet as well as to inter-link
multiple ad-hoc network partitions, creating a hybrid wireless network. In this
paper, we present a prototypically implemented hybrid wireless network system
optimized for multimedia content distribution. To efficiently manage the ad-hoc
communicating devices a weighted clustering algorithm is introduced. The
proposed localized algorithm deals with mobility, but does not require
geographical information or distances.
</summary>
    <author>
      <name>Adrian Andronache</name>
    </author>
    <author>
      <name>Matthias R. Brust</name>
    </author>
    <author>
      <name>Steffen Rothkugel</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2nd ACM Workshop on Wireless Multimedia Networking and Performance
  Modeling 2006 (ISBN 1-59593-485)</arxiv:comment>
    <link href="http://arxiv.org/abs/0706.1141v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0706.1141v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0706.3076v1</id>
    <updated>2007-06-21T02:44:44Z</updated>
    <published>2007-06-21T02:44:44Z</published>
    <title>On the Performance of Joint Fingerprint Embedding and Decryption Scheme</title>
    <summary>  Till now, few work has been done to analyze the performances of joint
fingerprint embedding and decryption schemes. In this paper, the security of
the joint fingerprint embedding and decryption scheme proposed by Kundur et al.
is analyzed and improved. The analyses include the security against
unauthorized customer, the security against authorized customer, the
relationship between security and robustness, the relationship between
secu-rity and imperceptibility and the perceptual security. Based these
analyses, some means are proposed to strengthen the system, such as multi-key
encryp-tion and DC coefficient encryption. The method can be used to analyze
other JFD schemes. It is expected to provide valuable information to design JFD
schemes.
</summary>
    <author>
      <name>Shiguo Lian</name>
    </author>
    <author>
      <name>Zhongxuan Liu</name>
    </author>
    <author>
      <name>Zhen Ren</name>
    </author>
    <author>
      <name>Haila Wang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages,9 figures. To be submitted</arxiv:comment>
    <link href="http://arxiv.org/abs/0706.3076v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0706.3076v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="C.2.0; D.2.11; D.4.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0707.0802v1</id>
    <updated>2007-07-05T15:11:24Z</updated>
    <published>2007-07-05T15:11:24Z</published>
    <title>Very fast watermarking by reversible contrast mapping</title>
    <summary>  Reversible contrast mapping (RCM) is a simple integer transform that applies
to pairs of pixels. For some pairs of pixels, RCM is invertible, even if the
least significant bits (LSBs) of the transformed pixels are lost. The data
space occupied by the LSBs is suitable for data hiding. The embedded
information bit-rates of the proposed spatial domain reversible watermarking
scheme are close to the highest bit-rates reported so far. The scheme does not
need additional data compression, and, in terms of mathematical complexity, it
appears to be the lowest complexity one proposed up to now. A very fast lookup
table implementation is proposed. Robustness against cropping can be ensured as
well.
</summary>
    <author>
      <name>Dinu Coltuc</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">GIPSA-lab</arxiv:affiliation>
    </author>
    <author>
      <name>Jean-Marc Chassery</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">GIPSA-lab</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/LSP.2006.884895</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/LSP.2006.884895" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE Signal Processing Letters 14, 4 (04/2007) pp 255-258</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0707.0802v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0707.0802v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0707.4524v1</id>
    <updated>2007-07-31T02:27:10Z</updated>
    <published>2007-07-31T02:27:10Z</published>
    <title>Image Authentication Based on Neural Networks</title>
    <summary>  Neural network has been attracting more and more researchers since the past
decades. The properties, such as parameter sensitivity, random similarity,
learning ability, etc., make it suitable for information protection, such as
data encryption, data authentication, intrusion detection, etc. In this paper,
by investigating neural networks' properties, the low-cost authentication
method based on neural networks is proposed and used to authenticate images or
videos. The authentication method can detect whether the images or videos are
modified maliciously. Firstly, this chapter introduces neural networks'
properties, such as parameter sensitivity, random similarity, diffusion
property, confusion property, one-way property, etc. Secondly, the chapter
gives an introduction to neural network based protection methods. Thirdly, an
image or video authentication scheme based on neural networks is presented, and
its performances, including security, robustness and efficiency, are analyzed.
Finally, conclusions are drawn, and some open issues in this field are
presented.
</summary>
    <author>
      <name>Shiguo Lian</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages,10 figures, submitted</arxiv:comment>
    <link href="http://arxiv.org/abs/0707.4524v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0707.4524v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="C.1.3; E.3.x; F.1.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0710.4180v1</id>
    <updated>2007-10-23T03:06:53Z</updated>
    <published>2007-10-23T03:06:53Z</published>
    <title>A quick search method for audio signals based on a piecewise linear
  representation of feature trajectories</title>
    <summary>  This paper presents a new method for a quick similarity-based search through
long unlabeled audio streams to detect and locate audio clips provided by
users. The method involves feature-dimension reduction based on a piecewise
linear representation of a sequential feature trajectory extracted from a long
audio stream. Two techniques enable us to obtain a piecewise linear
representation: the dynamic segmentation of feature trajectories and the
segment-based Karhunen-L\'{o}eve (KL) transform. The proposed search method
guarantees the same search results as the search method without the proposed
feature-dimension reduction method in principle. Experiment results indicate
significant improvements in search speed. For example the proposed method
reduced the total search time to approximately 1/12 that of previous methods
and detected queries in approximately 0.3 seconds from a 200-hour audio
database.
</summary>
    <author>
      <name>Akisato Kimura</name>
    </author>
    <author>
      <name>Kunio Kashino</name>
    </author>
    <author>
      <name>Takayuki Kurozumi</name>
    </author>
    <author>
      <name>Hiroshi Murase</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TASL.2007.912362</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TASL.2007.912362" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages, to appear in IEEE Transactions on Audio, Speech and
  Language Processing</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE Transactions on Audio, Speech and Language Processing,
  Vol.16, No.2, pp.396-407, February 2008.</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0710.4180v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0710.4180v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0710.4819v1</id>
    <updated>2007-10-25T12:03:15Z</updated>
    <published>2007-10-25T12:03:15Z</published>
    <title>A High Quality/Low Computational Cost Technique for Block Matching
  Motion Estimation</title>
    <summary>  Motion estimation is the most critical process in video coding systems. First
of all, it has a definitive impact on the rate-distortion performance given by
the video encoder. Secondly, it is the most computationally intensive process
within the encoding loop. For these reasons, the design of high-performance
low-cost motion estimators is a crucial task in the video compression field. An
adaptive cost block matching (ACBM) motion estimation technique is presented in
this paper, featuring an excellent tradeoff between the quality of the
reconstructed video sequences and the computational effort. Simulation results
demonstrate that the ACBM algorithm achieves a slight better rate-distortion
performance than the one given by the well-known full search algorithm block
matching algorithm with reductions of up to 95% in the computational load.
</summary>
    <author>
      <name>S. Lopez</name>
    </author>
    <author>
      <name>G. M. Callico</name>
    </author>
    <author>
      <name>J. F. Lopez</name>
    </author>
    <author>
      <name>R. Sarmiento</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted on behalf of EDAA (http://www.edaa.com/)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Dans Design, Automation and Test in Europe | Designers'Forum -
  DATE'05, Munich : Allemagne (2005)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0710.4819v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0710.4819v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0710.4823v1</id>
    <updated>2007-10-25T12:04:42Z</updated>
    <published>2007-10-25T12:04:42Z</published>
    <title>A Coprocessor for Accelerating Visual Information Processing</title>
    <summary>  Visual information processing will play an increasingly important role in
future electronics systems. In many applications, e.g. video surveillance
cameras, data throughput of microprocessors is not sufficient and power
consumption is too high. Instruction profiling on a typical test algorithm has
shown that pixel address calculations are the dominant operations to be
optimized. Therefore AddressLib, a structured scheme for pixel addressing was
developed, that can be accelerated by AddressEngine, a coprocessor for visual
information processing. In this paper, the architectural design of
AddressEngine is described, which in the first step supports a subset of the
AddressLib. Dataflow and memory organization are optimized during architectural
design. AddressEngine was implemented in a FPGA and was tested with MPEG-7
Global Motion Estimation algorithm. Results on processing speed and circuit
complexity are given and compared to a pure software implementation. The next
step will be the support for the full AddressLib, including segment addressing.
An outlook on further investigations on dynamic reconfiguration capabilities is
given.
</summary>
    <author>
      <name>W. Stechele</name>
    </author>
    <author>
      <name>L. Alvado Carcel</name>
    </author>
    <author>
      <name>S. Herrmann</name>
    </author>
    <author>
      <name>J. Lidon Simon</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted on behalf of EDAA (http://www.edaa.com/)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Dans Design, Automation and Test in Europe | Designers'Forum -
  DATE'05, Munich : Allemagne (2005)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0710.4823v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0710.4823v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0710.4846v1</id>
    <updated>2007-10-25T12:24:16Z</updated>
    <published>2007-10-25T12:24:16Z</published>
    <title>An Integrated Design and Verification Methodology for Reconfigurable
  Multimedia Systems</title>
    <summary>  Recently a lot of multimedia applications are emerging on portable
appliances. They require both the flexibility of upgradeable devices
(traditionally software based) and a powerful computing engine (typically
hardware). In this context, programmable HW and dynamic reconfiguration allow
novel approaches to the migration of algorithms from SW to HW. Thus, in the
frame of the Symbad project, we propose an industrial design flow for
reconfigurable SoC's. The goal of Symbad consists of developing a system level
design platform for hardware and software SoC systems including formal and
semi-formal verification techniques.
</summary>
    <author>
      <name>M. Borgatti</name>
    </author>
    <author>
      <name>A. Capello</name>
    </author>
    <author>
      <name>U. Rossi</name>
    </author>
    <author>
      <name>J. -L. Lambert</name>
    </author>
    <author>
      <name>I. Moussa</name>
    </author>
    <author>
      <name>F. Fummi</name>
    </author>
    <author>
      <name>G. Pravadelli</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted on behalf of EDAA (http://www.edaa.com/)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Dans Design, Automation and Test in Europe | Designers'Forum -
  DATE'05, Munich : Allemagne (2005)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0710.4846v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0710.4846v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0711.3500v1</id>
    <updated>2007-11-22T03:53:29Z</updated>
    <published>2007-11-22T03:53:29Z</published>
    <title>Secure Fractal Image Coding</title>
    <summary>  In recent work, various fractal image coding methods are reported, which
adopt the self-similarity of images to compress the size of images. However,
till now, no solutions for the security of fractal encoded images have been
provided. In this paper, a secure fractal image coding scheme is proposed and
evaluated, which encrypts some of the fractal parameters during fractal
encoding, and thus, produces the encrypted and encoded image. The encrypted
image can only be recovered by the correct key. To keep secure and efficient,
only the suitable parameters are selected and encrypted through in-vestigating
the properties of various fractal parameters, including parameter space,
parameter distribu-tion and parameter sensitivity. The encryption process does
not change the file format, keeps secure in perception, and costs little time
or computational resources. These properties make it suitable for secure image
encoding or transmission.
</summary>
    <author>
      <name>Shiguo Lian</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages, 8 figures. To be submitted</arxiv:comment>
    <link href="http://arxiv.org/abs/0711.3500v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0711.3500v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="C.2.0; D.2.11; D.4.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0803.0405v1</id>
    <updated>2008-03-04T10:27:59Z</updated>
    <published>2008-03-04T10:27:59Z</published>
    <title>Multi-dimensional sparse time series: feature extraction</title>
    <summary>  We show an analysis of multi-dimensional time series via entropy and
statistical linguistic techniques. We define three markers encoding the
behavior of the series, after it has been translated into a multi-dimensional
symbolic sequence. The leading component and the trend of the series with
respect to a mobile window analysis result from the entropy analysis and label
the dynamical evolution of the series. The diversification formalizes the
differentiation in the use of recurrent patterns, from a Zipf law point of
view. These markers are the starting point of further analysis such as
classification or clustering of large database of multi-dimensional time
series, prediction of future behavior and attribution of new data. We also
present an application to economic data. We deal with measurements of money
investments of some business companies in advertising market for different
media sources.
</summary>
    <author>
      <name>Marco Franciosi</name>
    </author>
    <author>
      <name>Giulia Menconi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Keywords: multimedia mining, trend, entropy, Zipf law</arxiv:comment>
    <link href="http://arxiv.org/abs/0803.0405v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0803.0405v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0805.2938v2</id>
    <updated>2008-08-25T10:40:57Z</updated>
    <published>2008-05-19T20:46:38Z</published>
    <title>Steganography of VoIP Streams</title>
    <summary>  The paper concerns available steganographic techniques that can be used for
creating covert channels for VoIP (Voice over Internet Protocol) streams. Apart
from characterizing existing steganographic methods we provide new insights by
presenting two new techniques. The first one is network steganography solution
which exploits free/unused protocols' fields and is known for IP, UDP or TCP
protocols but has never been applied to RTP (Real-Time Transport Protocol) and
RTCP (Real-Time Control Protocol) which are characteristic for VoIP. The second
method, called LACK (Lost Audio Packets Steganography), provides hybrid
storage-timing covert channel by utilizing delayed audio packets. The results
of the experiment, that was performed to estimate a total amount of data that
can be covertly transferred during typical VoIP conversation phase, regardless
of steganalysis, are also included in this paper.
</summary>
    <author>
      <name>Wojciech Mazurczyk</name>
    </author>
    <author>
      <name>Krzysztof Szczypiorski</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, 9 figures, content changed, accepted to The 3rd
  International Symposium on Information Security (IS'08), Monterrey, Mexico,
  November 10-11, 2008 (Proceedings will be published by Springer LNCS)</arxiv:comment>
    <link href="http://arxiv.org/abs/0805.2938v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0805.2938v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0806.4293v1</id>
    <updated>2008-06-26T12:19:27Z</updated>
    <published>2008-06-26T12:19:27Z</published>
    <title>Scalar Quantization for Audio Data Coding</title>
    <summary>  This paper is concerned with scalar quantization of transform coefficients in
an audio codec. The generalized Gaussian distribution (GGD) is used as an
approximation of one-dimensional probability density function for transform
coefficients obtained by modulated lapped transform (MLT) or modified cosine
transform (MDCT) filterbank. The rationale of the model is provided in
comparison with theoretically achievable rate-distortion function. The
rate-distortion function computed for the random sequence obtained from a real
sequence of samples from a large database is compared with that computed for
random sequence obtained by a GGD random generator. A simple algorithm of
constructing the Extended Zero Zone (EZZ) quantizer is proposed. Simulation
results show that the EZZ quantizer yields a negligible loss in terms of coding
efficiency compared to optimal scalar quantizers. Furthermore, we describe an
adaptive version of the EZZ quantizer which works efficiently with low bitrate
requirements for transmitting side information
</summary>
    <author>
      <name>Boris D. Kudryashov</name>
    </author>
    <author>
      <name>Anton V. Porov</name>
    </author>
    <author>
      <name>Eunmi L. Oh</name>
    </author>
    <link href="http://arxiv.org/abs/0806.4293v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0806.4293v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0810.2063v1</id>
    <updated>2008-10-12T00:15:27Z</updated>
    <published>2008-10-12T00:15:27Z</published>
    <title>Initial Offset Placement in p2p Live Streaming Systems</title>
    <summary>  Initial offset placement in p2p streaming systems is studied in this paper.
Proportional placement (PP) scheme is proposed. In this scheme, peer places the
initial offset as the offset reported by other reference peer with a shift
proportional to the buffer width or offset lag of this reference peer. This
will introduce a stable placement that supports larger buffer width for peers
and small buffer width for tracker. Real deployed placement method in PPLive is
studied through measurement. It shows that, instead of based on offset lag, the
placement is based on buffer width of the reference peer to facilitate the
initial chunk fetching. We will prove that, such a PP scheme may not be stable
under arbitrary buffer occupation in the reference peer. The required average
buffer width then is derived. A simple good peer selection mechanism to check
the buffer occupation of reference peer is proposed for a stable PP scheme
based on buffer width
</summary>
    <author>
      <name>Chunxi Li</name>
    </author>
    <author>
      <name>Changjia Chen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 8 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0810.2063v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0810.2063v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0811.0582v1</id>
    <updated>2008-11-04T19:36:16Z</updated>
    <published>2008-11-04T19:36:16Z</published>
    <title>Optimization of automatically generated multi-core code for the LTE
  RACH-PD algorithm</title>
    <summary>  Embedded real-time applications in communication systems require high
processing power. Manual scheduling devel-oped for single-processor
applications is not suited to multi-core architectures. The Algorithm
Architecture Matching (AAM) methodology optimizes static application
implementation on multi-core architectures. The Random Access Channel Preamble
Detection (RACH-PD) is an algorithm for non-synchronized access of Long Term
Evolu-tion (LTE) wireless networks. LTE aims to improve the spectral efficiency
of the next generation cellular system. This paper de-scribes a complete
methodology for implementing the RACH-PD. AAM prototyping is applied to the
RACH-PD which is modelled as a Synchronous DataFlow graph (SDF). An efficient
implemen-tation of the algorithm onto a multi-core DSP, the TI C6487, is then
explained. Benchmarks for the solution are given.
</summary>
    <author>
      <name>Maxime Pelcat</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IETR</arxiv:affiliation>
    </author>
    <author>
      <name>Slaheddine Aridhi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IETR</arxiv:affiliation>
    </author>
    <author>
      <name>Jean François Nezan</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IETR</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">DASIP 2008, Bruxelles : Belgique (2008)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0811.0582v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0811.0582v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0811.2868v1</id>
    <updated>2008-11-18T09:14:18Z</updated>
    <published>2008-11-18T09:14:18Z</published>
    <title>Approximate Sparse Decomposition Based on Smoothed L0-Norm</title>
    <summary>  In this paper, we propose a method to address the problem of source
estimation for Sparse Component Analysis (SCA) in the presence of additive
noise. Our method is a generalization of a recently proposed method (SL0),
which has the advantage of directly minimizing the L0-norm instead of L1-norm,
while being very fast. SL0 is based on minimization of the smoothed L0-norm
subject to As=x. In order to better estimate the source vector for noisy
mixtures, we suggest then to remove the constraint As=x, by relaxing exact
equality to an approximation (we call our method Smoothed L0-norm Denoising or
SL0DN). The final result can then be obtained by minimization of a proper
linear combination of the smoothed L0-norm and a cost function for the
approximation. Experimental results emphasize on the significant enhancement of
the modified method in noisy cases.
</summary>
    <author>
      <name>Hamed Firouzi</name>
    </author>
    <author>
      <name>Masoud Farivar</name>
    </author>
    <author>
      <name>Massoud Babaie-Zadeh</name>
    </author>
    <author>
      <name>Christian Jutten</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 Pages, Submitted to ICASSP 2009</arxiv:comment>
    <link href="http://arxiv.org/abs/0811.2868v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0811.2868v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0811.4483v1</id>
    <updated>2008-11-28T16:28:59Z</updated>
    <published>2008-11-28T16:28:59Z</published>
    <title>Wide spread spectrum watermarking with side information and interference
  cancellation</title>
    <summary>  Nowadays, a popular method used for additive watermarking is wide spread
spectrum. It consists in adding a spread signal into the host document. This
signal is obtained by the sum of a set of carrier vectors, which are modulated
by the bits to be embedded. To extract these embedded bits, weighted
correlations between the watermarked document and the carriers are computed.
Unfortunately, even without any attack, the obtained set of bits can be
corrupted due to the interference with the host signal (host interference) and
also due to the interference with the others carriers (inter-symbols
interference (ISI) due to the non-orthogonality of the carriers). Some recent
watermarking algorithms deal with host interference using side informed
methods, but inter-symbols interference problem is still open. In this paper,
we deal with interference cancellation methods, and we propose to consider ISI
as side information and to integrate it into the host signal. This leads to a
great improvement of extraction performance in term of signal-to-noise ratio
and/or watermark robustness.
</summary>
    <author>
      <name>Gaëtan Le Guelvouit</name>
    </author>
    <author>
      <name>Stéphane Pateux</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1117/12.476839</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1117/12.476839" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 8 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. IS&amp;T/SPIE Electronic Imaging, vol. 5020, Santa Clara, CA,
  Jan. 2003</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0811.4483v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0811.4483v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0812.2411v1</id>
    <updated>2008-12-12T16:08:04Z</updated>
    <published>2008-12-12T16:08:04Z</published>
    <title>Probabilistic SVM/GMM Classifier for Speaker-Independent Vowel
  Recognition in Continues Speech</title>
    <summary>  In this paper, we discuss the issues in automatic recognition of vowels in
Persian language. The present work focuses on new statistical method of
recognition of vowels as a basic unit of syllables. First we describe a vowel
detection system then briefly discuss how the detected vowels can feed to
recognition unit. According to pattern recognition, Support Vector Machines
(SVM) as a discriminative classifier and Gaussian mixture model (GMM) as a
generative model classifier are two most popular techniques. Current
state-ofthe- art systems try to combine them together for achieving more power
of classification and improving the performance of the recognition systems. The
main idea of the study is to combine probabilistic SVM and traditional GMM
pattern classification with some characteristic of speech like band-pass energy
to achieve better classification rate. This idea has been analytically
formulated and tested on a FarsDat based vowel recognition system. The results
show inconceivable increases in recognition accuracy. The tests have been
carried out by various proposed vowel recognition algorithms and the results
have been compared.
</summary>
    <author>
      <name>Mohammad Nazari</name>
    </author>
    <author>
      <name>Abolghasem Sayadiyan</name>
    </author>
    <author>
      <name>SeyedMajid Valiollahzadeh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/0812.2411v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0812.2411v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0812.2529v1</id>
    <updated>2008-12-13T07:46:52Z</updated>
    <published>2008-12-13T07:46:52Z</published>
    <title>Kalinahia: Considering Quality of Service to Design and Execute
  Distributed Multimedia Applications</title>
    <summary>  One of the current challenges of Information Systems is to ensure
semi-structured data transmission, such as multimedia data, in a distributed
and pervasive environment. Information Sytems must then guarantee users a
quality of service ensuring data accessibility whatever the hardware and
network conditions may be. They must also guarantee information coherence and
particularly intelligibility that imposes a personalization of the service.
Within this framework, we propose a design method based on original models of
multimedia applications and quality of service. We also define a supervision
platform Kalinahia using a user centered heuristic allowing us to define at any
moment which configuration of software components constitutes the best answers
to users' wishes in terms of service.
</summary>
    <author>
      <name>Sophie Laplace</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIUPPA</arxiv:affiliation>
    </author>
    <author>
      <name>Marc Dalmau</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIUPPA</arxiv:affiliation>
    </author>
    <author>
      <name>Philippe Roose</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIUPPA</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE/IFIP Int'l Conference on Network Management and Management
  Symposium, Salvador de Bahia : Br\'esil (2008)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0812.2529v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0812.2529v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0812.2988v1</id>
    <updated>2008-12-16T07:46:49Z</updated>
    <published>2008-12-16T07:46:49Z</published>
    <title>The Korrontea Data Modeling</title>
    <summary>  Needs of multimedia systems evolved due to the evolution of their
architecture which is now distributed into heterogeneous contexts. A critical
issue lies in the fact that they handle, process, and transmit multimedia data.
This data integrates several properties which should be considered since it
holds a considerable part of its semantics, for instance the lips
synchronization in a video. In this paper, we focus on the definition of a
model as a basic abstraction for describing and modeling media in multimedia
systems by taking into account their properties. This model will be used in
software architecture in order to handle data in efficient way. The provided
model is an interesting solution for the integration of media into
applications; we propose to consider and to handle them in a uniform way. This
model is proposed with synchronization policies to ensure synchronous transport
of media. Therefore, we use it in a component model that we develop for the
design and deployment of distributed multimedia systems.
</summary>
    <author>
      <name>Emmanuel Bouix</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIUPPA</arxiv:affiliation>
    </author>
    <author>
      <name>Philippe Roose</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIUPPA</arxiv:affiliation>
    </author>
    <author>
      <name>Marc Dalmau</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIUPPA</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Ambisys, Quebec City : Canada (2008)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0812.2988v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0812.2988v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0812.2989v1</id>
    <updated>2008-12-16T07:47:22Z</updated>
    <published>2008-12-16T07:47:22Z</published>
    <title>Heterogeneous component interactions: Sensors integration into
  multimedia applications</title>
    <summary>  Resource-constrained embedded and mobile devices are becoming increasingly
common. Since few years, some mobile and ubiquitous devices such as wireless
sensor, able to be aware of their physical environment, appeared. Such devices
enable proposing applications which adapt to user's need according the context
evolution. It implies the collaboration of sensors and software components
which differ on their nature and their communication mechanisms. This paper
proposes a unified component model in order to easily design applications based
on software components and sensors without taking care of their nature. Then it
presents a state of the art of communication problems linked to heterogeneous
components and proposes an interaction mechanism which ensures information
exchanges between wireless sensors and software components.
</summary>
    <author>
      <name>Christine Louberry</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIUPPA</arxiv:affiliation>
    </author>
    <author>
      <name>Philippe Roose</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIUPPA</arxiv:affiliation>
    </author>
    <author>
      <name>Marc Dalmau</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIUPPA</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Networks, Issue N6, Academy Publisher 3, 4 (2008)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0812.2989v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0812.2989v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0903.2272v1</id>
    <updated>2009-03-13T07:11:31Z</updated>
    <published>2009-03-13T07:11:31Z</published>
    <title>A Novel Approach for Compression of Images Captured using Bayer Color
  Filter Arrays</title>
    <summary>  We propose a new approach for image compression in digital cameras, where the
goal is to achieve better quality at a given rate by using the characteristics
of a Bayer color filter array. Most digital cameras produce color images by
using a single CCD plate, so that each pixel in an image has only one color
component and therefore an interpolation method is needed to produce a full
color image. After the image processing stage, in order to reduce the memory
requirements of the camera, a lossless or lossy compression stage often
follows. But in this scheme, before decreasing redundancy through compression,
redundancy is increased in an interpolation stage. In order to avoid increasing
the redundancy before compression, we propose algorithms for image compression
in which the order of the compression and interpolation stages is reversed. We
introduce image transform algorithms, since non interpolated images cannot be
directly compressed with general image coders. The simulation results show that
our algorithm outperforms conventional methods with various color interpolation
methods in a wide range of compression ratios. Our proposed algorithm provides
not only better quality but also lower encoding complexity because the amount
of luminance data used is only half of that in conventional methods.
</summary>
    <author>
      <name>Sang-Yong Lee</name>
    </author>
    <author>
      <name>Antonio Ortega</name>
    </author>
    <link href="http://arxiv.org/abs/0903.2272v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0903.2272v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0903.3995v1</id>
    <updated>2009-03-24T01:33:15Z</updated>
    <published>2009-03-24T01:33:15Z</published>
    <title>Gradient-based adaptive interpolation in super-resolution image
  restoration</title>
    <summary>  This paper presents a super-resolution method based on gradient-based
adaptive interpolation. In this method, in addition to considering the distance
between the interpolated pixel and the neighboring valid pixel, the
interpolation coefficients take the local gradient of the original image into
account. The smaller the local gradient of a pixel is, the more influence it
should have on the interpolated pixel. And the interpolated high resolution
image is finally deblurred by the application of wiener filter. Experimental
results show that our proposed method not only substantially improves the
subjective and objective quality of restored images, especially enhances edges,
but also is robust to the registration error and has low computational
complexity.
</summary>
    <author>
      <name>Jinyu Chu</name>
    </author>
    <author>
      <name>Ju Liu</name>
    </author>
    <author>
      <name>Jianping Qiao</name>
    </author>
    <author>
      <name>Xiaoling Wang</name>
    </author>
    <author>
      <name>Yujun Li</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4pages, 7figures, This paper presents a super-resolution method based
  on gradient-based adaptive interpolation</arxiv:comment>
    <link href="http://arxiv.org/abs/0903.3995v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0903.3995v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0904.3693v1</id>
    <updated>2009-04-23T13:50:36Z</updated>
    <published>2009-04-23T13:50:36Z</published>
    <title>The Multimedia Product - between Design and Information, Design and
  Utility and Design and Entertainment</title>
    <summary>  The paper investigates the possible coherent and effective alternatives to
solve the problems related to the communication needs of any multimedia
product. In essence, the presentation will focus on identifying the issues and
principles governing three types of the design - in fact, the multimedia design
in a broader sense - namely the information design - precisely aiming at ways
of organization and presentation of information in a useful and significant
form, the graphical user interface design, whose sub-domain consists of the
information displayed on the monitor screen and of interactivity between user,
computer and electronic devices, meaning, in fact, everything the user sees,
touches, hears and all the elements with which he interacts, the graphic
design, whose main concern is to create an aesthetic layout arrangement (from
the visual and perceptive) information.
</summary>
    <author>
      <name>Dieter Penteliuc Cotosman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">28 pages,exposed on 1st "European Conference on Computer Sciences &amp;
  Applications" - XA2006, Timisoara, Romania</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Ann. Univ. Tibiscus Comp. Sci. Series IV (2006), 167-194</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0904.3693v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0904.3693v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0904.3694v1</id>
    <updated>2009-04-23T13:57:23Z</updated>
    <published>2009-04-23T13:57:23Z</published>
    <title>The new multimedia educational technologies, used in open and distance
  learning</title>
    <summary>  This paper reviews and refers to the latest telematics technology that has
turned the open system learning and helped it to become an institutional
alternative to the face-to-face traditional one. Most technologies, briefly
presented here, will be implemented in the "ARTeFACt" project - telematic
system for vocational education system of open system learning, system which
will be officially launched at the end of 2006, in the institutional offer of
the Faculty of Arts of the University West of Timisoara. The scientific
coordination of the doctoral project "ARTeFACt" is done by Mr. Prof. Dr. Eng.
Savi G. George, representing the Department of Mechatronics Faculty of
Mechanical Engineering from the University "Politehnica" of Timisoara, Romania
</summary>
    <author>
      <name>Dieter Penteliuc-Cotosman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages,exposed on 1st "European Conference on Computer Sciences &amp;
  Applications" - XA2006, Timisoara, Romania</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Ann. Univ. Tibiscus Comp. Sci. Series IV (2006), 195-204</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0904.3694v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0904.3694v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0906.4936v1</id>
    <updated>2009-06-26T13:40:38Z</updated>
    <published>2009-06-26T13:40:38Z</published>
    <title>A New Approach to Manage QoS in Distributed Multimedia Systems</title>
    <summary>  Dealing with network congestion is a criterion used to enhance quality of
service (QoS) in distributed multimedia systems. The existing solutions for the
problem of network congestion ignore scalability considerations because they
maintain a separate classification for each video stream. In this paper, we
propose a new method allowing to control QoS provided to clients according to
the network congestion, by discarding some frames when needed. The technique
proposed, called (m,k)-frame, is scalable with little degradation in
application performances. (m,k)-frame method is issued from the notion of
(m,k)-firm realtime constraints which means that among k invocations of a task,
m invocations must meet their deadline. Our simulation studies show the
usefulness of (m,k)-frame method to adapt the QoS to the real conditions in a
multimedia application, according to the current system load. Notably, the
system must adjust the QoS provided to active clients1 when their number
varies, i.e. dynamic arrival of clients.
</summary>
    <author>
      <name>Bechir Alaya</name>
    </author>
    <author>
      <name>Claude Duvallet</name>
    </author>
    <author>
      <name>Bruno Sadeg</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, International Journal of Computer Science and Information
  Security (IJCSIS)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IJCSIS June 2009 Issue, Vol. 2, No. 1</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0906.4936v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0906.4936v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0909.0118v1</id>
    <updated>2009-09-01T08:19:18Z</updated>
    <published>2009-09-01T08:19:18Z</published>
    <title>Dynamic Multimedia Content Retrieval System in Distributed Environment</title>
    <summary>  WiCoM enables remote management of web resources. Our application Mobile
reporter is aimed at Journalist, who will be able to capture the events in
real-time using their mobile phones and update their web server on the latest
event. WiCoM has been developed using J2ME technology on the client side and
PHP on the server side. The communication between the client and the server is
established through GPRS. Mobile reporter will be able to upload, edit and
remove both textual as well as multimedia contents in the server.
</summary>
    <author>
      <name>R. Sivaraman</name>
    </author>
    <author>
      <name>R. Prabakaran</name>
    </author>
    <author>
      <name>S. Sujatha</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 4, No. 1 &amp; 2, August 2009, USA</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0909.0118v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0909.0118v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0909.0245v1</id>
    <updated>2009-09-01T18:57:06Z</updated>
    <published>2009-09-01T18:57:06Z</published>
    <title>Enhanced Mode Selection Algorithm for H.264 encoder for Application in
  Low Computational power devices</title>
    <summary>  The intent of the H.264 AVC project was to create a standard capable of
providing good video quality at substantially lower bit rates than previous
standards without increasing the complexity of design so much that it would be
impractical or excessively expensive to implement. An additional goal was to
provide enough flexibility to allow the standard to be applied to a wide
variety of applications. To achieve better coding efficiency, H.264 AVC uses
several techniques such as inter mode and intra mode prediction with variable
size motion compensation, which adopts Rate Distortion Optimization (RDO). This
increases the computational complexity of the encoder especially for devices
with lower processing capabilities such as mobile and other handheld devices.
In this paper, we propose an algorithm to reduce the number of mode and sub
mode evaluations in inter mode prediction. Experimental results show that this
fast intra mode selection algorithm can lessen about 75 percent encoding time
with little loss of bit rate and visual quality.
</summary>
    <author>
      <name>Sourabh Rungta</name>
    </author>
    <author>
      <name>Kshitij Verma</name>
    </author>
    <author>
      <name>Neeta Tripathi</name>
    </author>
    <author>
      <name>Anupam Shukla</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact factor 0.423
  http://sites.google.com/site/ijcsis/</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 4, No. 1 &amp; 2, August 2009, USA</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0909.0245v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0909.0245v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0909.2816v1</id>
    <updated>2009-09-15T14:44:21Z</updated>
    <published>2009-09-15T14:44:21Z</published>
    <title>Efficient Quality-Based Playout Buffer Algorithm</title>
    <summary>  Playout buffers are used in VoIP systems to compensate for network delay
jitter by making a trade-off between delay and loss. In this work we propose a
playout buffer algorithm that makes the trade-off based on maximization of
conversational speech quality, aiming to keep the computational complexity
lowest possible. We model the network delay using a Pareto distribution and
show that it is a good compromise between providing an appropriate fit to the
network delay characteristics and yielding a low arithmetical complexity. We
use the ITU-T E-Model as the quality model and simplify its delay impairment
function. The proposed playout buffer algorithm finds the optimum playout delay
using a closed-form solution that minimizes the sum of the simplified delay
impairment factor and the loss-dependent equipment impairment factor of the
E-model. The simulation results show that our proposed algorithm outperforms
existing state-of-the-art algorithms with a reduced complexity for a
quality-based algorithm.
</summary>
    <author>
      <name>Emine Zerrin Sakir</name>
    </author>
    <author>
      <name>Christian Feldbauer</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/0909.2816v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0909.2816v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0909.3554v1</id>
    <updated>2009-09-19T03:06:57Z</updated>
    <published>2009-09-19T03:06:57Z</published>
    <title>Robustness of the Digital Image Watermarking Techniques against
  Brightness and Rotation Attack</title>
    <summary>  The recent advent in the field of multimedia proposed a many facilities in
transport, transmission and manipulation of data. Along with this advancement
of facilities there are larger threats in authentication of data, its licensed
use and protection against illegal use of data. A lot of digital image
watermarking techniques have been designed and implemented to stop the illegal
use of the digital multimedia images. This paper compares the robustness of
three different watermarking schemes against brightness and rotation attacks.
The robustness of the watermarked images has been verified on the parameters of
PSNR (Peak Signal to Noise Ratio), RMSE (Root Mean Square Error) and MAE (Mean
Absolute Error).
</summary>
    <author>
      <name>Harsh K Verma</name>
    </author>
    <author>
      <name>Abhishek Narain Singh</name>
    </author>
    <author>
      <name>Raman Kumar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact factor 0.423</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Harsh K Verma, Abhishek Narain Singh, Raman Kumar, International
  Journal of Computer Science and Information Security, IJCSIS, Vol. 5, No. 1,
  September 2009, USA</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0909.3554v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0909.3554v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0910.0179v1</id>
    <updated>2009-10-01T14:03:51Z</updated>
    <published>2009-10-01T14:03:51Z</published>
    <title>Analysis, Design and Simulation of a New System for Internet Multimedia
  Transmission Guarantee</title>
    <summary>  QoS is a very important issue for multimedia communication systems. In this
paper, a new system that reinstalls the relation between the QoS elements
(RSVP, routing protocol, sender, and receiver) during the multimedia
transmission is proposed, then an alternative path is created in case of
original multimedia path failure. The suggested system considers the resulting
problems that may be faced within and after the creation of rerouting path.
Finally, the proposed system is simulated using OPNET 11.5 simulation package.
Simulation results show that our proposed system outperforms the old one in
terms of QoS parameters like packet loss and delay jitter.
</summary>
    <author>
      <name>O. Said</name>
    </author>
    <author>
      <name>S. Bahgat</name>
    </author>
    <author>
      <name>M. Ghoniemy</name>
    </author>
    <author>
      <name>Y. Elawdy</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 5, No. 1, pp. 77-86, September 2009, USA</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0910.0179v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0910.0179v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0910.1468v1</id>
    <updated>2009-10-08T11:21:21Z</updated>
    <published>2009-10-08T11:21:21Z</published>
    <title>Prefetching of VoD Programs Based On ART1 Requesting Clustering</title>
    <summary>  In this paper, we propose a novel approach to group users according to the
VoD user request pattern. We cluster the user requests based on ART1 neural
network algorithm. The knowledge extracted from the cluster is used to prefetch
the multimedia object from each cluster before the users request. We have
developed an algorithm to cluster users according to the users request patterns
based on ART1 neural network algorithm that offers an unsupervised clustering.
This approach adapts to changes in user request patterns over period without
losing previous information. Each cluster is represented as prototype vector by
generalizing the most frequently used URLs that are accessed by all the cluster
members. The simulation results of our proposed clustering and prefetching
algorithm, shows enormous increase in the performance of streaming server. Our
algorithm helps the servers agent to learn user preferences and discover the
information about the corresponding sources and other similar interested
individuals.
</summary>
    <author>
      <name>P. Jayarekha</name>
    </author>
    <author>
      <name>T. R. GopalaKrishnan Nair</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 5, No. 1, pp. 128-134, September 2009, USA</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0910.1468v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0910.1468v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0911.0399v1</id>
    <updated>2009-11-02T20:07:52Z</updated>
    <published>2009-11-02T20:07:52Z</published>
    <title>A Wavelet-Based Digital Watermarking for Video</title>
    <summary>  A novel video watermarking system operating in the three dimensional wavelet
transform is here presented. Specifically the video sequence is partitioned
into spatio temporal units and the single shots are projected onto the 3D
wavelet domain. First a grayscale watermark image is decomposed into a series
of bitplanes that are preprocessed with a random location matrix. After that
the preprocessed bitplanes are adaptively spread spectrum and added in 3D
wavelet coefficients of the video shot. Our video watermarking algorithm is
robust against the attacks of frame dropping, averaging and swapping.
Furthermore, it allows blind retrieval of embedded watermark which does not
need the original video and the watermark is perceptually invisible. The
algorithm design, evaluation, and experimentation of the proposed scheme are
described in this paper.
</summary>
    <author>
      <name>A. Essaouabi</name>
    </author>
    <author>
      <name>F. Regragui</name>
    </author>
    <author>
      <name>E. Ibnelhaj</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,
  http://sites.google.com/site/ijcsis/</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 1, pp. 029-033, October 2009, USA</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0911.0399v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0911.0399v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0912.1005v1</id>
    <updated>2009-12-05T12:33:09Z</updated>
    <published>2009-12-05T12:33:09Z</published>
    <title>Performance analysis of Non Linear Filtering Algorithms for underwater
  images</title>
    <summary>  Image filtering algorithms are applied on images to remove the different
types of noise that are either present in the image during capturing or
injected in to the image during transmission. Underwater images when captured
usually have Gaussian noise, speckle noise and salt and pepper noise. In this
work, five different image filtering algorithms are compared for the three
different noise types. The performances of the filters are compared using the
Peak Signal to Noise Ratio (PSNR) and Mean Square Error (MSE). The modified
spatial median filter gives desirable results in terms of the above two
parameters for the three different noise. Forty underwater images are taken for
study.
</summary>
    <author>
      <name>Dr. G. Padmavathi</name>
    </author>
    <author>
      <name>Dr. P. Subashini</name>
    </author>
    <author>
      <name>Mr. M. Muthu Kumar</name>
    </author>
    <author>
      <name>Suresh Kumar Thakur</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS November 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 2, pp. 232-238, November 2009, USA</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0912.1005v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0912.1005v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0912.1011v1</id>
    <updated>2009-12-05T13:03:17Z</updated>
    <published>2009-12-05T13:03:17Z</published>
    <title>A Reliable Replication Strategy for VoD System using Markov Chain</title>
    <summary>  In this paper we have investigated on the reliability of streams for a VoD
system. The objective of the paper is to maximize the availability of streams
for the peers in the VoD system. We have achieved this by using data
replication technique in the peers. Hence, we proposed a new data replication
technique to optimally store the videos in the peers. The new data replication
technique generates more number of replicas than the existing techniques such
as random, minimum request and maximize hit. We have also investigated by
applying the CTMC model for the reliability of replications during the peer
failures. Our result shows that the mean lifetime of replicas are more under
various circumstances. We have addressed the practical issues of efficient
utilization of overall bandwidth and buffer in the VoD system. We achieved
greater success playback probability of videos than the existing techniques.
</summary>
    <author>
      <name>R. Ashok Kumar</name>
    </author>
    <author>
      <name>K. Ganesan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS November 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 2, pp. 281-290, November 2009, USA</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0912.1011v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0912.1011v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0912.4881v1</id>
    <updated>2009-12-24T15:28:53Z</updated>
    <published>2009-12-24T15:28:53Z</published>
    <title>Music-ripping: des pratiques qui provoquent la musicologie</title>
    <summary>  Out of the scope of the usual positions of computing in the field of music
and musicology, one notices the emergence of human-computer systems that do
exist by breaking off. Though these singular systems take effect in the usual
fields of expansion of music, they do not make any systematic reference to
known musicological categories. On the contrary, they make possible experiments
that open uses where listening, composition and musical transmission get merged
in a gesture sometimes named as ?music-ripping?. We will show in which way the
music-ripping practices provoke traditional musicology, whose canonical
categories happen to be ineffectual to explain here. To achieve that purpose,
we shall need: - to make explicit a minimal set of categories that is
sufficient to underlie the usual models of computer assisted music;- to do the
same for human-computer systems (anti-musicological?) that disturb us; - to
examine the possibility conditions of reduction of the second set to the first;
- to conclude on the nature of music-ripping.
</summary>
    <author>
      <name>Francis Rousseaux</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">STMS, CRESTIC</arxiv:affiliation>
    </author>
    <author>
      <name>Alain Bonardi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">STMS</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Musicae Scientiae Special issue 2004 (2004)
  http://musicweb.hmt-hannover.de/escom/english/MusicScE/MSstart.htm</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0912.4881v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0912.4881v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1001.0441v1</id>
    <updated>2010-01-04T05:32:05Z</updated>
    <published>2010-01-04T05:32:05Z</published>
    <title>Semantic Modeling and Retrieval of Dance Video Annotations</title>
    <summary>  Dance video is one of the important types of narrative videos with semantic
rich content. This paper proposes a new meta model, Dance Video Content Model
(DVCM) to represent the expressive semantics of the dance videos at multiple
granularity levels. The DVCM is designed based on the concepts such as video,
shot, segment, event and object, which are the components of MPEG-7 MDS. This
paper introduces a new relationship type called Temporal Semantic Relationship
to infer the semantic relationships between the dance video objects. Inverted
file based index is created to reduce the search time of the dance queries. The
effectiveness of containment queries using precision and recall is depicted.
Keywords: Dance Video Annotations, Effectiveness Metrics, Metamodeling,
Temporal Semantic Relationships.
</summary>
    <author>
      <name>Rajkumar Kannan</name>
    </author>
    <author>
      <name>Balakrishnan Ramadoss</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">INFOCOMP Journal of Computer Science, Brazil</arxiv:comment>
    <link href="http://arxiv.org/abs/1001.0441v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1001.0441v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.1; H.5.4; H.2.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1001.0442v1</id>
    <updated>2010-01-04T05:41:01Z</updated>
    <published>2010-01-04T05:41:01Z</published>
    <title>Modeling and Annotating the Expressive Semantics of Dance Videos</title>
    <summary>  Dance videos are interesting and semantics-intensive. At the same time, they
are the complex type of videos compared to all other types such as sports, news
and movie videos. In fact, dance video is the one which is less explored by the
researchers across the globe. Dance videos exhibit rich semantics such as macro
features and micro features and can be classified into several types. Hence,
the conceptual modeling of the expressive semantics of the dance videos is very
crucial and complex. This paper presents a generic Dance Video Semantics Model
(DVSM) in order to represent the semantics of the dance videos at different
granularity levels, identified by the components of the accompanying song. This
model incorporates both syntactic and semantic features of the videos and
introduces a new entity type called, Agent, to specify the micro features of
the dance videos. The instantiations of the model are expressed as graphs. The
model is implemented as a tool using J2SE and JMF to annotate the macro and
micro features of the dance videos. Finally examples and evaluation results are
provided to depict the effectiveness of the proposed dance video model.
Keywords: Agents, Dance videos, Macro features, Micro features, Video
annotation, Video semantics.
</summary>
    <author>
      <name>Rajkumar Kannan</name>
    </author>
    <author>
      <name>Balakrishnan Ramadoss</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Information Technologies and Knowledge</arxiv:comment>
    <link href="http://arxiv.org/abs/1001.0442v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1001.0442v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.5; H.5.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1001.1794v1</id>
    <updated>2010-01-12T05:06:16Z</updated>
    <published>2010-01-12T05:06:16Z</published>
    <title>Designing a Truly Integrated (Onsite and Online) Conference: Concept,
  Processes, Solutions</title>
    <summary>  Web conferencing tools have entered the mainstream of business applications.
Using web conferencing for IEEE conferences has a good potential of adding
value to both organizers and participants. Authors propose a concept of Truly
Integrated Conference (TIC) according to which a multi-point
worldwide-distributed network of conference online authors/participants will
enhance the standard (centralized) IEEE conference model, which requires
attendance of the participants in person at the main conference location. The
concept entails seamless integration of the onsite and online conference
systems, including data/presentation, video, audio channels. Benefits and
challenges of the TIC concept are analyzed. Requirements to the web
conferencing system capable of supporting the TIC conference are presented and
reviewed against commercial web conferencing tools. Case study of the IEEE
Toronto International Conference ? Science and Technology for Humanity, which
was the first realization of TIC, is presented which analyzes various aspects
(organizational, technological, and financial) of the integrated conference.
</summary>
    <author>
      <name>Alexei Botchkarev</name>
    </author>
    <author>
      <name>Lian Zhao</name>
    </author>
    <author>
      <name>Hamed Rasouli</name>
    </author>
    <link href="http://arxiv.org/abs/1001.1794v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1001.1794v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1001.1937v2</id>
    <updated>2010-02-04T16:26:43Z</updated>
    <published>2010-01-12T16:13:50Z</published>
    <title>Avoiding Interruptions - QoE Trade-offs in Block-coded Streaming Media
  Applications</title>
    <summary>  We take an analytical approach to study Quality of user Experience (QoE) for
video streaming applications. First, we show that random linear network coding
applied to blocks of video frames can significantly simplify the packet
requests at the network layer and save resources by avoiding duplicate packet
reception. Network coding allows us to model the receiver's buffer as a queue
with Poisson arrivals and deterministic departures. We consider the probability
of interruption in video playback as well as the number of initially buffered
packets (initial waiting time) as the QoE metrics. We characterize the optimal
trade-off between these metrics by providing upper and lower bounds on the
minimum initial buffer size, required to achieve certain level of interruption
probability for different regimes of the system parameters. Our bounds are
asymptotically tight as the file size goes to infinity.
</summary>
    <author>
      <name>Ali Parandehgheibi</name>
    </author>
    <author>
      <name>Muriel Medard</name>
    </author>
    <author>
      <name>Srinivas Shakkottai</name>
    </author>
    <author>
      <name>Asu Ozdaglar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to ISIT 2010 - Full version</arxiv:comment>
    <link href="http://arxiv.org/abs/1001.1937v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1001.1937v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1001.1972v1</id>
    <updated>2010-01-12T18:30:20Z</updated>
    <published>2010-01-12T18:30:20Z</published>
    <title>A New Image Steganography Based On First Component Alteration Technique</title>
    <summary>  In this paper, A new image steganography scheme is proposed which is a kind
of spatial domain technique. In order to hide secret data in cover-image, the
first component alteration technique is used. Techniques used so far focuses
only on the two or four bits of a pixel in a image (at the most five bits at
the edge of an image) which results in less peak to signal noise ratio and high
root mean square error. In this technique, 8 bits of blue components of pixels
are replaced with secret data bits. Proposed scheme can embed more data than
previous schemes and shows better image quality. To prove this scheme, several
experiments are performed, and are compared the experimental results with the
related previous works.
</summary>
    <author>
      <name>Amanpreet Kaur</name>
    </author>
    <author>
      <name>Renu Dhir</name>
    </author>
    <author>
      <name>Geeta Sikka</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS December 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 3, pp. 053-056, December 2009, USA</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1001.1972v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1001.1972v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1001.1974v1</id>
    <updated>2010-01-12T18:34:24Z</updated>
    <published>2010-01-12T18:34:24Z</published>
    <title>Evaluating Effectiveness of Tamper Proofing on Dynamic Graph Software
  Watermarks</title>
    <summary>  For enhancing the protection level of dynamic graph software watermarks and
for the purpose of conducting the analysis which evaluates the effect of
integrating two software protection techniques such as software watermarking
and tamper proofing, constant encoding technique along with the enhancement
through the idea of constant splitting is proposed. In this paper Thomborson
technique has been implemented with the scheme of breaking constants which
enables to encode all constants without having any consideration about their
values with respect to the value of watermark tree. Experimental analysis which
have been conducted and provided in this paper concludes that the constant
encoding process significantly increases the code size, heap space usage, and
execution time, while making the tamper proofed code resilient to variety of
semantic preserving program transformation attacks.
</summary>
    <author>
      <name>Malik Sikandar Hayat Khiyal</name>
    </author>
    <author>
      <name>Aihab Khan</name>
    </author>
    <author>
      <name>Sehrish Amjad</name>
    </author>
    <author>
      <name>M. Shahid Khalil</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS December 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 3, pp. 057-063, December 2009, USA</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1001.1974v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1001.1974v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1001.3744v1</id>
    <updated>2010-01-21T08:57:27Z</updated>
    <published>2010-01-21T08:57:27Z</published>
    <title>Multicast Transmission Prefix and Popularity Aware Interval Caching
  Based Admission Control Policy</title>
    <summary>  Admission control is a key component in multimedia servers, which will allow
the resources to be used by the client only when they are available. A problem
faced by numerous content serving machines is overload, when there are too many
clients who need to be served, the server tends to slow down. An admission
control algorithm for a multimedia server is responsible for determining if a
new request can be accepted without violating the QoS requirements of the
existing requests in the system. By caching and streaming only the data in the
interval between two successive requests on the same object, the following
request can be serviced directly from the buffer cache without disk operations
and within the deadline of the request. An admission control strategy based on
Popularity-aware interval caching for Prefix [3] scheme extends the interval
caching by considering different popularity of multimedia objects. The method
of Prefix caching with multicast transmission of popular objects utilizes the
hard disk and network bandwidth efficiently and increases the number of
requests being served.
</summary>
    <author>
      <name>P. Jayarekha</name>
    </author>
    <author>
      <name>T. R. Gopalakrishnan Nair</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages,</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Innovations-2008, pp 15-31, 2008</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1001.3744v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1001.3744v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1001.3774v1</id>
    <updated>2010-01-21T11:08:42Z</updated>
    <published>2010-01-21T11:08:42Z</published>
    <title>Cooperative Proxy Servers Architecture for VoD to Achieve High QoS with
  Reduced Transmission Time and Cost</title>
    <summary>  - The aim of this paper is to propose a novel Voice On Demand (VoD)
architecture and implementation of an efficient load sharing algorithm to
achieve Quality of Service (QoS). This scheme reduces the transmission cost
from the Centralized Multimedia Sever (CMS) to Proxy Servers (PS) by sharing
the videos among the proxy servers of the Local Proxy Servers Group [LPSG] and
among the neighboring LPSGs, which are interconnected in a ring fashion. This
results in very low request rejection ratio, reduction in transmission time and
cost, reduction of load on the CMS and high QoS for the users. Simulation
results indicate acceptable initial startup latency, reduced transmission cost
and time, load sharing among the proxy servers, among the LPSGs and between the
CMS and the PS.
</summary>
    <author>
      <name>M. Dakshayini</name>
    </author>
    <author>
      <name>T. R. Gopalakrishan Nair</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 6 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Innovations-2008, pp 103-114, 2008</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1001.3774v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1001.3774v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1001.4135v1</id>
    <updated>2010-01-23T07:20:30Z</updated>
    <published>2010-01-23T07:20:30Z</published>
    <title>An Adaptive Dynamic Replacement Approach for a Multicast based
  Popularity Aware Prefix Cache Memory System</title>
    <summary>  In this paper we have proposed an adaptive dynamic cache replacement
algorithm for a multimedia servers cache system. The goal is to achieve an
effective utilization of the cache memory which stores the prefix of popular
videos. A replacement policy is usually evaluated using hit ratio, the
frequency with which any video is requested. Usually discarding the least
recently used page is the policy of choice in cache management. The adaptive
dynamic replacement approach for prefix cache is a self tuning, low overhead
algorithm that responds online to changing access patterns. It constantly
balances between lru and lfu to improve combined result. It automatically
adapts to evolving workloads. Since in our algorithm we have considered a
prefix caching with multicast transmission of popular objects it utilizes the
hard disk and network bandwidth efficiently and increases the number of
requests being served.
</summary>
    <author>
      <name>P. Jayarekha</name>
    </author>
    <author>
      <name>T. R. Gopalakrishnan Nair</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1001.4135v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1001.4135v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1002.1727v3</id>
    <updated>2010-06-21T20:50:53Z</updated>
    <published>2010-02-08T22:05:04Z</published>
    <title>An Improved DC Recovery Method from AC Coefficients of DCT-Transformed
  Images</title>
    <summary>  Motivated by the work of Uehara et al. [1], an improved method to recover DC
coefficients from AC coefficients of DCT-transformed images is investigated in
this work, which finds applications in cryptanalysis of selective multimedia
encryption. The proposed under/over-flow rate minimization (FRM) method employs
an optimization process to get a statistically more accurate estimation of
unknown DC coefficients, thus achieving a better recovery performance. It was
shown by experimental results based on 200 test images that the proposed DC
recovery method significantly improves the quality of most recovered images in
terms of the PSNR values and several state-of-the-art objective image quality
assessment (IQA) metrics such as SSIM and MS-SSIM.
</summary>
    <author>
      <name>Shujun Li</name>
    </author>
    <author>
      <name>Junaid Jameel Ahmad</name>
    </author>
    <author>
      <name>Dietmar Saupe</name>
    </author>
    <author>
      <name>C. -C. Jay Kuo</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/ICIP.2010.5653467</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/ICIP.2010.5653467" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 6 figures, ICIP 2010</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of 2010 17th IEEE International Conference on Image
  Processing (ICIP 2010), pages 2085-2088, IEEE, 2010</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1002.1727v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1002.1727v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.4.2; E.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1002.1951v1</id>
    <updated>2010-02-09T19:43:44Z</updated>
    <published>2010-02-09T19:43:44Z</published>
    <title>Image Retrieval Techniques based on Image Features, A State of Art
  approach for CBIR</title>
    <summary>  The purpose of this Paper is to describe our research on different feature
extraction and matching techniques in designing a Content Based Image Retrieval
(CBIR) system. Due to the enormous increase in image database sizes, as well as
its vast deployment in various applications, the need for CBIR development
arose. Firstly, this paper outlines a description of the primitive feature
extraction techniques like, texture, colour, and shape. Once these features are
extracted and used as the basis for a similarity check between images, the
various matching techniques are discussed. Furthermore, the results of its
performance are illustrated by a detailed example.
</summary>
    <author>
      <name>Mr. Kondekar V. H.</name>
    </author>
    <author>
      <name>Mr. Kolkure V. S.</name>
    </author>
    <author>
      <name>Prof. Kore S. N</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS January 2010, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 7, No. 1, pp. 69-76, January 2010, USA</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1002.1951v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1002.1951v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1002.2184v1</id>
    <updated>2010-02-10T19:27:25Z</updated>
    <published>2010-02-10T19:27:25Z</published>
    <title>The Fast Haar Wavelet Transform for Signal &amp; Image Processing</title>
    <summary>  A method for the design of Fast Haar wavelet for signal processing and image
processing has been proposed. In the proposed work, the analysis bank and
synthesis bank of Haar wavelet is modified by using polyphase structure.
Finally, the Fast Haar wavelet was designed and it satisfies alias free and
perfect reconstruction condition. Computational time and computational
complexity is reduced in Fast Haar wavelet transform.
</summary>
    <author>
      <name>V. Ashok</name>
    </author>
    <author>
      <name>T. Balakumaran</name>
    </author>
    <author>
      <name>C. Gowrishankar</name>
    </author>
    <author>
      <name>I. L. A. Vennila</name>
    </author>
    <author>
      <name>A. Nirmal kumar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS January 2010, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 7, No. 1, pp. 126-130, January 2010, USA</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1002.2184v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1002.2184v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1002.2193v1</id>
    <updated>2010-02-10T19:52:12Z</updated>
    <published>2010-02-10T19:52:12Z</published>
    <title>Using Statistical Moment Invariants and Entropy in Image Retrieval</title>
    <summary>  Although content-based image retrieval (CBIR) is not a new subject, it keeps
attracting more and more attention, as the amount of images grow tremendously
due to internet, inexpensive hardware and automation of image acquisition. One
of the applications of CBIR is fetching images from a database. This paper
presents a new method for automatic image retrieval using moment invariants and
image entropy, our technique could be used to find semi or perfect matches
based on query by example manner, experimental results demonstrate that the
purposed technique is scalable and efficient.
</summary>
    <author>
      <name>Ismail I. Amr</name>
    </author>
    <author>
      <name>Mohamed Amin</name>
    </author>
    <author>
      <name>Passent El Kafrawy</name>
    </author>
    <author>
      <name>Amr M. Sauber</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS January 2010, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 7, No. 1, pp. 160-164, January 2010, USA</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1002.2193v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1002.2193v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1002.2414v1</id>
    <updated>2010-02-11T20:05:22Z</updated>
    <published>2010-02-11T20:05:22Z</published>
    <title>Dual Watermarking Scheme with Encryption</title>
    <summary>  Digital Watermarking is used for copyright protection and authentication. In
the proposed system, a Dual Watermarking Scheme based on DWT SVD with chaos
encryption algorithm, will be developed to improve the robustness and
protection along with security. DWT and SVD have been used as a mathematical
tool to embed watermark in the image. Two watermarks are embedded in the host
image. The secondary is embedded into primary watermark and the resultant
watermarked image is encrypted using chaos based logistic map. This provides an
efficient and secure way for image encryption and transmission. The watermarked
image is decrypted and a reliable watermark extraction scheme is developed for
the extraction of the primary as well as secondary watermark from the distorted
image.
</summary>
    <author>
      <name>R. Dhanalakshmi</name>
    </author>
    <author>
      <name>K. Thaiyalnayaki</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS January 2010, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 7, No. 1, pp. 248-253, January 2010, USA</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1002.2414v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1002.2414v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1002.3984v1</id>
    <updated>2010-02-21T18:29:53Z</updated>
    <published>2010-02-21T18:29:53Z</published>
    <title>Effect of Embedding Watermark on Compression of the Digital Images</title>
    <summary>  Image Compression plays a very important role in image processing especially
when we are to send the image on the internet. The threat to the information on
the internet increases and image is no exception. Generally the image is sent
on the internet as the compressed image to optimally use the bandwidth of the
network. But as we are on the network, at any intermediate level the image can
be changed intentionally or unintentionally. To make sure that the correct
image is being delivered at the other end we embed the water mark to the image.
The watermarked image is then compressed and sent on the network. When the
image is decompressed at the other end we can extract the watermark and make
sure that the image is the same that was sent by the other end. Though
watermarking the image increases the size of the uncompressed image but that
has to done to achieve the high degree of robustness i.e. how an image sustains
the attacks on it. The present paper is an attempt to make transmission of the
images secure from the intermediate attacks by applying the generally used
compression transforms.
</summary>
    <author>
      <name>Deepak Aggarwal</name>
    </author>
    <author>
      <name>Kanwalvir Singh Dhindsa</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Computing, Volume 2, Issue 2, February 2010,
  https://sites.google.com/site/journalofcomputing/</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1002.3984v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1002.3984v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1003.3080v1</id>
    <updated>2010-03-16T05:07:10Z</updated>
    <published>2010-03-16T05:07:10Z</published>
    <title>An Algorithm for Index Multimedia Data (Video) using the Movement
  Oriented Method for Real-time Online Services</title>
    <summary>  Multimedia data is a form of data that can represent all types of data
(images, sound and text). The use of multimedia data for the online application
requires a more comprehensive database in the use of storage media, Sorting /
indexing, search and system / data searching. This is necessary in order to
help providers and users to access multimedia data online. Systems that use of
the index image as a reference requires storage media so that the rules and
require special expertise to obtain the desired file. Changes in multimedia
data into a series of stories / storyboard in the form of a text will help
reduce the consumption of media storage, system index / sorting and search
applications. Oriented Movement is one method that is being developed to change
the form of multimedia data into a storyboard.
</summary>
    <author>
      <name>A. Muslim</name>
    </author>
    <author>
      <name>A. B. Mutiara</name>
    </author>
    <author>
      <name>C. M. Karyati</name>
    </author>
    <author>
      <name>P. Musa</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, International Conference on Robotics, Informatics,
  Intelligence control system Technologies (RIIT'09)</arxiv:comment>
    <link href="http://arxiv.org/abs/1003.3080v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1003.3080v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1003.3533v1</id>
    <updated>2010-03-18T09:27:16Z</updated>
    <published>2010-03-18T09:27:16Z</published>
    <title>Towards Automated Lecture Capture, Navigation and Delivery System for
  Web-Lecture on Demand</title>
    <summary>  Institutions all over the world are continuously exploring ways to use ICT in
improving teaching and learning effectiveness. The use of course web pages,
discussion groups, bulletin boards, and e-mails have shown considerable impact
on teaching and learning in significant ways, across all disciplines. ELearning
has emerged as an alternative to traditional classroom-based education and
training and web lectures can be a powerful addition to traditional lectures.
They can even serve as a main content source for learning, provided users can
quickly navigate and locate relevant pages in a web lecture. A web lecture
consists of video and audio of the presenter and slides complemented with
screen capturing. In this paper, an automated approach for recording live
lectures and for browsing available web lectures for on-demand applications by
end users is presented.
</summary>
    <author>
      <name>Rajkumar Kannan</name>
    </author>
    <author>
      <name>Frederic Andres</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3rd International Conference on Data Management, March 2010, India</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Book Chapter in Innovations and Advances in Computer Science and
  Engineering, MacMillan Publishers, 386-394, 2010</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1003.3533v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1003.3533v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1003.4049v1</id>
    <updated>2010-03-22T03:31:50Z</updated>
    <published>2010-03-22T03:31:50Z</published>
    <title>An Optimal Prefix Replication Strategy for VoD Services</title>
    <summary>  In this paper we propose scalable proxy servers cluster architecture of
interconnected proxy servers for high quality and high availability services.
We also propose an optimal regional popularity based video prefix replication
strategy and a scene change based replica caching algorithm that utilizes the
zipf-like video popularity distribution to maximize the availability of videos
closer to the client and request-servicing rate thereby reducing the client
rejection ratio and the response time for the client. The simulation results of
our proposed architecture and algorithm show the greater achievement in
maximizing the availability of videos, client request-servicing rate and in
reduction of initial start-up latency and client rejection ratio.
</summary>
    <author>
      <name>M Dakshayini</name>
    </author>
    <author>
      <name>T R GopalaKrishnan Nair</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Computing, Volume 2, Issue 3, March 2010,
  https://sites.google.com/site/journalofcomputing/</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1003.4049v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1003.4049v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1003.4084v1</id>
    <updated>2010-03-22T06:42:05Z</updated>
    <published>2010-03-22T06:42:05Z</published>
    <title>New Classification Methods for Hiding Information into Two Parts:
  Multimedia Files and Non Multimedia Files</title>
    <summary>  With the rapid development of various multimedia technologies, more and more
multimedia data are generated and transmitted in the medical, commercial, and
military fields, which may include some sensitive information which should not
be accessed by or can only be partially exposed to the general users.
Therefore, security and privacy has become an important, Another problem with
digital document and video is that undetectable modifications can be made with
very simple and widely available equipment, which put the digital material for
evidential purposes under question .With the large flood of information and the
development of the digital format Information hiding considers one of the
techniques which used to protect the important information. The main goals for
this paper, provides a general overview of the New Classification Methods for
Hiding Information into Two Parts: Multimedia Files and Non Multimedia Files.
</summary>
    <author>
      <name>Hamdan. O. Alanazi</name>
    </author>
    <author>
      <name>A. A. Zaidan</name>
    </author>
    <author>
      <name>B. B. Zaidan</name>
    </author>
    <author>
      <name>Hamid A. Jalab</name>
    </author>
    <author>
      <name>Zaidoon Kh. AL-Ani</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Computing, Volume 2, Issue 3, March 2010</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1003.4084v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1003.4084v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1003.4637v1</id>
    <updated>2010-03-24T13:07:08Z</updated>
    <published>2010-03-24T13:07:08Z</published>
    <title>Context-Oriented Web Video Tag Recommendation</title>
    <summary>  Tag recommendation is a common way to enrich the textual annotation of
multimedia contents. However, state-of-the-art recommendation methods are built
upon the pair-wised tag relevance, which hardly capture the context of the web
video, i.e., when who are doing what at where. In this paper we propose the
context-oriented tag recommendation (CtextR) approach, which expands tags for
web videos under the context-consistent constraint. Given a web video, CtextR
first collects the multi-form WWW resources describing the same event with the
video, which produce an informative and consistent context; and then, the tag
recommendation is conducted based on the obtained context. Experiments on an
80,031 web video collection show CtextR recommends various relevant tags to web
videos. Moreover, the enriched tags improve the performance of web video
categorization.
</summary>
    <author>
      <name>Zhineng Chen</name>
    </author>
    <author>
      <name>Juan Cao</name>
    </author>
    <author>
      <name>Yicheng Song</name>
    </author>
    <author>
      <name>Junbo Guo</name>
    </author>
    <author>
      <name>Yongdong Zhang</name>
    </author>
    <author>
      <name>Jintao Li</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2 pages, 2 figures, 1 table</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 19th international conference on World wide web
  (WWW2010), April 26-30, 2010</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1003.4637v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1003.4637v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1004.1676v1</id>
    <updated>2010-04-10T03:42:06Z</updated>
    <published>2010-04-10T03:42:06Z</published>
    <title>A reversible high embedding capacity data hiding technique for hiding
  secret data in images</title>
    <summary>  As the multimedia and internet technologies are growing fast, the
transmission of digital media plays an important role in communication. The
various digital media like audio, video and images are being transferred
through internet. There are a lot of threats for the digital data that are
transferred through internet. Also, a number of security techniques have been
employed to protect the data that is transferred through internet. This paper
proposes a new technique for sending secret messages securely, using
steganographic technique. Since the proposed system uses multiple level of
security for data hiding, where the data is hidden in an image file and the
stego file is again concealed in another image. Previously, the secret message
is being encrypted with the encryption algorithm which ensures the achievement
of high security enabled data transfer through internet.
</summary>
    <author>
      <name>P. Mohan Kumar</name>
    </author>
    <author>
      <name>K. L. Shunmuganathan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE Publication format, International Journal of Computer Science
  and Information Security, IJCSIS, Vol. 7 No. 3, March 2010, USA. ISSN 1947
  5500, http://sites.google.com/site/ijcsis/</arxiv:comment>
    <link href="http://arxiv.org/abs/1004.1676v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1004.1676v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1004.1682v1</id>
    <updated>2010-04-10T04:29:01Z</updated>
    <published>2010-04-10T04:29:01Z</published>
    <title>Design And Implementation Of Multilevel Access Control In Medical Image
  Transmission Using Symmetric Polynomial Based Audio Steganography</title>
    <summary>  ...The steganography scheme makes it possible to hide the medical image in
different bit locations of host media without inviting suspicion. The Secret
file is embedded in a cover media with a key. At the receiving end the key can
be derived by all the classes which are higher in the hierarchy using symmetric
polynomial and the medical image file can be retrieved. The system is
implemented and found to be secure, fast and scalable. Simulation results show
that the system is dynamic in nature and allows any type of hierarchy. The
proposed approach performs better even during frequent member joins and leaves.
The computation cost is reduced as the same algorithm is used for key
computation and descendant key derivation. Steganographic technique used in
this paper does not use the conventional LSB's and uses two bit positions and
the hidden data occurs only from a frame which is dictated by the key that is
used. Hence the quality of stego data is improved.
</summary>
    <author>
      <name>J. Nafeesa Begum</name>
    </author>
    <author>
      <name>K. Kumar</name>
    </author>
    <author>
      <name>V. Sumathy</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE Publication format, International Journal of Computer Science
  and Information Security, IJCSIS, Vol. 7 No. 3, March 2010, USA. ISSN 1947
  5500, http://sites.google.com/site/ijcsis/</arxiv:comment>
    <link href="http://arxiv.org/abs/1004.1682v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1004.1682v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1004.1789v1</id>
    <updated>2010-04-11T11:05:33Z</updated>
    <published>2010-04-11T11:05:33Z</published>
    <title>SAR Image Segmentation using Vector Quantization Technique on Entropy
  Images</title>
    <summary>  The development and application of various remote sensing platforms result in
the production of huge amounts of satellite image data. Therefore, there is an
increasing need for effective querying and browsing in these image databases.
In order to take advantage and make good use of satellite images data, we must
be able to extract meaningful information from the imagery. Hence we proposed a
new algorithm for SAR image segmentation. In this paper we propose segmentation
using vector quantization technique on entropy image. Initially, we obtain
entropy image and in second step we use Kekre's Fast Codebook Generation (KFCG)
algorithm for segmentation of the entropy image. Thereafter, a codebook of size
128 was generated for the Entropy image. These code vectors were further
clustered in 8 clusters using same KFCG algorithm and converted into 8 images.
These 8 images were displayed as a result. This approach does not lead to over
segmentation or under segmentation. We compared these results with well known
Gray Level Co-occurrence Matrix. The proposed algorithm gives better
segmentation with less complexity.
</summary>
    <author>
      <name>H. B. Kekre</name>
    </author>
    <author>
      <name>Saylee Gharge</name>
    </author>
    <author>
      <name>Tanuja K. Sarode</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE Publication format, International Journal of Computer Science
  and Information Security, IJCSIS, Vol. 7 No. 3, March 2010, USA. ISSN 1947
  5500, http://sites.google.com/site/ijcsis/</arxiv:comment>
    <link href="http://arxiv.org/abs/1004.1789v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1004.1789v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1004.4457v1</id>
    <updated>2010-04-26T09:57:23Z</updated>
    <published>2010-04-26T09:57:23Z</published>
    <title>Combination of Subtractive Clustering and Radial Basis Function in
  Speaker Identification</title>
    <summary>  Speaker identification is the process of determining which registered speaker
provides a given utterance. Speaker identification required to make a claim on
the identity of speaker from the Ns trained speaker in its user database. In
this study, we propose the combination of clustering algorithm and the
classification technique - subtractive and Radial Basis Function (RBF). The
proposed technique is chosen because RBF is a simpler network structures and
faster learning algorithm. RBF finds the input to output map using the local
approximators which will combine the linear of the approximators and cause the
linear combiner have few weights. Besides that, RBF neural network model using
subtractive clustering algorithm for selecting the hidden node centers, which
can achieve faster training speed. In the meantime, the RBF network was trained
with a regularization term so as to minimize the variances of the nodes in the
hidden layer and perform more accu-rate prediction.
</summary>
    <author>
      <name>Ibrahim A. Albidewi</name>
    </author>
    <author>
      <name>Yap Teck Ann</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Computing online at
  https://sites.google.com/site/journalofcomputing/</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Computing, Volume 2, Issue 4, April 2010</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1004.4457v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1004.4457v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1004.4459v1</id>
    <updated>2010-04-26T10:01:53Z</updated>
    <published>2010-04-26T10:01:53Z</published>
    <title>Visual Infrared Video Fusion for Night Vision using Background
  Estimation</title>
    <summary>  Video fusion is a process that combines visual data from different sensors to
obtain a single composite video preserving the information of the sources. The
availability of a system, enhancing human ability to perceive the observed
scenario, is crucial to improve the performance of a surveillance system. The
infrared (IR) camera captures thermal image of object in night-time
environment, when only limited visual information can be captured by RGB
camera. The fusion of data recorded by an IR sensor and a visible RGB camera
can produce information otherwise not obtainable by viewing the sensor outputs
separately. In this paper we consider the problem of fusing two video streams
acquired by an RGB camera and an IR sensor. The pedestrians, distinctly
captured by IR video, are separated and fused with the RGB video. The
algorithms implemented involve estimation of the background, followed by
detection of object from the IR Video, after necessary denoising. Finally a
suitable fusion algorithm is employed to combine the extracted pedestrians with
the visual output. The obtained results clearly demonstrate the effectiveness
of the proposed video fusion scheme, for night vision.
</summary>
    <author>
      <name>Anjali Malviya</name>
    </author>
    <author>
      <name>S. G. Bhirud</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">https://sites.google.com/site/journalofcomputing/</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Computing, Volume 2, Issue 4, April 2010, 66-69</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1004.4459v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1004.4459v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1005.1757v1</id>
    <updated>2010-05-11T08:42:18Z</updated>
    <published>2010-05-11T08:42:18Z</published>
    <title>Architecture for Cooperative Prefetching in P2P Video-on- Demand System</title>
    <summary>  Most P2P VoD schemes focused on service architectures and overlays
optimization without considering segments rarity and the performance of
prefetching strategies. As a result, they cannot better support VCRoriented
service in heterogeneous environment having clients using free VCR controls.
Despite the remarkable popularity in VoD systems, there exist no prior work
that studies the performance gap between different prefetching strategies. In
this paper, we analyze and understand the performance of different prefetching
strategies. Our analytical characterization brings us not only a better
understanding of several fundamental tradeoffs in prefetching strategies, but
also important insights on the design of P2P VoD system. On the basis of this
analysis, we finally proposed a cooperative prefetching strategy called
"cooching". In this strategy, the requested segments in VCR interactivities are
prefetched into session beforehand using the information collected through
gossips. We evaluate our strategy through extensive simulations. The results
indicate that the proposed strategy outperforms the existing prefetching
mechanisms.
</summary>
    <author>
      <name>Ubaid Abbasi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Bordeaux, France</arxiv:affiliation>
    </author>
    <author>
      <name>Toufik Ahmed</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Bordeaux, France</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5121/ijcnc.2010.2310</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5121/ijcnc.2010.2310" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 Pages, IJCNC</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Networks &amp; Communications 2.3
  (2010) 126-138</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1005.1757v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1005.1757v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1005.4014v1</id>
    <updated>2010-05-21T17:18:29Z</updated>
    <published>2010-05-21T17:18:29Z</published>
    <title>A Study on Potential of Integrating Multimodal Interaction into Musical
  Conducting Education</title>
    <summary>  With the rapid development of computer technology, computer music has begun
to appear in the laboratory. Many potential utility of computer music is
gradually increasing. The purpose of this paper is attempted to analyze the
possibility of integrating multimodal interaction such as vision-based hand
gesture and speech interaction into musical conducting education. To achieve
this purpose, this paper is focus on discuss some related research and the
traditional musical conducting education. To do so, six musical conductors had
been interviewed to share their musical conducting learning/ teaching
experience. These interviews had been analyzed in this paper to show the
syllabus and the focus of musical conducting education for beginners.
</summary>
    <author>
      <name>Gilbert Phuah Leong Siang</name>
    </author>
    <author>
      <name>Nor Azman Ismail</name>
    </author>
    <author>
      <name>Pang Yee Yong</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">http://www.journalofcomputing.org</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Computing, Volume 2, Issue 5, May 2010</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1005.4014v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1005.4014v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1005.4267v1</id>
    <updated>2010-05-24T07:28:24Z</updated>
    <published>2010-05-24T07:28:24Z</published>
    <title>Content Base Image Retrieval Using Phong Shading</title>
    <summary>  The digital image data is rapidly expanding in quantity and heterogeneity.
The traditional information retrieval techniques does not meet the user's
demand, so there is need to develop an efficient system for content based image
retrieval. Content based image retrieval means retrieval of images from
database on the basis of visual features of image like as color, texture etc.
In our proposed method feature are extracted after applying Phong shading on
input image. Phong shading, flattering out the dull surfaces of the image The
features are extracted using color, texture &amp; edge density methods. Feature
extracted values are used to find the similarity between input query image and
the data base image. It can be measure by the Euclidean distance formula. The
experimental result shows that the proposed approach has a better retrieval
results with phong shading.
</summary>
    <author>
      <name>Uday Pratap Singh</name>
    </author>
    <author>
      <name>Sanjeev Jain</name>
    </author>
    <author>
      <name>Gulfishan Firdose Ahmed</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE Publication format, International Journal of Computer Science
  and Information Security, IJCSIS, Vol. 8 No. 1, April 2010, USA. ISSN 1947
  5500, http://sites.google.com/site/ijcsis/</arxiv:comment>
    <link href="http://arxiv.org/abs/1005.4267v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1005.4267v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1005.5436v1</id>
    <updated>2010-05-29T08:00:39Z</updated>
    <published>2010-05-29T08:00:39Z</published>
    <title>Client-to-Client Streaming Scheme for VOD Applications</title>
    <summary>  In this paper, we propose an efficient client-to-client streaming approach to
cooperatively stream the video using chaining technique with unicast
communication among the clients. This approach considers two major issues of
VoD 1) Prefix caching scheme to accommodate more number of videos closer to
client, so that the request-service delay for the user can be minimized. 2)
Cooperative proxy and client chaining scheme for streaming the videos using
unicasting. This approach minimizes the client rejection rate and bandwidth
requirement on server to proxy and proxy to client path. Our simulation results
show that the proposed approach achieves reduced client waiting time and
optimal prefix caching of videos minimizing server to proxy path bandwidth
usage by utilizing the client to client bandwidth, which is occasionally used
when compared to busy server to proxy path bandwidth.
</summary>
    <author>
      <name>M. Dakshayini</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Dr.MGR University, India</arxiv:affiliation>
    </author>
    <author>
      <name>T. R. Gopala Krishnan Nair</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Research and Industry Incubation Centre - Bangalore, India</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5121/ijma.2010.2204</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5121/ijma.2010.2204" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 Pages, IJMA</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International journal of Multimedia &amp; Its Applications 2.2 (2010)
  46-55</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1005.5436v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1005.5436v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1005.5613v1</id>
    <updated>2010-05-31T08:11:59Z</updated>
    <published>2010-05-31T08:11:59Z</published>
    <title>An Automated Algorithm for Approximation of Temporal Video Data Using
  Linear B'EZIER Fitting</title>
    <summary>  This paper presents an efficient method for approximation of temporal video
data using linear Bezier fitting. For a given sequence of frames, the proposed
method estimates the intensity variations of each pixel in temporal dimension
using linear Bezier fitting in Euclidean space. Fitting of each segment ensures
upper bound of specified mean squared error. Break and fit criteria is employed
to minimize the number of segments required to fit the data. The proposed
method is well suitable for lossy compression of temporal video data and
automates the fitting process of each pixel. Experimental results show that the
proposed method yields good results both in terms of objective and subjective
quality measurement parameters without causing any blocking artifacts.
</summary>
    <author>
      <name>Murtaza Ali Khan</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Royal University for Women, Bahrain</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5121/ijma.2010.2207</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5121/ijma.2010.2207" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 Pages, IJMA 2010</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International journal of Multimedia &amp; Its Applications 2.2 (2010)
  81-94</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1005.5613v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1005.5613v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1007.1233v1</id>
    <updated>2010-07-01T09:40:40Z</updated>
    <published>2010-07-01T09:40:40Z</published>
    <title>An Alternative Approach of Steganography using Reference Image</title>
    <summary>  This paper is to create a practical steganographic implementation for 4-bit
images.The proposed technique converts 4 bit image into 4 shaded Gray Scale
image. This image will be act as reference image to hide the text. Using this
grey scale reference image any text can be hidden. Single character of a text
can be represented by 8-bit. The 8-bit character can be split into 4X2 bit
information. If the reference image and the data file are transmitted through
network separately, we can achieve the effect of Steganography. Here the image
is not at all distorted because said image is only used for referencing. Any
huge mount of text material can be hidden using a very small image. Decipher
the text is not possible intercepting the image or data file separately. So, it
is more secure.
</summary>
    <author>
      <name>Samir Kumar Bandyopadhyay</name>
    </author>
    <author>
      <name>Indra Kanta Maitra</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">http://ijict.org/index.php/ijoat/article/view/approach-of-stegnagraphy .
  arXiv admin note: text overlap with
  http://dx.doi.org/10.1016/j.sigpro.2009.08.010 by other authors without
  attribution</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Advancements in Technology, Vol 1, No 1
  (2010)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1007.1233v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1007.1233v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1007.5136v1</id>
    <updated>2010-07-29T07:41:51Z</updated>
    <published>2010-07-29T07:41:51Z</published>
    <title>Perceptual Copyright Protection Using Multiresolution Wavelet-Based
  Watermarking And Fuzzy Logic</title>
    <summary>  In this paper, an efficiently DWT-based watermarking technique is proposed to
embed signatures in images to attest the owner identification and discourage
the unauthorized copying. This paper deals with a fuzzy inference filter to
choose the larger entropy of coefficients to embed watermarks. Unlike most
previous watermarking frameworks which embedded watermarks in the larger
coefficients of inner coarser subbands, the proposed technique is based on
utilizing a context model and fuzzy inference filter by embedding watermarks in
the larger-entropy coefficients of coarser DWT subbands. The proposed
approaches allow us to embed adaptive casting degree of watermarks for
transparency and robustness to the general image-processing attacks such as
smoothing, sharpening, and JPEG compression. The approach has no need the
original host image to extract watermarks. Our schemes have been shown to
provide very good results in both image transparency and robustness.
</summary>
    <author>
      <name>Ming-Shing Hsieh</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Aletheia University, Taiwan</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5121/ijaia.2010.1304</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5121/ijaia.2010.1304" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 7 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Artificial Intelligence &amp; Applications
  1.3 (2010) 45-57</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1007.5136v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1007.5136v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1008.0757v1</id>
    <updated>2010-08-04T12:01:39Z</updated>
    <published>2010-08-04T12:01:39Z</published>
    <title>Web Video Categorization based on Wikipedia Categories and
  Content-Duplicated Open Resources</title>
    <summary>  This paper presents a novel approach for web video categorization by
leveraging Wikipedia categories (WikiCs) and open resources describing the same
content as the video, i.e., content-duplicated open resources (CDORs). Note
that current approaches only col-lect CDORs within one or a few media forms and
ignore CDORs of other forms. We explore all these resources by utilizing WikiCs
and commercial search engines. Given a web video, its discrimin-ative Wikipedia
concepts are first identified and classified. Then a textual query is
constructed and from which CDORs are collected. Based on these CDORs, we
propose to categorize web videos in the space spanned by WikiCs rather than
that spanned by raw tags. Experimental results demonstrate the effectiveness of
both the proposed CDOR collection method and the WikiC voting catego-rization
algorithm. In addition, the categorization model built based on both WikiCs and
CDORs achieves better performance compared with the models built based on only
one of them as well as state-of-the-art approach.
</summary>
    <author>
      <name>Zhineng Chen</name>
    </author>
    <author>
      <name>Juan Cao</name>
    </author>
    <author>
      <name>Yicheng Song</name>
    </author>
    <author>
      <name>Yongdong Zhang</name>
    </author>
    <author>
      <name>Jintao Li</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 3 figures, 2 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1008.0757v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1008.0757v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1008.3741v2</id>
    <updated>2012-03-04T22:07:22Z</updated>
    <published>2010-08-23T03:06:22Z</published>
    <title>Reliable Multicasting for Device-to-Device Radio Underlaying Cellular
  Networks</title>
    <summary>  This paper proposes Leader in Charge (LiC), a reliable multicast architecture
for device-to-device (D2D) radio underlaying cellular networks. The
multicast-requesting user equipments (UEs) in close proximity form a D2D
cluster to receive the multicast packets through cooperation. In addition to
receiving the multicast packets from the eNB, UEs share what they received from
the multicast on short-range links among UEs, namely the D2D links, to exploit
the wireless resources a more efficient way. Consequently, we show that
utilizing the D2D links in cellular networks increases the throughput of a
multicast session by means of simulation. We also discuss some practical issues
facing the integration of LiC into the current cellular networks. In
particular, we propose efficient delay control mechanism to reduce the average
and maximum delay experienced by LiC users, which is further confirmed by the
simulation results.
</summary>
    <author>
      <name>Wei Yang</name>
    </author>
    <author>
      <name>Wanlu Sun</name>
    </author>
    <author>
      <name>Lihua Li</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper has been withdrawn</arxiv:comment>
    <link href="http://arxiv.org/abs/1008.3741v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1008.3741v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1009.1170v1</id>
    <updated>2010-09-06T22:33:38Z</updated>
    <published>2010-09-06T22:33:38Z</published>
    <title>M-Learning: A New Paradigm of Learning Mathematics in Malaysia</title>
    <summary>  M-Learning is a new learning paradigm of the new social structure with mobile
and wireless technologies.Smart school is one of the four flagship applications
for Multimedia Super Corridor (MSC) under Malaysian government initiative to
improve education standard in the country. With the advances of mobile devices
technologies, mobile learning could help the government in realizing the
initiative. This paper discusses the prospect of implementing mobile learning
for primary school students. It indicates significant and challenges and
analysis of user perceptions on potential mobile applications through a survey
done in primary school context. The authors propose the m-Learning for
mathematics by allowing the extension of technology in the traditional
classroom in term of learning and teaching.
</summary>
    <author>
      <name>Saipunidzam Mahamad</name>
    </author>
    <author>
      <name>Mohammad Noor Ibrahim</name>
    </author>
    <author>
      <name>Shakirah Mohd Taib</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5121/ijcsit.2010.2407</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5121/ijcsit.2010.2407" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Wireless technology, teaching mathematics, flexible learning,
  m-Learning</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International journal of computer science &amp; information Technology
  (IJCSIT) Vol 2 No 4 (2010) pp 76-86</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1009.1170v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1009.1170v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="K.3.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1012.1882v1</id>
    <updated>2010-12-08T21:45:16Z</updated>
    <published>2010-12-08T21:45:16Z</published>
    <title>Evaluating Modelling Approaches for Medical Image Annotations</title>
    <summary>  Information system designers face many challenges w.r.t. selecting
appropriate semantic technologies and deciding on a modelling approach for
their system. However, there is no clear methodology yet to evaluate
"semantically enriched" information systems. In this paper we present a case
study on different modelling approaches for annotating medical images and
introduce a conceptual framework that can be used to analyse the fitness of
information systems and help designers to spot the strengths and weaknesses of
various modelling approaches as well as managing trade-offs between modelling
effort and their potential benefits.
</summary>
    <author>
      <name>Jasmin Opitz</name>
    </author>
    <author>
      <name>Bijan Parsia</name>
    </author>
    <author>
      <name>Ulrike Sattler</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">in Adrian Paschke, Albert Burger, Andrea Splendiani, M. Scott
  Marshall, Paolo Romano: Proceedings of the 3rd International Workshop on
  Semantic Web Applications and Tools for the Life Sciences, Berlin,Germany,
  December 8-10, 2010</arxiv:comment>
    <link href="http://arxiv.org/abs/1012.1882v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1012.1882v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1012.2965v1</id>
    <updated>2010-12-14T08:50:29Z</updated>
    <published>2010-12-14T08:50:29Z</published>
    <title>Digital watermarking : An approach based on Hilbert transform</title>
    <summary>  Most of the well known algorithms for watermarking of digital images involve
transformation of the image data to Fourier or singular vector space. In this
paper, we introduce watermarking in Hilbert transform domain for digital media.
Generally, if the image is a matrix of order $m$ by $n$, then the transformed
space is also an image of the same order. However, with Hilbert transforms, the
transformed space is of order $2m$ by $2n$. This allows for more latitude in
storing the watermark in the host image. Based on this idea, we propose an
algorithm for embedding and extracting watermark in a host image and
analytically obtain a parameter related to this procedure. Using extensive
simulations, we show that the algorithm performs well even if the host image is
corrupted by various attacks.
</summary>
    <author>
      <name>Rashmi Agarwal</name>
    </author>
    <author>
      <name>R. Krishnan</name>
    </author>
    <author>
      <name>M. S. Santhanam</name>
    </author>
    <author>
      <name>K. Srinivas</name>
    </author>
    <author>
      <name>K. Venugopalan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 Pages, 52 Figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1012.2965v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1012.2965v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1101.5127v1</id>
    <updated>2011-01-13T15:01:12Z</updated>
    <published>2011-01-13T15:01:12Z</published>
    <title>A Color Image Digital Watermarking Scheme Based on SOFM</title>
    <summary>  Digital watermarking technique has been presented and widely researched to
solve some important issues in the digital world, such as copyright protection,
copy protection and content authentication. Several robust watermarking schemes
based on vector quantization (VQ) have been presented. In this paper, we
present a new digital image watermarking method based on SOFM vector quantizer
for color images. This method utilizes the codebook partition technique in
which the watermark bit is embedded into the selected VQ encoded block. The
main feature of this scheme is that the watermark exists both in VQ compressed
image and in the reconstructed image. The watermark extraction can be performed
without the original image. The watermark is hidden inside the compressed
image, so much transmission time and storage space can be saved when the
compressed data are transmitted over the Internet. Simulation results
demonstrate that the proposed method has robustness against various image
processing operations without sacrificing compression performance and the
computational speed.
</summary>
    <author>
      <name>J. Anitha</name>
    </author>
    <author>
      <name>S. Immanuel Alex Pandian</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Science Issues online at
  http://www.ijcsi.org</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IJCSI, Volume 7, Issue 5, September 2010</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1101.5127v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1101.5127v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1102.5699v1</id>
    <updated>2011-02-28T16:13:20Z</updated>
    <published>2011-02-28T16:13:20Z</published>
    <title>Ontology based approach for video transmission over the network</title>
    <summary>  With the increase in the bandwidth &amp; the transmission speed over the
internet, transmission of multimedia objects like video, audio, images has
become an easier work. In this paper we provide an approach that can be useful
for transmission of video objects over the internet without much fuzz. The
approach provides a ontology based framework that is used to establish an
automatic deployment of video transmission system. Further the video is
compressed using the structural flow mechanism that uses the wavelet principle
for compression of video frames. Finally the video transmission algorithm known
as RRDBFSF algorithm is provided that makes use of the concept of restrictive
flooding to avoid redundancy thereby increasing the efficiency.
</summary>
    <author>
      <name>Rachit Mohan Garg</name>
    </author>
    <author>
      <name>Yamini Sood</name>
    </author>
    <author>
      <name>Neha Tyagi</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5121/ijma.2011.3106</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5121/ijma.2011.3106" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 2 figures, 4 tables</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">The International journal of Multimedia &amp; Its Applications (IJMA)
  Vol.3, No.1, February 2011</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1102.5699v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1102.5699v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1102.5769v1</id>
    <updated>2011-02-28T20:47:08Z</updated>
    <published>2011-02-28T20:47:08Z</published>
    <title>Multimedia Database Applications: Issues and Concerns for Classroom
  Teaching</title>
    <summary>  The abundance of multimedia data and information is challenging educators to
effectively search, browse, access, use, and store the data for their classroom
teaching. However, many educators could still be accustomed to teaching or
searching for information using conventional methods, but often the
conventional methods may not function well with multimedia data. Educators need
to efficiently interact and manage a variety of digital media files too. The
purpose of this study is to review current multimedia database applications in
teaching and learning, and further discuss some of the issues or concerns that
educators may have while incorporating multimedia data into their classrooms.
Some strategies and recommendations are also provided in order for educators to
be able to use multimedia data more effectively in their teaching environments.
</summary>
    <author>
      <name>Chien Yu</name>
    </author>
    <author>
      <name>Teri Brandenburg</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages and 22 references</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">The International Journal of Multimedia &amp; Its Applications, 3(1),
  2011</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1102.5769v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1102.5769v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.0065v1</id>
    <updated>2011-03-01T02:02:54Z</updated>
    <published>2011-03-01T02:02:54Z</published>
    <title>Interdisciplinary Collaboration through Designing 3D Simulation Case
  Studies</title>
    <summary>  Interdisciplinary collaboration is essential for the advance of research. As
domain subjects become more and more specialized, researchers need to cross
disciplines for insights from peers in other areas to have a broader and deeper
understand of a topic at micro- and macro-levels. We developed a 3D virtual
learning environment that served as a platform for faculty to plan curriculum,
share educational beliefs, and conduct cross-discipline research for effective
learning. Based upon the scripts designed by faculty from five disciplines,
virtual doctors, nurses, or patients interact in a 3D virtual hospital. The
teaching vignettes were then converted to video clips, allowing users to view,
pause, replay, or comment on the videos individually or in groups. Unlike many
existing platforms, we anticipated a value-added by adding a social networking
capacity to this virtual environment. The focus of this paper is on the
cost-efficiency and system design of the virtual learning environment.
</summary>
    <author>
      <name>Xin Bai</name>
    </author>
    <author>
      <name>Dana Fusco</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5121/ijma.2011.3109</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5121/ijma.2011.3109" rel="related"/>
    <link href="http://arxiv.org/abs/1103.0065v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.0065v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.0829v1</id>
    <updated>2011-03-04T05:38:59Z</updated>
    <published>2011-03-04T05:38:59Z</published>
    <title>Hiding Secret Information in Movie Clip: A Steganographic Approach</title>
    <summary>  Establishing hidden communication is an important subject of discussion that
has gained increasing importance nowadays with the development of the internet.
One of the key methods for establishing hidden communication is steganography.
Modern day steganography mainly deals with hiding information within files like
image, text, html, binary files etc. These file contains small irrelevant
information that can be substituted for small secret data. To store a high
capacity secret data these carrier files are not very supportive. To overcome
the problem of storing the high capacity secret data with the utmost security
fence, we have proposed a novel methodology for concealing a voluminous data
with high levels of security wall by using movie clip as a carrier file.
</summary>
    <author>
      <name>G. Sahoo</name>
    </author>
    <author>
      <name>Rajesh Kumar Tiwari</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Steganography, Frame, Stego-Frame, Stego-key, and Carrier</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computing and Applications, Vol. 4, No.
  1, June 2009, pp. 87-94</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1103.0829v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.0829v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.2.2; I.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.0837v1</id>
    <updated>2011-03-04T07:40:44Z</updated>
    <published>2011-03-04T07:40:44Z</published>
    <title>Priority based Interface Selection for Overlaying Heterogeneous Networks</title>
    <summary>  Offering of different attractive opportunities by different wireless
technologies trends the convergence of heterogeneous networks for the future
wireless communication system. To make a seamless handover among the
heterogeneous networks, the optimization of the power consumption, and optimal
selection of interface are the challenging issues for convergence networks. The
access of multi interfaces simultaneously reduces the handover latency and data
loss in heterogeneous handover. The mobile node (MN) maintains one interface
connection while other interface is used for handover process. However, it
causes much battery power consumption. In this paper we propose an efficient
interface selection scheme including interface selection algorithms, interface
selection procedures considering battery power consumption and user mobility
with other existing parameters for overlaying networks. We also propose a
priority based network selection scheme according to the service types. MN's
battery power level, provision of QoS/QoE in the target network and our
proposed priority parameters are considered as more important parameters for
our interface selection algorithm. The performances of the proposed scheme are
verified using numerical analysis.
</summary>
    <author>
      <name>Mostafa Zaman Chowdhury</name>
    </author>
    <author>
      <name>Yeong Min Jang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 7 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">The Journal of Korea Information and Communications Soceity
  (KICS,), Vol. 35, No. 7, July 2010</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1103.0837v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.0837v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.3802v1</id>
    <updated>2011-03-19T18:43:30Z</updated>
    <published>2011-03-19T18:43:30Z</published>
    <title>Stage Staffing Scheme for Copyright Protection in Multimedia</title>
    <summary>  Copyright protection has become a need in today's world. To achieve a secure
copyright protection we embedded some information in images and videos and that
image or video is called copyright protected. The embedded information can't be
detected by human eye but some attacks and operations can tamper that
information to breach protection. So in order to find a secure technique of
copyright protection, we have analyzed image processing techniques i.e. Spatial
Domain (Least Significant Bit (LSB)), Transform Domain (Discrete Cosine
Transform (DCT)), Discrete Wavelet Transform (DWT) and there are numerous
algorithm for watermarking using them. After having a good understanding of the
same we have proposed a novel algorithm named as Stage Staffing Algorithm that
generates results with high effectiveness, additionally we can use self
extracted-watermark technique to increase the security and automate the process
of watermark image. The proposed algorithm provides protection in three stages.
We have implemented the algorithm and results of the simulations are shown. The
various factors affecting spatial domain watermarking are also discussed.
</summary>
    <author>
      <name>Sumit Kumar</name>
    </author>
    <author>
      <name>Santosh Kumar</name>
    </author>
    <author>
      <name>Sukumar Nandi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 7 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Network Security &amp; Its Applications
  (IJNSA), Vol.3, No.2, March 2011</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1103.3802v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.3802v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1104.0809v1</id>
    <updated>2011-04-05T11:06:30Z</updated>
    <published>2011-04-05T11:06:30Z</published>
    <title>SLDs for Visualizing Multicolor Elevation Contour Lines in Geo-Spatial
  Web Applications</title>
    <summary>  This paper addresses the need for geospatial consumers (either humans or
machines) to visualize multicolored elevation contour poly lines with respect
their different contour intervals and control the visual portrayal of the data
with which they work. The current OpenGIS Web Map Service (WMS) specification
supports the ability for an information provider to specify very basic styling
options by advertising a preset collection of visual portrayals for each
available data set. However, while a WMS currently can provide the user with a
choice of style options, the WMS can only tell the user the name of each style.
It cannot tell the user what portrayal will look like on the map. More
importantly, the user has no way of defining their own styling rules. The
ability for a human or machine client to define these rules requires a styling
language that the client and server can both understand. Defining this
language, called the StyledLayerDescriptor (SLD), is the main focus of this
paper, and it can be used to portray the output of Web Map Servers, Web Feature
Servers and Web Coverage Servers.
</summary>
    <author>
      <name>B. G. Kodge</name>
    </author>
    <author>
      <name>P. S. Hiremath</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">World of Computer Science and Information Technology Journal
  (WCSIT), ISSN: 2221-0741, Vol. 1, No. 2, 39-43, 2011</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1104.0809v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1104.0809v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1105.0699v1</id>
    <updated>2011-05-03T21:57:18Z</updated>
    <published>2011-05-03T21:57:18Z</published>
    <title>Robust Sign Language Recognition System Using ToF Depth Cameras</title>
    <summary>  Sign language recognition is a difficult task, yet required for many
applications in real-time speed. Using RGB cameras for recognition of sign
languages is not very successful in practical situations and accurate 3D
imaging requires expensive and complex instruments. With introduction of
Time-of-Flight (ToF) depth cameras in recent years, it has become easier to
scan the environment for accurate, yet fast depth images of the objects without
the need of any extra calibrating object. In this paper, a robust system for
sign language recognition using ToF depth cameras is presented for converting
the recorded signs to a standard and portable XML sign language named SiGML for
easy transferring and converting to real-time 3D virtual characters animations.
Feature extraction using moments and classification using nearest neighbor
classifier are used to track hand gestures and significant result of 100% is
achieved for the proposed approach.
</summary>
    <author>
      <name>Morteza Zahedi</name>
    </author>
    <author>
      <name>Ali Reza Manashty</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 Pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">World of Computer Science and Information Technology Journal
  (WCSIT), Vol. 1, No. 3, 50-55, 2011</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1105.0699v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1105.0699v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1105.0826v1</id>
    <updated>2011-05-04T13:46:31Z</updated>
    <published>2011-05-04T13:46:31Z</published>
    <title>Streaming Multimedia Information Using the Features of the DVB-S Card</title>
    <summary>  This paper presents a study of audio-video streaming using the additional
possibilities of a DVB-S card. The board used for experiments (Technisat
SkyStar 2) is one of the most frequently used cards for this purpose. Using the
main blocks of the board's software support it is possible the implement a
really useful and full functional system for audio-video streaming. The
streaming is possible to be implemented either for decoded MPEG stream or for
transport stream. In this last case it is possible to view not only a program,
but any program from the same multiplex. This allows us to implement
</summary>
    <author>
      <name>Radu Arsinte</name>
    </author>
    <author>
      <name>Eugen Lupu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 5 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Scientific Bulletin of the "Politehnica" University Timi\c{s}oara,
  Transaction on Electronics and Telecomunications, Tom 51(65), Fascicola 1-2,
  pag. 181-184, 2006</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1105.0826v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1105.0826v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1105.1561v2</id>
    <updated>2011-08-03T18:57:17Z</updated>
    <published>2011-05-09T00:07:56Z</published>
    <title>Efficient Image Transmission Through Analog Error Correction</title>
    <summary>  This paper presents a new paradigm for image transmission through analog
error correction codes. Conventional schemes rely on digitizing images through
quantization (which inevitably causes significant bandwidth expansion) and
transmitting binary bit-streams through digital error correction codes (which
do not automatically differentiate the different levels of significance among
the bits). To strike a better overall performance in terms of transmission
efficiency and quality, we propose to use a single analog error correction code
in lieu of digital quantization, digital code and digital modulation. The key
is to get analog coding right. We show that this can be achieved by cleverly
exploiting an elegant "butterfly" property of chaotic systems. Specifically, we
demonstrate a tail-biting triple-branch baker's map code and its
maximum-likelihood decoding algorithm. Simulations show that the proposed
analog code can actually outperform digital turbo code, one of the best codes
known to date. The results and findings discussed in this paper speak volume
for the promising potential of analog codes, in spite of their rather short
history.
</summary>
    <author>
      <name>Yang Liu</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Tiffany</arxiv:affiliation>
    </author>
    <author>
      <name> Jing</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Tiffany</arxiv:affiliation>
    </author>
    <author>
      <name> Li</name>
    </author>
    <author>
      <name>Kai Xie</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1105.1561v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1105.1561v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1105.1948v1</id>
    <updated>2011-05-10T13:55:31Z</updated>
    <published>2011-05-10T13:55:31Z</published>
    <title>Analytical Classification of Multimedia Index Structures by Using a
  Partitioning Method-Based Framework</title>
    <summary>  Due to the advances in hardware technology and increase in production of
multimedia data in many applications, during the last decades, multimedia
databases have become increasingly important. Contentbased multimedia retrieval
is one of an important research area in the field of multimedia databases. Lots
of research on this field has led to proposition of different kinds of index
structures to support fast and efficient similarity search to retrieve
multimedia data from these databases. Due to variety and plenty of proposed
index structures, we suggest a systematic framework based on partitioning
method used in these structures to classify multimedia index structures, and
then we evaluated these structures based on important functional measures. We
hope this proposed framework will lead to empirical and technical comparison of
multimedia index structures and development of more efficient structures at
future.
</summary>
    <author>
      <name>Mohammadreza keyvanpour</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Computer Engineering, Alzahra University, Tehran, Iran</arxiv:affiliation>
    </author>
    <author>
      <name>Najva Izadpanah</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Department of Computer Engineering, Islamic Azad University, Qazvin Branch, Qazvin, Iran</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">The International Journal of Multimedia &amp; Its Applications (IJMA)
  Vol.3, No.1, February 2011</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1105.1948v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1105.1948v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1105.2344v1</id>
    <updated>2011-05-12T00:43:46Z</updated>
    <published>2011-05-12T00:43:46Z</published>
    <title>Learning content similarity for music recommendation</title>
    <summary>  Many tasks in music information retrieval, such as recommendation, and
playlist generation for online radio, fall naturally into the query-by-example
setting, wherein a user queries the system by providing a song, and the system
responds with a list of relevant or similar song recommendations. Such
applications ultimately depend on the notion of similarity between items to
produce high-quality results. Current state-of-the-art systems employ
collaborative filter methods to represent musical items, effectively comparing
items in terms of their constituent users. While collaborative filter
techniques perform well when historical data is available for each item, their
reliance on historical data impedes performance on novel or unpopular items. To
combat this problem, practitioners rely on content-based similarity, which
naturally extends to novel items, but is typically out-performed by
collaborative filter methods.
  In this article, we propose a method for optimizing contentbased similarity
by learning from a sample of collaborative filter data. The optimized
content-based similarity metric can then be applied to answer queries on novel
and unpopular items, while still maintaining high recommendation accuracy. The
proposed system yields accurate and efficient representations of audio content,
and experimental results show significant improvements in accuracy over
competing content-based recommendation techniques.
</summary>
    <author>
      <name>Brian McFee</name>
    </author>
    <author>
      <name>Luke Barrington</name>
    </author>
    <author>
      <name>Gert Lanckriet</name>
    </author>
    <link href="http://arxiv.org/abs/1105.2344v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1105.2344v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1105.5675v1</id>
    <updated>2011-05-28T00:44:54Z</updated>
    <published>2011-05-28T00:44:54Z</published>
    <title>Scale-Invariant Local Descriptor for Event Recognition in 1D Sensor
  Signals</title>
    <summary>  In this paper, we introduce a shape-based, time-scale invariant feature
descriptor for 1-D sensor signals. The time-scale invariance of the feature
allows us to use feature from one training event to describe events of the same
semantic class which may take place over varying time scales such as walking
slow and walking fast. Therefore it requires less training set. The descriptor
takes advantage of the invariant location detection in the scale space theory
and employs a high level shape encoding scheme to capture invariant local
features of events. Based on this descriptor, a scale-invariant classifier with
"R" metric (SIC-R) is designed to recognize multi-scale events of human
activities. The R metric combines the number of matches of keypoint in scale
space with the Dynamic Time Warping score. SICR is tested on various types of
1-D sensors data from passive infrared, accelerometer and seismic sensors with
more than 90% classification accuracy.
</summary>
    <author>
      <name>Jierui Xie</name>
    </author>
    <author>
      <name>Mandis S. Beigi</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE International Conference on Multimedia &amp;
  Expo(ICME),Page(s):1226 - 1229, 2009</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1105.5675v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1105.5675v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1106.4451v1</id>
    <updated>2011-06-22T14:01:51Z</updated>
    <published>2011-06-22T14:01:51Z</published>
    <title>Activities of Daily Living Indexing by Hierarchical HMM for Dementia
  Diagnostics</title>
    <summary>  This paper presents a method for indexing human ac- tivities in videos
captured from a wearable camera being worn by patients, for studies of
progression of the dementia diseases. Our method aims to produce indexes to
facilitate the navigation throughout the individual video recordings, which
could help doctors search for early signs of the dis- ease in the activities of
daily living. The recorded videos have strong motion and sharp lighting
changes, inducing noise for the analysis. The proposed approach is based on a
two steps analysis. First, we propose a new approach to segment this type of
video, based on apparent motion. Each segment is characterized by two original
motion de- scriptors, as well as color, and audio descriptors. Second, a
Hidden-Markov Model formulation is used to merge the multimodal audio and video
features, and classify the test segments. Experiments show the good properties
of the ap- proach on real data.
</summary>
    <author>
      <name>Svebor Karaman</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LaBRI</arxiv:affiliation>
    </author>
    <author>
      <name>Jenny Benois-Pineau</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LaBRI</arxiv:affiliation>
    </author>
    <author>
      <name>Jean-François Dartigues</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">ISPED</arxiv:affiliation>
    </author>
    <author>
      <name>Yann Gaëstel</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">ISPED</arxiv:affiliation>
    </author>
    <author>
      <name>Rémi Mégret</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IMS</arxiv:affiliation>
    </author>
    <author>
      <name>Julien Pinquier</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IRIT</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/CBMI.2011.5972524</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/CBMI.2011.5972524" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2011 9th International Workshop on Content-Based Multimedia Indexing
  (CBMI), Madrid : Spain (2011)</arxiv:comment>
    <link href="http://arxiv.org/abs/1106.4451v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1106.4451v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1107.2222v1</id>
    <updated>2011-07-12T09:21:37Z</updated>
    <published>2011-07-12T09:21:37Z</published>
    <title>Study of a Hybrid - Analog TV and Ethernet- Home Data Link using a
  Coaxial Cable</title>
    <summary>  The paper presents an implementation and compatibility tests of a simple home
network implemented in a nonconventional manner using a CATV coaxial cable.
Reusing the cable, normally designated to supply RF modulated TV signals from
cable TV networks, makes possible to add data services as well. A short
presentation of the technology is given with an investigation of the main
performances obtained using this technique. The measurements revealed that this
simple solution makes possible to have both TV and data services with
performances close to traditional home data services: cable modems or ADSL,
with minimal investments. This technology keeps also open the possibility for
future improvements of the network: DVB-C or Data via Cable Modems.
</summary>
    <author>
      <name>Radu Arsinte</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 12 figures; Acta Technica Napocensis, Electronics and
  telecommunications, No.1/2007</arxiv:comment>
    <link href="http://arxiv.org/abs/1107.2222v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1107.2222v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1109.1145v1</id>
    <updated>2011-09-06T11:12:55Z</updated>
    <published>2011-09-06T11:12:55Z</published>
    <title>A Survey on Web Multimedia Mining</title>
    <summary>  Modern developments in digital media technologies has made transmitting and
storing large amounts of multi/rich media data (e.g. text, images, music, video
and their combination) more feasible and affordable than ever before. However,
the state of the art techniques to process, mining and manage those rich media
are still in their infancy. Advances developments in multimedia acquisition and
storage technology the rapid progress has led to the fast growing incredible
amount of data stored in databases. Useful information to users can be revealed
if these multimedia files are analyzed. Multimedia mining deals with the
extraction of implicit knowledge, multimedia data relationships, or other
patterns not explicitly stored in multimedia files. Also in retrieval, indexing
and classification of multimedia data with efficient information fusion of the
different modalities is essential for the system's overall performance. The
purpose of this paper is to provide a systematic overview of multimedia mining.
This article is also represents the issues in the application process component
for multimedia mining followed by the multimedia mining models.
</summary>
    <author>
      <name>Pravin M. Kamde</name>
    </author>
    <author>
      <name>Dr. Siddu. P. Algur</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5121/ijma</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5121/ijma" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 Pages; The International Journal of Multimedia &amp; Its Applications
  (IJMA) Vol.3, No.3, August 2011</arxiv:comment>
    <link href="http://arxiv.org/abs/1109.1145v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1109.1145v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="A.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1109.2325v1</id>
    <updated>2011-09-11T16:24:00Z</updated>
    <published>2011-09-11T16:24:00Z</published>
    <title>Secured color image watermarking technique in DWT-DCT domain</title>
    <summary>  The multilayer secured DWT-DCT and YIQ color space based image watermarking
technique with robustness and better correlation is presented here. The
security levels are increased by using multiple pn sequences, Arnold
scrambling, DWT domain, DCT domain and color space conversions. Peak signal to
noise ratio and Normalized correlations are used as measurement metrics. The
512x512 sized color images with different histograms are used for testing and
watermark of size 64x64 is embedded in HL region of DWT and 4x4 DCT is used.
'Haar' wavelet is used for decomposition and direct flexing factor is used. We
got PSNR value is 63.9988 for flexing factor k=1 for Lena image and the maximum
NC 0.9781 for flexing factor k=4 in Q color space. The comparative performance
in Y, I and Q color space is presented. The technique is robust for different
attacks like scaling, compression, rotation etc.
</summary>
    <author>
      <name>Baisa L. Gunjal</name>
    </author>
    <author>
      <name>Suresh N. Mali</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages; International Journal of Computer Science, Engineering and
  Information Technology (IJCSEIT), Vol.1, No. 3, August 2011</arxiv:comment>
    <link href="http://arxiv.org/abs/1109.2325v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1109.2325v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1110.6895v1</id>
    <updated>2011-10-31T18:44:41Z</updated>
    <published>2011-10-31T18:44:41Z</published>
    <title>Multi-Layer Local Graph Words for Object Recognition</title>
    <summary>  In this paper, we propose a new multi-layer structural approach for the task
of object based image retrieval. In our work we tackle the problem of
structural organization of local features. The structural features we propose
are nested multi-layered local graphs built upon sets of SURF feature points
with Delaunay triangulation. A Bag-of-Visual-Words (BoVW) framework is applied
on these graphs, giving birth to a Bag-of-Graph-Words representation. The
multi-layer nature of the descriptors consists in scaling from trivial Delaunay
graphs - isolated feature points - by increasing the number of nodes layer by
layer up to graphs with maximal number of nodes. For each layer of graphs its
own visual dictionary is built. The experiments conducted on the SIVAL and
Caltech-101 data sets reveal that the graph features at different layers
exhibit complementary performances on the same content and perform better than
baseline BoVW approach. The combination of all existing layers, yields
significant improvement of the object recognition performance compared to
single level approaches.
</summary>
    <author>
      <name>Svebor Karaman</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LaBRI</arxiv:affiliation>
    </author>
    <author>
      <name>Jenny Benois-Pineau</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LaBRI</arxiv:affiliation>
    </author>
    <author>
      <name>Rémi Mégret</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IMS</arxiv:affiliation>
    </author>
    <author>
      <name>Aurélie Bugeau</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LaBRI</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-642-27355-1_6</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-642-27355-1_6" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">International Conference on MultiMedia Modeling, Klagenfurt :
  Autriche (2012)</arxiv:comment>
    <link href="http://arxiv.org/abs/1110.6895v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1110.6895v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.0242v1</id>
    <updated>2011-11-01T16:52:10Z</updated>
    <published>2011-11-01T16:52:10Z</published>
    <title>Storage Balancing in Self-organizing Multimedia Delivery Systems</title>
    <summary>  Many of the current bio-inspired delivery networks set their focus on search,
e.g., by using artificial ants. If the network size and, therefore, the search
space gets too large, the users experience high delays until the requested
content can be consumed. In previous work, we proposed different replication
strategies to reduce the search space. In this report we further evaluate
measures for storage load balancing, because peers are most likely limited in
space. We periodically apply clean-ups if a certain storage level is reached.
For our evaluations we combine the already introduced replication measures with
least recently used (LRU), least frequently used (LFU) and a hormone-based
clean-up. The goal is to elaborate a combination that leads to low delays while
the replica utilization is high.
</summary>
    <author>
      <name>Anita Sobe</name>
    </author>
    <author>
      <name>Wilfried Elmenreich</name>
    </author>
    <author>
      <name>Laszlo Böszörmenyi</name>
    </author>
    <link href="http://arxiv.org/abs/1111.0242v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.0242v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="nlin.AO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.2993v1</id>
    <updated>2011-11-13T07:13:23Z</updated>
    <published>2011-11-13T07:13:23Z</published>
    <title>A Survey on Web-based AR Applications</title>
    <summary>  Due to the increase of interest in Augmented Reality (AR), the potential uses
of AR are increasing also. It can benefit the user in various fields such as
education, business, medicine, and other. Augmented Reality supports the real
environment with synthetic environment to give more details and meaning to the
objects in the real word. AR refers to a situation in which the goal is to
supplement a user's perception of the real-world through the addition of
virtual objects. This paper is an attempt to make a survey of web-based
Augmented Reality applications and make a comparison among them.
</summary>
    <author>
      <name>Behrang Parhizkar</name>
    </author>
    <author>
      <name>Ashraf Abbas M. Al-Modwahi</name>
    </author>
    <author>
      <name>Arash Habibi Lashkari</name>
    </author>
    <author>
      <name>Mohammad Mehdi Bartaripou</name>
    </author>
    <author>
      <name>Hossein Reza Babae</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Science Issues (IJCSI), Vol. 8,
  Issue 4, July 2011</arxiv:comment>
    <link href="http://arxiv.org/abs/1111.2993v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.2993v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.6727v1</id>
    <updated>2011-11-29T08:37:08Z</updated>
    <published>2011-11-29T08:37:08Z</published>
    <title>A New Digital Watermarking Algorithm Using Combination of Least
  Significant Bit (LSB) and Inverse Bit</title>
    <summary>  In this paper, we introduce a new digital watermarking algorithm using least
significant bit (LSB). LSB is used because of its little effect on the image.
This new algorithm is using LSB by inversing the binary values of the watermark
text and shifting the watermark according to the odd or even number of pixel
coordinates of image before embedding the watermark. The proposed algorithm is
flexible depending on the length of the watermark text. If the length of the
watermark text is more than ((MxN)/8)-2 the proposed algorithm will also embed
the extra of the watermark text in the second LSB. We compare our proposed
algorithm with the 1-LSB algorithm and Lee's algorithm using Peak
signal-to-noise ratio (PSNR). This new algorithm improved its quality of the
watermarked image. We also attack the watermarked image by using cropping and
adding noise and we got good results as well.
</summary>
    <author>
      <name>Abdullah Bamatraf</name>
    </author>
    <author>
      <name>Rosziati Ibrahim</name>
    </author>
    <author>
      <name>Mohd. Najib Mohd. Salleh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 6 figures and 4 tables; Journal of Computing, Volume 3,
  Issue 4, April 2011, ISSN 2151-9617</arxiv:comment>
    <link href="http://arxiv.org/abs/1111.6727v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.6727v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1112.2027v1</id>
    <updated>2011-12-09T07:05:49Z</updated>
    <published>2011-12-09T07:05:49Z</published>
    <title>Automatic Classification of X-rated Videos using Obscene Sound Analysis
  based on a Repeated Curve-like Spectrum Feature</title>
    <summary>  This paper addresses the automatic classification of X-rated videos by
analyzing its obscene sounds. In this paper, obscene sounds refer to audio
signals generated from sexual moans and screams during sexual scenes. By
analyzing various sound samples, we determined the distinguishable
characteristics of obscene sounds and propose a repeated curve-like spectrum
feature that represents the characteristics of such sounds. We constructed
6,269 audio clips to evaluate the proposed feature, and separately constructed
1,200 X-rated and general videos for classification. The proposed feature has
an F1-score, precision, and recall rate of 96.6%, 98.2%, and 95.2%,
respectively, for the original dataset, and 92.6%, 97.6%, and 88.0% for a noisy
dataset of 5dB SNR. And, in classifying videos, the feature has more than a 90%
F1-score, 97% precision, and an 84% recall rate. From the measured performance,
X-rated videos can be classified with only the audio features and the repeated
curve-like spectrum feature is suitable to detect obscene sounds.
</summary>
    <author>
      <name>JaeDeok Lim</name>
    </author>
    <author>
      <name>ByeongCheol Choi</name>
    </author>
    <author>
      <name>SeungWan Han</name>
    </author>
    <author>
      <name>ChoelHoon Lee</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, 5 figures, 11 tables, IJMA(The International Journal of
  Multimedia &amp; Its Applications)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">The International Journal of Multimedia &amp; Its Applications (IJMA)
  Vol.3, No.4, November 2011, pp.1-17</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1112.2027v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1112.2027v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1112.2261v1</id>
    <updated>2011-12-10T08:34:51Z</updated>
    <published>2011-12-10T08:34:51Z</published>
    <title>Lossless Digital Image Compression Method for Bitmap Images</title>
    <summary>  In this research paper, the authors propose a new approach to digital image
compression using crack coding This method starts with the original image and
develop crack codes in a recursive manner, marking the pixels visited earlier
and expanding the entropy in four directions. The proposed method is
experimented with sample bitmap images and results are tabulated. The method is
implemented in uni-processor machine using C language source code.
</summary>
    <author>
      <name>Dr. T. Meyyappan</name>
    </author>
    <author>
      <name>SM. Thamarai</name>
    </author>
    <author>
      <name>N. M. Jeya Nachiaban</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5121/ijma.2011.3407</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5121/ijma.2011.3407" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 7 figures, presented in First International Conference on
  Digital Image Processing and Pattern Recognition (DPPR-2011)In conjunction
  with (CCSEIT-2011), Manonmaniam Sundharanar University, September 23~25,
  2011, Tirunelveli, Tamil Nadu, India</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">The International Journal of Multimedia &amp; Its Applications (IJMA)
  Vol.3, No.4, November 2011</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1112.2261v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1112.2261v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65D18" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1112.2809v1</id>
    <updated>2011-12-13T06:56:25Z</updated>
    <published>2011-12-13T06:56:25Z</published>
    <title>Steganography Algorithm to Hide Secret Message inside an Image</title>
    <summary>  In this paper, the authors propose a new algorithm to hide data inside image
using steganography technique. The proposed algorithm uses binary codes and
pixels inside an image. The zipped file is used before it is converted to
binary codes to maximize the storage of data inside the image. By applying the
proposed algorithm, a system called Steganography Imaging System (SIS) is
developed. The system is then tested to see the viability of the proposed
algorithm. Various sizes of data are stored inside the images and the PSNR
(Peak signal-to-noise ratio) is also captured for each of the images tested.
Based on the PSNR value of each images, the stego image has a higher PSNR
value. Hence this new steganography algorithm is very efficient to hide the
data inside the image.
</summary>
    <author>
      <name>Rosziati Ibrahim</name>
    </author>
    <author>
      <name>Teoh Suk Kuan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 7 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Computer Technology and Application 2 (2011) 102-108</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1112.2809v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1112.2809v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1201.0598v1</id>
    <updated>2012-01-03T09:19:58Z</updated>
    <published>2012-01-03T09:19:58Z</published>
    <title>Interactive multiview video system with non-complex navigation at the
  decoder</title>
    <summary>  Multiview video with interactive and smooth view switching at the receiver is
a challenging application with several issues in terms of effective use of
storage and bandwidth resources, reactivity of the system, quality of the
viewing experience and system complexity. The classical decoding system for
generating virtual views first projects a reference or encoded frame to a given
viewpoint and then fills in the holes due to potential occlusions. This last
step still constitutes a complex operation with specific software or hardware
at the receiver and requires a certain quantity of information from the
neighboring frames for insuring consistency between the virtual images. In this
work we propose a new approach that shifts most of the burden due to
interactivity from the decoder to the encoder, by anticipating the navigation
of the decoder and sending auxiliary information that guarantees temporal and
interview consistency. This leads to an additional cost in terms of
transmission rate and storage, which we minimize by using optimization
techniques based on the user behavior modeling. We show by experiments that the
proposed system represents a valid solution for interactive multiview systems
with classical decoders.
</summary>
    <author>
      <name>Thomas Maugey</name>
    </author>
    <author>
      <name>Pascal Frossard</name>
    </author>
    <link href="http://arxiv.org/abs/1201.0598v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1201.0598v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1201.1383v1</id>
    <updated>2012-01-06T10:10:54Z</updated>
    <published>2012-01-06T10:10:54Z</published>
    <title>Stereo image Transference &amp; Retrieval over SMS</title>
    <summary>  Paper presents the way of transferring stereo images using SMS over GSM
network. Generally, Stereo image is composed of two stereoscopic images in such
way that gives three dimensional affect when viewed. GSM have two short
messaging services, which can transfer images and sounds etc. Such services are
known as; MMS (Multimedia Messaging Service) and EMS (Extended Messaging
Service). EMS can send Predefined sounds, animation and images but have
limitation that it does not support widely. MMS can send much higher contents
than EMS but need 3G and other network capability in order to send large size
data up to 1000 bytes. Other limitations are Portability, content adaption etc.
Our major aim in this paper is to provide an alternative way of sending stereo
images over SMS which is widely supported than EMS. We develop an application
using J2ME Platform.
</summary>
    <author>
      <name>Muhammad Fahad Khan</name>
    </author>
    <author>
      <name>Saira Beg</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3 pages,3 figuers,Journal</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">JOURNAL OF COMPUTING, VOLUME 3, ISSUE 7, JULY 2011, ISSN 2151-9617
  WWW.JOURNALOFCOMPUTING.ORG</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1201.1383v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1201.1383v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1201.1668v1</id>
    <updated>2012-01-08T23:45:27Z</updated>
    <published>2012-01-08T23:45:27Z</published>
    <title>Identifying and Analysis of Scene Mining Methods Beased on Scenes
  Extracted Features</title>
    <summary>  Scene mining is a subset of image mining in which scenes are classified to a
distinct set of classes based on analysis of their content. In other word in
scene mining, a label is given to visual content of scene, for example,
mountain, beach. Scene mining is used in applications such as medicine, movie,
information retrieval, computer vision, recognition of traffic scene. Reviewing
of represented methods shows there are various methods in scene mining. Scene
mining applications extension and existence of various scenes, make comparison
of methods hard. Scene mining can be followed by identifying scene mining
components and representing a framework to analyzing and evaluating methods. In
this paper, at first, components of scene mining are introduced, then a
framework based on extracted features of scene is represented to classify scene
mining methods. Finally, these methods are analyzed and evaluated via a
proposal framework.
</summary>
    <author>
      <name>Ashraf Sadat Jabari</name>
    </author>
    <author>
      <name>Mohammadreza Keyvanpour</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Engineering Science and Technology, Vol.
  3 No. 9 September 2011, 7211-7217</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1201.1668v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1201.1668v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1201.3018v1</id>
    <updated>2012-01-14T14:22:54Z</updated>
    <published>2012-01-14T14:22:54Z</published>
    <title>Throughput Scaling Of Convolution For Error-Tolerant Multimedia
  Applications</title>
    <summary>  Convolution and cross-correlation are the basis of filtering and pattern or
template matching in multimedia signal processing. We propose two throughput
scaling options for any one-dimensional convolution kernel in programmable
processors by adjusting the imprecision (distortion) of computation. Our
approach is based on scalar quantization, followed by two forms of tight
packing in floating-point (one of which is proposed in this paper) that allow
for concurrent calculation of multiple results. We illustrate how our approach
can operate as an optional pre- and post-processing layer for off-the-shelf
optimized convolution routines. This is useful for multimedia applications that
are tolerant to processing imprecision and for cases where the input signals
are inherently noisy (error tolerant multimedia applications). Indicative
experimental results with a digital music matching system and an MPEG-7 audio
descriptor system demonstrate that the proposed approach offers up to 175%
increase in processing throughput against optimized (full-precision)
convolution with virtually no effect in the accuracy of the results. Based on
marginal statistics of the input data, it is also shown how the throughput and
distortion can be adjusted per input block of samples under constraints on the
signal-to-noise ratio against the full-precision convolution.
</summary>
    <author>
      <name>Mohammad Ashraful Anam</name>
    </author>
    <author>
      <name>Yiannis Andreopoulos</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE Trans. on Multimedia, 2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1201.3018v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1201.3018v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1201.5285v1</id>
    <updated>2012-01-25T14:39:39Z</updated>
    <published>2012-01-25T14:39:39Z</published>
    <title>An Authoring System for Editing Lessons in Phonetic English in SMIL3.0</title>
    <summary>  One of the difficulties of teaching English is the prosody, including the
stress. French learners have difficulties to encode this information about the
word because it is irrelevant for them. Therefore, they have difficulty to
produce this stress when they speak that language. Studies in this area have
concluded that the dual-coding approach (auditory and visual) of a phonetic
phenomenon helps a lot to improve its perception and memorization for novice
learners. The aim of our work is to provide English teachers with an authoring
named SaCoPh for editing multimedia courses that support this approach. This
course is based on a template that fits the educational aspects of phonetics,
exploiting the features of version 3.0 of the standard SMIL (Synchronized
Multimedia Integration Language) for the publication of this course on the web.
</summary>
    <author>
      <name>G. Merzougui</name>
    </author>
    <author>
      <name>M. Djoudi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 6 figures and 2 codes</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IJCSI International Journal of Computer Science Issues, Vol. 8,
  Issue 6, No 3, November 2011</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1201.5285v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1201.5285v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.1808v1</id>
    <updated>2012-02-08T20:26:26Z</updated>
    <published>2012-02-08T20:26:26Z</published>
    <title>Personalised product design using virtual interactive techniques</title>
    <summary>  Use of Virtual Interactive Techniques for personalized product design is
described in this paper. Usually products are designed and built by considering
general usage patterns and Prototyping is used to mimic the static or working
behaviour of an actual product before manufacturing the product. The user does
not have any control on the design of the product. Personalized design
postpones design to a later stage. It allows for personalized selection of
individual components by the user. This is implemented by displaying the
individual components over a physical model constructed using Cardboard or
Thermocol in the actual size and shape of the original product. The components
of the equipment or product such as screen, buttons etc. are then projected
using a projector connected to the computer into the physical model. Users can
interact with the prototype like the original working equipment and they can
select, shape, position the individual components displayed on the interaction
panel using simple hand gestures. Computer Vision techniques as well as sound
processing techniques are used to detect and recognize the user gestures
captured using a web camera and microphone.
</summary>
    <author>
      <name>Kurien Zacharia</name>
    </author>
    <author>
      <name>Eldo P. Elias</name>
    </author>
    <author>
      <name>Surekha Mariam Varghese</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5121/ijcga.2012.2101</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5121/ijcga.2012.2101" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages; International Journal of Computer Graphics &amp; Animation
  (IJCGA) Vol.2, No.1, January 2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1202.1808v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.1808v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68u05, 68u20" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.2; I.3.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.4743v1</id>
    <updated>2012-02-21T20:42:17Z</updated>
    <published>2012-02-21T20:42:17Z</published>
    <title>Real-time detection and tracking of multiple objects with partial
  decoding in H.264/AVC bitstream domain</title>
    <summary>  In this paper, we show that we can apply probabilistic spatiotemporal
macroblock filtering (PSMF) and partial decoding processes to effectively
detect and track multiple objects in real time in H.264|AVC bitstreams with
stationary background. Our contribution is that our method cannot only show
fast processing time but also handle multiple moving objects that are
articulated, changing in size or internally have monotonous color, even though
they contain a chaotic set of non-homogeneous motion vectors inside. In
addition, our partial decoding process for H.264|AVC bitstreams enables to
improve the accuracy of object trajectories and overcome long occlusion by
using extracted color information.
</summary>
    <author>
      <name>Wonsang You</name>
    </author>
    <author>
      <name>M. S. Houari Sabirin</name>
    </author>
    <author>
      <name>Munchurl Kim</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1117/12.805596</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1117/12.805596" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">SPIE Real-Time Image and Video Processing Conference 2009</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of SPIE 2009, Volume: 7244, Publisher: SPIE, Pages:
  72440D-72440D-12</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1202.4743v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.4743v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.4943v1</id>
    <updated>2012-02-22T15:43:56Z</updated>
    <published>2012-02-22T15:43:56Z</published>
    <title>A new hybrid jpeg image compression scheme using symbol reduction
  technique</title>
    <summary>  Lossy JPEG compression is a widely used compression technique. Normally the
JPEG standard technique uses three process mapping reduces interpixel
redundancy, quantization, which is lossy process and entropy encoding, which is
considered lossless process. In this paper, a new technique has been proposed
by combining the JPEG algorithm and Symbol Reduction Huffman technique for
achieving more compression ratio. The symbols reduction technique reduces the
number of symbols by combining together to form a new symbol. As a result of
this technique the number of Huffman code to be generated also reduced. It is
simple fast and easy to implement. The result shows that the performance of
standard JPEG method can be improved by proposed method. This hybrid approach
achieves about 20% more compression ratio than the Standard JPEG.
</summary>
    <author>
      <name>Bheshaj Kumar</name>
    </author>
    <author>
      <name>Kavita Thakur</name>
    </author>
    <author>
      <name>G. R. Sinha</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5121/csit.2012.2101-10.5121-csit.2012.2141</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5121/csit.2012.2101-10.5121-csit.2012.2141" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages,9 figures, SIP 2012 held on 3-4 January 2012,at
  Bangalore,India. arXiv admin note: text overlap with standard references on
  JPEG without attribution</arxiv:comment>
    <link href="http://arxiv.org/abs/1202.4943v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.4943v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.5289v2</id>
    <updated>2013-07-30T12:54:15Z</updated>
    <published>2012-02-23T20:39:38Z</published>
    <title>Development Trends in Steganography</title>
    <summary>  Steganography is a general term referring to all methods for the embedding of
additional secret content into some form of carrier, with the aim of
concealment of the introduced alterations. The choice of the carrier is nearly
unlimited, it may be an ancient piece of parchment, as well as a network
protocol header. Inspired by biological phenomena, adopted by man in the
ancient times, it has been developed over the ages. Present day steganographic
methods are far more sophisticated than their ancient predecessors, but the
main principles have remained unchanged. They typically rely on the utilization
of digital media files or network protocols as a carrier, in which secret data
is embedded. This paper presents the evolution of the hidden data carrier from
the ancient times till the present day and pinpoints the observed development
trends, with special emphasis on network steganography.
</summary>
    <author>
      <name>Elzbieta Zielinska</name>
    </author>
    <author>
      <name>Wojciech Mazurczyk</name>
    </author>
    <author>
      <name>Krzysztof Szczypiorski</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 1 figure, 1 table</arxiv:comment>
    <link href="http://arxiv.org/abs/1202.5289v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.5289v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1203.2147v1</id>
    <updated>2012-03-09T17:43:28Z</updated>
    <published>2012-03-09T17:43:28Z</published>
    <title>A Hybrid Image Cryptosystem Based On OMFLIP Permutation Cipher</title>
    <summary>  The protection of confidential image data from unauthorized access is an
important area of research in network communication. This paper presents a
high-level security encryption scheme for gray scale images. The gray level
image is first decomposed into binary images using bit scale decomposition.
Each binary image is then compressed by selecting a good scanning path that
minimizes the total number of bits needed to encode the bit sequence along the
scanning path using two dimensional run encoding. The compressed bit string is
then scrambled iteratively using a pseudo-random number generator and finally
encrypted using a bit level permutation OMFLIP. The performance is tested,
illustrated and discussed.
</summary>
    <author>
      <name>G. Sudheer</name>
    </author>
    <author>
      <name>B. V. S. Renuka Devi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Signal &amp; Image Processing : An International Journal (SIPIJ)
  Vol.3, No.1, February 2012</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1203.2147v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1203.2147v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1203.4035v1</id>
    <updated>2012-03-19T05:09:50Z</updated>
    <published>2012-03-19T05:09:50Z</published>
    <title>Quantitative Multiscale Analysis using Different Wavelets in 1D Voice
  Signal and 2D Image</title>
    <summary>  Mutiscale analysis represents multiresolution scrutiny of a signal to improve
its signal quality. Multiresolution analysis of 1D voice signal and 2D image is
conducted using DCT, FFT and different wavelets such as Haar, Deubachies,
Morlet, Cauchy, Shannon, Biorthogonal, Symmlet and Coiflet deploying the
cascaded filter banks based decomposition and reconstruction. The outstanding
quantitative analysis of the specified wavelets is done to investigate the
signal quality, mean square error, entropy and peak-to-peak SNR at multiscale
stage-4 for both 1D voice signal and 2D image. In addition, the 2D image
compression performance is significantly found 93.00% in DB-4, 93.68% in
bior-4.4, 93.18% in Sym-4 and 92.20% in Coif-2 during the multiscale analysis.
</summary>
    <author>
      <name>Niraj Shakhakarmi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 37 figures, Full paper is available at
  http://sites.google.com/site/nirajskorg/Home/wavelets; IJCSI International
  Journal of Computer Science Issues, Vol. 9, Issue 1, No 2, January 2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1203.4035v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1203.4035v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1203.5772v1</id>
    <updated>2012-03-26T19:44:26Z</updated>
    <published>2012-03-26T19:44:26Z</published>
    <title>Compressed Sensing for Moving Imagery in Medical Imaging</title>
    <summary>  Numerous applications in signal processing have benefited from the theory of
compressed sensing which shows that it is possible to reconstruct signals
sampled below the Nyquist rate when certain conditions are satisfied. One of
these conditions is that there exists a known transform that represents the
signal with a sufficiently small number of non-zero coefficients. However when
the signal to be reconstructed is composed of moving images or volumes, it is
challenging to form such regularization constraints with traditional transforms
such as wavelets. In this paper, we present a motion compensating prior for
such signals that is derived directly from the optical flow constraint and can
utilize the motion information during compressed sensing reconstruction.
Proposed regularization method can be used in a wide variety of applications
involving compressed sensing and images or volumes of moving and deforming
objects. It is also shown that it is possible to estimate the signal and the
motion jointly or separately. Practical examples from magnetic resonance
imaging has been presented to demonstrate the benefit of the proposed method.
</summary>
    <author>
      <name>Cagdas Bilen</name>
    </author>
    <author>
      <name>Yao Wang</name>
    </author>
    <author>
      <name>Ivan Selesnick</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to IEEE Transactions on Image Processing</arxiv:comment>
    <link href="http://arxiv.org/abs/1203.5772v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1203.5772v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.0056v1</id>
    <updated>2012-03-31T02:06:00Z</updated>
    <published>2012-03-31T02:06:00Z</published>
    <title>I-SolFramework: An Integrated Solution Framework Six Layers Assessment
  on Multimedia Information Security Architecture Policy Compliance</title>
    <summary>  Multimedia Information security becomes a important part for the
organization's intangible assets. Level of confidence and stakeholder trusted
are performance indicator as successes organization, it is imperative for
organizations to use Information Security Management System (ISMS) to
effectively manage their multimedia information assets. The main objective of
this paper is to Provide a novel practical framework approach to the
development of ISMS, Called by the I-SolFramework, implemented in multimedia
information security architecture (MISA), it divides a problem into six object
domains or six layers, namely organization,stakeholders, tool &amp; technology,
policy, knowledge, and culture. In addition, this framework also introduced
novelty algorithm and mathematic models as measurement and assessment tools of
MISA parameters.
</summary>
    <author>
      <name>Heru Susanto</name>
    </author>
    <author>
      <name>Mohammad Nabil Almunawar</name>
    </author>
    <author>
      <name>Yong Chee Tuan</name>
    </author>
    <author>
      <name>Mehmet Sabih Aksoy</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Electrical &amp; Computer Sciences IJECS-IJENS
  Vol: 12 No: 01 (126501-9494 IJECS-IJENS \c{opyright} February 2012 IJENS)</arxiv:comment>
    <link href="http://arxiv.org/abs/1204.0056v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.0056v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.1868v1</id>
    <updated>2012-04-09T12:23:36Z</updated>
    <published>2012-04-09T12:23:36Z</published>
    <title>User-based key frame detection in social web video</title>
    <summary>  Video search results and suggested videos on web sites are represented with a
video thumbnail, which is manually selected by the video up-loader among three
randomly generated ones (e.g., YouTube). In contrast, we present a grounded
user-based approach for automatically detecting interesting key-frames within a
video through aggregated users' replay interactions with the video player.
Previous research has focused on content-based systems that have the benefit of
analyzing a video without user interactions, but they are monolithic, because
the resulting video thumbnails are the same regardless of the user preferences.
We constructed a user interest function, which is based on aggregate video
replays, and analyzed hundreds of user interactions. We found that the local
maximum of the replaying activity stands for the semantics of information rich
videos, such as lecture, and how-to. The concept of user-based key-frame
detection could be applied to any video on the web, in order to generate a
user-based and dynamic video thumbnail in search results.
</summary>
    <author>
      <name>Konstantinos Chorianopoulos</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1204.1868v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.1868v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.2214v3</id>
    <updated>2013-07-25T17:25:32Z</updated>
    <published>2012-04-10T16:41:33Z</published>
    <title>Simplification Resilient LDPC-Coded Sparse-QIM Watermarking for
  3D-Meshes</title>
    <summary>  We propose a blind watermarking scheme for 3-D meshes which combines sparse
quantization index modulation (QIM) with deletion correction codes. The QIM
operates on the vertices in rough concave regions of the surface thus ensuring
impeccability, while the deletion correction code recovers the data hidden in
the vertices which is removed by mesh optimization and/or simplification. The
proposed scheme offers two orders of magnitude better performance in terms of
recovered watermark bit error rate compared to the existing schemes of similar
payloads and fidelity constraints.
</summary>
    <author>
      <name>Bata Vasic</name>
    </author>
    <author>
      <name>Bane Vasic</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TMM.2013.2265673</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TMM.2013.2265673" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted, revised and Copyright transfered to IEEE Transactions on
  Multimedia, October 9th 2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1204.2214v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.2214v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.2359v1</id>
    <updated>2012-04-11T07:16:35Z</updated>
    <published>2012-04-11T07:16:35Z</published>
    <title>An Overview of Video Allocation Algorithms for Flash-based SSD Storage
  Systems</title>
    <summary>  Despite the fact that Solid State Disk (SSD) data storage media had offered a
revolutionary property storages community, but the unavailability of a
comprehensive allocation strategy in SSDs storage media, leads to consuming the
available space, random writing processes, time-consuming reading processes,
and system resources consumption. In order to overcome these challenges, an
efficient allocation algorithm is a desirable option. In this paper, we had
executed an intensive investigation on the SSD-based allocation algorithms that
had been proposed by the knowledge community. An explanatory comparison had
been made between these algorithms. We reviewed these algorithms in order to
building advanced knowledge armature that would help in inventing new
allocation algorithms for this type of storage media.
</summary>
    <author>
      <name>Jaafer Al-Sabateen</name>
    </author>
    <author>
      <name>Saleh Ali Alomari</name>
    </author>
    <author>
      <name>Putra Sumari</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 2 figure, 3 algorithm, 3 table, (IJACSA) International
  Journal of Advanced Computer Science and Applications, Vol. 3, No. 3, 2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1204.2359v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.2359v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.2616v1</id>
    <updated>2012-04-12T04:43:08Z</updated>
    <published>2012-04-12T04:43:08Z</published>
    <title>Genetic Algorithm to Make Persistent Security and Quality of Image in
  Steganography from RS Analysis</title>
    <summary>  Retention of secrecy is one of the significant features during communication
activity. Steganography is one of the popular methods to achieve secret
communication between sender and receiver by hiding message in any form of
cover media such as an audio, video, text, images etc. Least significant bit
encoding is the simplest encoding method used by many steganography programs to
hide secret message in 24bit, 8bit colour images and grayscale images.
Steganalysis is a method of detecting secret message hidden in a cover media
using steganography. RS steganalysis is one of the most reliable steganalysis
which performs statistical analysis of the pixels to successfully detect the
hidden message in an image. However, existing steganography method protects the
information against RS steganalysis in grey scale images. This paper presents a
steganography method using genetic algorithm to protect against the RS attack
in colour images. Stego image is divided into number of blocks. Subsequently,
with the implementation of natural evolution on the stego image using genetic
algorithm enables to achieve optimized security and image quality.
</summary>
    <author>
      <name>T. R. Gopalakrishnan Nair</name>
    </author>
    <author>
      <name>Suma V</name>
    </author>
    <author>
      <name>Manas S</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 Pages, 4 Figures, Swarm Evolutionary and Memetric Computing
  Conference (SEMCCO), Vishakhapatnam</arxiv:comment>
    <link href="http://arxiv.org/abs/1204.2616v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.2616v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.6321v1</id>
    <updated>2012-04-27T20:00:20Z</updated>
    <published>2012-04-27T20:00:20Z</published>
    <title>Efficient Video Indexing on the Web: A System that Leverages User
  Interactions with a Video Player</title>
    <summary>  In this paper, we propose a user-based video indexing method, that
automatically generates thumbnails of the most important scenes of an online
video stream, by analyzing users' interactions with a web video player. As a
test bench to verify our idea we have extended the YouTube video player into
the VideoSkip system. In addition, VideoSkip uses a web-database (Google
Application Engine) to keep a record of some important parameters, such as the
timing of basic user actions (play, pause, skip). Moreover, we implemented an
algorithm that selects representative thumbnails. Finally, we populated the
system with data from an experiment with nine users. We found that the
VideoSkip system indexes video content by leveraging implicit users
interactions, such as pause and thirty seconds skip. Our early findings point
toward improvements of the web video player and its thumbnail generation
technique. The VideSkip system could compliment content-based algorithms, in
order to achieve efficient video-indexing in difficult videos, such as lectures
or sports.
</summary>
    <author>
      <name>Ioannis Leftheriotis</name>
    </author>
    <author>
      <name>Chrysoula Gkonela</name>
    </author>
    <author>
      <name>Konstantinos Chorianopoulos</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 3 figures, UCMedia 2010: 2nd International ICST Conference
  on User Centric Media</arxiv:comment>
    <link href="http://arxiv.org/abs/1204.6321v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.6321v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.1365v1</id>
    <updated>2012-05-07T12:49:42Z</updated>
    <published>2012-05-07T12:49:42Z</published>
    <title>Image Enhancement with Statistical Estimation</title>
    <summary>  Contrast enhancement is an important area of research for the image analysis.
Over the decade, the researcher worked on this domain to develop an efficient
and adequate algorithm. The proposed method will enhance the contrast of image
using Binarization method with the help of Maximum Likelihood Estimation (MLE).
The paper aims to enhance the image contrast of bimodal and multi-modal images.
The proposed methodology use to collect mathematical information retrieves from
the image. In this paper, we are using binarization method that generates the
desired histogram by separating image nodes. It generates the enhanced image
using histogram specification with binarization method. The proposed method has
showed an improvement in the image contrast enhancement compare with the other
image.
</summary>
    <author>
      <name>Aroop Mukherjee</name>
    </author>
    <author>
      <name>Soumen Kanrar</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5121/ijma.2012.4205</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5121/ijma.2012.4205" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages,6 figures; ISSN:0975-5578 (Online); 0975-5934 (Print)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">The International Journal of Multimedia &amp; Its Applications (IJMA)
  April 2012, Volume 4, Number 2, page 59-67</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1205.1365v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.1365v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.1859v1</id>
    <updated>2012-05-09T02:50:16Z</updated>
    <published>2012-05-09T02:50:16Z</published>
    <title>Text Steganography using LSB insertion method along with Chaos Theory</title>
    <summary>  The art of information hiding has been around nearly as long as the need for
covert communication. Steganography, the concealing of information, arose early
on as an extremely useful method for covert information transmission.
Steganography is the art of hiding secret message within a larger image or
message such that the hidden message or an image is undetectable; this is in
contrast to cryptography, where the existence of the message itself is not
disguised, but the content is obscure. The goal of a steganographic method is
to minimize the visually apparent and statistical differences between the cover
data and a steganogram while maximizing the size of the payload. Current
digital image steganography presents the challenge of hiding message in a
digital image in a way that is robust to image manipulation and attack. This
paper explains about how a secret message can be hidden into an image using
least significant bit insertion method along with chaos.
</summary>
    <author>
      <name>Bhavana S.</name>
    </author>
    <author>
      <name>K. L. Sudha</name>
    </author>
    <link href="http://arxiv.org/abs/1205.1859v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.1859v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.0692v3</id>
    <updated>2012-09-17T23:11:17Z</updated>
    <published>2012-06-04T18:02:03Z</published>
    <title>Signal and Image Processing with Sinlets</title>
    <summary>  This paper presents a new family of localized orthonormal bases - sinlets -
which are well suited for both signal and image processing and analysis.
One-dimensional sinlets are related to specific solutions of the time-dependent
harmonic oscillator equation. By construction, each sinlet is infinitely
differentiable and has a well-defined and smooth instantaneous frequency known
in analytical form. For square-integrable transient signals with infinite
support, one-dimensional sinlet basis provides an advantageous alternative to
the Fourier transform by rendering accurate signal representation via a
countable set of real-valued coefficients. The properties of sinlets make them
suitable for analyzing many real-world signals whose frequency content changes
with time including radar and sonar waveforms, music, speech, biological
echolocation sounds, biomedical signals, seismic acoustic waves, and signals
employed in wireless communication systems. One-dimensional sinlet bases can be
used to construct two- and higher-dimensional bases with variety of potential
applications including image analysis and representation.
</summary>
    <author>
      <name>Alexander Y. Davydov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">26 pages, 21 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1206.0692v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.0692v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.MP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="91A28" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.4326v1</id>
    <updated>2012-06-19T20:16:04Z</updated>
    <published>2012-06-19T20:16:04Z</published>
    <title>Joint Reconstruction of Multi-view Compressed Images</title>
    <summary>  The distributed representation of correlated multi-view images is an
important problem that arise in vision sensor networks. This paper concentrates
on the joint reconstruction problem where the distributively compressed
correlated images are jointly decoded in order to improve the reconstruction
quality of all the compressed images. We consider a scenario where the images
captured at different viewpoints are encoded independently using common coding
solutions (e.g., JPEG, H.264 intra) with a balanced rate distribution among
different cameras. A central decoder first estimates the underlying correlation
model from the independently compressed images which will be used for the joint
signal recovery. The joint reconstruction is then cast as a constrained convex
optimization problem that reconstructs total-variation (TV) smooth images that
comply with the estimated correlation model. At the same time, we add
constraints that force the reconstructed images to be consistent with their
compressed versions. We show by experiments that the proposed joint
reconstruction scheme outperforms independent reconstruction in terms of image
quality, for a given target bit rate. In addition, the decoding performance of
our proposed algorithm compares advantageously to state-of-the-art distributed
coding schemes based on disparity learning and on the DISCOVER.
</summary>
    <author>
      <name>Vijayaraghavan Thirumalai</name>
    </author>
    <author>
      <name>Pascal Frossard</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TIP.2013.2240006</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TIP.2013.2240006" rel="related"/>
    <link href="http://arxiv.org/abs/1206.4326v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.4326v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1208.3718v1</id>
    <updated>2012-08-18T02:11:20Z</updated>
    <published>2012-08-18T02:11:20Z</published>
    <title>Exploiting Image Local And Nonlocal Consistency For Mixed
  Gaussian-Impulse Noise Removal</title>
    <summary>  Most existing image denoising algorithms can only deal with a single type of
noise, which violates the fact that the noisy observed images in practice are
often suffered from more than one type of noise during the process of
acquisition and transmission. In this paper, we propose a new variational
algorithm for mixed Gaussian-impulse noise removal by exploiting image local
consistency and nonlocal consistency simultaneously. Specifically, the local
consistency is measured by a hyper-Laplace prior, enforcing the local
smoothness of images, while the nonlocal consistency is measured by
three-dimensional sparsity of similar blocks, enforcing the nonlocal
self-similarity of natural images. Moreover, a Split-Bregman based technique is
developed to solve the above optimization problem efficiently. Extensive
experiments for mixed Gaussian plus impulse noise show that significant
performance improvements over the current state-of-the-art schemes have been
achieved, which substantiates the effectiveness of the proposed algorithm.
</summary>
    <author>
      <name>Jian Zhang</name>
    </author>
    <author>
      <name>Ruiqin Xiong</name>
    </author>
    <author>
      <name>Chen Zhao</name>
    </author>
    <author>
      <name>Siwei Ma</name>
    </author>
    <author>
      <name>Debin Zhao</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/ICME.2012.109</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/ICME.2012.109" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 4 figures, 3 tables, to be published at IEEE Int. Conf. on
  Multimedia &amp; Expo (ICME) 2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1208.3718v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1208.3718v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1208.6389v1</id>
    <updated>2012-08-31T06:31:01Z</updated>
    <published>2012-08-31T06:31:01Z</published>
    <title>Behavioral Systel Level Power Consumption Modeling of Mobile Video
  Streaming applications</title>
    <summary>  Nowadays, the use of mobile applications and terminals faces fundamental
challenges related to energy constraint. This is due to the limited battery
lifetime as compared to the increasing hardware evolution. Video streaming is
one of the most energy consuming applications in a mobile system because of its
intensive use of bandwidth, memory and processing power. In this work, we aim
to propose a methodology for building and validating a high level global power
consumption model including a hardware and software elements. Our approach is
based on exploiting the interactions between power consumption sub-models of
standalone systems in the perspective to build more accurate global model. The
interactions are studied within the exclusive context of video streaming
applications that are one of the most used mobile applications.
</summary>
    <author>
      <name>Yahia Benmoussa</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Lab-STICC</arxiv:affiliation>
    </author>
    <author>
      <name>Jalil Boukhobza</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Lab-STICC</arxiv:affiliation>
    </author>
    <author>
      <name>Yassine Hadjadj Aoul</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA - IRISA</arxiv:affiliation>
    </author>
    <author>
      <name>Loïc Lagadec</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Lab-STICC</arxiv:affiliation>
    </author>
    <author>
      <name>Djamel Benazzouz</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LMSS</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Colloque du GDR SoC SiP, Paris : France (2012)</arxiv:comment>
    <link href="http://arxiv.org/abs/1208.6389v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1208.6389v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.1399v1</id>
    <updated>2012-09-06T20:10:02Z</updated>
    <published>2012-09-06T20:10:02Z</published>
    <title>Video Chat with Multiple Cameras</title>
    <summary>  The dominant paradigm for video chat employs a single camera at each end of
the conversation, but some conversations can be greatly enhanced by using
multiple cameras at one or both ends. This paper provides the first rigorous
investigation of multi-camera video chat, concentrating especially on the
ability of users to switch between views at either end of the conversation. A
user study of 23 individuals analyzes the advantages and disadvantages of
permitting a user to switch between views at a remote location. Benchmark
experiments employing up to four webcams simultaneously demonstrate that
multi-camera video chat is feasible on consumer hardware. The paper also
presents the design of MultiCam, a software package permitting multi-camera
video chat. Some important trade-offs in the design of MultiCam are discussed,
and typical usage scenarios are analyzed.
</summary>
    <author>
      <name>John MacCormick</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">49 pages, 14 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1209.1399v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.1399v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.1; C.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.1673v1</id>
    <updated>2012-09-07T23:59:01Z</updated>
    <published>2012-09-07T23:59:01Z</published>
    <title>Recovering Missing Coefficients in DCT-Transformed Images</title>
    <summary>  A general method for recovering missing DCT coefficients in DCT-transformed
images is presented in this work. We model the DCT coefficients recovery
problem as an optimization problem and recover all missing DCT coefficients via
linear programming. The visual quality of the recovered image gradually
decreases as the number of missing DCT coefficients increases. For some images,
the quality is surprisingly good even when more than 10 most significant DCT
coefficients are missing. When only the DC coefficient is missing, the proposed
algorithm outperforms existing methods according to experimental results
conducted on 200 test images. The proposed recovery method can be used for
cryptanalysis of DCT based selective encryption schemes and other applications.
</summary>
    <author>
      <name>Shujun Li</name>
    </author>
    <author>
      <name>Andreas Karrenbauer</name>
    </author>
    <author>
      <name>Dietmar Saupe</name>
    </author>
    <author>
      <name>C. -C. Jay Kuo</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/ICIP.2011.6115738</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/ICIP.2011.6115738" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 4 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of 2011 18th IEEE International Conference on Image
  Processing (ICIP 2011), pages 1537-1540, IEEE, 2011</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1209.1673v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.1673v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.2067v2</id>
    <updated>2013-11-23T23:41:20Z</updated>
    <published>2012-09-10T17:19:45Z</published>
    <title>A Markov Decision Model for Adaptive Scheduling of Stored Scalable
  Videos</title>
    <summary>  We propose two scheduling algorithms that seek to optimize the quality of
scalably coded videos that have been stored at a video server before
transmission.} The first scheduling algorithm is derived from a Markov Decision
Process (MDP) formulation developed here. We model the dynamics of the channel
as a Markov chain and reduce the problem of dynamic video scheduling to a
tractable Markov decision problem over a finite state space. Based on the MDP
formulation, a near-optimal scheduling policy is computed that minimize the
mean square error. Using insights taken from the development of the optimal
MDP-based scheduling policy, the second proposed scheduling algorithm is an
online scheduling method that only requires easily measurable knowledge of the
channel dynamics, and is thus viable in practice. Simulation results show that
the performance of both scheduling algorithms is close to a performance upper
bound also derived in this paper.
</summary>
    <author>
      <name>Chao Chen</name>
    </author>
    <author>
      <name>Robert W. Heath Jr</name>
    </author>
    <author>
      <name>Alan C. Bovik</name>
    </author>
    <author>
      <name>Gustavo de Veciana</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE Transactions on Circuits and Systems for Video Technology,
  vol.23, no.6, pp.1081-1095, June 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1209.2067v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.2067v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.8165v1</id>
    <updated>2012-10-30T21:05:16Z</updated>
    <published>2012-10-30T21:05:16Z</published>
    <title>Non-uniform Quantization of Detail Components in Wavelet Transformed
  Image for Lossy JPEG2000 Compression</title>
    <summary>  The paper introduces the idea of non-uniform quantization in the detail
components of wavelet transformed image. It argues that most of the
coefficients of horizontal, vertical and diagonal components lie near to zeros
and the coefficients representing large differences are few at the extreme ends
of histogram. Therefore, this paper advocates need for variable step size
quantization scheme which preserves the edge information at the edge of
histogram and removes redundancy with the minimal number of quantized values.
To support the idea, preliminary results are provided using a non-uniform
quantization algorithm. We believe that successful implementation of
non-uniform quantization in detail components in JPEG-2000 still image standard
will improve image quality and compression efficiency with lesser number of
quantized values.
</summary>
    <author>
      <name>Madhur Srivastava</name>
    </author>
    <author>
      <name>Prasanta K. Panigrahi</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5220/0004333706040607</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5220/0004333706040607" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 3 figures, conference</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Conference on Pattern Recognition Applications and
  Methods (ICPRAM 2013)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1210.8165v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.8165v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.2699v1</id>
    <updated>2012-11-12T17:15:41Z</updated>
    <published>2012-11-12T17:15:41Z</published>
    <title>A Non-Blind Watermarking Scheme for Gray Scale Images in Discrete
  Wavelet Transform Domain using Two Subbands</title>
    <summary>  Digital watermarking is the process to hide digital pattern directly into a
digital content. Digital watermarking techniques are used to address digital
rights management, protect information and conceal secrets. An invisible
non-blind watermarking approach for gray scale images is proposed in this
paper. The host image is decomposed into 3-levels using Discrete Wavelet
Transform. Based on the parent-child relationship between the wavelet
coefficients the Set Partitioning in Hierarchical Trees (SPIHT) compression
algorithm is performed on the LH3, LH2, HL3 and HL2 subbands to find out the
significant coefficients. The most significant coefficients of LH2 and HL2
bands are selected to embed a binary watermark image. The selected significant
coefficients are modulated using Noise Visibility Function, which is considered
as the best strength to ensure better imperceptibility. The approach is tested
against various image processing attacks such as addition of noise, filtering,
cropping, JPEG compression, histogram equalization and contrast adjustment. The
experimental results reveal the high effectiveness of the method.
</summary>
    <author>
      <name>Abdur Shahid</name>
    </author>
    <author>
      <name>Shahriar Badsha</name>
    </author>
    <author>
      <name>Md. Rethwan Kabeer</name>
    </author>
    <author>
      <name>Junaid Ahsan</name>
    </author>
    <author>
      <name>Mufti Mahmud</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 7 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IJCSI International Journal of Computer Science Issues, Vol. 9,
  Issue 5, No 1, September 2012, page 101-109</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1211.2699v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.2699v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.4683v1</id>
    <updated>2012-11-20T08:22:56Z</updated>
    <published>2012-11-20T08:22:56Z</published>
    <title>Content based video retrieval</title>
    <summary>  Content based video retrieval is an approach for facilitating the searching
and browsing of large image collections over World Wide Web. In this approach,
video analysis is conducted on low level visual properties extracted from video
frame. We believed that in order to create an effective video retrieval system,
visual perception must be taken into account. We conjectured that a technique
which employs multiple features for indexing and retrieval would be more
effective in the discrimination and search tasks of videos. In order to
validate this claim, content based indexing and retrieval systems were
implemented using color histogram, various texture features and other
approaches. Videos were stored in Oracle 9i Database and a user study measured
correctness of response.
</summary>
    <author>
      <name>B. V. Patel</name>
    </author>
    <author>
      <name>B. B. Meshram</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5121/ijma.2012.4506</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5121/ijma.2012.4506" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">The International Journal of Multimedia &amp; Its Applications (IJMA)
  Vol.4, No.5, October 2012</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1211.4683v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.4683v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.6058v1</id>
    <updated>2012-12-25T14:28:52Z</updated>
    <published>2012-12-25T14:28:52Z</published>
    <title>High Quality Image Interpolation via Local Autoregressive and Nonlocal
  3-D Sparse Regularization</title>
    <summary>  In this paper, we propose a novel image interpolation algorithm, which is
formulated via combining both the local autoregressive (AR) model and the
nonlocal adaptive 3-D sparse model as regularized constraints under the
regularization framework. Estimating the high-resolution image by the local AR
regularization is different from these conventional AR models, which weighted
calculates the interpolation coefficients without considering the rough
structural similarity between the low-resolution (LR) and high-resolution (HR)
images. Then the nonlocal adaptive 3-D sparse model is formulated to regularize
the interpolated HR image, which provides a way to modify these pixels with the
problem of numerical stability caused by AR model. In addition, a new
Split-Bregman based iterative algorithm is developed to solve the above
optimization problem iteratively. Experiment results demonstrate that the
proposed algorithm achieves significant performance improvements over the
traditional algorithms in terms of both objective quality and visual perception
</summary>
    <author>
      <name>Xinwei Gao</name>
    </author>
    <author>
      <name>Jian Zhang</name>
    </author>
    <author>
      <name>Feng Jiang</name>
    </author>
    <author>
      <name>Xiaopeng Fan</name>
    </author>
    <author>
      <name>Siwei Ma</name>
    </author>
    <author>
      <name>Debin Zhao</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/VCIP.2012.6410749</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/VCIP.2012.6410749" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 5 figures, 2 tables, to be published at IEEE Visual
  Communications and Image Processing (VCIP) 2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1212.6058v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.6058v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.0344v1</id>
    <updated>2013-01-02T22:18:06Z</updated>
    <published>2013-01-02T22:18:06Z</published>
    <title>A Poisson Hidden Markov Model for Multiview Video Traffic</title>
    <summary>  Multiview video has recently emerged as a means to improve user experience in
novel multimedia services. We propose a new stochastic model to characterize
the traffic generated by a Multiview Video Coding (MVC) variable bit rate
source. To this aim, we resort to a Poisson Hidden Markov Model (P-HMM), in
which the first (hidden) layer represents the evolution of the video activity
and the second layer represents the frame sizes of the multiple encoded views.
We propose a method for estimating the model parameters in long MVC sequences.
We then present extensive numerical simulations assessing the model's ability
to produce traffic with realistic characteristics for a general class of MVC
sequences. We then extend our framework to network applications where we show
that our model is able to accurately describe the sender and receiver buffers
behavior in MVC transmission. Finally, we derive a model of user behavior for
interactive view selection, which, in conjunction with our traffic model, is
able to accurately predict actual network load in interactive multiview
services.
</summary>
    <author>
      <name>Lorenzo Rossi</name>
    </author>
    <author>
      <name>Jacob Chakareski</name>
    </author>
    <author>
      <name>Pascal Frossard</name>
    </author>
    <author>
      <name>Stefania Colonnese</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 21 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1301.0344v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.0344v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.1894v1</id>
    <updated>2013-01-09T15:36:40Z</updated>
    <published>2013-01-09T15:36:40Z</published>
    <title>An Extensive Analysis of Query by Singing/Humming System Through Query
  Proportion</title>
    <summary>  Query by Singing/Humming (QBSH) is a Music Information Retrieval (MIR) system
with small audio excerpt as query. The rising availability of digital music
stipulates effective music retrieval methods. Further, MIR systems support
content based searching for music and requires no musical acquaintance. Current
work on QBSH focuses mainly on melody features such as pitch, rhythm, note
etc., size of databases, response time, score matching and search algorithms.
Even though a variety of QBSH techniques are proposed, there is a dearth of
work to analyze QBSH through query excerption. Here, we present an analysis
that works on QBSH through query excerpt. To substantiate a series of
experiments are conducted with the help of Mel-Frequency Cepstral Coefficients
(MFCC), Linear Predictive Coefficients (LPC) and Linear Predictive Cepstral
Coefficients (LPCC) to portray the robustness of the knowledge representation.
Proposed experiments attempt to reveal that retrieval performance as well as
precision diminishes in the snail phase with the growing database size.
</summary>
    <author>
      <name>Trisiladevi C. Nagavi</name>
    </author>
    <author>
      <name>Nagappa U. Bhajantri</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5121/ijma.2012.4606</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5121/ijma.2012.4606" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages,11 figures; The International Journal of Multimedia &amp; Its
  Applications (IJMA) Vol.4, No.6, December 2012. arXiv admin note: text
  overlap with arXiv:1003.4083 by other authors</arxiv:comment>
    <link href="http://arxiv.org/abs/1301.1894v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.1894v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.2173v1</id>
    <updated>2013-01-10T16:29:11Z</updated>
    <published>2013-01-10T16:29:11Z</published>
    <title>AViTExt: Automatic Video Text Extraction, A new Approach for video
  content indexing Application</title>
    <summary>  In this paper, we propose a spatial temporal video-text detection technique
which proceed in two principal steps:potential text region detection and a
filtering process. In the first step we divide dynamically each pair of
consecutive video frames into sub block in order to detect change. A
significant difference between homologous blocks implies the appearance of an
important object which may be a text region. The temporal redundancy is then
used to filter these regions and forms an effective text region. The
experimentation driven on a variety of video sequences shows the effectiveness
of our approach by obtaining a 89,39% as precision rate and 90,19 as recall.
</summary>
    <author>
      <name>Baseem Bouaziz</name>
    </author>
    <author>
      <name>Tarek Zlitni</name>
    </author>
    <author>
      <name>Walid Mahdi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 5 figures, 3rd International Conference on Information and
  Communication Technologies: From Theory to Applications(ICTTA 2008)</arxiv:comment>
    <link href="http://arxiv.org/abs/1301.2173v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.2173v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.2200v1</id>
    <updated>2013-01-10T17:56:02Z</updated>
    <published>2013-01-10T17:56:02Z</published>
    <title>A Visual Grammar Approach for TV Program Identification</title>
    <summary>  Automatic identification of TV programs within TV streams is an important
task for archive exploitation. This paper proposes a new spatial-temporal
approach to identify programs in TV streams in two main steps: First, a
reference catalogue for video grammars of visual jingles is constructed. We
exploit visual grammars characterizing instances of the same program type in
order to identify the various program types in the TV stream. The role of video
grammar is to represent the visual invariants for each visual jingle using a
set of descriptors appropriate for each TV program. Secondly, programs in TV
streams are identified by examining the similarity of the video signal to the
visual grammars in the catalogue. The main idea of identification process
consists in comparing the visual similarity of the video signal signature in TV
stream to the catalogue elements. After presenting the proposed approach, the
paper overviews the encouraging experimental results on several streams
extracted from different channels and composed of several programs.
</summary>
    <author>
      <name>Tarek Zlitni</name>
    </author>
    <author>
      <name>Walid Mahdi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 6 figures, (IJCNS) International Journal of Computer and
  Network Security, Vol. 2, No. 9, September 2010</arxiv:comment>
    <link href="http://arxiv.org/abs/1301.2200v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.2200v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.5793v1</id>
    <updated>2013-01-24T14:31:10Z</updated>
    <published>2013-01-24T14:31:10Z</published>
    <title>Video Tester -- A multiple-metric framework for video quality assessment
  over IP networks</title>
    <summary>  This paper presents an extensible and reusable framework which addresses the
problem of video quality assessment over IP networks. The proposed tool
(referred to as Video-Tester) supports raw uncompressed video encoding and
decoding. It also includes different video over IP transmission methods (i.e.:
RTP over UDP unicast and multicast, as well as RTP over TCP). In addition, it
is furnished with a rich set of offline analysis capabilities. Video-Tester
analysis includes QoS and bitstream parameters estimation (i.e.: bandwidth,
packet inter-arrival time, jitter and loss rate, as well as GOP size and
I-frame loss rate). Our design facilitates the integration of virtually any
existing video quality metric thanks to the adopted Python-based modular
approach. Video-Tester currently provides PSNR, SSIM, ITU-T G.1070 video
quality metric, DIV and PSNR-based MOS estimations. In order to promote its use
and extension, Video-Tester is open and publicly available.
</summary>
    <author>
      <name>Iñaki Ucar</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Universidad Pública de Navarra</arxiv:affiliation>
    </author>
    <author>
      <name>Jorge Navarro-Ortiz</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Universidad de Granada</arxiv:affiliation>
    </author>
    <author>
      <name>Pablo Ameigeiras</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Universidad de Granada</arxiv:affiliation>
    </author>
    <author>
      <name>Juan M. Lopez-Soler</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Universidad de Granada</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/BMSB.2012.6264243</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/BMSB.2012.6264243" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 5 figures. For the Google Code project, see
  http://video-tester.googlecode.com/</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE International Symposium on Broadband Multimedia Systems and
  Broadcasting, pp.1-5, 2012</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1301.5793v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.5793v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="C.2.3; C.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1303.1697v1</id>
    <updated>2013-03-07T14:17:23Z</updated>
    <published>2013-03-07T14:17:23Z</published>
    <title>Secure Video Streaming Plug-In</title>
    <summary>  Video sharing sites like YouTube, Metacafe, Dailymotion, Vimeo, etc. provide
a platform for media content sharing among its users. Some of these videos are
copyright protected and restricted from being downloaded and saved. But users
can use various download managers or application programs to download and save
these videos. This affects the incoming traffic on these websites reducing
their hit rate and consequently reducing their revenue. Adobe Flash Player is
the most commonly used player for watching online videos. It uses RTMP (Real
Time Messaging Protocol) to stream audio, video and data over the Internet,
between a Flash Player and Adobe Flash Media Server.Here, we propose a plug-in
that enables the site owner control over downloading of videos from such
website. The plug-in will be installed at the client side with the consent of
the user. When the video is being played this plug-in will send unique keys to
the media server. The server will continue streaming the video after verifying
the keys. Download managers or application programs will not be able to
download the videos as they wont be able to create the unique keys that need to
be sent to the server.
</summary>
    <author>
      <name>Avinash Bhujbal</name>
    </author>
    <author>
      <name>Ashish Jagtap</name>
    </author>
    <author>
      <name>Devendra Gurav</name>
    </author>
    <author>
      <name>Tino Jameskutty</name>
    </author>
    <link href="http://arxiv.org/abs/1303.1697v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1303.1697v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.0793v1</id>
    <updated>2013-04-02T20:35:11Z</updated>
    <published>2013-04-02T20:35:11Z</published>
    <title>A local fingerprinting approach for audio copy detection</title>
    <summary>  This study proposes an audio copy detection system that is robust to various
attacks. These include the severe pitch shift and tempo change attacks which
existing systems fail to detect. First, we propose a novel two dimensional
representation for audio signals called the time-chroma image. This image is
based on a modification of the concept of chroma in the music literature and is
shown to achieve better performance in song identification. Then, we propose a
novel fingerprinting algorithm that extracts local fingerprints from the
time-chroma image. The proposed local fingerprinting algorithm is invariant to
time/frequency scale changes in audio signals. It also outperforms existing
methods like SIFT by a great extent. Finally, we introduce a song
identification algorithm that uses the proposed fingerprints. The resulting
copy detection system is shown to significantly outperform existing methods.
Besides being able to detect whether a song (or a part of it) has been copied,
the proposed system can accurately estimate the amount of pitch shift and/or
tempo change that might have been applied to a song.
</summary>
    <author>
      <name>Mani Malekesmaeili</name>
    </author>
    <author>
      <name>Rabab K. Ward</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, journal</arxiv:comment>
    <link href="http://arxiv.org/abs/1304.0793v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.0793v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.1571v1</id>
    <updated>2013-04-04T22:17:47Z</updated>
    <published>2013-04-04T22:17:47Z</published>
    <title>Hiding Image in Image by Five Modulus Method for Image Steganography</title>
    <summary>  This paper is to create a practical steganographic implementation to hide
color image (stego) inside another color image (cover). The proposed technique
uses Five Modulus Method to convert the whole pixels within both the cover and
the stego images into multiples of five. Since each pixels inside the stego
image is divisible by five then the whole stego image could be divided by five
to get new range of pixels 0..51. Basically, the reminder of each number that
is not divisible by five is either 1,2,3 or 4 when divided by 5. Subsequently,
then a 4-by-4 window size has been implemented to accommodate the proposed
technique. For each 4-by-4 window inside the cover image, a number from 1 to 4
could be embedded secretly from the stego image. The previous discussion must
be applied separately for each of the R, G, and B arrays. Moreover, a stego-key
could be combined with the proposed algorithm to make it difficult for any
adversary to extract the secret image from the cover image. Based on the PSNR
value, the extracted stego image has high PSNR value. Hence this new
steganography algorithm is very efficient to hide color images.
</summary>
    <author>
      <name>Firas A. Jassim</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 5 tables, 5 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of computing, volume 5, issue 2, 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1304.1571v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.1571v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.2671v1</id>
    <updated>2013-04-09T17:29:56Z</updated>
    <published>2013-04-09T17:29:56Z</published>
    <title>Genetic Soundtracks: Creative Matching of Audio to Video</title>
    <summary>  The matching of the soundtrack in a movie or a video can have an enormous
influence in the message being conveyed and its impact, in the sense of
involvement and engagement, and ultimately in their aesthetic and entertainment
qualities. Art is often associated with creativity, implying the presence of
inspiration, originality and appropriateness. Evolutionary systems provides us
with the novelty, showing us new and subtly different solutions in every
generation, possibly stimulating the creativity of the human using the system.
In this paper, we present Genetic Soundtracks, an evolutionary approach to the
creative matching of audio to a video. It analyzes both media to extract
features based on their content, and adopts genetic algorithms, with the
purpose of truncating, combining and adjusting audio clips, to align and match
them with the video scenes.
</summary>
    <author>
      <name>Jorge Gomes</name>
    </author>
    <author>
      <name>Fernando Silva</name>
    </author>
    <author>
      <name>Teresa Chambel</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Artech'2012 Crossing Digital Boundaries, 6th International Conference
  on Digital Arts. Faro, Portugal. Nov 7-9, 2012</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">6th International Conference on Digital Arts (Artech), pp.349-352,
  2012</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1304.2671v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.2671v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.3056v1</id>
    <updated>2013-04-10T19:12:38Z</updated>
    <published>2013-04-10T19:12:38Z</published>
    <title>Anticipatory Buffer Control and Resource Allocation for Wireless Video
  Streaming</title>
    <summary>  This paper describes a new approach for allocating resources to video
streaming traffic. Assuming that the future channel state can be predicted for
a certain time, we minimize the fraction of the bandwidth consumed for smooth
streaming by jointly allocating wireless channel resources and play-out buffer
size. To formalize this idea, we introduce a new model to capture the dynamic
of a video streaming buffer and the allocated spectrum in an optimization
problem. The result is a Linear Program that allows to trade off buffer size
and allocated bandwidth. Based on this tractable model, our simulation results
show that anticipating poor channel states and pre-loading the buffer
accordingly allows to serve more users at perfect video quality.
</summary>
    <author>
      <name>Sanam Sadr</name>
    </author>
    <author>
      <name>Stefan Valentin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, submitted to IEEE Globecom 2013</arxiv:comment>
    <link href="http://arxiv.org/abs/1304.3056v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.3056v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.3629v1</id>
    <updated>2013-04-11T14:45:51Z</updated>
    <published>2013-04-11T14:45:51Z</published>
    <title>A Secure And High Capacity Image Steganography Technique</title>
    <summary>  Steganography is the science of invisible communication. The purpose of
Steganography is to maintain secret communication between two parties. The
secret information can be concealed in content such as image, audio, or video.
This paper provides a novel image steganography technique to hide multiple
secret images and keys in color cover image using Integer Wavelet Transform
(IWT). There is no visual difference between the stego image and the cover
image. The extracted secret images are also similar to the original secret
images. Very good PSNR (Peak Signal to Noise Ratio) values are obtained for
both stego and extracted secret images. The results are compared with the
results of other techniques, where single image is hidden and it is found that
the proposed technique is simple and gives better PSNR values than others.
</summary>
    <author>
      <name>Hemalatha S</name>
    </author>
    <author>
      <name>U Dinesh Acharya</name>
    </author>
    <author>
      <name>Renuka A</name>
    </author>
    <author>
      <name>Priya R. Kamath</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5121/sipij.2013.4108</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5121/sipij.2013.4108" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, Signal &amp; Image Processing : An International Journal (SIPIJ)
  Vol.4, No.1, February 2013. arXiv admin note: substantial text overlap with
  arXiv:1304.3313</arxiv:comment>
    <link href="http://arxiv.org/abs/1304.3629v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.3629v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.3758v1</id>
    <updated>2013-04-13T01:59:01Z</updated>
    <published>2013-04-13T01:59:01Z</published>
    <title>Metrics for Video Quality Assessment in Mobile Scenarios</title>
    <summary>  With exponential increase in the volumes of video traffic in cellular
net-works, there is an increasing need for optimizing the quality of video
delivery. 4G networks (Long Term Evolution Advanced or LTE A) are being
introduced in many countries worldwide, which allow a downlink speed of upto 1
Gbps and uplink of 100 Mbps over a single base station. This makes a strong
push towards video broadcasting over LTE networks, characterizing its
performance and developing metrics which can be deployed to provide user
feedback of video quality and feed-back them to network operators to fine tune
the network. In this paper, we characterize the performance of video
transmission over LTE A physical layer using popular video quality metrics such
as SSIM, Blocking, Blurring, NIQE and BRISQUE. We conduct experiments to find a
suitable no-reference metrics for mobile scenario and find that Blocking
Metrics is most promising in case of channel or modulation variations but it
does not perform well to quantize variations in compression ratios. The metrics
BRISQUE is very efficient in quantizing this distortion and performs well in
case of network variations also.
</summary>
    <author>
      <name>Gaurav Pande</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to International Journal of Digital Multimedia Broadcasting</arxiv:comment>
    <link href="http://arxiv.org/abs/1304.3758v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.3758v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.5068v1</id>
    <updated>2013-04-18T10:00:38Z</updated>
    <published>2013-04-18T10:00:38Z</published>
    <title>Joint On-the-Fly Network Coding/Video Quality Adaptation for Real-Time
  Delivery</title>
    <summary>  This paper introduces a redundancy adaptation algorithm for an on-the-fly
erasure network coding scheme called Tetrys in the context of real-time video
transmission. The algorithm exploits the relationship between the redundancy
ratio used by Tetrys and the gain or loss in encoding bit rate from changing a
video quality parameter called the Quantization Parameter (QP). Our evaluations
show that with equal or less bandwidth occupation, the video protected by
Tetrys with redundancy adaptation algorithm obtains a PSNR gain up to or more 4
dB compared to the video without Tetrys protection. We demonstrate that the
Tetrys redundancy adaptation algorithm performs well with the variations of
both loss pattern and delay induced by the networks. We also show that Tetrys
with the redundancy adaptation algorithm outperforms FEC with and without
redundancy adaptation.
</summary>
    <author>
      <name>Tuan Tran Thai</name>
    </author>
    <author>
      <name>Jérôme Lacan</name>
    </author>
    <author>
      <name>Emmanuel Lochin</name>
    </author>
    <link href="http://arxiv.org/abs/1304.5068v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.5068v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.6872v1</id>
    <updated>2013-04-25T10:53:39Z</updated>
    <published>2013-04-25T10:53:39Z</published>
    <title>Security Issues In Speech Watermarking for Information Transmission</title>
    <summary>  The secure transmission of speech information is a significant issue faced by
many security professionals and individuals. By applying voice-encryption
technique any kind of encrypted sensitive speech data such as password can be
transmitted. But this has the serious disadvantage that by means of
cryptanalysis attack encrypted data can be compromised. Increasing the strength
of encryption/decryption results in an associated increased in the cost.
Additional techniques like stenography and digital watermarking can be used to
conceal information in an undetectable way in audio data. However this
watermarked audio data has to be send through unreliable media and an
eavesdropper might get hold of secret message and can also determine the
identity of a speaker who is sending the information since human voice contains
information based on its characteristics such as frequency, pitch, and energy.
This paper proposes Normalized Speech Watermarking technique. Speech signal is
normalized to hide the identity of the speaker who is sending the information
and then speech watermarking technique is applied on this normalized signal
that contains the message (password) so that what information is transmitted
should not be unauthorizedly revealed.
</summary>
    <author>
      <name>Rupa Patel</name>
    </author>
    <author>
      <name>Urmila Shrawankar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Pages: 10 Figures: 5, Conference Procedings, AMOC 2011, Advances in
  Modeling, Optimization and Computing</arxiv:comment>
    <link href="http://arxiv.org/abs/1304.6872v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.6872v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.8080v1</id>
    <updated>2013-04-25T10:42:04Z</updated>
    <published>2013-04-25T10:42:04Z</published>
    <title>Secure Transmission of Password Using Speech Watermarking</title>
    <summary>  Internet is one of the most valuable resources for information communication
and retrievals. Most multimedia signals today are in digital formats. The
digital data can be duplicated and edited with great ease which has led to a
need for data integrity and protection of digital data. The security
requirements such as integrity or data authentication can be met by
implementing security measures using digital watermarking techniques. In this
paper a blind speech watermarking algorithm that embeds the watermark signal
data in the musical (sequence) host signal by using frequency masking is used.
A different logarithmic approach is proposed. In this regard a logarithmic
function is first applied to watermark data. Then the transformed signal is
embedded to the converted version of host signal which is obtained by applying
Fast Fourier transform method. Finally using inverse Fast Fourier Transform and
antilogarithmic function watermark signal is retrieved.
</summary>
    <author>
      <name>Rupa Patel</name>
    </author>
    <author>
      <name>Urmila Shrawankar</name>
    </author>
    <author>
      <name>V. M Thakare</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Pages: 4 Figures: 7, International Journal of Computer Science and
  Technology (IJCST) Vol.2, Issue 3, September 2011</arxiv:comment>
    <link href="http://arxiv.org/abs/1304.8080v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.8080v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1305.1887v1</id>
    <updated>2013-05-08T17:19:50Z</updated>
    <published>2013-05-08T17:19:50Z</published>
    <title>Performance Evaluation of Video Communications over 4G Network</title>
    <summary>  With exponential increase in the volumes of video traffic in cellular
net-works, there is an increasing need for optimizing the quality of video
delivery. 4G networks (Long Term Evolution Advanced or LTE A) are being
introduced in many countries worldwide, which allow a downlink speed of upto 1
Gbps and uplink of 100 Mbps over a single base station. In this paper, we
characterize the performance of LTE A physical layer in terms of transmitted
video quality when the channel condi-tions and LTE settings are varied. We test
the performance achieved as the channel quality is changed and HARQ features
are enabled in physical layer. Blocking and blurring metrics were used to model
image quality.
</summary>
    <author>
      <name>Gaurav Pande</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted in ICACNI 2013. arXiv admin note: substantial text overlap
  with arXiv:1304.3758</arxiv:comment>
    <link href="http://arxiv.org/abs/1305.1887v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1305.1887v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1305.2251v4</id>
    <updated>2015-07-17T10:29:44Z</updated>
    <published>2013-05-10T02:53:07Z</published>
    <title>Quantum Image Representation Through Two-Dimensional Quantum States and
  Normalized Amplitude</title>
    <summary>  We propose a novel method for image representation in quantum computers,
which uses the two-dimensional (2-D) quantum states to locate each pixel in an
image through row-location and column-location vectors for identifying each
pixel location. The quantum state of an image is the linear superposition of
the tensor product of the m-qubits row-location vector and the n-qubits
column-location vector of each pixel. It enables the natural quantum
representation of rectangular images that other methods lack. The
amplitude/intensity of each pixel is incorporated into the coefficient values
of the pixel's quantum state, without using any qubits. Due to the fact that
linear superposition, tensor product and qubits form the fundamental basis of
quantum computing, the proposed method presents the machine level
representation of images on quantum computers. Unlike other methods, this
method is a pure quantum representation without any classical components.
</summary>
    <author>
      <name>Madhur Srivastava</name>
    </author>
    <author>
      <name>Subhayan R. Moulick</name>
    </author>
    <author>
      <name>Prasanta K. Panigrahi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1305.2251v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1305.2251v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1305.3021v2</id>
    <updated>2015-08-07T13:06:09Z</updated>
    <published>2013-05-14T05:27:52Z</published>
    <title>Wave Atom Based Watermarking</title>
    <summary>  Watermarking helps in ensuring originality, ownership and copyrights of a
digital image. This paper aims at embedding a Watermark in an image using Wave
Atom Transform. Preference of Wave Atoms on other transformations has been due
to its sparser expansion, adaptability to the direction of local pattern, and
sharp frequency localization. In this scheme, we had tried to spread the
watermark in an image so that the information at one place is very small and
undetectable. In order to extract the watermark and verify ownership of an
image, one would have the advantage of prior knowledge of embedded locations. A
noise of high amplitude will be needed to be added to the image for watermark
distortion. Furthermore, the information spread will ensure the robustness of
the watermark data. The proposed scheme has the ability to withstand malicious
operations and attacks.
</summary>
    <author>
      <name>Ijaz Bukhari</name>
    </author>
    <author>
      <name> Nuhman-ul-Haq</name>
    </author>
    <author>
      <name>Khizar Hyat</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">I want to withdraw the paper due to serious error</arxiv:comment>
    <link href="http://arxiv.org/abs/1305.3021v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1305.3021v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1305.4999v2</id>
    <updated>2013-12-08T10:24:01Z</updated>
    <published>2013-05-22T01:25:02Z</published>
    <title>Optimal Frame Transmission for Scalable Video with Hierarchical
  Prediction Structure</title>
    <summary>  An optimal frame transmission scheme is presented for streaming scalable
video over a link with limited capacity. The objective is to select a
transmission sequence of frames and their transmission schedule such that the
overall video quality is maximized. The problem is solved for two general
classes of hierarchical prediction structures, which include as a special case
the popular dyadic structure. Based on a new characterization of the
interdependence among frames in terms of trees, structural properties of an
optimal transmission schedule are derived. These properties lead to the
development of a jointly optimal frame selection and scheduling algorithm,
which has computational complexity that is quadratic in the number of frames.
Simulation results show that the optimal scheme substantially outperforms three
existing alternatives.
</summary>
    <author>
      <name>Saied Mehdian</name>
    </author>
    <author>
      <name>Ben Liang</name>
    </author>
    <link href="http://arxiv.org/abs/1305.4999v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1305.4999v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1306.0221v1</id>
    <updated>2013-06-02T15:53:26Z</updated>
    <published>2013-06-02T15:53:26Z</published>
    <title>Survey on QoE\QoS Correlation Models For Multimedia Services</title>
    <summary>  This paper presents a brief review of some existing correlation models which
attempt to map Quality of Service (QoS) to Quality of Experience (QoE) for
multimedia services. The term QoS refers to deterministic network behaviour, so
that data can be transported with a minimum of packet loss, delay and maximum
bandwidth. QoE is a subjective measure that involves human dimensions; it ties
together user perception, expectations, and experience of the application and
network performance. The Holy Grail of subjective measurement is to predict it
from the objective measurements; in other words predict QoE from a given set of
QoS parameters or vice versa. Whilst there are many quality models for
multimedia, most of them are only partial solutions to predicting QoE from a
given QoS. This contribution analyses a number of previous attempts and
optimisation techniquesthat can reliably compute the weighting coefficients for
the QoS/QoE mapping.
</summary>
    <author>
      <name>Mohammed Alreshoodi</name>
    </author>
    <author>
      <name>John Woods</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages, International Journal of Distributed and Parallel Systems
  (IJDPS)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Distributed and Parallel Systems (IJDPS)
  Vol.4, No.3, May 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1306.0221v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1306.0221v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1306.6920v1</id>
    <updated>2013-06-03T10:23:38Z</updated>
    <published>2013-06-03T10:23:38Z</published>
    <title>Enhanced Tiny Encryption Algorithm with Embedding (ETEA)</title>
    <summary>  As computer systems become more pervasive and complex, security is
increasingly important. Secure Transmission refers to the transfer of data such
as confidential or proprietary information over a secure channel. Many secure
transmission methods require a type of encryption. Secure transmissions are put
in place to prevent attacks such as ARP spoofing and general data loss. Hence,
in order to provide a better security mechanism, in this paper we propose
Enhanced Tiny Encryption Algorithm with Embedding (ETEA), a data hiding
technique called steganography along with the technique of encryption
(Cryptography). The advantage of ETEA is that it incorporates cryptography and
steganography. The advantage proposed algorithm is that it hides the messages.
</summary>
    <author>
      <name>Deepali Virmani</name>
    </author>
    <author>
      <name>Nidhi Beniwal</name>
    </author>
    <author>
      <name>Gargi Mandal</name>
    </author>
    <author>
      <name>Saloni Talwar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 3 figures, International Journal of Computers &amp; Technology,
  Vol 7, No 1, 2013</arxiv:comment>
    <link href="http://arxiv.org/abs/1306.6920v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1306.6920v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.0642v1</id>
    <updated>2013-07-02T09:33:43Z</updated>
    <published>2013-07-02T09:33:43Z</published>
    <title>A Novel Steganography Algorithm for Hiding Text in Image using Five
  Modulus Method</title>
    <summary>  The needs for steganographic techniques for hiding secret message inside
images have been arise. This paper is to create a practical steganographic
implementation to hide text inside grey scale images. The secret message is
hidden inside the cover image using Five Modulus Method. The novel algorithm is
called (ST-FMM. FMM which consists of transforming all the pixels within the
5X5 window size into its corresponding multiples of 5. After that, the secret
message is hidden inside the 5X5 window as a non-multiples of 5. Since the
modulus of non-multiples of 5 are 1,2,3 and 4, therefore; if the reminder is
one of these, then this pixel represents a secret character. The secret key
that has to be sent is the window size. The main advantage of this novel
algorithm is to keep the size of the cover image constant while the secret
message increased in size. Peak signal-to-noise ratio is captured for each of
the images tested. Based on the PSNR value of each images, the stego image has
high PSNR value. Hence this new steganography algorithm is very efficient to
hide the data inside the image.
</summary>
    <author>
      <name>Firas A. Jassim</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Applications, Vol.72, No.17, pp.
  39-44, June 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1307.0642v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.0642v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.2818v1</id>
    <updated>2013-07-10T15:07:26Z</updated>
    <published>2013-07-10T15:07:26Z</published>
    <title>Anisotropic Diffusion for Details Enhancement in Multi-Exposure Image
  Fusion</title>
    <summary>  We develop a multiexposure image fusion method based on texture features,
which exploits the edge preserving and intraregion smoothing property of
nonlinear diffusion filters based on partial differential equations (PDE). With
the captured multiexposure image series, we first decompose images into base
layers and detail layers to extract sharp details and fine details,
respectively. The magnitude of the gradient of the image intensity is utilized
to encourage smoothness at homogeneous regions in preference to inhomogeneous
regions. Then, we have considered texture features of the base layer to
generate a mask (i.e., decision mask) that guides the fusion of base layers in
multiresolution fashion. Finally, well-exposed fused image is obtained that
combines fused base layer and the detail layers at each scale across all the
input exposures. Proposed algorithm skipping complex High Dynamic Range Image
(HDRI) generation and tone mapping steps to produce detail preserving image for
display on standard dynamic range display devices. Moreover, our technique is
effective for blending flash/no-flash image pair and multifocus images, that
is, images focused on different targets.
</summary>
    <author>
      <name>Harbinder Singh</name>
    </author>
    <author>
      <name>Vinay Kumar</name>
    </author>
    <author>
      <name>Sunil Bhooshan</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1155/2013/928971</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1155/2013/928971" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">30 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ISRN Signal Processing, vol. 2013, Article ID 928971, 18 pages,
  2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1307.2818v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.2818v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.3026v1</id>
    <updated>2013-07-11T09:26:21Z</updated>
    <published>2013-07-11T09:26:21Z</published>
    <title>Comparison of secure and high capacity color image steganography
  techniques in RGB and YCbCr domains</title>
    <summary>  Steganography is one of the methods used for secret communication.
Steganography attempts to hide the existence of the information. The object
used to hide the secret information is called as cover object. Images are the
most popular cover objects used for steganography. Different techniques have to
be used for color image steganography and grey scale image steganography since
they are stored in different ways. Color image are normally stored with 24 bit
depth and grey scale images are stored with 8 bit depth. Color images can hold
large amount of secret information since they have three color components.
Different color spaces namely RGB (Red Green Blue), HSV (Hue, Saturation,
Value), YUV, YIQ, YCbCr (Luminance, Chrominance) etc. are used to represent
color images. Color image steganography can be done in any color space domain.
In this paper color image steganography in RGB and YCbCr domain are compared.
The secret information considered is grey scale image. Since RGB is the common
method of representation, hiding secret information in this format is not
secure.
</summary>
    <author>
      <name>S. Hemalatha</name>
    </author>
    <author>
      <name>U. Dinesh Acharya</name>
    </author>
    <author>
      <name>A. Renuka</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Journal, 9 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Advanced Information Technology (IJAIT)
  Vol. 3, No. 3, June 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1307.3026v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.3026v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.3294v1</id>
    <updated>2013-07-11T23:35:44Z</updated>
    <published>2013-07-11T23:35:44Z</published>
    <title>A dwt, dct and svd based watermarking technique to protect the image
  piracy</title>
    <summary>  With the rapid development of information technology and multimedia, the use
of digital data is increasing day by day. So it becomes very essential to
protect multimedia information from piracy and also it is challenging. A great
deal of Copyright owners is worried about protecting any kind of illegal
repetition of their information. Hence, facing all these kinds of problems
development of the techniques is very important. Digital watermarking
considered as a solution to prevent the multimedia data. In this paper, an idea
of watermarking is proposed and implemented. In proposed watermarking method,
the original image is rearranged using zigzag sequence and DWT is applied on
rearranged image. Then DCT and SVD are applied on all high bands LH, HL and HH.
Watermark is then embedded by modifying the singular values of these bands.
Extraction of watermark is performed by the inversion of watermark embedding
process. For choosing of these three bands it gives facility of mid-band and
pure high band that ensures good imperceptibility and more robustness against
different kinds of attacks.
</summary>
    <author>
      <name>Md. Maklachur Rahman</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5121/ijmpict.2013.4203</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5121/ijmpict.2013.4203" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 12 figures and 1 table</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Managing Public Sector Information and
  Communication Technologies (IJMPICT) Vol. 4, No. 2, June 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1307.3294v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.3294v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.3811v1</id>
    <updated>2013-07-15T03:14:05Z</updated>
    <published>2013-07-15T03:14:05Z</published>
    <title>Multiview Hessian Discriminative Sparse Coding for Image Annotation</title>
    <summary>  Sparse coding represents a signal sparsely by using an overcomplete
dictionary, and obtains promising performance in practical computer vision
applications, especially for signal restoration tasks such as image denoising
and image inpainting. In recent years, many discriminative sparse coding
algorithms have been developed for classification problems, but they cannot
naturally handle visual data represented by multiview features. In addition,
existing sparse coding algorithms use graph Laplacian to model the local
geometry of the data distribution. It has been identified that Laplacian
regularization biases the solution towards a constant function which possibly
leads to poor extrapolating power. In this paper, we present multiview Hessian
discriminative sparse coding (mHDSC) which seamlessly integrates Hessian
regularization with discriminative sparse coding for multiview learning
problems. In particular, mHDSC exploits Hessian regularization to steer the
solution which varies smoothly along geodesics in the manifold, and treats the
label information as an additional view of feature for incorporating the
discriminative power for image annotation. We conduct extensive experiments on
PASCAL VOC'07 dataset and demonstrate the effectiveness of mHDSC for image
annotation.
</summary>
    <author>
      <name>Weifeng Liu</name>
    </author>
    <author>
      <name>Dacheng Tao</name>
    </author>
    <author>
      <name>Jun Cheng</name>
    </author>
    <author>
      <name>Yuanyan Tang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">35 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Computer vision and image understanding,118(2014) 50-60</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1307.3811v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.3811v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.4581v4</id>
    <updated>2014-04-10T00:51:45Z</updated>
    <published>2013-07-17T11:23:09Z</published>
    <title>Smart Streaming for Online Video Services</title>
    <summary>  Bandwidth consumption is a significant concern for online video service
providers. Practical video streaming systems usually use some form of HTTP
streaming (progressive download) to let users download the video at a faster
rate than the video bitrate. Since users may quit before viewing the complete
video, however, much of the downloaded video will be "wasted". To the extent
that users' departure behavior can be predicted, we develop smart streaming
that can be used to improve user QoE with limited server bandwidth or save
bandwidth cost with unlimited server bandwidth. Through measurement, we extract
certain user behavior properties for implementing such smart streaming, and
demonstrate its advantage using prototype implementation as well as
simulations.
</summary>
    <author>
      <name>Liang Chen</name>
    </author>
    <author>
      <name>Yipeng Zhou</name>
    </author>
    <author>
      <name>Dah Ming Chiu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper has been updated after checking the possible issues</arxiv:comment>
    <link href="http://arxiv.org/abs/1307.4581v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.4581v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.8385v1</id>
    <updated>2013-07-31T16:55:35Z</updated>
    <published>2013-07-31T16:55:35Z</published>
    <title>A simple technique for steganography</title>
    <summary>  A new technique for data hiding in digital image is proposed in this paper.
Steganography is a well known technique for hiding data in an image, but
generally the format of image plays a pivotal role in it, and the scheme is
format dependent. In this paper we will discuss a new technique where
irrespective of the format of image, we can easily hide a large amount of data
without deteriorating the quality of the image. The data to be hidden is
enciphered with the help of a secret key. This enciphered data is then embedded
at the end of the image. The enciphered data bits are extracted and then
deciphered with the help of same key used for encryption. Simulation results
show that Image Quality Measures of this proposed scheme are better than the
conventional LSB replacing technique. The proposed method is simple and is easy
to implement.
</summary>
    <author>
      <name>Adity Sharma</name>
    </author>
    <author>
      <name>Anoo Agarwal</name>
    </author>
    <author>
      <name>Vinay Kumar</name>
    </author>
    <link href="http://arxiv.org/abs/1307.8385v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.8385v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1308.0315v1</id>
    <updated>2013-08-01T19:45:23Z</updated>
    <published>2013-08-01T19:45:23Z</published>
    <title>MAS for video objects segmentation and tracking based on active contours
  and SURF descriptor</title>
    <summary>  In computer vision, video segmentation and tracking is an important
challenging issue. In this paper, we describe a new video sequences
segmentation and tracking algorithm based on MAS "multi-agent systems" and SURF
"Speeded Up Robust Features". Our approach consists in modelling a multi-agent
system for segmenting the first image from a video sequence and tracking
objects in the video sequences. The used agents are supervisor and explorator
agents, they are communicating between them and they inspire in their behavior
from active contours approaches. The tracking of objects is based on SURF
descriptors "Speed Up Robust Features". We used the DIMA platform and "API
Ateji PX" (an extension of the Java language to facilitate parallel programming
on heterogeneous architectures) to implement this algorithm. The experimental
results indicate that the proposed algorithm is more robust and faster than
previous approaches.
</summary>
    <author>
      <name>Mohamed Chakroun</name>
    </author>
    <author>
      <name>Ali Wali</name>
    </author>
    <author>
      <name>Adel M. Alimi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IJCSI International Journal of Computer Science Issues, Vol. 10,
  Issue 2, No 3, March 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1308.0315v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1308.0315v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1308.0435v1</id>
    <updated>2013-08-02T08:20:13Z</updated>
    <published>2013-08-02T08:20:13Z</published>
    <title>Improved Watermarking Scheme Using Discrete Cosine Transform and Schur
  Decomposition</title>
    <summary>  Watermarking is a technique which consists in introducing a brand, the name
or the logo of the author, in an image in order to protect it against illegal
copy. The capacity of the existing watermark channel is often limited. We
propose in this paper a new robust method which consists in adding the
triangular matrix of the mark obtained after the Schur decomposition to the DCT
transform of the host image. The unitary matrix acts as secret key for the
extraction of the mark. Unlike most watermarking algorithms, the host image and
the mark have the same size. The results show that our method is robust against
attack techniques as : JPEG compression, colors reducing, adding noise,
filtering, cropping, low rotations, and histogram spreading.
</summary>
    <author>
      <name>Henri Bruno Razafindradina</name>
    </author>
    <author>
      <name>Nicolas Raft Razafindrakoto</name>
    </author>
    <author>
      <name>Paul Auguste Randriamitantsoa</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IJCSN International Journal of Computer Science and Network,
  Volume 2, Issue 4, August 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1308.0435v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1308.0435v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1308.1150v1</id>
    <updated>2013-08-06T01:21:35Z</updated>
    <published>2013-08-06T01:21:35Z</published>
    <title>Multimodal Approach for Video Surveillance Indexing and Retrieval</title>
    <summary>  In this paper, we present an overview of a multimodal system to indexing and
searching video sequence by the content that has been developed within the
REGIMVid project. A large part of our system has been developed as part of
TRECVideo evaluation. The MAVSIR platform provides High-level feature
extraction from audio-visual content and concept/event-based video retrieval.
We illustrate the architecture of the system as well as provide an overview of
the descriptors supported to date. Then we demonstrate the usefulness of the
toolbox in the context of feature extraction, concepts/events learning and
retrieval in large collections of video surveillance dataset. The results are
encouraging as we are able to get good results on several event categories,
while for all events we have gained valuable insights and experience.
</summary>
    <author>
      <name>Ali Wali</name>
    </author>
    <author>
      <name>Adel M. Alimi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Intelligent Computing, Volume: 1, Issue: 4 (December
  2010), Page: 165-175</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1308.1150v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1308.1150v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1308.2393v1</id>
    <updated>2013-08-11T13:29:06Z</updated>
    <published>2013-08-11T13:29:06Z</published>
    <title>An Efficient Transport Protocol for delivery of Multimedia An Efficient
  Transport Protocol for delivery of Multimedia Content in Wireless Grids</title>
    <summary>  A grid computing system is designed for solving complicated scientific and
commercial problems effectively,whereas mobile computing is a traditional
distributed system having computing capability with mobility and adopting
wireless communications. Media and Entertainment fields can take advantage from
both paradigms by applying its usage in gaming applications and multimedia data
management. Multimedia data has to be stored and retrieved in an efficient and
effective manner to put it in use. In this paper, we proposed an application
layer protocol for delivery of multimedia data in wireless girds i.e.
multimedia grid protocol (MMGP). To make streaming efficient a new video
compression algorithm called dWave is designed and embedded in the proposed
protocol. This protocol will provide faster, reliable access and render an
imperceptible QoS in delivering multimedia in wireless grid environment and
tackles the challenging issues such as i) intermittent connectivity, ii) device
heterogeneity, iii) weak security and iv) device mobility.
</summary>
    <author>
      <name>Suresh Jaganathan</name>
    </author>
    <author>
      <name>Srinivasan Arulanadam</name>
    </author>
    <author>
      <name>Damodaram Avula</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages, 15 figures, Peer Reviewed Journal</arxiv:comment>
    <link href="http://arxiv.org/abs/1308.2393v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1308.2393v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1308.3225v1</id>
    <updated>2013-08-14T19:54:11Z</updated>
    <published>2013-08-14T19:54:11Z</published>
    <title>An interactive engine for multilingual video browsing using semantic
  content</title>
    <summary>  The amount of audio-visual information has increased dramatically with the
advent of High Speed Internet. Furthermore, technological advances in recent
years in the field of information technology, have simplified the use of video
data in various fields by the general public. This made it possible to store
large collections of video documents into computer systems. To enable efficient
use of these collections, it is necessary to develop tools to facilitate access
to these documents and handling them. In this paper we propose a method for
indexing and retrieval of video sequences in a video database of large
dimension, based on a weighting technique to calculate the degree of membership
of a concept in a video also a structuring of the data of the audio-visual
(context / concept / video) and a relevance feedback mechanism.
</summary>
    <author>
      <name>M. Ben Halima</name>
    </author>
    <author>
      <name>M. Hamroun</name>
    </author>
    <author>
      <name>S. Ben Moussa</name>
    </author>
    <author>
      <name>A. M. Alimi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, IGS 2013 Conference; IGS 2013</arxiv:comment>
    <link href="http://arxiv.org/abs/1308.3225v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1308.3225v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1308.3243v1</id>
    <updated>2013-08-14T20:15:44Z</updated>
    <published>2013-08-14T20:15:44Z</published>
    <title>Arabic Text Recognition in Video Sequences</title>
    <summary>  In this paper, we propose a robust approach for text extraction and
recognition from Arabic news video sequence. The text included in video
sequences is an important needful for indexing and searching system. However,
this text is difficult to detect and recognize because of the variability of
its size, their low resolution characters and the complexity of the
backgrounds. To solve these problems, we propose a system performing in two
main tasks: extraction and recognition of text. Our system is tested on a
varied database composed of different Arabic news programs and the obtained
results are encouraging and show the merits of our approach.
</summary>
    <author>
      <name>M. Ben Halima</name>
    </author>
    <author>
      <name>H. Karray</name>
    </author>
    <author>
      <name>A. M. Alimi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages - International Journal of Computational Linguistics
  Research. arXiv admin note: substantial text overlap with arXiv:1211.2150</arxiv:comment>
    <link href="http://arxiv.org/abs/1308.3243v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1308.3243v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1308.4458v1</id>
    <updated>2013-08-21T01:13:46Z</updated>
    <published>2013-08-21T01:13:46Z</published>
    <title>Coded Acquisition of High Frame Rate Video</title>
    <summary>  High frame video (HFV) is an important investigational tool in sciences,
engineering and military. In ultra-high speed imaging, the obtainable temporal,
spatial and spectral resolutions are limited by the sustainable throughput of
in-camera mass memory, the lower bound of exposure time, and illumination
conditions. In order to break these bottlenecks, we propose a new coded video
acquisition framework that employs K &gt; 2 conventional cameras, each of which
makes random measurements of the 3D video signal in both temporal and spatial
domains. For each of the K cameras, this multi-camera strategy greatly relaxes
the stringent requirements in memory speed, shutter speed, and illumination
strength. The recovery of HFV from these random measurements is posed and
solved as a large scale l1 minimization problem by exploiting joint temporal
and spatial sparsities of the 3D signal. Three coded video acquisition
techniques of varied trade offs between performance and hardware complexity are
developed: frame-wise coded acquisition, pixel-wise coded acquisition, and
column-row-wise coded acquisition. The performances of these techniques are
analyzed in relation to the sparsity of the underlying video signal.
Simulations of these new HFV capture techniques are carried out and
experimental results are reported.
</summary>
    <author>
      <name>Reza Pournaghi</name>
    </author>
    <author>
      <name>Xiaolin Wu</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TIP.2014.2368359</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TIP.2014.2368359" rel="related"/>
    <link href="http://arxiv.org/abs/1308.4458v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1308.4458v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1309.2359v1</id>
    <updated>2013-09-10T01:57:14Z</updated>
    <published>2013-09-10T01:57:14Z</published>
    <title>Speech Enhancement using Kernel and Normalized Kernel Affine Projection
  Algorithm</title>
    <summary>  The goal of this paper is to investigate the speech signal enhancement using
Kernel Affine Projection Algorithm (KAPA) and Normalized KAPA. The removal of
background noise is very important in many applications like speech
recognition, telephone conversations, hearing aids, forensic, etc. Kernel
adaptive filters shown good performance for removal of noise. If the evaluation
of background noise is more slowly than the speech, i.e., noise signal is more
stationary than the speech, we can easily estimate the noise during the pauses
in speech. Otherwise it is more difficult to estimate the noise which results
in degradation of speech. In order to improve the quality and intelligibility
of speech, unlike time and frequency domains, we can process the signal in new
domain like Reproducing Kernel Hilbert Space (RKHS) for high dimensional to
yield more powerful nonlinear extensions. For experiments, we have used the
database of noisy speech corpus (NOIZEUS). From the results, we observed the
removal noise in RKHS has great performance in signal to noise ratio values in
comparison with conventional adaptive filters.
</summary>
    <author>
      <name>Bolimera Ravi</name>
    </author>
    <author>
      <name>T. Kishore Kumar</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5121/sipij.2013.4411</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5121/sipij.2013.4411" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Signal &amp; Image Processing : An International Journal (SIPIJ)
  Vol.4, No.4, August 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1309.2359v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1309.2359v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1309.2423v7</id>
    <updated>2013-09-27T03:08:12Z</updated>
    <published>2013-09-10T09:18:27Z</published>
    <title>Robust watermarking based on DWT SVD</title>
    <summary>  Digital information revolution has brought about many advantages and new
issues. The protection of ownership and the prevention of unauthorized
manipulation of digital audio, image, and video materials has become an
important concern due to the ease of editing and perfect reproduction.
Watermarking is identified as a major means to achieve copyright protection. It
is a branch of information hiding which is used to hide proprietary information
in digital media like photographs, digital music, digital video etc. In this
paper, a new image watermarking algorithm that is robust against various
attacks is presented. DWT (Discrete Wavelet Transform) and SVD (Singular Value
Decomposition) have been used to embed two watermarks in the HL and LH bands of
the host image. Simulation evaluation demonstrates that the proposed technique
withstand various attacks.
</summary>
    <author>
      <name>Anumol Joseph</name>
    </author>
    <author>
      <name>K. Anusudha</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">paper has bee withdrawn by the author due to error in equation</arxiv:comment>
    <link href="http://arxiv.org/abs/1309.2423v7" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1309.2423v7" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1309.7640v1</id>
    <updated>2013-09-29T19:17:18Z</updated>
    <published>2013-09-29T19:17:18Z</published>
    <title>An Efficient Authorship Protection Scheme for Shared Multimedia Content</title>
    <summary>  Many electronic content providers today like Flickr and Google, offer space
to users to publish their electronic media (e.g. photos and videos) in their
cloud infrastructures, so that they can be publicly accessed. Features like
including other information, such as keywords or owner information into the
digital material is already offered by existing providers. Despite the useful
features made available to users by such infrastructures, the authorship of the
published content is not protected against various attacks such as compression.
In this paper we propose a robust scheme that uses digital invisible
watermarking and hashing to protect the authorship of the digital content and
provide resistance against malicious manipulation of multimedia content. The
scheme is enhanced by an algorithm called MMBEC, that is an extension of an
established scheme MBEC, towards higher resistance.
</summary>
    <author>
      <name>Mohamed El-Hadedy</name>
    </author>
    <author>
      <name>Georgios Pitsilis</name>
    </author>
    <author>
      <name>Svein J. Knapskog</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/ICIG.2011.183</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/ICIG.2011.183" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Extensive technical report of paper published in Sixth International
  Conference on Image and Graphics (ICIG), pp.914-919, Hefei, Anhui, China,
  August 12-15, 2011. ISBN: 978-0-7695-4541-7</arxiv:comment>
    <link href="http://arxiv.org/abs/1309.7640v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1309.7640v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.0524v1</id>
    <updated>2013-09-27T12:00:29Z</updated>
    <published>2013-09-27T12:00:29Z</published>
    <title>Steganography using the Extensible Messaging and Presence Protocol
  (XMPP)</title>
    <summary>  We present here the first work to propose different mechanisms for hiding
data in the Extensible Messaging and Presence Protocol (XMPP). This is a very
popular instant messaging protocol used by many messaging platforms such as
Google Talk, Cisco, LiveJournal and many others. Our paper describes how to
send a secret message from one XMPP client to another, without raising the
suspicion of any intermediaries. The methods described primarily focus on using
the underlying protocol as a means for steganography, unlike other related
works that try to hide data in the content of instant messages. In doing so, we
provide a more robust means of data hiding and additionally offer some
preliminary analysis of its general security, in particular against
entropic-based steganalysis.
</summary>
    <author>
      <name>Reshad Patuck</name>
    </author>
    <author>
      <name>Julio Hernandez-Castro</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 3 figures, 2 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1310.0524v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.0524v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.6377v1</id>
    <updated>2013-10-22T18:41:45Z</updated>
    <published>2013-10-22T18:41:45Z</published>
    <title>Multiview Navigation based on Extended Layered Depth Image
  Representation</title>
    <summary>  Emerging applications in multiview streaming look for providing interactive
navigation services to video players. The user can ask for information from any
viewpoint with a minimum transmission delay. The purpose is to provide user
with as much information as possible with least number of redundancies. The
recent concept of navigation segment representation consists of regrouping a
given number of viewpoints in one signal and transmitting them to the users
according to their navigation path. The question of the best description
strategy of these navigation segments is however still open. In this paper, we
propose to represent and code navigation segments by a method that extends the
recent layered depth image (LDI) format. It consists of describing the scene
from a viewpoint with multiple images organized in layers corresponding to the
different levels of occluded objects. The notion of extended LDI comes from the
fact that the size of this image is adapted to take into account the sides of
the scene also, in contrary to classical LDI. The obtained results show a
significant rate-distortion gain compared to classical multiview compression
approaches in navigation scenario.
</summary>
    <author>
      <name>Uday Takyar</name>
    </author>
    <author>
      <name>Thomas Maugey</name>
    </author>
    <author>
      <name>Pascal Frossard</name>
    </author>
    <link href="http://arxiv.org/abs/1310.6377v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.6377v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1311.1083v1</id>
    <updated>2013-09-26T12:01:18Z</updated>
    <published>2013-09-26T12:01:18Z</published>
    <title>An Efficient Method for Image and Audio Steganography using Least
  Significant Bit (LSB) Substitution</title>
    <summary>  In order to improve the data hiding in all types of multimedia data formats
such as image and audio and to make hidden message imperceptible, a novel
method for steganography is introduced in this paper. It is based on Least
Significant Bit (LSB) manipulation and inclusion of redundant noise as secret
key in the message. This method is applied to data hiding in images. For data
hiding in audio, Discrete Cosine Transform (DCT) and Discrete Wavelet Transform
(DWT) both are used. All the results displayed prove to be time-efficient and
effective. Also the algorithm is tested for various numbers of bits. For those
values of bits, Mean Square Error (MSE) and Peak-Signal-to-Noise-Ratio (PSNR)
are calculated and plotted. Experimental results show that the stego-image is
visually indistinguishable from the original cover-image when n&lt;=4, because of
better PSNR which is achieved by this technique. The final results obtained
after steganography process does not reveal presence of any hidden message,
thus qualifying the criteria of imperceptible message.
</summary>
    <author>
      <name>Ankit Chadha</name>
    </author>
    <author>
      <name>Neha Satam</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5120/13547-1342</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5120/13547-1342" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Applications 77(13):37-45,
  September 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1311.1083v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1311.1083v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1311.1419v1</id>
    <updated>2013-11-06T15:24:17Z</updated>
    <published>2013-11-06T15:24:17Z</published>
    <title>Increasing Compression Ratio of Low Complexity Compressive Sensing Video
  Encoder with Application-Aware Configurable Mechanism</title>
    <summary>  With the development of embedded video acquisition nodes and wireless video
surveillance systems, traditional video coding methods could not meet the needs
of less computing complexity any more, as well as the urgent power consumption.
So, a low-complexity compressive sensing video encoder framework with
application-aware configurable mechanism is proposed in this paper, where novel
encoding methods are exploited based on the practical purposes of the real
applications to reduce the coding complexity effectively and improve the
compression ratio (CR). Moreover, the group of processing (GOP) size and the
measurement matrix size can be configured on the encoder side according to the
post-analysis requirements of an application example of object tracking to
increase the CR of encoder as best as possible. Simulations show the proposed
framework of encoder could achieve 60X of CR when the tracking successful rate
(SR) is still keeping above 90%.
</summary>
    <author>
      <name>Shuang Yu</name>
    </author>
    <author>
      <name>Fei Qiao</name>
    </author>
    <author>
      <name>Li Luo</name>
    </author>
    <author>
      <name>Huazhong Yang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages with 6figures and 1 table,conference</arxiv:comment>
    <link href="http://arxiv.org/abs/1311.1419v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1311.1419v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1311.1700v1</id>
    <updated>2013-11-07T14:45:30Z</updated>
    <published>2013-11-07T14:45:30Z</published>
    <title>Image Steganography using Karhunen-Loeve Transform and Least Bit
  Substitution</title>
    <summary>  As communication channels are increasing in number, reliability of faithful
communication is reducing. Hacking and tempering of data are two major issues
for which security should be provided by channel. This raises the importance of
steganography. In this paper, a novel method to encode the message information
inside a carrier image has been described. It uses Karhunen-Lo\`eve Transform
for compression of data and Least Bit Substitution for data encryption.
Compression removes redundancy and thus also provides encoding to a level. It
is taken further by means of Least Bit Substitution. The algorithm used for
this purpose uses pixel matrix which serves as a best tool to work on. Three
different sets of images were used with three different numbers of bits to be
substituted by message information. The experimental results show that
algorithm is time efficient and provides high data capacity. Further, it can
decrypt the original data effectively. Parameters such as carrier error and
message error were calculated for each set and were compared for performance
analysis.
</summary>
    <author>
      <name>Ankit Chadha</name>
    </author>
    <author>
      <name>Neha Satam</name>
    </author>
    <author>
      <name>Rakshak Sood</name>
    </author>
    <author>
      <name>Dattatray Bade</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5120/13771-1628 10.5120/13771-1628 10.5120/13771-1628</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5120/13771-1628" rel="related"/>
    <link title="doi" href="http://dx.doi.org/10.5120/13771-1628" rel="related"/>
    <link title="doi" href="http://dx.doi.org/10.5120/13771-1628" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Applications 79(9):31-37,
  October 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1311.1700v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1311.1700v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1311.3220v1</id>
    <updated>2013-11-13T17:21:42Z</updated>
    <published>2013-11-13T17:21:42Z</published>
    <title>Chaotic Arithmetic Coding for Secure Video Multicast</title>
    <summary>  Arithmetic Coding (AC) is widely used for the entropy coding of text and
video data. It involves recursive partitioning of the range [0,1) in accordance
with the relative probabilities of occurrence of the input symbols. A data
(image or video) encryption scheme based on arithmetic coding called as Chaotic
Arithmetic Coding (CAC) has been presented in previous works. In CAC, a large
number of chaotic maps can be used to perform coding, each achieving Shannon
optimal compression performance. The exact choice of map is governed by a key.
CAC has the effect of scrambling the intervals without making any changes to
the width of interval in which the codeword must lie, thereby allowing
encryption without sacrificing any coding efficiency. In this paper, we use a
redundancy in CAC procedure for secure multicast of videos where multiple users
are distributed with different keys to decode same encrypted file. By
encrypting once, we can generate multiple keys, either of which can be used to
decrypt the encoded file. This is very suitable for video distribution over
Internet where a single video can be distributed to multiple clients in a
privacy preserving manner.
</summary>
    <author>
      <name>Gaurav Pande</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to SPIN 2014</arxiv:comment>
    <link href="http://arxiv.org/abs/1311.3220v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1311.3220v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1311.5834v1</id>
    <updated>2013-11-22T18:09:25Z</updated>
    <published>2013-11-22T18:09:25Z</published>
    <title>Traffic and Statistical Multiplexing Characterization of 3D Video
  Representation Formats (Extended Version)</title>
    <summary>  The network transport of 3D video, which contains two views of a video scene,
poses significant challenges due to the increased video data compared to
conventional single-view video. Addressing these challenges requires a thorough
understanding of the traffic and multiplexing characteristics of the different
representation formats of 3D video. We examine the average bitrate-distortion
(RD) and bitrate variability-distortion (VD) characteristics of three main
representation formats. Specifically, we compare multiview video (MV)
representation and encoding, frame sequential (FS) representation, and
side-by-side (SBS) representation, whereby conventional single-view encoding is
employed for the FS and SBS representations. Our results for long 3D videos in
full HD format indicate that the MV representation and encoding achieves the
highest RD efficiency, while exhibiting the highest bitrate variabilities. We
examine the impact of these bitrate variabilities on network transport through
extensive statistical multiplexing simulations. We find that when multiplexing
a small number of streams, the MV and FS representations require the same
bandwidth. However, when multiplexing a large number of streams or smoothing
traffic, the MV representation and encoding reduces the bandwidth requirement
relative to the FS representation.
</summary>
    <author>
      <name>Akshay Pulipaka</name>
    </author>
    <author>
      <name>Patrick Seeling</name>
    </author>
    <author>
      <name>Martin Reisslein</name>
    </author>
    <author>
      <name>Lina J. Karam</name>
    </author>
    <link href="http://arxiv.org/abs/1311.5834v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1311.5834v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1311.6355v1</id>
    <updated>2013-11-06T12:20:35Z</updated>
    <published>2013-11-06T12:20:35Z</published>
    <title>Exploration in Interactive Personalized Music Recommendation: A
  Reinforcement Learning Approach</title>
    <summary>  Current music recommender systems typically act in a greedy fashion by
recommending songs with the highest user ratings. Greedy recommendation,
however, is suboptimal over the long term: it does not actively gather
information on user preferences and fails to recommend novel songs that are
potentially interesting. A successful recommender system must balance the needs
to explore user preferences and to exploit this information for recommendation.
This paper presents a new approach to music recommendation by formulating this
exploration-exploitation trade-off as a reinforcement learning task called the
multi-armed bandit. To learn user preferences, it uses a Bayesian model, which
accounts for both audio content and the novelty of recommendations. A
piecewise-linear approximation to the model and a variational inference
algorithm are employed to speed up Bayesian inference. One additional benefit
of our approach is a single unified model for both music recommendation and
playlist generation. Both simulation results and a user study indicate strong
potential for the new approach.
</summary>
    <author>
      <name>Xinxi Wang</name>
    </author>
    <author>
      <name>Yi Wang</name>
    </author>
    <author>
      <name>David Hsu</name>
    </author>
    <author>
      <name>Ye Wang</name>
    </author>
    <link href="http://arxiv.org/abs/1311.6355v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1311.6355v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3; H.5.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1311.6441v1</id>
    <updated>2013-11-25T20:31:44Z</updated>
    <published>2013-11-25T20:31:44Z</published>
    <title>Modeling the Time-varying Subjective Quality of HTTP Video Streams with
  Rate Adaptations</title>
    <summary>  Newly developed HTTP-based video streaming technologies enable flexible
rate-adaptation under varying channel conditions. Accurately predicting the
users' Quality of Experience (QoE) for rate-adaptive HTTP video streams is thus
critical to achieve efficiency. An important aspect of understanding and
modeling QoE is predicting the up-to-the-moment subjective quality of a video
as it is played, which is difficult due to hysteresis effects and
nonlinearities in human behavioral responses. This paper presents a
Hammerstein-Wiener model for predicting the time-varying subjective quality
(TVSQ) of rate-adaptive videos. To collect data for model parameterization and
validation, a database of longer-duration videos with time-varying distortions
was built and the TVSQs of the videos were measured in a large-scale subjective
study. The proposed method is able to reliably predict the TVSQ of rate
adaptive videos. Since the Hammerstein-Wiener model has a very simple
structure, the proposed method is suitable for on-line TVSQ prediction in HTTP
based streaming.
</summary>
    <author>
      <name>Chao Chen</name>
    </author>
    <author>
      <name>Lark Kwon Choi</name>
    </author>
    <author>
      <name>Gustavo de Veciana</name>
    </author>
    <author>
      <name>Constantine Caramanis</name>
    </author>
    <author>
      <name>Robert W. Heath Jr.</name>
    </author>
    <author>
      <name>Alan C. Bovik</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TIP.2014.2312613</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TIP.2014.2312613" rel="related"/>
    <link href="http://arxiv.org/abs/1311.6441v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1311.6441v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1311.6453v1</id>
    <updated>2013-11-25T20:42:33Z</updated>
    <published>2013-11-25T20:42:33Z</published>
    <title>Rate Adaptation and Admission Control for Video Transmission with
  Subjective Quality Constraints</title>
    <summary>  Adapting video data rate during streaming can effectively reduce the risk of
playback interruptions caused by channel throughput fluctuations. The
variations in rate, however, also introduce video quality fluctuations and thus
potentially affects viewers' Quality of Experience (QoE). We show how the QoE
of video users can be improved by rate adaptation and admission control. We
conducted a subjective study wherein we found that viewers' QoE was strongly
correlated with the empirical cumulative distribution function (eCDF) of the
predicted video quality. Based on this observation, we propose a
rate-adaptation algorithm that can incorporate QoE constraints on the empirical
cumulative quality distribution per user. We then propose a threshold-based
admission control policy to block users whose empirical cumulative quality
distribution is not likely to satisfy their QoE constraint. We further devise
an online adaptation algorithm to automatically optimize the threshold.
Extensive simulation results show that the proposed scheme can reduce network
resource consumption by $40\%$ over conventional average-quality maximized
rate-adaptation algorithms.
</summary>
    <author>
      <name>Chao Chen</name>
    </author>
    <author>
      <name>Xiaoqing Zhu</name>
    </author>
    <author>
      <name>Gustavo de Veciana</name>
    </author>
    <author>
      <name>Alan C. Bovik</name>
    </author>
    <author>
      <name>Robert W. Heath Jr</name>
    </author>
    <link href="http://arxiv.org/abs/1311.6453v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1311.6453v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1312.6090v1</id>
    <updated>2013-12-20T19:55:33Z</updated>
    <published>2013-12-20T19:55:33Z</published>
    <title>Graph-based representation for multiview image coding</title>
    <summary>  In this paper, we propose a new representation for multiview image sets. Our
approach relies on graphs to describe geometry information in a compact and
controllable way. The links of the graph connect pixels in different images and
describe the proximity between pixels in the 3D space. These connections are
dependent on the geometry of the scene and provide the right amount of
information that is necessary for coding and reconstructing multiple views.
This multiview image representation is very compact and adapts the transmitted
geometry information as a function of the complexity of the prediction
performed at the decoder side. To achieve this, our GBR adapts the accuracy of
the geometry representation, in contrast with depth coding, which directly
compresses with losses the original geometry signal. We present the principles
of this graph-based representation (GBR) and we build a complete prototype
coding scheme for multiview images. Experimental results demonstrate the
potential of this new representation as compared to a depth-based approach. GBR
can achieve a gain of 2 dB in reconstructed quality over depth-based schemes
operating at similar rates.
</summary>
    <author>
      <name>Thomas Maugey</name>
    </author>
    <author>
      <name>Antonio Ortega</name>
    </author>
    <author>
      <name>Pascal Frossard</name>
    </author>
    <link href="http://arxiv.org/abs/1312.6090v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1312.6090v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1312.6497v1</id>
    <updated>2013-12-23T09:43:09Z</updated>
    <published>2013-12-23T09:43:09Z</published>
    <title>State-of-the Art Motion Estimation in the Context of 3D TV</title>
    <summary>  Progress in image sensors and computation power has fueled studies to improve
acquisition, processing, and analysis of 3D streams along with 3D
scenes/objects reconstruction. The role of motion compensation/motion
estimation (MCME) in 3D TV from end-to-end user is investigated in this
chapter. Motion vectors (MVs) are closely related to the concept of
disparities, and they can help improving dynamic scene acquisition, content
creation, 2D to 3D conversion, compression coding, decompression/decoding,
scene rendering, error concealment, virtual/augmented reality handling,
intelligent content retrieval, and displaying. Although there are different 3D
shape extraction methods, this chapter focuses mostly on shape-from-motion
(SfM) techniques due to their relevance to 3D TV. SfM extraction can restore 3D
shape information from a single camera data.
</summary>
    <author>
      <name>Vania V. Estrela</name>
    </author>
    <author>
      <name>Alessandra M. Coelho</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4018/978-1-4666-2660-7.ch006</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4018/978-1-4666-2660-7.ch006" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Multimedia Networking and Coding. IGI Global, 2013. 148-173. Web.
  23 Dec. 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1312.6497v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1312.6497v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1312.7442v1</id>
    <updated>2013-12-28T15:19:09Z</updated>
    <published>2013-12-28T15:19:09Z</published>
    <title>Evaluating the Performance of IPTV over Fixed WiMAX</title>
    <summary>  IEEE specifies different modulation techniques for WiMAX; namely, BPSK, QPSK,
16 QAM and 64 QAM. This paper studies the performance of Internet Protocol
Television (IPTV) over Fixed WiMAX system considering different combinations of
digital modulation. The performance is studied taking into account a number of
key system parameters which include the variation in the video coding,
path-loss, scheduling service classes different rated codes in FEC channel
coding. The performance study was conducted using OPNET simulation. The
performance is studied in terms of packet lost, packet jitter delay, end-to-end
delay, and network throughput. Simulation results show that higher order
modulation and coding schemes (namely, 16 QAM and 64 QAM) yield better
performance than that of QPSK.
</summary>
    <author>
      <name>Jamil Hamodi</name>
    </author>
    <author>
      <name>Khaled Salah</name>
    </author>
    <author>
      <name>Ravindra Thool</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5120/14582-2812</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5120/14582-2812" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 Pages, 9 Figures. arXiv admin note: substantial text overlap with
  other internet sources by other authors</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Applications 84(6):35-43,
  December 2013. Published by Foundation of Computer Science, New York, USA</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1312.7442v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1312.7442v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1401.2482v1</id>
    <updated>2014-01-10T23:36:51Z</updated>
    <published>2014-01-10T23:36:51Z</published>
    <title>STIMONT: A core ontology for multimedia stimuli description</title>
    <summary>  Affective multimedia documents such as images, sounds or videos elicit
emotional responses in exposed human subjects. These stimuli are stored in
affective multimedia databases and successfully used for a wide variety of
research in psychology and neuroscience in areas related to attention and
emotion processing. Although important all affective multimedia databases have
numerous deficiencies which impair their applicability. These problems, which
are brought forward in the paper, result in low recall and precision of
multimedia stimuli retrieval which makes creating emotion elicitation
procedures difficult and labor-intensive. To address these issues a new core
ontology STIMONT is introduced. The STIMONT is written in OWL-DL formalism and
extends W3C EmotionML format with an expressive and formal representation of
affective concepts, high-level semantics, stimuli document metadata and the
elicited physiology. The advantages of ontology in description of affective
multimedia stimuli are demonstrated in a document retrieval experiment and
compared against contemporary keyword-based querying methods. Also, a software
tool Intelligent Stimulus Generator for retrieval of affective multimedia and
construction of stimuli sequences is presented.
</summary>
    <author>
      <name>Marko Horvat</name>
    </author>
    <author>
      <name>Nikola Bogunović</name>
    </author>
    <author>
      <name>Krešimir Ćosić</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s11042-013-1624-4</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s11042-013-1624-4" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">27 pages, 13 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Multimedia tools and applications, 11042, July 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1401.2482v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1401.2482v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1401.5966v2</id>
    <updated>2016-08-27T00:50:13Z</updated>
    <published>2014-01-23T13:23:27Z</published>
    <title>Image Block Loss Restoration Using Sparsity Pattern as Side Information</title>
    <summary>  In this paper, we propose a method for image block loss restoration based on
the notion of sparse representation. We use the sparsity pattern as side
information to efficiently restore block losses by iteratively imposing the
constraints of spatial and transform domains on the corrupted image. Two novel
features, including a pre-interpolation and a criterion for stopping the
iterations, are proposed to improve the performance. Also, to deal with
practical applications, we develop a technique to transmit the side information
along with the image. In this technique, we first compress the side information
and then embed its LDPC coded version in the least significant bits of the
image pixels. This technique ensures the error-free transmission of the side
information, while causing only a small perturbation on the transmitted image.
Mathematical analysis and extensive simulations are performed to validate the
method and investigate the efficiency of the proposed techniques. The results
verify that the proposed method outperforms its counterparts for image block
loss restoration.
</summary>
    <author>
      <name>Hossein Hosseini</name>
    </author>
    <author>
      <name>Ali Goli</name>
    </author>
    <author>
      <name>Neda Barzegar Marvasti</name>
    </author>
    <author>
      <name>Masoume Azghani</name>
    </author>
    <author>
      <name>Farokh Marvasti</name>
    </author>
    <link href="http://arxiv.org/abs/1401.5966v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1401.5966v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1402.0812v1</id>
    <updated>2014-02-04T18:05:37Z</updated>
    <published>2014-02-04T18:05:37Z</published>
    <title>A Study on the Optimal Implementation of Statistical Multiplexing in DVB
  Distribution Systems</title>
    <summary>  The paper presents an overview of the main methods used to improve the
efficiency of DVB systems, based on multiplexing, through a study on the impact
of the multiplexing methods used in DVB, having as a final goal a better usage
of the data capacity and the possibility to insert new services into the
original DVB Transport Stream. This study revealed that not all DVB providers
are using statistical multiplexing. Based on this study, we were able to
propose a method to improve the original DVB stream, originated from DVB-S or
DVB-T providers. This method is proposing the detection of null packets,
removal and reinserting a new service, with a VBR content. The method developed
in this research can be implemented even in optimized statistical multiplexing
systems, due to a residual use of null packets for data rate adjustment. There
is no need to have access in the original stream multiplexer, since the method
allows the implementation on the fly, near to the end user. The proposed method
is proposed to be applied in DVB-S to DVB-C translation, using the computing
power of a PC or in a FPGA implementation.
</summary>
    <author>
      <name>Alexandru Florin Antone</name>
    </author>
    <author>
      <name>Radu Arsinte</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 17 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Informatics and IT Today, Volume 1, July 2013, pp.19-27</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1402.0812v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1402.0812v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1402.5979v2</id>
    <updated>2016-12-11T19:23:57Z</updated>
    <published>2014-02-24T21:04:41Z</published>
    <title>A Multiplierless Pruned DCT-like Transformation for Image and Video
  Compression that Requires 10 Additions Only</title>
    <summary>  A multiplierless pruned approximate 8-point discrete cosine transform (DCT)
requiring only 10 additions is introduced. The proposed algorithm was assessed
in image and video compression, showing competitive performance with
state-of-the-art methods. Digital implementation in 45 nm CMOS technology up to
place-and-route level indicates clock speed of 288 MHz at a 1.1 V supply. The
8x8 block rate is 36 MHz.The DCT approximation was embedded into HEVC reference
software; resulting video frames, at up to 327 Hz for 8-bit RGB HEVC, presented
negligible image degradation.
</summary>
    <author>
      <name>V. A. Coutinho</name>
    </author>
    <author>
      <name>R. J. Cintra</name>
    </author>
    <author>
      <name>F. M. Bayer</name>
    </author>
    <author>
      <name>S. Kulasekera</name>
    </author>
    <author>
      <name>A. Madanayake</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s11554-015-0492-8</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s11554-015-0492-8" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 4 figures, 5 tables</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Real-Time Image Processing, August 2016, Volume 12,
  Issue 2, pp 247-255</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1402.5979v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1402.5979v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1403.3710v1</id>
    <updated>2014-03-14T21:08:28Z</updated>
    <published>2014-03-14T21:08:28Z</published>
    <title>Saving Energy in Mobile Devices for On-Demand Multimedia Streaming -- A
  Cross-Layer Approach</title>
    <summary>  This paper proposes a novel energy-efficient multimedia delivery system
called EStreamer. First, we study the relationship between buffer size at the
client, burst-shaped TCP-based multimedia traffic, and energy consumption of
wireless network interfaces in smartphones. Based on the study, we design and
implement EStreamer for constant bit rate and rate-adaptive streaming.
EStreamer can improve battery lifetime by 3x, 1.5x and 2x while streaming over
Wi-Fi, 3G and 4G respectively.
</summary>
    <author>
      <name>Mohammad Ashraful Hoque</name>
    </author>
    <author>
      <name>Matti Siekkinen</name>
    </author>
    <author>
      <name>Jukka K. Nurminen</name>
    </author>
    <author>
      <name>Sasu Tarkoma</name>
    </author>
    <author>
      <name>Mika Aalto</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/2556942</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/2556942" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted in ACM Transactions on Multimedia Computing, Communications
  and Applications (ACM TOMCCAP), November 2013</arxiv:comment>
    <link href="http://arxiv.org/abs/1403.3710v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1403.3710v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="C.2.1; C.2.4; C.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1403.4169v1</id>
    <updated>2014-03-17T17:03:01Z</updated>
    <published>2014-03-17T17:03:01Z</published>
    <title>Pervasive Image Computation: A Mobile Phone Application for getting
  Information of the Images</title>
    <summary>  Although many of the information processing systems are text-based, much of
the information in the real life is generally multimedia objects, so there is a
need to define and standardize the frame works for multimedia-based information
processing systems. In this paper we consider the application of such a system
namely pervasive image computation system, in which the user uses the cellphone
for taking the picture of the objects, and he wants to get some information
about them. We have implemented two architectures, the first one, called online
architecture, which the user sends the picture to the server and server sends
the picture information directly back to him. In the second one, which is
called offline architecture, the user uploads the image in one public image
database such as Flickr and sends the ID of the image in this database to the
server. The server processes the image and adds the information of the image in
the database, and finally the user can connect to the database and download the
image information. The implementation results show that these architectures are
very flexible and could be easily extended to be used in more complicated
pervasive multimedia systems.
</summary>
    <author>
      <name>Reza Rahimi</name>
    </author>
    <author>
      <name>J Hengmeechai</name>
    </author>
    <link href="http://arxiv.org/abs/1403.4169v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1403.4169v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.1314v1</id>
    <updated>2014-03-21T06:10:27Z</updated>
    <published>2014-03-21T06:10:27Z</published>
    <title>Robust Video Watermarking Schemes in Phase domain Using Binary Phase
  Shift Keying</title>
    <summary>  This paper presents a robust video watermarking scheme in Discrete Fourier
Transform (DFT) and Sequencyordered Complex Hadamard Transform (SCHT). The DFT
and SCHT coefficients are complex and consist of both magnitude and phase and
are well suited to adopt phase shift keying techniques to embed the watermark.
In the proposed schemes, the phases of DFT and SCHT coefficients are modified
to convey watermark information using binary phase shift keying in cover video.
Low amplitude block selection (LABS) is used to improve transparency, amplitude
boost to improve the resistance of watermark from signal processing and
compression attacks and spread spectrum technique is used for encrypting
watermark in order to protect it from third party. It is observed that both
algorithms showing more or less same robustness but SCHT offers high
transparency, simple implementation and less computational cost than DFT.
</summary>
    <author>
      <name>K. Meenakshi</name>
    </author>
    <author>
      <name>Ch. Srinivasa Rao</name>
    </author>
    <author>
      <name>K. Satya Prasad</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1404.1314v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.1314v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.2344v1</id>
    <updated>2014-04-09T01:23:31Z</updated>
    <published>2014-04-09T01:23:31Z</published>
    <title>Analysis of Computer Hardware Affecting Video Transmission via IEEE
  1394a connection</title>
    <summary>  When 60 de-interlaced fields per second digital uncompressed video is
streamed to a computer, some video fields are lost and not able to be stored on
a computer s hard drive successfully. Additionally, this problem amplifies once
multiple video sources are deployed. If it is possible to stream digital
uncompressed video without dropped video fields, then a sophisticated computer
analysis of the transmitted via IEEE 1394a connection video is possible. Such
process is used in biomechanics when it is important to analyze athletes
performance via streaming digital uncompressed video to a computer and then
analyzing it. If a loss of video fields occurs, then a quality analysis of
video is not possible.
</summary>
    <author>
      <name>Dr. Timur Mirzoev</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Information systems. Problems, perspectives, innovation
  approaches. Volume 2. 2007. Saint Petersburg State University of Aerospace
  Instrumentation. ISBN 978-5-80888-0244-5</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1404.2344v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.2344v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.2952v1</id>
    <updated>2014-04-10T20:56:21Z</updated>
    <published>2014-04-10T20:56:21Z</published>
    <title>A blind robust watermarking scheme based on svd and circulant matrices</title>
    <summary>  Multimedia security has been the aim point of considerable research activity
because of its wide application area. The major technology to achieve copyright
protection, content authentication, access control and multimedia security is
watermarking which is the process of embedding data into a multimedia element
such as image or audio, this embedded data can later be extracted from, or
detected in the embedded element for different purposes. In this work, a blind
watermarking algorithm based on SVD and circulant matrices has been presented.
Every circulant matrix is associated with a matrix for which the SVD
decomposition coincides with the spectral decomposition. This leads to improve
the Chandra algorithm [1], our presentation will include a discussion on the
data hiding capacity, watermark transparency and robustness against a wide
range of common image processing attacks.
</summary>
    <author>
      <name>Noui Oussama</name>
    </author>
    <author>
      <name>Noui Lemnouar</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5121/csit.2014.4406</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5121/csit.2014.4406" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 6 figures, 5 tables, Second International Conference on
  Computational Science &amp; Engineering (CSE - 2014)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Second International Conference on Computational Science and
  Engineering (CSE-2014) Dubai, UAE, April 04 ~ 05 - 2014 Volume Editors:
  Dhinaharan Nagamalai, Sundarapandian Vaidyanathan ISBN : 978-1-921987-30-4 pp
  65 - 77</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1404.2952v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.2952v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.3018v1</id>
    <updated>2014-04-11T07:13:22Z</updated>
    <published>2014-04-11T07:13:22Z</published>
    <title>Enhancing User Experience for Multi-Screen Social TV Streaming over
  Wireless Networks</title>
    <summary>  Recently, multi-screen cloud social TV is invented to transform TV into
social experience. People watching the same content on social TV may come from
different locations, while freely interact with each other through text, image,
audio and video. This crucial virtual living-room experience adds social
aspects into existing performance metrics. In this paper, we parse social TV
user experience into three elements (i.e., inter-user delay, video quality of
experience (QoE), and resource efficiency), and provide a joint analytical
framework to enhance user experience. Specifically, we propose a cloud-based
optimal playback rate allocation scheme to maximize the overall QoE while upper
bounding inter-user delay. Experiment results show that our algorithm achieves
near-optimal tradeoff between inter-user delay and video quality, and
demonstrates resilient performance even under very fast wireless channel
fading.
</summary>
    <author>
      <name>Huazi Zhang</name>
    </author>
    <author>
      <name>Yichao Jin</name>
    </author>
    <author>
      <name>Weiwen Zhang</name>
    </author>
    <author>
      <name>Yonggang Wen</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/GLOCOMW.2014.7063414</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/GLOCOMW.2014.7063414" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">submitted to IEEE GLOBECOM 2014</arxiv:comment>
    <link href="http://arxiv.org/abs/1404.3018v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.3018v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.4026v2</id>
    <updated>2015-04-24T10:24:57Z</updated>
    <published>2014-04-15T19:26:13Z</published>
    <title>Improving Low Bit-Rate Video Coding using Spatio-Temporal Down-Scaling</title>
    <summary>  Good quality video coding for low bit-rate applications is important for
transmission over narrow-bandwidth channels and for storage with limited memory
capacity. In this work, we develop a previous analysis for image compression at
low bit-rates to adapt it to video signals. Improving compression using
down-scaling in the spatial and temporal dimensions is examined. We show, both
theoretically and experimentally, that at low bit-rates, we benefit from
applying spatio-temporal scaling. The proposed method includes down-scaling
before the compression and a corresponding up-scaling afterwards, while the
codec itself is left unmodified. We propose analytic models for low bit-rate
compression and spatio-temporal scaling operations. Specifically, we use
theoretic models of motion-compensated prediction of available and absent
frames as in coding and frame-rate up-conversion (FRUC) applications,
respectively. The proposed models are designed for multi-resolution analysis.
In addition, we formulate a bit-allocation procedure and propose a method for
estimating good down-scaling factors of a given video based on its second-order
statistics and the given bit-budget. We validate our model with experimental
results of H.264 compression.
</summary>
    <author>
      <name>Yehuda Dar</name>
    </author>
    <author>
      <name>Alfred M. Bruckstein</name>
    </author>
    <link href="http://arxiv.org/abs/1404.4026v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.4026v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.4543v1</id>
    <updated>2014-04-17T14:42:03Z</updated>
    <published>2014-04-17T14:42:03Z</published>
    <title>A Novel Approach for Video Temporal Annotation</title>
    <summary>  Recent advances in computing, communication, and data storage have led to an
increasing number of large digital libraries publicly available on the
Internet. Main problem of content-based video retrieval is inferring semantics
from raw video data. Video data play an important role in these libraries.
Instead of words, a video retrieval system deals with collections of video
records. Therefore, the system is confronted with the problem of video
understanding. Because machine understanding of the video data is still an
unsolved research problem, text annotations are usually used to describe the
content of video data according to the annotator's understanding and the
purpose of that video data. Most of proposed systems for video annotation are
domain dependent. In addition, in many of these systems, an important feature
of video data, temporality, is disregarded. In this paper, we proposed a
framework for video temporal annotation. The proposed system uses domain
knowledge and a time ontology to perform temporal annotation of input video.
</summary>
    <author>
      <name>Hadi Restgou Haghi</name>
    </author>
    <author>
      <name>Mohammadreza Kangavari</name>
    </author>
    <author>
      <name>Behrang QasemiZadeh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published in a Local Confrence, 2006</arxiv:comment>
    <link href="http://arxiv.org/abs/1404.4543v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.4543v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68Uxx" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.2.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.7237v1</id>
    <updated>2014-04-29T05:20:25Z</updated>
    <published>2014-04-29T05:20:25Z</published>
    <title>A Smart Intelligent Way of Video Authentication Using Classification and
  Decomposition of Watermarking Methods</title>
    <summary>  Video Watermarking serves as a new technology mainly used to provide security
to the illegal distribution of digital video over the web. The purpose of any
video watermarking scheme is to embed extra information into video in such a
way that must be perceptually undetectable while still holding enough
information in order to extract the watermark beginning with the resultant
video. Information which is embedded within the original image is a Digital
Watermark, which could be visible or invisible. To improved more security,
embedding and extraction Watermark process should be complex against attackers.
Recent research indicates SVD (Singular Value Decomposition) algorithms are
employed owing to their simple scheme with mathematical function. In this
proposed work an advanced SVD transformation algorithm is used for embedding
and extraction process. Experimental results show proposed watermarking process
is more secured than existing SVD approach.
</summary>
    <author>
      <name>T. Srinivasa Rao</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">InformationTechnology, UshaRama College of Engineering &amp; Technology, India</arxiv:affiliation>
    </author>
    <author>
      <name>Rajasekhar R. Kurra</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Principal, Sri Prakash College of Engineering &amp; Technology, India</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.14445/22312803/IJCTT-V10P123</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.14445/22312803/IJCTT-V10P123" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 Pages, 4 Figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Trends and Technology (IJCTT)
  V10(3):136-142, Apr 2014. ISSN:2231-2803. www.ijcttjournal.org. Published by
  Seventh Sense Research Group</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1404.7237v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.7237v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.3173v1</id>
    <updated>2014-05-11T08:45:07Z</updated>
    <published>2014-05-11T08:45:07Z</published>
    <title>Image Restoration Using Joint Statistical Modeling in Space-Transform
  Domain</title>
    <summary>  This paper presents a novel strategy for high-fidelity image restoration by
characterizing both local smoothness and nonlocal self-similarity of natural
images in a unified statistical manner. The main contributions are three-folds.
First, from the perspective of image statistics, a joint statistical modeling
(JSM) in an adaptive hybrid space-transform domain is established, which offers
a powerful mechanism of combining local smoothness and nonlocal self-similarity
simultaneously to ensure a more reliable and robust estimation. Second, a new
form of minimization functional for solving image inverse problem is formulated
using JSM under regularization-based framework. Finally, in order to make JSM
tractable and robust, a new Split-Bregman based algorithm is developed to
efficiently solve the above severely underdetermined inverse problem associated
with theoretical proof of convergence. Extensive experiments on image
inpainting, image deblurring and mixed Gaussian plus salt-and-pepper noise
removal applications verify the effectiveness of the proposed algorithm.
</summary>
    <author>
      <name>Jian Zhang</name>
    </author>
    <author>
      <name>Debin Zhao</name>
    </author>
    <author>
      <name>Ruiqin Xiong</name>
    </author>
    <author>
      <name>Siwei Ma</name>
    </author>
    <author>
      <name>Wen Gao</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TCSVT.2014.2302380</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TCSVT.2014.2302380" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 18 figures, 7 Tables, to be published in IEEE Transactions
  on Circuits System and Video Technology (TCSVT). High resolution pdf version
  and Code can be found at: http://idm.pku.edu.cn/staff/zhangjian/IRJSM/</arxiv:comment>
    <link href="http://arxiv.org/abs/1405.3173v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.3173v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.4709v1</id>
    <updated>2014-05-19T13:10:09Z</updated>
    <published>2014-05-19T13:10:09Z</published>
    <title>YouTube QoE Evaluation Tool for Android Wireless Terminals</title>
    <summary>  In this paper, we present an Android application which is able to evaluate
and analyze the perceived Quality of Experience (QoE) for YouTube service in
wireless terminals. To achieve this goal, the application carries out
measurements of objective Quality of Service (QoS) parameters, which are then
mapped onto subjective QoE (in terms of Mean Opinion Score, MOS) by means of a
utility function. Our application also informs the user about potential causes
that lead to a low MOS as well as provides some hints to improve it. After each
YouTube session, the users may optionally qualify the session through an online
opinion survey. This information has been used in a pilot experience to
correlate the theoretical QoE model with real user feedback. Results from such
an experience have shown that the theoretical model (taken from the literature)
provides slightly more pessimistic results compared to user feedback. Users
seem to be more indulgent with wireless connections, increasing the MOS from
the opinion survey in about 20% compared to the theoretical model, which was
obtained from wired scenarios.
</summary>
    <author>
      <name>Gerardo Gomez</name>
    </author>
    <author>
      <name>Lorenzo Hortiguela</name>
    </author>
    <author>
      <name>Quiliano Perez</name>
    </author>
    <author>
      <name>Javier Lorca</name>
    </author>
    <author>
      <name>Raquel Garcia</name>
    </author>
    <author>
      <name>Mari Carmen Aguayo-Torres</name>
    </author>
    <link href="http://arxiv.org/abs/1405.4709v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.4709v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.5340v1</id>
    <updated>2014-05-21T09:01:32Z</updated>
    <published>2014-05-21T09:01:32Z</published>
    <title>A hybrid video quality metric for analyzing quality degradation due to
  frame drop</title>
    <summary>  In last decade, ever growing internet technologies provided platform to share
the multimedia data among different communities. As the ultimate users are
human subjects who are concerned about quality of visual information, it is
often desired to have good resumed perceptual quality of videos, thus arises
the need of quality assessment. This paper presents a full reference hybrid
video quality metric which is capable to analyse the video quality for
spatially or temporally (frame drop) or spatio-temporally distorted video
sequences. Simulated results show that the metric efficiently analyses the
quality degradation and more closer to the developed human visual system
</summary>
    <author>
      <name>Manish K Thakur</name>
    </author>
    <author>
      <name>Vikas Saxena</name>
    </author>
    <author>
      <name>J P Gupta</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 9 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IJCSI International Journal of Computer Science Issues, Vol. 9,
  Issue 6, No 1, November 2012</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1405.5340v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.5340v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.6661v1</id>
    <updated>2014-05-08T07:16:46Z</updated>
    <published>2014-05-08T07:16:46Z</published>
    <title>A scenario based approach for dealing with challenges in a pervasive
  computing environment</title>
    <summary>  With the surge in modern research focus towards Pervasive Computing, lot of
techniques and challenges needs to be addressed so as to effectively create
smart spaces and achieve miniaturization. In the process of scaling down to
compact devices, the real things to ponder upon are the Information Retrieval
challenges. In this work, we discuss the aspects of multimedia which makes
information access challenging. An Example Pattern Recognition scenario is
presented and the mathematical techniques that can be used to model uncertainty
are also presented for developing a system that can sense, compute and
communicate in a way that can make human life easy with smart objects assisting
from around his surroundings.
</summary>
    <author>
      <name>Divyajyothi M G</name>
    </author>
    <author>
      <name> Rachappa</name>
    </author>
    <author>
      <name>D H Rao</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5121/ijcsa.2014.4204</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5121/ijcsa.2014.4204" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, IJCSA, Vol 4, No.2,April 2014</arxiv:comment>
    <link href="http://arxiv.org/abs/1405.6661v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.6661v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.7102v2</id>
    <updated>2014-06-14T20:17:48Z</updated>
    <published>2014-05-28T02:07:29Z</published>
    <title>Detection Bank: An Object Detection Based Video Representation for
  Multimedia Event Recognition</title>
    <summary>  While low-level image features have proven to be effective representations
for visual recognition tasks such as object recognition and scene
classification, they are inadequate to capture complex semantic meaning
required to solve high-level visual tasks such as multimedia event detection
and recognition. Recognition or retrieval of events and activities can be
improved if specific discriminative objects are detected in a video sequence.
In this paper, we propose an image representation, called Detection Bank, based
on the detection images from a large number of windowed object detectors where
an image is represented by different statistics derived from these detections.
This representation is extended to video by aggregating the key frame level
image representations through mean and max pooling. We empirically show that it
captures complementary information to state-of-the-art representations such as
Spatial Pyramid Matching and Object Bank. These descriptors combined with our
Detection Bank representation significantly outperforms any of the
representations alone on TRECVID MED 2011 data.
</summary>
    <author>
      <name>Tim Althoff</name>
    </author>
    <author>
      <name>Hyun Oh Song</name>
    </author>
    <author>
      <name>Trevor Darrell</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ACM Multimedia 2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1405.7102v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.7102v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.7571v1</id>
    <updated>2014-05-29T14:43:55Z</updated>
    <published>2014-05-29T14:43:55Z</published>
    <title>JPEG Noises beyond the First Compression Cycle</title>
    <summary>  This paper focuses on the JPEG noises, which include the quantization noise
and the rounding noise, during a JPEG compression cycle. The JPEG noises in the
first compression cycle have been well studied; however, so far less attention
has been paid on the JPEG noises in higher compression cycles. In this work, we
present a statistical analysis on JPEG noises beyond the first compression
cycle. To our knowledge, this is the first work on this topic. We find that the
noise distributions in higher compression cycles are different from those in
the first compression cycle, and they are dependent on the quantization
parameters used between two successive cycles. To demonstrate the benefits from
the statistical analysis, we provide two applications that can employ the
derived noise distributions to uncover JPEG compression history with
state-of-the-art performance.
</summary>
    <author>
      <name>Bin Li</name>
    </author>
    <author>
      <name>Tian-Tsong Ng</name>
    </author>
    <author>
      <name>Xiaolong Li</name>
    </author>
    <author>
      <name>Shunquan Tan</name>
    </author>
    <author>
      <name>Jiwu Huang</name>
    </author>
    <link href="http://arxiv.org/abs/1405.7571v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.7571v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.7629v1</id>
    <updated>2014-05-28T17:15:51Z</updated>
    <published>2014-05-28T17:15:51Z</published>
    <title>QoE assessment for SVC streaming in ENVISION</title>
    <summary>  Scalable video coding has drawn great interest in content delivery in many
multimedia services thanks to its capability to handle terminal heterogeneity
and network conditions variation. In our previous work, and under the umbrella
of ENVISION, we have proposed a playout smoothing mechanism to ensure the
uniform delivery of the layered stream, by reducing the quality changes that
the stream undergoes when adapting to changing network conditions. In this
paper we study the resulting video quality, from the final user perception
under different network conditions of loss and delays. For that we have adopted
the Double Stimulus Impairment Scale (DSIS) method. The results show that the
Mean Opinion Score for the smoothed video clips was higher under different
network configuration. This confirms the effectiveness of the proposed
smoothing mechanism.
</summary>
    <author>
      <name>Abbas Bradai</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LaBRI</arxiv:affiliation>
    </author>
    <author>
      <name>Toufik Ahmed</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LaBRI</arxiv:affiliation>
    </author>
    <author>
      <name>Samir Medjiah</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LaBRI</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE 20th International Conference on Electronics, Circuits, and
  Systems (IEEE ICECS 2013), Abu Dhabi : United Arab Emirates (2013)</arxiv:comment>
    <link href="http://arxiv.org/abs/1405.7629v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.7629v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1406.0912v3</id>
    <updated>2015-03-04T14:49:04Z</updated>
    <published>2014-06-04T00:14:06Z</published>
    <title>Towards Quality of Experience Determination for Video in Augmented
  Binocular Vision Scenarios</title>
    <summary>  With the continuous growth in the consumer markets of mobile smartphones and
increasingly in augmented reality wearable devices, several avenues of research
investigate the relationships between the quality perceived by mobile users and
the delivery mechanisms at play to support a high quality of experience for
mobile users. In this paper, we present the first study that evaluates the
relationships of mobile movie quality and the viewer-perceived quality thereof
in an augmented reality setting with see-through devices. We find that
participants tend to overestimate the video quality and exhibit a significant
variation of accuracy that leans onto the movie content and its dynamics. Our
findings, thus, can broadly impact future media adaptation and delivery
mechanisms for this new display format of mobile multimedia.
</summary>
    <author>
      <name>Patrick Seeling</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to Signal Processing: Image Communication</arxiv:comment>
    <link href="http://arxiv.org/abs/1406.0912v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1406.0912v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1406.2519v1</id>
    <updated>2014-06-10T12:07:22Z</updated>
    <published>2014-06-10T12:07:22Z</published>
    <title>On Importance of Steganographic Cost For Network Steganography</title>
    <summary>  Network steganography encompasses the information hiding techniques that can
be applied in communication network environments and that utilize hidden data
carriers for this purpose. In this paper we introduce a characteristic called
steganographic cost which is an indicator for the degradation or distortion of
the carrier caused by the application of the steganographic method. Based on
exemplary cases for single- and multi-method steganographic cost analyses we
observe that it can be an important characteristic that allows to express
hidden data carrier degradation - similarly as MSE (Mean-Square Error) or PSNR
(Peak Signal-to-Noise Ratio) are utilized for digital media steganography.
Steganographic cost can moreover be helpful to analyse the relationships
between two or more steganographic methods applied to the same hidden data
carrier.
</summary>
    <author>
      <name>Wojciech Mazurczyk</name>
    </author>
    <author>
      <name>Steffen Wendzel</name>
    </author>
    <author>
      <name>Ignacio Azagra Villares</name>
    </author>
    <author>
      <name>Krzysztof Szczypiorski</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 14 figures, 3 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1406.2519v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1406.2519v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1406.6473v1</id>
    <updated>2014-06-25T06:45:02Z</updated>
    <published>2014-06-25T06:45:02Z</published>
    <title>Performance Comparison of Linear Prediction based Vocoders in Linux
  Platform</title>
    <summary>  Linear predictive coders form an important class of speech coders. This paper
describes the software level implementation of linear prediction based
vocoders, viz. Code Excited Linear Prediction (CELP), Low-Delay CELP (LD-CELP)
and Mixed Excitation Linear Prediction (MELP) at bit rates of 4.8 kb/s, 16 kb/s
and 2.4 kb/s respectively. The C programs of the vocoders have been compiled
and executed in Linux platform. Subjective testing with the help of Mean
Opinion Score test has been performed. Waveform analysis has been done using
Praat and Adobe Audition software. The results show that MELP and CELP produce
comparable quality while the quality of LD-CELP coder is much higher, at the
expense of higher bit rate.
</summary>
    <author>
      <name>Lani Rachel Mathew</name>
    </author>
    <author>
      <name>Ancy S. Anselam</name>
    </author>
    <author>
      <name>Sakuntala S. Pillai</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.14445/22315381/IJETT-V10P310</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.14445/22315381/IJETT-V10P310" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 5 figures, Published with International Journal of
  Engineering Trends and Technology (IJETT)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Engineering Trends and Technology
  (IJETT),V10(11),554-558 April 2014</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1406.6473v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1406.6473v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1406.7226v1</id>
    <updated>2014-06-26T18:27:36Z</updated>
    <published>2014-06-26T18:27:36Z</published>
    <title>Securing Medical Images by Watermarking Using DWT DCT and SVD</title>
    <summary>  Telemedicine is well known application where enormous amount of medical data
need to be transferred securely over network and manipulate effectively.
Security of digital data, especially medical images, becomes important for many
reasons such as confidentiality, authentication and integrity. Digital
watermarking has emerged as a advanced technology to enhance the security of
digital images. The insertion of watermark in medical images can authenticate
it and guarantee its integrity. The watermark must be generally hidden does not
affect the quality of the medical image. In this paper, we propose blind
watermarking based on Discrete Wavelet Transform (DWT), Discrete Cosine
Transform (DCT) and Singular Value Decomposition (SVD), we compare the
performance of this technique with watermarking based DWT and SVD. The proposed
method DWT, DCT and SVD comparatively better than DWT and SVD method.
</summary>
    <author>
      <name>Nilesh Rathi</name>
    </author>
    <author>
      <name>Ganga Holi</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.14445/22312803/IJCTT-V12P113</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.14445/22312803/IJCTT-V12P113" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 14 figures, 4 tables, Published with International Journal
  of Computer Trends and Technology (IJCTT)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Trends and Technology (IJCTT)
  V12(2):67-74, June 2014. ISSN:2231-2803. Published by Seventh Sense Research
  Group</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1406.7226v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1406.7226v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1407.6877v1</id>
    <updated>2014-07-25T12:58:23Z</updated>
    <published>2014-07-25T12:58:23Z</published>
    <title>An Easy yet Effective Method for Detecting Spatial Domain LSB
  Steganography</title>
    <summary>  Digitization of image was a revolutionary step for the fields of photography
and Image processing as this made the editing of images much effortless and
easier. Image editing was not an issue until it was limited to corrective
editing procedures used to enhance the quality of an image such as, contrast
stretching, noise filtering, sharpening etc. But, it became a headache for many
fields when image editing became manipulative. Digital images have become an
easier source of tampering and forgery during last few decades. Today users and
editing specialists, equipped with easily available image editing software,
manipulate digital images with varied goals. Photo journalists often tamper
photographs to give dramatic effect to their stories. Scientists and
researchers use this trick to get theirs works published. Patients' diagnoses
are misrepresented by manipulating medical imageries. Lawyers and Politicians
use tampered images to direct the opinion of people or court to their favor.
Terrorists, anti-social groups use manipulated Stego images for secret
communication. In this paper we present an effective method for detecting
spatial domain Steganography.
</summary>
    <author>
      <name>Minati Mishra</name>
    </author>
    <author>
      <name>M. C. Adhikary</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages; International Journal of Computer Science and Business
  Informatics, Dec 2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1407.6877v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1407.6877v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1407.6879v1</id>
    <updated>2014-07-25T13:00:50Z</updated>
    <published>2014-07-25T13:00:50Z</published>
    <title>Detection of Clones in Digital Images</title>
    <summary>  During the recent years, tampering of digital images has become a general
habit among people and professionals. As a result, establishment of image
authenticity has become a key issue in fields those make use of digital images.
Authentication of an image involves separation of original camera outputs from
their tampered or Stego counterparts. Digital image cloning being a popular
type of image tampering, in this paper we have experimentally analyzed seven
different algorithms of cloning detection such as the simple overlapped block
matching with lexicographic sorting (SOBMwLS) algorithm, block matching with
discrete cosine transformation, principal component analysis, discrete wavelet
transformation and singular value decomposition performed on the blocks (DCT,
DWT, PCA, SVD), two combination models where, DCT and DWT are combined with
singular value decomposition (DCTSVD and DWTSVD. A comparative study of all
these techniques with respect to their time complexities and robustness of
detection against various post processing operations such as cropping,
brightness and contrast adjustments are presented in the paper.
</summary>
    <author>
      <name>Minati Mishra</name>
    </author>
    <author>
      <name>M. C. Adhikary</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 Pages, International Journal of Computer Science and Business
  Informatics, Jan 2014</arxiv:comment>
    <link href="http://arxiv.org/abs/1407.6879v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1407.6879v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1407.7667v2</id>
    <updated>2014-08-01T09:25:38Z</updated>
    <published>2014-07-29T09:10:05Z</published>
    <title>Impact of video quality and wireless network interface on power
  consumption of mobile devices</title>
    <summary>  During the last years, many improvements were made to the hardware capability
of mobile devices. As mobile software also became more interactive and data
processing intensive, the increased power demand could not be compensated by
the improvements on battery technology. Adaptive systems can help to balance
the demand of applications with the limitations of battery resources. For
effective systems, the influence of multimedia quality on power consumption of
the components of mobile devices needs to be better understood. In this paper,
we analyze the impact of video quality and wireless network type on the energy
consumption of a mobile device. We have found that the additional power
consumption is up to 38% higher when a movie is played over a WiFi network
instead from internal memory and 64% higher in case of a mobile network (3G).
We have also discovered that a higher movie quality not only affects the power
consumption of the CPU but also the power consumption of the WiFi unit by up to
58% and up to 72% respectively on mobile networks.
</summary>
    <author>
      <name>Norbert Zsak</name>
    </author>
    <author>
      <name>Christian Wolff</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2 pages, 1 figure, unpublished short paper</arxiv:comment>
    <link href="http://arxiv.org/abs/1407.7667v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1407.7667v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1408.3564v1</id>
    <updated>2014-08-15T15:33:40Z</updated>
    <published>2014-08-15T15:33:40Z</published>
    <title>Digital Image Data Hiding Techniques: A Comparative Study</title>
    <summary>  With the advancements in the field of digital image processing during the
last decade, digital image data hiding techniques such as watermarking,
Steganography have gained wide popularity. Digital image watermarking
techniques hide a small amount of data into a digital image which, later can be
retrieved using some specific retrieval algorithms to prove the copyright of a
piece of digital information whereas, Steganographic techniques are used to
hide a large amount of data secretly into some innocuous looking digital
medium. In this paper we are providing an up-to-date review of these data
hiding techniques.
</summary>
    <author>
      <name>Minati Mishra</name>
    </author>
    <author>
      <name>Priyadarsini Mishra</name>
    </author>
    <author>
      <name>M. C. Adhikary</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, ANVESA - The Journal of F.M. University, ISSN-0974-715X.
  arXiv admin note: text overlap with
  http://dx.doi.org/10.1016/j.sigpro.2009.08.010 by other authors</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ANVESA,7(2), 105-115, 2012</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1408.3564v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1408.3564v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1408.5777v1</id>
    <updated>2014-08-07T16:38:25Z</updated>
    <published>2014-08-07T16:38:25Z</published>
    <title>Characterizing Internet Video for Large-scale Active Measurements</title>
    <summary>  The availability of high definition video content on the web has brought
about a significant change in the characteristics of Internet video, but not
many studies on characterizing video have been done after this change. Video
characteristics such as video length, format, target bit rate, and resolution
provide valuable input to design Adaptive Bit Rate (ABR) algorithms, sizing
playout buffers in Dynamic Adaptive HTTP streaming (DASH) players, model the
variability in video frame sizes, etc. This paper presents datasets collected
in 2013 and 2014 that contains over 130,000 videos from YouTube's most viewed
(or most popular) video charts in 58 countries. We describe the basic
characteristics of the videos on YouTube for each category, format, video
length, file size, and data rate variation, observing that video length and
file size fit a log normal distribution. We show that three minutes of a video
suffice to represent its instant data rate fluctuation and that we can infer
data rate characteristics of different video resolutions from a single given
one. Based on our findings, we design active measurements for measuring the
performance of Internet video.
</summary>
    <author>
      <name>Saba Ahsan</name>
    </author>
    <author>
      <name>Varun Singh</name>
    </author>
    <author>
      <name>Jörg Ott</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 18 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1408.5777v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1408.5777v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1409.1148v1</id>
    <updated>2014-09-03T16:28:36Z</updated>
    <published>2014-09-03T16:28:36Z</published>
    <title>Toward Green Media Delivery: Location-Aware Opportunities and Approaches</title>
    <summary>  Mobile media has undoubtedly become the predominant source of traffic in
wireless networks. The result is not only congestion and poor
Quality-of-Experience, but also an unprecedented energy drain at both the
network and user devices. In order to sustain this continued growth, novel
disruptive paradigms of media delivery are urgently needed. We envision that
two key contemporary advancements can be leveraged to develop greener media
delivery platforms: 1) the proliferation of navigation hardware and software in
mobile devices has created an era of location-awareness, where both the current
and future user locations can be predicted; and 2) the rise of context-aware
network architectures and self-organizing functionalities is enabling context
signaling and in-network adaptation. With these developments in mind, this
article investigates the opportunities of exploiting location-awareness to
enable green end-to-end media delivery. In particular, we discuss and propose
approaches for location-based adaptive video quality planning, in-network
caching, content prefetching, and long-term radio resource management. To
provide insights on the energy savings, we then present a cross-layer framework
that jointly optimizes resource allocation and multi-user video quality using
location predictions. Finally, we highlight some of the future research
directions for location-aware media delivery in the conclusion.
</summary>
    <author>
      <name>Hatem Abou-zeid</name>
    </author>
    <author>
      <name>Hosssam S. Hassenein</name>
    </author>
    <link href="http://arxiv.org/abs/1409.1148v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1409.1148v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1409.4587v1</id>
    <updated>2014-09-16T11:27:38Z</updated>
    <published>2014-09-16T11:27:38Z</published>
    <title>A new Watermarking Technique for Medical Image using Hierarchical
  Encryption</title>
    <summary>  In recent years, characterized by the innovation of technology and the
digital revolution, the field of media has become important. The transfer and
exchange of multimedia data and duplication have become major concerns of
researchers. Consequently, protecting copyrights and ensuring service safety is
needed. Cryptography has a specific role, is to protect secret files against
unauthorized access. In this paper, a hierarchical cryptosystem algorithm based
on Logistic Map chaotic systems is proposed. The results show that the proposed
method improves the security of the image. Experimental results on a database
of 200 medical images show that the proposed method significantly gives better
results.
</summary>
    <author>
      <name>Med Karim Abdmouleh</name>
    </author>
    <author>
      <name>Ali Khalfallah</name>
    </author>
    <author>
      <name>Med Salim Bouhlel</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 9 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IJCSI International Journal of Computer Science Issues 11(4)
  (2014) 27-32</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1409.4587v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1409.4587v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.1474v1</id>
    <updated>2014-10-06T17:48:39Z</updated>
    <published>2014-10-06T17:48:39Z</published>
    <title>An adaptive quasi harmonic broadcasting scheme with optimal bandwidth
  requirement</title>
    <summary>  The aim of Harmonic Broadcasting protocol is to reduce the bandwidth usage in
video-on-demand service where a video is divided into some equal sized segments
and every segment is repeatedly transmitted over a number of channels that
follows harmonic series for channel bandwidth assignment. As the bandwidth of
channels differs from each other and users can join at any time to these
multicast channels, they may experience a synchronization problem between
download and playback. To deal with this issue, some schemes have been
proposed, however, at the cost of additional or wastage of bandwidth or sudden
extreme bandwidth requirement. In this paper we present an adaptive quasi
harmonic broadcasting scheme (AQHB) which delivers all data segment on time
that is the download and playback synchronization problem is eliminated while
keeping the bandwidth consumption as same as traditional harmonic broadcasting
scheme without cost of any additional or wastage of bandwidth. It also ensures
the video server not to increase the channel bandwidth suddenly that is, also
eliminates the sudden buffer requirement at the client side. We present several
analytical results to exhibit the efficiency of our proposed broadcasting
scheme over the existing ones.
</summary>
    <author>
      <name>Farzana Afrin</name>
    </author>
    <author>
      <name>Mohammad Saiedur Rahaman</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/ICIEV.2013.6572684</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/ICIEV.2013.6572684" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE International Conference on Informatics, Electronics &amp; Vision
  (ICIEV), 2013, 6pages, 8 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1410.1474v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.1474v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.3117v1</id>
    <updated>2014-10-12T16:47:55Z</updated>
    <published>2014-10-12T16:47:55Z</published>
    <title>An Efficient Bit Plane X-OR Algorithm for Irreversible Image
  Steganography</title>
    <summary>  The science of hiding secret information in another message is known as
Steganography; hence the presence of secret information is concealed. It is the
method of hiding cognitive content in same or another media to avoid
recognition by the intruders. This paper introduces new method wherein
irreversible steganography is used to hide an image in the same medium so that
the secret data is masked. The secret image is known as payload and the carrier
is known as cover image. X-OR operation is used amongst mid level bit planes of
carrier image and high level bit planes of data image to generate new low level
bit planes of the stego image. Recovery process includes the X-ORing of low
level bit planes and mid level bit planes of the stego image. Based on the
result of the recovery, subsequent data image is generated. A RGB color image
is used as carrier and the data image is a grayscale image of dimensions less
than or equal to the dimensions of the carrier image. The proposed method
greatly increases the embedding capacity without significantly decreasing the
PSNR value.
</summary>
    <author>
      <name>Soumendu Chakraborty</name>
    </author>
    <author>
      <name>Anand Singh Jalal</name>
    </author>
    <author>
      <name>Charul Bhatnagar</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1504/IJTMCC.2013.053263</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1504/IJTMCC.2013.053263" rel="related"/>
    <link href="http://arxiv.org/abs/1410.3117v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.3117v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.3977v1</id>
    <updated>2014-10-15T09:09:10Z</updated>
    <published>2014-10-15T09:09:10Z</published>
    <title>Multi-View 3D Video Multicast for Broadband IP Networks</title>
    <summary>  With the recent emergence of 3D-supported TVs, video service providers now
face an opportunity to provide high resolution multi-view 3D videos over IP
networks. One simple way to support efficient communications between a video
server and multiple clients is to deliver each desired view in a multicast
stream. Nevertheless, it is expected that significantly increased bandwidth
will be required to support the transmission of all views in multi-view 3D
videos. However, the recent emergence of a new video synthesis technique called
Depth-Image-Based Rendering (DIBR) suggests that multi-view 3D video does not
necessarily require the transmission of all views. Therefore, we formulate a
new problem, named Multi-view and Multicast Delivery Selection Problem (MMDS),
and design an algorithm, called MMDEA, to find the optimal solution. Simulation
results manifest that using DIBR can effectively reduce bandwidth consumption
by 35% compared to the original multicast delivery scheme.
</summary>
    <author>
      <name>Ting-Yu Ho</name>
    </author>
    <author>
      <name>Yi-Nung Yeh</name>
    </author>
    <author>
      <name>De-Nian Yang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 10 figures, IEEE ICC 2015</arxiv:comment>
    <link href="http://arxiv.org/abs/1410.3977v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.3977v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.4730v1</id>
    <updated>2014-10-17T14:16:08Z</updated>
    <published>2014-10-17T14:16:08Z</published>
    <title>Human Motion Capture Data Tailored Transform Coding</title>
    <summary>  Human motion capture (mocap) is a widely used technique for digitalizing
human movements. With growing usage, compressing mocap data has received
increasing attention, since compact data size enables efficient storage and
transmission. Our analysis shows that mocap data have some unique
characteristics that distinguish themselves from images and videos. Therefore,
directly borrowing image or video compression techniques, such as discrete
cosine transform, does not work well. In this paper, we propose a novel
mocap-tailored transform coding algorithm that takes advantage of these
features. Our algorithm segments the input mocap sequences into clips, which
are represented in 2D matrices. Then it computes a set of data-dependent
orthogonal bases to transform the matrices to frequency domain, in which the
transform coefficients have significantly less dependency. Finally, the
compression is obtained by entropy coding of the quantized coefficients and the
bases. Our method has low computational cost and can be easily extended to
compress mocap databases. It also requires neither training nor complicated
parameter setting. Experimental results demonstrate that the proposed scheme
significantly outperforms state-of-the-art algorithms in terms of compression
performance and speed.
</summary>
    <author>
      <name>Junhui Hou</name>
    </author>
    <author>
      <name>Lap-Pui Chau</name>
    </author>
    <author>
      <name>Nadia Magnenat-Thalmann</name>
    </author>
    <author>
      <name>Ying He</name>
    </author>
    <link href="http://arxiv.org/abs/1410.4730v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.4730v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.6592v1</id>
    <updated>2014-10-24T06:36:48Z</updated>
    <published>2014-10-24T06:36:48Z</published>
    <title>Hiding Sound in Image by K-LSB Mutation</title>
    <summary>  In this paper a novel approach to hide sound files in a digital image is
proposed and implemented such that it becomes difficult to conclude about the
existence of the hidden data inside the image. In this approach, we utilize the
rightmost k-LSB of pixels in an image to embed MP3 sound bits into a pixel. The
pixels are so chosen that the distortion in image would be minimized due to
embedding. This requires comparing all the possible permutations of pixel
values, which may would lead to exponential time computation. To speed up this,
Cuckoo Search (CS) could be used to find the most optimal solution. The
advantage of using proposed CS is that it is easy to implement and is very
effective at converging in relatively less iterations/generations.
</summary>
    <author>
      <name>Ankur Gupta</name>
    </author>
    <author>
      <name>Ankit Chaudhary</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">appears in ISCBI 2014</arxiv:comment>
    <link href="http://arxiv.org/abs/1410.6592v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.6592v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.6796v1</id>
    <updated>2014-08-27T08:46:05Z</updated>
    <published>2014-08-27T08:46:05Z</published>
    <title>Steganography in Modern Smartphones and Mitigation Techniques</title>
    <summary>  By offering sophisticated services and centralizing a huge volume of personal
data, modern smartphones changed the way we socialize, entertain and work. To
this aim, they rely upon complex hardware/software frameworks leading to a
number of vulnerabilities, attacks and hazards to profile individuals or gather
sensitive information. However, the majority of works evaluating the security
degree of smartphones neglects steganography, which can be mainly used to: i)
exfiltrate confidential data via camouflage methods, and ii) conceal valuable
or personal information into innocent looking carriers.
  Therefore, this paper surveys the state of the art of steganographic
techniques for smartphones, with emphasis on methods developed over the period
2005 to the second quarter of 2014. The different approaches are grouped
according to the portion of the device used to hide information, leading to
three different covert channels, i.e., local, object and network. Also, it
reviews the relevant approaches used to detect and mitigate steganographic
attacks or threats. Lastly, it showcases the most popular software applications
to embed secret data into carriers, as well as possible future directions.
</summary>
    <author>
      <name>Wojciech Mazurczyk</name>
    </author>
    <author>
      <name>Luca Caviglione</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">25 pages, 8 figures, 6 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1410.6796v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.6796v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1411.1705v1</id>
    <updated>2014-11-05T16:29:30Z</updated>
    <published>2014-11-05T16:29:30Z</published>
    <title>A Novel No-reference Video Quality Metric for Evaluating Temporal
  Jerkiness due to Frame Freezing</title>
    <summary>  In this work, we propose a novel no-reference (NR) video quality metric that
evaluates the impact of frame freezing due to either packet loss or late
arrival. Our metric uses a trained neural network acting on features that are
chosen to capture the impact of frame freezing on the perceived quality. The
considered features include the number of freezes, freeze duration statistics,
inter-freeze distance statistics, frame difference before and after the freeze,
normal frame difference, and the ratio of them. We use the neural network to
find the mapping between features and subjective test scores. We optimize the
network structure and the feature selection through a cross validation
procedure, using training samples extracted from both VQEG and LIVE video
databases. The resulting feature set and network structure yields accurate
quality prediction for both the training data containing 54 test videos and a
separate testing dataset including 14 videos, with Pearson Correlation
Coefficients greater than 0.9 and 0.8 for the training set and the testing set,
respectively. Our proposed metric has low complexity and could be utilized in a
system with realtime processing constraint.
</summary>
    <author>
      <name>Yuanyi Xue</name>
    </author>
    <author>
      <name>Beril Erkin</name>
    </author>
    <author>
      <name>Yao Wang</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TMM.2014.2368272</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TMM.2014.2368272" rel="related"/>
    <link href="http://arxiv.org/abs/1411.1705v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1411.1705v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1411.4080v1</id>
    <updated>2014-11-14T23:29:18Z</updated>
    <published>2014-11-14T23:29:18Z</published>
    <title>6 Seconds of Sound and Vision: Creativity in Micro-Videos</title>
    <summary>  The notion of creativity, as opposed to related concepts such as beauty or
interestingness, has not been studied from the perspective of automatic
analysis of multimedia content. Meanwhile, short online videos shared on social
media platforms, or micro-videos, have arisen as a new medium for creative
expression. In this paper we study creative micro-videos in an effort to
understand the features that make a video creative, and to address the problem
of automatic detection of creative content. Defining creative videos as those
that are novel and have aesthetic value, we conduct a crowdsourcing experiment
to create a dataset of over 3,800 micro-videos labelled as creative and
non-creative. We propose a set of computational features that we map to the
components of our definition of creativity, and conduct an analysis to
determine which of these features correlate most with creative video. Finally,
we evaluate a supervised approach to automatically detect creative video, with
promising results, showing that it is necessary to model both aesthetic value
and novelty to achieve optimal classification accuracy.
</summary>
    <author>
      <name>Miriam Redi</name>
    </author>
    <author>
      <name>Neil O Hare</name>
    </author>
    <author>
      <name>Rossano Schifanella</name>
    </author>
    <author>
      <name>Michele Trevisiol</name>
    </author>
    <author>
      <name>Alejandro Jaimes</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/CVPR.2014.544</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/CVPR.2014.544" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 1 figures, conference IEEE CVPR 2014</arxiv:comment>
    <link href="http://arxiv.org/abs/1411.4080v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1411.4080v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1411.4290v1</id>
    <updated>2014-11-16T18:52:54Z</updated>
    <published>2014-11-16T18:52:54Z</published>
    <title>Maximizing compression efficiency through block rotation</title>
    <summary>  The Discrete Cosine Transform (DCT) is widely used in lossy image and video
compression schemes, e.g., JPEG and MPEG. In this paper, we show that the
compression efficiency of the DCT is dependent on the edge directions within a
block. In particular, higher compression ratios are achieved when edges are
aligned with the image axes. To maximize compression for general images, we
propose a rotated block DCT method. It consists of rotating each block, before
applying the DCT, by an angle that aligns the edges, and rotating back the
block in the decompression stage. We show how to compute the rotation angle and
analyze two alternative block rotation approaches. Our experiments show that
our method enables both a perceptual improvement and a PSNR increase of up to
2dB, compared with the standard DCT, for low and medium bit rates.
</summary>
    <author>
      <name>Rui F. C. Guerreiro</name>
    </author>
    <author>
      <name>Pedro M. Q. Aguiar</name>
    </author>
    <link href="http://arxiv.org/abs/1411.4290v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1411.4290v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1411.4790v1</id>
    <updated>2014-11-18T10:05:23Z</updated>
    <published>2014-11-18T10:05:23Z</published>
    <title>The Art of Data Hiding with Reed-Solomon Error Correcting Codes</title>
    <summary>  With the tremendous advancements in technology and the Internet, data
security has become a major issue around the globe. To guarantee that data is
protected and does not go to an unintended endpoint, the art of data hiding
(steganography) emerged. Steganography is the art of hiding information such
that it is not detectable to the naked eye. Various techniques have been
proposed for hiding a secret message in a carrier document. In this paper, we
present a novel design that applies Reed-Solomon (RS) error correcting codes in
steganographic applications. The model works by substituting the redundant RS
codes with the steganographic message. The experimental results show that the
proposed design is satisfactory with the percentage of decoded information 100%
and percentage of decoded secret message 97. 36%. The proposed model proved
that it could be applied in various steganographic applications.
</summary>
    <author>
      <name>Fredrick R. Ishengoma</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5120/18590-9902</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5120/18590-9902" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Applications 106(14):28-31,
  November 2014</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1411.4790v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1411.4790v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1412.6143v1</id>
    <updated>2014-11-17T16:58:54Z</updated>
    <published>2014-11-17T16:58:54Z</published>
    <title>Block Based Medical Image Watermarking Technique for Tamper Detection
  and Recovery</title>
    <summary>  In this paper, we propose a novel fragile block based medical image
watermarking technique for embedding data of patient into medical image,
verifying the integrity of ROI (Region of Interest), detecting the tampered
blocks inside ROI and recovering original ROI with less size authentication and
recovery data and with simple mathematical calculations. In the proposed
method, the medical image is divided into three regions called ROI, RONI
(Region of Non Interest) and border pixels. Later, authentication data of ROI
and Electronic Patient Record (EPR) are compressed using Run Length Encoding
(RLE) technique and then embedded into ROI. Recovery information of ROI is
embedded inside RONI and information of ROI is embedded inside border pixels.
Results of experiments conducted on several medical images reveal that proposed
method produces high quality watermarked medical images, identifies tampered
areas inside ROI of watermarked medical images and recovers the original ROI.
</summary>
    <author>
      <name>Eswaraiah Rayachoti</name>
    </author>
    <author>
      <name>Sreenivasa Reddy Edara</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 6 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ijcsi.org/papers/IJCSI-11-5-1-31-40.pdf 2014</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1412.6143v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1412.6143v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1501.01576v3</id>
    <updated>2015-09-16T17:17:32Z</updated>
    <published>2015-01-07T17:59:15Z</published>
    <title>Improving image watermarking based on Tabu search by Chaos</title>
    <summary>  With the fast development of communication and multimedia technology, the
rights of the owners of multimedia products is vulnerable to the unauthorized
copies and watermarking is one of the best known methods for proving the
ownership of a product. In this paper we prosper the previous watermarking
method which was based on Tabu search by Chaos. The modification applied in the
permutation step of watermarking and the initial population generation of the
Tabu search. We analyze our method on some well known images and experimental
results shows the improvement in the quality and speed of the proposed
watermarking method.
</summary>
    <author>
      <name>Mohammad Tafaghodi</name>
    </author>
    <author>
      <name>Meysam Ghaffari</name>
    </author>
    <author>
      <name>Alimohammad Latif</name>
    </author>
    <author>
      <name>Seyed Rasoul Mousavi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper has been withdrawn by arXiv. arXiv admin note: author list
  truncated due to disputed authorship and content</arxiv:comment>
    <link href="http://arxiv.org/abs/1501.01576v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1501.01576v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1501.01755v1</id>
    <updated>2015-01-08T08:02:01Z</updated>
    <published>2015-01-08T08:02:01Z</published>
    <title>Minimization of image watermarking side effects through subjective
  optimization</title>
    <summary>  This paper investigates the use of Structural Similaritys (SSIM) index on the
minimized side effect to image watermarking. For fast implementation and more
compatibility with the standard DCT based codecs, watermark insertion is
carried out on the DCT coefficients and hence a SSIM model for DCT based
watermarking is developed. For faster implementation, the SSIM index is
maximized over independent 4x4 non-overlapped blocks but the disparity between
the adjacent blocks reduces the overall image quality. This problem is resolved
through optimization of overlapped blocks, but, the higher image quality is
achieved at a cost of high computational complexity. To reduce the
computational complexity while preserving the good quality, optimization of
semi-overlapped blocks is introduced. We show that while SSIM-based
optimization over overlapped blocks has as high as 64 times the complexity of
the 4x4 non-overlapped method, with semi-overlapped optimization the high
quality of overlapped method is preserved only at a cost of less than 8 times
the non-overlapped method.
</summary>
    <author>
      <name>Hossein Bakhshi Golestani</name>
    </author>
    <author>
      <name>Mohammed Ghanbari</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1049/iet-ipr.2013.0086</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1049/iet-ipr.2013.0086" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages,11 figures, IET Image Processing Journal</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IET Image Processing, vol. 7, no. 8, pp. 733-741, 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1501.01755v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1501.01755v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1501.02528v1</id>
    <updated>2015-01-12T03:13:34Z</updated>
    <published>2015-01-12T03:13:34Z</published>
    <title>A Systematic Scheme for Measuring the Performance of the Display-Camera
  Channel</title>
    <summary>  Display-camera communication has become a promising direction in both
computer vision and wireless communication communities. However, the
consistency of the channel measurement is an open issue since precise
calibration of the experimental setting has not been fully studied in the
literatures. This paper focuses on establishing a scheme for precise
calibration of the display-camera channel performance. To guarantee high
consistency of the experiment, we propose an accurate measurement scheme for
the geometric parameters, and identify some unstable channel factors, e.g.,
Moire effect, rolling shutter effect, blocking artifacts, inconsistency in
auto-focus, trembling and vibration. In the experiment, we first define the
consistency criteria according to the error-prone region in bit error rate
(BER) plots of the channel measurements. It is demonstrated that the
consistency of the experimental result can be improved by the proposed precise
calibration scheme.
</summary>
    <author>
      <name>Changsheng Chen</name>
    </author>
    <author>
      <name>Wai Ho Mow</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, preliminary conference version</arxiv:comment>
    <link href="http://arxiv.org/abs/1501.02528v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1501.02528v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.00296v1</id>
    <updated>2015-02-01T18:43:29Z</updated>
    <published>2015-02-01T18:43:29Z</published>
    <title>Fragile Watermarking Using Finite Field Trigonometrical Transforms</title>
    <summary>  Fragile digital watermarking has been applied for authentication and
alteration detection in images. Utilizing the cosine and Hartley transforms
over finite fields, a new transform domain fragile watermarking scheme is
introduced. A watermark is embedded into a host image via a blockwise
application of two-dimensional finite field cosine or Hartley transforms.
Additionally, the considered finite field transforms are adjusted to be number
theoretic transforms, appropriate for error-free calculation. The employed
technique can provide invisible fragile watermarking for authentication systems
with tamper location capability. It is shown that the choice of the finite
field characteristic is pivotal to obtain perceptually invisible watermarked
images. It is also shown that the generated watermarked images can be used as
publicly available signature data for authentication purposes.
</summary>
    <author>
      <name>R. J. Cintra</name>
    </author>
    <author>
      <name>V. S. Dimitrov</name>
    </author>
    <author>
      <name>H. M. de Oliveira</name>
    </author>
    <author>
      <name>R. M. Campello de Souza</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.image.2009.04.003</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.image.2009.04.003" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 7 figures, 2 tables</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Image Communication, Volume 24, Issue 7, August, 2009, pp. 587-597</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1502.00296v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.00296v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.01996v1</id>
    <updated>2015-02-06T19:16:45Z</updated>
    <published>2015-02-06T19:16:45Z</published>
    <title>Wavelet based Watermarking approach in the Compressive Sensing Scenario</title>
    <summary>  Due to the wide distribution and usage of digital media, an important issue
is protection of the digital content. There is a number of algorithms and
techniques developed for the digital watermarking.In this paper, the invisible
image watermark procedure is considered. Watermark is created as a pseudo
random sequence, embedded in the certain region of the image, obtained using
Haar wavelet decomposition. Generally, the watermarking procedure should be
robust to the various attacks-filtering, noise etc. Here we assume the
Compressive sensing scenario as a new signal processing technique that may
influence the robustness. The focus of this paper was the possibility of the
watermark detection under Compressive Sensing attack with different number of
available image coefficients. The quality of the reconstructed images has been
evaluated using Peak Signal to Noise Ratio (PSNR).The theory is supported with
experimental results.
</summary>
    <author>
      <name>Jelena Music</name>
    </author>
    <author>
      <name>Ivan Knezevic</name>
    </author>
    <author>
      <name>Edis Franca</name>
    </author>
    <link href="http://arxiv.org/abs/1502.01996v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.01996v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.02969v1</id>
    <updated>2015-02-10T16:23:07Z</updated>
    <published>2015-02-10T16:23:07Z</published>
    <title>A DCT And SVD based Watermarking Technique To Identify Tag</title>
    <summary>  With the rapid development of the multimedia,the secure of the multimedia is
get more concerned. as far as we know , Digital watermarking is an effective
way to protect copyright. The watermark must be generally hidden does not
affect the quality of the original image. In this paper,a novel way based on
discrete cosine transform(DCT) and singular value decomposition(SVD) .In the
proposed way,we decomposition the image into 8*8 blocks, next we use the DCT to
get the transformed block,then we choose the diagonal to embed the information,
after we do this, we recover the image and then we decomposition the image to
8*8 blocks,we use the SVD way to get the diagonal matrix and embed the
information in the matrix. next we extract the information use both inverse of
DCT and SVD, as we all know,after we embed the information seconded time , the
information we first information we embed must be changed, we choose a measure
way called Peak Signal to Noise Ratio(PSNR) to estimate the similarity of the
two image, and set a threshold to ensure whether the information is same or
not.
</summary>
    <author>
      <name>Ke Ji</name>
    </author>
    <author>
      <name>Jianbiao Lin</name>
    </author>
    <author>
      <name>Hui Li</name>
    </author>
    <author>
      <name>Ao Wang</name>
    </author>
    <author>
      <name>Tianjing Tang</name>
    </author>
    <link href="http://arxiv.org/abs/1502.02969v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.02969v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.03802v1</id>
    <updated>2015-02-12T20:41:15Z</updated>
    <published>2015-02-12T20:41:15Z</published>
    <title>A two-stage video coding framework with both self-adaptive redundant
  dictionary and adaptively orthonormalized DCT basis</title>
    <summary>  In this work, we propose a two-stage video coding framework, as an extension
of our previous one-stage framework in [1]. The two-stage frameworks consists
two different dictionaries. Specifically, the first stage directly finds the
sparse representation of a block with a self-adaptive dictionary consisting of
all possible inter-prediction candidates by solving an L0-norm minimization
problem using an improved orthogonal matching pursuit with embedded
orthonormalization (eOMP) algorithm, and the second stage codes the residual
using DCT dictionary adaptively orthonormalized to the subspace spanned by the
first stage atoms. The transition of the first stage and the second stage is
determined based on both stages' quantization stepsizes and a threshold. We
further propose a complete context adaptive entropy coder to efficiently code
the locations and the coefficients of chosen first stage atoms. Simulation
results show that the proposed coder significantly improves the RD performance
over our previous one-stage coder. More importantly, the two-stage coder, using
a fixed block size and inter-prediction only, outperforms the H.264 coder
(x264) and is competitive with the HEVC reference coder (HM) over a large rate
range.
</summary>
    <author>
      <name>Yuanyi Xue</name>
    </author>
    <author>
      <name>Yi Zhou</name>
    </author>
    <author>
      <name>Yao Wang</name>
    </author>
    <link href="http://arxiv.org/abs/1502.03802v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.03802v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.06078v1</id>
    <updated>2015-02-21T07:26:33Z</updated>
    <published>2015-02-21T07:26:33Z</published>
    <title>Evaluating QoS Parameters for IPTV Distribution in Heterogeneous
  Networks</title>
    <summary>  The present work presents an architecture developed to evaluate the QoS
parameters for the IPTV heterogeneous network. At its very basic level lie two
software technologies: Video LAN and Windows Media Services with two operating
systems: Windows and Linux. Three types of streams are analyzed, which will be
transmitted to a Linux VLC client through means of the aggregation and access
servers. The first stream is generated in real time by a capture camera,
processed by the encapsulated VC-1 encoder and sent to the Media Server, while
the second one is of VoD(Video on Demand) type and the third one will be
handled by DVBViewer through the MPEG TS form. The first stream is transcoded
in H.264-AAC such that the Linux stations will recognize its format. Through
the simultaneous transmission of the three streams, we are analyzing their
performance from a QoS parameters point of view by means of an application
implemented in C programming language. The stream transporting the DVB-S
television content was proven to ensure the best performance regarding loss of
packets, delays and jitter.
</summary>
    <author>
      <name>Ioan Sorin Comsa</name>
    </author>
    <author>
      <name>Radu Arsinte</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 19 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1502.06078v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.06078v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.06314v1</id>
    <updated>2015-02-23T04:44:02Z</updated>
    <published>2015-02-23T04:44:02Z</published>
    <title>Crowdsourced Live Streaming over the Cloud</title>
    <summary>  Empowered by today's rich tools for media generation and distribution, and
the convenient Internet access, crowdsourced streaming generalizes the
single-source streaming paradigm by including massive contributors for a video
channel. It calls a joint optimization along the path from crowdsourcers,
through streaming servers, to the end-users to minimize the overall latency.
The dynamics of the video sources, together with the globalized request demands
and the high computation demand from each sourcer, make crowdsourced live
streaming challenging even with powerful support from modern cloud computing.
In this paper, we present a generic framework that facilitates a cost-effective
cloud service for crowdsourced live streaming. Through adaptively leasing, the
cloud servers can be provisioned in a fine granularity to accommodate
geo-distributed video crowdsourcers. We present an optimal solution to deal
with service migration among cloud instances of diverse lease prices. It also
addresses the location impact to the streaming quality. To understand the
performance of the proposed strategies in the realworld, we have built a
prototype system running over the planetlab and the Amazon/Microsoft Cloud. Our
extensive experiments demonstrate that the effectiveness of our solution in
terms of deployment cost and streaming quality.
</summary>
    <author>
      <name>Fei Chen</name>
    </author>
    <author>
      <name>Cong Zhang</name>
    </author>
    <author>
      <name>Feng Wang</name>
    </author>
    <author>
      <name>Jiangchuan Liu</name>
    </author>
    <link href="http://arxiv.org/abs/1502.06314v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.06314v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.07808v1</id>
    <updated>2015-02-27T03:05:43Z</updated>
    <published>2015-02-27T03:05:43Z</published>
    <title>A Secure Cyclic Steganographic Technique for Color Images using
  Randomization</title>
    <summary>  Information Security is a major concern in today's modern era. Almost all the
communicating bodies want the security, confidentiality and integrity of their
personal data. But this security goal cannot be achieved easily when we are
using an open network like Internet. Steganography provides one of the best
solutions to this problem. This paper represents a new Cyclic Steganographic T
echnique (CST) based on Least Significant Bit (LSB) for true color (RGB)
images. The proposed method hides the secret data in the LSBs of cover image
pixels in a randomized cyclic manner. The proposed technique is evaluated using
both subjective and objective analysis using histograms changeability, Peak
Signal-to-Noise Ratio (PSNR) and Mean Square Error (MSE). Experimentally it is
found that the proposed method gives promising results in terms of security,
imperceptibility and robustness as compared to some existent methods and
vindicates this new algorithm.
</summary>
    <author>
      <name>Khan Muhammad</name>
    </author>
    <author>
      <name>Jamil Ahmad</name>
    </author>
    <author>
      <name>Naeem Ur Rehman</name>
    </author>
    <author>
      <name>Zahoor Jan</name>
    </author>
    <author>
      <name>Rashid Jalal Qureshi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Technical Journal, University of Engineering and Technology
  Taxila, Pakistan, vol. 19, pp. 57-64, 2014</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1502.07808v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.07808v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.00083v1</id>
    <updated>2015-02-28T06:59:42Z</updated>
    <published>2015-02-28T06:59:42Z</published>
    <title>A Computation Control Motion Estimation Method for Complexity-Scalable
  Video Coding</title>
    <summary>  In this paper, a new Computation-Control Motion Estimation (CCME) method is
proposed which can perform Motion Estimation (ME) adaptively under different
computation or power budgets while keeping high coding performance. We first
propose a new class-based method to measure the Macroblock (MB) importance
where MBs are classified into different classes and their importance is
measured by combining their class information as well as their initial matching
cost information. Based on the new MB importance measure, a complete CCME
framework is then proposed to allocate computation for ME. The proposed method
performs ME in a one-pass flow. Experimental results demonstrate that the
proposed method can allocate computation more accurately than previous methods
and thus has better performance under the same computation budget.
</summary>
    <author>
      <name>Weiyao Lin</name>
    </author>
    <author>
      <name>Krit Panusopone</name>
    </author>
    <author>
      <name>David M. Baylon</name>
    </author>
    <author>
      <name>Ming-Ting Sun</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TCSVT.2010.2077773</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TCSVT.2010.2077773" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This manuscript is the accepted version for TCSVT (IEEE Transactions
  on Circuits and Systems for Video Technology)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE Trans. Circuits and Systems for Video Technology, vol. 20,
  no. 11, pp. 1533-1543, 2010</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1503.00083v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.00083v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.00087v1</id>
    <updated>2015-02-28T07:14:01Z</updated>
    <published>2015-02-28T07:14:01Z</published>
    <title>Macroblock Classification Method for Video Applications Involving
  Motions</title>
    <summary>  In this paper, a macroblock classification method is proposed for various
video processing applications involving motions. Based on the analysis of the
Motion Vector field in the compressed video, we propose to classify Macroblocks
of each video frame into different classes and use this class information to
describe the frame content. We demonstrate that this low-computation-complexity
method can efficiently catch the characteristics of the frame. Based on the
proposed macroblock classification, we further propose algorithms for different
video processing applications, including shot change detection, motion
discontinuity detection, and outlier rejection for global motion estimation.
Experimental results demonstrate that the methods based on the proposed
approach can work effectively on these applications.
</summary>
    <author>
      <name>Weiyao Lin</name>
    </author>
    <author>
      <name>Ming-Ting Sun</name>
    </author>
    <author>
      <name>Hongxiang Li</name>
    </author>
    <author>
      <name>Zhenzhong Chen</name>
    </author>
    <author>
      <name>Wei Li</name>
    </author>
    <author>
      <name>Bing Zhou</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TBC.2011.2170611</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TBC.2011.2170611" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This manuscript is the accepted version for TB (IEEE Transactions on
  Broadcasting)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE Trans. Broadcasting, vol. 58, no. 1, pp. 34-46, 2012</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1503.00087v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.00087v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.00118v1</id>
    <updated>2015-02-28T11:42:42Z</updated>
    <published>2015-02-28T11:42:42Z</published>
    <title>An Efficient Coding Method for Coding Region-of-Interest Locations in
  AVS2</title>
    <summary>  Region-of-Interest (ROI) location information in videos has many practical
usages in video coding field, such as video content analysis and user
experience improvement. Although ROI-based coding has been studied widely by
many researchers to improve coding efficiency for video contents, the ROI
location information itself is seldom coded in video bitstream. In this paper,
we will introduce our proposed ROI location coding tool which has been adopted
in surveillance profile of AVS2 video coding standard (surveillance profile).
Our tool includes three schemes: direct-coding scheme, differential- coding
scheme, and reconstructed-coding scheme. We will illustrate the details of
these schemes, and perform analysis of their advantages and disadvantages,
respectively.
</summary>
    <author>
      <name>Mingliang Chen</name>
    </author>
    <author>
      <name>Weiyao Lin</name>
    </author>
    <author>
      <name>Xiaozhen Zheng</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/ICMEW.2014.6890688</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/ICMEW.2014.6890688" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This manuscript is the accepted version for ICMEW (IEEE Intl. Conf.
  Multimedia &amp; Expo Workshop), IEEE Intl. Conf. Multimedia &amp; Expo Workshop
  (ICME), 2014</arxiv:comment>
    <link href="http://arxiv.org/abs/1503.00118v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.00118v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.00388v1</id>
    <updated>2015-03-02T01:41:39Z</updated>
    <published>2015-03-02T01:41:39Z</published>
    <title>A Novel Image Steganographic Approach for Hiding Text in Color Images
  using HSI Color Model</title>
    <summary>  Image Steganography is the process of embedding text in images such that its
existence cannot be detected by Human Visual System (HVS) and is known only to
sender and receiver. This paper presents a novel approach for image
steganography using Hue-Saturation-Intensity (HSI) color space based on Least
Significant Bit (LSB). The proposed method transforms the image from RGB color
space to Hue-Saturation-Intensity (HSI) color space and then embeds secret data
inside the Intensity Plane (I-Plane) and transforms it back to RGB color model
after embedding. The said technique is evaluated by both subjective and
Objective Analysis. Experimentally it is found that the proposed method have
larger Peak Signal-to Noise Ratio (PSNR) values, good imperceptibility and
multiple security levels which shows its superiority as compared to several
existing methods
</summary>
    <author>
      <name>Khan Muhammad</name>
    </author>
    <author>
      <name>Jamil Ahmad</name>
    </author>
    <author>
      <name>Haleem Farman</name>
    </author>
    <author>
      <name>Muhammad Zubair</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5829/idosi.mejsr.2014.22.05.21946</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5829/idosi.mejsr.2014.22.05.21946" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">An easy to follow paper of 11 pages. arXiv admin note: text overlap
  with arXiv:1502.07808</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Middle-East Journal of Scientific Research 22.5 (2014): 647-654</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1503.00388v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.00388v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.00843v1</id>
    <updated>2015-03-03T07:17:46Z</updated>
    <published>2015-03-03T07:17:46Z</published>
    <title>A Survey On Video Forgery Detection</title>
    <summary>  The Digital Forgeries though not visibly identifiable to human perception it
may alter or meddle with underlying natural statistics of digital content.
Tampering involves fiddling with video content in order to cause damage or make
unauthorized alteration/modification. Tampering detection in video is
cumbersome compared to image when considering the properties of the video.
Tampering impacts need to be studied and the applied technique/method is used
to establish the factual information for legal course in judiciary. In this
paper we give an overview of the prior literature and challenges involved in
video forgery detection where passive approach is found.
</summary>
    <author>
      <name>Sowmya K. N.</name>
    </author>
    <author>
      <name>H. R. Chennamma</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 3 figures, International Journal of Computer Engineering
  and Applications, Volume IX, Issue II, February 2015</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Engineering and Applications,
  Volume IX, Issue II, pp. 17-27, February 2015</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1503.00843v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.00843v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.01620v2</id>
    <updated>2015-07-13T08:12:27Z</updated>
    <published>2015-03-05T12:31:36Z</published>
    <title>Gaussian Mixture Model Based Contrast Enhancement</title>
    <summary>  In this paper, a method for enhancing low contrast images is proposed. This
method, called Gaussian Mixture Model based Contrast Enhancement (GMMCE),
brings into play the Gaussian mixture modeling of histograms to model the
content of the images. Based on the fact that each homogeneous area in natural
images has a Gaussian-shaped histogram, it decomposes the narrow histogram of
low contrast images into a set of scaled and shifted Gaussians. The individual
histograms are then stretched by increasing their variance parameters, and are
diffused on the entire histogram by scattering their mean parameters, to build
a broad version of the histogram. The number of Gaussians as well as their
parameters are optimized to set up a GMM with lowest approximation error and
highest similarity to the original histogram. Compared to the existing
histogram-based methods, the experimental results show that the quality of
GMMCE enhanced pictures are mostly consistent and outperform other benchmark
methods. Additionally, the computational complexity analysis show that GMMCE is
a low complexity method.
</summary>
    <author>
      <name>Mohsen Abdoli</name>
    </author>
    <author>
      <name>Hossein Sarikhani</name>
    </author>
    <author>
      <name>Mohammad Ghanbari</name>
    </author>
    <author>
      <name>Patrice Brault</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1049/iet-ipr.2014.0583</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1049/iet-ipr.2014.0583" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Image Processing, IET, Vol. 9, No. 7, pp. 569-577, 2015</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1503.01620v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.01620v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.01817v2</id>
    <updated>2016-04-25T20:10:14Z</updated>
    <published>2015-03-05T23:43:42Z</published>
    <title>YFCC100M: The New Data in Multimedia Research</title>
    <summary>  We present the Yahoo Flickr Creative Commons 100 Million Dataset (YFCC100M),
the largest public multimedia collection that has ever been released. The
dataset contains a total of 100 million media objects, of which approximately
99.2 million are photos and 0.8 million are videos, all of which carry a
Creative Commons license. Each media object in the dataset is represented by
several pieces of metadata, e.g. Flickr identifier, owner name, camera, title,
tags, geo, media source. The collection provides a comprehensive snapshot of
how photos and videos were taken, described, and shared over the years, from
the inception of Flickr in 2004 until early 2014. In this article we explain
the rationale behind its creation, as well as the implications the dataset has
for science, research, engineering, and development. We further present several
new challenges in multimedia research that can now be expanded upon with our
dataset.
</summary>
    <author>
      <name>Bart Thomee</name>
    </author>
    <author>
      <name>David A. Shamma</name>
    </author>
    <author>
      <name>Gerald Friedland</name>
    </author>
    <author>
      <name>Benjamin Elizalde</name>
    </author>
    <author>
      <name>Karl Ni</name>
    </author>
    <author>
      <name>Douglas Poland</name>
    </author>
    <author>
      <name>Damian Borth</name>
    </author>
    <author>
      <name>Li-Jia Li</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/2812802</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/2812802" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Communications of the ACM, 59(2), pp. 64-73, 2016</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1503.01817v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.01817v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.01934v1</id>
    <updated>2015-03-06T12:42:32Z</updated>
    <published>2015-03-06T12:42:32Z</published>
    <title>Reliable SVD based Semi-blind and Invisible Watermarking Schemes</title>
    <summary>  A semi-blind watermarking scheme is presented based on Singular Value
Decomposition (SVD), which makes essential use of the fact that, the SVD
subspace preserves significant amount of information of an image and is a one
way decomposition. The principal components are used, along with the
corresponding singular vectors of the watermark image to watermark the target
image. For further security, the semi-blind scheme is extended to an invisible
hash based watermarking scheme. The hash based scheme commits a watermark with
a key such that, it is incoherent with the actual watermark, and can only be
extracted using the key. Its security is analyzed in the random oracle model
and shown to be unforgeable, invisible and satisfying the property of
non-repudiation.
</summary>
    <author>
      <name>Subhayan Roy Moulick</name>
    </author>
    <author>
      <name>Siddharth Arora</name>
    </author>
    <author>
      <name>Chirag Jain</name>
    </author>
    <author>
      <name>Prasanta K. Panigrahi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 Pages, 1 Figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1503.01934v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.01934v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.03674v1</id>
    <updated>2015-03-12T11:16:18Z</updated>
    <published>2015-03-12T11:16:18Z</published>
    <title>A novel hash based least significant bit (2-3-3) image steganography in
  spatial domain</title>
    <summary>  This paper presents a novel 2-3-3 LSB insertion method. The image
steganography takes the advantage of human eye limitation. It uses color image
as cover media for embedding secret message.The important quality of a
steganographic system is to be less distortive while increasing the size of the
secret message. In this paper a method is proposed to embed a color secret
image into a color cover image. A 2-3-3 LSB insertion method has been used for
image steganography. Experimental results show an improvement in the Mean
squared error (MSE) and Peak Signal to Noise Ratio (PSNR) values of the
proposed technique over the base technique of hash based 3-3-2 LSB insertion.
</summary>
    <author>
      <name>G. R. Manjula</name>
    </author>
    <author>
      <name>Ajit Danti</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5121/ijsptm.2015.4102</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5121/ijsptm.2015.4102" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages International journal of security privacy and trust
  management Feb 2015 issue</arxiv:comment>
    <link href="http://arxiv.org/abs/1503.03674v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.03674v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.04263v1</id>
    <updated>2015-03-14T03:56:25Z</updated>
    <published>2015-03-14T03:56:25Z</published>
    <title>User Centric Content Management System for Open IPTV Over SNS (ICTC2012)</title>
    <summary>  Coupled schemes between service-oriented architecture (SOA) and Web 2.0 have
recently been researched. Web-based content providers and telecommunications
company (Telecom) based Internet protocol television (IPTV) providers have
struggled against each other to accommodate more three-screen service
subscribers. Since the advent of Web 2.0, more abundant reproduced content can
be circulated. However, because according to increasing device's resolution and
content formats IPTV providers transcode content in advance, network bandwidth,
storage and operation costs for content management systems (CMSs) are wasted.
In this paper, we present a user centric CMS for open IPTV, which integrates
SOA and Web 2.0. Considering content popularity based on a Zipf-like
distribution to solve these problems, we analyze the performance between the
user centric CMS and the conventional Web syndication system for normalized
costs. Based on the user centric CMS, we implement a social Web TV with
device-aware function, which can aggregate, transcode, and deploy content over
social networking service (SNS) independently.
</summary>
    <author>
      <name>Seung Hyun Jeon</name>
    </author>
    <author>
      <name>Sanghong An</name>
    </author>
    <author>
      <name>Changwoo Yoon</name>
    </author>
    <author>
      <name>Hyun-woo Lee</name>
    </author>
    <author>
      <name>Junkyun Choi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 17 figures, An earlier version of this paper was awarded as
  best paper at the IEEE International Conference on ICT Convergence (ICTC),
  Jeju, Korea, October 2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1503.04263v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1503.04263v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.06786v2</id>
    <updated>2015-05-06T19:37:36Z</updated>
    <published>2015-04-26T05:06:33Z</published>
    <title>Deviation Based Pooling Strategies For Full Reference Image Quality
  Assessment</title>
    <summary>  The state-of-the-art pooling strategies for perceptual image quality
assessment (IQA) are based on the mean and the weighted mean. They are robust
pooling strategies which usually provide a moderate to high performance for
different IQAs. Recently, standard deviation (SD) pooling was also proposed.
Although, this deviation pooling provides a very high performance for a few
IQAs, its performance is lower than mean poolings for many other IQAs. In this
paper, we propose to use the mean absolute deviation (MAD) and show that it is
a more robust and accurate pooling strategy for a wider range of IQAs. In fact,
MAD pooling has the advantages of both mean pooling and SD pooling. The joint
computation and use of the MAD and SD pooling strategies is also considered in
this paper. Experimental results provide useful information on the choice of
the proper deviation pooling strategy for different IQA models.
</summary>
    <author>
      <name>Hossein Ziaei Nafchi</name>
    </author>
    <author>
      <name>Rachid Hedjam</name>
    </author>
    <author>
      <name>Atena Shahkolaei</name>
    </author>
    <author>
      <name>Mohamed Cheriet</name>
    </author>
    <link href="http://arxiv.org/abs/1504.06786v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.06786v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.07004v1</id>
    <updated>2015-04-27T09:44:30Z</updated>
    <published>2015-04-27T09:44:30Z</published>
    <title>An Active Learning Based Approach For Effective Video Annotation And
  Retrieval</title>
    <summary>  Conventional multimedia annotation/retrieval systems such as Normalized
Continuous Relevance Model (NormCRM) [16] require a fully labeled training data
for a good performance. Active Learning, by determining an order for labeling
the training data, allows for a good performance even before the training data
is fully annotated. In this work we propose an active learning algorithm, which
combines a novel measure of sample uncertainty with a novel clustering-based
approach for determining sample density and diversity and integrate it with
NormCRM. The clusters are also iteratively refined to ensure both feature and
label-level agreement among samples. We show that our approach outperforms
multiple baselines both on a recent, open character animation dataset and on
the popular TRECVID corpus at both the tasks of annotation and text-based
retrieval of videos.
</summary>
    <author>
      <name>Moitreya Chatterjee</name>
    </author>
    <author>
      <name>Anton Leuski</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 3 figures, Compressed version published at ACM ICMR 2015</arxiv:comment>
    <link href="http://arxiv.org/abs/1504.07004v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.07004v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.3; H.5.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.00765v1</id>
    <updated>2015-06-02T06:31:57Z</updated>
    <published>2015-06-02T06:31:57Z</published>
    <title>Video (GIF) Sentiment Analysis using Large-Scale Mid-Level Ontology</title>
    <summary>  With faster connection speed, Internet users are now making social network a
huge reservoir of texts, images and video clips (GIF). Sentiment analysis for
such online platform can be used to predict political elections, evaluates
economic indicators and so on. However, GIF sentiment analysis is quite
challenging, not only because it hinges on spatio-temporal visual
contentabstraction, but also for the relationship between such abstraction and
final sentiment remains unknown.In this paper, we dedicated to find out such
relationship.We proposed a SentiPairSequence basedspatiotemporal visual
sentiment ontology, which forms the midlevel representations for GIFsentiment.
The establishment process of SentiPair contains two steps. First, we construct
the Synset Forest to define the semantic tree structure of visual sentiment
label elements. Then, through theSynset Forest, we organically select and
combine sentiment label elements to form a mid-level visual sentiment
representation. Our experiments indicate that SentiPair outperforms other
competing mid-level attributes. Using SentiPair, our analysis frameworkcan
achieve satisfying prediction accuracy (72.6%). We also opened ourdataset
(GSO-2015) to the research community. GSO-2015 contains more than 6,000
manually annotated GIFs out of more than 40,000 candidates. Each is labeled
with both sentiment and SentiPair Sequence.
</summary>
    <author>
      <name>Zheng Cai</name>
    </author>
    <author>
      <name>Donglin Cao</name>
    </author>
    <author>
      <name>Rongrong Ji</name>
    </author>
    <link href="http://arxiv.org/abs/1506.00765v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.00765v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.02071v1</id>
    <updated>2015-06-05T21:16:22Z</updated>
    <published>2015-06-05T21:16:22Z</published>
    <title>Using Facebook for Image Steganography</title>
    <summary>  Because Facebook is available on hundreds of millions of desktop and mobile
computing platforms around the world and because it is available on many
different kinds of platforms (from desktops and laptops running Windows, Unix,
or OS X to hand held devices running iOS, Android, or Windows Phone), it would
seem to be the perfect place to conduct steganography. On Facebook, information
hidden in image files will be further obscured within the millions of pictures
and other images posted and transmitted daily. Facebook is known to alter and
compress uploaded images so they use minimum space and bandwidth when displayed
on Facebook pages. The compression process generally disrupts attempts to use
Facebook for image steganography. This paper explores a method to minimize the
disruption so JPEG images can be used as steganography carriers on Facebook.
</summary>
    <author>
      <name>Jason Hiney</name>
    </author>
    <author>
      <name>Tejas Dakve</name>
    </author>
    <author>
      <name>Krzysztof Szczypiorski</name>
    </author>
    <author>
      <name>Kris Gaj</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 4 figures, 2 tables. Accepted to Fourth International
  Workshop on Cyber Crime (IWCC 2015), co-located with 10th International
  Conference on Availability, Reliability and Security (ARES 2015), Toulouse,
  France, 24-28 August 2015</arxiv:comment>
    <link href="http://arxiv.org/abs/1506.02071v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.02071v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.02311v1</id>
    <updated>2015-06-07T20:46:27Z</updated>
    <published>2015-06-07T20:46:27Z</published>
    <title>StegBlocks: ensuring perfect undetectability of network steganography</title>
    <summary>  The paper presents StegBlocks, which defines a new concept for performing
undetectable hidden communication. StegBlocks is a general approach for
constructing methods of network steganography. In StegBlocks, one has to
determine objects with defined properties which will be used to transfer hidden
messages. The objects are dependent on a specific network protocol (or
application) used as a carrier for a given network steganography method.
Moreover, the paper presents the approach to perfect undetectability of network
steganography, which was developed based on the rules of undetectability for
general steganography. The approach to undetectability of network steganography
was used to show the possibility of developing perfectly undetectable network
steganography methods using the StegBlocks concept.
</summary>
    <author>
      <name>Wojciech Fraczek</name>
    </author>
    <author>
      <name>Krzysztof Szczypiorski</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 1 figure, Accepted to Fourth International Workshop on Cyber
  Crime (IWCC 2015), co-located with 10th International Conference on
  Availability, Reliability and Security (ARES 2015), Toulouse, France, 24-28
  August 2015</arxiv:comment>
    <link href="http://arxiv.org/abs/1506.02311v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.02311v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.07823v1</id>
    <updated>2015-06-25T17:24:13Z</updated>
    <published>2015-06-25T17:24:13Z</published>
    <title>Optimal Layered Representation for Adaptive Interactive Multiview Video
  Streaming</title>
    <summary>  We consider an interactive multiview video streaming (IMVS) system where
clients select their preferred viewpoint in a given navigation window. To
provide high quality IMVS, many high quality views should be transmitted to the
clients. However, this is not always possible due to the limited and
heterogeneous capabilities of the clients. In this paper, we propose a novel
adaptive IMVS solution based on a layered multiview representation where camera
views are organized into layered subsets to match the different clients
constraints. We formulate an optimization problem for the joint selection of
the views subsets and their encoding rates. Then, we propose an optimal and a
reduced computational complexity greedy algorithms, both based on
dynamic-programming. Simulation results show the good performance of our novel
algorithms compared to a baseline algorithm, proving that an effective IMVS
adaptive solution should consider the scene content and the client capabilities
and their preferences in navigation.
</summary>
    <author>
      <name>Ana De Abreu</name>
    </author>
    <author>
      <name>Laura Toni</name>
    </author>
    <author>
      <name>Nikolaos Thomos</name>
    </author>
    <author>
      <name>Thomas Maugey</name>
    </author>
    <author>
      <name>Fernando Pereira</name>
    </author>
    <author>
      <name>Pascal Frossard</name>
    </author>
    <link href="http://arxiv.org/abs/1506.07823v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.07823v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.08125v1</id>
    <updated>2015-06-26T15:46:24Z</updated>
    <published>2015-06-26T15:46:24Z</published>
    <title>Data-driven Approaches for Social Video Distribution</title>
    <summary>  The Internet has recently witnessed the convergence of online social network
services and online video services: users import videos from content sharing
sites, and propagate them along the social connections by re-sharing them. Such
social behaviors have dramatically reshaped how videos are disseminated, and
the users are now actively engaged to be part of the social ecosystem, rather
than being passively consumers. Despite the increasingly abundant bandwidth and
computation resources, the ever increasing data volume of user generated video
content and the boundless coverage of socialized sharing have presented
unprecedented challenges. In this paper, we first presents the challenges in
social-aware video delivery. Then, we present a principal framework for
data-driven social video delivery approaches. Moreover, we identify the unique
characteristics of social-aware video access and the social content
propagation, and closely reveal the design of individual modules and their
integration towards enhancing users' experience in the social network context.
</summary>
    <author>
      <name>Zhi Wang</name>
    </author>
    <link href="http://arxiv.org/abs/1506.08125v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.08125v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.08898v3</id>
    <updated>2016-02-19T02:53:43Z</updated>
    <published>2015-06-29T23:47:00Z</published>
    <title>Low-latency compression of mocap data using learned spatial
  decorrelation transform</title>
    <summary>  Due to the growing needs of human motion capture (mocap) in movie, video
games, sports, etc., it is highly desired to compress mocap data for efficient
storage and transmission. This paper presents two efficient frameworks for
compressing human mocap data with low latency. The first framework processes
the data in a frame-by-frame manner so that it is ideal for mocap data
streaming and time critical applications. The second one is clip-based and
provides a flexible tradeoff between latency and compression performance. Since
mocap data exhibits some unique spatial characteristics, we propose a very
effective transform, namely learned orthogonal transform (LOT), for reducing
the spatial redundancy. The LOT problem is formulated as minimizing square
error regularized by orthogonality and sparsity and solved via alternating
iteration. We also adopt a predictive coding and temporal DCT for temporal
decorrelation in the frame- and clip-based frameworks, respectively.
Experimental results show that the proposed frameworks can produce higher
compression performance at lower computational cost and latency than the
state-of-the-art methods.
</summary>
    <author>
      <name>Junhui Hou</name>
    </author>
    <author>
      <name>Lap-Pui Chau</name>
    </author>
    <author>
      <name>Nadia Magnenat-Thalmann</name>
    </author>
    <author>
      <name>Ying He</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 9 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1506.08898v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.08898v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.05150v2</id>
    <updated>2015-11-20T19:56:36Z</updated>
    <published>2015-07-18T05:55:37Z</published>
    <title>Towards Understanding User Preferences from User Tagging Behavior for
  Personalization</title>
    <summary>  Personalizing image tags is a relatively new and growing area of research,
and in order to advance this research community, we must review and challenge
the de-facto standard of defining tag importance. We believe that for greater
progress to be made, we must go beyond tags that merely describe objects that
are visually represented in the image, towards more user-centric and subjective
notions such as emotion, sentiment, and preferences.
  We focus on the notion of user preferences and show that the order that users
list tags on images is correlated to the order of preference over the tags that
they provided for the image. While this observation is not completely
surprising, to our knowledge, we are the first to explore this aspect of user
tagging behavior systematically and report empirical results to support this
observation. We argue that this observation can be exploited to help advance
the image tagging (and related) communities.
  Our contributions include: 1.) conducting a user study demonstrating this
observation, 2.) collecting a dataset with user tag preferences explicitly
collected.
</summary>
    <author>
      <name>Amandianeze O. Nwana</name>
    </author>
    <author>
      <name>Tshuan Chen</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/ISM.2015.79</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/ISM.2015.79" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1507.05150v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.05150v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.05174v1</id>
    <updated>2015-07-18T11:45:44Z</updated>
    <published>2015-07-18T11:45:44Z</published>
    <title>Joint Data Scheduling and FEC Coding for Multihomed Wireless Video
  Delivery</title>
    <summary>  This paper studies the problem of mobile video delivery in heterogenous
wireless networks from a server to multihomed device. Most existing works only
consider delivering video streaming on single path which bandwidth is limited
causing ultimate video transmission rate. To solve this live video streaming
transmission bottleneck problem, we propose a novel solution named Joint Data
Allocation and Fountain Coding (JDAFC) method that contain below characters:
(1) path selection, (2) dynamic data allocation, and (3) fountain coding. We
evaluate the performance of JDAFC by simulation experiments using Exata and
JVSM and compare it with some reference solutions. Experimental results
represent that JDAFC outperforms the competing solutions in improving the video
peak signal-to-noise ratio as well as reducing the end-to-end delay.
</summary>
    <author>
      <name>Jasmin Fantel</name>
    </author>
    <author>
      <name>Yan Gao</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1507.05174v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.05174v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.05242v1</id>
    <updated>2015-07-19T03:05:26Z</updated>
    <published>2015-07-19T03:05:26Z</published>
    <title>Data Hiding in Video using Triangularization LSB Technique</title>
    <summary>  The importance of data hiding in the field of Information Technology is a
widely accepted. The challenge is to be able to pass information in a manner
that the very existence of the message is unknown in order to repel attention
of the potential attacker. Steganography is a technique that has been widely
used to achieve this objective. However Steganography is often found to be
lacking when it comes to hiding bulk data. Attempting to hide data in a video
overcomes this problem because of the large sized cover object (video) as
compared to an image in the case of steganography. This paper attempts to
propose a scheme using which data can be hidden in a video. We focus on the
Triangularization method and make use of the Least Significant Bit (LSB)
technique in hiding messages in a video.
</summary>
    <author>
      <name>Subhashri Acharya</name>
    </author>
    <author>
      <name>Pramita Srimany</name>
    </author>
    <author>
      <name>Sanchari Kundu</name>
    </author>
    <author>
      <name>JayatiGhosh Dastidar</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Advanced Trends in Computer Science and
  Engineering, Volume 4, No.3, May - June 2015</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1507.05242v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.05242v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.08075v1</id>
    <updated>2015-07-29T09:25:44Z</updated>
    <published>2015-07-29T09:25:44Z</published>
    <title>Low Bit-Rate and High Fidelity Reversible Data Hiding</title>
    <summary>  An accurate predictor is crucial for histogram-shifting (HS) based reversible
data hiding methods. The embedding capacity is increased and the embedding
distortion is decreased simultaneously if the predictor can generate accurate
predictions. In this paper, we propose an accurate linear predictor based on
weighted least squares (WLS) estimation. The robustness of WLS helps the
proposed predictor generate accurate predictions, especially in complex texture
areas of an image, where other predictors usually fail. To further reduce the
embedding distortion, we propose a new embedding method called dynamic
histogram shifting with pixel selection (DHS-PS) that selects not only the
proper histogram bins but also the proper pixel locations to embed the given
data. As a result, the proposed method can obtain very high fidelity marked
images with low bit-rate data embedded. The experimental results show that the
proposed method outperforms the state-of-the-art low bit-rate reversible data
hiding method.
</summary>
    <author>
      <name>Xiaochao Qu</name>
    </author>
    <author>
      <name>Suah Kim</name>
    </author>
    <author>
      <name>Run Cui</name>
    </author>
    <author>
      <name>Hyoung Joong Kim</name>
    </author>
    <link href="http://arxiv.org/abs/1507.08075v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.08075v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1507.08861v1</id>
    <updated>2015-07-31T13:02:23Z</updated>
    <published>2015-07-31T13:02:23Z</published>
    <title>Mobile Multi-View Object Image Search</title>
    <summary>  High user interaction capability of mobile devices can help improve the
accuracy of mobile visual search systems. At query time, it is possible to
capture multiple views of an object from different viewing angles and at
different scales with the mobile device camera to obtain richer information
about the object compared to a single view and hence return more accurate
results. Motivated by this, we developed a mobile multi-view object image
search system, using a client-server architecture. Multi-view images of objects
acquired by the mobile clients are processed and local features are sent to the
server, which combines the query image representations with early/late fusion
methods based on bag-of-visual-words and sends back the query results. We
performed a comprehensive analysis of early and late fusion approaches using
various similarity functions, on an existing single view and a new multi-view
object image database. The experimental results show that multi-view search
provides significantly better retrieval accuracy compared to single view
search.
</summary>
    <author>
      <name>Fatih Çalışır</name>
    </author>
    <author>
      <name>Özgür Ulusoy</name>
    </author>
    <author>
      <name>Uğur Güdükbay</name>
    </author>
    <author>
      <name>Muhammet Baştan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 20 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1507.08861v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1507.08861v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.01055v1</id>
    <updated>2015-08-05T12:46:26Z</updated>
    <published>2015-08-05T12:46:26Z</published>
    <title>Estimating snow cover from publicly available images</title>
    <summary>  In this paper we study the problem of estimating snow cover in mountainous
regions, that is, the spatial extent of the earth surface covered by snow. We
argue that publicly available visual content, in the form of user generated
photographs and image feeds from outdoor webcams, can both be leveraged as
additional measurement sources, complementing existing ground, satellite and
airborne sensor data. To this end, we describe two content acquisition and
processing pipelines that are tailored to such sources, addressing the specific
challenges posed by each of them, e.g., identifying the mountain peaks,
filtering out images taken in bad weather conditions, handling varying
illumination conditions. The final outcome is summarized in a snow cover index,
which indicates for a specific mountain and day of the year, the fraction of
visible area covered by snow, possibly at different elevations. We created a
manually labelled dataset to assess the accuracy of the image snow covered area
estimation, achieving 90.0% precision at 91.1% recall. In addition, we show
that seasonal trends related to air temperature are captured by the snow cover
index.
</summary>
    <author>
      <name>Roman Fedorov</name>
    </author>
    <author>
      <name>Alessandro Camerada</name>
    </author>
    <author>
      <name>Piero Fraternali</name>
    </author>
    <author>
      <name>Marco Tagliasacchi</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TMM.2016.2535356</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TMM.2016.2535356" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">submitted to IEEE Transactions on Multimedia</arxiv:comment>
    <link href="http://arxiv.org/abs/1508.01055v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.01055v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.02284v1</id>
    <updated>2015-08-10T15:28:39Z</updated>
    <published>2015-08-10T15:28:39Z</published>
    <title>Approaching Maximum Embedding Efficiency on Small Covers Using
  Staircase-Generator Codes</title>
    <summary>  We introduce a new family of binary linear codes suitable for steganographic
matrix embedding. The main characteristic of the codes is the staircase random
block structure of the generator matrix. We propose an efficient list decoding
algorithm for the codes that finds a close codeword to a given random word. We
provide both theoretical analysis of the performance and stability of the
decoding algorithm, as well as practical results. Used for matrix embedding,
these codes achieve almost the upper theoretical bound of the embedding
efficiency for covers in the range of 1000 - 1500 bits, which is at least an
order of magnitude smaller than the values reported in related works.
</summary>
    <author>
      <name>Simona Samardjiska</name>
    </author>
    <author>
      <name>Danilo Gligoroski</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Extended version of the paper presented at ISIT 2015</arxiv:comment>
    <link href="http://arxiv.org/abs/1508.02284v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.02284v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="94B05" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.04978v2</id>
    <updated>2015-09-09T22:22:09Z</updated>
    <published>2015-08-20T13:35:43Z</published>
    <title>"The Good, The Bad And The Ugly": Evaluation of Wi-Fi Steganography</title>
    <summary>  In this paper we propose a new method for the evaluation of network
steganography algorithms based on the new concept of "the moving observer". We
considered three levels of undetectability named: "good", "bad", and "ugly". To
illustrate this method we chose Wi-Fi steganography as a solid family of
information hiding protocols. We present the state of the art in this area
covering well-known hiding techniques for 802.11 networks. "The moving
observer" approach could help not only in the evaluation of steganographic
algorithms, but also might be a starting point for a new detection system of
network steganography. The concept of a new detection system, called MoveSteg,
is explained in detail.
</summary>
    <author>
      <name>Krzysztof Szczypiorski</name>
    </author>
    <author>
      <name>Artur Janicki</name>
    </author>
    <author>
      <name>Steffen Wendzel</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 6 figures, to appear in Proc. of: ICNIT 2015 - 6th
  International Conference on Networking and Information Technology, Tokyo,
  Japan, November 5-6, 2015</arxiv:comment>
    <link href="http://arxiv.org/abs/1508.04978v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.04978v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.05056v2</id>
    <updated>2015-08-24T09:43:18Z</updated>
    <published>2015-08-20T17:36:48Z</published>
    <title>Diving Deep into Sentiment: Understanding Fine-tuned CNNs for Visual
  Sentiment Prediction</title>
    <summary>  Visual media are powerful means of expressing emotions and sentiments. The
constant generation of new content in social networks highlights the need of
automated visual sentiment analysis tools. While Convolutional Neural Networks
(CNNs) have established a new state-of-the-art in several vision problems,
their application to the task of sentiment analysis is mostly unexplored and
there are few studies regarding how to design CNNs for this purpose. In this
work, we study the suitability of fine-tuning a CNN for visual sentiment
prediction as well as explore performance boosting techniques within this deep
learning setting. Finally, we provide a deep-dive analysis into a benchmark,
state-of-the-art network architecture to gain insight about how to design
patterns for CNNs on the task of visual sentiment prediction.
</summary>
    <author>
      <name>Victor Campos</name>
    </author>
    <author>
      <name>Amaia Salvador</name>
    </author>
    <author>
      <name>Brendan Jou</name>
    </author>
    <author>
      <name>Xavier Giró-i-Nieto</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/2813524.2813530</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/2813524.2813530" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Preprint of the paper accepted at the 1st Workshop on Affect and
  Sentiment in Multimedia (ASM), in ACM MultiMedia 2015. Brisbane, Australia</arxiv:comment>
    <link href="http://arxiv.org/abs/1508.05056v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.05056v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.10; H.1.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.05373v1</id>
    <updated>2015-08-21T19:06:53Z</updated>
    <published>2015-08-21T19:06:53Z</published>
    <title>Dot-Diffused Halftoning with Improved Homogeneity</title>
    <summary>  Compared to the error diffusion, dot diffusion provides an additional
pixel-level parallelism for digital halftoning. However, even though its
periodic and blocking artifacts had been eased by previous works, it was still
far from satisfactory in terms of the blue noise spectrum perspective. In this
work, we strengthen the relationship among the pixel locations of the same
processing order by an iterative halftoning method, and the results demonstrate
a significant improvement. Moreover, a new approach of deriving the averaged
power spectrum density (APSD) is proposed to avoid the regular sampling of the
well-known Bartlett's procedure which inaccurately presents the halftone
periodicity of certain halftoning techniques with parallelism. As a result, the
proposed dot diffusion is substantially superior to the state-of-the-art
parallel halftoning methods in terms of visual quality and artifact-free
property, and competitive runtime to the theoretical fastest ordered dithering
is offered simultaneously.
</summary>
    <author>
      <name>Yun-Fu Liu</name>
    </author>
    <author>
      <name>Jing-Ming Guo</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TIP.2015.2470599</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TIP.2015.2470599" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to IEEE Trans. on Image Processing</arxiv:comment>
    <link href="http://arxiv.org/abs/1508.05373v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.05373v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.06106v2</id>
    <updated>2016-04-06T18:50:38Z</updated>
    <published>2015-08-25T11:17:54Z</published>
    <title>Reversible Denoising and Lifting Based Color Component Transformation
  for Lossless Image Compression</title>
    <summary>  An undesirable side effect of reversible color space transformation, which
consists of lifting steps, is that while removing correlation it contaminates
transformed components with noise from other components. To remove correlation
without increasing noise, we integrate denoising into the lifting steps and
obtain a reversible image component transformation. For JPEG-LS, JPEG 2000, and
JPEG XR algorithms in lossless mode, we find that the proposed method applied
to the RDgDb color space transformation with a simple denoising filter is
especially effective for images in the native optical resolutions of
acquisition devices, but may lead to increased bitrates for typical images. We
also present an efficient estimator of image component transformation effects.
</summary>
    <author>
      <name>Roman Starosolski</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Reversible color space transformation; Denoising; Lifting technique;
  Lossless image compression</arxiv:comment>
    <link href="http://arxiv.org/abs/1508.06106v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.06106v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="94A08 (Primary) 68P30, 94A15 (Secondary)" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.07640v1</id>
    <updated>2015-08-30T21:47:00Z</updated>
    <published>2015-08-30T21:47:00Z</published>
    <title>Compressive Video Sensing via Dictionary Learning and Forward Prediction</title>
    <summary>  In this paper, we propose a new framework for compressive video sensing (CVS)
that exploits the inherent spatial and temporal redundancies of a video
sequence, effectively. The proposed method splits the video sequence into the
key and non-key frames followed by dividing each frame into small
non-overlapping blocks of equal sizes. At the decoder side, the key frames are
reconstructed using adaptively learned sparsifying (ALS) basis via $\ell_0$
minimization, in order to exploit the spatial redundancy. Also, the
effectiveness of three well-known dictionary learning algorithms is
investigated in our method. For recovery of the non-key frames, a prediction of
the current frame is initialized, by using the previous reconstructed frame, in
order to exploit the temporal redundancy. The prediction is employed in a
proper optimization problem to recover the current non-key frame. To compare
our experimental results with the results of some other methods, we employ peak
signal to noise ratio (PSNR) and structural similarity (SSIM) index as the
quality assessor. The numerical results show the adequacy of our proposed
method in CVS.
</summary>
    <author>
      <name>Nasser Eslahi</name>
    </author>
    <author>
      <name>Ali Aghagolzadeh</name>
    </author>
    <author>
      <name>Seyed Mehdi Hosseini Andargoli</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">26 Pages, 5 Figures, 3 Tables, This paper was presented in part at
  the 7th International Symposium on Telecommunications. arXiv admin note: text
  overlap with arXiv:1404.7566 by other authors</arxiv:comment>
    <link href="http://arxiv.org/abs/1508.07640v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.07640v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1509.02630v1</id>
    <updated>2015-09-09T04:00:59Z</updated>
    <published>2015-09-09T04:00:59Z</published>
    <title>Audio Steganography: LSB Technique Using a Pyramid Structure and Range
  of Bytes</title>
    <summary>  The demand for keeping the information secure and confidential simultaneously
has been progressively increasing. Among various techniques- Audio
Steganography, a technique of embedding information transparently in a digital
media thereby restricting the access to such information has been prominently
developed. Imperceptibility, robustness, and payload or hiding capacity are the
main character for it. In earlier, LSB techniques increased payload capacity
would hamper robustness as well as imperceptibility of the cover media and vice
versa. The proposed technique overcomes the problem. It provides relatively
good improvement in the payload capacity by dividing the bytes of cover media
into ranges to hide the bits of secret message appropriately. As well as due to
the use of ranges of bytes the robustness of cover media has maintained and
imperceptibility preserved by using a pyramid structure.
</summary>
    <author>
      <name>Satish Bhalshankar</name>
    </author>
    <author>
      <name>Avinash K. Gulve</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 page, 16 Figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Advanced Computer Research (IJACR),
  Volume-5, Issue-20, September-2015 ,pp.233-248</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1509.02630v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1509.02630v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1509.05671v1</id>
    <updated>2015-09-18T15:45:41Z</updated>
    <published>2015-09-18T15:45:41Z</published>
    <title>User-Curated Image Collections: Modeling and Recommendation</title>
    <summary>  Most state-of-the-art image retrieval and recommendation systems
predominantly focus on individual images. In contrast, socially curated image
collections, condensing distinctive yet coherent images into one set, are
largely overlooked by the research communities. In this paper, we aim to design
a novel recommendation system that can provide users with image collections
relevant to individual personal preferences and interests. To this end, two key
issues need to be addressed, i.e., image collection modeling and similarity
measurement. For image collection modeling, we consider each image collection
as a whole in a group sparse reconstruction framework and extract concise
collection descriptors given the pretrained dictionaries. We then consider
image collection recommendation as a dynamic similarity measurement problem in
response to user's clicked image set, and employ a metric learner to measure
the similarity between the image collection and the clicked image set. As there
is no previous work directly comparable to this study, we implement several
competitive baselines and related methods for comparison. The evaluations on a
large scale Pinterest data set have validated the effectiveness of our proposed
methods for modeling and recommending image collections.
</summary>
    <author>
      <name>Yuncheng Li</name>
    </author>
    <author>
      <name>Yang Cong</name>
    </author>
    <author>
      <name>Tao Mei</name>
    </author>
    <author>
      <name>Jiebo Luo</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/BigData.2015.7363803</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/BigData.2015.7363803" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">in IEEE BigData 2015</arxiv:comment>
    <link href="http://arxiv.org/abs/1509.05671v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1509.05671v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1509.06792v1</id>
    <updated>2015-09-22T21:44:28Z</updated>
    <published>2015-09-22T21:44:28Z</published>
    <title>A Resource Allocation Mechanism for Video Mixing as a Cloud Computing
  Service in Multimedia Conferencing Applications</title>
    <summary>  Multimedia conferencing is the conversational exchange of multimedia content
between multiple parties. It has a wide range of applications (e.g. Massively
Multiplayer Online Games (MMOGs) and distance learning). Many multimedia
conferencing applications use video extensively, thus video mixing in
conferencing settings is of critical importance. Cloud computing is a
technology that can solve the scalability issue in multimedia conferencing,
while bringing other benefits, such as, elasticity, efficient use of resources,
rapid development, and introduction of new applications. However, proposed
cloud-based multimedia conferencing approaches so far have several deficiencies
when it comes to efficient resource usage while meeting Quality of Service
(QoS) requirements. We propose a solution to optimize resource allocation for
cloud-based video mixing service in multimedia conferencing applications, which
can support scalability in terms of number of users, while guaranteeing QoS. We
formulate the resource allocation problem mathematically as an Integer Linear
Programming (ILP) problem and design a heuristic for it. Simulation results
show that our resource allocation model can support more participants compared
to the state-of-the-art, while honoring QoS, with respect to end-to-end delay.
</summary>
    <author>
      <name>Abbas Soltanian</name>
    </author>
    <author>
      <name>Mohammad A. Salahuddin</name>
    </author>
    <author>
      <name>Halima Elbiaze</name>
    </author>
    <author>
      <name>Roch Glitho</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, CNSM 2015</arxiv:comment>
    <link href="http://arxiv.org/abs/1509.06792v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1509.06792v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.00561v1</id>
    <updated>2015-10-02T11:08:45Z</updated>
    <published>2015-10-02T11:08:45Z</published>
    <title>CVC: The Contourlet Video Compression algorithm for real-time
  applications</title>
    <summary>  Nowadays, real-time video communication over the internet through video
conferencing applications has become an invaluable tool in everyone's
professional and personal life. This trend underlines the need for video coding
algorithms that provide acceptable quality on low bitrates and can support
various resolutions inside the same stream in order to cope with limitations on
computational resources and network bandwidth. In this work, a novel scalable
video coding algorithm based on the contourlet transform is presented. The
algorithm utilizes both lossy and lossless methods in order to achieve
compression. One of its most notable features is that due to the transform
utilised, it does not suffer from blocking artifacts that occur with many
widely adopted compression algorithms. The proposed algorithm takes advantage
of the vast computational capabilities of modern GPUs, in order to achieve
real-time performance and provide satisfactory encoding and decoding times at
relatively low cost, making it suitable for applications like video
conferencing. Experiments show that the proposed algorithm performs
satisfactorily in terms of compression ratio and speed, while it outperforms
standard methods in terms of perceptual quality on lower bitrates.
</summary>
    <author>
      <name>Stamos Katsigiannis</name>
    </author>
    <author>
      <name>Georgios Papaioannou</name>
    </author>
    <author>
      <name>Dimitris Maroulis</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">22 pages, 13 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1510.00561v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.00561v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.01134v2</id>
    <updated>2016-08-22T13:36:58Z</updated>
    <published>2015-10-05T13:04:55Z</published>
    <title>A System for Precise End-to-End Delay Measurements in Video
  Communication</title>
    <summary>  Low delay video transmission is becoming increasingly important. Delay
critical, video enabled applications range from teleoperation scenarios such as
controlling drones or telesurgery to autonomous control through computer vision
algorithms applied on real-time video. To judge the quality of the video
transmission in such a system, it is important to be able to precisely measure
the end-to-end (E2E) delay of the transmitted video. We present a
low-complexity system that automatically takes pairwise independent
measurements of E2E delay. The precision can be far below the millisecond
order, mainly limited by the sampling rate of the measurement system. In our
implementation, we achieve a precision of 0.5 milliseconds with a sampling rate
of 2kHz.
</summary>
    <author>
      <name>Christoph Bachhuber</name>
    </author>
    <author>
      <name>Eckehard Steinbach</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/ICIP.2016.7532735</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/ICIP.2016.7532735" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 4 figures, IEEE International Conference on Image Processing
  (ICIP 2016), Phoenix, AZ, USA, 2016</arxiv:comment>
    <link href="http://arxiv.org/abs/1510.01134v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.01134v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.05405v1</id>
    <updated>2015-10-19T09:40:17Z</updated>
    <published>2015-10-19T09:40:17Z</published>
    <title>The Virtual Splitter: Refactoring Web Applications for the Multiscreen
  Environment</title>
    <summary>  Creating web applications for the multiscreen environment is still a
challenge. One approach is to transform existing single-screen applications but
this has not been done yet automatically or generically. This paper proposes a
refactor-ing system. It consists of a generic and extensible mapping phase that
automatically analyzes the application content based on a semantic or a visual
criterion determined by the author or the user, and prepares it for the
splitting process. The system then splits the application and as a result
delivers two instrumented applications ready for distribution across devices.
During runtime, the system uses a mirroring phase to maintain the functionality
of the distributed application and to support a dynamic splitting process.
Developed as a Chrome extension, our approach is validated on several web
applications, including a YouTube page and a video application from Mozilla.
</summary>
    <author>
      <name>Mira Sarkis</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LTCI</arxiv:affiliation>
    </author>
    <author>
      <name>Cyril Concolato</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LTCI</arxiv:affiliation>
    </author>
    <author>
      <name>Jean-Claude Dufourd</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LTCI</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/2644866.2644893</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/2644866.2644893" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">DocEng'14: ACM Symposium on Document Engineering, ACM, 2014,
  pp.Pages139-142 \&amp;lt;10.1145/2644866.2644893\&amp;gt;</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1510.05405v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.05405v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.02656v1</id>
    <updated>2015-11-09T12:20:11Z</updated>
    <published>2015-11-09T12:20:11Z</published>
    <title>A Novel Adaptation Method for HTTP Streaming of VBR Videos over Mobile
  Networks</title>
    <summary>  Recently, HTTP streaming has become very popular for delivering video over
the Internet. For adaptivity, a provider should generate multiple versions of a
video as well as the related metadata. Various adaptation methods have been
proposed to support a streaming client in coping with strong bandwidth
variations. However, most of existing methods target at constant bitrate (CBR)
videos only. In this paper, we present a new method for quality adaptation in
on-demand streaming of variable bitrate (VBR) videos. To cope with strong
variations of VBR bitrate, we use a local average bitrate as the representative
bitrate of a version. A buffer-based algorithm is then proposed to
conservatively adapt video quality. Through experiments, we show that our
method can provide quality stability as well as buffer stability even under
very strong variations of bandwidth and video bitrates.
</summary>
    <author>
      <name>Hung. T Le</name>
    </author>
    <author>
      <name>Hai N. Nguyen</name>
    </author>
    <author>
      <name>Nam Pham Ngoc</name>
    </author>
    <author>
      <name>Anh T. Pham</name>
    </author>
    <author>
      <name>Truong Cong Thang</name>
    </author>
    <link href="http://arxiv.org/abs/1511.02656v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.02656v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.03351v1</id>
    <updated>2015-11-11T01:32:47Z</updated>
    <published>2015-11-11T01:32:47Z</published>
    <title>Attribute-Based Multi-Dimensional Scalable Access Control For Social
  Media Sharing</title>
    <summary>  Media sharing is an extremely popular paradigm of social interaction in
online social networks (OSNs) nowadays. The scalable media access control is
essential to perform information sharing among users with various access
privileges. In this paper, we present a multi-dimensional scalable media access
control (MD-SMAC) system based on the proposed scalable ciphertext policy
attribute-based encryption (SCP-ABE) algorithm. In the proposed MD-SMAC system,
fine-grained access control can be performed on the media contents encoded in a
multi-dimensional scalable manner based on data consumers' diverse attributes.
Through security analysis, we show that the proposed MC-SMAC system is able to
resist collusion attacks. Additionally, we conduct experiments to evaluate the
efficiency performance of the proposed system, especially on mobile devices.
</summary>
    <author>
      <name>Changsha Ma</name>
    </author>
    <author>
      <name>Chang Wen Chen</name>
    </author>
    <link href="http://arxiv.org/abs/1511.03351v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.03351v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.04691v1</id>
    <updated>2015-11-15T12:27:43Z</updated>
    <published>2015-11-15T12:27:43Z</published>
    <title>Optimization of the Block-level Bit Allocation in Perceptual Video
  Coding based on MINMAX</title>
    <summary>  In video coding, it is expected that the encoder could adaptively select the
encoding parameters (e.g., quantization parameter) to optimize the bit
allocation to different sources under the given constraint. However, in hybrid
video coding, the dependency between sources brings high complexity for the bit
allocation optimization, especially in the block-level, and existing
optimization methods mostly focus on frame-level bit allocation. In this paper,
we propose a macroblock (MB) level bit allocation method based on the minimum
maximum (MINMAX) criterion, which has acceptable encoding complexity for
offline applications. An iterative-based algorithm, namely maximum distortion
descend (MDD), is developed to reduce quality fluctuation among MBs within a
frame, where the Structure SIMilarity (SSIM) index is used to measure the
perceptual distortion of MBs. Our extensive experimental results on benchmark
video sequences show that the proposed method can greatly enhance the encoding
performance in terms of both bits saving and perceptual quality improvement.
</summary>
    <author>
      <name>Chao Wang</name>
    </author>
    <author>
      <name>Xuanqin Mou</name>
    </author>
    <author>
      <name>Lei Zhang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 17 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1511.04691v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.04691v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.4.2; E.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.08507v1</id>
    <updated>2015-11-26T21:07:05Z</updated>
    <published>2015-11-26T21:07:05Z</published>
    <title>Creativity in Mind: Evaluating and Maintaining Advances in Network
  Steganographic Research</title>
    <summary>  The research discipline of network steganography deals with the hiding of
information within network transmissions, e.g. to transfer illicit information
in networks with Internet censorship. The last decades of research on network
steganography led to more than hundred techniques for hiding data in network
transmissions. However, previous research has shown that most of these hiding
techniques are either based on the same idea or introduce limited novelty,
enabling the application of existing countermeasures. In this paper, we provide
a link between the field of creativity and network steganographic research. We
propose a framework and a metric to help evaluating the creativity bound to a
given hiding technique. This way, we support two sides of the scientific peer
review process as both authors and reviewers can use our framework to analyze
the novelty and applicability of hiding techniques. At the same time, we
contribute to a uniform terminology in network steganography.
</summary>
    <author>
      <name>Steffen Wendzel</name>
    </author>
    <author>
      <name>Carolin Palmer</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.3217/jucs-021-12-1684</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.3217/jucs-021-12-1684" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">to appear in Journal of Universal Computer Science (J.UCS)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Universal Computer Science, Vol. 21(12), 2015</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1511.08507v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.08507v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.2.11; D.4.6; K.6.5; K.7.m" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1512.05705v3</id>
    <updated>2016-01-21T22:59:36Z</updated>
    <published>2015-12-17T18:16:25Z</published>
    <title>NEWCAST: Anticipating Resource Management and QoE Provisioning for
  Mobile Video Streaming</title>
    <summary>  The knowledge of future throughput variation in wireless networks using
smartphone becomes more and more possible by exploiting the rich contextual
information from smartphone sensors through mobile applications and services.
Contextual information may include the traffic, mobility and radio conditions.
Inspired by the attractive features and potential advantages of this agile
resource management, several approaches have been proposed during the last
period. However, agile resource management also comes with its own challenges,
and there are significant technical issues that still need to be addressed for
successful rollout and operation of this technique. In this paper, we propose
an approach for anticipating throughput variation for mobile video streaming
services. The solution of the optimization problem realizes a fundamental
trade-offs among critical metrics that impact the user's perceptual quality of
the experience (QoE) and system utilization. Both simulated and real-world
traces are carried out to evaluate the performance of the proposed approach. It
is shown that our approach provides the accuracy, efficiency and robustness
that the new 5G architectures require.
</summary>
    <author>
      <name>Imen Triki</name>
    </author>
    <author>
      <name>Rachid El-Azouzi</name>
    </author>
    <author>
      <name>Majed Haddad</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 16 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1512.05705v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1512.05705v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1512.08854v1</id>
    <updated>2015-12-30T05:41:21Z</updated>
    <published>2015-12-30T05:41:21Z</published>
    <title>An Overview of Emerging Technologies for High Efficiency 3D Video Coding</title>
    <summary>  3D video coding is one of the most popular research area in multimedia. This
paper reviews the recent progress of the coding technologies for multiview
video (MVV) and free view-point video (FVV) which is represented by MVV and
depth maps. We first discuss the traditional multiview video coding (MVC)
framework with different prediction structures. The rate-distortion performance
and the view switching delay of the three main coding prediction structures are
analyzed. We further introduce the joint coding technologies for MVV and depth
maps and evaluate the rate-distortion performance of them. The scalable 3D
video coding technologies are reviewed by the quality and view scalability,
respectively. Finally, we summarize the bit allocation work of 3D video coding.
This paper also points out some future research problems in high efficiency 3D
video coding such as the view switching latency optimization in coding
structure and bit allocation.
</summary>
    <author>
      <name>Qifei Wang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1512.08854v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1512.08854v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.01408v1</id>
    <updated>2016-01-07T06:15:16Z</updated>
    <published>2016-01-07T06:15:16Z</published>
    <title>Comparison of cinepak, intel, microsoft video and indeo codec for video
  compression</title>
    <summary>  The file size and picture quality are factors to be considered for streaming,
storage and transmitting videos over networks. This work compares Cinepak,
Intel, Microsoft Video and Indeo Codec for video compression. The peak signal
to noise ratio is used to compare the quality of such video compressed using
AVI codecs. The most widely used objective measurement by developers of video
processing systems is Peak Signal-to-Noise Ratio (PSNR). Peak Signal to Noise
Ration is measured on a logarithmic scale and depends on the mean squared error
(MSE) between an original and an impaired image or video, relative to (2n-1)2.
  Previous research done regarding assessing of video quality has been mainly
by the use of subjective methods, and there is still no standard method for
objective assessments. Although it has been considered that compression might
not be significant in future as storage and transmission capabilities improve,
but at low bandwidths compression makes communication possible.
</summary>
    <author>
      <name>Suleiman Mustafa</name>
    </author>
    <author>
      <name>Hannan Xiao</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 1 figure, 7 tables, journal paper</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">The International Journal of Multimedia and Its Applications
  (IJMA), Volume 7, Number 6 December 2015</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1601.01408v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.01408v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.02076v1</id>
    <updated>2016-01-09T04:48:08Z</updated>
    <published>2016-01-09T04:48:08Z</published>
    <title>An Enhanced Edge Adaptive Steganography Approach Using Threshold Value
  for Region Selection</title>
    <summary>  This paper attempts to improve the quality and the modification rate of a
Stego Image. The input image provided for estimating the quality of an image
and the modified rate is a bitmap image. The threshold value is used as a
parameter for selecting the high frequency pixels from the Cover Image. The
data embedding process are performed on the pixels that are found with the help
of Threshold value by using LSBMR. The quality of an image is estimated by the
value of PSNR and the modification rate of an image is estimated by the value
of MSE. The proposed approach achieves about 0.2 to 0.6 % of improvement in the
quality of an image and about 4 to 10 % of improvement in the modification rate
of an image compared to the edge detection techniques such as Sobel and Canny.
</summary>
    <author>
      <name>Sachin Mungmode</name>
    </author>
    <author>
      <name>R. R. Sedamkar</name>
    </author>
    <author>
      <name>Niranjan Kulkarni</name>
    </author>
    <link href="http://arxiv.org/abs/1601.02076v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.02076v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.04473v1</id>
    <updated>2016-01-18T11:22:29Z</updated>
    <published>2016-01-18T11:22:29Z</published>
    <title>Lossless Intra Coding in HEVC with 3-tap Filters</title>
    <summary>  This paper presents a pixel-by-pixel spatial prediction method for lossless
intra coding within High Efficiency Video Coding (HEVC). A well-known previous
pixel-by-pixel spatial prediction method uses only two neighboring pixels for
prediction, based on the angular projection idea borrowed from block-based
intra prediction in lossy coding. This paper explores a method which uses three
neighboring pixels for prediction according to a two-dimensional correlation
model, and the used neighbor pixels and prediction weights change depending on
intra mode. To find the best prediction weights for each intra mode, a
two-stage offline optimization algorithm is used and a number of implementation
aspects are discussed to simplify the proposed prediction method. The proposed
method is implemented in the HEVC reference software and experimental results
show that the explored 3-tap filtering method can achieve an average 11.34%
bitrate reduction over the default lossless intra coding in HEVC. The proposed
method also decreases average decoding time by 12.7% while it increases average
encoding time by 9.7%
</summary>
    <author>
      <name>Saeed R. Alvar</name>
    </author>
    <author>
      <name>Fatih Kamisli</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1601.04473v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.04473v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.04522v1</id>
    <updated>2016-01-18T14:15:06Z</updated>
    <published>2016-01-18T14:15:06Z</published>
    <title>Multiple Watermarking Algorithm Based on Spread Transform Dither
  Modulation</title>
    <summary>  Multiple watermarking technique, embedding several watermarks in one carrier,
has enabled many interesting applications. In this study, a novel multiple
watermarking algorithm is proposed based on the spirit of spread transform
dither modulation (STDM). It can embed multiple watermarks into the same region
and the same transform domain of one image; meanwhile, the embedded watermarks
can be extracted independently and blindly in the detector without any
interference. Furthermore, to improve the fidelity of the watermarked image,
the properties of the dither modulation quantizer and the proposed multiple
watermarks embedding strategy are investigated, and two practical optimization
methods are proposed. Finally, to enhance the application flexibility, an
extension of the proposed algorithm is proposed which can sequentially embeds
different watermarks into one image during each stage of its circulation.
Compared with the pioneering multiple watermarking algorithms, the proposed one
owns more flexibility in practical application and is more robust against
distortion due to basic operations such as random noise, JPEG compression and
volumetric scaling.
</summary>
    <author>
      <name>Xinchao Li</name>
    </author>
    <author>
      <name>Ju Liu</name>
    </author>
    <author>
      <name>Jiande Sun</name>
    </author>
    <author>
      <name>Xiaohui Yang</name>
    </author>
    <author>
      <name>Wei Liu</name>
    </author>
    <link href="http://arxiv.org/abs/1601.04522v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.04522v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.06603v1</id>
    <updated>2016-01-25T13:57:07Z</updated>
    <published>2016-01-25T13:57:07Z</published>
    <title>Egocentric Activity Recognition with Multimodal Fisher Vector</title>
    <summary>  With the increasing availability of wearable devices, research on egocentric
activity recognition has received much attention recently. In this paper, we
build a Multimodal Egocentric Activity dataset which includes egocentric videos
and sensor data of 20 fine-grained and diverse activity categories. We present
a novel strategy to extract temporal trajectory-like features from sensor data.
We propose to apply the Fisher Kernel framework to fuse video and temporal
enhanced sensor features. Experiment results show that with careful design of
feature extraction and fusion algorithm, sensor data can enhance
information-rich video data. We make publicly available the Multimodal
Egocentric Activity dataset to facilitate future research.
</summary>
    <author>
      <name>Sibo Song</name>
    </author>
    <author>
      <name>Ngai-Man Cheung</name>
    </author>
    <author>
      <name>Vijay Chandrasekhar</name>
    </author>
    <author>
      <name>Bappaditya Mandal</name>
    </author>
    <author>
      <name>Jie Lin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 4 figures, ICASSP 2016 accepted</arxiv:comment>
    <link href="http://arxiv.org/abs/1601.06603v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.06603v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.07262v1</id>
    <updated>2016-01-27T04:58:16Z</updated>
    <published>2016-01-27T04:58:16Z</published>
    <title>Revisiting copy-move forgery detection by considering realistic image
  with similar but genuine objects</title>
    <summary>  Many images, of natural or man-made scenes often contain Similar but Genuine
Objects (SGO). This poses a challenge to existing Copy-Move Forgery Detection
(CMFD) methods which match the key points / blocks, solely based on the pair
similarity in the scene. To address such issue, we propose a novel CMFD method
using Scaled Harris Feature Descriptors (SHFD) that preform consistently well
on forged images with SGO. It involves the following main steps: (i) Pyramid
scale space and orientation assignment are used to keep scaling and rotation
invariance; (ii) Combined features are applied for precise texture description;
(iii) Similar features of two points are matched and RANSAC is used to remove
the false matches. The experimental results indicate that the proposed
algorithm is effective in detecting SGO and copy-move forgery, which compares
favorably to existing methods. Our method exhibits high robustness even when an
image is operated by geometric transformation and post-processing
</summary>
    <author>
      <name>Ye Zhu</name>
    </author>
    <author>
      <name>Tian-Tsong Ng</name>
    </author>
    <author>
      <name>Xuanjing Shen</name>
    </author>
    <author>
      <name>Bihan Wen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The version of ICASSP2016 submission</arxiv:comment>
    <link href="http://arxiv.org/abs/1601.07262v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.07262v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.07884v1</id>
    <updated>2016-01-28T20:13:01Z</updated>
    <published>2016-01-28T20:13:01Z</published>
    <title>Geo-distinctive Visual Element Matching for Location Estimation of
  Images</title>
    <summary>  We propose an image representation and matching approach that substantially
improves visual-based location estimation for images. The main novelty of the
approach, called distinctive visual element matching (DVEM), is its use of
representations that are specific to the query image whose location is being
predicted. These representations are based on visual element clouds, which
robustly capture the connection between the query and visual evidence from
candidate locations. We then maximize the influence of visual elements that are
geo-distinctive because they do not occur in images taken at many other
locations. We carry out experiments and analysis for both geo-constrained and
geo-unconstrained location estimation cases using two large-scale,
publicly-available datasets: the San Francisco Landmark dataset with $1.06$
million street-view images and the MediaEval '15 Placing Task dataset with
$5.6$ million geo-tagged images from Flickr. We present examples that
illustrate the highly-transparent mechanics of the approach, which are based on
common sense observations about the visual patterns in image collections. Our
results show that the proposed method delivers a considerable performance
improvement compared to the state of the art.
</summary>
    <author>
      <name>Xinchao Li</name>
    </author>
    <author>
      <name>Martha A. Larson</name>
    </author>
    <author>
      <name>Alan Hanjalic</name>
    </author>
    <link href="http://arxiv.org/abs/1601.07884v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.07884v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1602.00489v2</id>
    <updated>2016-02-19T15:23:02Z</updated>
    <published>2016-02-01T12:12:17Z</published>
    <title>Real Time Video Quality Representation Classification of Encrypted HTTP
  Adaptive Video Streaming - the Case of Safari</title>
    <summary>  The increasing popularity of HTTP adaptive video streaming services has
dramatically increased bandwidth requirements on operator networks, which
attempt to shape their traffic through Deep Packet Inspection (DPI). However,
Google and certain content providers have started to encrypt their video
services. As a result, operators often encounter difficulties in shaping their
encrypted video traffic via DPI. This highlights the need for new traffic
classification methods for encrypted HTTP adaptive video streaming to enable
smart traffic shaping. These new methods will have to effectively estimate the
quality representation layer and playout buffer. We present a new method and
show for the first time that video quality representation classification for
(YouTube) encrypted HTTP adaptive streaming is possible. We analyze the
performance of this classification method with Safari over HTTPS. Based on a
large number of offline and online traffic classification experiments, we
demonstrate that it can independently classify, in real time, every video
segment into one of the quality representation layers with 97.18% average
accuracy.
</summary>
    <author>
      <name>Ran Dubin</name>
    </author>
    <author>
      <name>Amit Dvir</name>
    </author>
    <author>
      <name>Ofir Pele</name>
    </author>
    <author>
      <name>Ofer Hadar</name>
    </author>
    <author>
      <name>Itay Richman</name>
    </author>
    <author>
      <name>Ofir Trabelsi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1602.00489v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1602.00489v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1602.02030v1</id>
    <updated>2016-02-05T14:17:52Z</updated>
    <published>2016-02-05T14:17:52Z</published>
    <title>Adaptation Logic for HTTP Dynamic Adaptive Streaming using
  Geo-Predictive Crowdsourcing</title>
    <summary>  The increasing demand for video streaming services with high Quality of
Experience (QoE) has prompted a lot of research on client-side adaptation logic
approaches. However, most algorithms use the client's previous download
experience and do not use a crowd knowledge database generated by users of a
professional service. We propose a new crowd algorithm that maximizes the QoE.
Additionally, we show how crowd information can be integrated into existing
algorithms and illustrate this with two state-of-the-art algorithms. We
evaluate our algorithm and state-of-the-art algorithms (including our modified
algorithms) on a large, real-life crowdsourcing dataset that contains 336,551
samples on network performance. The dataset was provided by WeFi LTD. Our new
algorithm outperforms all other methods in terms of QoS (eMOS).
</summary>
    <author>
      <name>Ran Dubin</name>
    </author>
    <author>
      <name>Amit Dvir</name>
    </author>
    <author>
      <name>Ofir Pele</name>
    </author>
    <author>
      <name>Ofer Hadar</name>
    </author>
    <author>
      <name>Itay Katz</name>
    </author>
    <author>
      <name>Ori Mashiach</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s00530-016-0525-6</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s00530-016-0525-6" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1602.02030v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1602.02030v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1602.05209v1</id>
    <updated>2016-02-16T21:27:58Z</updated>
    <published>2016-02-16T21:27:58Z</published>
    <title>Perceptual Vector Quantization For Video Coding</title>
    <summary>  This paper applies energy conservation principles to the Daala video codec
using gain-shape vector quantization to encode a vector of AC coefficients as a
length (gain) and direction (shape). The technique originates from the CELT
mode of the Opus audio codec, where it is used to conserve the spectral
envelope of an audio signal. Conserving energy in video has the potential to
preserve textures rather than low-passing them. Explicitly quantizing a gain
allows a simple contrast masking model with no signaling cost. Vector
quantizing the shape keeps the number of degrees of freedom the same as scalar
quantization, avoiding redundancy in the representation. We demonstrate how to
predict the vector by transforming the space it is encoded in, rather than
subtracting off the predictor, which would make energy conservation impossible.
We also derive an encoding of the vector-quantized codewords that takes
advantage of their non-uniform distribution. We show that the resulting
technique outperforms scalar quantization by an average of 0.90 dB on still
images, equivalent to a 24.8% reduction in bitrate at equal quality, while for
videos, the improvement averages 0.83 dB, equivalent to a 13.7% reduction in
bitrate.
</summary>
    <author>
      <name>Jean-Marc Valin</name>
    </author>
    <author>
      <name>Timothy B. Terriberry</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1117/12.2080529</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1117/12.2080529" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, Proceedings of SPIE Visual Information Processing and
  Communication, 2015</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. SPIE 9410, Visual Information Processing and Communication
  VI, 941009 (March 4, 2015)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1602.05209v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1602.05209v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.02980v3</id>
    <updated>2016-08-01T22:20:23Z</updated>
    <published>2016-03-09T17:59:26Z</published>
    <title>Impact Analysis of Baseband Quantizer on Coding Efficiency for HDR Video</title>
    <summary>  Digitally acquired high dynamic range (HDR) video baseband signal can take 10
to 12 bits per color channel. It is economically important to be able to reuse
the legacy 8 or 10-bit video codecs to efficiently compress the HDR video.
Linear or nonlinear mapping on the intensity can be applied to the baseband
signal to reduce the dynamic range before the signal is sent to the codec, and
we refer to this range reduction step as a baseband quantization. We show
analytically and verify using test sequences that the use of the baseband
quantizer lowers the coding efficiency. Experiments show that as the baseband
quantizer is strengthened by 1.6 bits, the drop of PSNR at a high bitrate is up
to 1.60dB. Our result suggests that in order to achieve high coding efficiency,
information reduction of videos in terms of quantization error should be
introduced in the video codec instead of on the baseband signal.
</summary>
    <author>
      <name>Chau-Wai Wong</name>
    </author>
    <author>
      <name>Guan-Ming Su</name>
    </author>
    <author>
      <name>Min Wu</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/LSP.2016.2597175</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/LSP.2016.2597175" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted for publication in IEEE Signal Processing Letters</arxiv:comment>
    <link href="http://arxiv.org/abs/1603.02980v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.02980v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.03482v1</id>
    <updated>2016-03-10T22:55:36Z</updated>
    <published>2016-03-10T22:55:36Z</published>
    <title>Predicting Chroma from Luma with Frequency Domain Intra Prediction</title>
    <summary>  This paper describes a technique for performing intra prediction of the
chroma planes based on the reconstructed luma plane in the frequency domain.
This prediction exploits the fact that while RGB to YUV color conversion has
the property that it decorrelates the color planes globally across an image,
there is still some correlation locally at the block level. Previous proposals
compute a linear model of the spatial relationship between the luma plane (Y)
and the two chroma planes (U and V). In codecs that use lapped transforms this
is not possible since transform support extends across the block boundaries and
thus neighboring blocks are unavailable during intra-prediction. We design a
frequency domain intra predictor for chroma that exploits the same local
correlation with lower complexity than the spatial predictor and which works
with lapped transforms. We then describe a low-complexity algorithm that
directly uses luma coefficients as a chroma predictor based on gain-shape
quantization and band partitioning. An experiment is performed that compares
these two techniques inside the experimental Daala video codec and shows the
lower complexity algorithm to be a better chroma predictor.
</summary>
    <author>
      <name>Nathan E. Egge</name>
    </author>
    <author>
      <name>Jean-Marc Valin</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1117/12.2080837</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1117/12.2080837" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 7 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of SPIE 9410, Visual Information Processing and
  Communication VI, 941009 (March 4, 2015)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1603.03482v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.03482v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.06083v2</id>
    <updated>2016-03-28T19:30:21Z</updated>
    <published>2016-03-19T11:43:01Z</published>
    <title>Towards Coordinated Bandwidth Adaptations for Hundred-Scale 3D
  Tele-Immersive Systems</title>
    <summary>  3D tele-immersion improves the state of collaboration among geographically
distributed participants. Unlike the traditional 2D videos, a 3D tele-immersive
system employs multiple 3D cameras based in each physical site to cover a much
larger field of view, generating a very large amount of stream data. One of the
major challenges is how to efficiently transmit these bulky 3D streaming data
to bandwidth-constrained sites. In this paper, we study an adaptive Human
Visual System (HVS) -compliant bandwidth management framework for efficient
delivery of hundred-scale streams produced from distributed 3D tele-immersive
sites to a receiver site with limited bandwidth budget. Our adaptation
framework exploits the semantics link of HVS with multiple 3D streams in the 3D
tele-immersive environment. We developed TELEVIS, a visual simulation tool to
showcase a HVS-aware tele-immersive system for realistic cases. Our evaluation
results show that the proposed adaptation can improve the total quality per
unit of bandwidth used to deliver streams in 3D tele-immersive systems.
</summary>
    <author>
      <name>Mohammad Hosseini</name>
    </author>
    <author>
      <name>Gregorij Kurillo</name>
    </author>
    <author>
      <name>Seyed Rasoul Etesami</name>
    </author>
    <author>
      <name>Jiang Yu</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/s00530-016-0511-z</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/s00530-016-0511-z" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Springer Multimedia Systems Journal, 14 pages, March 2016</arxiv:comment>
    <link href="http://arxiv.org/abs/1603.06083v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.06083v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.09012v1</id>
    <updated>2016-03-30T01:16:37Z</updated>
    <published>2016-03-30T01:16:37Z</published>
    <title>A framework for event co-occurrence detection in event streams</title>
    <summary>  This paper shows that characterizing co-occurrence between events is an
important but non-trivial and neglected aspect of discovering potential causal
relationships in multimedia event streams. First an introduction to the notion
of event co-occurrence and its relation to co-occurrence pattern detection is
given. Then a finite state automaton extended with a time model and event
parameterization is introduced to convert high level co-occurrence pattern
definition to its corresponding pattern matching automaton. Finally a
processing algorithm is applied to count the occurrence frequency of a
collection of patterns with only one pass through input event streams. The
method proposed in this paper can be used for detecting co-occurrences between
both events of one event stream (Auto co-occurrence), and events from multiple
event streams (Cross co-occurrence). Some fundamental results concerning the
characterization of event co-occurrence are presented in form of a visual co-
occurrence matrix. Reusable causality rules can be extracted easily from
co-occurrence matrix and fed into various analysis tools, such as
recommendation systems and complex event processing systems for further
analysis.
</summary>
    <author>
      <name>Laleh Jalali</name>
    </author>
    <author>
      <name>Ramesh Jain</name>
    </author>
    <link href="http://arxiv.org/abs/1603.09012v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.09012v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.09396v1</id>
    <updated>2016-03-30T22:03:19Z</updated>
    <published>2016-03-30T22:03:19Z</published>
    <title>Robust Hybrid Image Watermarking based on Discrete Wavelet and Shearlet
  Transforms</title>
    <summary>  With the growth of digital networks such as the Internet, digital media have
been explosively developed in e-commerce and online services. This causes
problems such as illegal copy and fake ownership. Watermarking is proposed as
one of the solutions to such cases. Among different watermarking techniques,
the wavelet transform has been used more because of its good ability in
modeling the human visual system. Recently, Shearlet transform as an extension
of Wavelet transform which is based on multi-resolution and multi-directional
analysis is introduced. The most important feature of this transform is the
appropriate representation of image edges. In this paper a hybrid scheme using
Discrete Wavelet Transform (DWT) and Discrete Shearlet Transform (DST) is
presented. In this way, the host image is decomposed using DWT, and then its
low frequency sub-band is decomposed by DST. After that, the bidiagonal
singular value decomposition (BSVD) is applied on the selected sub-band from
Shearlet transform and the gray-scale watermark image is embedded into its
bidiagonal singular values. The proposed method is examined on the images with
different textures and resistance is evaluated against various attacks like
image processing and geometric attacks. The results show good transparency and
high robustness in proposed method.
</summary>
    <author>
      <name>Malihe Mardanpour</name>
    </author>
    <author>
      <name>Mohammad Ali Zare Chahooki</name>
    </author>
    <link href="http://arxiv.org/abs/1603.09396v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.09396v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.00493v1</id>
    <updated>2016-04-02T12:21:52Z</updated>
    <published>2016-04-02T12:21:52Z</published>
    <title>Steganography -- A Game of Hide and Seek in Information Communication</title>
    <summary>  With the growth of communication over computer networks, how to maintain the
confidentiality and security of transmitted information have become some of the
important issues. In order to transfer data securely to the destination without
unwanted disclosure or damage, nature inspired hide and seek tricks such as,
cryptography and Steganography are heavily in use. Just like the Chameleon and
many other bio-species those change their body color and hide themselves in the
background in order to protect them from external attacks, Cryptography and
Steganography are techniques those are used to encrypt and hide the secret data
inside other media to ensure data security. This paper discusses the concept of
a simple spatial domain LSB Steganography that encrypts the secrets using
Fibonacci- Lucas transformation, before hiding, for better security.
</summary>
    <author>
      <name>Sanjeeb Kumar Behera</name>
    </author>
    <author>
      <name>Minati Mishra</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 4 figures, National Conference on Recent Innovations in
  Engineering and Management Sciences (RIEMS-2016)</arxiv:comment>
    <link href="http://arxiv.org/abs/1604.00493v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.00493v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.02778v1</id>
    <updated>2016-04-11T02:58:06Z</updated>
    <published>2016-04-11T02:58:06Z</published>
    <title>Trends toward real-time network data steganography</title>
    <summary>  Network steganography has been a well-known covert data channeling method for
over three decades. The basic set of techniques and implementation tools have
not changed significantly since their introduction in the early 1980's. In this
paper, we review the predominant methods of classical network steganography,
describing the detailed operations and resultant challenges involved in
embedding data in the network transport domain. We also consider the various
cyber threat vectors of network steganography and point out the major
differences between classical network steganography and the widely known
end-point multimedia embedding techniques, which focus exclusively on static
data modification for data hiding. We then challenge the security community by
introducing an entirely new network dat hiding methodology, which we refer to
as real-time network data steganography. Finally we provide the groundwork for
this fundamental change of covert network data embedding by forming a basic
framework for real-time network data operations that will open the path for
even further advances in computer network security.
</summary>
    <author>
      <name>James Collins</name>
    </author>
    <author>
      <name>Sos Agaian</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages introducing the concept of real-time network steganography</arxiv:comment>
    <link href="http://arxiv.org/abs/1604.02778v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.02778v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.03688v2</id>
    <updated>2016-04-27T07:47:54Z</updated>
    <published>2016-04-13T08:33:36Z</published>
    <title>A Practical Approach to Spatiotemporal Data Compression</title>
    <summary>  Datasets representing the world around us are becoming ever more unwieldy as
data volumes grow. This is largely due to increased measurement and modelling
resolution, but the problem is often exacerbated when data are stored at
spuriously high precisions. In an effort to facilitate analysis of these
datasets, computationally intensive calculations are increasingly being
performed on specialised remote servers before the reduced data are transferred
to the consumer. Due to bandwidth limitations, this often means data are
displayed as simple 2D data visualisations, such as scatter plots or images. We
present here a novel way to efficiently encode and transmit 4D data fields
on-demand so that they can be locally visualised and interrogated. This nascent
"4D video" format allows us to more flexibly move the boundary between data
server and consumer client. However, it has applications beyond purely
scientific visualisation, in the transmission of data to virtual and augmented
reality.
</summary>
    <author>
      <name>Niall H. Robinson</name>
    </author>
    <author>
      <name>Rachel Prudden</name>
    </author>
    <author>
      <name>Alberto Arribas</name>
    </author>
    <link href="http://arxiv.org/abs/1604.03688v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.03688v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.07051v1</id>
    <updated>2016-04-24T16:58:08Z</updated>
    <published>2016-04-24T16:58:08Z</published>
    <title>Lossless Intra Coding in HEVC with Adaptive 3-tap Filters</title>
    <summary>  In pixel-by-pixel spatial prediction methods for lossless intra coding, the
prediction is obtained by a weighted sum of neighbouring pixels. The proposed
prediction approach in this paper uses a weighted sum of three neighbor pixels
according to a two-dimensional correlation model. The weights are obtained
after a three step optimization procedure. The first two stages are offline
procedures where the computed prediction weights are obtained offline from
training sequences. The third stage is an online optimization procedure where
the offline obtained prediction weights are further fine-tuned and adapted to
each encoded block during encoding using a rate-distortion optimized method and
the modification in this third stage is transmitted to the decoder as side
information. The results of the simulations show average bit rate reductions of
12.02% and 3.28% over the default lossless intra coding in HEVC and the
well-known Sample-based Angular Prediction (SAP) method, respectively.
</summary>
    <author>
      <name>Saeed Ranjbar Alvar</name>
    </author>
    <author>
      <name>Fatih Kamisli</name>
    </author>
    <link href="http://arxiv.org/abs/1604.07051v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.07051v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.07211v1</id>
    <updated>2016-04-25T11:43:09Z</updated>
    <published>2016-04-25T11:43:09Z</published>
    <title>Towards Reduced Reference Parametric Models for Estimating Audiovisual
  Quality in Multimedia Services</title>
    <summary>  We have developed reduced reference parametric models for estimating
perceived quality in audiovisual multimedia services. We have created 144
unique configurations for audiovisual content including various application and
network parameters such as bitrates and distortions in terms of bandwidth,
packet loss rate and jitter. To generate the data needed for model training and
validation we have tasked 24 subjects, in a controlled environment, to rate the
overall audiovisual quality on the absolute category rating (ACR) 5-level
quality scale. We have developed models using Random Forest and Neural Network
based machine learning methods in order to estimate Mean Opinion Scores (MOS)
values. We have used information retrieved from the packet headers and side
information provided as network parameters for model training. Random Forest
based models have performed better in terms of Root Mean Square Error (RMSE)
and Pearson correlation coefficient. The side information proved to be very
effective in developing the model. We have found that, while the model
performance might be improved by replacing the side information with more
accurate bit stream level measurements, they are performing well in estimating
perceived quality in audiovisual multimedia services.
</summary>
    <author>
      <name>Edip Demirbilek</name>
    </author>
    <author>
      <name>Jean-Charles Grégoire</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to ICC 2016</arxiv:comment>
    <link href="http://arxiv.org/abs/1604.07211v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.07211v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.07322v2</id>
    <updated>2016-04-27T06:16:40Z</updated>
    <published>2016-04-25T16:34:17Z</published>
    <title>Predictive No-Reference Assessment of Video Quality</title>
    <summary>  Among the various means to evaluate the quality of video streams,
No-Reference (NR) methods have low computation and may be executed on thin
clients. Thus, NR algorithms would be perfect candidates in cases of real-time
quality assessment, automated quality control and, particularly, in adaptive
mobile streaming. Yet, existing NR approaches are often inaccurate, in
comparison to Full-Reference (FR) algorithms, especially under lossy network
conditions. In this work, we present an NR method that combines machine
learning with simple NR metrics to achieve a quality index comparably as
accurate as the Video Quality Metric (VQM) Full-Reference algorithm. Our method
is tested in an extensive dataset (960 videos), under lossy network conditions
and considering nine different machine learning algorithms. Overall, we achieve
an over 97% correlation with VQM, while allowing real-time assessment of video
quality of experience in realistic streaming scenarios.
</summary>
    <author>
      <name>Maria Torres Vega</name>
    </author>
    <author>
      <name>Decebal Constantin Mocanu</name>
    </author>
    <author>
      <name>Antonio Liotta</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 8 figures, IEEE Selected Topics on Signal Processing</arxiv:comment>
    <link href="http://arxiv.org/abs/1604.07322v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.07322v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.07339v1</id>
    <updated>2016-04-25T17:39:25Z</updated>
    <published>2016-04-25T17:39:25Z</published>
    <title>Compressed-domain visual saliency models: A comparative study</title>
    <summary>  Computational modeling of visual saliency has become an important research
problem in recent years, with applications in video quality estimation, video
compression, object tracking, retargeting, summarization, and so on. While most
visual saliency models for dynamic scenes operate on raw video, several models
have been developed for use with compressed-domain information such as motion
vectors and transform coefficients. This paper presents a comparative study of
eleven such models as well as two high-performing pixel-domain saliency models
on two eye-tracking datasets using several comparison metrics. The results
indicate that highly accurate saliency estimation is possible based only on a
partially decoded video bitstream. The strategies that have shown success in
compressed-domain saliency modeling are highlighted, and certain challenges are
identified as potential avenues for further improvement.
</summary>
    <author>
      <name>Sayed Hossein Khatoonabadi</name>
    </author>
    <author>
      <name>Ivan V. Bajic</name>
    </author>
    <author>
      <name>Yufeng Shan</name>
    </author>
    <link href="http://arxiv.org/abs/1604.07339v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.07339v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.10; I.4.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.07519v1</id>
    <updated>2016-04-26T05:02:33Z</updated>
    <published>2016-04-26T05:02:33Z</published>
    <title>Subjective Assessment of H.264 Compressed Stereoscopic Video</title>
    <summary>  The tremendous growth in 3D (stereo) imaging and display technologies has led
to stereoscopic content (video and image) becoming increasingly popular.
However, both the subjective and the objective evaluation of stereoscopic video
content has not kept pace with the rapid growth of the content. Further, the
availability of standard stereoscopic video databases is also quite limited. In
this work, we attempt to alleviate these shortcomings. We present a
stereoscopic video database and its subjective evaluation. We have created a
database containing a set of 144 distorted videos. We limit our attention to
H.264 compression artifacts. The distorted videos were generated using 6
uncompressed pristine videos of left and right views originally created by
Goldmann et al. at EPFL [1]. Further, 19 subjects participated in the
subjective assessment task. Based on the subjective study, we have formulated a
relation between the 2D and stereoscopic subjective scores as a function of
compression rate and depth range. We have also evaluated the performance of
popular 2D and 3D image/video quality assessment (I/VQA) algorithms on our
database.
</summary>
    <author>
      <name>Manasa K</name>
    </author>
    <author>
      <name>Balasubramanyam Appina</name>
    </author>
    <author>
      <name>Sumohana S. Channappayya</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1604.07519v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.07519v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.07939v2</id>
    <updated>2016-07-12T17:58:16Z</updated>
    <published>2016-04-27T05:46:52Z</published>
    <title>Large-Scale Query-by-Image Video Retrieval Using Bloom Filters</title>
    <summary>  We consider the problem of using image queries to retrieve videos from a
database. Our focus is on large-scale applications, where it is infeasible to
index each database video frame independently. Our main contribution is a
framework based on Bloom filters, which can be used to index long video
segments, enabling efficient image-to-video comparisons. Using this framework,
we investigate several retrieval architectures, by considering different types
of aggregation and different functions to encode visual information -- these
play a crucial role in achieving high performance. Extensive experiments show
that the proposed technique improves mean average precision by 24% on a public
dataset, while being 4X faster, compared to the previous state-of-the-art.
</summary>
    <author>
      <name>Andre Araujo</name>
    </author>
    <author>
      <name>Jason Chaves</name>
    </author>
    <author>
      <name>Haricharan Lakshman</name>
    </author>
    <author>
      <name>Roland Angst</name>
    </author>
    <author>
      <name>Bernd Girod</name>
    </author>
    <link href="http://arxiv.org/abs/1604.07939v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.07939v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.08088v1</id>
    <updated>2016-04-27T14:32:16Z</updated>
    <published>2016-04-27T14:32:16Z</published>
    <title>Detecting Violence in Video using Subclasses</title>
    <summary>  This paper attacks the challenging problem of violence detection in videos.
Different from existing works focusing on combining multi-modal features, we go
one step further by adding and exploiting subclasses visually related to
violence. We enrich the MediaEval 2015 violence dataset by \emph{manually}
labeling violence videos with respect to the subclasses. Such fine-grained
annotations not only help understand what have impeded previous efforts on
learning to fuse the multi-modal features, but also enhance the generalization
ability of the learned fusion to novel test data. The new subclass based
solution, with AP of 0.303 and P100 of 0.55 on the MediaEval 2015 test set,
outperforms several state-of-the-art alternatives. Notice that our solution
does not require fine-grained annotations on the test set, so it can be
directly applied on novel and fully unlabeled videos. Interestingly, our study
shows that motion related features, though being essential part in previous
systems, are dispensable.
</summary>
    <author>
      <name>Xirong Li</name>
    </author>
    <author>
      <name>Yujia Huo</name>
    </author>
    <author>
      <name>Jieping Xu</name>
    </author>
    <author>
      <name>Qin Jin</name>
    </author>
    <link href="http://arxiv.org/abs/1604.08088v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.08088v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.00957v1</id>
    <updated>2016-05-03T15:50:54Z</updated>
    <published>2016-05-03T15:50:54Z</published>
    <title>Bloom Filters and Compact Hash Codes for Efficient and Distributed Image
  Retrieval</title>
    <summary>  This paper presents a novel method for efficient image retrieval, based on a
simple and effective hashing of CNN features and the use of an indexing
structure based on Bloom filters. These filters are used as gatekeepers for the
database of image features, allowing to avoid to perform a query if the query
features are not stored in the database and speeding up the query process,
without affecting retrieval performance. Thanks to the limited memory
requirements the system is suitable for mobile applications and distributed
databases, associating each filter to a distributed portion of the database.
Experimental validation has been performed on three standard image retrieval
datasets, outperforming state-of-the-art hashing methods in terms of precision,
while the proposed indexing method obtains a $2\times$ speedup.
</summary>
    <author>
      <name>Andrea Salvi</name>
    </author>
    <author>
      <name>Simone Ercoli</name>
    </author>
    <author>
      <name>Marco Bertini</name>
    </author>
    <author>
      <name>Alberto Del Bimbo</name>
    </author>
    <link href="http://arxiv.org/abs/1605.00957v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.00957v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.02605v1</id>
    <updated>2016-05-09T14:39:02Z</updated>
    <published>2016-05-09T14:39:02Z</published>
    <title>Efficient Reversible Data Hiding Algorithms Based on Dual Prediction</title>
    <summary>  In this paper, a new reversible data hiding (RDH) algorithm that is based on
the concept of shifting of prediction error histograms is proposed. The
algorithm extends the efficient modification of prediction errors (MPE)
algorithm by incorporating two predictors and using one prediction error value
for data embedding. The motivation behind using two predictors is driven by the
fact that predictors have different prediction accuracy which is directly
related to the embedding capacity and quality of the stego image. The key
feature of the proposed algorithm lies in using two predictors without the need
to communicate additional overhead with the stego image. Basically, the
identification of the predictor that is used during embedding is done through a
set of rules. The proposed algorithm is further extended to use two and three
bins in the prediction errors histogram in order to increase the embedding
capacity. Performance evaluation of the proposed algorithm and its extensions
showed the advantage of using two predictors in boosting the embedding capacity
while providing competitive quality for the stego image.
</summary>
    <author>
      <name>Enas N. Jaara</name>
    </author>
    <author>
      <name>Iyad F. Jafar</name>
    </author>
    <link href="http://arxiv.org/abs/1605.02605v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.02605v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.02976v1</id>
    <updated>2016-05-10T12:29:18Z</updated>
    <published>2016-05-10T12:29:18Z</published>
    <title>Frame-level quality and memory traffic allocation for lossy embedded
  compression in video codec systems</title>
    <summary>  For mobile video codecs, the huge energy dissipation for external memory
traffic is a critical challenge under the battery power constraint. Lossy
embedded compression (EC), as a solution to this challenge, is considered in
this paper. While previous studies in EC mostly focused on compression
algorithms at the block level, this work, to the best of our knowledge, is the
first one that addresses the allocation of video quality and memory traffic at
the frame level. For lossy EC, a main difficulty of its application lies in the
error propagation from quality degradation of reference frames. Instinctively,
it is preferred to perform more lossy EC in non-reference frames to minimize
the quality loss. The analysis and experiments in this paper, however, will
show lossy EC should actually be distributed to more frames. Correspondingly,
for hierarchical-B GOPs, we developed an efficient allocation that outperforms
the non-reference-only allocation by up to 4.5 dB in PSNR. In comparison, the
proposed allocation also delivers more consistent quality between frames by
having lower PSNR fluctuation.
</summary>
    <author>
      <name>Li Guo</name>
    </author>
    <author>
      <name>Dajiang Zhou</name>
    </author>
    <author>
      <name>Shinji Kimura</name>
    </author>
    <author>
      <name>Satoshi Goto</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICME Workshops 2016</arxiv:comment>
    <link href="http://arxiv.org/abs/1605.02976v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.02976v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.03754v1</id>
    <updated>2016-05-12T10:50:18Z</updated>
    <published>2016-05-12T10:50:18Z</published>
    <title>Regression-based Intra-prediction for Image and Video Coding</title>
    <summary>  By utilizing previously known areas in an image, intra-prediction techniques
can find a good estimate of the current block. This allows the encoder to store
only the error between the original block and the generated estimate, thus
leading to an improvement in coding efficiency. Standards such as AVC and HEVC
describe expert-designed prediction modes operating in certain angular
orientations alongside separate DC and planar prediction modes. Being designed
predictors, while these techniques have been demonstrated to perform well in
image and video coding applications, they do not necessarily fully utilize
natural image structures. In this paper, we describe a novel system for
developing predictors derived from natural image blocks. The proposed algorithm
is seeded with designed predictors (e.g. HEVC-style prediction) and allowed to
iteratively refine these predictors through regularized regression. The
resulting prediction models show significant improvements in estimation quality
over their designed counterparts across all conditions while maintaining
reasonable computational complexity. We also demonstrate how the proposed
algorithm handles the worst-case scenario of intra-prediction with no error
reporting.
</summary>
    <author>
      <name>Carlo Noel Ochotorena</name>
    </author>
    <author>
      <name>Yukihiko Yamashita</name>
    </author>
    <link href="http://arxiv.org/abs/1605.03754v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.03754v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.03815v1</id>
    <updated>2016-05-12T14:01:14Z</updated>
    <published>2016-05-12T14:01:14Z</published>
    <title>Backward-Shifted Strategies Based on SVC for HTTP Adaptive Video
  Streaming</title>
    <summary>  Although HTTP-based video streaming can easily penetrate firewalls and profit
from Web caches, the underlying TCP may introduce large delays in case of a
sudden capacity loss. To avoid an interruption of the video stream in such
cases we propose the Backward-Shifted Coding (BSC). Based on Scalable Video
Coding (SVC), BSC adds a time-shifted layer of redundancy to the video stream
such that future frames are downloaded at any instant. This pre-fetched content
maintains a fluent video stream even under highly variant network conditions
and leads to high Quality of Experience (QoE). We characterize this QoE gain by
analyzing initial buffering time, re-buffering time and content resolution
using the Ballot theorem. The probability generating functions of the playback
interruption and of the initial buffering latency are provided in closed form.
We further compute the quasi-stationary distribution of the video quality, in
order to compute the average quality, as well as temporal variability in video
quality. Employing these analytic results to optimize QoE shows interesting
trade-offs and video streaming at outstanding fluency.
</summary>
    <author>
      <name>Zakaria Ye</name>
    </author>
    <author>
      <name>Rachid El-Azouzi</name>
    </author>
    <author>
      <name>Tania Jimenez</name>
    </author>
    <author>
      <name>Eitan Altman</name>
    </author>
    <author>
      <name>Stefan Valentin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1605.03815v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.03815v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.05319v1</id>
    <updated>2016-05-17T11:54:04Z</updated>
    <published>2016-05-17T11:54:04Z</published>
    <title>Lossless Intra Coding in HEVC with Integer-to-Integer DST</title>
    <summary>  It is desirable to support efficient lossless coding within video coding
standards, which are primarily designed for lossy coding, with as little
modification as possible. A simple approach is to skip transform and
quantization, and directly entropy code the prediction residual, but this is
inefficient for compression. A more efficient and popular approach is to
process the residual block with DPCM prior to entropy coding. This paper
explores an alternative approach based on processing the residual block with
integer-to-integer (i2i) transforms. I2i transforms map integers to integers,
however, unlike the integer transforms used in HEVC for lossy coding, they do
not increase the dynamic range at the output and can be used in lossless
coding. We use both an i2i DCT from the literature and a novel i2i
approximation of the DST. Experiments with the HEVC reference software show
competitive results.
</summary>
    <author>
      <name>Fatih Kamisli</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: substantial text overlap with arXiv:1605.05118</arxiv:comment>
    <link href="http://arxiv.org/abs/1605.05319v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.05319v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.05758v1</id>
    <updated>2016-05-18T21:10:16Z</updated>
    <published>2016-05-18T21:10:16Z</published>
    <title>Resource Provisioning and Profit Maximization for Transcoding in
  Information Centric Networking</title>
    <summary>  Adaptive bitrate streaming (ABR) has been widely adopted to support video
streaming services over heterogeneous devices and varying network conditions.
With ABR, each video content is transcoded into multiple representations in
different bitrates and resolutions. However, video transcoding is computing
intensive, which requires the transcoding service providers to deploy a large
number of servers for transcoding the video contents published by the content
producers. As such, a natural question for the transcoding service provider is
how to provision the computing resource for transcoding the video contents
while maximizing service profit. To address this problem, we design a cloud
video transcoding system by taking the advantage of cloud computing technology
to elastically allocate computing resource. We propose a method for jointly
considering the task scheduling and resource provisioning problem in two
timescales, and formulate the service profit maximization as a two-timescale
stochastic optimization problem. We derive some approximate policies for the
task scheduling and resource provisioning. Based on our proposed methods, we
implement our open source cloud video transcoding system Morph and evaluate its
performance in a real environment. The experiment results demonstrate that our
proposed method can reduce the resource consumption and achieve a higher profit
compared with the baseline schemes.
</summary>
    <author>
      <name>Guanyu Gao</name>
    </author>
    <author>
      <name>Yonggang Wen</name>
    </author>
    <author>
      <name>Cedric Westphal</name>
    </author>
    <link href="http://arxiv.org/abs/1605.05758v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.05758v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.08969v1</id>
    <updated>2016-05-29T06:03:26Z</updated>
    <published>2016-05-29T06:03:26Z</published>
    <title>Improving Crowdsourced Live Streaming with Aggregated Edge Networks</title>
    <summary>  Recent years have witnessed a dramatic increase of user-generated video
services. In such user-generated video services, crowdsourced live streaming
(e.g., Periscope, Twitch) has significantly challenged today's edge network
infrastructure: today's edge networks (e.g., 4G, Wi-Fi) have limited uplink
capacity support, making high-bitrate live streaming over such links
fundamentally impossible. In this paper, we propose to let broadcasters (i.e.,
users who generate the video) upload crowdsourced video streams using
aggregated network resources from multiple edge networks. There are several
challenges in the proposal: First, how to design a framework that aggregates
bandwidth from multiple edge networks? Second, how to make this framework
transparent to today's crowdsourced live streaming services? Third, how to
maximize the streaming quality for the whole system? We design a
multi-objective and deployable bandwidth aggregation system BASS to address
these challenges: (1) We propose an aggregation framework transparent to
today's crowdsourced live streaming services, using an edge proxy box and
aggregation cloud paradigm; (2) We dynamically allocate geo-distributed cloud
aggregation servers to enable MPTCP (i.e., multi-path TCP), according to
location and network characteristics of both broadcasters and the original
streaming servers; (3) We maximize the overall performance gain for the whole
system, by matching streams with the best aggregation paths.
</summary>
    <author>
      <name>Chenglei Wu</name>
    </author>
    <author>
      <name>Zhi Wang</name>
    </author>
    <author>
      <name>Jiangchuan Liu</name>
    </author>
    <author>
      <name>Shiqiang Yang</name>
    </author>
    <link href="http://arxiv.org/abs/1605.08969v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.08969v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.09425v1</id>
    <updated>2016-05-30T21:46:31Z</updated>
    <published>2016-05-30T21:46:31Z</published>
    <title>Models and Algorithms for Graph Watermarking</title>
    <summary>  We introduce models and algorithmic foundations for graph watermarking. Our
frameworks include security definitions and proofs, as well as
characterizations when graph watermarking is algorithmically feasible, in spite
of the fact that the general problem is NP-complete by simple reductions from
the subgraph isomorphism or graph edit distance problems. In the digital
watermarking of many types of files, an implicit step in the recovery of a
watermark is the mapping of individual pieces of data, such as image pixels or
movie frames, from one object to another. In graphs, this step corresponds to
approximately matching vertices of one graph to another based on graph
invariants such as vertex degree. Our approach is based on characterizing the
feasibility of graph watermarking in terms of keygen, marking, and
identification functions defined over graph families with known distributions.
We demonstrate the strength of this approach with exemplary watermarking
schemes for two random graph models, the classic Erd\H{o}s-R\'{e}nyi model and
a random power-law graph model, both of which are used to model real-world
networks.
</summary>
    <author>
      <name>David Eppstein</name>
    </author>
    <author>
      <name>Michael T. Goodrich</name>
    </author>
    <author>
      <name>Jenny Lam</name>
    </author>
    <author>
      <name>Nil Mamano</name>
    </author>
    <author>
      <name>Michael Mitzenmacher</name>
    </author>
    <author>
      <name>Manuel Torres</name>
    </author>
    <link href="http://arxiv.org/abs/1605.09425v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.09425v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.00264v1</id>
    <updated>2016-06-01T12:49:09Z</updated>
    <published>2016-06-01T12:49:09Z</published>
    <title>Advanced Transport Options for the Dynamic Adaptive Streaming over HTTP</title>
    <summary>  Multimedia streaming over HTTP is no longer a niche research topic as it has
entered our daily live. The common assumption is that it is deployed on top of
the existing infrastructure utilizing application (HTTP) and transport (TCP)
layer protocols as is. Interestingly, standards like MPEG's Dynamic Adaptive
Streaming over HTTP (DASH) do not mandate the usage of any specific transport
protocol allowing for sufficient deployment flexibility which is further
supported by emerging developments within both protocol layers. This paper
investigates and evaluates the usage of advanced transport options for the
dynamic adaptive streaming over HTTP. We utilize a common test setup to
evaluate HTTP/2.0 and Google's Quick UDP Internet Connections (QUIC) protocol
in the context of DASH-based services.
</summary>
    <author>
      <name>Christian Timmerer</name>
    </author>
    <author>
      <name>Alan Bertoni</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1606.00264v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.00264v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.00341v1</id>
    <updated>2016-06-01T16:05:14Z</updated>
    <published>2016-06-01T16:05:14Z</published>
    <title>Which Adaptation Logic? An Objective and Subjective Performance
  Evaluation of HTTP-based Adaptive Media Streaming Systems</title>
    <summary>  Multimedia content delivery over the Internet is predominantly using the
Hypertext Transfer Protocol (HTTP) as its primary protocol and multiple
proprietary solutions exits. The MPEG standard Dynamic Adaptive Streaming over
HTTP (DASH) provides an interoperable solution and in recent years various
adaptation logics/algorithms have been proposed. However, to the best of our
knowledge, there is no comprehensive evaluation of the various
logics/algorithms. Therefore, this paper provides a comprehensive evaluation of
ten different adaptation logics/algorithms, which have been proposed in the
past years. The evaluation is done both objectively and subjectively. The
former is using a predefined bandwidth trajectory within a controlled
environment and the latter is done in a real-world environment adopting
crowdsourcing. The results shall provide insights about which strategy can be
adopted in actual deployment scenarios. Additionally, the evaluation
methodology described in this paper can be used to evaluate any other/new
adaptation logic and to compare it directly with the results reported here.
</summary>
    <author>
      <name>Christian Timmerer</name>
    </author>
    <author>
      <name>Matteo Maiero</name>
    </author>
    <author>
      <name>Benjamin Rainer</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1606.00341v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.00341v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.02312v1</id>
    <updated>2016-06-07T20:00:41Z</updated>
    <published>2016-06-07T20:00:41Z</published>
    <title>High Capacity Image Steganography using Adjunctive Numerical
  Representations with Multiple Bit-Plane Decomposition Methods</title>
    <summary>  LSB steganography is a one of the most widely used methods for implementing
covert data channels in image file exchanges [1][2]. The low computational
complexity and implementation simplicity of the algorithm are significant
factors for its popularity with the primary reason being low image distortion.
Many attempts have been made to increase the embedding capacity of LSB
algorithms by expanding into the second or third binary layers of the image
while maintaining a low probability of detection with minimal distortive
effects [2][3][4]. In this paper, we introduce an advanced technique for
covertly embedding data within images using redundant number system
decomposition over non-standard digital bit planes. Both grayscale and
bit-mapped images are equally effective as cover files. It will be shown that
this unique steganography method has minimal visual distortive affects while
also preserving the cover file statistics, making it less susceptible to most
general steganography detection algorithms.
</summary>
    <author>
      <name>James Collins</name>
    </author>
    <author>
      <name>Sos Agaian</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages, 13 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1606.02312v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.02312v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.03333v1</id>
    <updated>2016-06-10T14:09:32Z</updated>
    <published>2016-06-10T14:09:32Z</published>
    <title>Automatic Genre and Show Identification of Broadcast Media</title>
    <summary>  Huge amounts of digital videos are being produced and broadcast every day,
leading to giant media archives. Effective techniques are needed to make such
data accessible further. Automatic meta-data labelling of broadcast media is an
essential task for multimedia indexing, where it is standard to use multi-modal
input for such purposes. This paper describes a novel method for automatic
detection of media genre and show identities using acoustic features, textual
features or a combination thereof. Furthermore the inclusion of available
meta-data, such as time of broadcast, is shown to lead to very high
performance. Latent Dirichlet Allocation is used to model both acoustics and
text, yielding fixed dimensional representations of media recordings that can
then be used in Support Vector Machines based classification. Experiments are
conducted on more than 1200 hours of TV broadcasts from the British
Broadcasting Corporation (BBC), where the task is to categorise the broadcasts
into 8 genres or 133 show identities. On a 200-hour test set, accuracies of
98.6% and 85.7% were achieved for genre and show identification respectively,
using a combination of acoustic and textual features with meta-data.
</summary>
    <author>
      <name>Mortaza Doulaty</name>
    </author>
    <author>
      <name>Oscar Saz</name>
    </author>
    <author>
      <name>Raymond W. M. Ng</name>
    </author>
    <author>
      <name>Thomas Hain</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. of 17th Interspeech (2016), San Francisco, California, USA</arxiv:comment>
    <link href="http://arxiv.org/abs/1606.03333v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.03333v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.04631v1</id>
    <updated>2016-06-15T03:26:53Z</updated>
    <published>2016-06-15T03:26:53Z</published>
    <title>Bidirectional Long-Short Term Memory for Video Description</title>
    <summary>  Video captioning has been attracting broad research attention in multimedia
community. However, most existing approaches either ignore temporal information
among video frames or just employ local contextual temporal knowledge. In this
work, we propose a novel video captioning framework, termed as
\emph{Bidirectional Long-Short Term Memory} (BiLSTM), which deeply captures
bidirectional global temporal structure in video. Specifically, we first devise
a joint visual modelling approach to encode video data by combining a forward
LSTM pass, a backward LSTM pass, together with visual features from
Convolutional Neural Networks (CNNs). Then, we inject the derived video
representation into the subsequent language model for initialization. The
benefits are in two folds: 1) comprehensively preserving sequential and visual
information; and 2) adaptively learning dense visual features and sparse
semantic representations for videos and sentences, respectively. We verify the
effectiveness of our proposed video captioning framework on a commonly-used
benchmark, i.e., Microsoft Video Description (MSVD) corpus, and the
experimental results demonstrate that the superiority of the proposed approach
as compared to several state-of-the-art methods.
</summary>
    <author>
      <name>Yi Bin</name>
    </author>
    <author>
      <name>Yang Yang</name>
    </author>
    <author>
      <name>Zi Huang</name>
    </author>
    <author>
      <name>Fumin Shen</name>
    </author>
    <author>
      <name>Xing Xu</name>
    </author>
    <author>
      <name>Heng Tao Shen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1606.04631v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.04631v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.05294v1</id>
    <updated>2016-06-16T17:52:59Z</updated>
    <published>2016-06-16T17:52:59Z</published>
    <title>Can Machine Learn Steganography? - Implementing LSB Substitution and
  Matrix Coding Steganography with Feed-Forward Neural Networks</title>
    <summary>  In recent years, due to the powerful abilities to deal with highly complex
tasks, the artificial neural networks (ANNs) have been studied in the hope of
achieving human-like performance in many applications. Since the ANNs have the
ability to approximate complex functions from observations, it is
straightforward to consider the ANNs for steganography. In this paper, we aim
to implement the well-known LSB substitution and matrix coding steganography
with the feed-forward neural networks (FNNs). Our experimental results have
shown that, the used FNNs can achieve the data embedding operation of the LSB
substitution and matrix coding steganography. For steganography with the ANNs,
though there may be some challenges to us, it would be very promising and
valuable to pay attention to the ANNs for steganography, which may be a new
direction for steganography.
</summary>
    <author>
      <name>Han-Zhou Wu</name>
    </author>
    <author>
      <name>Hong-Xia Wang</name>
    </author>
    <author>
      <name>Yun-Qing Shi</name>
    </author>
    <link href="http://arxiv.org/abs/1606.05294v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.05294v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.06873v2</id>
    <updated>2016-07-18T08:45:14Z</updated>
    <published>2016-06-22T10:02:39Z</published>
    <title>Personality, Culture, and System Factors - Impact on Affective Response
  to Multimedia</title>
    <summary>  Whilst affective responses to various forms and genres of multimedia content
have been well researched, precious few studies have investigated the combined
impact that multimedia system parameters and human factors have on affect.
Consequently, in this paper we explore the role that two primordial dimensions
of human factors - personality and culture - in conjunction with system factors
- frame rate, resolution, and bit rate - have on user affect and enjoyment of
multimedia presentations. To this end, a two-site, cross-cultural study was
undertaken, the results of which produced three predictve models. Personality
and Culture traits were shown statistically to represent 5.6% of the variance
in positive affect, 13.6% in negative affect and 9.3% in enjoyment. The
correlation between affect and enjoyment, was significant. Predictive modeling
incorporating human factors showed about 8%, 7% and 9% improvement in
predicting positive affect, negative affect and enjoyment respectively when
compared to models trained only on system factors. Results and analysis
indicate the significant role played by human factors in influencing affect
that users experience while watching multimedia.
</summary>
    <author>
      <name>Sharath Chandra Guntuku</name>
    </author>
    <author>
      <name>Michael James Scott</name>
    </author>
    <author>
      <name>Gheorghita Ghinea</name>
    </author>
    <author>
      <name>Weisi Lin</name>
    </author>
    <link href="http://arxiv.org/abs/1606.06873v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.06873v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.07583v1</id>
    <updated>2016-06-24T07:18:42Z</updated>
    <published>2016-06-24T07:18:42Z</published>
    <title>N-queens-based algorithm for moving object detection in distributed
  wireless sensor networks</title>
    <summary>  The main constraint of wireless sensor networks (WSN) in enabling wireless
image communication is the high energy requirement, which may exceed even the
future capabilities of battery technologies. In this paper we have shown that
this bottleneck can be overcome by developing local in-network image processing
algorithm that offers optimal energy consumption. Our algorithm is very
suitable for intruder detection applications. Each node is responsible for
processing the image captured by the video sensor, which consists of NxN
blocks. If an intruder is detected in the monitoring region, the node will
transmit the image for further processing. Otherwise, the node takes no action.
Results provided from our experiments show that our algorithm is better than
the traditional moving object detection techniques by a factor of (N/2) in
terms of energy savings.
</summary>
    <author>
      <name>Biljana Stojkoska</name>
    </author>
    <author>
      <name>Danco Davcev</name>
    </author>
    <author>
      <name>Vladimir Trajkovik</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/ITI.2008.4588530</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/ITI.2008.4588530" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the ITI 2008 30th Int. Conf. on Information
  Technology Interfaces, June 23-26, 2008, Cavtat, Croatia, pp.899-904</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1606.07583v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.07583v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.07908v2</id>
    <updated>2016-07-26T11:42:20Z</updated>
    <published>2016-06-25T12:57:44Z</published>
    <title>Label Tree Embeddings for Acoustic Scene Classification</title>
    <summary>  We present in this paper an efficient approach for acoustic scene
classification by exploring the structure of class labels. Given a set of class
labels, a category taxonomy is automatically learned by collectively optimizing
a clustering of the labels into multiple meta-classes in a tree structure. An
acoustic scene instance is then embedded into a low-dimensional feature
representation which consists of the likelihoods that it belongs to the
meta-classes. We demonstrate state-of-the-art results on two different datasets
for the acoustic scene classification task, including the DCASE 2013 and LITIS
Rouen datasets.
</summary>
    <author>
      <name>Huy Phan</name>
    </author>
    <author>
      <name>Lars Hertel</name>
    </author>
    <author>
      <name>Marco Maass</name>
    </author>
    <author>
      <name>Philipp Koch</name>
    </author>
    <author>
      <name>Alfred Mertins</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/2964284.2967268</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/2964284.2967268" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">to appear in the Proceedings of ACM Multimedia 2016 (ACMMM 2016)</arxiv:comment>
    <link href="http://arxiv.org/abs/1606.07908v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.07908v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.5.5; I.5.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.08955v1</id>
    <updated>2016-06-29T05:04:27Z</updated>
    <published>2016-06-29T05:04:27Z</published>
    <title>Leveraging Contextual Cues for Generating Basketball Highlights</title>
    <summary>  The massive growth of sports videos has resulted in a need for automatic
generation of sports highlights that are comparable in quality to the
hand-edited highlights produced by broadcasters such as ESPN. Unlike previous
works that mostly use audio-visual cues derived from the video, we propose an
approach that additionally leverages contextual cues derived from the
environment that the game is being played in. The contextual cues provide
information about the excitement levels in the game, which can be ranked and
selected to automatically produce high-quality basketball highlights. We
introduce a new dataset of 25 NCAA games along with their play-by-play stats
and the ground-truth excitement data for each basket. We explore the
informativeness of five different cues derived from the video and from the
environment through user studies. Our experiments show that for our study
participants, the highlights produced by our system are comparable to the ones
produced by ESPN for the same games.
</summary>
    <author>
      <name>Vinay Bettadapura</name>
    </author>
    <author>
      <name>Caroline Pantofaru</name>
    </author>
    <author>
      <name>Irfan Essa</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of ACM Multimedia 2016</arxiv:comment>
    <link href="http://arxiv.org/abs/1606.08955v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.08955v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.3.1; I.2.10" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.08999v1</id>
    <updated>2016-06-29T08:33:28Z</updated>
    <published>2016-06-29T08:33:28Z</published>
    <title>De-Hashing: Server-Side Context-Aware Feature Reconstruction for Mobile
  Visual Search</title>
    <summary>  Due to the prevalence of mobile devices, mobile search becomes a more
convenient way than desktop search. Different from the traditional desktop
search, mobile visual search needs more consideration for the limited resources
on mobile devices (e.g., bandwidth, computing power, and memory consumption).
The state-of-the-art approaches show that bag-of-words (BoW) model is robust
for image and video retrieval; however, the large vocabulary tree might not be
able to be loaded on the mobile device. We observe that recent works mainly
focus on designing compact feature representations on mobile devices for
bandwidth-limited network (e.g., 3G) and directly adopt feature matching on
remote servers (cloud). However, the compact (binary) representation might fail
to retrieve target objects (images, videos). Based on the hashed binary codes,
we propose a de-hashing process that reconstructs BoW by leveraging the
computing power of remote servers. To mitigate the information loss from binary
codes, we further utilize contextual information (e.g., GPS) to reconstruct a
context-aware BoW for better retrieval results. Experiment results show that
the proposed method can achieve competitive retrieval accuracy as BoW while
only transmitting few bits from mobile devices.
</summary>
    <author>
      <name>Yin-Hsi Kuo</name>
    </author>
    <author>
      <name>Winston H. Hsu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted for publication in IEEE Transactions on Circuits and Systems
  for Video Technology (TCSVT)</arxiv:comment>
    <link href="http://arxiv.org/abs/1606.08999v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.08999v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.09047v1</id>
    <updated>2016-06-29T11:18:41Z</updated>
    <published>2016-06-29T11:18:41Z</published>
    <title>Minimum-latency Time-frequency Analysis Using Asymmetric Window
  Functions</title>
    <summary>  We study the real-time dynamics retrieval from a time series via the
time-frequency (TF) analysis with the minimal latency guarantee. While
different from the well-known intrinsic latency definition in the filter
design, a rigorous definition of intrinsic latency for different time-frequency
representations (TFR) is provided, including the short time Fourier transform
(STFT), synchrosqeezing transform (SST) and reassignment method (RM). To
achieve the minimal latency, a systematic method is proposed to construct an
asymmetric window from a well-designed symmetric one based on the concept of
minimum-phase, if the window satisfies some weak conditions. We theoretically
show that the TFR determined by SST with the constructed asymmetric window does
have a smaller intrinsic latency. Finally, the music onset detection problem is
studied to show the strength of the proposed algorithm.
</summary>
    <author>
      <name>Li Su</name>
    </author>
    <author>
      <name>Hau-tieng Wu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">29 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1606.09047v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.09047v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.00719v1</id>
    <updated>2016-07-04T01:56:20Z</updated>
    <published>2016-07-04T01:56:20Z</published>
    <title>Coarse2Fine: Two-Layer Fusion For Image Retrieval</title>
    <summary>  This paper addresses the problem of large-scale image retrieval. We propose a
two-layer fusion method which takes advantage of global and local cues and
ranks database images from coarse to fine (C2F). Departing from the previous
methods fusing multiple image descriptors simultaneously, C2F is featured by a
layered procedure composed by filtering and refining. In particular, C2F
consists of three components. 1) Distractor filtering. With holistic
representations, noise images are filtered out from the database, so the number
of candidate images to be used for comparison with the query can be greatly
reduced. 2) Adaptive weighting. For a certain query, the similarity of
candidate images can be estimated by holistic similarity scores in
complementary to the local ones. 3) Candidate refining. Accurate retrieval is
conducted via local features, combining the pre-computed adaptive weights.
Experiments are presented on two benchmarks, \emph{i.e.,} Holidays and Ukbench
datasets. We show that our method outperforms recent fusion methods in terms of
storage consumption and computation complexity, and that the accuracy is
competitive to the state-of-the-arts.
</summary>
    <author>
      <name>Gaipeng Kong</name>
    </author>
    <author>
      <name>Le Dong</name>
    </author>
    <author>
      <name>Wenpu Dong</name>
    </author>
    <author>
      <name>Liang Zheng</name>
    </author>
    <author>
      <name>Qi Tian</name>
    </author>
    <link href="http://arxiv.org/abs/1607.00719v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.00719v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.01172v1</id>
    <updated>2016-07-05T09:51:25Z</updated>
    <published>2016-07-05T09:51:25Z</published>
    <title>A Measurement Study of TCP Performance for Chunk Delivery in DASH</title>
    <summary>  Dynamic Adaptive Streaming over HTTP (DASH) has emerged as an increasingly
popular paradigm for video streaming [13], in which a video is segmented into
many chunks delivered to users by HTTP request/response over Transmission
Control Protocol (TCP) con- nections. Therefore, it is intriguing to study the
performance of strategies implemented in conventional TCPs, which are not
dedicated for video streaming, e.g., whether chunks are efficiently delivered
when users per- form interactions with the video players. In this paper, we
conduct mea- surement studies on users chunk requesting traces in DASH from a
rep- resentative video streaming provider, to investigate users behaviors in
DASH, and TCP-connection-level traces from CDN servers, to investi- gate the
performance of TCP for DASH. By studying how video chunks are delivered in both
the slow start and congestion avoidance phases, our observations have revealed
the performance characteristics of TCP for DASH as follows: (1) Request
patterns in DASH have a great impact on the performance of TCP variations
including cubic; (2) Strategies in conventional TCPs may cause user perceived
quality degradation in DASH streaming; (3) Potential improvement to TCP
strategies for better delivery in DASH can be further explored.
</summary>
    <author>
      <name>Wen Hu</name>
    </author>
    <author>
      <name>Zhi Wang</name>
    </author>
    <author>
      <name>Lifeng Sun</name>
    </author>
    <link href="http://arxiv.org/abs/1607.01172v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.01172v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.03257v1</id>
    <updated>2016-07-12T08:30:45Z</updated>
    <published>2016-07-12T08:30:45Z</published>
    <title>City-Identification of Flickr Videos Using Semantic Acoustic Features</title>
    <summary>  City-identification of videos aims to determine the likelihood of a video
belonging to a set of cities. In this paper, we present an approach using only
audio, thus we do not use any additional modality such as images, user-tags or
geo-tags. In this manner, we show to what extent the city-location of videos
correlates to their acoustic information. Success in this task suggests
improvements can be made to complement the other modalities. In particular, we
present a method to compute and use semantic acoustic features to perform
city-identification and the features show semantic evidence of the
identification. The semantic evidence is given by a taxonomy of urban sounds
and expresses the potential presence of these sounds in the city- soundtracks.
We used the MediaEval Placing Task set, which contains Flickr videos labeled by
city. In addition, we used the UrbanSound8K set containing audio clips labeled
by sound- type. Our method improved the state-of-the-art performance and
provides a novel semantic approach to this task
</summary>
    <author>
      <name>Benjamin Elizalde</name>
    </author>
    <author>
      <name>Guan-Lin Chao</name>
    </author>
    <author>
      <name>Ming Zeng</name>
    </author>
    <author>
      <name>Ian Lane</name>
    </author>
    <link href="http://arxiv.org/abs/1607.03257v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.03257v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.05808v1</id>
    <updated>2016-07-20T03:23:49Z</updated>
    <published>2016-07-20T03:23:49Z</published>
    <title>Hybrid Video Signal Coding Technologies: Past, Current and Future</title>
    <summary>  The growing needs for high-quality video applications have resulted in a lot
of studies and developments in video signal coding. This chapter presents some
advanced techniques in enhancing the rate-distortion performance of the
block-based hybrid video coding systems. Additionally, as can be seen from the
developments of H.264/AVC and HEVC, most of the current coding tools, such as
prediction, transformation and entropy coding, have less room to improve in the
compression performance. On the other hand, loop filer in the modern video
standards shows the promising results. Thus, we believe that loop filter can be
the candidate in contributing to higher video compression for the
next-generation video coding. Specifically, improvements on ALF and SAO are
also introduced, and the simulation results show that the proposed methods
outperform the existing method, which offer new degrees of freedom to improve
the overall rate-distortion performance. As a result, they can be the candidate
coding tools for the next-generation video codec.
</summary>
    <author>
      <name>Miaohui Wang</name>
    </author>
    <author>
      <name>Ngan King Ngi</name>
    </author>
    <link href="http://arxiv.org/abs/1607.05808v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.05808v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.06803v3</id>
    <updated>2017-02-16T16:55:20Z</updated>
    <published>2016-07-22T19:44:01Z</published>
    <title>Restoring highly corrupted images by impulse noise using radial basis
  functions interpolation</title>
    <summary>  Preserving details in restoring images highly corrupted by impulse noise
remains a challenging problem. We proposed an algorithm based on radial basis
functions (RBF) interpolation which estimates the intensities of corrupted
pixels by their neighbors. In this algorithm, first intensity values of noisy
pixels in the corrupted image are estimated using RBFs. Next, the image is
smoothed. The proposed algorithm can effectively remove the highly dense
impulse noise. Experimental results show the superiority of the proposed
algorithm in comparison to the recent similar methods both in noise suppression
and detail preservation. Extensive simulations show better results in measure
of peak signal-to-noise ratio (PSNR) and structural similarity index (SSIM),
especially when the image is corrupted by very highly dense impulse noise.
</summary>
    <author>
      <name>Fariborz Taherkhani</name>
    </author>
    <author>
      <name>Mansour Jamzad</name>
    </author>
    <link href="http://arxiv.org/abs/1607.06803v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.06803v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.07697v1</id>
    <updated>2016-07-15T06:13:21Z</updated>
    <published>2016-07-15T06:13:21Z</published>
    <title>Low-complexity feedback-channel-free distributed video coding using
  Local Rank Transform</title>
    <summary>  In this paper, we propose a new feedback-channel-free Distributed Video
Coding (DVC) algorithm using Local Rank Transform (LRT). The encoder computes
LRT by considering selected neighborhood pixels of Wyner-Ziv frame. The ranks
from the modified LRT are merged, and their positions are entropy coded and
sent to the decoder. In addition, means of each block of Wyner-Ziv frame are
also transmitted to assist motion estimation. Using these measurements, the
decoder generates side information (SI) by implementing motion estimation and
compensation in LRT domain. An iterative algorithm is executed on SI using LRT
to reconstruct the Wyner-Ziv frame. Experimental results show that the coding
efficiency of our codec is close to the efficiency of pixel domain distributed
video coders based on Low-Density Parity Check and Accumulate (LDPCA) or turbo
codes, with less encoder complexity.
</summary>
    <author>
      <name>P Raj Bhagath</name>
    </author>
    <author>
      <name>Kallol Mallick</name>
    </author>
    <author>
      <name>Jayanta Mukherjee</name>
    </author>
    <author>
      <name>Sudipta Mukopadhayay</name>
    </author>
    <link href="http://arxiv.org/abs/1607.07697v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.07697v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.07824v1</id>
    <updated>2016-07-26T18:02:44Z</updated>
    <published>2016-07-26T18:02:44Z</published>
    <title>Natural Steganography: cover-source switching for better steganography</title>
    <summary>  This paper proposes a new steganographic scheme relying on the principle of
cover-source switching, the key idea being that the embedding should switch
from one cover-source to another. The proposed implementation, called Natural
Steganography, considers the sensor noise naturally present in the raw images
and uses the principle that, by the addition of a specific noise the
steganographic embedding tries to mimic a change of ISO sensitivity. The
embedding methodology consists in 1) perturbing the image in the raw domain, 2)
modeling the perturbation in the processed domain, 3) embedding the payload in
the processed domain. We show that this methodology is easily tractable
whenever the processes are known and enables to embed large and undetectable
payloads. We also show that already used heuristics such as synchronization of
embedding changes or detectability after rescaling can be respectively
explained by operations such as color demosaicing and down-scaling kernels.
</summary>
    <author>
      <name>Patrick Bas</name>
    </author>
    <link href="http://arxiv.org/abs/1607.07824v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.07824v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.00905v2</id>
    <updated>2016-09-15T11:16:36Z</updated>
    <published>2016-08-02T17:09:19Z</published>
    <title>PicHunt: Social Media Image Retrieval for Improved Law Enforcement</title>
    <summary>  First responders are increasingly using social media to identify and reduce
crime for well-being and safety of the society. Images shared on social media
hurting religious, political, communal and other sentiments of people, often
instigate violence and create law &amp; order situations in society. This results
in the need for first responders to inspect the spread of such images and users
propagating them on social media. In this paper, we present a comparison
between different hand-crafted features and a Convolutional Neural Network
(CNN) model to retrieve similar images, which outperforms state-of-art
hand-crafted features. We propose an Open-Source-Intelligent (OSINT) real-time
image search system, robust to retrieve modified images that allows first
responders to analyze the current spread of images, sentiments floating and
details of users propagating such content. The system also aids officials to
save time of manually analyzing the content by reducing the search space on an
average by 67%.
</summary>
    <author>
      <name>Sonal Goel</name>
    </author>
    <author>
      <name>Niharika Sachdeva</name>
    </author>
    <author>
      <name>Ponnurangam Kumaraguru</name>
    </author>
    <author>
      <name>A V Subramanyam</name>
    </author>
    <author>
      <name>Divam Gupta</name>
    </author>
    <link href="http://arxiv.org/abs/1608.00905v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.00905v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.01947v1</id>
    <updated>2016-08-05T17:36:51Z</updated>
    <published>2016-08-05T17:36:51Z</published>
    <title>Daala: Building A Next-Generation Video Codec From Unconventional
  Technology</title>
    <summary>  Daala is a new royalty-free video codec that attempts to compete with
state-of-the-art royalty-bearing codecs. To do so, it must achieve good
compression while avoiding all of their patented techniques. We use technology
that is as different as possible from traditional approaches to achieve this.
This paper describes the technology behind Daala and discusses where it fits in
the newly created AV1 codec from the Alliance for Open Media. We show that
Daala is approaching the performance level of more mature, state-of-the art
video codecs and can contribute to improving AV1.
</summary>
    <author>
      <name>Jean-Marc Valin</name>
    </author>
    <author>
      <name>Timothy B. Terriberry</name>
    </author>
    <author>
      <name>Nathan E. Egge</name>
    </author>
    <author>
      <name>Thomas Daede</name>
    </author>
    <author>
      <name>Yushin Cho</name>
    </author>
    <author>
      <name>Christopher Montgomery</name>
    </author>
    <author>
      <name>Michael Bebenita</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, accepted for multimedia signal processing (MMSP) workshop,
  2016</arxiv:comment>
    <link href="http://arxiv.org/abs/1608.01947v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.01947v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.02291v1</id>
    <updated>2016-08-08T01:10:11Z</updated>
    <published>2016-08-08T01:10:11Z</published>
    <title>Semi-Fragile Image Authentication based on CFD and 3-Bit Quantization</title>
    <summary>  There is a great adventure of watermarking usage in the context of
conventional authentication since it does not require additional storage space
for supplementary metadata. However JPEG compression, being a conventional
method to compress images, leads to exact authentication breaking. We discuss a
semi-fragile watermarking system for digital images tolerant to JPEG/JPEG2000
compression. Recently we have published a selective authentication method based
on Zernike moments. But unfortunately it has large computational complexity and
not sufficiently good detection of small image modifications. In the current
paper it is proposed (in contrast to Zernike moments approach) the usage of
image finite differences and 3-bit quantization as the main technique. In order
to embed a watermark (WM) into the image, some areas of the Haar wavelet
transform coefficients are used. Simulation results show a good resistance of
this method to JPEG compression with $\mbox{\rm CR}\leq 30\%$ (Compression
Ratio), high probability of small image modification recognition, image quality
assessments $\mbox{\rm PSNR}\geq 40$ (Peak signal-to-noise ratio) dB and
$\mbox{\rm SSIM}\geq 0.98$ (Structural Similarity Index Measure) after
embedding and lower computation complexity of WM embedding and extraction. All
these properties qualify this approach as effective.
</summary>
    <author>
      <name>Aleksey Zhuvikin</name>
    </author>
    <author>
      <name>Valery Korzhik</name>
    </author>
    <author>
      <name>Guillermo Morales-Luna</name>
    </author>
    <link href="http://arxiv.org/abs/1608.02291v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.02291v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.03016v2</id>
    <updated>2017-04-15T05:26:23Z</updated>
    <published>2016-08-10T01:11:32Z</published>
    <title>Mining Fashion Outfit Composition Using An End-to-End Deep Learning
  Approach on Set Data</title>
    <summary>  Composing fashion outfits involves deep understanding of fashion standards
while incorporating creativity for choosing multiple fashion items (e.g.,
Jewelry, Bag, Pants, Dress). In fashion websites, popular or high-quality
fashion outfits are usually designed by fashion experts and followed by large
audiences. In this paper, we propose a machine learning system to compose
fashion outfits automatically. The core of the proposed automatic composition
system is to score fashion outfit candidates based on the appearances and
meta-data. We propose to leverage outfit popularity on fashion oriented
websites to supervise the scoring component. The scoring component is a
multi-modal multi-instance deep learning system that evaluates instance
aesthetics and set compatibility simultaneously. In order to train and evaluate
the proposed composition system, we have collected a large scale fashion outfit
dataset with 195K outfits and 368K fashion items from Polyvore. Although the
fashion outfit scoring and composition is rather challenging, we have achieved
an AUC of 85% for the scoring component, and an accuracy of 77% for a
constrained composition task.
</summary>
    <author>
      <name>Yuncheng Li</name>
    </author>
    <author>
      <name>LiangLiang Cao</name>
    </author>
    <author>
      <name>Jiang Zhu</name>
    </author>
    <author>
      <name>Jiebo Luo</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TMM.2017.2690144</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TMM.2017.2690144" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE TMM</arxiv:comment>
    <link href="http://arxiv.org/abs/1608.03016v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.03016v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.05850v1</id>
    <updated>2016-08-20T17:26:15Z</updated>
    <published>2016-08-20T17:26:15Z</published>
    <title>Steganalyzer performances in operational contexts</title>
    <summary>  Steganography and steganalysis are two important branches of the information
hiding field of research. Steganography methods consist in hiding information
in such a way that the secret message is undetectable for the uninitiated.
Steganalyzis encompasses all the techniques that attempt to detect the presence
of such hidden information. This latter is usually designed by making
classifiers able to separate innocent images from steganographied ones
according to their differences on well-selected features. We wonder, in this
article whether it is possible to construct a kind of universal steganalyzer
without any knowledge regarding the steganographier side. The effects on the
classification score of a modification of either parameters or methods between
the learning and testing stages are then evaluated, while the possibility to
improve the separation score by merging many methods during learning stage is
deeper investigated.
</summary>
    <author>
      <name>Yousra A. Fadil</name>
    </author>
    <author>
      <name>Jean-François Couchot</name>
    </author>
    <author>
      <name>Raphaël Couturier</name>
    </author>
    <author>
      <name>Christophe Guyeux</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of IIH-MSP 2015, The Eleventh International Conference on
  Intelligent Information Hiding and Multimedia Signal Processing</arxiv:comment>
    <link href="http://arxiv.org/abs/1608.05850v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.05850v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.06690v2</id>
    <updated>2016-10-29T11:23:20Z</updated>
    <published>2016-08-24T02:15:06Z</published>
    <title>A Convolutional Neural Network Approach for Post-Processing in HEVC
  Intra Coding</title>
    <summary>  Lossy image and video compression algorithms yield visually annoying
artifacts including blocking, blurring, and ringing, especially at low
bit-rates. To reduce these artifacts, post-processing techniques have been
extensively studied. Recently, inspired by the great success of convolutional
neural network (CNN) in computer vision, some researches were performed on
adopting CNN in post-processing, mostly for JPEG compressed images. In this
paper, we present a CNN-based post-processing algorithm for High Efficiency
Video Coding (HEVC), the state-of-the-art video coding standard. We redesign a
Variable-filter-size Residue-learning CNN (VRCNN) to improve the performance
and to accelerate network training. Experimental results show that using our
VRCNN as post-processing leads to on average 4.6% bit-rate reduction compared
to HEVC baseline. The VRCNN outperforms previously studied networks in
achieving higher bit-rate reduction, lower memory cost, and multiplied
computational speedup.
</summary>
    <author>
      <name>Yuanying Dai</name>
    </author>
    <author>
      <name>Dong Liu</name>
    </author>
    <author>
      <name>Feng Wu</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-319-51811-4_3</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-319-51811-4_3" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">MMM 2017</arxiv:comment>
    <link href="http://arxiv.org/abs/1608.06690v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.06690v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.06770v2</id>
    <updated>2017-01-16T11:19:49Z</updated>
    <published>2016-08-24T10:17:16Z</published>
    <title>Automatic Synchronization of Multi-User Photo Galleries</title>
    <summary>  In this paper we address the issue of photo galleries synchronization, where
pictures related to the same event are collected by different users. Existing
solutions to address the problem are usually based on unrealistic assumptions,
like time consistency across photo galleries, and often heavily rely on
heuristics, limiting therefore the applicability to real-world scenarios. We
propose a solution that achieves better generalization performance for the
synchronization task compared to the available literature. The method is
characterized by three stages: at first, deep convolutional neural network
features are used to assess the visual similarity among the photos; then, pairs
of similar photos are detected across different galleries and used to construct
a graph; eventually, a probabilistic graphical model is used to estimate the
temporal offset of each pair of galleries, by traversing the minimum spanning
tree extracted from this graph. The experimental evaluation is conducted on
four publicly available datasets covering different types of events,
demonstrating the strength of our proposed method. A thorough discussion of the
obtained results is provided for a critical assessment of the quality in
synchronization.
</summary>
    <author>
      <name>E. Sansone</name>
    </author>
    <author>
      <name>K. Apostolidis</name>
    </author>
    <author>
      <name>N. Conci</name>
    </author>
    <author>
      <name>G. Boato</name>
    </author>
    <author>
      <name>V. Mezaris</name>
    </author>
    <author>
      <name>F. G. B. De Natale</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ACCEPTED to IEEE Transactions on Multimedia</arxiv:comment>
    <link href="http://arxiv.org/abs/1608.06770v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.06770v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
