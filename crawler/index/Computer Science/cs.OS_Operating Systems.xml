<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3Dall%3Acs.OS%26id_list%3D%26start%3D0%26max_results%3D500" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=all:cs.OS&amp;id_list=&amp;start=0&amp;max_results=500</title>
  <id>http://arxiv.org/api/iEAD6D8Sy7jS7oka1x1lG/MbyVU</id>
  <updated>2017-10-08T00:00:00-04:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">349</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">500</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/cs/0612079v2</id>
    <updated>2015-04-12T14:14:00Z</updated>
    <published>2006-12-16T21:37:00Z</published>
    <title>Executing the same binary on several operating systems</title>
    <summary>  We notice a way to execute a binary file on Windows and ELF-based systems. It
can be used to create software installers and other applications not exceeding
64 kilo bytes.
</summary>
    <author>
      <name>Steffen Grønneberg</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The technique is outdated</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0612079v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0612079v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0909.5064v1</id>
    <updated>2009-09-28T10:54:48Z</updated>
    <published>2009-09-28T10:54:48Z</published>
    <title>A Conceivable Origin of Machine Consciousness in the IDLE process</title>
    <summary>  In this short paper, we would like to call professional community's attention
to a daring idea that is surely unhelpful, but is exciting for programmers and
anyway conflicts with the trend of energy consumption in computer systems.
</summary>
    <author>
      <name>Norbert Bátfai</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/0909.5064v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0909.5064v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.4.7; C.2.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.6447v1</id>
    <updated>2012-10-24T07:56:48Z</updated>
    <published>2012-10-24T07:56:48Z</published>
    <title>Disk Scheduling: Selection of Algorithm</title>
    <summary>  The objective of this paper is to take some aspects of disk scheduling and
scheduling algorithms. The disk scheduling is discussed with a sneak peak in
general and selection of algorithm in particular.
</summary>
    <author>
      <name>S. Yashvir</name>
    </author>
    <author>
      <name>Om Prakash</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages; http://www.ijascse.in/publications-2012--2</arxiv:comment>
    <link href="http://arxiv.org/abs/1210.6447v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.6447v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.05798v1</id>
    <updated>2017-05-16T16:41:43Z</updated>
    <published>2017-05-16T16:41:43Z</published>
    <title>Comments on "Gang EDF Schedulability Analysis"</title>
    <summary>  This short report raises a correctness issue in the schedulability test
presented in Kato et al., "Gang EDF Scheduling of Parallel Task Systems", 30th
IEEE Real-Time Systems Symposium, 2009, pp. 459-468.
</summary>
    <author>
      <name>Pascal Richard</name>
    </author>
    <author>
      <name>Joël Goossens</name>
    </author>
    <author>
      <name>Shinpei Kato</name>
    </author>
    <link href="http://arxiv.org/abs/1705.05798v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.05798v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0809.4082v1</id>
    <updated>2008-09-24T06:10:39Z</updated>
    <published>2008-09-24T06:10:39Z</published>
    <title>Multiprocessor Global Scheduling on Frame-Based DVFS Systems</title>
    <summary>  In this ongoing work, we are interested in multiprocessor energy efficient
systems, where task durations are not known in advance, but are know
stochastically. More precisely, we consider global scheduling algorithms for
frame-based multiprocessor stochastic DVFS (Dynamic Voltage and Frequency
Scaling) systems. Moreover, we consider processors with a discrete set of
available frequencies.
</summary>
    <author>
      <name>Vandy Berten</name>
    </author>
    <author>
      <name>Joël Goossens</name>
    </author>
    <link href="http://arxiv.org/abs/0809.4082v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0809.4082v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.4.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0809.5238v1</id>
    <updated>2008-09-30T15:55:04Z</updated>
    <published>2008-09-30T15:55:04Z</published>
    <title>Mode Change Protocol for Multi-Mode Real-Time Systems upon Identical
  Multiprocessors</title>
    <summary>  In this paper, we propose a synchronous protocol without periodicity for
scheduling multi-mode real-time systems upon identical multiprocessor
platforms. Our proposal can be considered to be a multiprocessor extension of
the uniprocessor protocol called "Minimal Single Offset protocol".
</summary>
    <author>
      <name>Vincent Nélis</name>
    </author>
    <author>
      <name>Joël Goossens</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0809.5238v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0809.5238v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0908.3519v1</id>
    <updated>2009-08-25T12:46:56Z</updated>
    <published>2009-08-25T12:46:56Z</published>
    <title>Predictability of Fixed-Job Priority Schedulers on Heterogeneous
  Multiprocessor Real-Time Systems</title>
    <summary>  The multiprocessor Fixed-Job Priority (FJP) scheduling of real-time systems
is studied. An important property for the schedulability analysis, the
predictability (regardless to the execution times), is studied for
heterogeneous multiprocessor platforms. Our main contribution is to show that
any FJP schedulers are predictable on unrelated platforms. A convenient
consequence is the fact that any FJP schedulers are predictable on uniform
multiprocessors.
</summary>
    <author>
      <name>Liliana Cucu-Grosjean</name>
    </author>
    <author>
      <name>Joël Goossens</name>
    </author>
    <link href="http://arxiv.org/abs/0908.3519v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0908.3519v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1003.5525v1</id>
    <updated>2010-03-29T12:51:23Z</updated>
    <published>2010-03-29T12:51:23Z</published>
    <title>Searching publications on operating systems</title>
    <summary>  This note concerns a search for publications in which one can find statements
that explain the concept of an operating system, reasons for introducing
operating systems, a formalization of the concept of an operating system or
theory about operating systems based on such a formalization. It reports on the
way in which the search has been carried out and the outcome of the search. The
outcome includes not only what the search was meant for, but also some added
bonuses.
</summary>
    <author>
      <name>C. A. Middelburg</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1003.5525v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1003.5525v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.4.m" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1004.3687v1</id>
    <updated>2010-04-21T12:31:53Z</updated>
    <published>2010-04-21T12:31:53Z</published>
    <title>Scheduling Multi-Mode Real-Time Systems upon Uniform Multiprocessor
  Platforms</title>
    <summary>  In this paper, we address the scheduling problem of multi-mode real-time
systems upon uniform multiprocessor platforms. We propose two transition
protocols, specified together with their schedulability test, and provide the
reader with two distinct upper bounds for the length of the transient phases
during mode transitions, respectively for the cases where jobs priorities are
known and unknown beforehand.
</summary>
    <author>
      <name>Patrick Meumeu Yomsi</name>
    </author>
    <author>
      <name>Vincent Nelis</name>
    </author>
    <author>
      <name>Joël Goossens</name>
    </author>
    <link href="http://arxiv.org/abs/1004.3687v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1004.3687v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1006.0813v1</id>
    <updated>2010-06-04T09:03:39Z</updated>
    <published>2010-06-04T09:03:39Z</published>
    <title>On the definition of a theoretical concept of an operating system</title>
    <summary>  We dwell on how a definition of a theoretical concept of an operating system,
suitable to be incorporated in a mathematical theory of operating systems,
could look like. This is considered a valuable preparation for the development
of a mathematical theory of operating systems.
</summary>
    <author>
      <name>J. A. Bergstra</name>
    </author>
    <author>
      <name>C. A. Middelburg</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1006.0813v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1006.0813v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.4.0" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1110.5793v1</id>
    <updated>2011-10-26T13:53:41Z</updated>
    <published>2011-10-26T13:53:41Z</published>
    <title>Sufficient FTP Schedulability Test for the Non-Cyclic Generalized
  Multiframe Task Model</title>
    <summary>  Our goal is to provide a sufficient schedulability test -ideally polynomial-
for the scheduling of Non-Cyclic Generalized Multiframe Task Model using
Fixed-Task-Priority schedulers. We report two first results: (i) we present and
prove correct the critical instant for the Non-Cyclic Generalized Multiframe
Task Model then (ii) we propose an algorithm which provides a sufficient (but
pseudo-polynomial) schedulability test.
</summary>
    <author>
      <name>Vandy Berten</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">U.L.B</arxiv:affiliation>
    </author>
    <author>
      <name>Joël Goossens</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">U.L.B</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/1110.5793v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1110.5793v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.1687v1</id>
    <updated>2012-05-08T13:12:27Z</updated>
    <published>2012-05-08T13:12:27Z</published>
    <title>Age Based User Interface in Mobile Operating System</title>
    <summary>  This paper proposes the creation of different interfaces in the mobile
operating system for different age groups. The different age groups identified
are kids, elderly people and all others. The motive behind creating different
interfaces is to make the smartphones of today's world usable to all age
groups.
</summary>
    <author>
      <name>Sumit Sharma</name>
    </author>
    <author>
      <name>Rohitt Sharma</name>
    </author>
    <author>
      <name>Paramjit Singh</name>
    </author>
    <author>
      <name>Aditya Mahajan</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5121/ijcsea.2012.2215</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5121/ijcsea.2012.2215" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Science, Engineering and
  Applications (IJCSEA) 2,2: 177-184 April 2012</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1205.1687v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.1687v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1402.4929v1</id>
    <updated>2014-02-20T08:33:02Z</updated>
    <published>2014-02-20T08:33:02Z</published>
    <title>Formal Description of Components in Operating Systems</title>
    <summary>  The contemporary development of hardware components is a prerequisite for
increasing the concentration of computing power. System software is developing
at a much slower pace. To use available resources efficiently modeling is
required. Formalization of elements, present in the material, provides the
basis for modeling. Examples are presented to demonstrate the efficiency of the
concept.
</summary>
    <author>
      <name>Asen Petkov Iliev</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IJITEE (ISSN: 2278 - 3075, Volume-3, Issue-4, September 2013) 96 -
  98</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1402.4929v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1402.4929v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1509.07694v1</id>
    <updated>2015-09-25T12:37:09Z</updated>
    <published>2015-09-25T12:37:09Z</published>
    <title>Folding a Tree into a Map</title>
    <summary>  Analysis of the retrieval architecture of the highly influential UNIX file
system (\cite{Ritchie}\cite{multicsfs}) provides insight into design methods,
constraints, and possible alternatives. The basic architecture can be
understood in terms of function composition and recursion by anyone with some
mathematical maturity. Expertise in operating system coding or in any
specialized "formal method" is not required.
</summary>
    <author>
      <name>Victor Yodaiken</name>
    </author>
    <link href="http://arxiv.org/abs/1509.07694v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1509.07694v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.08154v1</id>
    <updated>2016-09-26T17:36:18Z</updated>
    <published>2016-09-26T17:36:18Z</published>
    <title>Implementing RBAC model in An Operating System Kernel</title>
    <summary>  In this paper, the implementation of an operating system oriented RBAC model
is discussed. Firstly, on the basis of RBAC96 model, a new RBAC model named OSR
is presented. Secondly, the OSR model is enforced in RFSOS kernel by the way of
integrating GFAC method and Capability mechanism together. All parts of the OSR
implementation are described in detail.
</summary>
    <author>
      <name>Zhiyong Shan</name>
    </author>
    <author>
      <name>Yu-fang Sun</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">in Chinese</arxiv:comment>
    <link href="http://arxiv.org/abs/1609.08154v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.08154v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9903014v1</id>
    <updated>1999-03-22T21:24:35Z</updated>
    <published>1999-03-22T21:24:35Z</published>
    <title>Perpetual Adaptation of Software to Hardware: An Extensible Architecture
  for Providing Code Optimization as a Central System Service</title>
    <summary>  We present an open architecture for just-in-time code generation and dynamic
code optimization that is flexible, customizable, and extensible. While
previous research has primarily investigated functional aspects of such a
system, architectural aspects have so far remained unexplored. In this paper,
we argue that these properties are important to generate optimal code for a
variety of hardware architectures and different processor generations within
processor families. These properties are also important to make system-level
code generation useful in practice.
</summary>
    <author>
      <name>Thomas Kistler</name>
    </author>
    <author>
      <name>Michael Franz</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">22 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/9903014v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9903014v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.3.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0111035v1</id>
    <updated>2001-11-10T03:30:11Z</updated>
    <published>2001-11-10T03:30:11Z</published>
    <title>Open Source Real Time Operating Systems Overview</title>
    <summary>  Modern control systems applications are often built on top of a real time
operating system (RTOS) which provides the necessary hardware abstraction as
well as scheduling, networking and other services. Several open source RTOS
solutions are publicly available, which is very attractive, both from an
economic (no licensing fees) as well as from a technical (control over the
source code) point of view. This contribution gives an overview of the RTLinux
and RTEMS systems (architecture, development environment, API etc.). Both
systems feature most popular CPUs, several APIs (including Posix), networking,
portability and optional commercial support. Some performance figures are
presented, focusing on interrupt latency and context switching delay.
</summary>
    <author>
      <name>Till Straumann</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Talk at ICALEPCS 2001 Conference, Nov 2001, San Jose, USA, (WEBT001),
  3 pages, LaTex</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">eConf C011127 (2001) WEBT001</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0111035v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0111035v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0309044v1</id>
    <updated>2003-09-23T13:57:01Z</updated>
    <published>2003-09-23T13:57:01Z</published>
    <title>The combinatorics of resource sharing</title>
    <summary>  We discuss general models of resource-sharing computations, with emphasis on
the combinatorial structures and concepts that underlie the various deadlock
models that have been proposed, the design of algorithms and deadlock-handling
policies, and concurrency issues. These structures are mostly graph-theoretic
in nature, or partially ordered sets for the establishment of priorities among
processes and acquisition orders on resources. We also discuss graph-coloring
concepts as they relate to resource sharing.
</summary>
    <author>
      <name>V. C. Barbosa</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-1-4757-3609-0_2</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-1-4757-3609-0_2" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">R. Correa et alii (eds.), Models for Parallel and Distributed
  Computation, pp. 27-52. Kluwer Academic Publishers, Dordrecht, The
  Netherlands, 2002</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0309044v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0309044v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.1.3; D.4.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0403013v1</id>
    <updated>2004-03-11T04:01:51Z</updated>
    <published>2004-03-11T04:01:51Z</published>
    <title>Predictable Software -- A Shortcut to Dependable Computing ?</title>
    <summary>  Many dependability techniques expect certain behaviors from the underlying
subsystems and fail in chaotic ways if these expectations are not met. Under
expected circumstances, however, software tends to work quite well. This paper
suggests that, instead of fixing elusive bugs or rewriting software, we improve
the predictability of conditions faced by our programs. This approach might be
a cheaper and faster way to improve dependability of software. After
identifying some of the common triggers of unpredictability, the paper
describes three engineering principles that hold promise in combating
unpredictability, suggests a way to benchmark predictability, and outlines a
brief research agenda.
</summary>
    <author>
      <name>George Candea</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages; submitted to 11th ACM SIGOPS European Workshop</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">WIP Session, USENIX Technical Conference, Boston, MA, June 2004</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0403013v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0403013v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.4.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0410007v2</id>
    <updated>2005-01-09T19:07:05Z</updated>
    <published>2004-10-04T14:49:00Z</published>
    <title>A Shared Write-protected Root Filesystem for a Group of Networked
  Clients</title>
    <summary>  A method to boot a cluster of diskless network clients from a single
write-protected NFS root file system is shown. The problems encountered when
first implementing the setup and their solution are discussed. Finally, the
setup is briefly compared to using a kernel-embedded root file system.
</summary>
    <author>
      <name>Ignatios Souvatzis</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented at the 2nd European BSD Conference, 2002, Amsterdam, The
  Netherlands; v2: reformatted to help citation browser</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 2nd European BSD Conference, 2002, Amsterdam,
  The Netherlands</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0410007v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0410007v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="C.2.4; D.4.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0502027v1</id>
    <updated>2005-02-04T22:48:31Z</updated>
    <published>2005-02-04T22:48:31Z</published>
    <title>Markets are Dead, Long Live Markets</title>
    <summary>  Researchers have long proposed using economic approaches to resource
allocation in computer systems. However, few of these proposals became
operational, let alone commercial. Questions persist about the economic
approach regarding its assumptions, value, applicability, and relevance to
system design. The goal of this paper is to answer these questions. We find
that market-based resource allocation is useful, and more importantly, that
mechanism design and system design should be integrated to produce systems that
are both economically and computationally efficient.
</summary>
    <author>
      <name>Kevin Lai</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Fix rotation of figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0502027v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0502027v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.4.0; D.4.7; K.6.0" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0601068v1</id>
    <updated>2006-01-14T23:21:31Z</updated>
    <published>2006-01-14T23:21:31Z</published>
    <title>Checkbochs: Use Hardware to Check Software</title>
    <summary>  In this paper, we present a system called Checkbochs, a machine simulator
that checks rules about its guest operating system and applications at the
hardware level. The properties to be checked can be implemented as `plugins' in
the Checkbochs simulator. Some of the properties that were checked using
Checkbochs include null-pointer checks, format-string vulnerabilities,
user/kernel pointer checks, and race-conditions. On implementing these checks,
we were able to uncover previously-unknown bugs in widely used Linux
distributions. We also tested our tools on undergraduate coursework, and found
numerous bugs.
</summary>
    <author>
      <name>Sorav Bansal</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0601068v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0601068v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0611055v1</id>
    <updated>2006-11-14T10:11:34Z</updated>
    <published>2006-11-14T10:11:34Z</published>
    <title>A Low-Footprint Class Loading Mechanism for Embedded Java Virtual
  Machines</title>
    <summary>  This paper shows that it is possible to dramatically reduce the memory
consumption of classes loaded in an embedded Java virtual machine without
reducing its functionalities. We describe how to pack the constant pool by
deleting entries which are only used during the class loading process. We
present some benchmarks which demonstrate the efficiency of this mechanism. We
finally suggest some additional optimizations which can be applied if some
restrictions to the functionalities of the virtual machine can be tolerated.
</summary>
    <author>
      <name>Christophe Rippert</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Futurs</arxiv:affiliation>
    </author>
    <author>
      <name>Alexandre Courbot</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Futurs</arxiv:affiliation>
    </author>
    <author>
      <name>Gilles Grimaud</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Futurs, LIFL</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Dans 3rd ACM International Conference on the Principles and
  Practice of Programming in Java (2004)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0611055v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0611055v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0706.2748v2</id>
    <updated>2007-06-20T07:31:38Z</updated>
    <published>2007-06-19T09:44:36Z</published>
    <title>A Survey of Unix Init Schemes</title>
    <summary>  In most modern operating systems, init (as in "initialization") is the
program launched by the kernel at boot time. It runs as a daemon and typically
has PID 1. Init is responsible for spawning all other processes and scavenging
zombies. It is also responsible for reboot and shutdown operations. This
document describes existing solutions that implement the init process and/or
init scripts in Unix-like systems. These solutions range from the legacy and
still-in-use BSD and SystemV schemes, to recent and promising schemes from
Ubuntu, Apple, Sun and independent developers. Our goal is to highlight their
focus and compare their sets of features.
</summary>
    <author>
      <name>Yvan Royon</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rhône-Alpes</arxiv:affiliation>
    </author>
    <author>
      <name>Stéphane Frénot</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rhône-Alpes</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/0706.2748v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0706.2748v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0709.4558v1</id>
    <updated>2007-09-28T09:04:27Z</updated>
    <published>2007-09-28T09:04:27Z</published>
    <title>Practical Multiwriter Lock-Free Queues for "Hard Real-Time" Systems
  without CAS</title>
    <summary>  FIFO queues with a single reader and writer can be insufficient for "hard
real-time" systems where interrupt handlers require wait-free guarantees when
writing to message queues. We present an algorithm which elegantly and
practically solves this problem on small processors that are often found in
embedded systems. The algorithm does not require special CPU instructions (such
as atomic CAS), and therefore is more robust than many existing methods that
suffer the ABA problem associated with swing pointers. The algorithm gives
"first-in, almost first-out" guarantees under pathological interrupt
conditions, which manifests as arbitrary "shoving" among nearly-simultaneous
arrivals at the end of the queue.
</summary>
    <author>
      <name>Jeremy Lee</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 Pages, Preprint</arxiv:comment>
    <link href="http://arxiv.org/abs/0709.4558v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0709.4558v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="E.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0710.4635v1</id>
    <updated>2007-10-25T08:09:07Z</updated>
    <published>2007-10-25T08:09:07Z</published>
    <title>OS Debugging Method Using a Lightweight Virtual Machine Monitor</title>
    <summary>  Demands for implementing original OSs that can achieve high I/O performance
on PC/AT compatible hardware have recently been increasing, but conventional OS
debugging environments have not been able to simultaneously assure their
stability, be easily customized to new OSs and new I/O devices, and assure
efficient execution of I/O operations. We therefore developed a novel OS
debugging method using a lightweight virtual machine. We evaluated this
debugging method experimentally and confirmed that it can transfer data about
5.4 times as fast as the conventional virtual machine monitor.
</summary>
    <author>
      <name>Tadashi Takeuchi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted on behalf of EDAA (http://www.edaa.com/)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0710.4635v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0710.4635v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0710.4746v1</id>
    <updated>2007-10-25T09:47:35Z</updated>
    <published>2007-10-25T09:47:35Z</published>
    <title>RTK-Spec TRON: A Simulation Model of an ITRON Based RTOS Kernel in
  SystemC</title>
    <summary>  This paper presents the methodology and the modeling constructs we have
developed to capture the real time aspects of RTOS simulation models in a
System Level Design Language (SLDL) like SystemC. We describe these constructs
and show how they are used to build a simulation model of an RTOS kernel
targeting the $\mu$-ITRON OS specification standard.
</summary>
    <author>
      <name>M. Abdelsalam Hassan</name>
    </author>
    <author>
      <name>Keishi Sakanushi</name>
    </author>
    <author>
      <name>Yoshinori Takeuchi</name>
    </author>
    <author>
      <name>Masaharu Imai</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted on behalf of EDAA (http://www.edaa.com/)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0710.4746v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0710.4746v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0712.2958v2</id>
    <updated>2008-03-10T16:10:50Z</updated>
    <published>2007-12-18T13:42:45Z</published>
    <title>Power-Aware Real-Time Scheduling upon Identical Multiprocessor Platforms</title>
    <summary>  In this paper, we address the power-aware scheduling of sporadic
constrained-deadline hard real-time tasks using dynamic voltage scaling upon
multiprocessor platforms. We propose two distinct algorithms. Our first
algorithm is an off-line speed determination mechanism which provides an
identical speed for each processor. That speed guarantees that all deadlines
are met if the jobs are scheduled using EDF. The second algorithm is an on-line
and adaptive speed adjustment mechanism which reduces the energy consumption
while the system is running.
</summary>
    <author>
      <name>Vincent Nélis</name>
    </author>
    <author>
      <name>Joël Goossens</name>
    </author>
    <author>
      <name>Nicolas Navet</name>
    </author>
    <author>
      <name>Raymond Devillers</name>
    </author>
    <author>
      <name>Dragomir Milojevic</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The manuscript corresponds to the final version of SUTC 2008
  conference</arxiv:comment>
    <link href="http://arxiv.org/abs/0712.2958v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0712.2958v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0805.0200v2</id>
    <updated>2008-09-08T09:22:24Z</updated>
    <published>2008-05-02T09:32:03Z</published>
    <title>(m,k)-firm constraints and DBP scheduling: impact of the initial
  k-sequence and exact schedulability test</title>
    <summary>  In this paper we study the scheduling of (m,k)-firm synchronous periodic task
systems using the Distance Based Priority (DBP) scheduler. We first show three
phenomena: (i) choosing, for each task, the initial k-sequence 1^k is not
optimal, (ii) we can even start the scheduling from a (fictive) error state (in
regard to the initial k-sequence) and (iii) the period of feasible
DBP-schedules is not necessarily the task hyper-period. We then show that any
feasible DBP-schedule is periodic and we upper-bound the length of that period.
Lastly, based on our periodicity result we provide an exact schedulability
test.
</summary>
    <author>
      <name>Joël Goossens</name>
    </author>
    <link href="http://arxiv.org/abs/0805.0200v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0805.0200v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0805.3237v1</id>
    <updated>2008-05-21T09:38:15Z</updated>
    <published>2008-05-21T09:38:15Z</published>
    <title>Integrating Job Parallelism in Real-Time Scheduling Theory</title>
    <summary>  We investigate the global scheduling of sporadic, implicit deadline,
real-time task systems on multiprocessor platforms. We provide a task model
which integrates job parallelism. We prove that the time-complexity of the
feasibility problem of these systems is linear relatively to the number of
(sporadic) tasks for a fixed number of processors. We propose a scheduling
algorithm theoretically optimal (i.e., preemptions and migrations neglected).
Moreover, we provide an exact feasibility utilization bound. Lastly, we propose
a technique to limit the number of migrations and preemptions.
</summary>
    <author>
      <name>S. Collette</name>
    </author>
    <author>
      <name>L. Cucu</name>
    </author>
    <author>
      <name>J. Goossens</name>
    </author>
    <link href="http://arxiv.org/abs/0805.3237v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0805.3237v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0807.3933v1</id>
    <updated>2008-07-24T17:51:07Z</updated>
    <published>2008-07-24T17:51:07Z</published>
    <title>Interface Matching and Combining Techniques for Services Integration</title>
    <summary>  The development of many highly dynamic environments, like pervasive
environments, introduces the possibility to use geographically close-related
services. Dynamically integrating and unintegrating these services in running
applications is a key challenge for this use. In this article, we classify
service integration issues according to interfaces exported by services and
internal combining techniques. We also propose a contextual integration
service, IntegServ, and an interface, Integrable, for developing services.
</summary>
    <author>
      <name>Frédéric Le Mouël</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rhône-Alpes / CITI</arxiv:affiliation>
    </author>
    <author>
      <name>Noha Ibrahim</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rhône-Alpes / CITI</arxiv:affiliation>
    </author>
    <author>
      <name>Stéphane Frénot</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rhône-Alpes / CITI</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Dans 3er Congreso Nacional de Ciencias de la Computacion
  (CNCC'2005) (2005)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0807.3933v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0807.3933v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0906.0268v1</id>
    <updated>2009-06-01T12:10:10Z</updated>
    <published>2009-06-01T12:10:10Z</published>
    <title>MORA: an Energy-Aware Slack Reclamation Scheme for Scheduling Sporadic
  Real-Time Tasks upon Multiprocessor Platforms</title>
    <summary>  In this paper, we address the global and preemptive energy-aware scheduling
problem of sporadic constrained-deadline tasks on DVFS-identical multiprocessor
platforms. We propose an online slack reclamation scheme which profits from the
discrepancy between the worst- and actual-case execution time of the tasks by
slowing down the speed of the processors in order to save energy. Our algorithm
called MORA takes into account the application-specific consumption profile of
the tasks. We demonstrate that MORA does not jeopardize the system
schedulability and we show by performing simulations that it can save up to 32%
of energy (in average) compared to execution without using any energy-aware
algorithm.
</summary>
    <author>
      <name>Vincent Nelis</name>
    </author>
    <author>
      <name>Joel Goossens</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/0906.0268v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0906.0268v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0910.5577v1</id>
    <updated>2009-10-29T08:38:32Z</updated>
    <published>2009-10-29T08:38:32Z</published>
    <title>On the stability of two-chunk file-sharing systems</title>
    <summary>  We consider five different peer-to-peer file sharing systems with two chunks,
with the aim of finding chunk selection algorithms that have provably stable
performance with any input rate and assuming non-altruistic peers who leave the
system immediately after downloading the second chunk. We show that many
algorithms that first looked promising lead to unstable or oscillating
behavior. However, we end up with a system with desirable properties. Most of
our rigorous results concern the corresponding deterministic large system
limits, but in two simplest cases we provide proofs for the stochastic systems
also.
</summary>
    <author>
      <name>Ilkka Norros</name>
    </author>
    <author>
      <name>Hannu Reittu</name>
    </author>
    <author>
      <name>Timo Eirola</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0910.5577v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0910.5577v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="60K25, 68M14" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0912.4062v1</id>
    <updated>2009-12-20T23:49:25Z</updated>
    <published>2009-12-20T23:49:25Z</published>
    <title>Process Description of COM Object Life Cycle</title>
    <summary>  The objective of this article is to provide for the reader a basic
description of all the steps involved in the COM object life-cycle process. COM
is a software technology and process performer. The first section briefly
introduces the Component Object Model (COM), considering the process of the COM
object life cycle as the baseline of all COM issues. The second part describes
in detail the basic steps of the process - client request, server location,
object creation, interaction, and disconnection. A brief description is given
for the components involved in each step. Finally, the third section provides a
brief conclusion summarizing all the process steps.
</summary>
    <author>
      <name>Emil Vassev</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0912.4062v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0912.4062v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1001.3727v1</id>
    <updated>2010-01-21T06:02:41Z</updated>
    <published>2010-01-21T06:02:41Z</published>
    <title>Fault Tolerance in Real Time Multiprocessors - Embedded Systems</title>
    <summary>  All real time tasks which are termed as critical tasks by nature have to
complete its execution before its deadline, even in presence of faults. The
most popularly used real time task assignment algorithms are First Fit (FF),
Best Fit (BF), Bin Packing (BP).The common task scheduling algorithms are Rate
Monotonic (RM), Earliest Deadline First (EDF) etc.All the current approaches
deal with either fault tolerance or criticality in real time. In this paper we
have proposed an integrated approach with a new algorithm, called SASA (Sorting
And Sequential Assignment) which maps the real time task assignment with task
schedule and fault tolerance
</summary>
    <author>
      <name>A. Christy Persya</name>
    </author>
    <author>
      <name>T. R. Gopalakrishnan Nair</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Fourth Innovative Conference on Embedded Systems, Mobile
  Communication and Computing, 2009</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1001.3727v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1001.3727v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1003.1336v2</id>
    <updated>2010-03-09T13:02:01Z</updated>
    <published>2010-03-05T20:34:44Z</published>
    <title>FIFO anomaly is unbounded</title>
    <summary>  Virtual memory of computers is usually implemented by demand paging. For some
page replacement algorithms the number of page faults may increase as the
number of page frames increases. Belady, Nelson and Shedler constructed
reference strings for which page replacement algorithm FIFO produces near twice
more page faults in a larger memory than in a smaller one. They formulated the
conjecture that 2 is a general bound. We prove that this ratio can be
arbitrarily large.
</summary>
    <author>
      <name>Peter Fornai</name>
    </author>
    <author>
      <name>Antal Ivanyi</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Acta Univ. Sapientiae, Informatica, 2,1 (2010) 80-89</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1003.1336v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1003.1336v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.2.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1006.2104v1</id>
    <updated>2010-06-10T18:13:36Z</updated>
    <published>2010-06-10T18:13:36Z</published>
    <title>Perbandingan Shell Unix</title>
    <summary>  Is it possible for an Information Technology [IT] product to be both mature
and state-of-theart at the same time? In the case of the UNIX system, the
answer is an unqualified "Yes." The UNIX system has continued to develop over
the past twenty-five years. In millions of installations running on nearly
every hardware platform made, the UNIX system has earned its reputation for
stability and scalability. Over the years, UNIX system suppliers have steadily
assimilated new technologies so that UNIX systems today provide more
functionality as any other operating system.
</summary>
    <author>
      <name>Spits Warnars H. L. H</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 Pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Widya, Vol 21,No. 230, pp. 9-15, November 2004</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1006.2104v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1006.2104v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.4.0" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1006.2617v1</id>
    <updated>2010-06-14T07:17:14Z</updated>
    <published>2010-06-14T07:17:14Z</published>
    <title>Gang FTP scheduling of periodic and parallel rigid real-time tasks</title>
    <summary>  In this paper we consider the scheduling of periodic and parallel rigid
tasks. We provide (and prove correct) an exact schedulability test for Fixed
Task Priority (FTP) Gang scheduler sub-classes: Parallelism Monotonic, Idling,
Limited Gang, and Limited Slack Reclaiming. Additionally, we study the
predictability of our schedulers: we show that Gang FJP schedulers are not
predictable and we identify several sub-classes which are actually predictable.
Moreover, we extend the definition of rigid, moldable and malleable jobs to
recurrent tasks.
</summary>
    <author>
      <name>Joël Goossens</name>
    </author>
    <author>
      <name>Vandy Berten</name>
    </author>
    <link href="http://arxiv.org/abs/1006.2617v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1006.2617v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.1717v1</id>
    <updated>2011-03-09T07:25:00Z</updated>
    <published>2011-03-09T07:25:00Z</published>
    <title>Efficient and Playful Tools to Teach Unix to New Students</title>
    <summary>  Teaching Unix to new students is a common tasks in many higher schools. This
paper presents an approach to such course where the students progress
autonomously with the help of the teacher. The traditional textbook is
complemented with a wiki, and the main thread of the course is a game, in the
form of a treasure hunt. The course finishes with a lab exam, where students
have to perform practical manipulations similar to the ones performed during
the treasure hunt. The exam is graded fully automatically. This paper discusses
the motivations and advantages of the approach, and gives an overall view of
the tools we developed. The tools are available from the web, and open-source,
hence re-usable outside the Ensimag.
</summary>
    <author>
      <name>Matthieu Moy</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">VERIMAG - IMAG</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ITiCSE, Darmstadt : Germany (2011)</arxiv:comment>
    <link href="http://arxiv.org/abs/1103.1717v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.1717v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1104.2110v1</id>
    <updated>2011-04-12T04:06:34Z</updated>
    <published>2011-04-12T04:06:34Z</published>
    <title>Deterministic Real-time Thread Scheduling</title>
    <summary>  Race condition is a timing sensitive problem. A significant source of timing
variation comes from nondeterministic hardware interactions such as cache
misses. While data race detectors and model checkers can check races, the
enormous state space of complex software makes it difficult to identify all of
the races and those residual implementation errors still remain a big
challenge. In this paper, we propose deterministic real-time scheduling methods
to address scheduling nondeterminism in uniprocessor systems. The main idea is
to use timing insensitive deterministic events, e.g, an instruction counter, in
conjunction with a real-time clock to schedule threads. By introducing the
concept of Worst Case Executable Instructions (WCEI), we guarantee both
determinism and real-time performance.
</summary>
    <author>
      <name>Heechul Yun</name>
    </author>
    <author>
      <name>Cheolgi Kim</name>
    </author>
    <author>
      <name>Lui Sha</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">RTAS11 Work-In-Progress</arxiv:comment>
    <link href="http://arxiv.org/abs/1104.2110v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1104.2110v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1104.3523v1</id>
    <updated>2011-04-18T15:39:21Z</updated>
    <published>2011-04-18T15:39:21Z</published>
    <title>An Optimal Real-Time Scheduling Approach: From Multiprocessor to
  Uniprocessor</title>
    <summary>  An optimal solution to the problem of scheduling real-time tasks on a set of
identical processors is derived. The described approach is based on solving an
equivalent uniprocessor real-time scheduling problem. Although there are other
scheduling algorithms that achieve optimality, they usually impose prohibitive
preemption costs. Unlike these algorithms, it is observed through simulation
that the proposed approach produces no more than three preemptions points per
job.
</summary>
    <author>
      <name>Paul Regnier</name>
    </author>
    <author>
      <name>George Lima</name>
    </author>
    <author>
      <name>Ernesto Massa</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages - rejected for publication by ECRTS 2011</arxiv:comment>
    <link href="http://arxiv.org/abs/1104.3523v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1104.3523v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="98B35, 68M20" scheme="http://arxiv.org/schemas/atom"/>
    <category term="C.3.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1105.5080v1</id>
    <updated>2011-05-25T16:15:35Z</updated>
    <published>2011-05-25T16:15:35Z</published>
    <title>Scheduling of Hard Real-Time Multi-Thread Periodic Tasks</title>
    <summary>  In this paper we study the scheduling of parallel and real-time recurrent
tasks. Firstly, we propose a new parallel task model which allows recurrent
tasks to be composed of several threads, each thread requires a single
processor for execution and can be scheduled simultaneously. Secondly, we
define several kinds of real-time schedulers that can be applied to our
parallel task model. We distinguish between two scheduling classes:
hierarchical schedulers and global thread schedulers. We present and prove
correct an exact schedulability test for each class. Lastly, we also evaluate
the performance of our scheduling paradigm in comparison with Gang scheduling
by means of simulations.
</summary>
    <author>
      <name>Irina Iulia Lupu</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">U.L.B.</arxiv:affiliation>
    </author>
    <author>
      <name>Joël Goossens</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">U.L.B.</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/1105.5080v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1105.5080v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1109.3075v1</id>
    <updated>2011-09-14T13:26:07Z</updated>
    <published>2011-09-14T13:26:07Z</published>
    <title>Design and Performance Evaluation of A New Proposed Fittest Job First
  Dynamic Round Robin(FJFDRR) Scheduling Algorithm</title>
    <summary>  In this paper, we have proposed a new variant of Round Robin scheduling
algorithm by executing the processes according to the new calculated Fit Factor
f and using the concept of dynamic time quantum. We have compared the
performance of our proposed Fittest Job First Dynamic Round Robin(FJFDRR)
algorithm with the Priority Based Static Round Robin(PBSRR) algorithm.
Experimental results show that our proposed algorithm performs better than
PBSRR in terms of reducing the number of context switches, average waiting time
and average turnaround time.
</summary>
    <author>
      <name>Rakesh Mohanty</name>
    </author>
    <author>
      <name>Manas Das</name>
    </author>
    <author>
      <name>M. Lakshmi Prasanna</name>
    </author>
    <author>
      <name> Sudhashree</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">05 Pages, 12 Figures, International Journal of Computer Information
  Systems Vol. 2, No. 2, February 2011</arxiv:comment>
    <link href="http://arxiv.org/abs/1109.3075v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1109.3075v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.6423v1</id>
    <updated>2012-05-29T17:10:29Z</updated>
    <published>2012-05-29T17:10:29Z</published>
    <title>Proposed Challenges And Areas of Concern in Operating System Research
  and Development</title>
    <summary>  Computers are a very important part of our lives and the major reason why
they have been such a success is because of the excellent graphical operating
systems that run on these powerful machines. As the computer hardware is
becoming more and more powerful, it is also vital to keep the software updated
in order to utilize the hardware of the system efficiently and make it faster
and smarter. This paper highlights some core issues that if dealt with in the
operating system level would make use of the full potential of the computer
hardware and provide an excellent user experience.
</summary>
    <author>
      <name>Plawan Kumar Rath</name>
    </author>
    <author>
      <name>G. N. Anil</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages; International Journal for Computer Science Issues(IJCSI),
  Volume 9, Issue 2, March 2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1205.6423v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.6423v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1208.6390v1</id>
    <updated>2012-08-31T06:31:48Z</updated>
    <published>2012-08-31T06:31:48Z</published>
    <title>Performance Evaluation of Flash File Systems</title>
    <summary>  Today, flash memory are strongly used in the embedded system domain. NAND
flash memories are the building block of main secondary storage systems. Such
memories present many benefits in terms of data density, I/O performance, shock
resistance and power consumption. Nevertheless, flash does not come without
constraints: the write / erase granularity asymmetry and the limited lifetime
bring the need for specific management. This can be done through the operating
system using dedicated Flash File Systems (FFSs). In this document, we present
general concepts about FFSs, and implementations example that are JFFS2, YAFFS2
and UBIFS, the most commonly used flash file systems. Then we give performance
evaluation results for these FFSs.
</summary>
    <author>
      <name>Pierre Olivier</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Lab-STICC</arxiv:affiliation>
    </author>
    <author>
      <name>Jalil Boukhobza</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Lab-STICC</arxiv:affiliation>
    </author>
    <author>
      <name>Eric Senn</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Lab-STICC</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Colloque du GDR SoC-SiP, Paris : France (2012)</arxiv:comment>
    <link href="http://arxiv.org/abs/1208.6390v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1208.6390v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.3502v1</id>
    <updated>2012-12-14T15:33:45Z</updated>
    <published>2012-12-14T15:33:45Z</published>
    <title>Adaptive Scheduling in Real-Time Systems Through Period Adjustment</title>
    <summary>  Real time system technology traditionally developed for safety critical
systems, has now been extended to support multimedia systems and virtual
reality. A large number of real-time application, related to multimedia and
adaptive control system, require more flexibility than classical real-time
theory usually permits. This paper proposes an efficient adaptive scheduling
framework in real-time systems based on period adjustment. Under this model
periodic task can change their execution rates based on their importance value
to keep the system underloaded. We propose Period_Adjust algorithm, which
consider the tasks whose periods are bounded as well as the tasks whose periods
are not bounded.
</summary>
    <author>
      <name>Shri Prakash Dwivedi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1212.3502v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.3502v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1302.1747v1</id>
    <updated>2013-02-07T13:52:09Z</updated>
    <published>2013-02-07T13:52:09Z</published>
    <title>Energy Minimization for Parallel Real-Time Systems with Malleable Jobs
  and Homogeneous Frequencies</title>
    <summary>  In this work, we investigate the potential utility of parallelization for
meeting real-time constraints and minimizing energy. We consider malleable Gang
scheduling of implicit-deadline sporadic tasks upon multiprocessors. We first
show the non-necessity of dynamic voltage/frequency regarding optimality of our
scheduling problem. We adapt the canonical schedule for DVFS multiprocessor
platforms and propose a polynomial-time optimal processor/frequency-selection
algorithm. We evaluate the performance of our algorithm via simulations using
parameters obtained from a hardware testbed implementation. Our algorithm has
up to a 60 watt decrease in power consumption over the optimal non-parallel
approach.
</summary>
    <author>
      <name>Nathan Fisher</name>
    </author>
    <author>
      <name>Joël Goossens</name>
    </author>
    <author>
      <name>Pradeep M. Hettiarachchi</name>
    </author>
    <author>
      <name>Antonio Paolillo</name>
    </author>
    <link href="http://arxiv.org/abs/1302.1747v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1302.1747v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1302.5109v1</id>
    <updated>2013-02-20T15:50:29Z</updated>
    <published>2013-02-20T15:50:29Z</published>
    <title>Capturing Information Flows inside Android and Qemu Environments</title>
    <summary>  The smartphone market has grown so wide that it assumed a strategic
relevance. Today the most common smartphone OSs are Google's Android and
Apple's iOS. The former is particularly interesting due to its open source
nature, that allows everyone to deeply inspect every aspect of the OS. Android
source code is also bundled with an hardware emulator, based on the open source
software Qemu, that allows the user to run the Android OS without the need of a
physical device. We first present a procedure to extract information flows from
a generic system. We then focus on Android and Qemu architectures and their
logging infrastructures. Finally, we detail what happens inside an Android
device in a particular scenario: the system boot.
</summary>
    <author>
      <name>Marco Sironi</name>
    </author>
    <author>
      <name>Francesco Tisato</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1302.5109v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1302.5109v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1305.3849v1</id>
    <updated>2013-05-16T15:54:12Z</updated>
    <published>2013-05-16T15:54:12Z</published>
    <title>On the periodic behavior of real-time schedulers on identical
  multiprocessor platforms</title>
    <summary>  This paper is proposing a general periodicity result concerning any
deterministic and memoryless scheduling algorithm (including
non-work-conserving algorithms), for any context, on identical multiprocessor
platforms. By context we mean the hardware architecture (uniprocessor,
multicore), as well as task constraints like critical sections, precedence
constraints, self-suspension, etc. Since the result is based only on the
releases and deadlines, it is independent from any other parameter. Note that
we do not claim that the given interval is minimal, but it is an upper bound
for any cycle of any feasible schedule provided by any deterministic and
memoryless scheduler.
</summary>
    <author>
      <name>Emmanuel Grolleau</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIAS-ISAE/ENSMA</arxiv:affiliation>
    </author>
    <author>
      <name>Joël Goossens</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">ULB</arxiv:affiliation>
    </author>
    <author>
      <name>Liliana Cucu-Grosjean</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/1305.3849v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1305.3849v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1311.3322v1</id>
    <updated>2013-11-13T22:05:58Z</updated>
    <published>2013-11-13T22:05:58Z</published>
    <title>Impact of Limpware on HDFS: A Probabilistic Estimation</title>
    <summary>  With the advent of cloud computing, thousands of machines are connected and
managed collectively. This era is confronted with a new challenge: performance
variability, primarily caused by large-scale management issues such as hardware
failures, software bugs, and configuration mistakes. In our previous work we
highlighted one overlooked cause: limpware - hardware whose performance
degrades significantly compared to its specification. We showed that limpware
can cause severe impact in current scale-out systems. In this report, we
quantify how often these scenarios happen in Hadoop Distributed File System.
</summary>
    <author>
      <name>Thanh Do</name>
    </author>
    <author>
      <name>Haryadi S. Gunawi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 6 figures, detailed probability calculation for SOCC 13
  limplock paper</arxiv:comment>
    <link href="http://arxiv.org/abs/1311.3322v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1311.3322v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1312.4509v1</id>
    <updated>2013-12-16T20:32:52Z</updated>
    <published>2013-12-16T20:32:52Z</published>
    <title>Cache-aware static scheduling for hard real-time multicore systems based
  on communication affinities</title>
    <summary>  The growing need for continuous processing capabilities has led to the
development of multicore systems with a complex cache hierarchy. Such multicore
systems are generally designed for improving the performance in average case,
while hard real-time systems must consider worst-case scenarios. An open
challenge is therefore to efficiently schedule hard real-time tasks on a
multicore architecture. In this work, we propose a mathematical formulation for
computing a static scheduling that minimize L1 data cache misses between hard
real-time tasks on a multicore architecture using communication affinities.
</summary>
    <author>
      <name>Lilia Zaourar</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIST</arxiv:affiliation>
    </author>
    <author>
      <name>Mathieu Jan</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIST</arxiv:affiliation>
    </author>
    <author>
      <name>Maurice Pitel</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">34th IEEE Real-Time Systems Symposium (RTSS'13), WiP session,
  Vancouver : Canada (2013)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1312.4509v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1312.4509v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1402.0631v1</id>
    <updated>2014-02-04T06:26:34Z</updated>
    <published>2014-02-04T06:26:34Z</published>
    <title>LWRP: Low Power Consumption Weighting Replacement Policy using Buffer
  Memory</title>
    <summary>  As the performance gap between memory and processors has increased, then it
leads to the poor performance. Efficient virtual memory can overcome this
problem. And the efficiency of virtual memory depends on the replacement policy
used for cache. In this paper, our algorithm not only based on the time to last
access and frequency index but, we also consider the power consumption. We show
that Low Power Consumption Weighting Replacement Policy (LWRP) has better
performance and low power consumption.
</summary>
    <author>
      <name>S. R. Bhalgama</name>
    </author>
    <author>
      <name>C. C. Kavar</name>
    </author>
    <author>
      <name>S. S. Parmar</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.14445/22312803/IJCTT-V7P142</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.14445/22312803/IJCTT-V7P142" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 2 figures, Published with International Journal of Computer
  Trends and Technology (IJCTT)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IJCTT 7(3):147-150, January 2014. Published by Seventh Sense
  Research Group</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1402.0631v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1402.0631v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1408.0990v1</id>
    <updated>2014-08-02T19:56:24Z</updated>
    <published>2014-08-02T19:56:24Z</published>
    <title>Assessment of Response Time for New Multi Level Feedback Queue Scheduler</title>
    <summary>  Response time is one of the characteristics of scheduler, happens to be a
prominent attribute of any CPU scheduling algorithm. The proposed New Multi
Level Feedback Queue [NMLFQ] Scheduler is compared with dynamic, real time,
Dependent Activity Scheduling Algorithm (DASA) and Lockes Best Effort
Scheduling Algorithm (LBESA). We abbreviated beneficial result of NMLFQ
scheduler in comparison with dynamic best effort schedulers with respect to
response time.
</summary>
    <author>
      <name>M. V. Panduranga Rao</name>
    </author>
    <author>
      <name>K. C. Shet</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.14445/22312803/IJCTT-V13P124</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.14445/22312803/IJCTT-V13P124" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 5 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Trends and Technology (IJCTT),
  Volume 13, Number 3, Pages: 113-119, July 2014. ISSN:2231-2803</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1408.0990v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1408.0990v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68U20" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.3.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.01509v1</id>
    <updated>2015-02-05T11:36:45Z</updated>
    <published>2015-02-05T11:36:45Z</published>
    <title>OS-level Failure Injection with SystemTap</title>
    <summary>  Failure injection in distributed systems has been an important issue to
experiment with robust, resilient distributed systems. In order to reproduce
real-life conditions, parts of the application must be killed without letting
the operating system close the existing network communications in a "clean"
way. When a process is simply killed, the OS closes them. SystemTap is a an
infrastructure that probes the Linux kernel's internal calls. If processes are
killed at kernel-level, they can be destroyed without letting the OS do
anything else. In this paper, we present a kernel-level failure injection
system based on SystemTap. We present how it can be used to implement
deterministic and probabilistic failure scenarios.
</summary>
    <author>
      <name>Camille Coti</name>
    </author>
    <author>
      <name>Nicolas Greneche</name>
    </author>
    <link href="http://arxiv.org/abs/1502.01509v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.01509v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.02517v2</id>
    <updated>2015-04-13T13:39:37Z</updated>
    <published>2015-04-09T23:17:01Z</published>
    <title>Survey of Operating Systems for the IoT Environment</title>
    <summary>  This paper is a comprehensive survey of the various operating systems
available for the Internet of Things environment. At first the paper introduces
the various aspects of the operating systems designed for the IoT environment
where resource constraint poses a huge problem for the operation of the general
OS designed for the various computing devices. The latter part of the paper
describes the various OS available for the resource constraint IoT environment
along with the various platforms each OS supports, the software development
kits available for the development of applications in the respective OS along
with the various protocols implemented in these OS for the purpose of
communication and networking.
</summary>
    <author>
      <name>Tuhin Borgohain</name>
    </author>
    <author>
      <name>Uday Kumar</name>
    </author>
    <author>
      <name>Sugata Sanyal</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 7 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1504.02517v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.02517v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1512.01984v2</id>
    <updated>2016-03-10T11:04:54Z</updated>
    <published>2015-12-07T11:16:43Z</published>
    <title>Parallel and sequential reclaiming in multicore real-time global
  scheduling</title>
    <summary>  When integrating hard, soft and non-real-time tasks in general purpose
operating systems, it is necessary to provide temporal isolation so that the
timing properties of one task do not depend on the behaviour of the others.
However, strict budget enforcement can lead to inefficient use of the
computational resources in the presence of tasks with variable workload. Many
resource reclaiming algorithms have been proposed in the literature for single
processor scheduling, but not enough work exists for global scheduling in
multiprocessor systems. In this report, we propose two reclaiming algorithms
for multiprocessor global scheduling and we prove their correctness.
</summary>
    <author>
      <name>Luca Abeni</name>
    </author>
    <author>
      <name>Giuseppe Lipari</name>
    </author>
    <author>
      <name>Andrea Parri</name>
    </author>
    <author>
      <name>Youcheng Sun</name>
    </author>
    <link href="http://arxiv.org/abs/1512.01984v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1512.01984v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1512.06908v1</id>
    <updated>2015-12-21T23:35:42Z</updated>
    <published>2015-12-21T23:35:42Z</published>
    <title>Research on Scalability of Operating Systems on Multicore Processors</title>
    <summary>  Large number of cores and hardware resource sharing are two characteristics
on multicore processors, which bring new challenges for the design of operating
systems. How to locate and analyze the speedup restrictive factors in operating
systems, how to simulate and avoid the phenomenon that speedup decreases with
the number of cores because of lock contention (i.e., lock thrashing) and how
to avoid the contention of shared resources such as the last level cache are
key challenges for the operating system scalability research on multicore
systems.
</summary>
    <author>
      <name>Yan Cui</name>
    </author>
    <link href="http://arxiv.org/abs/1512.06908v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1512.06908v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.05810v1</id>
    <updated>2016-05-19T05:03:00Z</updated>
    <published>2016-05-19T05:03:00Z</published>
    <title>The Design of the NetBSD I/O Subsystems</title>
    <summary>  This book describes the source code of the NetBSD Operating System Release
1.6 in SUN UltraSPARC 64-bit platform by annotating related excerpts from
references and user manuals on the NetBSD Operating System. The goal of this
book is to provide necessary information to understand the operation and the
implementation of I/O subsystems in the kernel as well as to design and
implement a new filesystem on the NetBSD platform.
</summary>
    <author>
      <name>SungWon Chung</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This arXiv archival version is the same as the initial 2002 release
  of this publication except updates in preface and few corrections on typos
  and contact information</arxiv:comment>
    <link href="http://arxiv.org/abs/1605.05810v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.05810v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.00111v2</id>
    <updated>2016-06-02T05:32:46Z</updated>
    <published>2016-06-01T04:29:58Z</published>
    <title>It's Time: OS Mechanisms for Enforcing Asymmetric Temporal Integrity</title>
    <summary>  Mixed-criticality systems combine real-time components of different levels of
criticality, i.e. severity of failure, on the same processor, in order to
obtain good resource utilisation. They must guarantee deadlines of
highly-critical tasks at the expense of lower-criticality ones in the case of
overload. Present operating systems provide inadequate support for this kind of
system, which is of growing importance in avionics and other verticals. We
present an approach that provides the required asymmetric integrity and its
implementation in the high-assurance seL4 microkernel.
</summary>
    <author>
      <name>Anna Lyons</name>
    </author>
    <author>
      <name>Gernot Heiser</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Paper submitted to OSDI 2016</arxiv:comment>
    <link href="http://arxiv.org/abs/1606.00111v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.00111v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1704.01198v1</id>
    <updated>2017-04-04T21:43:04Z</updated>
    <published>2017-04-04T21:43:04Z</published>
    <title>Tackling Diversity and Heterogeneity by Vertical Memory Management</title>
    <summary>  Existing memory management mechanisms used in commodity computing machines
typically adopt hardware based address interleaving and OS directed random
memory allocation to service generic application requests. These conventional
memory management mechanisms are challenged by contention at multiple memory
levels, a daunting variety of workload behaviors, and an increasingly
complicated memory hierarchy. Our ISCA-41 paper proposes vertical partitioning
to eliminate shared resource contention at multiple levels in the memory
hierarchy. Combined with horizontal memory management policies, our framework
supports a flexible policy space for tackling diverse application needs in
production environment and is suitable for future heterogeneous memory systems.
</summary>
    <author>
      <name>Lei Liu</name>
    </author>
    <link href="http://arxiv.org/abs/1704.01198v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1704.01198v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1706.02621v1</id>
    <updated>2017-05-26T16:39:55Z</updated>
    <published>2017-05-26T16:39:55Z</published>
    <title>Design and Implementation of Modified Fuzzy based CPU Scheduling
  Algorithm</title>
    <summary>  CPU Scheduling is the base of multiprogramming. Scheduling is a process which
decides order of task from a set of multiple tasks that are ready to execute.
There are number of CPU scheduling algorithms available, but it is very
difficult task to decide which one is better. This paper discusses the design
and implementation of modified fuzzy based CPU scheduling algorithm. This paper
present a new set of fuzzy rules. It demonstrates that scheduling done with new
priority improves average waiting time and average turnaround time.
</summary>
    <author>
      <name>Rajani Kumari</name>
    </author>
    <author>
      <name>Vivek Kumar Sharma</name>
    </author>
    <author>
      <name>Sandeep Kumar</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5120/13612-1323 10.5120/13612-1323 10.5120/13612-1323
  10.5120/13612-1323</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5120/13612-1323" rel="related"/>
    <link title="doi" href="http://dx.doi.org/10.5120/13612-1323" rel="related"/>
    <link title="doi" href="http://dx.doi.org/10.5120/13612-1323" rel="related"/>
    <link title="doi" href="http://dx.doi.org/" rel="related"/>
    <link title="doi" href="http://dx.doi.org/" rel="related"/>
    <link title="doi" href="http://dx.doi.org/10.5120/13612-1323" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 Pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Applications, Volume 77, No 17,
  September 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1706.02621v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1706.02621v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.06450v1</id>
    <updated>2017-08-21T23:10:59Z</updated>
    <published>2017-08-21T23:10:59Z</published>
    <title>Entirely protecting operating systems against transient errors in space
  environment</title>
    <summary>  In this article, we propose a mainly-software hardening technique to totally
protect unmodified running operating systems on COTS hardware against transient
errors in heavily radiation - flooded environment like high altitude space. The
technique is currently being implemented in a hypervisor and allows to control
the upper layers of the software stack (operating system and applications). The
rest of the system, the hypervisor, will be protected by other means, thus
resulting in a completely protected system against transient errors. The
induced overhead turns around 200% but this is expected to decrease with future
improvements.
</summary>
    <author>
      <name>Mahoukpégo Parfait Tokponnon</name>
    </author>
    <author>
      <name>Marc Lobelle</name>
    </author>
    <author>
      <name>Eugene C. Ezin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2 pages, 4 figures, Conference</arxiv:comment>
    <link href="http://arxiv.org/abs/1708.06450v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.06450v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0810.1316v1</id>
    <updated>2008-10-07T23:03:29Z</updated>
    <published>2008-10-07T23:03:29Z</published>
    <title>The meaning of concurrent programs</title>
    <summary>  The semantics of assignment and mutual exclusion in concurrent and
multi-core/multi-processor systems is presented with attention to low level
architectural features in an attempt to make the presentation realistic.
Recursive functions on event sequences are used to define state dependent
functions and variables in ordinary (non-formal-method) algebra.
</summary>
    <author>
      <name>Victor Yodaiken</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Technical report on using recursive functions for the low level
  semantics of concurrent systems</arxiv:comment>
    <link href="http://arxiv.org/abs/0810.1316v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0810.1316v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.2281v1</id>
    <updated>2014-05-08T07:09:55Z</updated>
    <published>2014-05-08T07:09:55Z</published>
    <title>Proceedings of the First Workshop on Resource Awareness and Adaptivity
  in Multi-Core Computing (Racing 2014)</title>
    <summary>  This volume contains the papers accepted at the 1st Workshop on Resource
Awareness and Adaptivity in Multi-Core Computing (Racing 2014), held in
Paderborn, Germany, May 29-30, 2014. Racing 2014 was co-located with the IEEE
European Test Symposium (ETS).
</summary>
    <author>
      <name>Frank Hannig</name>
    </author>
    <author>
      <name>Jürgen Teich</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Website of the workshop: http://www12.cs.fau.de/racing2014/</arxiv:comment>
    <link href="http://arxiv.org/abs/1405.2281v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.2281v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.3226v1</id>
    <updated>2014-10-13T08:51:40Z</updated>
    <published>2014-10-13T08:51:40Z</published>
    <title>Proceedings 2014 International Workshop on Advanced Intrusion Detection
  and Prevention</title>
    <summary>  This volume contains the proceedings of the 2014 International Advanced
Intrusion Detection and Prevention (AIDP'14) Workshop, held in Marrakesh,
Morocco, on the 5th of June 2014, in conjunction with the 29th IFIP TC-11 SEC
2014 International Conference. It includes a revised version of the papers
selected for presentation at the work- shop.
</summary>
    <author>
      <name>Joaquin Garcia-Alfaro</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Institut Mines-Télécom, Télécom SudParis</arxiv:affiliation>
    </author>
    <author>
      <name>Gürkan Gür</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Provus</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.165</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.165" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 165, 2014</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1410.3226v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.3226v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="Security" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9809006v1</id>
    <updated>1998-09-02T17:11:54Z</updated>
    <published>1998-09-02T17:11:54Z</published>
    <title>The Design and Architecture of the Microsoft Cluster Service -- A
  Practical Approach to High-Availability and Scalability</title>
    <summary>  Microsoft Cluster Service (MSCS) extends the Win-dows NT operating system to
support high-availability services. The goal is to offer an execution
environment where off-the-shelf server applications can continue to operate,
even in the presence of node failures. Later ver-sions of MSCS will provide
scalability via a node and application management system that allows
applications to scale to hundreds of nodes. This paper provides a de-tailed
description of the MSCS architecture and the de-sign decisions that have driven
the implementation of the service. The paper also describes how some major
appli-cations use the MSCS features, and describes features added to make it
easier to implement and manage fault-tolerant applications on MSCS.
</summary>
    <author>
      <name>Werner Vogels</name>
    </author>
    <author>
      <name>Dan Dumitriu</name>
    </author>
    <author>
      <name>Ken Birman</name>
    </author>
    <author>
      <name>Rod Gamache</name>
    </author>
    <author>
      <name>Mike Massa</name>
    </author>
    <author>
      <name>Rob Short</name>
    </author>
    <author>
      <name>John Vert</name>
    </author>
    <author>
      <name>Joe Barrera</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Original document at:
  http://research.microsoft.com/~gray/MSCS_FTCS98.doc</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of FTCS'98, June 23-25, 1998 in Munich, Germany</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/9809006v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9809006v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="C.4; C.5;D.4.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9812011v1</id>
    <updated>1998-12-10T16:49:04Z</updated>
    <published>1998-12-10T16:49:04Z</published>
    <title>A nested transaction mechanism for LOCUS</title>
    <summary>  A working implementation of nested transactions has been produced for LOCUS,
an integrated distributed operating system which provides a high degree of
network transparency. Several aspects of our mechanism are novel. First, the
mechanism allows a transaction to access objects directly without regard to the
location of the object. Second, processes running on behalf of a single
transaction may be located at many sites. Thus there is no need to invoke a new
transaction to perform processing or access objects at a remote site. Third,
unlike other environments, LOCUS allows replication of data objects at more
than one site in the network, and this capability is incorporated into the
transaction mechanism. If the copy of an object that is currently being
accessed becomes unavailable, it is possible to continue work by using another
one of the replicated copies. Finally, an efficient orphan removal algorithm is
presented, and the problem of providing continued operation during network
partitions is addressed in detail.
</summary>
    <author>
      <name>Erik T. Mueller</name>
    </author>
    <author>
      <name>Johanna D. Moore</name>
    </author>
    <author>
      <name>Gerald J. Popek</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages. Appears in: Proceedings of the Ninth ACM Symposium on
  Operating Systems Principles (pp. 71-87). Operating Systems Review. Vol. 17,
  No. 5. New York: Association for Computing Machinery. 1983</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/9812011v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9812011v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.2.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0003064v1</id>
    <updated>2000-03-15T19:20:53Z</updated>
    <published>2000-03-15T19:20:53Z</published>
    <title>A network file system over HTTP: remote access and modification of files
  and "files"</title>
    <summary>  The goal of the present HTTPFS project is to enable access to remote files,
directories, and other containers through an HTTP pipe. HTTPFS system permits
retrieval, creation and modification of these resources as if they were regular
files and directories on a local filesystem. The remote host can be any UNIX or
Win9x/WinNT box that is capable of running a Perl CGI script and accessible
either directly or via a web proxy or a gateway. HTTPFS runs entirely in user
space.
  The current implementation fully supports reading as well as creating,
writing, appending, and truncating of files on a remote HTTP host. HTTPFS
provides an isolation level for concurrent file access stronger than the one
mandated by POSIX file system semantics, closer to that of AFS. Both an API
with familiar open(), read(), write(), close(), etc. calls, and an interactive
interface, via the popular Midnight Commander file browser, are provided.
</summary>
    <author>
      <name>Oleg Kiselyov</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This present document combines a paper and a Freenix Track talk
  presented at a 1999 USENIX Annual Technical Conference, June 6-11, 1999;
  Monterey, CA, USA; 6 HTML files. The paper alone appeared in Proc. FREENIX
  Track: 1999 USENIX Annual Technical Conference, June 6-11,1999; Monterey, CA,
  USA, pp. 75-80</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0003064v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0003064v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.4.3; D.4.4; E.5; C.2.2; C.2.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0403007v1</id>
    <updated>2004-03-06T02:52:17Z</updated>
    <published>2004-03-06T02:52:17Z</published>
    <title>End-User Effects of Microreboots in Three-Tiered Internet Systems</title>
    <summary>  Microreboots restart fine-grained components of software systems "with a
clean slate," and only take a fraction of the time needed for full system
reboot. Microreboots provide an application-generic recovery technique for
Internet services, which can be supported entirely in middleware and requires
no changes to the applications or any a priori knowledge of application
semantics.
  This paper investigates the effect of microreboots on end-users of an
eBay-like online auction application; we find that microreboots are nearly as
effective as full reboots, but are significantly less disruptive in terms of
downtime and lost work. In our experiments, microreboots reduced the number of
failed user requests by 65% and the perceived downtime by 78% compared to a
server process restart. We also show how to replace user-visible transient
failures with transparent call-retry, at the cost of a slight increase in
end-user-visible latency during recovery. Due to their low cost, microreboots
can be used aggressively, even when their necessity is less than certain, hence
adding to the reduced recovery time a reduction in the fault detection time,
which further improves availability.
</summary>
    <author>
      <name>George Candea</name>
    </author>
    <author>
      <name>Armando Fox</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0403007v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0403007v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.4.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0409034v1</id>
    <updated>2004-09-17T21:51:24Z</updated>
    <published>2004-09-17T21:51:24Z</published>
    <title>Securing Data in Storage: A Review of Current Research</title>
    <summary>  Protecting data from malicious computer users continues to grow in
importance. Whether preventing unauthorized access to personal photographs,
ensuring compliance with federal regulations, or ensuring the integrity of
corporate secrets, all applications require increased security to protect data
from talented intruders. Specifically, as more and more files are preserved on
disk the requirement to provide secure storage has increased in importance.
This paper presents a survey of techniques for securely storing data, including
theoretical approaches, prototype systems, and existing systems currently
available. Due to the wide variety of potential solutions available and the
variety of techniques to arrive at a particular solution, it is important to
review the entire field prior to selecting an implementation that satisfies
particular requirements. This paper provides an overview of the prominent
characteristics of several systems to provide a foundation for making an
informed decision. Initially, the paper establishes a set of criteria for
evaluating a storage solution based on confidentiality, integrity,
availability, and performance. Then, using these criteria, the paper explains
the relevant characteristics of select storage systems and provides a
comparison of the major differences.
</summary>
    <author>
      <name>Paul Stanton</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">22 pages, 4 figures, 3 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0409034v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0409034v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.4.3;D.4.6;K.6.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0511010v1</id>
    <updated>2005-11-02T19:52:58Z</updated>
    <published>2005-11-02T19:52:58Z</published>
    <title>A Survey of Virtualization Techniques Focusing on Secure On-Demand
  Cluster Computing</title>
    <summary>  Virtualization, a technique once used to multiplex the resources of
high-priced mainframe hardware, is seeing a resurgence in applicability with
the increasing computing power of commodity computers. By inserting a layer of
software between the machine and traditional operating systems, this technology
allows access to a shared computing medium in a manner that is secure,
resource-controlled, and efficient. These properties are attractive in the
field of on-demand computing, where the fine-grained subdivision of resources
provided by virtualized systems allows potentially higher utilization of
computing resources.
  It this work, we survey a number of virtual machine systems with the goal of
finding an appropriate candidate to serve as the basis for the On-Demand Secure
Cluster Computing project at the National Center for Supercomputing
Applications. Contenders are reviewed on a number of desirable properties
including portability and security. We conclude with a comparison and
justification of our choice.
</summary>
    <author>
      <name>Nadir Kiyanclar</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0511010v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0511010v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.4.m" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0701021v2</id>
    <updated>2013-07-05T14:09:11Z</updated>
    <published>2007-01-04T09:45:28Z</published>
    <title>The Unix KISS: A Case Study</title>
    <summary>  In this paper we show that the initial philosophy used in designing and
developing UNIX in early times has been forgotten due to "fast practices". We
question the leitmotif that microkernels, though being by design adherent to
the KISS principle, have a number of context switches higher than their
monolithic counterparts, running a test suite and verify the results with
standard statistical validation tests. We advocate a wiser distribution of
shared libraries by statistically analyzing the weight of each shared object in
a typical UNIX system, showing that the majority of shared libraries exist in a
common space for no real evidence of need. Finally we examine the UNIX heritage
with an historical point of view, noticing how habits swiftly replaced the
intents of the original authors, moving the focus from the earliest purpose of
is avoiding complications, keeping a system simple to use and maintain.
</summary>
    <author>
      <name>Franco Milicchio</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Removed from arXiv and other sources</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0701021v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0701021v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0705.2786v1</id>
    <updated>2007-05-19T00:02:24Z</updated>
    <published>2007-05-19T00:02:24Z</published>
    <title>Virtualization: A double-edged sword</title>
    <summary>  Virtualization became recently a hot topic once again, after being dormant
for more than twenty years. In the meantime, it has been almost forgotten, that
virtual machines are not so perfect isolating environments as it seems, when
looking at the principles. These lessons were already learnt earlier when the
first virtualized systems have been exposed to real life usage.
  Contemporary virtualization software enables instant creation and destruction
of virtual machines on a host, live migration from one host to another,
execution history manipulation, etc. These features are very useful in
practice, but also causing headaches among security specialists, especially in
current hostile network environments.
  In the present contribution we discuss the principles, potential benefits and
risks of virtualization in a deja vu perspective, related to previous
experiences with virtualization in the mainframe era.
</summary>
    <author>
      <name>Joachim J. Wlodarz</name>
    </author>
    <link href="http://arxiv.org/abs/0705.2786v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0705.2786v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0801.4292v1</id>
    <updated>2008-01-28T14:30:34Z</updated>
    <published>2008-01-28T14:30:34Z</published>
    <title>Exact Feasibility Tests for Real-Time Scheduling of Periodic Tasks upon
  Multiprocessor Platforms</title>
    <summary>  In this paper we study the global scheduling of periodic task systems upon
multiprocessor platforms. We first show two very general properties which are
well-known for uniprocessor platforms and which remain for multiprocessor
platforms: (i) under few and not so restrictive assumptions, we show that
feasible schedules of periodic task systems are periodic from some point with a
period equal to the least common multiple of task periods and (ii) for the
specific case of synchronous periodic task systems, we show that feasible
schedules repeat from the origin. We then present our main result: we
characterize, for task-level fixed-priority schedulers and for asynchronous
constrained or arbitrary deadline periodic task models, upper bounds of the
first time instant where the schedule repeats. We show that job-level
fixed-priority schedulers are predictable upon unrelated multiprocessor
platforms. For task-level fixed-priority schedulers, based on the upper bounds
and the predictability property, we provide for asynchronous constrained or
arbitrary deadline periodic task sets, exact feasibility tests. Finally, for
the job-level fixed-priority EDF scheduler, for which such an upper bound
remains unknown, we provide an exact feasibility test as well.
</summary>
    <author>
      <name>Liliana Cucu</name>
    </author>
    <author>
      <name>Joël Goossens</name>
    </author>
    <link href="http://arxiv.org/abs/0801.4292v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0801.4292v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0803.2365v1</id>
    <updated>2008-03-16T18:24:13Z</updated>
    <published>2008-03-16T18:24:13Z</published>
    <title>SAFIUS - A secure and accountable filesystem over untrusted storage</title>
    <summary>  We describe SAFIUS, a secure accountable file system that resides over an
untrusted storage. SAFIUS provides strong security guarantees like
confidentiality, integrity, prevention from rollback attacks, and
accountability. SAFIUS also enables read/write sharing of data and provides the
standard UNIX-like interface for applications. To achieve accountability with
good performance, it uses asynchronous signatures; to reduce the space required
for storing these signatures, a novel signature pruning mechanism is used.
SAFIUS has been implemented on a GNU/Linux based system modifying OpenGFS.
Preliminary performance studies show that SAFIUS has a tolerable overhead for
providing secure storage: while it has an overhead of about 50% of OpenGFS in
data intensive workloads (due to the overhead of performing
encryption/decryption in software), it is comparable (or better in some cases)
to OpenGFS in metadata intensive workloads.
</summary>
    <author>
      <name>V Sriram</name>
    </author>
    <author>
      <name>Ganesh Narayan</name>
    </author>
    <author>
      <name>K Gopinath</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/SISW.2007.7</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/SISW.2007.7" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11pt, 12 pages, 16 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Fourth International IEEE Security in Storage Workshop, 2007 -
  SISW '07. Publication Date: 27-27 Sept. 2007 On page(s): 34-45</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0803.2365v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0803.2365v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.4.6; D.4.2; C.2.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0803.3632v1</id>
    <updated>2008-03-25T20:52:17Z</updated>
    <published>2008-03-25T20:52:17Z</published>
    <title>Void Traversal for Guaranteed Delivery in Geometric Routing</title>
    <summary>  Geometric routing algorithms like GFG (GPSR) are lightweight, scalable
algorithms that can be used to route in resource-constrained ad hoc wireless
networks. However, such algorithms run on planar graphs only. To efficiently
construct a planar graph, they require a unit-disk graph. To make the topology
unit-disk, the maximum link length in the network has to be selected
conservatively. In practical setting this leads to the designs where the node
density is rather high. Moreover, the network diameter of a planar subgraph is
greater than the original graph, which leads to longer routes. To remedy this
problem, we propose a void traversal algorithm that works on arbitrary
geometric graphs. We describe how to use this algorithm for geometric routing
with guaranteed delivery and compare its performance with GFG.
</summary>
    <author>
      <name>Mikhail Nesterenko</name>
    </author>
    <author>
      <name>Adnan Vora</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/MAHSS.2005.1542862</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/MAHSS.2005.1542862" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">The 2nd IEEE International Conference on Mobile Ad-hoc and Sensor
  Systems (MASS 2005), Washington, DC, November, 2005</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0803.3632v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0803.3632v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="C.2.2; C.2.1; F.2.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0803.4308v2</id>
    <updated>2008-04-07T07:55:38Z</updated>
    <published>2008-03-30T09:26:38Z</published>
    <title>Discrete Frequency Selection of Frame-Based Stochastic Real-Time Tasks</title>
    <summary>  Energy-efficient real-time task scheduling has been actively explored in the
past decade. Different from the past work, this paper considers schedulability
conditions for stochastic real-time tasks. A schedulability condition is first
presented for frame-based stochastic real-time tasks, and several algorithms
are also examined to check the schedulability of a given strategy. An approach
is then proposed based on the schedulability condition to adapt a
continuous-speed-based method to a discrete-speed system. The approach is able
to stay as close as possible to the continuous-speed-based method, but still
guaranteeing the schedulability. It is shown by simulations that the energy
saving can be more than 20% for some system configurations
</summary>
    <author>
      <name>Vandy Berten</name>
    </author>
    <author>
      <name>Chi-Ju Chang</name>
    </author>
    <author>
      <name>Tei-Wei Kuo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/0803.4308v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0803.4308v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0805.4680v3</id>
    <updated>2008-06-10T07:13:01Z</updated>
    <published>2008-05-30T07:01:51Z</published>
    <title>Telex: Principled System Support for Write-Sharing in Collaborative
  Applications</title>
    <summary>  The Telex system is designed for sharing mutable data in a distributed
environment, particularly for collaborative applications. Users operate on
their local, persistent replica of shared documents; they can work disconnected
and suffer no network latency. The Telex approach to detect and correct
conflicts is application independent, based on an action-constraint graph (ACG)
that summarises the concurrency semantics of applications. The ACG is stored
efficiently in a multilog structure that eliminates contention and is optimised
for locality. Telex supports multiple applications and multi-document updates.
The Telex system clearly separates system logic (which includes replication,
views, undo, security, consistency, conflicts, and commitment) from application
logic. An example application is a shared calendar for managing multi-user
meetings; the system detects meeting conflicts and resolves them consistently.
</summary>
    <author>
      <name>Lamia Benmouffok</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rocquencourt, LIP6</arxiv:affiliation>
    </author>
    <author>
      <name>Jean-Michel Busca</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rocquencourt, LIP6</arxiv:affiliation>
    </author>
    <author>
      <name>Joan Manuel Marquès</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIP6, UOC</arxiv:affiliation>
    </author>
    <author>
      <name>Marc Shapiro</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rocquencourt, LIP6</arxiv:affiliation>
    </author>
    <author>
      <name>Pierre Sutra</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rocquencourt, LIP6</arxiv:affiliation>
    </author>
    <author>
      <name>Georgios Tsoukalas</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">NTUA</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/0805.4680v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0805.4680v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0806.0132v1</id>
    <updated>2008-06-01T08:30:10Z</updated>
    <published>2008-06-01T08:30:10Z</published>
    <title>Control-theoretic dynamic voltage scaling for embedded controllers</title>
    <summary>  For microprocessors used in real-time embedded systems, minimizing power
consumption is difficult due to the timing constraints. Dynamic voltage scaling
(DVS) has been incorporated into modern microprocessors as a promising
technique for exploring the trade-off between energy consumption and system
performance. However, it remains a challenge to realize the potential of DVS in
unpredictable environments where the system workload cannot be accurately
known. Addressing system-level power-aware design for DVS-enabled embedded
controllers, this paper establishes an analytical model for the DVS system that
encompasses multiple real-time control tasks. From this model, a feedback
control based approach to power management is developed to reduce dynamic power
consumption while achieving good application performance. With this approach,
the unpredictability and variability of task execution times can be attacked.
Thanks to the use of feedback control theory, predictable performance of the
DVS system is achieved, which is favorable to real-time applications. Extensive
simulations are conducted to evaluate the performance of the proposed approach.
</summary>
    <author>
      <name>Feng Xia</name>
    </author>
    <author>
      <name>Yu-Chu Tian</name>
    </author>
    <author>
      <name>Youxian Sun</name>
    </author>
    <author>
      <name>Jinxiang Dong</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted for publication in IET Computers and Digital Techniques.
  doi:10.1049/iet-cdt:20070112</arxiv:comment>
    <link href="http://arxiv.org/abs/0806.0132v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0806.0132v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.4.1; C.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0806.1381v1</id>
    <updated>2008-06-09T07:23:28Z</updated>
    <published>2008-06-09T07:23:28Z</published>
    <title>Feedback Scheduling: An Event-Driven Paradigm</title>
    <summary>  Embedded computing systems today increasingly feature resource constraints
and workload variability, which lead to uncertainty in resource availability.
This raises great challenges to software design and programming in multitasking
environments. In this paper, the emerging methodology of feedback scheduling is
introduced to address these challenges. As a closed-loop approach to resource
management, feedback scheduling promises to enhance the flexibility and
resource efficiency of various software programs through dynamically
distributing available resources among concurrent tasks based on feedback
information about the actual usage of the resources. With emphasis on the
behavioral design of feedback schedulers, we describe a general framework of
feedback scheduling in the context of real-time control applications. A simple
yet illustrative feedback scheduling algorithm is given. From a programming
perspective, we describe how to modify the implementation of control tasks to
facilitate the application of feedback scheduling. An event-driven paradigm
that combines time-triggered and event-triggered approaches is proposed for
programming of the feedback scheduler. Simulation results argue that the
proposed event-driven paradigm yields better performance than time-triggered
paradigm in dynamic environments where the workload varies irregularly and
unpredictably.
</summary>
    <author>
      <name>Feng Xia</name>
    </author>
    <author>
      <name>Guosong Tian</name>
    </author>
    <author>
      <name>Youxian Sun</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 10 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ACM SIGPLAN Notices, vol.42, no.12, pp. 7-14, Dec. 2007</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0806.1381v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0806.1381v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.4.1; C.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0806.1768v1</id>
    <updated>2008-06-11T00:03:00Z</updated>
    <published>2008-06-11T00:03:00Z</published>
    <title>Local Read-Write Operations in Sensor Networks</title>
    <summary>  Designing protocols and formulating convenient programming units of
abstraction for sensor networks is challenging due to communication errors and
platform constraints. This paper investigates properties and implementation
reliability for a \emph{local read-write} abstraction. Local read-write is
inspired by the class of read-modify-write operations defined for shared-memory
multiprocessor architectures. The class of read-modify-write operations is
important in solving consensus and related synchronization problems for
concurrency control. Local read-write is shown to be an atomic abstraction for
synchronizing neighborhood states in sensor networks. The paper compares local
read-write to similar lightweight operations in wireless sensor networks, such
as read-all, write-all, and a transaction-based abstraction: for some
optimistic scenarios, local read-write is a more efficient neighborhood
operation. A partial implementation is described, which shows that three
outcomes characterize operation response: success, failure, and cancel. A
failure response indicates possible inconsistency for the operation result,
which is the result of a timeout event at the operation's initiator. The paper
presents experimental results on operation performance with different timeout
values and situations of no contention, with some tests also on various
neighborhood sizes.
</summary>
    <author>
      <name>Ted Herman</name>
    </author>
    <author>
      <name>Morten Mjelde</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages, 16 figures (using pstricks)</arxiv:comment>
    <link href="http://arxiv.org/abs/0806.1768v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0806.1768v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="C.2.4; D.1.3; C.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0808.0920v1</id>
    <updated>2008-08-06T20:33:56Z</updated>
    <published>2008-08-06T20:33:56Z</published>
    <title>A Distributed and Deterministic TDMA Algorithm for
  Write-All-With-Collision Model</title>
    <summary>  Several self-stabilizing time division multiple access (TDMA) algorithms are
proposed for sensor networks. In addition to providing a collision-free
communication service, such algorithms enable the transformation of programs
written in abstract models considered in distributed computing literature into
a model consistent with sensor networks, i.e., write all with collision (WAC)
model. Existing TDMA slot assignment algorithms have one or more of the
following properties: (i) compute slots using a randomized algorithm, (ii)
assume that the topology is known upfront, and/or (iii) assign slots
sequentially. If these algorithms are used to transform abstract programs into
programs in WAC model then the transformed programs are probabilistically
correct, do not allow the addition of new nodes, and/or converge in a
sequential fashion. In this paper, we propose a self-stabilizing deterministic
TDMA algorithm where a sensor is aware of only its neighbors. We show that the
slots are assigned to the sensors in a concurrent fashion and starting from
arbitrary initial states, the algorithm converges to states where
collision-free communication among the sensors is restored. Moreover, this
algorithm facilitates the transformation of abstract programs into programs in
WAC model that are deterministically correct.
</summary>
    <author>
      <name>Mahesh Arumugam</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/0808.0920v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0808.0920v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0809.1132v1</id>
    <updated>2008-09-06T04:38:34Z</updated>
    <published>2008-09-06T04:38:34Z</published>
    <title>Managing Varying Worst Case Execution Times on DVS Platforms</title>
    <summary>  Energy efficient real-time task scheduling attracted a lot of attention in
the past decade. Most of the time, deterministic execution lengths for tasks
were considered, but this model fits less and less with the reality, especially
with the increasing number of multimedia applications. It's why a lot of
research is starting to consider stochastic models, where execution times are
only known stochastically. However, authors consider that they have a pretty
much precise knowledge about the properties of the system, especially regarding
to the worst case execution time (or worst case execution cycles, WCEC).
  In this work, we try to relax this hypothesis, and assume that the WCEC can
vary. We propose miscellaneous methods to react to such a situation, and give
many simulation results attesting that with a small effort, we can provide very
good results, allowing to keep a low deadline miss rate as well as an energy
consumption similar to clairvoyant algorithms.
</summary>
    <author>
      <name>Vandy Berten</name>
    </author>
    <author>
      <name>Chi-Ju Chang</name>
    </author>
    <author>
      <name>Tei-Wei Kuo</name>
    </author>
    <link href="http://arxiv.org/abs/0809.1132v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0809.1132v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0910.5046v1</id>
    <updated>2009-10-27T17:31:02Z</updated>
    <published>2009-10-27T17:31:02Z</published>
    <title>Temporal Debugging using URDB</title>
    <summary>  A new style of temporal debugging is proposed. The new URDB debugger can
employ such techniques as temporal search for finding an underlying fault that
is causing a bug. This improves on the standard iterative debugging style,
which iteratively re-executes a program under debugger control in the search
for the underlying fault. URDB acts as a meta-debugger, with current support
for four widely used debuggers: gdb, MATLAB, python, and perl. Support for a
new debugger can be added in a few hours. Among its points of novelty are: (i)
the first reversible debuggers for MATLAB, python, and perl; (ii) support for
today's multi-core architectures; (iii) reversible debugging of multi-process
and distributed computations; and (iv) temporal search on changes in program
expressions. URDB gains its reversibility and temporal abilities through the
fast checkpoint-restart capability of DMTCP (Distributed MultiThreaded
CheckPointing). The recently enhanced DMTCP also adds ptrace support, enabling
one to freeze, migrate, and replicate debugging sessions.
</summary>
    <author>
      <name>Ana Maria Visan</name>
    </author>
    <author>
      <name>Artem Polyakov</name>
    </author>
    <author>
      <name>Praveen S. Solanki</name>
    </author>
    <author>
      <name>Kapil Arya</name>
    </author>
    <author>
      <name>Tyler Denniston</name>
    </author>
    <author>
      <name>Gene Cooperman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages, 3 figures, 5 tables; software at urdb.sourceforge.net</arxiv:comment>
    <link href="http://arxiv.org/abs/0910.5046v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0910.5046v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.2.5; D.4.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0912.0606v1</id>
    <updated>2009-12-03T09:06:59Z</updated>
    <published>2009-12-03T09:06:59Z</published>
    <title>A New Scheduling Algorithms For Real Time Tasks</title>
    <summary>  The main objective of this paper is to develop the two different ways in
which round robin architecture is modified and made suitable to be implemented
in real time and embedded systems. The scheduling algorithm plays a significant
role in the design of real time embedded systems. Simple round robin
architecture is not efficient to be implemented in embedded systems because of
higher context switch rate, larger waiting time and larger response time.
Missing of deadlines will degrade the system performance in soft real time
systems. The main objective of this paper is to develop the scheduling
algorithm which removes the drawbacks in simple round robin architecture. A
comparison with round robin architecture to the proposed architectures has been
made. It is observed that the proposed architectures solves the problems
encountered in round robin architecture in soft real time by decreasing the
number of context switches waiting time and response time thereby increasing
the system throughput.
</summary>
    <author>
      <name>C. Yaashuwanth</name>
    </author>
    <author>
      <name>Dr. R. Ramesh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS November 2009, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 6, No. 2, pp. 061-066, November 2009, USA</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0912.0606v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0912.0606v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0912.0926v2</id>
    <updated>2010-02-01T16:27:48Z</updated>
    <published>2009-12-04T20:10:12Z</published>
    <title>Deterministic Consistency: A Programming Model for Shared Memory
  Parallelism</title>
    <summary>  The difficulty of developing reliable parallel software is generating
interest in deterministic environments, where a given program and input can
yield only one possible result. Languages or type systems can enforce
determinism in new code, and runtime systems can impose synthetic schedules on
legacy parallel code. To parallelize existing serial code, however, we would
like a programming model that is naturally deterministic without language
restrictions or artificial scheduling. We propose "deterministic consistency",
a parallel programming model as easy to understand as the "parallel assignment"
construct in sequential languages such as Perl and JavaScript, where concurrent
threads always read their inputs before writing shared outputs. DC supports
common data- and task-parallel synchronization abstractions such as fork/join
and barriers, as well as non-hierarchical structures such as producer/consumer
pipelines and futures. A preliminary prototype suggests that software-only
implementations of DC can run applications written for popular parallel
environments such as OpenMP with low (&lt;10%) overhead for some applications.
</summary>
    <author>
      <name>Amittai Aviram</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Yale University</arxiv:affiliation>
    </author>
    <author>
      <name>Bryan Ford</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Yale University</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0912.0926v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0912.0926v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="C.1.4; D.1.3; D.3.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1001.4115v3</id>
    <updated>2011-01-24T12:39:16Z</updated>
    <published>2010-01-25T08:09:27Z</published>
    <title>On the Design of an Optimal Multiprocessor Real-Time Scheduling
  Algorithm under Practical Considerations (Extended Version)</title>
    <summary>  This research addresses the multiprocessor scheduling problem of hard
real-time systems, and it especially focuses on optimal and global schedulers
when practical constraints are taken into account. First, we propose an
improvement of the optimal algorithm BF. We formally prove that our adaptation
is (i) optimal, i.e., it always generates a feasible schedule as long as such a
schedule exists, and (ii) valid, i.e., it complies with the all the
requirements. We also show that it outperforms BF by providing a computing
complexity of O(n), where n is the number of tasks to be scheduled. Next, we
propose a schedulability analysis which indicates a priori whether the
real-time application can be scheduled by our improvement of BF without missing
any deadline. This analysis is, to the best of our knowledge, the first such
test for multiprocessors that takes into account all the main overheads
generated by the Operating System.
</summary>
    <author>
      <name>Shelby Funk</name>
    </author>
    <author>
      <name>Vincent Nelis</name>
    </author>
    <author>
      <name>Joel Goossens</name>
    </author>
    <author>
      <name>Dragomir Milojevic</name>
    </author>
    <author>
      <name>Geoffrey Nelissen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper has been withdrawn by the authors</arxiv:comment>
    <link href="http://arxiv.org/abs/1001.4115v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1001.4115v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1004.3715v1</id>
    <updated>2010-04-21T14:24:13Z</updated>
    <published>2010-04-21T14:24:13Z</published>
    <title>Multi-Criteria Evaluation of Partitioning Schemes for Real-Time Systems</title>
    <summary>  In this paper we study the partitioning approach for multiprocessor real-time
scheduling. This approach seems to be the easiest since, once the partitioning
of the task set has been done, the problem reduces to well understood
uniprocessor issues. Meanwhile, there is no optimal and polynomial solution to
partition tasks on processors. In this paper we analyze partitioning algorithms
from several points of view such that for a given task set and specific
constraints (processor number, task set type, etc.) we should be able to
identify the best heuristic and the best schedulability test. We also analyze
the influence of the heuristics on the performance of the uniprocessor tests
and the impact of a specific task order on the schedulability. A study on
performance difference between Fixed Priority schedulers and EDF in the case of
partitioning scheduling is also considered.
</summary>
    <author>
      <name>Irina Lupu</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">U.L.B</arxiv:affiliation>
    </author>
    <author>
      <name>Pierre Courbin</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">ECE</arxiv:affiliation>
    </author>
    <author>
      <name>Laurent George</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">ECE</arxiv:affiliation>
    </author>
    <author>
      <name>Joël Goossens</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">U.L.B</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE International Conference on Emerging Technologies and Factory
  Automation, 2010</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1004.3715v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1004.3715v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1005.3450v1</id>
    <updated>2010-05-19T14:17:56Z</updated>
    <published>2010-05-19T14:17:56Z</published>
    <title>Efficient System-Enforced Deterministic Parallelism</title>
    <summary>  Deterministic execution offers many benefits for debugging, fault tolerance,
and security. Running parallel programs deterministically is usually difficult
and costly, however - especially if we desire system-enforced determinism,
ensuring precise repeatability of arbitrarily buggy or malicious software.
Determinator is a novel operating system that enforces determinism on both
multithreaded and multi-process computations. Determinator's kernel provides
only single-threaded, "shared-nothing" address spaces interacting via
deterministic synchronization. An untrusted user-level runtime uses distributed
computing techniques to emulate familiar abstractions such as Unix processes,
file systems, and shared memory multithreading. The system runs parallel
applications deterministically both on multicore PCs and across nodes in a
cluster. Coarse-grained parallel benchmarks perform and scale comparably to -
sometimes better than - conventional systems, though determinism is costly for
fine-grained parallel applications.
</summary>
    <author>
      <name>Amittai Aviram</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Yale University</arxiv:affiliation>
    </author>
    <author>
      <name>Shu-Chun Weng</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Yale University</arxiv:affiliation>
    </author>
    <author>
      <name>Sen Hu</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Yale University</arxiv:affiliation>
    </author>
    <author>
      <name>Bryan Ford</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Yale University</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 12 figures, 3 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1005.3450v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1005.3450v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1006.2637v1</id>
    <updated>2010-06-14T08:51:05Z</updated>
    <published>2010-06-14T08:51:05Z</published>
    <title>Semi-Partitioned Hard Real-Time Scheduling with Restricted Migrations
  upon Identical Multiprocessor Platforms</title>
    <summary>  Algorithms based on semi-partitioned scheduling have been proposed as a
viable alternative between the two extreme ones based on global and partitioned
scheduling. In particular, allowing migration to occur only for few tasks which
cannot be assigned to any individual processor, while most tasks are assigned
to specific processors, considerably reduces the runtime overhead compared to
global scheduling on the one hand, and improve both the schedulability and the
system utilization factor compared to partitioned scheduling on the other hand.
In this paper, we address the preemptive scheduling problem of hard real-time
systems composed of sporadic constrained-deadline tasks upon identical
multiprocessor platforms. We propose a new algorithm and a scheduling paradigm
based on the concept of semi-partitioned scheduling with restricted migrations
in which jobs are not allowed to migrate, but two subsequent jobs of a task can
be assigned to different processors by following a periodic strategy.
</summary>
    <author>
      <name>François Dorin</name>
    </author>
    <author>
      <name>Patrick Meumeu Yomsi</name>
    </author>
    <author>
      <name>Joël Goossens</name>
    </author>
    <author>
      <name>Pascal Richard</name>
    </author>
    <link href="http://arxiv.org/abs/1006.2637v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1006.2637v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1006.5845v1</id>
    <updated>2010-06-30T13:01:58Z</updated>
    <published>2010-06-30T13:01:58Z</published>
    <title>Dynamic and Transparent Analysis of Commodity Production Systems</title>
    <summary>  We propose a framework that provides a programming interface to perform
complex dynamic system-level analyses of deployed production systems. By
leveraging hardware support for virtualization available nowadays on all
commodity machines, our framework is completely transparent to the system under
analysis and it guarantees isolation of the analysis tools running on its top.
Thus, the internals of the kernel of the running system needs not to be
modified and the whole platform runs unaware of the framework. Moreover, errors
in the analysis tools do not affect the running system and the framework. This
is accomplished by installing a minimalistic virtual machine monitor and
migrating the system, as it runs, into a virtual machine. In order to
demonstrate the potentials of our framework we developed an interactive kernel
debugger, nicknamed HyperDbg. HyperDbg can be used to debug any critical kernel
component, and even to single step the execution of exception and interrupt
handlers.
</summary>
    <author>
      <name>Aristide Fattori</name>
    </author>
    <author>
      <name>Roberto Paleari</name>
    </author>
    <author>
      <name>Lorenzo Martignoni</name>
    </author>
    <author>
      <name>Mattia Monga</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/1858996.1859085</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/1858996.1859085" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, To appear in the 25th IEEE/ACM International Conference on
  Automated Software Engineering, Antwerp, Belgium, 20-24 September 2010</arxiv:comment>
    <link href="http://arxiv.org/abs/1006.5845v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1006.5845v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.2.5; D.4.9" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1011.1735v1</id>
    <updated>2010-11-08T09:07:54Z</updated>
    <published>2010-11-08T09:07:54Z</published>
    <title>Use of Data Mining in Scheduler Optimization</title>
    <summary>  The operating system's role in a computer system is to manage the various
resources. One of these resources is the Central Processing Unit. It is managed
by a component of the operating system called the CPU scheduler. Schedulers are
optimized for typical workloads expected to run on the platform. However, a
single scheduler may not be appropriate for all workloads. That is, a scheduler
may schedule a workload such that the completion time is minimized, but when
another type of workload is run on the platform, scheduling and therefore
completion time will not be optimal; a different scheduling algorithm, or a
different set of parameters, may work better. Several approaches to solving
this problem have been proposed. The objective of this survey is to summarize
the approaches based on data mining, which are available in the literature. In
addition to solutions that can be directly utilized for solving this problem,
we are interested in data mining research in related areas that have potential
for use in operating system scheduling. We also explain general technical
issues involved in scheduling in modern computers, including parallel
scheduling issues related to multi-core CPUs. We propose a taxonomy that
classifies the scheduling approaches we discuss into different categories.
</summary>
    <author>
      <name>George Anderson</name>
    </author>
    <author>
      <name>Tshilidzi Marwala</name>
    </author>
    <author>
      <name>Fulufhelo V. Nelwamondo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1011.1735v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1011.1735v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1012.4045v1</id>
    <updated>2010-12-18T00:51:57Z</updated>
    <published>2010-12-18T00:51:57Z</published>
    <title>Application of Global and One-Dimensional Local Optimization to
  Operating System Scheduler Tuning</title>
    <summary>  This paper describes a study of comparison of global and one-dimensional
local optimization methods to operating system scheduler tuning. The operating
system scheduler we use is the Linux 2.6.23 Completely Fair Scheduler (CFS)
running in simulator (LinSched). We have ported the Hackbench scheduler
benchmark to this simulator and use this as the workload. The global
optimization approach we use is Particle Swarm Optimization (PSO). We make use
of Response Surface Methodology (RSM) to specify optimal parameters for our PSO
implementation. The one-dimensional local optimization approach we use is the
Golden Section method. In order to use this approach, we convert the scheduler
tuning problem from one involving setting of three parameters to one involving
the manipulation of one parameter. Our results show that the global
optimization approach yields better response but the one- dimensional
optimization approach converges to a solution faster than the global
optimization approach.
</summary>
    <author>
      <name>George Anderson</name>
    </author>
    <author>
      <name>Tshilidzi Marwala</name>
    </author>
    <author>
      <name>Fulufhelo Vincent Nelwamondo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the Twenty-First Annual Symposium of the Pattern
  Recognition Association of South Africa 22-23 November 2010 Stellenbosch,
  South Africa, pp. 7-11</arxiv:comment>
    <link href="http://arxiv.org/abs/1012.4045v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1012.4045v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1012.5929v1</id>
    <updated>2010-12-29T12:41:13Z</updated>
    <published>2010-12-29T12:41:13Z</published>
    <title>Exact Schedulability Test for global-EDF Scheduling of Periodic Hard
  Real-Time Tasks on Identical Multiprocessors</title>
    <summary>  In this paper we consider the scheduling problem of hard real-time systems
composed of periodic constrained-deadline tasks upon identical multiprocessor
platforms. We assume that tasks are scheduled by using the global-EDF
scheduler. We establish an exact schedulability test for this scheduler by
exploiting on the one hand its predictability property and by providing on the
other hand a feasibility interval so that if it is possible to find a valid
schedule for all the jobs contained in this interval, then the whole system
will be stamped feasible. In addition, we show by means of a counterexample
that the feasibility interval, and thus the schedulability test, proposed by
Leung [Leung 1989] is incorrect and we show which arguments are actually
incorrect.
</summary>
    <author>
      <name>Joël Goossens</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Brussels University, U.L.B., Brussels, Belgium</arxiv:affiliation>
    </author>
    <author>
      <name>Patrick Meumeu Yomsi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">F.N.R.S, Belgium</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/1012.5929v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1012.5929v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1101.1466v1</id>
    <updated>2011-01-06T10:28:58Z</updated>
    <published>2011-01-06T10:28:58Z</published>
    <title>Comparison of Loss ratios of different scheduling algorithms</title>
    <summary>  It is well known that in a firm real time system with a renewal arrival
process, exponential service times and independent and identically distributed
deadlines till the end of service of a job, the earliest deadline first (EDF)
scheduling policy has smaller loss ratio (expected fraction of jobs, not
completed) than any other service time independent scheduling policy, including
the first come first served (FCFS). Various modifications to the EDF and FCFS
policies have been proposed in the literature, with a view to improving
performance. In this article, we compare the loss ratios of these two policies
along with some of the said modifications, as well as their counterparts with
deterministic deadlines. The results include some formal inequalities and some
counter-examples to establish non-existence of an order. A few relations
involving loss ratios are posed as conjectures, and simulation results in
support of these are reported. These results lead to a complete picture of
dominance and non-dominance relations between pairs of scheduling policies, in
terms of loss ratios.
</summary>
    <author>
      <name>Sudipta Das</name>
    </author>
    <author>
      <name>Lawrence Jenkins</name>
    </author>
    <author>
      <name>Debasis Sengupta</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 10 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1101.1466v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1101.1466v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1102.2094v1</id>
    <updated>2011-02-10T12:15:58Z</updated>
    <published>2011-02-10T12:15:58Z</published>
    <title>Global Scheduling of Multi-Mode Real-Time Applications upon
  Multiprocessor Platforms</title>
    <summary>  Multi-mode real-time systems are those which support applications with
different modes of operation, where each mode is characterized by a specific
set of tasks. At run-time, such systems can, at any time, be requested to
switch from its current operating mode to another mode (called "new mode") by
replacing the current set of tasks with that of the new-mode. Thereby, ensuring
that all the timing requirements are met not only requires that a
schedulability test is performed on the tasks of each mode but also that (i) a
protocol for transitioning from one mode to another is specified and (ii) a
schedulability test for each transition is performed. We propose two distinct
protocols that manage the mode transitions upon uniform and identical
multiprocessor platforms at run-time, each specific to distinct task
requirements. For each protocol, we formally establish schedulability analyses
that indicate beforehand whether all the timing requirements will be met during
any mode transition of the system. This is performed assuming both
Fixed-Task-Priority and Fixed-Job-Priority schedulers.
</summary>
    <author>
      <name>Vincent Nelis</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CISTER Research unit Polytechnic Institute of Porto</arxiv:affiliation>
    </author>
    <author>
      <name>Patrick Meumeu Yomsi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LORIA</arxiv:affiliation>
    </author>
    <author>
      <name>Björn Andersson</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CISTER Research unit Polytechnic Institute of Porto</arxiv:affiliation>
    </author>
    <author>
      <name>Joël Goossens</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">U.L.B</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/1102.2094v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1102.2094v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.2336v1</id>
    <updated>2011-03-11T18:36:38Z</updated>
    <published>2011-03-11T18:36:38Z</published>
    <title>Building XenoBuntu Linux Distribution for Teaching and Prototyping
  Real-Time Operating Systems</title>
    <summary>  This paper describes the realization of a new Linux distribution based on
Ubuntu Linux and Xenomai Real-Time framework. This realization is motivated by
the eminent need of real-time systems in modern computer science courses. The
majority of the technical choices are made after qualitative comparison. The
main goal of this distribution is to offer standard Operating Systems (OS) that
include Xenomai infrastructure and the essential tools to begin hard real-time
application development inside a convivial desktop environment. The released
live/installable DVD can be adopted to emulate several classic RTOS Application
Program Interfaces (APIs), directly use and understand real-time Linux in
convivial desktop environment and prototyping real-time embedded applications.
</summary>
    <author>
      <name>Nabil Litayem</name>
    </author>
    <author>
      <name>Ahmed Ben Achballah</name>
    </author>
    <author>
      <name>Slim Ben Saoud</name>
    </author>
    <link href="http://arxiv.org/abs/1103.2336v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.2336v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.3831v1</id>
    <updated>2011-03-20T06:45:16Z</updated>
    <published>2011-03-20T06:45:16Z</published>
    <title>A New Proposed Dynamic Quantum with Re-Adjusted Round Robin Scheduling
  Algorithm and Its Performance Analysis</title>
    <summary>  Scheduling is the central concept used frequently in Operating System. It
helps in choosing the processes for execution. Round Robin (RR) is one of the
most widely used CPU scheduling algorithm. But, its performance degrades with
respect to context switching, which is an overhead and it occurs during each
scheduling. Overall performance of the system depends on choice of an optimal
time quantum, so that context switching can be reduced. In this paper, we have
proposed a new variant of RR scheduling algorithm, known as Dynamic Quantum
with Readjusted Round Robin (DQRRR) algorithm. We have experimentally shown
that performance of DQRRR is better than RR by reducing number of context
switching, average waiting time and average turn around time.
</summary>
    <author>
      <name>H. S. Behera</name>
    </author>
    <author>
      <name>Rakesh Mohanty</name>
    </author>
    <author>
      <name>Debashree Nayak</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">06 pages; International Journal of Computer Applications, Vol. 5, No.
  5, August 2010</arxiv:comment>
    <link href="http://arxiv.org/abs/1103.3831v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.3831v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.3832v1</id>
    <updated>2011-03-20T06:56:27Z</updated>
    <published>2011-03-20T06:56:27Z</published>
    <title>A New Dynamic Round Robin and SRTN Algorithm with Variable Original Time
  Slice and Intelligent Time Slice for Soft Real Time Systems</title>
    <summary>  The main objective of the paper is to improve the Round Robin (RR) algorithm
using dynamic ITS by coalescing it with Shortest Remaining Time Next (SRTN)
algorithm thus reducing the average waiting time, average turnaround time and
the number of context switches. The original time slice has been calculated for
each process based on its burst time.This is mostly suited for soft real time
systems where meeting of deadlines is desirable to increase its performance.
The advantage is that processes that are closer to their remaining completion
time will get more chances to execute and leave the ready queue. This will
reduce the number of processes in the ready queue by knocking out short jobs
relatively faster in a hope to reduce the average waiting time, turn around
time and number of context switches. This paper improves the algorithm [8] and
the experimental analysis shows that the proposed algorithm performs better
than algorithm [6] and [8] when the processes are having an increasing order,
decreasing order and random order of burst time.
</summary>
    <author>
      <name>H. S. Behera</name>
    </author>
    <author>
      <name>Simpi Patel</name>
    </author>
    <author>
      <name>Bijayalakshmi Panda</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5120/2037-2648</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5120/2037-2648" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">07 pages; International Journal of Computer Applications, Vol 16, No.
  1(9) February 2011</arxiv:comment>
    <link href="http://arxiv.org/abs/1103.3832v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.3832v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1105.1736v1</id>
    <updated>2011-05-09T17:29:03Z</updated>
    <published>2011-05-09T17:29:03Z</published>
    <title>Priority Based Dynamic Round Robin (PBDRR) Algorithm with Intelligent
  Time Slice for Soft Real Time Systems</title>
    <summary>  In this paper, a new variant of Round Robin (RR) algorithm is proposed which
is suitable for soft real time systems. RR algorithm performs optimally in
timeshared systems, but it is not suitable for soft real time systems. Because
it gives more number of context switches, larger waiting time and larger
response time. We have proposed a novel algorithm, known as Priority Based
Dynamic Round Robin Algorithm(PBDRR),which calculates intelligent time slice
for individual processes and changes after every round of execution. The
proposed scheduling algorithm is developed by taking dynamic time quantum
concept into account. Our experimental results show that our proposed algorithm
performs better than algorithm in [8] in terms of reducing the number of
context switches, average waiting time and average turnaround time.
</summary>
    <author>
      <name>Rakesh Mohanty</name>
    </author>
    <author>
      <name>H. S. Behera</name>
    </author>
    <author>
      <name>Khusbu Patwari</name>
    </author>
    <author>
      <name>Monisha Dash</name>
    </author>
    <author>
      <name>M. Lakshmi Prasanna</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Advanced Computer Science and
  Applications(IJACSA), Vol. 2 No. 2, February 2011 2011, 46-50</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1105.1736v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1105.1736v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1105.1811v1</id>
    <updated>2011-05-09T22:26:15Z</updated>
    <published>2011-05-09T22:26:15Z</published>
    <title>User Mode Memory Page Allocation: A Silver Bullet For Memory Allocation?</title>
    <summary>  This paper proposes a novel solution: the elimination of paged virtual memory
and partial outsourcing of memory page allocation and manipulation from the
operating system kernel into the individual process' user space - a user mode
page allocator - which allows an application to have direct, bare metal access
to the page mappings used by the hardware Memory Management Unit (MMU) for its
part of the overall address space. A user mode page allocator based emulation
of the mmap() abstraction layer of dlmalloc is then benchmarked against the
traditional kernel mode implemented mmap() in a series of synthetic Monte-Carlo
and real world application settings. Given the superb synthetic and positive
real world results from the profiling conducted, this paper proposes that with
proper operating system and API support one could gain a further order higher
performance again while keeping allocator performance invariant to the amount
of memory being allocated or freed i.e. a 100x performance improvement or more
in some common use cases. It is rare that through a simple and easy to
implement API and operating system structure change one can gain a Silver
Bullet with the potential for a second one.
</summary>
    <author>
      <name>Niall Douglas</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages. Rejected from ISMM11</arxiv:comment>
    <link href="http://arxiv.org/abs/1105.1811v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1105.1811v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.4.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1105.5055v2</id>
    <updated>2011-09-07T13:42:51Z</updated>
    <published>2011-05-25T15:02:01Z</published>
    <title>A faster exact multiprocessor schedulability test for sporadic tasks</title>
    <summary>  Baker and Cirinei introduced an exact but naive algorithm, based on solving a
state reachability problem in a finite automaton, to check whether sets of
sporadic hard real-time tasks are schedulable on identical multiprocessor
platforms. However, the algorithm suffered from poor performance due to the
exponential size of the automaton relative to the size of the task set. In this
paper, we successfully apply techniques developed by the formal verification
community, specifically antichain algorithms, by defining and proving the
correctness of a simulation relation on Baker and Cirinei's automaton. We show
our improved algorithm yields dramatically improved performance for the
schedulability test and opens for many further improvements.
</summary>
    <author>
      <name>Markus Lindström</name>
    </author>
    <author>
      <name>Gilles Geeraerts</name>
    </author>
    <author>
      <name>Joël Goossens</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1105.5055v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1105.5055v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1107.4786v1</id>
    <updated>2011-07-24T19:39:02Z</updated>
    <published>2011-07-24T19:39:02Z</published>
    <title>Towards Bridging IoT and Cloud Services: Proposing Smartphones as Mobile
  and Autonomic Service Gateways</title>
    <summary>  Computing is currently getting at the same time incredibly in the small with
sensors/actuators embedded in our every- day objects and also greatly in the
large with data and ser- vice clouds accessible anytime, anywhere. This
Internet of Things is physically closed to the user but suffers from weak
run-time execution environments. Cloud Environments provide powerful data
storage and computing power but can not be easily accessed and integrate the
final-user context- awareness. We consider smartphones are set to become the
universal interface between these two worlds. In this position paper, we
propose a middleware approach where smartphones provide service gateways to
bridge the gap between IoT services and Cloud services. Since smartphones are
mobile gateways, they should be able to (re)configure themself according to
their place, things discovered around, and their own resources such battery.
Several issues are discussed: collaborative event-based context management,
adaptive and opportunistic service deployment and invocation, multi-criteria
(user- and performance-oriented) optimization decision algorithm.
</summary>
    <author>
      <name>Roya Golchay</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CITI Insa Lyon / Inria Grenoble Rhône-Alpes</arxiv:affiliation>
    </author>
    <author>
      <name>Frédéric Le Mouël</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CITI Insa Lyon / Inria Grenoble Rhône-Alpes</arxiv:affiliation>
    </author>
    <author>
      <name>Stéphane Frénot</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CITI Insa Lyon / Inria Grenoble Rhône-Alpes</arxiv:affiliation>
    </author>
    <author>
      <name>Julien Ponge</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CITI Insa Lyon / Inria Grenoble Rhône-Alpes</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Position Paper</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">UbiMob'2011 (2011) 45--48</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1107.4786v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1107.4786v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1109.2638v1</id>
    <updated>2011-09-12T21:49:38Z</updated>
    <published>2011-09-12T21:49:38Z</published>
    <title>Light-weight Locks</title>
    <summary>  In this paper, we propose a new approach to building synchronization
primitives, dubbed "lwlocks" (short for light-weight locks). The primitives are
optimized for small memory footprint while maintaining efficient performance in
low contention scenarios. A read-write lwlock occupies 4 bytes, a mutex
occupies 4 bytes (2 if deadlock detection is not required), and a condition
variable occupies 4 bytes. The corresponding primitives of the popular pthread
library occupy 56 bytes, 40 bytes and 48 bytes respectively on the x86-64
platform. The API for lwlocks is similar to that of the pthread library but
covering only the most common use cases. Lwlocks allow explicit control of
queuing and scheduling decisions in contention situations and support
"asynchronous" or "deferred blocking" acquisition of locks. Asynchronous
locking helps in working around the constraints of lock-ordering which
otherwise limits concurrency. The small footprint of lwlocks enables the
construction of data structures with very fine-grained locking, which in turn
is crucial for lowering contention and supporting highly concurrent access to a
data structure. Currently, the Data Domain File System uses lwlocks for its
in-memory inode cache as well as in a generic doubly-linked concurrent list
which forms the building block for more sophisticated structures.
</summary>
    <author>
      <name>Nitin Garg</name>
    </author>
    <author>
      <name>Ed Zhu</name>
    </author>
    <author>
      <name>Fabiano C. Botelho</name>
    </author>
    <link href="http://arxiv.org/abs/1109.2638v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1109.2638v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1109.3076v1</id>
    <updated>2011-09-14T13:32:55Z</updated>
    <published>2011-09-14T13:32:55Z</published>
    <title>Comparative performance analysis of multi dynamic time quantum Round
  Robin(MDTQRR) algorithm with arrival time</title>
    <summary>  CPU being considered a primary computer resource, its scheduling is central
to operating-system design. A thorough performance evaluation of various
scheduling algorithms manifests that Round Robin Algorithm is considered as
optimal in time shared environment because the static time is equally shared
among the processes. We have proposed an efficient technique in the process
scheduling algorithm by using dynamic time quantum in Round Robin. Our approach
is based on the calculation of time quantum twice in single round robin cycle.
Taking into consideration the arrival time, we implement the algorithm.
Experimental analysis shows better performance of this improved algorithm over
the Round Robin algorithm and the Shortest Remaining Burst Round Robin
algorithm. It minimizes the overall number of context switches, average waiting
time and average turn-around time. Consequently the throughput and CPU
utilization is better.
</summary>
    <author>
      <name>H. S. Behera</name>
    </author>
    <author>
      <name>Rakesh Mohanty</name>
    </author>
    <author>
      <name>Sabyasachi Sahu</name>
    </author>
    <author>
      <name>Sourav Kumar Bhoi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 18 Figures, Indian Journal of Computer Science and
  Engineering vol. 2 no. 2 April-May 2011</arxiv:comment>
    <link href="http://arxiv.org/abs/1109.3076v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1109.3076v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.5251v1</id>
    <updated>2011-11-22T17:00:50Z</updated>
    <published>2011-11-22T17:00:50Z</published>
    <title>Evolution of a Modular Software Network</title>
    <summary>  "Evolution behaves like a tinkerer" (Francois Jacob, Science, 1977). Software
systems provide a unique opportunity to understand biological processes using
concepts from network theory. The Debian GNU/Linux operating system allows us
to explore the evolution of a complex network in a novel way. The modular
design detected during its growth is based on the reuse of existing code in
order to minimize costs during programming. The increase of modularity
experienced by the system over time has not counterbalanced the increase in
incompatibilities between software packages within modules. This negative
effect is far from being a failure of design. A random process of package
installation shows that the higher the modularity the larger the fraction of
packages working properly in a local computer. The decrease in the relative
number of conflicts between packages from different modules avoids a failure in
the functionality of one package spreading throughout the entire system. Some
potential analogies with the evolutionary and ecological processes determining
the structure of ecological networks of interacting species are discussed.
</summary>
    <author>
      <name>Miguel A. Fortuna</name>
    </author>
    <author>
      <name>Juan A. Bonachela</name>
    </author>
    <author>
      <name>Simon A. Levin</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1073/pnas.1115960108</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1073/pnas.1115960108" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To appear in PNAS</arxiv:comment>
    <link href="http://arxiv.org/abs/1111.5251v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.5251v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.5348v1</id>
    <updated>2011-11-22T21:44:25Z</updated>
    <published>2011-11-22T21:44:25Z</published>
    <title>A New Round Robin Based Scheduling Algorithm for Operating Systems:
  Dynamic Quantum Using the Mean Average</title>
    <summary>  Round Robin, considered as the most widely adopted CPU scheduling algorithm,
undergoes severe problems directly related to quantum size. If time quantum
chosen is too large, the response time of the processes is considered too high.
On the other hand, if this quantum is too small, it increases the overhead of
the CPU. In this paper, we propose a new algorithm, called AN, based on a new
approach called dynamic-time-quantum; the idea of this approach is to make the
operating systems adjusts the time quantum according to the burst time of the
set of waiting processes in the ready queue. Based on the simulations and
experiments, we show that the new proposed algorithm solves the fixed time
quantum problem and increases the performance of Round Robin.
</summary>
    <author>
      <name>Abbas Noon</name>
    </author>
    <author>
      <name>Ali Kalakech</name>
    </author>
    <author>
      <name>Seifedine Kadry</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 4 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IJCSI International Journal of Computer Science Issues, Vol. 8,
  Issue 3, No. 1, 2011, 224-229</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1111.5348v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.5348v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68N25" scheme="http://arxiv.org/schemas/atom"/>
    <category term="B.1.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1112.4451v2</id>
    <updated>2012-02-17T20:40:00Z</updated>
    <published>2011-12-19T20:07:54Z</published>
    <title>What is an OS?</title>
    <summary>  While the engineering of operating systems is well understood, their formal
structure and properties are not. The latter needs a clear definition of the
purpose of an OS and an identification of the core. In this paper I offer
definitions of the OS, processes and files, and present a few useful
principles. The principles allow us to identify work like closure and
continuation algorithms, in programming languages that is useful for the OS
problem. The definitions and principles should yield a symbolic, albeit
semiquantitative, framework that encompasses practice. Towards that end I
specialise the definitions to describe conventional OSes and identify the core
operations for a single computer OS that can be used to express their
algorithms. The assumptions underlying the algorithms offer the design space
framework. The paging and segmentation algorithms for conventional OSes are
extracted from the framework as a check. Among the insights the emerge is that
an OS is a constructive proof of equivalence between models of computation.
Clear and useful definitions and principles are the first step towards a fully
quantitative structure of an OS.
</summary>
    <author>
      <name>Abhijat Vichare</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Major changes: Improvised the discussion of the implicit assumptions,
  added a sketch of a theory of an OS, and added a figure. Comments welcome. 32
  pages, 5 figures. Submitted</arxiv:comment>
    <link href="http://arxiv.org/abs/1112.4451v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1112.4451v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.4.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.4030v1</id>
    <updated>2012-02-17T22:33:12Z</updated>
    <published>2012-02-17T22:33:12Z</published>
    <title>AdSplit: Separating smartphone advertising from applications</title>
    <summary>  A wide variety of smartphone applications today rely on third-party
advertising services, which provide libraries that are linked into the hosting
application. This situation is undesirable for both the application author and
the advertiser. Advertising libraries require additional permissions, resulting
in additional permission requests to users. Likewise, a malicious application
could simulate the behavior of the advertising library, forging the user's
interaction and effectively stealing money from the advertiser. This paper
describes AdSplit, where we extended Android to allow an application and its
advertising to run as separate processes, under separate user-ids, eliminating
the need for applications to request permissions on behalf of their advertising
libraries.
  We also leverage mechanisms from Quire to allow the remote server to validate
the authenticity of client-side behavior. In this paper, we quantify the degree
of permission bloat caused by advertising, with a study of thousands of
downloaded apps. AdSplit automatically recompiles apps to extract their ad
services, and we measure minimal runtime overhead. We also observe that most ad
libraries just embed an HTML widget within and describe how AdSplit can be
designed with this in mind to avoid any need for ads to have native code.
</summary>
    <author>
      <name>Shashi Shekhar</name>
    </author>
    <author>
      <name>Michael Dietz</name>
    </author>
    <author>
      <name>Dan S. Wallach</name>
    </author>
    <link href="http://arxiv.org/abs/1202.4030v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.4030v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1204.0197v1</id>
    <updated>2012-04-01T11:05:34Z</updated>
    <published>2012-04-01T11:05:34Z</published>
    <title>Windows And Linux Operating Systems From A Security Perspective</title>
    <summary>  Operating systems are vital system software that, without them, humans would
not be able to manage and use computer systems. In essence, an operating system
is a collection of software programs whose role is to manage computer resources
and provide an interface for client applications to interact with the different
computer hardware. Most of the commercial operating systems available today on
the market have buggy code and they exhibit security flaws and vulnerabilities.
In effect, building a trusted operating system that can mostly resist attacks
and provide a secure computing environment to protect the important assets of a
computer is the goal of every operating system manufacturer. This paper deeply
investigates the various security features of the two most widespread and
successful operating systems, Microsoft Windows and Linux. The different
security features, designs, and components of the two systems are to be covered
elaborately, pin-pointing the key similarities and differences between them. In
due course, a head-to-head comparison is to be drawn for each security aspect,
exposing the advantage of one system over the other.
</summary>
    <author>
      <name>Youssef Bassil</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">LACSC - Lebanese Association for Computational Sciences,
  http://www.lacsc.org/; Journal of Global Research in Computer Science, Vol.
  3, No. 2, February 2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1204.0197v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1204.0197v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1205.0124v1</id>
    <updated>2012-05-01T09:17:43Z</updated>
    <published>2012-05-01T09:17:43Z</published>
    <title>Schedulability Test for Soft Real-Time Systems under Multiprocessor
  Environment by using an Earliest Deadline First Scheduling Algorithm</title>
    <summary>  This paper deals with the study of Earliest Deadline First (EDF) which is an
optimal scheduling algorithm for uniprocessor real time systems use for
scheduling the periodic task in soft real-time multiprocessor systems. In hard
real-time systems, a significant disparity exists EDF-based schemes and RMA
scheduling (which is the only known way of optimally scheduling recurrent
real-time tasks on multiprocessors): on M processors, all known EDF variants
have utilization-based schedulability bounds of approximately M/2, while RMA
algorithms can fully utilize all processors. This is unfortunate because EDF
based algorithms entail lower scheduling and task migration overheads. In work
on hard real-time systems, it has been shown that this disparity in
Schedulability can be lessened by placing caps on per task utilizations. Our
main contribution is a new EDF based scheme that ensures bounded deadline
tardiness. In this scheme, per-task utilizations must be focused,but overall
utilization need not be stricted. Our scheme should enable a wide range of soft
real-time applications to be scheduled with no constraints on total
utilization. Also propose techniques and heuristics that can be used to reduce
tardiness as well as increase the efficiency of task.
</summary>
    <author>
      <name>Jagbeer Singh</name>
    </author>
    <author>
      <name>Satyendra Prasad Singh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1205.0124v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1205.0124v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.0396v1</id>
    <updated>2012-06-02T18:22:37Z</updated>
    <published>2012-06-02T18:22:37Z</published>
    <title>Energy-Aware Task Partitioning on Heterogeneous Multiprocessor Platforms</title>
    <summary>  Efficient task partitioning plays a crucial role in achieving high
performance at multiprocessor plat forms. This paper addresses the problem of
energy-aware static partitioning of periodic real-time tasks on heterogeneous
multiprocessor platforms. A Particle Swarm Optimization variant based on
Min-min technique for task partitioning is proposed. The proposed approach aims
to minimize the overall energy consumption, meanwhile avoid deadline
violations. An energy-aware cost function is proposed to be considered in the
proposed approach. Extensive simulations and comparisons are conducted in order
to validate the effectiveness of the proposed technique. The achieved results
demonstrate that the proposed partitioning scheme significantly surpasses
previous approaches in terms of both number of iterations and energy savings.
</summary>
    <author>
      <name>Elsayed Saad</name>
    </author>
    <author>
      <name>Medhat Awadalla</name>
    </author>
    <author>
      <name>Mohamed Shalan</name>
    </author>
    <author>
      <name>Abdullah Elewi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 9 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">the International Journal of Computer Science Issues (IJCSI), Vol.
  9, Issue 2, No. 1, 2012, pp. 176-183</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1206.0396v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.0396v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1208.6391v1</id>
    <updated>2012-08-31T06:32:38Z</updated>
    <published>2012-08-31T06:32:38Z</published>
    <title>On Benchmarking Embedded Linux Flash File Systems</title>
    <summary>  Due to its attractive characteristics in terms of performance, weight and
power consumption, NAND flash memory became the main non volatile memory (NVM)
in embedded systems. Those NVMs also present some specific
characteristics/constraints: good but asymmetric I/O performance, limited
lifetime, write/erase granularity asymmetry, etc. Those peculiarities are
either managed in hardware for flash disks (SSDs, SD cards, USB sticks, etc.)
or in software for raw embedded flash chips. When managed in software, flash
algorithms and structures are implemented in a specific flash file system
(FFS). In this paper, we present a performance study of the most widely used
FFSs in embedded Linux: JFFS2, UBIFS,and YAFFS. We show some very particular
behaviors and large performance disparities for tested FFS operations such as
mounting, copying, and searching file trees, compression, etc.
</summary>
    <author>
      <name>Pierre Olivier</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Lab-STICC</arxiv:affiliation>
    </author>
    <author>
      <name>Jalil Boukhobza</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Lab-STICC</arxiv:affiliation>
    </author>
    <author>
      <name>Eric Senn</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Lab-STICC</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Embed With Linux, Lorient : France (2012)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ACM SIGBED Review 9(2) 43-47 9, 2 (2012) 43-47</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1208.6391v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1208.6391v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.4600v1</id>
    <updated>2012-09-19T03:59:12Z</updated>
    <published>2012-09-19T03:59:12Z</published>
    <title>Classification Of Heterogeneous Operating System</title>
    <summary>  Operating system is a bridge between system and user. An operating system
(OS) is a software program that manages the hardware and software resources of
a computer. The OS performs basic tasks, such as controlling and allocating
memory, prioritizing the processing of instructions, controlling input and
output devices, facilitating networking, and managing files. It is difficult to
present a complete as well as deep account of operating systems developed till
date. So, this paper tries to overview only a subset of the available operating
systems and its different categories. OS are being developed by a large number
of academic and commercial organizations for the last several decades. This
paper, therefore, concentrates on the different categories of OS with special
emphasis to those that had deep impact on the evolution process. The aim of
this paper is to provide a brief timely commentary on the different categories
important operating systems available today.
</summary>
    <author>
      <name>Kamlesh Sharma</name>
    </author>
    <author>
      <name>T. V. Prasad</name>
    </author>
    <link href="http://arxiv.org/abs/1209.4600v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.4600v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.1039v1</id>
    <updated>2012-10-03T09:15:19Z</updated>
    <published>2012-10-03T09:15:19Z</published>
    <title>JooFlux: Hijacking Java 7 InvokeDynamic To Support Live Code
  Modifications</title>
    <summary>  Changing functional and non-functional software implementation at runtime is
useful and even sometimes critical both in development and production
environments. JooFlux is a JVM agent that allows both the dynamic replacement
of method implementations and the application of aspect advices. It works by
doing bytecode transformation to take advantage of the new invokedynamic
instruction added in Java SE 7 to help implementing dynamic languages for the
JVM. JooFlux can be managed using a JMX agent so as to operate dynamic
modifications at runtime, without resorting to a dedicated domain-specific
language. We compared JooFlux with existing AOP platforms and dynamic
languages. Results demonstrate that JooFlux performances are close to the Java
ones --- with most of the time a marginal overhead, and sometimes a gain ---
where AOP platforms and dynamic languages present significant overheads. This
paves the way for interesting future evolutions and applications of JooFlux.
</summary>
    <author>
      <name>Julien Ponge</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CITI</arxiv:affiliation>
    </author>
    <author>
      <name>Frédéric Le Mouël</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CITI</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/1210.1039v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.1039v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.4840v1</id>
    <updated>2012-11-20T19:38:00Z</updated>
    <published>2012-11-20T19:38:00Z</published>
    <title>Multicore Dynamic Kernel Modules Attachment Technique for Kernel
  Performance Enhancement</title>
    <summary>  Traditional monolithic kernels dominated kernel structures for long time
along with small sized kernels,few hardware companies and limited kernel
functionalities. Monolithic kernel structure was not applicable when the number
of hardware companies increased and kernel services consumed by different users
for many purposes. One of the biggest disadvantages of the monolithic kernels
is the inflexibility due to the need to include all the available modules in
kernel compilation causing high time consuming. Lately, new kernel structure
was introduced through multicore operating systems. Unfortunately, many
multicore operating systems such as barrelfish and FOS are experimental. This
paper aims to simulate the performance of multicore hybrid kernels through
dynamic kernel module customized attachment/ deattachment for multicore
machines. In addition, this paper proposes a new technique for loading dynamic
kernel modules based on the user needs and machine capabilities.
</summary>
    <author>
      <name>Mohamed Farag</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5121/ijcsit.2012.4405</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5121/ijcsit.2012.4405" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, International Journal of Computer Science &amp; Information
  Technology (IJCSIT) Vol 4, No 4, August 2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1211.4840v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.4840v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.6185v1</id>
    <updated>2012-11-27T02:36:10Z</updated>
    <published>2012-11-27T02:36:10Z</published>
    <title>Automatic Verification of Message-Based Device Drivers</title>
    <summary>  We develop a practical solution to the problem of automatic verification of
the interface between device drivers and the OS. Our solution relies on a
combination of improved driver architecture and verification tools. It supports
drivers written in C and can be implemented in any existing OS, which sets it
apart from previous proposals for verification-friendly drivers. Our
Linux-based evaluation shows that this methodology amplifies the power of
existing verification tools in detecting driver bugs, making it possible to
verify properties beyond the reach of traditional techniques.
</summary>
    <author>
      <name>Sidney Amani</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">NICTA and UNSW</arxiv:affiliation>
    </author>
    <author>
      <name>Peter Chubb</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">NICTA and UNSW</arxiv:affiliation>
    </author>
    <author>
      <name>Alastair F. Donaldson</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Imperial College London</arxiv:affiliation>
    </author>
    <author>
      <name>Alexander Legg</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">NICTA and UNSW</arxiv:affiliation>
    </author>
    <author>
      <name>Leonid Ryzhyk</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">NICTA and UNSW</arxiv:affiliation>
    </author>
    <author>
      <name>Yanjin Zhu</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">NICTA and UNSW</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.102.3</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.102.3" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings SSV 2012, arXiv:1211.5873</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 102, 2012, pp. 4-17</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1211.6185v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.6185v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.4.4; B.4.2; D.2.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.1787v1</id>
    <updated>2012-12-08T12:56:49Z</updated>
    <published>2012-12-08T12:56:49Z</published>
    <title>A Generic Checkpoint-Restart Mechanism for Virtual Machines</title>
    <summary>  It is common today to deploy complex software inside a virtual machine (VM).
Snapshots provide rapid deployment, migration between hosts, dependability
(fault tolerance), and security (insulating a guest VM from the host). Yet, for
each virtual machine, the code for snapshots is laboriously developed on a
per-VM basis. This work demonstrates a generic checkpoint-restart mechanism for
virtual machines. The mechanism is based on a plugin on top of an unmodified
user-space checkpoint-restart package, DMTCP. Checkpoint-restart is
demonstrated for three virtual machines: Lguest, user-space QEMU, and KVM/QEMU.
The plugins for Lguest and KVM/QEMU require just 200 lines of code. The Lguest
kernel driver API is augmented by 40 lines of code. DMTCP checkpoints
user-space QEMU without any new code. KVM/QEMU, user-space QEMU, and DMTCP need
no modification. The design benefits from other DMTCP features and plugins.
Experiments demonstrate checkpoint and restart in 0.2 seconds using forked
checkpointing, mmap-based fast-restart, and incremental Btrfs-based snapshots.
</summary>
    <author>
      <name>Rohan Garg</name>
    </author>
    <author>
      <name>Komal Sodha</name>
    </author>
    <author>
      <name>Gene Cooperman</name>
    </author>
    <link href="http://arxiv.org/abs/1212.1787v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.1787v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.4800v1</id>
    <updated>2013-01-21T10:00:22Z</updated>
    <published>2013-01-21T10:00:22Z</published>
    <title>Schedulability Analysis of Distributed Real-Time Applications under
  Dependence and Several Latency Constraints</title>
    <summary>  This paper focuses on the analysis of real-time non preemptive multiprocessor
scheduling with precedence and several latency constraints. It aims to specify
a schedulability condition which enables a designer to check a priori -without
executing or simulating- if its scheduling of tasks will hold the precedences
between tasks as well as several latency constraints imposed on determined
pairs of tasks. It is shown that the required analysis is closely linked to the
topological structure of the application graph. More precisely, it depends on
the configuration of tasks paths subject to latency constraints. As a result of
the study, a sufficient schedulability condition is introduced for precedences
and latency constraints in the hardest configuration in term of complexity with
an optimal number of processors in term of applications parallelism. In
addition, the proposed conditions provides a practical lower bounds for general
cases. Performances results and comparisons with an optimal approach
demonstrate the effectiveness of the proposed approach.
</summary>
    <author>
      <name>Omar Kermia</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5120/10145-4978</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5120/10145-4978" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 6 figures, Published with International Journal of Computer
  Applications (IJCA)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Applications 62(14):1-7, January
  2013. Published by Foundation of Computer Science, New York, USA</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1301.4800v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.4800v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1302.5502v1</id>
    <updated>2013-02-22T07:32:48Z</updated>
    <published>2013-02-22T07:32:48Z</published>
    <title>LFTL: A multi-threaded FTL for a Parallel IO Flash Card under Linux</title>
    <summary>  New PCI-e flash cards and SSDs supporting over 100,000 IOPs are now
available, with several usecases in the design of a high performance storage
system. By using an array of flash chips, arranged in multiple banks, large
capacities are achieved. Such multi-banked architecture allow parallel read,
write and erase operations. In a raw PCI-e flash card, such parallelism is
directly available to the software layer. In addition, the devices have
restrictions such as, pages within a block can only be written sequentially.
The devices also have larger minimum write sizes (greater than 4KB). Current
flash translation layers (FTLs) in Linux are not well suited for such devices
due to the high device speeds, architectural restrictions as well as other
factors such as high lock contention. We present a FTL for Linux that takes
into account the hardware restrictions, that also exploits the parallelism to
achieve high speeds. We also consider leveraging the parallelism for garbage
collection by scheduling the garbage collection activities on idle banks. We
propose and evaluate an adaptive method to vary the amount of garbage
collection according to the current I/O load on the device.
</summary>
    <author>
      <name> Srimugunthan</name>
    </author>
    <author>
      <name>K. Gopinath</name>
    </author>
    <author>
      <name>Giridhar Appaji Nag Yasa</name>
    </author>
    <link href="http://arxiv.org/abs/1302.5502v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1302.5502v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.3557v1</id>
    <updated>2013-04-12T07:33:42Z</updated>
    <published>2013-04-12T07:33:42Z</published>
    <title>Survey of Server Virtualization</title>
    <summary>  Virtualization is a term that refers to the abstraction of computer
resources. The purpose of virtual computing environment is to improve resource
utilization by providing a unified integrated operating platform for users and
applications based on aggregation of heterogeneous and autonomous resources.
More recently, virtualization at all levels (system, storage, and network)
became important again as a way to improve system security, reliability and
availability, reduce costs, and provide greater flexibility. Virtualization has
rapidly become a go-to technology for increasing efficiency in the data center.
With virtualization technologies providing tremendous flexibility, even
disparate architectures may be deployed on a single machine without
interference This paper explains the basics of server virtualization and
addresses pros and cons of virtualization
</summary>
    <author>
      <name>Radhwan Y Ameen</name>
    </author>
    <author>
      <name>Asmaa Y. Hamo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages 14 figures. arXiv admin note: text overlap with
  arXiv:1010.3233 by other authors</arxiv:comment>
    <link href="http://arxiv.org/abs/1304.3557v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.3557v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.3771v1</id>
    <updated>2013-04-13T04:04:08Z</updated>
    <published>2013-04-13T04:04:08Z</published>
    <title>Making I/O Virtualization Easy with Device Files</title>
    <summary>  Personal computers have diverse and fast-evolving I/O devices, making their
I/O virtualization different from that of servers and data centers. In this
paper, we present our recent endeavors in simplifying I/O virtualization for
personal computers. Our key insight is that many operating systems, including
Unix-like ones, abstract I/O devices as device files. There is a small and
stable set of operations on device files, therefore, I/O virtualization at the
device file boundary requires a one-time effort to support various I/O devices.
  We present devirtualization, our design of I/O virtualization at the device
file boundary and its implementation for Linux/x86 systems. We are able to
virtualize various GPUs, input devices, cameras, and audio devices with fewer
than 4900 LoC, of which only about 300 are specific to I/O device classes. Our
measurements show that devirtualized devices achieve interactive performance
indistinguishable from native ones by human users, even when running 3D HD
games.
</summary>
    <author>
      <name>Ardalan Amiri Sani</name>
    </author>
    <author>
      <name>Sreekumar Nair</name>
    </author>
    <author>
      <name>Lin Zhong</name>
    </author>
    <author>
      <name>Quinn Jacobson</name>
    </author>
    <link href="http://arxiv.org/abs/1304.3771v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.3771v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.7001v1</id>
    <updated>2013-04-25T11:10:38Z</updated>
    <published>2013-04-25T11:10:38Z</published>
    <title>Network Control Systems RTAI framework A Review</title>
    <summary>  With the advancement in the automation industry, to perform complex remote
operations is required. Advancements in the networking technology has led to
the development of different architectures to implement control from a large
distance. In various control applications of the modern industry, the agents,
such as sensors, actuators, and controllers are basically geographically
distributed. For efficient working of a control application, all of the agents
have to exchange information through a communication media. At present, an
increasing number of distributed control systems are based on platforms made up
of conventional PCs running open-source real-time operating systems. Often,
these systems needed to have networked devices supporting synchronized
operations with respect to each node. A framework is studied that relies on
standard software and protocol as RTAI, EtherCAT, RTnet and IEEE 1588. RTAI and
its various protocols are studied in network control systems environment.
</summary>
    <author>
      <name>Deepika Bhatia</name>
    </author>
    <author>
      <name>Urmila Shrawankar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Pages: 4 Figures : 1</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Science and Information
  Technologies (IJCSIT),Vol. 2(5) , 2011, 2380-2383</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1304.7001v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.7001v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1305.2553v1</id>
    <updated>2013-05-12T02:44:15Z</updated>
    <published>2013-05-12T02:44:15Z</published>
    <title>Practical Fine-grained Privilege Separation in Multithreaded
  Applications</title>
    <summary>  An inherent security limitation with the classic multithreaded programming
model is that all the threads share the same address space and, therefore, are
implicitly assumed to be mutually trusted. This assumption, however, does not
take into consideration of many modern multithreaded applications that involve
multiple principals which do not fully trust each other. It remains challenging
to retrofit the classic multithreaded programming model so that the security
and privilege separation in multi-principal applications can be resolved.
  This paper proposes ARBITER, a run-time system and a set of security
primitives, aimed at fine-grained and data-centric privilege separation in
multithreaded applications. While enforcing effective isolation among
principals, ARBITER still allows flexible sharing and communication between
threads so that the multithreaded programming paradigm can be preserved. To
realize controlled sharing in a fine-grained manner, we created a novel
abstraction named ARBITER Secure Memory Segment (ASMS) and corresponding OS
support. Programmers express security policies by labeling data and principals
via ARBITER's API following a unified model. We ported a widely-used, in-memory
database application (memcached) to ARBITER system, changing only around 100
LOC. Experiments indicate that only an average runtime overhead of 5.6% is
induced to this security enhanced version of application.
</summary>
    <author>
      <name>Jun Wang</name>
    </author>
    <author>
      <name>Xi Xiong</name>
    </author>
    <author>
      <name>Peng Liu</name>
    </author>
    <link href="http://arxiv.org/abs/1305.2553v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1305.2553v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.4.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1305.3345v1</id>
    <updated>2013-05-15T02:53:19Z</updated>
    <published>2013-05-15T02:53:19Z</published>
    <title>Augmenting Operating Systems With the GPU</title>
    <summary>  The most popular heterogeneous many-core platform, the CPU+GPU combination,
has received relatively little attention in operating systems research. This
platform is already widely deployed: GPUs can be found, in some form, in most
desktop and laptop PCs. Used for more than just graphics processing, modern
GPUs have proved themselves versatile enough to be adapted to other
applications as well. Though GPUs have strengths that can be exploited in
systems software, this remains a largely untapped resource. We argue that
augmenting the OS kernel with GPU computing power opens the door to a number of
new opportunities. GPUs can be used to speed up some kernel functions, make
other scale better, and make it feasible to bring some computation-heavy
functionality into the kernel. We present our framework for using the GPU as a
co-processor from an OS kernel, and demonstrate a prototype in Linux.
</summary>
    <author>
      <name>Weibin Sun</name>
    </author>
    <author>
      <name>Robert Ricci</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 2 figures, old white paper submitted for KGPU citation</arxiv:comment>
    <link href="http://arxiv.org/abs/1305.3345v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1305.3345v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.4.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1306.1316v1</id>
    <updated>2013-06-06T06:57:57Z</updated>
    <published>2013-06-06T06:57:57Z</published>
    <title>Partitioned scheduling of multimode multiprocessor real-time systems
  with temporal isolation</title>
    <summary>  We consider the partitioned scheduling problem of multimode real-time systems
upon identical multiprocessor platforms. During the execution of a multimode
system, the system can change from one mode to another such that the current
task set is replaced with a new one. In this paper, we consider a synchronous
transition protocol in order to take into account mode-independent tasks, i.e.,
tasks of which the execution pattern must not be jeopardized by the mode
changes. We propose two methods for handling mode changes in partitioned
scheduling. The first method is offline/optimal and computes a static
allocation of tasks schedulable and respecting both tasks and transition
deadlines (if any). The second approach is subject to a sufficient condition in
order to ensure online First Fit based allocation to satisfy the timing
constraints.
</summary>
    <author>
      <name>Joël Goossens</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">ULB</arxiv:affiliation>
    </author>
    <author>
      <name>Pascal Richard</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIAS/Ensma and Université de Poitiers</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/1306.1316v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1306.1316v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.4165v1</id>
    <updated>2013-07-16T05:21:34Z</updated>
    <published>2013-07-16T05:21:34Z</published>
    <title>A Comparative Study of CPU Scheduling Algorithms</title>
    <summary>  Developing CPU scheduling algorithms and understanding their impact in
practice can be difficult and time consuming due to the need to modify and test
operating system kernel code and measure the resulting performance on a
consistent workload of real applications. As processor is the important
resource, CPU scheduling becomes very important in accomplishing the operating
system (OS) design goals. The intention should be allowed as many as possible
running processes at all time in order to make best use of CPU. This paper
presents a state diagram that depicts the comparative study of various
scheduling algorithms for a single CPU and shows which algorithm is best for
the particular situation. Using this representation, it becomes much easier to
understand what is going on inside the system and why a different set of
processes is a candidate for the allocation of the CPU at different time. The
objective of the study is to analyze the high efficient CPU scheduler on design
of the high quality scheduling algorithms which suits the scheduling goals. Key
Words:-Scheduler, State Diagrams, CPU-Scheduling, Performance
</summary>
    <author>
      <name>Neetu Goel</name>
    </author>
    <author>
      <name>R. B. Garg</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Graphics &amp; Image Processing |Vol 2|issue
  4|November 2012</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1307.4165v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.4165v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1307.4167v1</id>
    <updated>2013-07-16T05:25:16Z</updated>
    <published>2013-07-16T05:25:16Z</published>
    <title>An Optimum Multilevel Dynamic Round Robin Scheduling Algorithm</title>
    <summary>  The main objective of this paper is to improve the Round Robin scheduling
algorithm using the dynamic time slice concept. CPU scheduling becomes very
important in accomplishing the operating system (OS) design goals. The
intention should be allowed as many as possible running processes at all time
in order to make best use of CPU. CPU scheduling has strong effect on resource
utilization as well as overall performance of the system. Round Robin algorithm
performs optimally in time-shared systems, but it is not suitable for soft real
time systems, because it gives more number of context switches, larger waiting
time and larger response time. In this paper, a new CPU scheduling algorithm
called An Optimum Multilevel Dynamic Round Robin Scheduling Algorithm is
proposed, which calculates intelligent time slice and changes after every round
of execution. The suggested algorithm was evaluated on some CPU scheduling
objectives and it was observed that this algorithm gave good performance as
compared to the other existing CPU scheduling algorithms.
</summary>
    <author>
      <name>Neetu Goel</name>
    </author>
    <author>
      <name>R. B. Garg</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Published in National Conference on Information Communication &amp;
  Networks, Dated: April 6,2013 organized by Tecnia Institute of Advanced
  Studies</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1307.4167v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1307.4167v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1308.1199v1</id>
    <updated>2013-08-06T07:54:19Z</updated>
    <published>2013-08-06T07:54:19Z</published>
    <title>Intensional view of General Single Processor Operating Systems</title>
    <summary>  Operating systems are currently viewed ostensively. As a result they mean
different things to different people. The ostensive character makes it is hard
to understand OSes formally. An intensional view can enable better formal work,
and also offer constructive support for some important problems, e.g. OS
architecture. This work argues for an intensional view of operating systems. It
proposes to overcome the current ostensive view by defining an OS based on
formal models of computation, and also introduces some principles. Together
these are used to develop a framework of algorithms of single processor OS
structure using an approach similar to function level programming. In this
abridged paper we illustrate the essential approach, discuss some advantages
and limitations and point out some future possibilities.
</summary>
    <author>
      <name>Abhijat Vichare</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages, 3 figures. Condensed and improved version of
  http://arxiv.org/abs/1112.4451 for submission to SOSP'13. arXiv admin note:
  substantial text overlap with arXiv:1112.4451</arxiv:comment>
    <link href="http://arxiv.org/abs/1308.1199v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1308.1199v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.4.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1309.1714v1</id>
    <updated>2013-09-06T18:14:04Z</updated>
    <published>2013-09-06T18:14:04Z</published>
    <title>Flashmon V2: Monitoring Raw NAND Flash Memory I/O Requests on Embedded
  Linux</title>
    <summary>  This paper presents Flashmon version 2, a tool for monitoring embedded Linux
NAND flash memory I/O requests. It is designed for embedded boards based
devices containing raw flash chips. Flashmon is a kernel module and stands for
"flash monitor". It traces flash I/O by placing kernel probes at the NAND
driver level. It allows tracing at runtime the 3 main flash operations: page
reads / writes and block erasures. Flashmon is (1) generic as it was
successfully tested on the three most widely used flash file systems that are
JFFS2, UBIFS and YAFFS, and several NAND chip models. Moreover, it is (2) non
intrusive, (3) has a controllable memory footprint, and (4) exhibits a low
overhead (&lt;6%) on the traced system. Finally, it is (5) simple to integrate and
used as a standalone module or as a built-in function / module in existing
kernel sources. Monitoring flash memory operations allows a better
understanding of existing flash management systems by studying and analyzing
their behavior. Moreover it is useful in development phase for prototyping and
validating new solutions.
</summary>
    <author>
      <name>Pierre Olivier</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Lab-STICC</arxiv:affiliation>
    </author>
    <author>
      <name>Jalil Boukhobza</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Lab-STICC</arxiv:affiliation>
    </author>
    <author>
      <name>Eric Senn</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Lab-STICC</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">EWiLi, the Embedded Operating Systems Workshop, Toulouse : France
  (2013)</arxiv:comment>
    <link href="http://arxiv.org/abs/1309.1714v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1309.1714v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1309.3096v1</id>
    <updated>2013-09-12T10:26:10Z</updated>
    <published>2013-09-12T10:26:10Z</published>
    <title>Simulation of an Optimum Multilevel Dynamic Round Robin Scheduling
  Algorithm</title>
    <summary>  CPU scheduling has valiant effect on resource utilization as well as overall
quality of the system. Round Robin algorithm performs optimally in time shared
systems, but it performs more number of context switches, larger waiting time
and larger response time. In order to simulate the behavior of various CPU
scheduling algorithms and to improve Round Robin scheduling algorithm using
dynamic time slice concept, in this paper we produce the implementation of new
CPU scheduling algorithm called An Optimum Multilevel Dynamic Round Robin
Scheduling (OMDRRS), which calculates intelligent time slice and warps after
every round of execution. The results display the robustness of this software,
especially for academic, research and experimental use, as well as proving the
desirability and efficiency of the probabilistic algorithm over the other
existing techniques and it is observed that this OMDRRS projects good
performance as compared to the other existing CPU scheduling algorithms.
</summary>
    <author>
      <name>Neetu Goel</name>
    </author>
    <author>
      <name>R. B. Garg</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5120/13263-0743</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5120/13263-0743" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Applications, Aug 2013</arxiv:comment>
    <link href="http://arxiv.org/abs/1309.3096v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1309.3096v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.1588v1</id>
    <updated>2013-10-06T14:27:59Z</updated>
    <published>2013-10-06T14:27:59Z</published>
    <title>Impacting the bioscience progress by backporting software for Bio-Linux</title>
    <summary>  In year 2006 Bio-Linux with the work of Tim Booth and team gives its rising
and provide an operating system that was and still specialized in providing a
bioinformatic specific software environment for the working needs in this
corner of bioscience. It is shown that Bio-Linux is affected by a 2 year
release cycle and with this the final releases of Bio-Linux will not have the
latest bioinformatic software on board. The paper shows how to get around this
huge time gap and bring new software for Bio-Linux on board through a process
that is called backporting. A summary of within the work to this paper just
backported bioinformatic tools is given. A describtion of a workflow for
continuously integration of the newest bioinformatic tools gives an outlook to
further concrete planned developments and the influence of speeding up
scientific progress.
</summary>
    <author>
      <name>Sasa Paporovic</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages,2 Figures, 1 Table and 1 notice</arxiv:comment>
    <link href="http://arxiv.org/abs/1310.1588v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.1588v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.6298v1</id>
    <updated>2013-10-23T17:14:25Z</updated>
    <published>2013-10-23T17:14:25Z</published>
    <title>The Quest-V Separation Kernel for Mixed Criticality Systems</title>
    <summary>  Multi- and many-core processors are becoming increasingly popular in embedded
systems. Many of these processors now feature hardware virtualization
capabilities, such as the ARM Cortex A15, and x86 processors with Intel VT-x or
AMD-V support. Hardware virtualization offers opportunities to partition
physical resources, including processor cores, memory and I/O devices amongst
guest virtual machines. Mixed criticality systems and services can then
co-exist on the same platform in separate virtual machines. However,
traditional virtual machine systems are too expensive because of the costs of
trapping into hypervisors to multiplex and manage machine physical resources on
behalf of separate guests. For example, hypervisors are needed to schedule
separate VMs on physical processor cores. In this paper, we discuss the design
of the Quest-V separation kernel, that partitions services of different
criticalities in separate virtual machines, or sandboxes. Each sandbox
encapsulates a subset of machine physical resources that it manages without
requiring intervention of a hypervisor. Moreover, a hypervisor is not needed
for normal operation, except to bootstrap the system and establish
communication channels between sandboxes.
</summary>
    <author>
      <name>Ye Li</name>
    </author>
    <author>
      <name>Richard West</name>
    </author>
    <author>
      <name>Eric Missimer</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1310.6298v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.6298v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.6301v1</id>
    <updated>2013-10-23T17:29:42Z</updated>
    <published>2013-10-23T17:29:42Z</published>
    <title>Predictable Migration and Communication in the Quest-V Multikernel</title>
    <summary>  Quest-V is a system we have been developing from the ground up, with
objectives focusing on safety, predictability and efficiency. It is designed to
work on emerging multicore processors with hardware virtualization support.
Quest-V is implemented as a "distributed system on a chip" and comprises
multiple sandbox kernels. Sandbox kernels are isolated from one another in
separate regions of physical memory, having access to a subset of processing
cores and I/O devices. This partitioning prevents system failures in one
sandbox affecting the operation of other sandboxes. Shared memory channels
managed by system monitors enable inter-sandbox communication.
  The distributed nature of Quest-V means each sandbox has a separate physical
clock, with all event timings being managed by per-core local timers. Each
sandbox is responsible for its own scheduling and I/O management, without
requiring intervention of a hypervisor.
  In this paper, we formulate bounds on inter-sandbox communication in the
absence of a global scheduler or global system clock. We also describe how
address space migration between sandboxes can be guaranteed without violating
service constraints. Experimental results on a working system show the
conditions under which Quest-V performs real-time communication and migration.
</summary>
    <author>
      <name>Ye Li</name>
    </author>
    <author>
      <name>Eric Missimer</name>
    </author>
    <author>
      <name>Richard West</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1310.6301v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.6301v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.6349v1</id>
    <updated>2013-10-23T17:35:03Z</updated>
    <published>2013-10-23T17:35:03Z</published>
    <title>Quest-V: A Virtualized Multikernel for Safety-Critical Real-Time Systems</title>
    <summary>  Modern processors are increasingly featuring multiple cores, as well as
support for hardware virtualization. While these processors are common in
desktop and server-class computing, they are less prevalent in embedded and
real-time systems. However, smartphones and tablet PCs are starting to feature
multicore processors with hardware virtualization. If the trend continues, it
is possible that future real-time systems will feature more sophisticated
processor architectures. Future automotive or avionics systems, for example,
could replace complex networks of uniprocessors with consolidated services on a
smaller number of multicore processors. Likewise, virtualization could be used
to isolate services and increase the availability of a system even when
failures occur.
  This paper investigates whether advances in modern processor technologies
offer new opportunities to rethink the design of real-time operating systems.
We describe some of the design principles behind Quest-V, which is being used
as an exploratory vehicle for real-time system design on multicore processors
with hardware virtualization capabilities. While not all embedded systems
should assume such features, a case can be made that more robust,
safety-critical systems can be built to use hardware virtualization without
incurring significant overheads.
</summary>
    <author>
      <name>Richard West</name>
    </author>
    <author>
      <name>Ye Li</name>
    </author>
    <author>
      <name>Eric Missimer</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages. arXiv admin note: text overlap with arXiv:1112.5136,
  arXiv:1310.6301</arxiv:comment>
    <link href="http://arxiv.org/abs/1310.6349v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.6349v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1311.3686v1</id>
    <updated>2013-11-13T10:53:02Z</updated>
    <published>2013-11-13T10:53:02Z</published>
    <title>Performance Evaluation of Java File Security System (JFSS)</title>
    <summary>  Security is a critical issue of the modern file and storage systems, it is
imperative to protect the stored data from unauthorized access. We have
developed a file security system named as Java File Security System (JFSS) [1]
that guarantee the security to files on the demand of all users. It has been
developed on Java platform. Java has been used as programming language in order
to provide portability, but it enforces some performance limitations. It is
developed in FUSE (File System in User space) [3]. Many efforts have been done
over the years for developing file systems in user space (FUSE). All have their
own merits and demerits. In this paper we have evaluated the performance of
Java File Security System (JFSS). Over and over again, the increased security
comes at the expense of user convenience, performance or compatibility with
other systems. JFSS system performance evaluations show that encryption
overheads are modest as compared to security.
</summary>
    <author>
      <name>Brijender Kahanwal</name>
    </author>
    <author>
      <name>Dr. Tejinder Pal Singh</name>
    </author>
    <author>
      <name>Dr. R. K. Tuteja</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 5 figures, journal</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Pelagia Research Library Advances in Applied Science Research,
  Vol. 2(6), pp. 254-260, 2011</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1311.3686v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1311.3686v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1312.3665v2</id>
    <updated>2014-05-05T16:05:35Z</updated>
    <published>2013-12-12T22:38:08Z</published>
    <title>Managing NymBoxes for Identity and Tracking Protection</title>
    <summary>  Despite the attempts of well-designed anonymous communication tools to
protect users from tracking or identification, flaws in surrounding software
(such as web browsers) and mistakes in configuration may leak the user's
identity. We introduce Nymix, an anonymity-centric operating system
architecture designed "top-to-bottom" to strengthen identity- and
tracking-protection. Nymix's core contribution is OS support for nym-browsing:
independent, parallel, and ephemeral web sessions. Each web session, or
pseudonym, runs in a unique virtual machine (VM) instance evolving from a
common base state with support for long-lived sessions which can be anonymously
stored to the cloud, avoiding de-anonymization despite potential confiscation
or theft. Nymix allows a user to safely browse the Web using various different
transports simultaneously through a pluggable communication model that supports
Tor, Dissent, and a private browsing mode. In evaluations, Nymix consumes 600
MB per nymbox and loads within 15 to 25 seconds.
</summary>
    <author>
      <name>David Isaac Wolinsky</name>
    </author>
    <author>
      <name>Bryan Ford</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 7 figure, 1 table</arxiv:comment>
    <link href="http://arxiv.org/abs/1312.3665v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1312.3665v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1312.4931v1</id>
    <updated>2013-12-17T20:43:33Z</updated>
    <published>2013-12-17T20:43:33Z</published>
    <title>Rio: A System Solution for Sharing I/O between Mobile Systems</title>
    <summary>  Mobile systems are equipped with a diverse collection of I/O devices,
including cameras, microphones, sensors, and modems. There exist many novel use
cases for allowing an application on one mobile system to utilize I/O devices
from another. This paper presents Rio, an I/O sharing solution that supports
unmodified applications and exposes all the functionality of an I/O device for
sharing. Rio's design is common to many classes of I/O devices, thus
significantly reducing the engineering effort to support new I/O devices. Our
implementation of Rio on Android consists of 6700 total lines of code and
supports four I/O classes with fewer than 450 class-specific lines of code. Rio
also supports I/O sharing between mobile systems of different form factors,
including smartphones and tablets. We show that Rio achieves performance close
to that of local I/O for audio, sensors, and modems, but suffers noticeable
performance degradation for camera due to network throughput limitations
between the two systems, which is likely to be alleviated by emerging wireless
standards.
</summary>
    <author>
      <name>Ardalan Amiri Sani</name>
    </author>
    <author>
      <name>Kevin Boos</name>
    </author>
    <author>
      <name>Min Hong Yun</name>
    </author>
    <author>
      <name>Lin Zhong</name>
    </author>
    <link href="http://arxiv.org/abs/1312.4931v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1312.4931v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1312.6650v2</id>
    <updated>2014-02-03T23:01:55Z</updated>
    <published>2013-12-23T19:19:40Z</published>
    <title>Transparent Checkpoint-Restart for Hardware-Accelerated 3D Graphics</title>
    <summary>  Providing fault-tolerance for long-running GPU-intensive jobs requires
application-specific solutions, and often involves saving the state of complex
data structures spread among many graphics libraries. This work describes a
mechanism for transparent GPU-independent checkpoint-restart of 3D graphics.
The approach is based on a record-prune-replay paradigm: all OpenGL calls
relevant to the graphics driver state are recorded; calls not relevant to the
internal driver state as of the last graphics frame prior to checkpoint are
discarded; and the remaining calls are replayed on restart. A previous approach
for OpenGL 1.5, based on a shadow device driver, required more than 78,000
lines of OpenGL-specific code. In contrast, the new approach, based on
record-prune-replay, is used to implement the same case in just 4,500 lines of
code. The speed of this approach varies between 80 per cent and nearly 100 per
cent of the speed of the native hardware acceleration for OpenGL 1.5, as
measured when running the ioquake3 game under Linux. This approach has also
been extended to demonstrate checkpointing of OpenGL 3.0 for the first time,
with a demonstration for PyMol, for molecular visualization.
</summary>
    <author>
      <name>Samaneh Kazemi Nafchi</name>
    </author>
    <author>
      <name>Rohan Garg</name>
    </author>
    <author>
      <name>Gene Cooperman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages, 6 figures, 4 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1312.6650v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1312.6650v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.4.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1403.0334v1</id>
    <updated>2014-03-03T08:13:29Z</updated>
    <published>2014-03-03T08:13:29Z</published>
    <title>Design and Performance Evaluation of an Optimized Disk Scheduling
  Algorithm (ODSA)</title>
    <summary>  Management of disk scheduling is a very important aspect of operating system.
Performance of the disk scheduling completely depends on how efficient is the
scheduling algorithm to allocate services to the request in a better manner.
Many algorithms (FIFO, SSTF, SCAN, C-SCAN, LOOK, etc.) are developed in the
recent years in order to optimize the system disk I/O performance. By reducing
the average seek time and transfer time, we can improve the performance of disk
I/O operation. In our proposed algorithm, Optimize Disk Scheduling Algorithm
(ODSA) is taking less average seek time and transfer time as compare to other
disk scheduling algorithms (FIFO, SSTF, SCAN, C-SCAN, LOOK, etc.), which
enhances the efficiency of the disk performance in a better manner.
</summary>
    <author>
      <name>Sourav Kumar Bhoi</name>
    </author>
    <author>
      <name>Sanjaya Kumar Panda</name>
    </author>
    <author>
      <name>Imran Hossain Faruk</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5120/5010-7329 10.5120/5010-7329 10.5120/5010-7329 10.5120/5010-7329
  10.5120/5010-7329</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5120/5010-7329" rel="related"/>
    <link title="doi" href="http://dx.doi.org/10.5120/5010-7329" rel="related"/>
    <link title="doi" href="http://dx.doi.org/10.5120/5010-7329" rel="related"/>
    <link title="doi" href="http://dx.doi.org/10.5120/5010-7329" rel="related"/>
    <link title="doi" href="http://dx.doi.org/" rel="related"/>
    <link title="doi" href="http://dx.doi.org/" rel="related"/>
    <link title="doi" href="http://dx.doi.org/10.5120/5010-7329" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 26 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Applications 2012</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1403.0334v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1403.0334v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1403.0335v1</id>
    <updated>2014-03-03T08:27:29Z</updated>
    <published>2014-03-03T08:27:29Z</published>
    <title>A Group based Time Quantum Round Robin Algorithm using Min-Max Spread
  Measure</title>
    <summary>  Round Robin (RR) Scheduling is the basis of time sharing environment. It is
the combination of First Come First Served (FCFS) scheduling algorithm and
preemption among processes. It is basically used in a time sharing operating
system. It switches from one process to another process in a time interval. The
time interval or Time Quantum (TQ) is fixed for all available processes. So,
the larger process suffers from Context Switches (CS). To increase efficiency,
we have to select different TQ for processes. The main objective of RR is to
reduce the CS, maximize the utilization of CPU and minimize the turn around and
the waiting time. In this paper, we have considered different TQ for a group of
processes. It reduces CS as well as enhancing the performance of RR algorithm.
TQ can be calculated using min-max dispersion measure. Our experimental
analysis shows that Group Based Time Quantum (GBTQ) RR algorithm performs
better than existing RR algorithm with respect to Average Turn Around Time
(ATAT), Average Waiting Time (AWT) and CS.
</summary>
    <author>
      <name>Sanjaya Kumar Panda</name>
    </author>
    <author>
      <name>Debasis Dash</name>
    </author>
    <author>
      <name>Jitendra Kumar Rout</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5120/10667-5445</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5120/10667-5445" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 16 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Applications 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1403.0335v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1403.0335v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1403.5976v1</id>
    <updated>2014-03-21T05:31:33Z</updated>
    <published>2014-03-21T05:31:33Z</published>
    <title>File System Design Approaches</title>
    <summary>  In this article, the file system development design approaches are discussed.
The selection of the file system design approach is done according to the needs
of the developers what are the needed requirements and specifications for the
new design. It allowed us to identify where our proposal fitted in with
relation to current and past file system development. Our experience with file
system development is limited so the research served to identify the different
techniques that can be used. The variety of file systems encountered show what
an active area of research file system development is. The file systems may be
from one of the two fundamental categories. In one category, the file system is
developed in user space and runs as a user process. Another file system may be
developed in the kernel space and runs as a privileged process. Another one is
the mixed approach in which we can take the advantages of both aforesaid
approaches. Each development option has its own pros and cons. In this article,
these design approaches are discussed.
</summary>
    <author>
      <name>Brijender Kahanwal</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 6 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Advances in Engineering Sciences,2014,
  Vol. 4(1), PP 16-20</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1403.5976v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1403.5976v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.0088v1</id>
    <updated>2014-04-01T00:40:01Z</updated>
    <published>2014-04-01T00:40:01Z</published>
    <title>Toward Parametric Timed Interfaces for Real-Time Components</title>
    <summary>  We propose here a framework to model real-time components consisting of
concurrent real-time tasks running on a single processor, using parametric
timed automata. Our framework is generic and modular, so as to be easily
adapted to different schedulers and more complex task models. We first perform
a parametric schedulability analysis of the components using the inverse
method. We show that the method unfortunately does not provide satisfactory
results when the task periods are consid- ered as parameters. After identifying
and explaining the problem, we present a solution adapting the model by making
use of the worst-case scenario in schedulability analysis. We show that the
analysis with the inverse method always converges on the modified model when
the system load is strictly less than 100%. Finally, we show how to use our
parametric analysis for the generation of timed interfaces in compositional
system design.
</summary>
    <author>
      <name>Youcheng Sun</name>
    </author>
    <author>
      <name>Giuseppe Lipari</name>
    </author>
    <author>
      <name>Étienne André</name>
    </author>
    <author>
      <name>Laurent Fribourg</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.145.6</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.145.6" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings SynCoP 2014, arXiv:1403.7841</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 145, 2014, pp. 49-64</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1404.0088v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.0088v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.5869v1</id>
    <updated>2014-04-23T15:55:50Z</updated>
    <published>2014-04-23T15:55:50Z</published>
    <title>An Effective Round Robin Algorithm using Min-Max Dispersion Measure</title>
    <summary>  Round Robin (RR) scheduling algorithm is a preemptive scheduling algorithm.
It is designed especially for time sharing Operating System (OS). In RR
scheduling algorithm the CPU switches between the processes when the static
Time Quantum (TQ) expires. RR scheduling algorithm is considered as the most
widely used scheduling algorithm in research because the TQ is equally shared
among the processes. In this paper a newly proposed variant of RR algorithm
called Min-Max Round Robin (MMRR) scheduling algorithm is presented. The idea
of this MMRR is to make the TQ repeatedly adjusted using Min-Max dispersion
measure in accordance with remaining CPU burst time. Our experimental analysis
shows that MMRR performs much better than RR algorithm in terms of average
turnaround time, average waiting time and number of context switches.
</summary>
    <author>
      <name>Sanjaya Kumar Panda</name>
    </author>
    <author>
      <name>Sourav Kumar Bhoi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 15 figures. International Journal on Computer Science and
  Engineering (IJCSE), 2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1404.5869v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.5869v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.6087v1</id>
    <updated>2014-04-24T11:06:06Z</updated>
    <published>2014-04-24T11:06:06Z</published>
    <title>Enhancing CPU Performance using Subcontrary Mean Dynamic Round Robin
  (SMDRR) Scheduling Algorithm</title>
    <summary>  Round Robin (RR) Algorithm is considered as optimal in time shared
environment because the static time is equally shared among the processes. If
the time quantum taken is static then it undergoes degradation of the CPU
performance and leads to so many context switches. In this paper, we have
proposed a new effective dynamic RR algorithm SMDRR (Subcontrary Mean Dynamic
Round Robin) based on dynamic time quantum where we use the subcontrary mean or
harmonic mean to find the time quantum. The idea of this approach is to make
the time quantum repeatedly adjusted according to the burst time of the
currently running processes. Our experimental analysis shows that SMDRR
performs better than RR algorithm in terms of reducing the number of context
switches, average turnaround time and average waiting time.
</summary>
    <author>
      <name>Sourav Kumar Bhoi</name>
    </author>
    <author>
      <name>Sanjaya Kumar Panda</name>
    </author>
    <author>
      <name>Debashee Tarai</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 13 figures. Journal of Global Research in Computer Science
  2011. arXiv admin note: text overlap with arXiv:1103.3832 by other authors</arxiv:comment>
    <link href="http://arxiv.org/abs/1404.6087v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.6087v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.2912v1</id>
    <updated>2014-05-12T16:41:23Z</updated>
    <published>2014-05-12T16:41:23Z</published>
    <title>Heterogeneity-aware Fault Tolerance using a Self-Organizing Runtime
  System</title>
    <summary>  Due to the diversity and implicit redundancy in terms of processing units and
compute kernels, off-the-shelf heterogeneous systems offer the opportunity to
detect and tolerate faults during task execution in hardware as well as in
software. To automatically leverage this diversity, we introduce an extension
of an online-learning runtime system that combines the benefits of the existing
performance-oriented task mapping with task duplication, a diversity-oriented
mapping strategy and heterogeneity-aware majority voter. This extension uses a
new metric to dynamically rate the remaining benefit of unreliable processing
units and a memory management mechanism for automatic data transfers and
checkpointing in the host and device memories.
</summary>
    <author>
      <name>Mario Kicherer</name>
    </author>
    <author>
      <name>Wolfgang Karl</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented at 1st Workshop on Resource Awareness and Adaptivity in
  Multi-Core Computing (Racing 2014) (arXiv:1405.2281)</arxiv:comment>
    <link href="http://arxiv.org/abs/1405.2912v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.2912v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.5651v1</id>
    <updated>2014-05-22T07:52:45Z</updated>
    <published>2014-05-22T07:52:45Z</published>
    <title>Hello rootKitty: A lightweight invariance-enforcing framework</title>
    <summary>  In monolithic operating systems, the kernel is the piece of code that
executes with the highest privileges and has control over all the software
running on a host. A successful attack against an operating system's kernel
means a total and complete compromise of the running system. These attacks
usually end with the installation of a rootkit, a stealthy piece of software
running with kernel privileges. When a rootkit is present, no guarantees can be
made about the correctness, privacy or isolation of the operating system.
  In this paper we present \emph{Hello rootKitty}, an invariance-enforcing
framework which takes advantage of current virtualization technology to protect
a guest operating system against rootkits. \emph{Hello rootKitty} uses the idea
of invariance to detect maliciously modified kernel data structures and restore
them to their original legitimate values. Our prototype has negligible
performance and memory overhead while effectively protecting commodity
operating systems from modern rootkits.
</summary>
    <author>
      <name>Francesco Gadaleta</name>
    </author>
    <author>
      <name>Nick Nikiforakis</name>
    </author>
    <author>
      <name>Yves Younan</name>
    </author>
    <author>
      <name>Wouter Joosen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, ISC Information Security Conference, Xi'an China, 2011,
  Springer</arxiv:comment>
    <link href="http://arxiv.org/abs/1405.5651v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.5651v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.7322v1</id>
    <updated>2014-05-28T18:28:45Z</updated>
    <published>2014-05-28T18:28:45Z</published>
    <title>Supporting Soft Real-Time Sporadic Task Systems on Heterogeneous
  Multiprocessors with No Utilization Loss</title>
    <summary>  Heterogeneous multicore architectures are becoming increasingly popular due
to their potential of achieving high performance and energy efficiency compared
to the homogeneous multicore architectures. In such systems, the real-time
scheduling problem becomes more challenging in that processors have different
speeds. A job executing on a processor with speed $x$ for $t$ time units
completes $(x \cdot t)$ units of execution. Prior research on heterogeneous
multiprocessor real-time scheduling has focused on hard real-time systems,
where, significant processing capacity may have to be sacrificed in the
worst-case to ensure that all deadlines are met. As meeting hard deadlines is
overkill for many soft real-time systems in practice, this paper shows that on
soft real-time heterogeneous multiprocessors, bounded response times can be
ensured for globally-scheduled sporadic task systems with no utilization loss.
A GEDF-based scheduling algorithm, namely GEDF-H, is presented and response
time bounds are established under both preemptive and non-preemptive GEDF-H
scheduling. Extensive experiments show that the magnitude of the derived
response time bound is reasonable, often smaller than three task periods. To
the best of our knowledge, this paper is the first to show that soft real-time
sporadic task systems can be supported on heterogeneous multiprocessors without
utilization loss, and with reasonable predicted response time.
</summary>
    <author>
      <name>Guangmo Tong</name>
    </author>
    <author>
      <name>Cong Liu</name>
    </author>
    <link href="http://arxiv.org/abs/1405.7322v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.7322v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1407.0122v1</id>
    <updated>2014-07-01T07:23:10Z</updated>
    <published>2014-07-01T07:23:10Z</published>
    <title>Effects of Hard Real-Time Constraints in Implementing the Myopic
  Scheduling Algorithm</title>
    <summary>  Myopic is a hard real-time process scheduling algorithm that selects a
suitable process based on a heuristic function from a subset (Window)of all
ready processes instead of choosing from all available processes, like original
heuristic scheduling algorithm. Performance of the algorithm significantly
depends on the chosen heuristic function that assigns weight to different
parameters like deadline, earliest starting time, processing time etc. and the
sizeof the Window since it considers only k processes from n processes (where,
k&lt;= n). This research evaluates the performance of the Myopic algorithm for
different parameters to demonstrate the merits and constraints of the
algorithm. A comparative performance of the impact of window size in
implementing the Myopic algorithm is presented and discussed through a set of
experiments.
</summary>
    <author>
      <name>Kazi Sakib</name>
    </author>
    <author>
      <name>M. S. Hasan</name>
    </author>
    <author>
      <name>M. A. Hossain</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, Journal of Computer Science (JCS), Bangladesh, Vol. 1, No.
  2, December, 2007</arxiv:comment>
    <link href="http://arxiv.org/abs/1407.0122v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1407.0122v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1411.3777v1</id>
    <updated>2014-11-14T02:30:08Z</updated>
    <published>2014-11-14T02:30:08Z</published>
    <title>Glider: A GPU Library Driver for Improved System Security</title>
    <summary>  Legacy device drivers implement both device resource management and
isolation. This results in a large code base with a wide high-level interface
making the driver vulnerable to security attacks. This is particularly
problematic for increasingly popular accelerators like GPUs that have large,
complex drivers. We solve this problem with library drivers, a new driver
architecture. A library driver implements resource management as an untrusted
library in the application process address space, and implements isolation as a
kernel module that is smaller and has a narrower lower-level interface (i.e.,
closer to hardware) than a legacy driver. We articulate a set of device and
platform hardware properties that are required to retrofit a legacy driver into
a library driver. To demonstrate the feasibility and superiority of library
drivers, we present Glider, a library driver implementation for two GPUs of
popular brands, Radeon and Intel. Glider reduces the TCB size and attack
surface by about 35% and 84% respectively for a Radeon HD 6450 GPU and by about
38% and 90% respectively for an Intel Ivy Bridge GPU. Moreover, it incurs no
performance cost. Indeed, Glider outperforms a legacy driver for applications
requiring intensive interactions with the device driver, such as applications
using the OpenGL immediate mode API.
</summary>
    <author>
      <name>Ardalan Amiri Sani</name>
    </author>
    <author>
      <name>Lin Zhong</name>
    </author>
    <author>
      <name>Dan S. Wallach</name>
    </author>
    <link href="http://arxiv.org/abs/1411.3777v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1411.3777v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1501.01370v1</id>
    <updated>2015-01-07T05:51:19Z</updated>
    <published>2015-01-07T05:51:19Z</published>
    <title>A Case Study: Task Scheduling Methodologies for High Speed Computing
  Systems</title>
    <summary>  High Speed computing meets ever increasing real-time computational demands
through the leveraging of flexibility and parallelism. The flexibility is
achieved when computing platform designed with heterogeneous resources to
support multifarious tasks of an application where as task scheduling brings
parallel processing. The efficient task scheduling is critical to obtain
optimized performance in heterogeneous computing Systems (HCS). In this paper,
we brought a review of various application scheduling models which provide
parallelism for homogeneous and heterogeneous computing systems. In this paper,
we made a review of various scheduling methodologies targeted to high speed
computing systems and also prepared summary chart. The comparative study of
scheduling methodologies for high speed computing systems has been carried out
based on the attributes of platform &amp; application as well. The attributes are
execution time, nature of task, task handling capability, type of host &amp;
computing platform. Finally a summary chart has been prepared and it
demonstrates that the need of developing scheduling methodologies for
Heterogeneous Reconfigurable Computing Systems (HRCS) which is an emerging high
speed computing platform for real time applications.
</summary>
    <author>
      <name>Mahendra Vucha</name>
    </author>
    <author>
      <name>Arvind Rajawat</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5121/ijesa.2014.4401</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5121/ijesa.2014.4401" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1501.01370v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1501.01370v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1502.02287v1</id>
    <updated>2015-02-08T19:09:36Z</updated>
    <published>2015-02-08T19:09:36Z</published>
    <title>Protecting Memory-Performance Critical Sections in Soft Real-Time
  Applications</title>
    <summary>  Soft real-time applications such as multimedia applications often show bursty
memory access patterns---regularly requiring a high memory bandwidth for a
short duration of time. Such a period is often critical for timely data
processing. Hence, we call it a memory-performance critical section.
Unfortunately, in multicore architecture, non-real-time applications on
different cores may also demand high memory bandwidth at the same time, which
can substantially increase the time spent on the memory performance critical
sections.
  In this paper, we present BWLOCK, user-level APIs and a memory bandwidth
control mechanism that can protect such memory performance critical sections of
soft real-time applications. BWLOCK provides simple lock like APIs to declare
memory-performance critical sections. If an application enters a
memory-performance critical section, the memory bandwidth control system then
dynamically limit other cores' memory access rates to protect memory
performance of the application until the critical section finishes.
  From case studies with real-world soft real-time applications, we found (1)
such memory-performance critical sections do exist and are often easy to
identify; and (2) applying BWLOCK for memory critical sections significantly
improve performance of the soft real-time applications at a small or no cost in
throughput of non real-time applications.
</summary>
    <author>
      <name>Heechul Yun</name>
    </author>
    <author>
      <name>Santosh Gondi</name>
    </author>
    <author>
      <name>Siddhartha Biswas</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">technical report</arxiv:comment>
    <link href="http://arxiv.org/abs/1502.02287v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1502.02287v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.06833v1</id>
    <updated>2015-04-26T14:44:00Z</updated>
    <published>2015-04-26T14:44:00Z</published>
    <title>Evaluating Dynamic File Striping For Lustre</title>
    <summary>  We define dynamic striping as the ability to assign different Lustre striping
characteristics to contiguous segments of a file as it grows. In this paper, we
evaluate the effects of dynamic striping using a watermark-based strategy where
the stripe count or width is increased once a file's size exceeds one of the
chosen watermarks. To measure the performance of this strategy we used a
modified version of the IOR benchmark, a netflow analysis workload, and the
blastn algorithm from NCBI BLAST. The results indicate that dynamic striping is
beneficial to tasks with unpredictable data file size and large sequential
reads, but are less conclusive for workloads with significant random read
phases.
</summary>
    <author>
      <name>Joel Reed</name>
    </author>
    <author>
      <name>Jeremy Archuleta</name>
    </author>
    <author>
      <name>Michael J. Brim</name>
    </author>
    <author>
      <name>Joshua Lothian</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">International Workshop on the Lustre Ecosystem: Challenges and
  Opportunities, March 2015, Annapolis MD</arxiv:comment>
    <link href="http://arxiv.org/abs/1504.06833v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.06833v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.07070v2</id>
    <updated>2016-05-30T13:35:25Z</updated>
    <published>2015-04-27T13:08:26Z</published>
    <title>Deterministically Deterring Timing Attacks in Deterland</title>
    <summary>  The massive parallelism and resource sharing embodying today's cloud business
model not only exacerbate the security challenge of timing channels, but also
undermine the viability of defenses based on resource partitioning. We propose
hypervisor-enforced timing mitigation to control timing channels in cloud
environments. This approach closes "reference clocks" internal to the cloud by
imposing a deterministic view of time on guest code, and uses timing mitigators
to pace I/O and rate-limit potential information leakage to external observers.
Our prototype hypervisor is the first system to mitigate timing-channel leakage
across full-scale existing operating systems such as Linux and applications in
arbitrary languages. Mitigation incurs a varying performance cost, depending on
workload and tunable leakage-limiting parameters, but this cost may be
justified for security-critical cloud applications and data.
</summary>
    <author>
      <name>Weiyi Wu</name>
    </author>
    <author>
      <name>Bryan Ford</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 15 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1504.07070v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.07070v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.05269v1</id>
    <updated>2015-05-20T07:47:20Z</updated>
    <published>2015-05-20T07:47:20Z</published>
    <title>A Survey Report on Operating Systems for Tiny Networked Sensors</title>
    <summary>  Wireless sensor network (WSN) has attracted researchers worldwide to explore
the research opportunities, with application mainly in health monitoring,
industry automation, battlefields, home automation and environmental
monitoring. A WSN is highly resource constrained in terms of energy,
computation and memory. WSNs deployment ranges from the normal working
environment up to hostile and hazardous environment such as in volcano
monitoring and underground mines. These characteristics of WSNs hold additional
set of challenges in front of the operating system designer. The objective of
this survey is to highlight the features and weakness of the opearting system
available for WSNs, with the focus on the current application demands. The
paper also discusses the operating system design issues in terms of
architecture, programming model, scheduling and memory management and support
for real time applications.
</summary>
    <author>
      <name>Alok Ranjan</name>
    </author>
    <author>
      <name>H. B. Sahu</name>
    </author>
    <author>
      <name>Prasant Misra</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, Submitted to Journal</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Advanced Research in Networking and Communication
  Engineering, Vol(1) issue 1, 2014</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1505.05269v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.05269v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.01449v4</id>
    <updated>2016-06-29T20:42:04Z</updated>
    <published>2015-06-04T02:11:27Z</published>
    <title>Defending against malicious peripherals with Cinch</title>
    <summary>  Malicious peripherals designed to attack their host computers are a growing
problem. Inexpensive and powerful peripherals that attach to plug-and-play
buses have made such attacks easy to mount. Making matters worse, commodity
operating systems lack coherent defenses, and users are often unaware of the
scope of the problem. We present Cinch, a pragmatic response to this threat.
Cinch uses virtualization to attach peripheral devices to a logically separate,
untrusted machine, and includes an interposition layer between the untrusted
machine and the protected one. This layer regulates interaction with devices
according to user-configured policies. Cinch integrates with existing OSes,
enforces policies that thwart real-world attacks, and has low overhead.
</summary>
    <author>
      <name>Sebastian Angel</name>
    </author>
    <author>
      <name>Riad S. Wahby</name>
    </author>
    <author>
      <name>Max Howald</name>
    </author>
    <author>
      <name>Joshua B. Leners</name>
    </author>
    <author>
      <name>Michael Spilo</name>
    </author>
    <author>
      <name>Zhen Sun</name>
    </author>
    <author>
      <name>Andrew J. Blumberg</name>
    </author>
    <author>
      <name>Michael Walfish</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, 7 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. USENIX Security (2016), 397--414</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1506.01449v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.01449v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.06356v2</id>
    <updated>2015-10-18T04:50:29Z</updated>
    <published>2015-08-26T03:43:38Z</published>
    <title>EOS: Automatic In-vivo Evolution of Kernel Policies for Better
  Performance</title>
    <summary>  Today's monolithic kernels often implement a small, fixed set of policies
such as disk I/O scheduling policies, while exposing many parameters to let
users select a policy or adjust the specific setting of the policy. Ideally,
the parameters exposed should be flexible enough for users to tune for good
performance, but in practice, users lack domain knowledge of the parameters and
are often stuck with bad, default parameter settings.
  We present EOS, a system that bridges the knowledge gap between kernel
developers and users by automatically evolving the policies and parameters in
vivo on users' real, production workloads. It provides a simple policy
specification API for kernel developers to programmatically describe how the
policies and parameters should be tuned, a policy cache to make in-vivo tuning
easy and fast by memorizing good parameter settings for past workloads, and a
hierarchical search engine to effectively search the parameter space.
Evaluation of EOS on four main Linux subsystems shows that it is easy to use
and effectively improves each subsystem's performance.
</summary>
    <author>
      <name>Yan Cui</name>
    </author>
    <author>
      <name>Quan Chen</name>
    </author>
    <author>
      <name>Junfeng Yang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, technique report</arxiv:comment>
    <link href="http://arxiv.org/abs/1508.06356v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.06356v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.06367v2</id>
    <updated>2016-09-22T10:38:29Z</updated>
    <published>2015-08-26T05:20:50Z</published>
    <title>A Software-only Mechanism for Device Passthrough and Sharing</title>
    <summary>  Network processing elements in virtual machines, also known as Network
Function Virtualization (NFV) often face CPU bottlenecks at the virtualization
interface. Even highly optimized paravirtual device interfaces fall short of
the throughput requirements of modern devices. Passthrough devices, together
with SR-IOV support for multiple device virtual functions (VF) and IOMMU
support, mitigate this problem somewhat, by allowing a VM to directly control a
device partition bypassing the virtualization stack. However, device
passthrough requires high-end (expensive and power-hungry) hardware, places
scalability limits on consolidation ratios, and does not support efficient
switching between multiple VMs on the same host.
  We present a paravirtual interface that securely exposes an I/O device
directly to the guest OS running inside the VM, and yet allows that device to
be securely shared among multiple VMs and the host. Compared to the best-known
paravirtualization interfaces, our paravirtual interface supports up to 2x
higher throughput, and is closer in performance to device passthrough. Unlike
device passthrough however, we do not require SR-IOV or IOMMU support, and
allow fine-grained dynamic resource allocation, significantly higher
consolidation ratios, and seamless VM migration. Our security mechanism is
based on a novel approach called dynamic binary opcode subtraction.
</summary>
    <author>
      <name>Piyus Kedia</name>
    </author>
    <author>
      <name>Sorav Bansal</name>
    </author>
    <link href="http://arxiv.org/abs/1508.06367v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.06367v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.02498v1</id>
    <updated>2015-11-08T15:44:59Z</updated>
    <published>2015-11-08T15:44:59Z</published>
    <title>Characteristic specific prioritized dynamic average burst round robin
  scheduling for uniprocessor and multiprocessor environment</title>
    <summary>  CPU scheduling is one of the most crucial operations performed by operating
systems. Different conventional algorithms like FCFS, SJF, Priority, and RR
(Round Robin) are available for CPU Scheduling. The effectiveness of Priority
and Round Robin scheduling algorithm completely depends on selection of
priority features of processes and on the choice of time quantum. In this paper
a new CPU scheduling algorithm has been proposed, named as CSPDABRR
(Characteristic specific Prioritized Dynamic Average Burst Round Robin), that
uses seven priority features for calculating priority of processes and uses
dynamic time quantum instead of static time quantum used in RR. The performance
of the proposed algorithm is experimentally compared with traditional RR and
Priority scheduling algorithm in both uni-processor and multi-processor
environment. The results of our approach presented in this paper demonstrate
improved performance in terms of average waiting time, average turnaround time,
and optimal priority feature.
</summary>
    <author>
      <name>Amar Ranjan Dash</name>
    </author>
    <author>
      <name>Sandipta Kumar Sahu</name>
    </author>
    <author>
      <name>Sanjay Kumar Samantra</name>
    </author>
    <author>
      <name>Sradhanjali Sabat</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5121/ijcsea.2015.5501</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5121/ijcsea.2015.5501" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 Pages, 10 Figures, 18 Tables, 20 References, International Journal
  of Computer Science, Engineering and Applications (IJCSEA) Vol.5, No.4/5,
  October 2015</arxiv:comment>
    <link href="http://arxiv.org/abs/1511.02498v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.02498v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1512.00727v2</id>
    <updated>2015-12-03T10:38:11Z</updated>
    <published>2015-12-02T15:05:46Z</published>
    <title>TinyLFU: A Highly Efficient Cache Admission Policy</title>
    <summary>  This paper proposes to use a frequency based cache admission policy in order
to boost the effectiveness of caches subject to skewed access distributions.
Given a newly accessed item and an eviction candidate from the cache, our
scheme decides, based on the recent access history, whether it is worth
admitting the new item into the cache at the expense of the eviction candidate.
  Realizing this concept is enabled through a novel approximate LFU structure
called TinyLFU, which maintains an approximate representation of the access
frequency of a large sample of recently accessed items. TinyLFU is very compact
and light-weight as it builds upon Bloom filter theory.
  We study the properties of TinyLFU through simulations of both synthetic
workloads as well as multiple real traces from several sources. These
simulations demonstrate the performance boost obtained by enhancing various
replacement policies with the TinyLFU eviction policy. Also, a new combined
replacement and eviction policy scheme nicknamed W-TinyLFU is presented.
W-TinyLFU is demonstrated to obtain equal or better hit-ratios than other state
of the art replacement policies on these traces. It is the only scheme to
obtain such good results on all traces.
</summary>
    <author>
      <name>Gil Einziger</name>
    </author>
    <author>
      <name>Roy Friedman</name>
    </author>
    <author>
      <name>Ben Manes</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">A much earlier and shorter version of this work appeared in the
  Euromicro PDP 2014 conference</arxiv:comment>
    <link href="http://arxiv.org/abs/1512.00727v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1512.00727v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1512.01978v1</id>
    <updated>2015-12-07T11:05:05Z</updated>
    <published>2015-12-07T11:05:05Z</published>
    <title>Real-Time scheduling: from hard to soft real-time systems</title>
    <summary>  Real-time systems are traditionally classified into hard real-time and soft
real-time: in the first category we have safety critical real-time systems
where missing a deadline can have catastrophic consequences, whereas in the
second class we find systems or which we need to optimise the Quality of
service provided to the user. However, the frontier between these two classes
is thinner than one may think, and many systems that were considered as hard
real-time in the past should now be reconsidered under a different light. In
this paper we shall first recall the fundamental notion of time-predictability
and criticality, in order to understand where the real-time deadlines that we
use in our theoretical models come from. We shall then introduce the model of a
soft real-time system and present one popular method for scheduling hard and
soft real-time tasks, the resource reservation framework. Finally, we shall
show how resource reservation techniques can be successfully applied to the
design of classical control systems, thus adding robustness to the system and
increasing resource utilisation and performance.
</summary>
    <author>
      <name>Giuseppe Lipari</name>
    </author>
    <author>
      <name>Luigi Palopoli</name>
    </author>
    <link href="http://arxiv.org/abs/1512.01978v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1512.01978v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1512.07351v1</id>
    <updated>2015-12-23T04:39:00Z</updated>
    <published>2015-12-23T04:39:00Z</published>
    <title>Energy-aware Fixed-Priority Multi-core Scheduling for Real-time Systems</title>
    <summary>  Multi-core processors are becoming more and more popular in embedded and
real-time systems. While fixed-priority scheduling with task-splitting in
real-time systems are widely applied, current approaches have not taken into
consideration energy-aware aspects such as dynamic voltage/frequency scheduling
(DVS). In this paper, we propose two strategies to apply dynamic voltage
scaling (DVS) to fixed-priority scheduling algorithms with task-splitting for
periodic real-time tasks on multi-core processors. The first strategy
determines voltage scales for each processor after scheduling (Static DVS),
which ensures all tasks meet the timing requirements on synchronization. The
second strategy adaptively determines the frequency of each task before
scheduling (Adaptive DVS) according to the total utilization of task-set and
number of cores available. The combination of frequency pre-allocation and
task-splitting makes it possible to maximize energy savings with DVS.
Simulation results show that it is possible to achieve significant energy
savings with DVS while preserving the schedulability requirements of real-time
schedulers for multi-core processors.
</summary>
    <author>
      <name>Yao Guo</name>
    </author>
    <author>
      <name>Junyang Lu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">conference extension</arxiv:comment>
    <link href="http://arxiv.org/abs/1512.07351v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1512.07351v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="C.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.05851v1</id>
    <updated>2016-01-22T01:22:53Z</updated>
    <published>2016-01-22T01:22:53Z</published>
    <title>HyBIS: Windows Guest Protection through Advanced Memory Introspection</title>
    <summary>  Effectively protecting the Windows OS is a challenging task, since most
implementation details are not publicly known. Windows has always been the main
target of malwares that have exploited numerous bugs and vulnerabilities.
Recent trusted boot and additional integrity checks have rendered the Windows
OS less vulnerable to kernel-level rootkits. Nevertheless, guest Windows
Virtual Machines are becoming an increasingly interesting attack target. In
this work we introduce and analyze a novel Hypervisor-Based Introspection
System (HyBIS) we developed for protecting Windows OSes from malware and
rootkits. The HyBIS architecture is motivated and detailed, while targeted
experimental results show its effectiveness. Comparison with related work
highlights main HyBIS advantages such as: effective semantic introspection,
support for 64-bit architectures and for latest Windows (8.x and 10), advanced
malware disabling capabilities. We believe the research effort reported here
will pave the way to further advances in the security of Windows OSes.
</summary>
    <author>
      <name>Roberto di Pietro</name>
    </author>
    <author>
      <name>Federico Franzoni</name>
    </author>
    <author>
      <name>Flavio Lombardi</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-319-58469-0_13</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-319-58469-0_13" rel="related"/>
    <link href="http://arxiv.org/abs/1601.05851v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.05851v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.05636v1</id>
    <updated>2016-03-17T19:43:36Z</updated>
    <published>2016-03-17T19:43:36Z</published>
    <title>An Implementation and Analysis of a Kernel Network Stack in Go with the
  CSP Style</title>
    <summary>  Modern operating system kernels are written in lower-level languages such as
C. Although the low-level functionalities of C are often useful within kernels,
they also give rise to several classes of bugs. Kernels written in higher level
languages avoid many of these potential problems, at the possible cost of
decreased performance. This research evaluates the advantages and disadvantages
of a kernel written in a higher level language. To do this, the network stack
subsystem of the kernel was implemented in Go with the Communicating Sequential
Processes (CSP) style. Go is a high-level programming language that supports
the CSP style, which recommends splitting large tasks into several smaller ones
running in independent "threads". Modules for the major networking protocols,
including Ethernet, ARP, IPv4, ICMP, UDP, and TCP, were implemented. In this
study, the implemented Go network stack, called GoNet, was compared to a
representative network stack written in C. The GoNet code is more readable and
generally performs better than that of its C stack counterparts. From this, it
can be concluded that Go with CSP style is a viable alternative to C for the
language of kernel implementations.
</summary>
    <author>
      <name>Harshal Sheth</name>
    </author>
    <author>
      <name>Aashish Welling</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1603.05636v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.05636v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.00362v1</id>
    <updated>2016-05-02T06:24:43Z</updated>
    <published>2016-05-02T06:24:43Z</published>
    <title>An optimized round robin cpu scheduling algorithm with dynamic time
  quantum</title>
    <summary>  CPU scheduling is one of the most crucial operations performed by operating
system. Different algorithms are available for CPU scheduling amongst them RR
(Round Robin) is considered as optimal in time shared environment. The
effectiveness of Round Robin completely depends on the choice of time quantum.
In this paper a new CPU scheduling algorithm has been proposed, named as DABRR
(Dynamic Average Burst Round Robin). That uses dynamic time quantum instead of
static time quantum used in RR. The performance of the proposed algorithm is
experimentally compared with traditional RR and some existing variants of RR.
The results of our approach presented in this paper demonstrate improved
performance in terms of average waiting time, average turnaround time, and
context switching.
</summary>
    <author>
      <name>Amar Ranjan Dash</name>
    </author>
    <author>
      <name>Sandipta kumar Sahu</name>
    </author>
    <author>
      <name>Sanjay Kumar Samantra</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5121/ijcseit.2015.5102</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5121/ijcseit.2015.5102" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages, 7 figures, 16 Tables. arXiv admin note: text overlap with
  arXiv:1511.02498</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Science, Engineering and
  Information Technology (IJCSEIT), Vol. 5,No.1, February 2015</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1605.00362v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.00362v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1605.01168v1</id>
    <updated>2016-05-04T07:36:46Z</updated>
    <published>2016-05-04T07:36:46Z</published>
    <title>A Qualitative Comparison of MPSoC Mobile and Embedded Virtualization
  Techniques</title>
    <summary>  Virtualization is generally adopted in server and desktop environments to
provide for fault tolerance, resource management, and energy efficiency.
Virtualization enables parallel execution of multiple operating systems (OSs)
while sharing the hardware resources. Virtualization was previously not deemed
as feasible technology for mobile and embedded devices due to their limited
processing and memory resource. However, the enterprises are advocating Bring
Your Own Device (BYOD) applications that enable co-existence of heterogeneous
OSs on a single mobile device. Moreover, embedded device require virtualization
for logical isolation of secure and general purpose OSs on a single device. In
this paper, we investigate the processor architectures in the mobile and
embedded space while examining their formal visualizability. We also compare
the virtualization solutions enabling coexistence of multiple OSs in Multicore
Processor System-on-Chip (MPSoC) mobile and embedded systems. We advocate that
virtualization is necessary to manage resource in MPSoC designs and to enable
BYOD, security, and logical isolation use cases.
</summary>
    <author>
      <name>Junaid Shuja</name>
    </author>
    <author>
      <name>Abdullah Gani</name>
    </author>
    <author>
      <name>Sajjad A. Madani</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">International Conference of Global Network for Innovative Technology
  (IGNITE-2014), Penang, Malaysia</arxiv:comment>
    <link href="http://arxiv.org/abs/1605.01168v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1605.01168v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.02635v1</id>
    <updated>2016-06-08T16:52:03Z</updated>
    <published>2016-06-08T16:52:03Z</published>
    <title>Feedback Scheduling for Energy-Efficient Real-Time Homogeneous
  Multiprocessor Systems</title>
    <summary>  Real-time scheduling algorithms proposed in the literature are often based on
worst-case estimates of task parameters. The performance of an open-loop scheme
can be degraded significantly if there are uncertainties in task parameters,
such as the execution times of the tasks. Therefore, to cope with such a
situation, a closed-loop scheme, where feedback is exploited to adjust the
system parameters, can be applied. We propose an optimal control framework that
takes advantage of feeding back information of finished tasks to solve a
real-time multiprocessor scheduling problem with uncertainty in task execution
times, with the objective of minimizing the total energy consumption.
Specifically, we propose a linear programming based algorithm to solve a
workload partitioning problem and adopt McNaughton's wrap around algorithm to
find the task execution order. The simulation results illustrate that our
feedback scheduling algorithm can save energy by as much as 40% compared to an
open-loop method for two processor models, i.e. a PowerPC 405LP and an XScale
processor.
</summary>
    <author>
      <name>Mason Thammawichai</name>
    </author>
    <author>
      <name>Eric C. Kerrigan</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. 55th IEEE Conference on Decision and Control, 2016</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1606.02635v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.02635v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.05654v1</id>
    <updated>2016-08-19T16:23:24Z</updated>
    <published>2016-08-19T16:23:24Z</published>
    <title>POLYPATH: Supporting Multiple Tradeoffs for Interaction Latency</title>
    <summary>  Modern mobile systems use a single input-to-display path to serve all
applications. In meeting the visual goals of all applications, the path has a
latency inadequate for many important interactions. To accommodate the
different latency requirements and visual constraints by different
interactions, we present POLYPATH, a system design in which application
developers (and users) can choose from multiple path designs for their
application at any time. Because a POLYPATH system asks for two or more path
designs, we present a novel fast path design, called Presto. Presto reduces
latency by judiciously allowing frame drops and tearing.
  We report an Android 5-based prototype of POLYPATH with two path designs:
Android legacy and Presto. Using this prototype, we quantify the effectiveness,
overhead, and user experience of POLYPATH, especially Presto, through both
objective measurements and subjective user assessment. We show that Presto
reduces the latency of legacy touchscreen drawing applications by almost half;
and more importantly, this reduction is orthogonal to that of other popular
approaches and is achieved without any user-noticeable negative visual effect.
When combined with touch prediction, Presto is able to reduce the touch latency
below 10 ms, a remarkable achievement without any hardware support.
</summary>
    <author>
      <name>Min Hong Yun</name>
    </author>
    <author>
      <name>Songtao He</name>
    </author>
    <author>
      <name>Lin Zhong</name>
    </author>
    <link href="http://arxiv.org/abs/1608.05654v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.05654v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.08051v2</id>
    <updated>2016-09-03T22:46:29Z</updated>
    <published>2016-08-13T22:14:47Z</published>
    <title>Duplication of Windows Services</title>
    <summary>  OS-level virtualization techniques virtualize system resources at the system
call interface, has the distinct advantage of smaller run-time resource
requirements as compared to HAL-level virtualization techniques, and thus forms
an important building block for virtualizing parallel and distributed
applications such as a HPC clusters. Because the Windows operating system puts
certain critical functionalities in privileged user-level system service
processes, a complete OS-level virtualization solution for the Windows platform
requires duplication of such Windows service as Remote Procedure Call Server
Service (RPCSS). As many implementation details of the Windows system services
are proprietary, duplicating Windows system services becomes the key technical
challenge for virtualizing the Windows platform at the OS level. Moreover, as a
core component of cloud computing, IIS web server-related services need to be
duplicated in containers (i.e., OS-level virtual machines), but so far there is
no such scheme. In this paper, we thoroughly identify all issues that affect
service duplication, and then propose the first known methodology to
systematically duplicate both system and ordinary Windows services. Our
experiments show that the methodology can duplicate a set of system and
ordinary services on different versions of Windows OS.
</summary>
    <author>
      <name>Zhiyong Shan</name>
    </author>
    <author>
      <name>Tzi-cker Chiueh</name>
    </author>
    <author>
      <name>Xin Wang</name>
    </author>
    <link href="http://arxiv.org/abs/1608.08051v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.08051v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.00875v1</id>
    <updated>2016-09-03T23:09:11Z</updated>
    <published>2016-09-03T23:09:11Z</published>
    <title>Compatible and Usable Mandatory Access Control for Good-enough OS
  Security</title>
    <summary>  OS compromise is one of the most serious computer security problems today,
but still not being resolved. Although people proposed different kinds of
methods, they could not be accepted by most users who are non-expert due to the
lack of compatibility and usability. In this paper, we introduce a kind of new
mandatory access control model, named CUMAC, that aims to achieve good-enough
security, high compatibility and usability. It has two novel features. One is
access control based on tracing potential intrusion that can reduce false
negatives and facilitate security configuration, in order to improve both
compatibility and usability; the other is automatically figuring out all of the
compatibility exceptions that usually incurs incompatible problems. The
experiments performed on the prototype show that CUMAC can defense attacks from
network, mobile disk and local untrustable users while keeping good
compatibility and usability.
</summary>
    <author>
      <name>Zhiyong Shan</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/ISECS.2009.29</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/ISECS.2009.29" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Electronic Commerce and Security, 2009. ISECS '09. Second
  International Symposium on</arxiv:comment>
    <link href="http://arxiv.org/abs/1609.00875v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.00875v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.04781v1</id>
    <updated>2016-09-15T19:18:12Z</updated>
    <published>2016-09-15T19:18:12Z</published>
    <title>Confining Windows Inter-Process Communications for OS-Level Virtual
  Machine</title>
    <summary>  As OS-level virtualization technology usually imposes little overhead on
virtual machine start-up and running, it provides an excellent choice for
building intrusion/fault tolerant applications that require redundancy and
frequent invocation. When developing Windows OS-level virtual machine, however,
people will inevitably face the challenge of confining Windows Inter-Process
Communications (IPC). As IPC on Windows platform is more complex than UNIX
style OS and most of the programs on Windows are not open-source, it is
difficult to discover all of the performed IPCs and confine them. In this
paper, we propose three general principles to confine IPC on Windows OS and a
novel IPC confinement mechanism based on the principles. With the mechanism,
for the first time from the literature, we successfully virtualized RPC System
Service (RPCSS) and Internet Information Server (IIS) on Feather-weight Virtual
Machine (FVM). Experimental results demonstrate that multiple IIS web server
instances can simultaneously run on single Windows OS with much less
performance overhead than other popular VM technology, offering a good basis
for constructing dependable system.
</summary>
    <author>
      <name>Zhiyong Shan</name>
    </author>
    <author>
      <name>Yang Yu</name>
    </author>
    <author>
      <name>Tzi-cker Chiueh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">VDTS '09 Proceedings of the 1st EuroSys Workshop on Virtualization
  Technology for Dependable Systems</arxiv:comment>
    <link href="http://arxiv.org/abs/1609.04781v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.04781v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.04785v1</id>
    <updated>2016-09-15T19:21:22Z</updated>
    <published>2016-09-15T19:21:22Z</published>
    <title>Virtualizing System and Ordinary Services in Windows-based OS-Level
  Virtual Machines</title>
    <summary>  OS-level virtualization incurs smaller start-up and run-time overhead than
HAL-based virtualization and thus forms an important building block for
developing fault-tolerant and intrusion-tolerant applications. A complete
implementation of OS-level virtualization on the Windows platform requires
virtualization of Windows services, such as system services like the Remote
Procedure Call Server Service (RPCSS), because they are essentially extensions
of the kernel. As Windows system services work very differently from their
counterparts on UNIX-style OS, i.e., daemons, and many of their implementation
details are proprietary, virtualizing Windows system services turned out to be
the most challenging technical barrier for OS-level virtualization for the
Windows platform. In this paper, we describe a general technique to virtualize
Windows services, and demonstrate its effectiveness by applying it to
successfully virtualize a set of important Windows system services and ordinary
services on different versions of Windows OS, including RPCSS, DcomLaunch, IIS
service group, Tlntsvr, MySQL, Apache2.2, CiSvc, ImapiService, etc.
</summary>
    <author>
      <name>Zhiyong Shan</name>
    </author>
    <author>
      <name>Tzi-cker Chiueh</name>
    </author>
    <author>
      <name>Xin Wang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">SAC '11 Proceedings of the 2011 ACM Symposium on Applied Computing</arxiv:comment>
    <link href="http://arxiv.org/abs/1609.04785v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.04785v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.08372v2</id>
    <updated>2016-09-28T09:17:05Z</updated>
    <published>2016-09-27T12:21:02Z</published>
    <title>An Evaluation of Coarse-Grained Locking for Multicore Microkernels</title>
    <summary>  The trade-off between coarse- and fine-grained locking is a well understood
issue in operating systems. Coarse-grained locking provides lower overhead
under low contention, fine-grained locking provides higher scalability under
contention, though at the expense of implementation complexity and re- duced
best-case performance.
  We revisit this trade-off in the context of microkernels and tightly-coupled
cores with shared caches and low inter-core migration latencies. We evaluate
performance on two architectures: x86 and ARM MPCore, in the former case also
utilising transactional memory (Intel TSX). Our thesis is that on such
hardware, a well-designed microkernel, with short system calls, can take
advantage of coarse-grained locking on modern hardware, avoid the run-time and
complexity cost of multiple locks, enable formal verification, and still
achieve scalability comparable to fine-grained locking.
</summary>
    <author>
      <name>Kevin Elphinstone</name>
    </author>
    <author>
      <name>Amirreza Zarrabi</name>
    </author>
    <author>
      <name>Adrian Danis</name>
    </author>
    <author>
      <name>Yanyan Shen</name>
    </author>
    <author>
      <name>Gernot Heiser</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 7 figures, 28 references</arxiv:comment>
    <link href="http://arxiv.org/abs/1609.08372v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.08372v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.4.1; D.4.7; D.4.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.06830v1</id>
    <updated>2016-12-20T20:14:35Z</updated>
    <published>2016-12-20T20:14:35Z</published>
    <title>CannyFS: Opportunistically Maximizing I/O Throughput Exploiting the
  Transactional Nature of Batch-Mode Data Processing</title>
    <summary>  We introduce a user mode file system, CannyFS, that hides latency by assuming
all I/O operations will succeed. The user mode process will in turn report
errors, allowing proper cleanup and a repeated attempt to take place. We
demonstrate benefits for the model tasks of extracting archives and removing
directory trees in a real-life HPC environment, giving typical reductions in
time use of over 80%.
  This approach can be considered a view of HPC jobs and their I/O activity as
transactions. In general, file systems lack clearly defined transaction
semantics. Over time, the competing trends to add cache and maintain data
integrity have resulted in different practical tradeoffs.
  High-performance computing is a special case where overall throughput demands
are high. Latency can also be high, with non-local storage. In addition, a
theoretically possible I/O error (like permission denied, loss of connection,
exceeding disk quota) will frequently warrant the resubmission of a full job or
task, rather than traditional error reporting or handling. Therefore,
opportunistically treating each I/O operation as successful, and part of a
larger transaction, can speed up some applications that do not leverage
asynchronous I/O.
</summary>
    <author>
      <name>Jessica Nettelblad</name>
    </author>
    <author>
      <name>Carl Nettelblad</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 3 figures, 1 table. Submitted</arxiv:comment>
    <link href="http://arxiv.org/abs/1612.06830v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.06830v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.06571v1</id>
    <updated>2017-03-20T02:47:57Z</updated>
    <published>2017-03-20T02:47:57Z</published>
    <title>Formalizing Memory Accesses and Interrupts</title>
    <summary>  The hardware/software boundary in modern heterogeneous multicore computers is
increasingly complex, and diverse across different platforms. A single memory
access by a core or DMA engine traverses multiple hardware translation and
caching steps, and the destination memory cell or register often appears at
different physical addresses for different cores. Interrupts pass through a
complex topology of interrupt controllers and remappers before delivery to one
or more cores, each with specific constraints on their configurations. System
software must not only correctly understand the specific hardware at hand, but
also configure it appropriately at runtime. We propose a formal model of
address spaces and resources in a system that allows us to express and verify
invariants of the system's runtime configuration, and illustrate (and motivate)
it with several real platforms we have encountered in the process of OS
implementation.
</summary>
    <author>
      <name>Reto Achermann</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Systems Group, Department of Computer Science, ETH Zurich</arxiv:affiliation>
    </author>
    <author>
      <name>Lukas Humbel</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Systems Group, Department of Computer Science, ETH Zurich</arxiv:affiliation>
    </author>
    <author>
      <name>David Cock</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Systems Group, Department of Computer Science, ETH Zurich</arxiv:affiliation>
    </author>
    <author>
      <name>Timothy Roscoe</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Systems Group, Department of Computer Science, ETH Zurich</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.244.4</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.244.4" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings MARS 2017, arXiv:1703.05812</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 244, 2017, pp. 66-116</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1703.06571v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.06571v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.4; D.4.2; D.4.7; D.3.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.07725v1</id>
    <updated>2017-03-22T16:07:11Z</updated>
    <published>2017-03-22T16:07:11Z</published>
    <title>Memos: Revisiting Hybrid Memory Management in Modern Operating System</title>
    <summary>  The emerging hybrid DRAM-NVM architecture is challenging the existing memory
management mechanism in operating system. In this paper, we introduce memos,
which can schedule memory resources over the entire memory hierarchy including
cache, channels, main memory comprising DRAM and NVM simultaneously. Powered by
our newly designed kernel-level monitoring module and page migration engine,
memos can dynamically optimize the data placement at the memory hierarchy in
terms of the on-line memory patterns, current resource utilization and feature
of memory medium. Our experimental results show that memos can achieve high
memory utilization, contributing to system throughput by 19.1% and QoS by 23.6%
on average. Moreover, memos can reduce the NVM side memory latency by 3~83.3%,
energy consumption by 25.1~99%, and benefit the NVM lifetime significantly (40X
improvement on average).
</summary>
    <author>
      <name>Lei Liu</name>
    </author>
    <author>
      <name>Mengyao Xie</name>
    </author>
    <author>
      <name>Hao Yang</name>
    </author>
    <link href="http://arxiv.org/abs/1703.07725v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.07725v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.06932v1</id>
    <updated>2017-05-19T11:01:54Z</updated>
    <published>2017-05-19T11:01:54Z</published>
    <title>Look Mum, no VM Exits! (Almost)</title>
    <summary>  Multi-core CPUs are a standard component in many modern embedded systems.
Their virtualisation extensions enable the isolation of services, and gain
popularity to implement mixed-criticality or otherwise split systems. We
present Jailhouse, a Linux-based, OS-agnostic partitioning hypervisor that uses
novel architectural approaches to combine Linux, a powerful general-purpose
system, with strictly isolated special-purpose components. Our design goals
favour simplicity over features, establish a minimal code base, and minimise
hypervisor activity.
  Direct assignment of hardware to guests, together with a deferred
initialisation scheme, offloads any complex hardware handling and bootstrapping
issues from the hypervisor to the general purpose OS. The hypervisor
establishes isolated domains that directly access physical resources without
the need for emulation or paravirtualisation. This retains, with negligible
system overhead, Linux's feature-richness in uncritical parts, while frugal
safety and real-time critical workloads execute in isolated, safe domains.
</summary>
    <author>
      <name>Ralf Ramsauer</name>
    </author>
    <author>
      <name>Jan Kiszka</name>
    </author>
    <author>
      <name>Daniel Lohmann</name>
    </author>
    <author>
      <name>Wolfgang Mauerer</name>
    </author>
    <link href="http://arxiv.org/abs/1705.06932v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.06932v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.05405v1</id>
    <updated>2017-07-17T22:26:19Z</updated>
    <published>2017-07-17T22:26:19Z</published>
    <title>Study and Analysis of MAC/IPAD Lab Configuration</title>
    <summary>  This paper is about three virtualization modes: VMware, Parallels, and Boot
Camping. The trade off of their testing is the hardware requirements. The main
question is, among the three, which is the most suitable? The answer actually
varies from user to user. It depends on the user needs. Moreover, it is
necessary to consider its performance, graphics, efficiency and reliability,
and interoperability, and that is our major scope. In order to take the final
decision in choosing one of the modes it is important to run some tests, which
costs a lot in terms of money, complexity, and time consumption. Therefore, in
order to overcome this trade off, most of the research has been done through
online benchmarking and my own anticipation. The final solution was extracted
after comparing all previously mentioned above and after rigorous testing made
which will be introduced later in this document.
</summary>
    <author>
      <name>Ayman Noor</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 15 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1707.05405v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.05405v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.07780v1</id>
    <updated>2017-07-25T00:59:32Z</updated>
    <published>2017-07-25T00:59:32Z</published>
    <title>FluidMem: Memory as a Service for the Datacenter</title>
    <summary>  Disaggregating resources in data centers is an emerging trend. Recent work
has begun to explore memory disaggregation, but suffers limitations including
lack of consideration of the complexity of cloud-based deployment, including
heterogeneous hardware and APIs for cloud users and operators. In this paper,
we present FluidMem, a complete system to realize disaggregated memory in the
datacenter. Going beyond simply demonstrating remote memory is possible, we
create an entire Memory as a Service. We define the requirements of Memory as a
Service and build its implementation in Linux as FluidMem. We present a
performance analysis of FluidMem and demonstrate that it transparently supports
remote memory for standard applications such as MongoDB and genome sequencing
applications.
</summary>
    <author>
      <name>Blake Caldwell</name>
    </author>
    <author>
      <name>Youngbin Im</name>
    </author>
    <author>
      <name>Sangtae Ha</name>
    </author>
    <author>
      <name>Richard Han</name>
    </author>
    <author>
      <name>Eric Keller</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">University of Colorado Technical Report</arxiv:comment>
    <link href="http://arxiv.org/abs/1707.07780v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.07780v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.08514v1</id>
    <updated>2017-07-26T16:02:29Z</updated>
    <published>2017-07-26T16:02:29Z</published>
    <title>Analyzing IO Amplification in Linux File Systems</title>
    <summary>  We present the first systematic analysis of read, write, and space
amplification in Linux file systems. While many researchers are tackling write
amplification in key-value stores, IO amplification in file systems has been
largely unexplored. We analyze data and metadata operations on five widely-used
Linux file systems: ext2, ext4, XFS, btrfs, and F2FS. We find that data
operations result in significant write amplification (2-32X) and that metadata
operations have a large IO cost. For example, a single rename requires 648 KB
write IO in btrfs. We also find that small random reads result in read
amplification of 2-13X. Based on these observations, we present the CReWS
conjecture about the relationship between IO amplification, consistency, and
storage space utilization. We hope this paper spurs people to design future
file systems with less IO amplification, especially for non-volatile memory
technologies.
</summary>
    <author>
      <name>Jayashree Mohan</name>
    </author>
    <author>
      <name>Rohan Kadekodi</name>
    </author>
    <author>
      <name>Vijay Chidambaram</name>
    </author>
    <link href="http://arxiv.org/abs/1707.08514v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.08514v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.02746v2</id>
    <updated>2017-09-25T16:10:02Z</updated>
    <published>2017-09-08T15:29:17Z</published>
    <title>FreeGuard: A Faster Secure Heap Allocator</title>
    <summary>  In spite of years of improvements to software security, heap-related attacks
still remain a severe threat. One reason is that many existing memory
allocators fall short in a variety of aspects. For instance,
performance-oriented allocators are designed with very limited countermeasures
against attacks, but secure allocators generally suffer from significant
performance overhead, e.g., running up to 10x slower. This paper, therefore,
introduces FreeGuard, a secure memory allocator that prevents or reduces a wide
range of heap-related attacks, such as heap overflows, heap over-reads,
use-after-frees, as well as double and invalid frees. FreeGuard has similar
performance to the default Linux allocator, with less than 2% overhead on
average, but provides significant improvement to security guarantees. FreeGuard
also addresses multiple implementation issues of existing secure allocators,
such as the issue of scalability. Experimental results demonstrate that
FreeGuard is very effective in defending against a variety of heap-related
attacks.
</summary>
    <author>
      <name>Sam Silvestro</name>
    </author>
    <author>
      <name>Hongyu Liu</name>
    </author>
    <author>
      <name>Corey Crosser</name>
    </author>
    <author>
      <name>Zhiqiang Lin</name>
    </author>
    <author>
      <name>Tongping Liu</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3133956.3133957</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3133956.3133957" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 4 figures, to be published at CCS'17</arxiv:comment>
    <link href="http://arxiv.org/abs/1709.02746v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.02746v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1709.10140v1</id>
    <updated>2017-09-28T19:30:05Z</updated>
    <published>2017-09-28T19:30:05Z</published>
    <title>Performance Evaluation of Container-based Virtualization for High
  Performance Computing Environments</title>
    <summary>  Virtualization technologies have evolved along with the development of
computational environments since virtualization offered needed features at that
time such as isolation, accountability, resource allocation, resource fair
sharing and so on. Novel processor technologies bring to commodity computers
the possibility to emulate diverse environments where a wide range of
computational scenarios can be run. Along with processors evolution, system
developers have created different virtualization mechanisms where each new
development enhanced the performance of previous virtualized environments.
Recently, operating system-based virtualization technologies captured the
attention of communities abroad (from industry to academy and research) because
their important improvements on performance area.
  In this paper, the features of three container-based operating systems
virtualization tools (LXC, Docker and Singularity) are presented. LXC, Docker,
Singularity and bare metal are put under test through a customized single node
HPL-Benchmark and a MPI-based application for the multi node testbed. Also the
disk I/O performance, Memory (RAM) performance, Network bandwidth and GPU
performance are tested for the COS technologies vs bare metal. Preliminary
results and conclusions around them are presented and discussed.
</summary>
    <author>
      <name>Carlos Arango</name>
    </author>
    <author>
      <name>Rémy Dernat</name>
    </author>
    <author>
      <name>John Sanabria</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Keywords: Container-based virtualization; Linux containers;
  Singularity-Containers; Docker; High performance computing</arxiv:comment>
    <link href="http://arxiv.org/abs/1709.10140v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1709.10140v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0302033v1</id>
    <updated>2003-02-24T22:03:30Z</updated>
    <published>2003-02-24T22:03:30Z</published>
    <title>Experimental Software Schedulability Estimation For Varied Processor
  Frequencies</title>
    <summary>  This paper describes a new approach to experimentally estimate the
application schedulability for various processor frequencies. We use additional
workload generated by an artificial high priority routine to simulate the
frequency decrease of a processor. Then we estimate the schedulability of
applications at different frequencies. The results of such estimation can be
used to determine the frequencies and control algorithms of dynamic voltage
scaling/dynamic frequency scaling (DVS/DFS) implementations. The paper presents
a general problem description, the proposed schedulability estimation method,
its analysis and evaluation.
</summary>
    <author>
      <name>Sampsa Fabritius</name>
    </author>
    <author>
      <name>Raimondas Lencevicius</name>
    </author>
    <author>
      <name>Edu Metz</name>
    </author>
    <author>
      <name>Alexander Ran</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 3 figures, published in the Proceedings of the Symposium on
  Software Engineering at 21th IASTED International Multi-Conference on Applied
  Informatics (AI 2003)</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0302033v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0302033v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.2.8;D.4.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0502012v1</id>
    <updated>2005-02-02T04:43:33Z</updated>
    <published>2005-02-02T04:43:33Z</published>
    <title>Sequential File Programming Patterns and Performance with .NET</title>
    <summary>  Programming patterns for sequential file access in the .NET Framework are
described and the performance is measured. The default behavior provides
excellent performance on a single disk - 50 MBps both reading and writing.
Using large request sizes and doing file pre-allocation when possible have
quantifiable benefits. When one considers disk arrays, .NET unbuffered IO
delivers 800 MBps on a 16-disk array, but buffered IO delivers about 12% of
that performance. Consequently, high-performance file and database utilities
are still forced to use unbuffered IO for maximum sequential performance. The
report is accompanied by downloadable source code that demonstrates the
concepts and code that was used to obtain these measurements.
</summary>
    <author>
      <name>Peter Kukol</name>
    </author>
    <author>
      <name>Jim Gray</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0502012v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0502012v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0504051v1</id>
    <updated>2005-04-13T16:37:59Z</updated>
    <published>2005-04-13T16:37:59Z</published>
    <title>A Scalable Stream-Oriented Framework for Cluster Applications</title>
    <summary>  This paper presents a stream-oriented architecture for structuring cluster
applications. Clusters that run applications based on this architecture can
scale to tenths of thousands of nodes with significantly less performance loss
or reliability problems. Our architecture exploits the stream nature of the
data flow and reduces congestion through load balancing, hides latency behind
data pushes and transparently handles node failures. In our ongoing work, we
are developing an implementation for this architecture and we are able to run
simple data mining applications on a cluster simulator.
</summary>
    <author>
      <name>Tassos S. Argyros</name>
    </author>
    <author>
      <name>David R. Cheriton</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0504051v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0504051v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0507073v1</id>
    <updated>2005-07-29T19:33:13Z</updated>
    <published>2005-07-29T19:33:13Z</published>
    <title>Software Performance Analysis</title>
    <summary>  The key to speeding up applications is often understanding where the elapsed
time is spent, and why. This document reviews in depth the full array of
performance analysis tools and techniques available on Linux for this task,
from the traditional tools like gcov and gprof, to the more advanced tools
still under development like oprofile and the Linux Trace Toolkit. The focus is
more on the underlying data collection and processing algorithms, and their
overhead and precision, than on the cosmetic details of the graphical user
interface frontends.
</summary>
    <author>
      <name>Michel R. Dagenais</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Dept. of Computer Engineering, Ecole Polytechnique, Montreal, Canada</arxiv:affiliation>
    </author>
    <author>
      <name>Karim Yaghmour</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Opersys, Montreal, Canada</arxiv:affiliation>
    </author>
    <author>
      <name>Charles Levert</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Ericsson Research, Montreal, Canada</arxiv:affiliation>
    </author>
    <author>
      <name>Makan Pourzandi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Ericsson Research, Montreal, Canada</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/cs/0507073v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0507073v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0508063v1</id>
    <updated>2005-08-12T16:13:32Z</updated>
    <published>2005-08-12T16:13:32Z</published>
    <title>Disks, Partitions, Volumes and RAID Performance with the Linux Operating
  System</title>
    <summary>  Block devices in computer operating systems typically correspond to disks or
disk partitions, and are used to store files in a filesystem. Disks are not the
only real or virtual device which adhere to the block accessible stream of
bytes block device model. Files, remote devices, or even RAM may be used as a
virtual disks. This article examines several common combinations of block
device layers used as virtual disks in the Linux operating system: disk
partitions, loopback files, software RAID, Logical Volume Manager, and Network
Block Devices. It measures their relative performance using different
filesystems: Ext2, Ext3, ReiserFS, JFS, XFS,NFS.
</summary>
    <author>
      <name>Michel R. Dagenais</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Dept. of Computer Engineering, Ecole Polytechnique, Montreal, Canada</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/cs/0508063v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0508063v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0803.3230v2</id>
    <updated>2008-05-08T02:55:57Z</updated>
    <published>2008-03-21T21:28:16Z</published>
    <title>A Type System for Data-Flow Integrity on Windows Vista</title>
    <summary>  The Windows Vista operating system implements an interesting model of
multi-level integrity. We observe that in this model, trusted code can be
blamed for any information-flow attack; thus, it is possible to eliminate such
attacks by static analysis of trusted code. We formalize this model by
designing a type system that can efficiently enforce data-flow integrity on
Windows Vista. Typechecking guarantees that objects whose contents are
statically trusted never contain untrusted values, regardless of what untrusted
code runs in the environment. Some of Windows Vista's runtime access checks are
necessary for soundness; others are redundant and can be optimized away.
</summary>
    <author>
      <name>Avik Chaudhuri</name>
    </author>
    <author>
      <name>Prasad Naldurg</name>
    </author>
    <author>
      <name>Sriram Rajamani</name>
    </author>
    <link href="http://arxiv.org/abs/0803.3230v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0803.3230v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.4.6; D.2.4; F.3.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0810.0372v1</id>
    <updated>2008-10-02T09:41:52Z</updated>
    <published>2008-10-02T09:41:52Z</published>
    <title>Optimizing Binary Code Produced by Valgrind (Project Report on Virtual
  Execution Environments Course - AVExe)</title>
    <summary>  Valgrind is a widely used framework for dynamic binary instrumentation and
its mostly known by its memcheck tool. Valgrind's code generation module is far
from producing optimal code. In addition it has many backends for different CPU
architectures, which difficults code optimization in an architecture
independent way. Our work focused on identifying sub-optimal code produced by
Valgrind and optimizing it.
</summary>
    <author>
      <name>Filipe Cabecinhas</name>
    </author>
    <author>
      <name>Nuno Lopes</name>
    </author>
    <author>
      <name>Renato Crisostomo</name>
    </author>
    <author>
      <name>Luis Veiga</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Technical report from INESC-ID Lisboa describing optimizations to
  code generation of the Valgring execution environment. Work developed in the
  context of a Virtual Execution Environments course (AVExe) at IST/Technical
  university of Lisbon</arxiv:comment>
    <link href="http://arxiv.org/abs/0810.0372v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0810.0372v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0902.1610v1</id>
    <updated>2009-02-10T09:14:59Z</updated>
    <published>2009-02-10T09:14:59Z</published>
    <title>Package upgrades in FOSS distributions: details and challenges</title>
    <summary>  The upgrade problems faced by Free and Open Source Software distributions
have characteristics not easily found elsewhere. We describe the structure of
packages and their role in the upgrade process. We show that state of the art
package managers have shortcomings inhibiting their ability to cope with
frequent upgrade failures. We survey current countermeasures to such failures,
argue that they are not satisfactory, and sketch alternative solutions.
</summary>
    <author>
      <name>Roberto Di Cosmo</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PPS</arxiv:affiliation>
    </author>
    <author>
      <name>Stefano Zacchiroli</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PPS</arxiv:affiliation>
    </author>
    <author>
      <name>Paulo Trezentos</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/1490283.1490292</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/1490283.1490292" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Workshop On Hot Topics In Software Upgrades
  Proceedings of the 1st International Workshop on Hot Topics in Software
  Upgrades, Nashville, Tennessee : \'Etats-Unis d'Am\'erique (2008)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0902.1610v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0902.1610v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0909.1763v1</id>
    <updated>2009-09-09T18:09:06Z</updated>
    <published>2009-09-09T18:09:06Z</published>
    <title>Remembrance: The Unbearable Sentience of Being Digital</title>
    <summary>  We introduce a world vision in which data is endowed with memory. In this
data-centric systems paradigm, data items can be enabled to retain all or some
of their previous values. We call this ability "remembrance" and posit that it
empowers significant leaps in the security, availability, and general
operational dimensions of systems. With the explosion in cheap, fast memories
and storage, large-scale remembrance will soon become practical. Here, we
introduce and explore the advantages of such a paradigm and the challenges in
making it a reality.
</summary>
    <author>
      <name>Ragib Hasan</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Illinois</arxiv:affiliation>
    </author>
    <author>
      <name>Radu Sion</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Stony Brook University</arxiv:affiliation>
    </author>
    <author>
      <name>Marianne Winslett</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Illinois</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">CIDR 2009</arxiv:comment>
    <link href="http://arxiv.org/abs/0909.1763v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0909.1763v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1001.0196v1</id>
    <updated>2010-01-01T00:34:59Z</updated>
    <published>2010-01-01T00:34:59Z</published>
    <title>A distributed file system for a wide-area high performance computing
  infrastructure</title>
    <summary>  We describe our work in implementing a wide-area distributed file system for
the NSF TeraGrid. The system, called XUFS, allows private distributed name
spaces to be created for transparent access to personal files across over 9000
computer nodes. XUFS builds on many principles from prior distributed file
systems research, but extends key design goals to support the workflow of
computational science researchers. Specifically, XUFS supports file access from
the desktop to the wide-area network seamlessly, survives transient
disconnected operations robustly, and demonstrates comparable or better
throughput than some current high performance file systems on the wide-area
network.
</summary>
    <author>
      <name>Edward Walker</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, Proceedings of Third USENIX Workshop on Real, Large
  Distributed Systems, Seattle, Nov 2006</arxiv:comment>
    <link href="http://arxiv.org/abs/1001.0196v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1001.0196v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="C.2.4; D.4.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1010.4411v1</id>
    <updated>2010-10-21T10:12:59Z</updated>
    <published>2010-10-21T10:12:59Z</published>
    <title>Revisiting deadlock prevention: a probabilistic approach</title>
    <summary>  We revisit the deadlock-prevention problem by focusing on priority digraphs
instead of the traditional wait-for digraphs. This has allowed us to formulate
deadlock prevention in terms of prohibiting the occurrence of directed cycles
even in the most general of wait models (the so-called AND-OR model, in which
prohibiting wait-for directed cycles is generally overly restrictive). For a
particular case in which the priority digraphs are somewhat simplified, we
introduce a Las Vegas probabilistic mechanism for resource granting and analyze
its key aspects in detail.
</summary>
    <author>
      <name>Fabiano de S. Oliveira</name>
    </author>
    <author>
      <name>Valmir C. Barbosa</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1002/net.21537</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1002/net.21537" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Networks 63 (2014), 203-210</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1010.4411v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1010.4411v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1106.2766v1</id>
    <updated>2011-06-14T17:26:21Z</updated>
    <published>2011-06-14T17:26:21Z</published>
    <title>Supporting Parallelism in Server-based Multiprocessor Systems</title>
    <summary>  Developing an efficient server-based real-time scheduling solution that
supports dynamic task-level parallelism is now relevant to even the desktop and
embedded domains and no longer only to the high performance computing market
niche. This paper proposes a novel approach that combines the constant
bandwidth server abstraction with a work-stealing load balancing scheme which,
while ensuring isolation among tasks, enables a task to be executed on more
than one processor at a given time instant.
</summary>
    <author>
      <name>Luís Nogueira</name>
    </author>
    <author>
      <name>Luís Miguel Pinho</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">WiP Session of the 31st IEEE Real-Time Systems Symposium</arxiv:comment>
    <link href="http://arxiv.org/abs/1106.2766v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1106.2766v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1106.2992v1</id>
    <updated>2011-06-15T15:18:27Z</updated>
    <published>2011-06-15T15:18:27Z</published>
    <title>A Characterization of the SPARC T3-4 System</title>
    <summary>  This technical report covers a set of experiments on the 64-core SPARC T3-4
system, comparing it to two similar AMD and Intel systems. Key characteristics
as maximum integer and floating point arithmetic throughput are measured as
well as memory throughput, showing the scalability of the SPARC T3-4 system.
The performance of POSIX threads primitives is characterized and compared in
detail, such as thread creation and mutex synchronization. Scalability tests
with a fine grained multithreaded runtime are performed, showing problems with
atomic CAS operations on such physically highly parallel systems.
</summary>
    <author>
      <name>Michiel W. van Tol</name>
    </author>
    <link href="http://arxiv.org/abs/1106.2992v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1106.2992v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.2649v1</id>
    <updated>2013-01-12T05:31:57Z</updated>
    <published>2013-01-12T05:31:57Z</published>
    <title>Dynamic Transparent General Purpose Process Migration For Linux</title>
    <summary>  Process migration refers to the act of transferring a process in the middle
of its execution from one machine to another in a network. In this paper, we
proposed a process migration framework for Linux OS. It is a multilayer
architecture to confine every functionality independent section of the system
in separate layer. This architecture is capable of supporting diverse
applications due to generic user space interface and dynamic structure that can
be modified according to demands.
</summary>
    <author>
      <name>Amirreza Zarrabi</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5121/ijgca.2012.3402</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5121/ijgca.2012.3402" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Grid Computing &amp; Applications (IJGCA)
  Vol.3, No.4, December 2012</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1301.2649v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1301.2649v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1308.2881v1</id>
    <updated>2013-08-13T14:37:51Z</updated>
    <published>2013-08-13T14:37:51Z</published>
    <title>Opacity of Memory Management in Software Transactional Memory</title>
    <summary>  Opacity of Transactional Memory is proposed to be established by incremental
validation. Quiescence in terms of epoch-based memory reclamation is applied to
deal with doomed transactions causing memory access violations. This method
unfortunately involves increased memory consumption and does not cover
reclamations outside of transactions. This paper introduces a different method
which combines incremental validation with elements of sandboxing to solve
these issues.
</summary>
    <author>
      <name>Holger Machens</name>
    </author>
    <author>
      <name>Volker Turau</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Keywords: transactional memory, opacity, privatization, memory
  reclamation</arxiv:comment>
    <link href="http://arxiv.org/abs/1308.2881v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1308.2881v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="65Y05" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1405.2913v1</id>
    <updated>2014-05-12T16:41:49Z</updated>
    <published>2014-05-12T16:41:49Z</published>
    <title>Resource-Aware Replication on Heterogeneous Multicores: Challenges and
  Opportunities</title>
    <summary>  Decreasing hardware feature sizes and increasing heterogeneity in multicore
hardware require software that can adapt to these platforms' properties. We
implemented ROMAIN, an OS service providing redundant multithreading on top of
the FIASCO.OC microkernel to address the increasing unreliability of hardware.
In this paper we review challenges and opportunities for ROMAIN to adapt to
such multicore platforms in order to decrease execution overhead, resource
requirements, and vulnerability against faults.
</summary>
    <author>
      <name>Björn Döbel</name>
    </author>
    <author>
      <name>Robert Muschner</name>
    </author>
    <author>
      <name>Hermann Härtig</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented at 1st Workshop on Resource Awareness and Adaptivity in
  Multi-Core Computing (Racing 2014) (arXiv:1405.2281)</arxiv:comment>
    <link href="http://arxiv.org/abs/1405.2913v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1405.2913v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1406.1133v1</id>
    <updated>2014-06-04T18:18:37Z</updated>
    <published>2014-06-04T18:18:37Z</published>
    <title>Timing Analysis for DAG-based and GFP Scheduled Tasks</title>
    <summary>  Modern embedded systems have made the transition from single-core to
multi-core architectures, providing performance improvement via parallelism
rather than higher clock frequencies. DAGs are considered among the most
generic task models in the real-time domain and are well suited to exploit this
parallelism. In this paper we provide a schedulability test using response-time
analysis exploiting exploring and bounding the self interference of a DAG task.
Additionally we bound the interference a high priority task has on lower
priority ones.
</summary>
    <author>
      <name>José Marinho</name>
    </author>
    <author>
      <name>Stefan M. Petters</name>
    </author>
    <link href="http://arxiv.org/abs/1406.1133v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1406.1133v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1407.4245v1</id>
    <updated>2014-07-16T10:03:51Z</updated>
    <published>2014-07-16T10:03:51Z</published>
    <title>Security of OS-level virtualization technologies: Technical report</title>
    <summary>  The need for flexible, low-overhead virtualization is evident on many fronts
ranging from high-density cloud servers to mobile devices. During the past
decade OS-level virtualization has emerged as a new, efficient approach for
virtualization, with implementations in multiple different Unix-based systems.
Despite its popularity, there has been no systematic study of OS-level
virtualization from the point of view of security. In this report, we conduct a
comparative study of several OS-level virtualization systems, discuss their
security and identify some gaps in current solutions.
</summary>
    <author>
      <name>Elena Reshetova</name>
    </author>
    <author>
      <name>Janne Karhunen</name>
    </author>
    <author>
      <name>Thomas Nyman</name>
    </author>
    <author>
      <name>N. Asokan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1407.4245v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1407.4245v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1408.4715v1</id>
    <updated>2014-08-20T16:39:15Z</updated>
    <published>2014-08-20T16:39:15Z</published>
    <title>Making FPGAs Accessible to Scientists and Engineers as Domain Expert
  Software Programmers with LabVIEW</title>
    <summary>  In this paper we present a graphical programming framework, LabVIEW, and
associated language and libraries, as well as programming techniques and
patterns that we have found useful in making FPGAs accessible to scientists and
engineers as domain expert software programmers.
</summary>
    <author>
      <name>Hugo A. Andrade</name>
    </author>
    <author>
      <name>Simon Hogg</name>
    </author>
    <author>
      <name>Stephan Ahrends</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented at First International Workshop on FPGAs for Software
  Programmers (FSP 2014) (arXiv:1408.4423)</arxiv:comment>
    <link href="http://arxiv.org/abs/1408.4715v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1408.4715v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.04169v1</id>
    <updated>2015-11-13T06:27:39Z</updated>
    <published>2015-11-13T06:27:39Z</published>
    <title>Specifying a Realistic File System</title>
    <summary>  We present the most interesting elements of the correctness specification of
BilbyFs, a performant Linux flash file system. The BilbyFs specification
supports asynchronous writes, a feature that has been overlooked by several
file system verification projects, and has been used to verify the correctness
of BilbyFs's fsync() C implementation. It makes use of nondeterminism to be
concise and is shallowly-embedded in higher-order logic.
</summary>
    <author>
      <name>Sidney Amani</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">NICTA and University of New South Wales, Australia</arxiv:affiliation>
    </author>
    <author>
      <name>Toby Murray</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">NICTA and University of New South Wales, Australia</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.196.1</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.196.1" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings MARS 2015, arXiv:1511.02528</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 196, 2015, pp. 1-9</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1511.04169v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.04169v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1603.03635v1</id>
    <updated>2016-03-11T14:10:18Z</updated>
    <published>2016-03-11T14:10:18Z</published>
    <title>Powering the Internet of Things with RIOT: Why? How? What is RIOT?</title>
    <summary>  The crucial importance of software platforms was highlighted by recent events
both at the political level (e.g. renewed calls for digital data and operating
system "sovereignty", following E. Snowden's revelations) and at the business
level (e.g. Android generated a new industry worth tens of billions of euros
yearly). In the Internet of Things, which is expected to generate business at
very large scale, but also to threaten even more individual privacy, such
aspects will be exacerbated. The need for an operating system like RIOT stems
from this context, and this short article outlines RIOT's main non-technical
aspects, as well as its key technical characteristics.
</summary>
    <author>
      <name>Emmanuel Baccelli</name>
    </author>
    <author>
      <name>Kaspar Schleiser</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1603.03635v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1603.03635v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.09334v1</id>
    <updated>2017-08-29T10:24:40Z</updated>
    <published>2017-08-29T10:24:40Z</published>
    <title>Tug-of-War: Observations on Unified Content Handling</title>
    <summary>  Modern applications and Operating Systems vary greatly with respect to how
they register and identify different types of content. These discrepancies lead
to exploits and inconsistencies in user experience. In this paper, we highlight
the issues arising in the modern content handling ecosystem, and examine how
the operating system can be used to achieve unified and consistent content
identification.
</summary>
    <author>
      <name>Theofilos Petsios</name>
    </author>
    <author>
      <name>Adrian Tang</name>
    </author>
    <author>
      <name>Dimitris Mitropoulos</name>
    </author>
    <author>
      <name>Salvatore Stolfo</name>
    </author>
    <author>
      <name>Angelos D. Keromytis</name>
    </author>
    <author>
      <name>Suman Jana</name>
    </author>
    <link href="http://arxiv.org/abs/1708.09334v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.09334v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0406005v3</id>
    <updated>2004-10-12T05:43:58Z</updated>
    <published>2004-06-02T21:54:50Z</published>
    <title>Microreboot -- A Technique for Cheap Recovery</title>
    <summary>  A significant fraction of software failures in large-scale Internet systems
are cured by rebooting, even when the exact failure causes are unknown.
However, rebooting can be expensive, causing nontrivial service disruption or
downtime even when clusters and failover are employed. In this work we separate
process recovery from data recovery to enable microrebooting -- a fine-grain
technique for surgically recovering faulty application components, without
disturbing the rest of the application.
  We evaluate microrebooting in an Internet auction system running on an
application server. Microreboots recover most of the same failures as full
reboots, but do so an order of magnitude faster and result in an order of
magnitude savings in lost work. This cheap form of recovery engenders a new
approach to high availability: microreboots can be employed at the slightest
hint of failure, prior to node failover in multi-node clusters, even when
mistakes in failure detection are likely; failure and recovery can be masked
from end users through transparent call-level retries; and systems can be
rejuvenated by parts, without ever being shut down.
</summary>
    <author>
      <name>George Candea</name>
    </author>
    <author>
      <name>Shinichi Kawamoto</name>
    </author>
    <author>
      <name>Yuichi Fujiki</name>
    </author>
    <author>
      <name>Greg Friedman</name>
    </author>
    <author>
      <name>Armando Fox</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. 6th Symposium on Operating Systems Design and Implementation
  (OSDI), San Francisco, CA, Dec 2004</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0406005v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0406005v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.4.0" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0411080v1</id>
    <updated>2004-11-23T16:52:26Z</updated>
    <published>2004-11-23T16:52:26Z</published>
    <title>Modeling the input history of programs for improved instruction-memory
  performance</title>
    <summary>  When a program is loaded into memory for execution, the relative position of
its basic blocks is crucial, since loading basic blocks that are unlikely to be
executed first places them high in the instruction-memory hierarchy only to be
dislodged as the execution goes on. In this paper we study the use of Bayesian
networks as models of the input history of a program. The main point is the
creation of a probabilistic model that persists as the program is run on
different inputs and at each new input refines its own parameters in order to
reflect the program's input history more accurately. As the model is thus
tuned, it causes basic blocks to be reordered so that, upon arrival of the next
input for execution, loading the basic blocks into memory automatically takes
into account the input history of the program. We report on extensive
experiments, whose results demonstrate the efficacy of the overall approach in
progressively lowering the execution times of a program on identical inputs
placed randomly in a sequence of varied inputs. We provide results on selected
SPEC CINT2000 programs and also evaluate our approach as compared to the gcc
level-3 optimization and to Pettis-Hansen reordering.
</summary>
    <author>
      <name>C. A. G. Assis</name>
    </author>
    <author>
      <name>E. S. T. Fernandes</name>
    </author>
    <author>
      <name>V. C. Barbosa</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1093/comjnl/bxl044</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1093/comjnl/bxl044" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Computer Journal 49 (2006), 744-761</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0411080v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0411080v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="B.3.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1002.3329v1</id>
    <updated>2010-02-17T17:52:17Z</updated>
    <published>2010-02-17T17:52:17Z</published>
    <title>A new model for virtual machine migration in virtualized cluster server
  based on Fuzzy Decision Making</title>
    <summary>  In this paper, we show that performance of the virtualized cluster servers
could be improved through intelligent decision over migration time of Virtual
Machines across heterogeneous physical nodes of a cluster server. The cluster
serves a variety range of services from Web Service to File Service. Some of
them are CPU-Intensive while others are RAM-Intensive and so on. Virtualization
has many advantages such as less hardware cost, cooling cost, more
manageability. One of the key benefits is better load balancing by using of VM
migration between hosts. To migrate, we must know which virtual machine needs
to be migrated and when this relocation has to be done and, moreover, which
host must be destined. To relocate VMs from overloaded servers to underloaded
ones, we need to sort nodes from the highest volume to the lowest. There are
some models to finding the most overloaded node, but they have some
shortcomings. The focus of this paper is to present a new method to migrate VMs
between cluster nodes using TOPSIS algorithm - one of the most efficient Multi
Criteria Decision Making techniques- to make more effective decision over whole
active servers of the Cluster and find the most loaded serversTo evaluate the
performance improvement resulted from this model, we used cluster Response time
and Unbalanced Factor.
</summary>
    <author>
      <name>M. Tarighi</name>
    </author>
    <author>
      <name>S. A. Motamedi</name>
    </author>
    <author>
      <name>S. Sharifian</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Telecommunications,Volume 1, Issue 1, pp40-51, February
  2010</arxiv:comment>
    <link href="http://arxiv.org/abs/1002.3329v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1002.3329v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1003.4088v1</id>
    <updated>2010-03-22T06:52:12Z</updated>
    <published>2010-03-22T06:52:12Z</published>
    <title>Proficient Pair of Replacement Algorithms on L1 and L2 Cache for Merge
  Sort</title>
    <summary>  Memory hierarchy is used to compete the processors speed. Cache memory is the
fast memory which is used to conduit the speed difference of memory and
processor. The access patterns of Level 1 cache (L1) and Level 2 cache (L2) are
different, when CPU not gets the desired data in L1 then it accesses L2. Thus
the replacement algorithm which works efficiently on L1 may not be as efficient
on L2. Similarly various applications such as Matrix Multiplication, Web, Fast
Fourier Transform (FFT) etc will have varying access pattern. Thus same
replacement algorithm for all types of application may not be efficient. This
paper works for getting an efficient pair of replacement algorithm on L1 and L2
for the algorithm Merge Sort. With the memory reference string of Merge Sort,
we have analyzed the behavior of various existing replacement algorithms on L1.
The existing replacement algorithms which are taken into consideration are:
Least Recently Used (LRU), Least Frequently Used (LFU) and First In First Out
(FIFO). After Analyzing the memory reference pattern of Merge Sort, we have
proposed a Partition Based Replacement algorithm (PBR_L1)) on L1 Cache.
Furthermore we have analyzed various pairs of algorithms on L1 and L2
respectively, resulting in finding a suitable pair of replacement algorithms.
Simulation on L1 shows, among the considered existing replacement algorithms
FIFO is performing better than others. While the proposed replacement algorithm
PBR_L1 is working about 1.7% to 44 % better than FIFO for various cache sizes.
</summary>
    <author>
      <name>Richa Gupta</name>
    </author>
    <author>
      <name>Sanjiv Tokekar</name>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Computing, Volume 2, Issue 3, March 2010,
  https://sites.google.com/site/journalofcomputing/</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1003.4088v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1003.4088v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1003.5303v2</id>
    <updated>2010-07-25T15:40:38Z</updated>
    <published>2010-03-27T14:44:01Z</published>
    <title>Determinating Timing Channels in Compute Clouds</title>
    <summary>  Timing side-channels represent an insidious security challenge for cloud
computing, because: (a) massive parallelism in the cloud makes timing channels
pervasive and hard to control; (b) timing channels enable one customer to steal
information from another without leaving a trail or raising alarms; (c) only
the cloud provider can feasibly detect and report such attacks, but the
provider's incentives are not to; and (d) resource partitioning schemes for
timing channel control undermine statistical sharing efficiency, and, with it,
the cloud computing business model. We propose a new approach to timing channel
control, using provider-enforced deterministic execution instead of resource
partitioning to eliminate timing channels within a shared cloud domain.
Provider-enforced determinism prevents execution timing from affecting the
results of a compute task, however large or parallel, ensuring that a task's
outputs leak no timing information apart from explicit timing inputs and total
compute duration. Experiments with a prototype OS for deterministic cloud
computing suggest that such an approach may be practical and efficient. The OS
supports deterministic versions of familiar APIs such as processes, threads,
shared memory, and file systems, and runs coarse-grained parallel tasks as
efficiently and scalably as current timing channel-ridden systems.
</summary>
    <author>
      <name>Amittai Aviram</name>
    </author>
    <author>
      <name>Sen Hu</name>
    </author>
    <author>
      <name>Bryan Ford</name>
    </author>
    <author>
      <name>Ramakrishna Gummadi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1003.5303v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1003.5303v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1012.2831v2</id>
    <updated>2010-12-20T22:16:29Z</updated>
    <published>2010-12-13T18:47:10Z</published>
    <title>Sesame: Self-Constructive System Energy Modeling for Battery-Powered
  Mobile Systems</title>
    <summary>  System energy models are important for energy optimization and management in
mobile systems. However, existing system energy models are built in lab with
the help from a second computer. Not only are they labor-intensive; but also
they will not adequately account for the great diversity in the hardware and
usage of mobile systems. Moreover, existing system energy models are intended
for energy estimation for time intervals of one second or longer; they do not
provide the required rate for fine-grain use such as per-application energy
accounting.
  In this work, we study a self-modeling paradigm in which a mobile system
automatically generates its energy model without any external assistance. Our
solution, Se-same, leverages the possibility of self power measurement through
the smart battery interface and employs a suite of novel techniques to achieve
accuracy and rate much higher than that of the smart battery interface.
  We report the implementation and evaluation of Se-same on a laptop and a
smartphone. The experiment results show that Sesame generates system energy
models of 95% accuracy at one estimation per second and 88% accuracy at one
estimation per 10ms, without any external assistance. A five-day field studies
with four laptop and four smartphones users further demonstrate the
effectiveness, efficiency, and noninvasiveness of Sesame.
</summary>
    <author>
      <name>Mian Dong</name>
    </author>
    <author>
      <name>Lin Zhong</name>
    </author>
    <link href="http://arxiv.org/abs/1012.2831v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1012.2831v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1012.3452v1</id>
    <updated>2010-12-15T20:38:40Z</updated>
    <published>2010-12-15T20:38:40Z</published>
    <title>Customer Appeasement Scheduling</title>
    <summary>  Almost all of the current process scheduling algorithms which are used in
modern operating systems (OS) have their roots in the classical scheduling
paradigms which were developed during the 1970's. But modern computers have
different types of software loads and user demands. We think it is important to
run what the user wants at the current moment. A user can be a human, sitting
in front of a desktop machine, or it can be another machine sending a request
to a server through a network connection. We think that OS should become
intelligent to distinguish between different processes and allocate resources,
including CPU, to those processes which need them most. In this work, as a
first step to make the OS aware of the current state of the system, we consider
process dependencies and interprocess communications. We are developing a
model, which considers the need to satisfy interactive users and other possible
remote users or customers, by making scheduling decisions based on process
dependencies and interprocess communications. Our simple proof of concept
implementation and experiments show the effectiveness of this approach in the
real world applications. Our implementation does not require any change in the
software applications nor any special kind of configuration in the system,
Moreover, it does not require any additional information about CPU needs of
applications nor other resource requirements. Our experiments show significant
performance improvement for real world applications. For example, almost
constant average response time for Mysql data base server and constant frame
rate for mplayer under different simulated load values.
</summary>
    <author>
      <name>Mohammad R Nikseresht</name>
    </author>
    <author>
      <name>Anil Somayaji</name>
    </author>
    <author>
      <name>Anil Maheshwari</name>
    </author>
    <link href="http://arxiv.org/abs/1012.3452v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1012.3452v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1012.5695v1</id>
    <updated>2010-12-28T04:35:02Z</updated>
    <published>2010-12-28T04:35:02Z</published>
    <title>Dynamic Scheduling of Skippable Periodic Tasks with Energy Efficiency in
  Weakly Hard Real-Time System</title>
    <summary>  Energy consumption is a critical design issue in real-time systems,
especially in battery- operated systems. Maintaining high performance, while
extending the battery life between charges is an interesting challenge for
system designers. Dynamic Voltage Scaling (DVS) allows a processor to
dynamically change speed and voltage at run time, thereby saving energy by
spreading run cycles into idle time. Knowing when to use full power and when
not, requires the cooperation of the operating system scheduler. Usually,
higher processor voltage and frequency leads to higher system throughput while
energy reduction can be obtained using lower voltage and frequency. Instead of
lowering processor voltage and frequency as much as possible, energy efficient
real-time scheduling adjusts voltage and frequency according to some
optimization criteria, such as low energy consumption or high throughput, while
it meets the timing constraints of the real-time tasks. As the quantity and
functional complexity of battery powered portable devices continues to raise,
energy efficient design of such devices has become increasingly important. Many
real-time scheduling algorithms have been developed recently to reduce energy
consumption in the portable devices that use DVS capable processors. Three
algorithms namely Red Tasks Only (RTO), Blue When Possible (BWP) and Red as
Late as Possible (RLP) are proposed in the literature to schedule the real-time
tasks in Weakly-hard real-time systems. This paper proposes optimal slack
management algorithms to make the above existing weakly hard real-time
scheduling algorithms energy efficient using DVS and DPD techniques.
</summary>
    <author>
      <name>Santhi Baskaran</name>
    </author>
    <author>
      <name>P. Thambidurai</name>
    </author>
    <link href="http://arxiv.org/abs/1012.5695v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1012.5695v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1103.2348v1</id>
    <updated>2011-03-11T19:12:15Z</updated>
    <published>2011-03-11T19:12:15Z</published>
    <title>Transparent Programming of Heterogeneous Smartphones for Sensing</title>
    <summary>  Sensing on smartphones is known to be power-hungry. It has been shown that
this problem can be solved by adding an ultra low-power processor to execute
simple, frequent sensor data processing. While very effective in saving energy,
this resulting heterogeneous, distributed architecture poses a significant
challenge to application development.
  We present Reflex, a suite of runtime and compilation techniques to conceal
the heterogeneous, distributed nature from developers. The Reflex automatically
transforms the developer's code for distributed execution with the help of the
Reflex runtime. To create a unified system illusion, Reflex features a novel
software distributed shared memory (DSM) design that leverages the extreme
architectural asymmetry between the low-power processor and the powerful
central processor to achieve both energy efficiency and performance.
  We report a complete realization of Reflex for heterogeneous smartphones with
Maemo/Linux as the central kernel. Using a tri-processor hardware prototype and
sensing applications reported in recent literature, we evaluate the Reflex
realization for programming transparency, energy efficiency, and performance.
We show that Reflex supports a programming style that is very close to
contemporary smartphone programming. It allows existing sensing applications to
be ported with minor source code changes. Reflex reduces the system power in
sensing by up to 83%, and its runtime system only consumes 10% local memory on
a typical ultra-low power processor.
</summary>
    <author>
      <name>Felix Xiaozhu Lin</name>
    </author>
    <author>
      <name>Zhen Wang</name>
    </author>
    <author>
      <name>Robert LiKamWa</name>
    </author>
    <author>
      <name>Lin Zhong</name>
    </author>
    <link href="http://arxiv.org/abs/1103.2348v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1103.2348v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1105.1815v1</id>
    <updated>2011-05-09T22:39:46Z</updated>
    <published>2011-05-09T22:39:46Z</published>
    <title>User Mode Memory Page Management: An old idea applied anew to the memory
  wall problem</title>
    <summary>  It is often said that one of the biggest limitations on computer performance
is memory bandwidth (i.e."the memory wall problem"). In this position paper, I
argue that if historical trends in computing evolution (where growth in
available capacity is exponential and reduction in its access latencies is
linear) continue as they have, then this view is wrong - in fact we ought to be
concentrating on reducing whole system memory access latencies wherever
possible, and by "whole system" I mean that we ought to look at how software
can be unnecessarily wasteful with memory bandwidth due to legacy design
decisions. To this end I conduct a feasibility study to determine whether we
ought to virtualise the MMU for each application process such that it has
direct access to its own MMU page tables and the memory allocated to a process
is managed exclusively by the process and not the kernel. I find under typical
conditions that nearly scale invariant performance to memory allocation size is
possible such that hundreds of megabytes of memory can be allocated, relocated,
swapped and deallocated in almost the same time as kilobytes (e.g. allocating
8Mb is 10x quicker under this experimental allocator than a conventional
allocator, and resizing a 128Kb block to 256Kb block is 4.5x faster). I find
that first time page access latencies are improved tenfold; moreover, because
the kernel page fault handler is never called, the lack of cache pollution
improves whole application memory access latencies increasing performance by up
to 2x. Finally, I try binary patching existing applications to use the
experimental allocation technique, finding almost universal performance
improvements without having to recompile these applications to make better use
of the new facilities.
</summary>
    <author>
      <name>Niall Douglas</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages. Rejected from MSPC11</arxiv:comment>
    <link href="http://arxiv.org/abs/1105.1815v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1105.1815v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="C.4; D.4.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1110.4623v1</id>
    <updated>2011-10-20T19:43:58Z</updated>
    <published>2011-10-20T19:43:58Z</published>
    <title>Efficient Synchronization Primitives for GPUs</title>
    <summary>  In this paper, we revisit the design of synchronization
primitives---specifically barriers, mutexes, and semaphores---and how they
apply to the GPU. Previous implementations are insufficient due to the
discrepancies in hardware and programming model of the GPU and CPU. We create
new implementations in CUDA and analyze the performance of spinning on the GPU,
as well as a method of sleeping on the GPU, by running a set of memory-system
benchmarks on two of the most common GPUs in use, the Tesla- and Fermi-class
GPUs from NVIDIA. From our results we define higher-level principles that are
valid for generic many-core processors, the most important of which is to limit
the number of atomic accesses required for a synchronization operation because
atomic accesses are slower than regular memory accesses. We use the results of
the benchmarks to critique existing synchronization algorithms and guide our
new implementations, and then define an abstraction of GPUs to classify any GPU
based on the behavior of the memory system. We use this abstraction to create
suitable implementations of the primitives specifically targeting the GPU, and
analyze the performance of these algorithms on Tesla and Fermi. We then predict
performance on future GPUs based on characteristics of the abstraction. We also
examine the roles of spin waiting and sleep waiting in each primitive and how
their performance varies based on the machine abstraction, then give a set of
guidelines for when each strategy is useful based on the characteristics of the
GPU and expected contention.
</summary>
    <author>
      <name>Jeff A. Stuart</name>
    </author>
    <author>
      <name>John D. Owens</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages with appendix, several figures, plans to submit to CompSci
  conference in early 2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1110.4623v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1110.4623v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.4.1; I.3.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1112.5136v1</id>
    <updated>2011-12-21T19:02:12Z</updated>
    <published>2011-12-21T19:02:12Z</published>
    <title>Quest-V: A Virtualized Multikernel for High-Confidence Systems</title>
    <summary>  This paper outlines the design of `Quest-V', which is implemented as a
collection of separate kernels operating together as a distributed system on a
chip. Quest-V uses virtualization techniques to isolate kernels and prevent
local faults from affecting remote kernels. This leads to a high-confidence
multikernel approach, where failures of system subcomponents do not render the
entire system inoperable. A virtual machine monitor for each kernel keeps track
of shadow page table mappings that control immutable memory access
capabilities. This ensures a level of security and fault tolerance in
situations where a service in one kernel fails, or is corrupted by a malicious
attack. Communication is supported between kernels using shared memory regions
for message passing. Similarly, device driver data structures are shareable
between kernels to avoid the need for complex I/O virtualization, or
communication with a dedicated kernel responsible for I/O. In Quest-V, device
interrupts are delivered directly to a kernel, rather than via a monitor that
determines the destination. Apart from bootstrapping each kernel, handling
faults and managing shadow page tables, the monitors are not needed. This
differs from conventional virtual machine systems in which a central monitor,
or hypervisor, is responsible for scheduling and management of host resources
amongst a set of guest kernels. In this paper we show how Quest-V can implement
novel fault isolation and recovery techniques that are not possible with
conventional systems. We also show how the costs of using virtualization for
isolation of system services does not add undue overheads to the overall system
performance.
</summary>
    <author>
      <name>Ye Li</name>
    </author>
    <author>
      <name>Matthew Danish</name>
    </author>
    <author>
      <name>Richard West</name>
    </author>
    <link href="http://arxiv.org/abs/1112.5136v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1112.5136v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1207.1591v1</id>
    <updated>2012-07-06T11:48:24Z</updated>
    <published>2012-07-06T11:48:24Z</published>
    <title>A Secure Dynamic Job Scheduling on Smart Grid using RSA Algorithm</title>
    <summary>  Grid computing is a computation methodology using group of clusters connected
over high-speed networks that involves coordinating and sharing computational
power, data storage and network resources. Integrating a set of clusters of
workstations into one large computing environment can improve the availability
of computing power. The goal of scheduling is to achieve highest possible
system throughput and to match the application need with the available
computing resources. A secure scheduling model is presented, that performs job
grouping activity at runtime. In a Grid environment, security is necessary
because grid is a dynamic environment and participates are independent bodies
with different policies, objectives and requirements. Authentication should be
verified for Grid resource owners as well as resource requesters before they
are allowed to join in scheduling activities. In order to achieve secure
resource and job scheduling including minimum processing time and maximum
resource utilization, A Secure Resource by using RSA algorithm on Networking
and Job Scheduling model with Job Grouping strategy(JGS) in Grid Computing has
been proposed. The result shows significant improvement in the processing time
of jobs and resource utilization as compared to dynamic job grouping (DJG)
based scheduling on smart grids (SG).
</summary>
    <author>
      <name>P. Radha Krishna Reddy</name>
    </author>
    <author>
      <name>Ashim Roy</name>
    </author>
    <author>
      <name>G. Sireesha</name>
    </author>
    <author>
      <name>Ismatha Begum</name>
    </author>
    <author>
      <name>S. Siva Ramaiah</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Published; 2277128x 2012</arxiv:comment>
    <link href="http://arxiv.org/abs/1207.1591v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1207.1591v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1208.6406v1</id>
    <updated>2012-08-31T06:53:14Z</updated>
    <published>2012-08-31T06:53:14Z</published>
    <title>Building Resilient Cloud Over Unreliable Commodity Infrastructure</title>
    <summary>  Cloud Computing has emerged as a successful computing paradigm for
efficiently utilizing managed compute infrastructure such as high speed
rack-mounted servers, connected with high speed networking, and reliable
storage. Usually such infrastructure is dedicated, physically secured and has
reliable power and networking infrastructure. However, much of our idle compute
capacity is present in unmanaged infrastructure like idle desktops, lab
machines, physically distant server machines, and laptops. We present a scheme
to utilize this idle compute capacity on a best-effort basis and provide high
availability even in face of failure of individual components or facilities.
  We run virtual machines on the commodity infrastructure and present a cloud
interface to our end users. The primary challenge is to maintain availability
in the presence of node failures, network failures, and power failures. We run
multiple copies of a Virtual Machine (VM) redundantly on geographically
dispersed physical machines to achieve availability. If one of the running
copies of a VM fails, we seamlessly switchover to another running copy. We use
Virtual Machine Record/Replay capability to implement this redundancy and
switchover. In current progress, we have implemented VM Record/Replay for
uniprocessor machines over Linux/KVM and are currently working on VM
Record/Replay on shared-memory multiprocessor machines. We report initial
experimental results based on our implementation.
</summary>
    <author>
      <name>Piyus Kedia</name>
    </author>
    <author>
      <name>Sorav Bansal</name>
    </author>
    <author>
      <name>Deepak Deshpande</name>
    </author>
    <author>
      <name>Sreekanth Iyer</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/CCEM.2012.6354601</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/CCEM.2012.6354601" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Oral presentation at IEEE "Cloud Computing for Emerging Markets",
  Oct. 11-12, 2012, Bangalore, India</arxiv:comment>
    <link href="http://arxiv.org/abs/1208.6406v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1208.6406v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1208.6428v1</id>
    <updated>2012-08-31T09:04:05Z</updated>
    <published>2012-08-31T09:04:05Z</published>
    <title>A Hardware Time Manager Implementation for the Xenomai Real-Time Kernel
  of Embedded Linux</title>
    <summary>  Nowadays, the use of embedded operating systems in different embedded
projects is subject to a tremendous growth. Embedded Linux is becoming one of
those most popular EOSs due to its modularity, efficiency, reliability, and
cost. One way to make it hard real-time is to include a real-time kernel like
Xenomai. One of the key characteristics of a Real-Time Operating System (RTOS)
is its ability to meet execution time deadlines deterministically. So, the more
precise and flexible the time management can be, the better it can handle
efficiently the determinism for different embedded applications. RTOS time
precision is characterized by a specific periodic interrupt service controlled
by a software time manager. The smaller the period of the interrupt, the better
the precision of the RTOS, the more it overloads the CPU, and though reduces
the overall efficiency of the RTOS. In this paper, we propose to drastically
reduce these overheads by migrating the time management service of Xenomai into
a configurable hardware component to relieve the CPU. The hardware component is
implemented in a Field Programmable Gate Array coupled to the CPU. This work
was achieved in a Master degree project where students could apprehend many
fields of embedded systems: RTOS programming, hardware design, performance
evaluation, etc.
</summary>
    <author>
      <name>Pierre Olivier</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Lab-STICC</arxiv:affiliation>
    </author>
    <author>
      <name>Jalil Boukhobza</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Lab-STICC</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Embed With Linux (EWiLi) workshop, Lorient : France (2012)</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ACM SIGBED Review 9(2) 38-42 9, 2 (2012) 38-42</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1208.6428v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1208.6428v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.4839v1</id>
    <updated>2012-11-20T19:33:08Z</updated>
    <published>2012-11-20T19:33:08Z</published>
    <title>An Insight View of Kernel Visual Debugger in System Boot up</title>
    <summary>  For many years, developers could not figure out the mystery of OS kernels.
The main source of this mystery is the interaction between operating systems
and hardware while system's boot up and kernel initialization. In addition,
many operating system kernels differ in their behavior toward many situations.
For instance, kernels act differently in racing conditions, kernel
initialization and process scheduling. For such operations, kernel debuggers
were designed to help in tracing kernel behavior and solving many kernel bugs.
The importance of kernel debuggers is not limited to kernel code tracing but
also, they can be used in verification and performance comparisons. However,
developers had to be aware of debugger commands thus introducing some
difficulties to non-expert programmers. Later, several visual kernel debuggers
were presented to make it easier for programmers to trace their kernel code and
analyze kernel behavior. Nowadays, several kernel debuggers exist for solving
this mystery but only very few support line-by-line debugging at run-time. In
this paper, a generic approach for operating system source code debugging in
graphical mode with line-by-line tracing support is proposed. In the context of
this approach, system boot up and evaluation of two operating system schedulers
from several points of views will be discussed.
</summary>
    <author>
      <name>Mohamed Farag</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5121/ijcsit.2012.4510</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5121/ijcsit.2012.4510" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, International Journal</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Science &amp; Information Technology
  (IJCSIT) Vol 4, No 5, October 2012</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1211.4839v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.4839v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.6067v1</id>
    <updated>2013-04-22T19:29:05Z</updated>
    <published>2013-04-22T19:29:05Z</published>
    <title>Invasive Computing - Common Terms and Granularity of Invasion</title>
    <summary>  Future MPSoCs with 1000 or more processor cores on a chip require new means
for resource-aware programming in order to deal with increasing imperfections
such as process variation, fault rates, aging effects, and power as well as
thermal problems. On the other hand, predictable program executions are
threatened if not impossible if no proper means of resource isolation and
exclusive use may be established on demand. In view of these problems and
menaces, invasive computing enables an application programmer to claim for
processing resources and spread computations to claimed processors dynamically
at certain points of the program execution.
  Such decisions may be depending on the degree of application parallelism and
the state of the underlying resources such as utilization, load, and
temperature, but also with the goal to provide predictable program execution on
MPSoCs by claiming processing resources exclusively as the default and thus
eliminating interferences and creating the necessary isolation between multiple
concurrently running applications. For achieving this goal, invasive computing
introduces new programming constructs for resource-aware programming that
meanwhile, for testing purpose, have been embedded into the parallel computing
language X10 as developed by IBM using a library-based approach.
  This paper presents major ideas and common terms of invasive computing as
investigated by the DFG Transregional Collaborative Research Centre TR89.
Moreoever, a reflection is given on the granularity of resources that may be
requested by invasive programs.
</summary>
    <author>
      <name>Jürgen Teich</name>
    </author>
    <author>
      <name>Wolfgang Schröder-Preikschat</name>
    </author>
    <author>
      <name>Andreas Herkersdorf</name>
    </author>
    <link href="http://arxiv.org/abs/1304.6067v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.6067v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1312.1810v1</id>
    <updated>2013-12-06T09:18:04Z</updated>
    <published>2013-12-06T09:18:04Z</published>
    <title>File System - A Component of Operating System</title>
    <summary>  The file system provides the mechanism for online storage and access to file
contents, including data and programs. This paper covers the high-level details
of file systems, as well as related topics such as the disk cache, the file
system interface to the kernel, and the user-level APIs that use the features
of the file system. It will give you a thorough understanding of how a file
system works in general. The main component of the operating system is the file
system. It is used to create, manipulate, store, and retrieve data. At the
highest level, a file system is a way to manage information on a secondary
storage medium. There are so many layers under and above the file system. All
the layers are to be fully described here. This paper will give the explanatory
knowledge of the file system designers and the researchers in the area. The
complete path from the user process to secondary storage device is to be
mentioned. File system is the area where the researchers are doing lot of job
and there is always a need to do more work. The work is going on for the
efficient, secure, energy saving techniques for the file systems. As we know
that the hardware is going to be fast in performance and low-priced day by day.
The software is not built to comeback with the hardware technology. So there is
a need to do research in this area to bridge the technology gap.
</summary>
    <author>
      <name>Brijender Kahanwal</name>
    </author>
    <author>
      <name>Tejinder Pal Singh</name>
    </author>
    <author>
      <name>Ruchira Bhargava</name>
    </author>
    <author>
      <name>Girish Pal Singh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 3 figures, 1 table</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Asian Journal of Computer Science and Information Technology 2(5),
  pp. 124-128, 2012</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1312.1810v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1312.1810v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1312.1822v1</id>
    <updated>2013-12-06T10:20:38Z</updated>
    <published>2013-12-06T10:20:38Z</published>
    <title>Towards the Framework of the File Systems Performance Evaluation
  Techniques and the Taxonomy of Replay Traces</title>
    <summary>  This is the era of High Performance Computing (HPC). There is a great demand
of the best performance evaluation techniques for the file and storage systems.
The task of evaluation is both necessary and hard. It gives in depth analysis
of the target system and that becomes the decision points for the users. That
is also helpful for the inventors or developers to find out the bottleneck in
their systems. In this paper many performance evaluation techniques are
described for file and storage system evaluation and the main stress is given
on the important one that is replay traces. A survey has been done for the
performance evaluation techniques used by the researchers and on the replay
traces. And the taxonomy of the replay traces is described. The some of the
popular replay traces are just like, Tracefs [1], //Trace [2], Replayfs [3] and
VFS Interceptor [12]. At last we have concluded all the features that must be
considered when we are going to develop the new tool for the replay traces. The
complete work of this paper shows that the storage system developers must care
about all the techniques which can be used for the performance evaluation of
the file systems. So they can develop highly efficient future file and storage
systems.
</summary>
    <author>
      <name>Brijender Kahanwal</name>
    </author>
    <author>
      <name>Tejinder Pal Singh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Advanced Research in Computer Science,
  2(6) pp. 224-229, 2011</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1312.1822v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1312.1822v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1312.3938v3</id>
    <updated>2014-01-30T21:39:39Z</updated>
    <published>2013-12-13T20:53:39Z</published>
    <title>Transparent Checkpoint-Restart over InfiniBand</title>
    <summary>  InfiniBand is widely used for low-latency, high-throughput cluster computing.
Saving the state of the InfiniBand network as part of distributed checkpointing
has been a long-standing challenge for researchers. Because of a lack of a
solution, typical MPI implementations have included custom checkpoint-restart
services that "tear down" the network, checkpoint each node as if the node were
a standalone computer, and then re-connect the network again. We present the
first example of transparent, system-initiated checkpoint-restart that directly
supports InfiniBand. The new approach is independent of any particular Linux
kernel, thus simplifying the current practice of using a kernel-based module,
such as BLCR. This direct approach results in checkpoints that are found to be
faster than with the use of a checkpoint-restart service. The generality of
this approach is shown not only by checkpointing an MPI computation, but also a
native UPC computation (Berkeley Unified Parallel C), which does not use MPI.
Scalability is shown by checkpointing 2,048 MPI processes across 128 nodes
(with 16 cores per node). In addition, a cost-effective debugging approach is
also enabled, in which a checkpoint image from an InfiniBand-based production
cluster is copied to a local Ethernet-based cluster, where it can be restarted
and an interactive debugger can be attached to it. This work is based on a
plugin that extends the DMTCP (Distributed MultiThreaded CheckPointing)
checkpoint-restart package.
</summary>
    <author>
      <name>Jiajun Cao</name>
    </author>
    <author>
      <name>Gregory Kerr</name>
    </author>
    <author>
      <name>Kapil Arya</name>
    </author>
    <author>
      <name>Gene Cooperman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">22 pages, 2 figures, 9 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1312.3938v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1312.3938v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.0" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1403.5010v1</id>
    <updated>2014-03-20T00:34:00Z</updated>
    <published>2014-03-20T00:34:00Z</published>
    <title>Task &amp; Resource Self-adaptive Embedded Real-time Operating System
  Microkernel for Wireless Sensor Nodes</title>
    <summary>  Wireless Sensor Networks (WSNs) are used in many application fields, such as
military, healthcare, environment surveillance, etc. The WSN OS based on
event-driven model doesn't support real-time and multi-task application types
and the OSs based on thread-driven model consume much energy because of
frequent context switch. Due to the high-dense and large-scale deployment of
sensor nodes, it is very difficult to collect sensor nodes to update their
software. Furthermore, the sensor nodes are vulnerable to security attacks
because of the characteristics of broadcast communication and unattended
application. This paper presents a task and resource self-adaptive embedded
real-time microkernel, which proposes hybrid programming model and offers a
two-level scheduling strategy to support real-time multi-task correspondingly.
A communication scheme, which takes the "tuple" space and "IN/OUT" primitives
from "LINDA", is proposed to support some collaborative and distributed tasks.
In addition, this kernel implements a run-time over-the-air updating mechanism
and provides a security policy to avoid the attacks and ensure the reliable
operation of nodes. The performance evaluation is proposed and the experiential
results show this kernel is task-oriented and resource-aware and can be used
for the applications of event-driven and real-time multi-task.
</summary>
    <author>
      <name>Kexing Xing</name>
    </author>
    <author>
      <name>Decheng Zuo</name>
    </author>
    <author>
      <name>Haiying Zhou</name>
    </author>
    <author>
      <name>Hou Kun-Mean</name>
    </author>
    <link href="http://arxiv.org/abs/1403.5010v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1403.5010v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1404.1637v1</id>
    <updated>2014-04-06T23:53:01Z</updated>
    <published>2014-04-06T23:53:01Z</published>
    <title>An Enhanced Multi-Pager Environment Support for Second Generation
  Microkernels</title>
    <summary>  The main objective of this paper is to present a mechanism of enhanced paging
support for the second generation microkernels in the form of explicit support
of multi-pager environment for the tasks running in the system. Proposed
mechanism is based on the intra-kernel high granularity pagers assignments per
virtual address space, which allow efficient and simple dispatching of page
faults to the appropriate pagers. The paging is one of the major features of
the virtual memory, which is extensively used by advanced operating systems to
provide an illusion of elastic memory. Original and present second generation
microkernels provide only limited, inflexible and unnatural support for paging.
Furthermore, facilities provided by current solutions for multi-pager support
on the runtime level introduce an overhead in terms of mode switches and thread
context switches which can be significantly reduced. Limited paging support
limits the attractiveness of the second generation microkernel based systems
use in real-life applications, in which processes usually have concurrent
servicing of multiple paging servers. The purpose of this paper is to present a
facilities for the efficient and flexible support of multi-pager environments
for the second generation microkernels. A comparison of the proposed solution
to the present architecture L4 + L4Re has been made and overhead of the page
fault handling critical path has been evaluated. Proposed solution is simple
enough and provides a natural and flexible support of multi-pager environments
for second generation microkernels in efficient way. It introduces a third less
overhead in terms of the mode switches and thread context switches in
comparison to the present L4 + L4Re solution implemented in the Fiasco.OC.
</summary>
    <author>
      <name>Yauhen Klimiankou</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 4 figures, 1 table</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Science and Information
  Security, Vol. 12 No. 1 JAN 2014</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1404.1637v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1404.1637v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.3463v1</id>
    <updated>2014-10-13T14:26:28Z</updated>
    <published>2014-10-13T14:26:28Z</published>
    <title>Mining Block I/O Traces for Cache Preloading with Sparse Temporal
  Non-parametric Mixture of Multivariate Poisson</title>
    <summary>  Existing caching strategies, in the storage domain, though well suited to
exploit short range spatio-temporal patterns, are unable to leverage long-range
motifs for improving hitrates. Motivated by this, we investigate novel Bayesian
non-parametric modeling(BNP) techniques for count vectors, to capture long
range correlations for cache preloading, by mining Block I/O traces. Such
traces comprise of a sequence of memory accesses that can be aggregated into
high-dimensional sparse correlated count vector sequences.
  While there are several state of the art BNP algorithms for clustering and
their temporal extensions for prediction, there has been no work on exploring
these for correlated count vectors. Our first contribution addresses this gap
by proposing a DP based mixture model of Multivariate Poisson (DP-MMVP) and its
temporal extension(HMM-DP-MMVP) that captures the full covariance structure of
multivariate count data. However, modeling full covariance structure for count
vectors is computationally expensive, particularly for high dimensional data.
Hence, we exploit sparsity in our count vectors, and as our main contribution,
introduce the Sparse DP mixture of multivariate Poisson(Sparse-DP-MMVP),
generalizing our DP-MMVP mixture model, also leading to more efficient
inference. We then discuss a temporal extension to our model for cache
preloading.
  We take the first step towards mining historical data, to capture long range
patterns in storage traces for cache preloading. Experimentally, we show a
dramatic improvement in hitrates on benchmark traces and lay the groundwork for
further research in storage domain to reduce latencies using data mining
techniques to capture long range motifs.
</summary>
    <author>
      <name>Lavanya Sita Tekumalla</name>
    </author>
    <author>
      <name>Chiranjib Bhattacharyya</name>
    </author>
    <link href="http://arxiv.org/abs/1410.3463v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.3463v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1501.07084v3</id>
    <updated>2015-09-14T21:25:55Z</updated>
    <published>2015-01-28T12:38:20Z</published>
    <title>k2U: A General Framework from k-Point Effective Schedulability Analysis
  to Utilization-Based Tests</title>
    <summary>  To deal with a large variety of workloads in different application domains in
real-time embedded systems, a number of expressive task models have been
developed. For each individual task model, researchers tend to develop
different types of techniques for deriving schedulability tests with different
computation complexity and performance. In this paper, we present a general
schedulability analysis framework, namely the k2U framework, that can be
potentially applied to analyze a large set of real-time task models under any
fixed-priority scheduling algorithm, on both uniprocessor and multiprocessor
scheduling. The key to k2U is a k-point effective schedulability test, which
can be viewed as a "blackbox" interface. For any task model, if a corresponding
k-point effective schedulability test can be constructed, then a sufficient
utilization-based test can be automatically derived. We show the generality of
k2U by applying it to different task models, which results in new and improved
tests compared to the state-of-the-art.
  Analogously, a similar concept by testing only k points with a different
formulation has been studied by us in another framework, called k2Q, which
provides quadratic bounds or utilization bounds based on a different
formulation of schedulability test. With the quadratic and hyperbolic forms,
k2Q and k2U frameworks can be used to provide many quantitive features to be
measured, like the total utilization bounds, speed-up factors, etc., not only
for uniprocessor scheduling but also for multiprocessor scheduling. These
frameworks can be viewed as a "blackbox" interface for schedulability tests and
response-time analysis.
</summary>
    <author>
      <name>Jian-Jia Chen</name>
    </author>
    <author>
      <name>Wen-Hung Huang</name>
    </author>
    <author>
      <name>Cong Liu</name>
    </author>
    <link href="http://arxiv.org/abs/1501.07084v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1501.07084v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.04640v2</id>
    <updated>2015-04-29T20:05:56Z</updated>
    <published>2015-04-17T21:13:07Z</published>
    <title>The Influence of Malloc Placement on TSX Hardware Transactional Memory</title>
    <summary>  The hardware transactional memory (HTM) implementation in Intel's i7-4770
"Haswell" processor tracks the transactional read-set in the L1 (level-1), L2
(level-2) and L3 (level-3) caches and the write-set in the L1 cache.
Displacement or eviction of read-set entries from the cache hierarchy or
write-set entries from the L1 results in abort. We show that the placement
policies of dynamic storage allocators -- such as those found in common
"malloc" implementations -- can influence the L1 conflict miss rate in the L1.
Conflict misses -- sometimes called mapping misses -- arise because of less
than ideal associativity and represent imbalanced distribution of active memory
blocks over the set of available L1 indices. Under transactional execution
conflict misses may manifest as aborts, representing wasted or futile effort
instead of a simple stall as would occur in normal execution mode.
  Furthermore, when HTM is used for transactional lock elision (TLE),
persistent aborts arising from conflict misses can force the offending thread
through the so-called "slow path". The slow path is undesirable as the thread
must acquire the lock and run the critical section in normal execution mode,
precluding the concurrent execution of threads in the "fast path" that monitor
that same lock and run their critical sections in transactional mode. For a
given lock, multiple threads can concurrently use the transactional fast path,
but at most one thread can use the non-transactional slow path at any given
time. Threads in the slow path preclude safe concurrent fast path execution.
Aborts rising from placement policies and L1 index imbalance can thus result in
loss of concurrency and reduced aggregate throughput.
</summary>
    <author>
      <name>Dave Dice</name>
    </author>
    <author>
      <name>Tim Harris</name>
    </author>
    <author>
      <name>Alex Kogan</name>
    </author>
    <author>
      <name>Yossi Lev</name>
    </author>
    <link href="http://arxiv.org/abs/1504.04640v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.04640v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.1.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.07481v1</id>
    <updated>2015-04-28T14:05:59Z</updated>
    <published>2015-04-28T14:05:59Z</published>
    <title>Improving Block-level Efficiency with scsi-mq</title>
    <summary>  Current generation solid-state storage devices are exposing a new bottlenecks
in the SCSI and block layers of the Linux kernel, where IO throughput is
limited by lock contention, inefficient interrupt handling, and poor memory
locality. To address these limitations, the Linux kernel block layer underwent
a major rewrite with the blk-mq project to move from a single request queue to
a multi-queue model. The Linux SCSI subsystem rework to make use of this new
model, known as scsi-mq, has been merged into the Linux kernel and work is
underway for dm-multipath support in the upcoming Linux 4.0 kernel. These
pieces were necessary to make use of the multi-queue block layer in a Lustre
parallel filesystem with high availability requirements. We undertook adding
support of the 3.18 kernel to Lustre with scsi-mq and dm-multipath patches to
evaluate the potential of these efficiency improvements. In this paper we
evaluate the block-level performance of scsi-mq with backing storage hardware
representative of a HPC-targerted Lustre filesystem. Our findings show that
SCSI write request latency is reduced by as much as 13.6%. Additionally, when
profiling the CPU usage of our prototype Lustre filesystem, we found that CPU
idle time increased by a factor of 7 with Linux 3.18 and blk-mq as compared to
a standard 2.6.32 Linux kernel. Our findings demonstrate increased efficiency
of the multi-queue block layer even with disk-based caching storage arrays used
in existing parallel filesystems.
</summary>
    <author>
      <name>Blake Caldwell</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">International Workshop on the Lustre Ecosystem: Challenges and
  Opportunities, March 2015, Annapolis MD</arxiv:comment>
    <link href="http://arxiv.org/abs/1504.07481v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.07481v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.07566v1</id>
    <updated>2015-06-24T21:14:27Z</updated>
    <published>2015-06-24T21:14:27Z</published>
    <title>Optimize Unsynchronized Garbage Collection in an SSD Array</title>
    <summary>  Solid state disks (SSDs) have advanced to outperform traditional hard drives
significantly in both random reads and writes. However, heavy random writes
trigger fre- quent garbage collection and decrease the performance of SSDs. In
an SSD array, garbage collection of individ- ual SSDs is not synchronized,
leading to underutilization of some of the SSDs.
  We propose a software solution to tackle the unsyn- chronized garbage
collection in an SSD array installed in a host bus adaptor (HBA), where
individual SSDs are exposed to an operating system. We maintain a long I/O
queue for each SSD and flush dirty pages intelligently to fill the long I/O
queues so that we hide the performance imbalance among SSDs even when there are
few parallel application writes. We further define a policy of select- ing
dirty pages to flush and a policy of taking out stale flush requests to reduce
the amount of data written to SSDs. We evaluate our solution in a real system.
Experi- ments show that our solution fully utilizes all SSDs in an array under
random write-heavy workloads. It improves I/O throughput by up to 62% under
random workloads of mixed reads and writes when SSDs are under active garbage
collection. It causes little extra data writeback and increases the cache hit
rate.
</summary>
    <author>
      <name>Da Zheng</name>
    </author>
    <author>
      <name>Randal Burns</name>
    </author>
    <author>
      <name>Alexander S. Szalay</name>
    </author>
    <link href="http://arxiv.org/abs/1506.07566v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.07566v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.02552v1</id>
    <updated>2015-10-09T02:58:40Z</updated>
    <published>2015-10-09T02:58:40Z</published>
    <title>Multitasking Programming of OBDH Satellite Based On PC-104</title>
    <summary>  On Board Data Handling (OBDH) has functions to monitor, control, acquire,
analyze, take a decision, and execute the command. OBDH should organize the
task between sub system. OBDH like a heart which has a vital function. Because
the function is seriously important therefore designing and implementing the
OBDH should be carefully, in order to have a good reliability. Many OBDHs have
been made to support the satellite mission using primitive programming. In
handling the data from various input, OBDH should always be available to all
sub systems, when the tasks are many, it is not easy to program using primitive
programming. Sometimes the data become corrupt because the data which come to
the OBDH is in the same time. Therefore it is required to have a way to handle
the data safely and also easy in programming perspective. In this research,
OBDH is programmed using multi tasking programming perspective has been
created. The Operating System (OS) has been implemented so that can run the
tasks simultaneously. The OS is prepared by configuring the Linux Kernel for
the specific processor, creating Root File System (RFS), installing the
BusyBox. In order to do the above method, preparing the environment in our
machine has been done, they are installing the Cross Tool Chain, U-Boot,
GNU-Linux Kernel Source etc. After that, programming using c code with
multitasking programming can be implemented. By using above method, it is found
that programming is easier and the corruption data because of reentrancy can be
minimized. Keywords- Operating System, PC-104, Kernel, C Programming
</summary>
    <author>
      <name>Haryono Haryono</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of advanced studies in Computer Science and
  Engineering IJASCSE Volume 4, Issue 8, 2015</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1510.02552v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.02552v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1510.05567v2</id>
    <updated>2015-11-12T12:16:11Z</updated>
    <published>2015-10-19T16:26:47Z</published>
    <title>Energy-Efficient Scheduling for Homogeneous Multiprocessor Systems</title>
    <summary>  We present a number of novel algorithms, based on mathematical optimization
formulations, in order to solve a homogeneous multiprocessor scheduling
problem, while minimizing the total energy consumption. In particular, for a
system with a discrete speed set, we propose solving a tractable linear
program. Our formulations are based on a fluid model and a global scheduling
scheme, i.e. tasks are allowed to migrate between processors. The new methods
are compared with three global energy/feasibility optimal workload allocation
formulations. Simulation results illustrate that our methods achieve both
feasibility and energy optimality and outperform existing methods for
constrained deadline tasksets. Specifically, the results provided by our
algorithm can achieve up to an 80% saving compared to an algorithm without a
frequency scaling scheme and up to 70% saving compared to a constant frequency
scaling scheme for some simulated tasksets. Another benefit is that our
algorithms can solve the scheduling problem in one step instead of using a
recursive scheme. Moreover, our formulations can solve a more general class of
scheduling problems, i.e. any periodic real-time taskset with arbitrary
deadline. Lastly, our algorithms can be applied to both online and offline
scheduling schemes.
</summary>
    <author>
      <name>Mason Thammawichai</name>
    </author>
    <author>
      <name>Eric C. Kerrigan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Corrected typos: definition of J_i in Section 2.1; (3b)-(3c);
  definition of \Phi_A and \Phi_D in paragraph after (6b). Previous equations
  were correct only for special case of p_i=d_i</arxiv:comment>
    <link href="http://arxiv.org/abs/1510.05567v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1510.05567v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1512.07654v3</id>
    <updated>2016-03-12T18:13:31Z</updated>
    <published>2015-12-23T22:41:04Z</published>
    <title>Mixed-Criticality Scheduling with I/O</title>
    <summary>  This paper addresses the problem of scheduling tasks with different
criticality levels in the presence of I/O requests. In mixed-criticality
scheduling, higher criticality tasks are given precedence over those of lower
criticality when it is impossible to guarantee the schedulability of all tasks.
While mixed-criticality scheduling has gained attention in recent years, most
approaches typically assume a periodic task model. This assumption does not
always hold in practice, especially for real-time and embedded systems that
perform I/O. For example, many tasks block on I/O requests until devices signal
their completion via interrupts; both the arrival of interrupts and the waking
of blocked tasks can be aperiodic. In our prior work, we developed a scheduling
technique in the Quest real-time operating system, which integrates the
time-budgeted management of I/O operations with Sporadic Server scheduling of
tasks. This paper extends our previous scheduling approach with support for
mixed-criticality tasks and I/O requests on the same processing core. Results
show the effective schedulability of different task sets in the presence of I/O
requests is superior in our approach compared to traditional methods that
manage I/O using techniques such as Sporadic Servers.
</summary>
    <author>
      <name>Eric Missimer</name>
    </author>
    <author>
      <name>Katherine Zhao</name>
    </author>
    <author>
      <name>Richard West</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Second version has replaced simulation experiments with real machine
  experiments, third version fixed minor error in Equation 5 (missing a plus
  sign)</arxiv:comment>
    <link href="http://arxiv.org/abs/1512.07654v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1512.07654v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.01378v4</id>
    <updated>2017-07-31T02:13:45Z</updated>
    <published>2016-04-05T19:33:27Z</published>
    <title>Isolate First, Then Share: a New OS Architecture for Datacenter
  Computing</title>
    <summary>  Modern datacenter (DC) workloads are characterized by increasing diversity
and differentiated QoS requirements in terms of the average or worst-case
performance. The shift towards DC calls for the new OS architectures that not
only gracefully achieve disparate performance goals, but also protect software
investments. This paper presents the "isolate first, then share" OS
architecture. We decompose the OS into the supervisor and several subOSes
running side by side: a subOS directly manages physical resources without
intervention from the supervisor (isolate resources first), while the
supervisor can create, destroy, resize a subOS on-the-fly (then share). We
confine state sharing among the supervisor and SubOSes (isolate states first),
and provide fast inter-subOS communication mechanisms on demand (then share).
We present the first implementation--RainForest, which supports unmodified
Linux binaries. Our comprehensive evaluations show RainForest outperforms Linux
with three different kernels, LXC, and Xen in terms of improving resource
utilization, throughput, scalability, and worst-case performance. The
RainForest source code is soon available.
</summary>
    <author>
      <name>Gang Lu</name>
    </author>
    <author>
      <name>Jianfeng Zhan</name>
    </author>
    <author>
      <name>Chongkang Tan</name>
    </author>
    <author>
      <name>Xinlong Lin</name>
    </author>
    <author>
      <name>Defei Kong</name>
    </author>
    <author>
      <name>Tianshu Hao</name>
    </author>
    <author>
      <name>Lei Wang</name>
    </author>
    <author>
      <name>Fei Tang</name>
    </author>
    <author>
      <name>Chen Zheng</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 13 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1604.01378v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.01378v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.4.0; D.4.6; D.4.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.02171v1</id>
    <updated>2016-04-07T20:38:51Z</updated>
    <published>2016-04-07T20:38:51Z</published>
    <title>Aware: Controlling App Access to I/O Devices on Mobile Platforms</title>
    <summary>  Smartphones' cameras, microphones, and device displays enable users to
capture and view memorable moments of their lives. However, adversaries can
trick users into authorizing malicious apps that exploit weaknesses in current
mobile platforms to misuse such on-board I/O devices to stealthily capture
photos, videos, and screen content without the users' consent. Contemporary
mobile operating systems fail to prevent such misuse of I/O devices by
authorized apps due to lack of binding between users' interactions and accesses
to I/O devices performed by these apps. In this paper, we propose Aware, a
security framework for authorizing app requests to perform operations using I/O
devices, which binds app requests with user intentions to make all uses of
certain I/O devices explicit. We evaluate our defense mechanisms through
laboratory-based experimentation and a user study, involving 74 human subjects,
whose ability to identify undesired operations targeting I/O devices increased
significantly. Without Aware, only 18% of the participants were able to
identify attacks from tested RAT apps. Aware systematically blocks all the
attacks in absence of user consent and supports users in identifying 82% of
social-engineering attacks tested to hijack approved requests, including some
more sophisticated forms of social engineering not yet present in available
RATs. Aware introduces only 4.79% maximum performance overhead over operations
targeting I/O devices. Aware shows that a combination of system defenses and
user interface can significantly strengthen defenses for controlling the use of
on-board I/O devices.
</summary>
    <author>
      <name>Giuseppe Petracca</name>
    </author>
    <author>
      <name>Ahmad Atamli</name>
    </author>
    <author>
      <name>Yuqiong Sun</name>
    </author>
    <author>
      <name>Jens Grossklags</name>
    </author>
    <author>
      <name>Trent Jaeger</name>
    </author>
    <link href="http://arxiv.org/abs/1604.02171v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.02171v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1610.08129v1</id>
    <updated>2016-10-26T00:37:34Z</updated>
    <published>2016-10-26T00:37:34Z</published>
    <title>Memshare: a Dynamic Multi-tenant Memory Key-value Cache</title>
    <summary>  Web application performance is heavily reliant on the hit rate of
memory-based caches. Current DRAM-based web caches statically partition their
memory across multiple applications sharing the cache. This causes under
utilization of memory which negatively impacts cache hit rates. We present
Memshare, a novel web memory cache that dynamically manages memory across
applications. Memshare provides a resource sharing model that guarantees
private memory to different applications while dynamically allocating the
remaining shared memory to optimize overall hit rate. Today's high cost of DRAM
storage and the availability of high performance CPU and memory bandwidth, make
web caches memory capacity bound. Memshare's log-structured design allows it to
provide significantly higher hit rates and dynamically partition memory among
applications at the expense of increased CPU and memory bandwidth consumption.
In addition, Memshare allows applications to use their own eviction policy for
their objects, independent of other applications. We implemented Memshare and
ran it on a week-long trace from a commercial memcached provider. We
demonstrate that Memshare increases the combined hit rate of the applications
in the trace by an 6.1% (from 84.7% hit rate to 90.8% hit rate) and reduces the
total number of misses by 39.7% without affecting system throughput or latency.
Even for single-tenant applications, Memshare increases the average hit rate of
the current state-of-the-art memory cache by an additional 2.7% on our
real-world trace.
</summary>
    <author>
      <name>Asaf Cidon</name>
    </author>
    <author>
      <name>Daniel Rushton</name>
    </author>
    <author>
      <name>Stephen M. Rumble</name>
    </author>
    <author>
      <name>Ryan Stutsman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 5 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1610.08129v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1610.08129v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1611.07862v1</id>
    <updated>2016-11-23T16:23:40Z</updated>
    <published>2016-11-23T16:23:40Z</published>
    <title>Browsix: Bridging the Gap Between Unix and the Browser</title>
    <summary>  Applications written to run on conventional operating systems typically
depend on OS abstractions like processes, pipes, signals, sockets, and a shared
file system. Porting these applications to the web currently requires extensive
rewriting or hosting significant portions of code server-side because browsers
present a nontraditional runtime environment that lacks OS functionality.
  This paper presents Browsix, a framework that bridges the considerable gap
between conventional operating systems and the browser, enabling unmodified
programs expecting a Unix-like environment to run directly in the browser.
Browsix comprises two core parts: (1) a JavaScript-only system that makes core
Unix features (including pipes, concurrent processes, signals, sockets, and a
shared file system) available to web applications; and (2) extended JavaScript
runtimes for C, C++, Go, and Node.js that support running programs written in
these languages as processes in the browser. Browsix supports running a POSIX
shell, making it straightforward to connect applications together via pipes.
  We illustrate Browsix's capabilities via case studies that demonstrate how it
eases porting legacy applications to the browser and enables new functionality.
We demonstrate a Browsix-enabled LaTeX editor that operates by executing
unmodified versions of pdfLaTeX and BibTeX. This browser-only LaTeX editor can
render documents in seconds, making it fast enough to be practical. We further
demonstrate how Browsix lets us port a client-server application to run
entirely in the browser for disconnected operation. Creating these applications
required less than 50 lines of glue code and no code modifications,
demonstrating how easily Browsix can be used to build sophisticated web
applications from existing parts without modification.
</summary>
    <author>
      <name>Bobby Powers</name>
    </author>
    <author>
      <name>John Vilk</name>
    </author>
    <author>
      <name>Emery D. Berger</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">to appear at ASPLOS 2017</arxiv:comment>
    <link href="http://arxiv.org/abs/1611.07862v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1611.07862v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1702.02588v1</id>
    <updated>2017-02-08T19:21:13Z</updated>
    <published>2017-02-08T19:21:13Z</published>
    <title>Flashield: a Key-value Cache that Minimizes Writes to Flash</title>
    <summary>  As its price per bit drops, SSD is increasingly becoming the default storage
medium for cloud application databases. However, it has not become the
preferred storage medium for key-value caches, even though SSD offers more than
10x lower price per bit and sufficient performance compared to DRAM. This is
because key-value caches need to frequently insert, update and evict small
objects. This causes excessive writes and erasures on flash storage, since
flash only supports writes and erasures of large chunks of data. These
excessive writes and erasures significantly shorten the lifetime of flash,
rendering it impractical to use for key-value caches. We present Flashield, a
hybrid key-value cache that uses DRAM as a "filter" to minimize writes to SSD.
Flashield performs light-weight machine learning profiling to predict which
objects are likely to be read frequently before getting updated; these objects,
which are prime candidates to be stored on SSD, are written to SSD in large
chunks sequentially. In order to efficiently utilize the cache's available
memory, we design a novel in-memory index for the variable-sized objects stored
on flash that requires only 4 bytes per object in DRAM. We describe Flashield's
design and implementation and, we evaluate it on a real-world cache trace.
Compared to state-of-the-art systems that suffer a write amplification of 2.5x
or more, Flashield maintains a median write amplification of 0.5x without any
loss of hit rate or throughput.
</summary>
    <author>
      <name>Assaf Eisenman</name>
    </author>
    <author>
      <name>Asaf Cidon</name>
    </author>
    <author>
      <name>Evgenya Pergament</name>
    </author>
    <author>
      <name>Or Haimovich</name>
    </author>
    <author>
      <name>Ryan Stutsman</name>
    </author>
    <author>
      <name>Mohammad Alizadeh</name>
    </author>
    <author>
      <name>Sachin Katti</name>
    </author>
    <link href="http://arxiv.org/abs/1702.02588v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1702.02588v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1704.08876v1</id>
    <updated>2017-04-28T11:17:51Z</updated>
    <published>2017-04-28T11:17:51Z</published>
    <title>Mixed-criticality Scheduling with Dynamic Redistribution of Shared Cache</title>
    <summary>  The design of mixed-criticality systems often involvespainful tradeoffs
between safety guarantees and performance.However, the use of more detailed
architectural modelsin the design and analysis of scheduling arrangements for
mixedcriticalitysystems can provide greater confidence in the analysis,but also
opportunities for better performance. Motivated by thisview, we propose an
extension of Vestal 19s model for mixedcriticalitymulticore systems that (i)
accounts for the per-taskpartitioning of the last-level cache and (ii) supports
the dynamicreassignment, for better schedulability, of cache portions
initiallyreserved for lower-criticality tasks to the higher-criticalitytasks,
when the system switches to high-criticality mode. Tothis model, we apply
partitioned EDF scheduling with Ekbergand Yi 19s deadline-scaling technique.
Our schedulability analysisand scalefactor calculation is cognisant of the
cache resourcesassigned to each task, by using WCET estimates that take
intoaccount these resources. It is hence able to leverage the
dynamicreconfiguration of the cache partitioning, at mode change, forbetter
performance, in terms of provable schedulability. We alsopropose heuristics for
partitioning the cache in low- and highcriticalitymode, that promote
schedulability. Our experimentswith synthetic task sets, indicate tangible
improvements inschedulability compared to a baseline cache-aware
arrangementwhere there is no redistribution of cache resources from low-
tohigh-criticality tasks in the event of a mode change.
</summary>
    <author>
      <name>Muhammad Ali Awan</name>
    </author>
    <author>
      <name>Konstantinos Bletsas</name>
    </author>
    <author>
      <name>Pedro F. Souto</name>
    </author>
    <author>
      <name>Benny Akesson</name>
    </author>
    <author>
      <name>Eduardo Tovar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ECRTS 2017, 26 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1704.08876v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1704.08876v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.03591v1</id>
    <updated>2017-05-10T02:30:06Z</updated>
    <published>2017-05-10T02:30:06Z</published>
    <title>IOTune: A G-states Driver for Elastic Performance of Block Storage</title>
    <summary>  Imagining a disk which provides baseline performance at a relatively low
price during low-load periods, but when workloads demand more resources, the
disk performance is automatically promoted in situ and in real time. In a
hardware era, this is hardly achievable. However, this imagined disk is
becoming reality due to the technical advances of software-defined storage,
which enable volume performance to be adjusted on the fly. We propose IOTune, a
resource management middleware which employs software-defined storage
primitives to implement G-states of virtual block devices. G-states enable
virtual block devices to serve at multiple performance gears, getting rid of
conflicts between immutable resource reservation and dynamic resource demands,
and always achieving resource right-provisioning for workloads. Accompanying
G-states, we also propose a new block storage pricing policy for cloud
providers. Our case study for applying G-states to cloud block storage verifies
the effectiveness of the IOTune framework. Trace-replay based evaluations
demonstrate that storage volumes with G-states adapt to workload fluctuations.
For tenants, G-states enable volumes to provide much better QoS with a same
cost of ownership, comparing with static IOPS provisioning and the I/O credit
mechanism. G-states also reduce I/O tail latencies by one to two orders of
magnitude. From the standpoint of cloud providers, G-states promote storage
utilization, creating values and benefiting competitiveness. G-states supported
by IOTune provide a new paradigm for storage resource management and pricing in
multi-tenant clouds.
</summary>
    <author>
      <name>Tao Lu</name>
    </author>
    <author>
      <name>Ping Huang</name>
    </author>
    <author>
      <name>Xubin He</name>
    </author>
    <author>
      <name>Matthew Welch</name>
    </author>
    <author>
      <name>Steven Gonzales</name>
    </author>
    <author>
      <name>Ming Zhang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 10 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1705.03591v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.03591v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.4.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.06965v2</id>
    <updated>2017-05-24T20:48:00Z</updated>
    <published>2017-05-19T12:48:50Z</published>
    <title>GPU System Calls</title>
    <summary>  GPUs are becoming first-class compute citizens and are being tasked to
perform increasingly complex work. Modern GPUs increasingly support
programmability- enhancing features such as shared virtual memory and hardware
cache coherence, enabling them to run a wider variety of programs. But a key
aspect of general-purpose programming where GPUs are still found lacking is the
ability to invoke system calls. We explore how to directly invoke generic
system calls in GPU programs. We examine how system calls should be meshed with
prevailing GPGPU programming models where thousands of threads are organized in
a hierarchy of execution groups: Should a system call be invoked at the
individual GPU task, or at different execution group levels? What are
reasonable ordering semantics for GPU system calls across these hierarchy of
execution groups? To study these questions, we implemented GENESYS -- a
mechanism to allow GPU pro- grams to invoke system calls in the Linux operating
system. Numerous subtle changes to Linux were necessary, as the existing kernel
assumes that only CPUs invoke system calls. We analyze the performance of
GENESYS using micro-benchmarks and three applications that exercise the
filesystem, networking, and memory allocation subsystems of the kernel. We
conclude by analyzing the suitability of all of Linux's system calls for the
GPU.
</summary>
    <author>
      <name>Ján Veselý</name>
    </author>
    <author>
      <name>Arkaprava Basu</name>
    </author>
    <author>
      <name>Abhishek Bhattacharjee</name>
    </author>
    <author>
      <name>Gabriel Loh</name>
    </author>
    <author>
      <name>Mark Oskin</name>
    </author>
    <author>
      <name>Steven K. Reinhardt</name>
    </author>
    <link href="http://arxiv.org/abs/1705.06965v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.06965v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.4.4; D.4.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.07161v1</id>
    <updated>2017-07-22T13:29:01Z</updated>
    <published>2017-07-22T13:29:01Z</published>
    <title>Optimizations of Management Algorithms for Multi-Level Memory Hierarchy</title>
    <summary>  In the near future the SCM is predicted to modify the form of new programs,
the access form to storage, and the way that storage devices themselves are
built. Therefore, a combination between the SCM and a designated Memory
Allocation Manager (MAM) that will allow the programmer to manually control the
different memories in the memory hierarchy will be likely to achieve a new
level of performance for memory-aware data structures. Although the manual MAM
seems to be the optimal approach for multi-level memory hierarchy management,
this technique is still very far from being realistic, and the chances that it
would be implemented in current codes using High Performance Computing (HPC)
platforms is quite low. This premise means that the most reasonable way to
introduce the SCM into any usable and popular memory system would be by
implementing an automated version of the MAM using the fundamentals of paging
algorithms, as used for two-level memory hierarchy. Our hypothesis is that
achieving appropriate transferability between memory levels may be possible
using ideas of algorithms employed in current virtual memory systems, and that
the adaptation of those algorithms from a two-level memory hierarchy to an
N-level memory hierarchy is possible. In order to reach the conclusion that our
hypothesis is correct, we investigated various paging algorithms, and found the
ones that could be adapted successfully from two-level memory hierarchy to an
N-level memory hierarchy. We discovered that using an adaptation of the Aging
paging algorithm to an N-level memory hierarchy results in the best
performances in terms of Hit/Miss ratio. In order to verify our hypothesis we
build a simulator called "DeMemory simulator" for analyzing our algorithms as
well as for other algorithms that will be devised in the future.
</summary>
    <author>
      <name>Gal Oren</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Master's Thesis, Diss. The Open University (2015)</arxiv:comment>
    <link href="http://arxiv.org/abs/1707.07161v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.07161v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.00897v1</id>
    <updated>2017-03-02T18:52:45Z</updated>
    <published>2017-03-02T18:52:45Z</published>
    <title>Adapting the DMTCP Plugin Model for Checkpointing of Hardware Emulation</title>
    <summary>  Checkpoint-restart is now a mature technology. It allows a user to save and
later restore the state of a running process. The new plugin model for the
upcoming version 3.0 of DMTCP (Distributed MultiThreaded Checkpointing) is
described here. This plugin model allows a target application to disconnect
from the hardware emulator at checkpoint time and then re-connect to a possibly
different hardware emulator at the time of restart. The DMTCP plugin model is
important in allowing three distinct parties to seamlessly inter-operate. The
three parties are: the EDA designer, who is concerned with formal verification
of a circuit design; the DMTCP developers, who are concerned with providing
transparent checkpointing during the circuit emulation; and the hardware
emulator vendor, who provides a plugin library that responds to checkpoint,
restart, and other events.
  The new plugin model is an example of process-level virtualization:
virtualization of external abstractions from within a process. This capability
is motivated by scenarios for testing circuit models with the help of a
hardware emulator. The plugin model enables a three-way collaboration: allowing
a circuit designer and emulator vendor to each contribute separate proprietary
plugins while sharing an open source software framework from the DMTCP
developers. This provides a more flexible platform, where different fault
injection models based on plugins can be designed within the DMTCP
checkpointing framework. After initialization, one restarts from a checkpointed
state under the control of the desired plugin. This restart saves the time
spent in simulating the initialization phase, while enabling fault injection
exactly at the region of interest. Upon restart, one can inject faults or
otherwise modify the remainder of the simulation. The work concludes with a
brief survey of checkpointing and process-level virtualization.
</summary>
    <author>
      <name>Rohan Garg</name>
    </author>
    <author>
      <name>Kapil Arya</name>
    </author>
    <author>
      <name>Jiajun Cao</name>
    </author>
    <author>
      <name>Gene Cooperman</name>
    </author>
    <author>
      <name>Jeff Evans</name>
    </author>
    <author>
      <name>Ankit Garg</name>
    </author>
    <author>
      <name>Neil A. Rosenberg</name>
    </author>
    <author>
      <name>K. Suresh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 11 figure, 1 listing; SELSE '17, March 21--22, 2017, Boston,
  MA, USA</arxiv:comment>
    <link href="http://arxiv.org/abs/1703.00897v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.00897v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="B.6.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.09701v1</id>
    <updated>2017-05-26T20:03:18Z</updated>
    <published>2017-05-26T20:03:18Z</published>
    <title>SMORE: A Cold Data Object Store for SMR Drives (Extended Version)</title>
    <summary>  Shingled magnetic recording (SMR) increases the capacity of magnetic hard
drives, but it requires that each zone of a disk be written sequentially and
erased in bulk. This makes SMR a good fit for workloads dominated by large data
objects with limited churn. To explore this possibility, we have developed
SMORE, an object storage system designed to reliably and efficiently store
large, seldom-changing data objects on an array of host-managed or host-aware
SMR disks.
  SMORE uses a log-structured approach to accommodate the constraint that all
writes to an SMR drive must be sequential within large shingled zones. It
stripes data across zones on separate disks, using erasure coding to protect
against drive failure. A separate garbage collection thread reclaims space by
migrating live data out of the emptiest zones so that they can be trimmed and
reused. An index stored on flash and backed up to the SMR drives maps object
identifiers to on-disk locations. SMORE interleaves log records with object
data within SMR zones to enable index recovery after a system crash (or failure
of the flash device) without any additional logging mechanism.
  SMORE achieves full disk bandwidth when ingesting data---with a variety of
object sizes---and when reading large objects. Read performance declines for
smaller object sizes where inter- object seek time dominates. With a worst-case
pattern of random deletions, SMORE has a write amplification (not counting RAID
parity) of less than 2.0 at 80% occupancy. By taking an index snapshot every
two hours, SMORE recovers from crashes in less than a minute. More frequent
snapshots allow faster recovery.
</summary>
    <author>
      <name>Peter Macko</name>
    </author>
    <author>
      <name>Xiongzi Ge</name>
    </author>
    <author>
      <name>John Haskins Jr.</name>
    </author>
    <author>
      <name>James Kelley</name>
    </author>
    <author>
      <name>David Slik</name>
    </author>
    <author>
      <name>Keith A. Smith</name>
    </author>
    <author>
      <name>Maxim G. Smith</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 8 figures, full version of 6 page paper published at MSST
  2017</arxiv:comment>
    <link href="http://arxiv.org/abs/1705.09701v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.09701v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9903004v4</id>
    <updated>1999-04-01T00:41:47Z</updated>
    <published>1999-03-04T02:13:35Z</published>
    <title>A Flit Level Simulator for Wormhole Routing</title>
    <summary>  Wormhole routing, the latest switching technique to be utilized by massively
parallel computers, enjoys the distinct advantage of a low latency when
compared to other switching techniques. This low latency is due to the nearly
distance insensitive routing traits in the absence of channel contention. The
low latency of wormhole routing brings about a liability of this switching
technique, a chance of deadlock. Deadlock is a concern in wormhole routed
networks due to the fact a message does not release its allocated resources
until all flits of a message have completely traversed the router in which
these resources are associated. The deadlock condition is addressed in the
routing algorithm. Simulation tools are currently needed that will aid in the
size and number of resources necessary to obtain the optimum utilization of
network resources for an algorithm. Some of these resources include the
topology of the network along with the number of nodes for the topology, the
size of the message, and the number and size of buffers at each router.
</summary>
    <author>
      <name>Denvil Smith</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Complete Thesis 359 pages, 32 tables, 70 figures, HTML (add GIF
  files)</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/9903004v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9903004v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="B.4.4; C.2.6; D.4.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9904020v1</id>
    <updated>1999-04-26T21:13:00Z</updated>
    <published>1999-04-26T21:13:00Z</published>
    <title>ODP channel objects that provide services transparently for distributing
  processing systems</title>
    <summary>  This paper describes an architecture for a distributing processing system
that would allow remote procedure calls to invoke other services as messages
are passed between clients and servers. It proposes that an additional class of
data processing objects be located in the software communications channel. The
objects in this channel would then be used to enforce protocols on
client-server applications without any additional effort by the application
programmers. For example, services such as key-management, time-stamping,
sequencing and encryption can be implemented at different levels of the
software communications stack to provide a complete authentication service. A
distributing processing environment could be used to control broadband network
data delivery. Architectures and invocation semantics are discussed, Example
classes and interfaces for channel objects are given in the Java programming
language.
</summary>
    <author>
      <name>Walter Eaves</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">35 pages, 10 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/9904020v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9904020v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="C.2.0; C.2.4; D.4.7; H.5.1; K.6.4; D.4.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9905002v1</id>
    <updated>1999-05-05T01:43:13Z</updated>
    <published>1999-05-05T01:43:13Z</published>
    <title>DRAFT : Task System and Item Architecture (TSIA)</title>
    <summary>  During its execution, a task is independent of all other tasks. For an
application which executes in terms of tasks, the application definition can be
free of the details of the execution. Many projects have demonstrated that a
task system (TS) can provide such an application with a parallel, distributed,
heterogeneous, adaptive, dynamic, real-time, interactive, reliable, secure or
other execution. A task consists of items and thus the application is defined
in terms of items. An item architecture (IA) can support arrays, routines and
other structures of items, thus allowing for a structured application
definition. Taking properties from many projects, the support can extend
through to currying, application defined types, conditional items, streams and
other definition elements. A task system and item architecture (TSIA) thus
promises unprecedented levels of support for application execution and
definition.
</summary>
    <author>
      <name>Burkhard D. Burow</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">vii+244 pages, including 126 figures of diagrams and code examples.
  Submitted to Springer Verlag. For further information see http://www.tsia.org</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/9905002v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9905002v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="A.1;D.1.1;D.1.3;D.1.4;D.2.3;D.2.11;D.3.2;D.3.3;D.3.4;D.4.1;D.4.5;&#10;  D.4.7;E.1;F.1.2;F.3.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0006015v2</id>
    <updated>2000-06-13T22:07:28Z</updated>
    <published>2000-06-08T17:02:51Z</published>
    <title>UNIX Resource Managers: Capacity Planning and Resource Issues</title>
    <summary>  The latest implementations of commercial UNIX to offer mainframe style
capacity management on enterprise servers include: AIX Workload Manager (WLM),
HP-UX Process Resource Manager (PRM), Solaris Resource Manager (SRM), as well
as SGI and Compaq. The ability to manage server capacity is achieved by making
significant modifications to the standard UNIX operating system so that
processes are inherently tied to specific users. Those users, in turn, are
granted only a certain fraction of system resources. Resource usage is
monitored and compared with each users grant to ensure that the assigned
entitlement constraints are met. In this paper, we begin by clearing up some of
the confusion that has surrounded the motivation and the terminology behind the
new technology. The common theme across each of the commercial implementations
is the introduction of the fair-share scheduler. After reviewing some potential
performance pitfalls, we present capacity planning guidelines for migrating to
automated UNIX resource management.
</summary>
    <author>
      <name>Neil J. Gunther</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages. Fixed formatting problem. To be presented at the SAGE-AU
  Conference, Bond University, Gold Coast, Australia, July 7, 2000</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0006015v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0006015v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="C.4;D.4.1;D.4.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0104012v1</id>
    <updated>2001-04-07T17:17:14Z</updated>
    <published>2001-04-07T17:17:14Z</published>
    <title>System Support for Bandwidth Management and Content Adaptation in
  Internet Applications</title>
    <summary>  This paper describes the implementation and evaluation of an operating system
module, the Congestion Manager (CM), which provides integrated network flow
management and exports a convenient programming interface that allows
applications to be notified of, and adapt to, changing network conditions. We
describe the API by which applications interface with the CM, and the
architectural considerations that factored into the design. To evaluate the
architecture and API, we describe our implementations of TCP; a streaming
layered audio/video application; and an interactive audio application using the
CM, and show that they achieve adaptive behavior without incurring much
end-system overhead. All flows including TCP benefit from the sharing of
congestion information, and applications are able to incorporate new
functionality such as congestion control and adaptive behavior.
</summary>
    <author>
      <name>David G. Andersen</name>
    </author>
    <author>
      <name>Deepak Bansal</name>
    </author>
    <author>
      <name>Dorothy Curtis</name>
    </author>
    <author>
      <name>Srinivasan Seshan</name>
    </author>
    <author>
      <name>Hari Balakrishnan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, appeared in OSDI 2000</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. OSDI 2000</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0104012v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0104012v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.4.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0412038v1</id>
    <updated>2004-12-09T01:20:39Z</updated>
    <published>2004-12-09T01:20:39Z</published>
    <title>Tycoon: an Implementation of a Distributed, Market-based Resource
  Allocation System</title>
    <summary>  Distributed clusters like the Grid and PlanetLab enable the same statistical
multiplexing efficiency gains for computing as the Internet provides for
networking. One major challenge is allocating resources in an economically
efficient and low-latency way. A common solution is proportional share, where
users each get resources in proportion to their pre-defined weight. However,
this does not allow users to differentiate the value of their jobs. This leads
to economic inefficiency. In contrast, systems that require reservations impose
a high latency (typically minutes to hours) to acquire resources.
  We present Tycoon, a market based distributed resource allocation system
based on proportional share. The key advantages of Tycoon are that it allows
users to differentiate the value of their jobs, its resource acquisition
latency is limited only by communication delays, and it imposes no manual
bidding overhead on users. We present experimental results using a prototype
implementation of our design.
</summary>
    <author>
      <name>Kevin Lai</name>
    </author>
    <author>
      <name>Lars Rasmusson</name>
    </author>
    <author>
      <name>Eytan Adar</name>
    </author>
    <author>
      <name>Stephen Sorkin</name>
    </author>
    <author>
      <name>Li Zhang</name>
    </author>
    <author>
      <name>Bernardo A. Huberman</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0412038v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0412038v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="C.2.4; D.4.1; K.6.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0412074v1</id>
    <updated>2004-12-17T15:38:19Z</updated>
    <published>2004-12-17T15:38:19Z</published>
    <title>Threats of Human Error in a High-Performance Storage System: Problem
  Statement and Case Study</title>
    <summary>  System administration is a difficult, often tedious, job requiring many
skilled laborers. The data that is protected by system administrators is often
valued at or above the value of the institution maintaining that data. A number
of ethnographic studies have confirmed the skill of these operators, and the
difficulty of providing adequate tools. In an effort to minimize the
maintenance costs, an increasing portion of system administration is subject to
automation - particularly simple, routine tasks such as data backup. While such
tools reduce the risk of errors from carelessness, the same tools may result in
reduced skill and system familiarity in experienced workers. Care should be
taken to ensure that operators maintain system awareness without placing the
operator in a passive, monitoring role.
</summary>
    <author>
      <name>Elizabeth Haubert</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0412074v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0412074v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="H.1.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0502090v1</id>
    <updated>2005-02-24T14:13:56Z</updated>
    <published>2005-02-24T14:13:56Z</published>
    <title>UNICORE - From Project Results to Production Grids</title>
    <summary>  The UNICORE Grid-technology provides a seamless, secure and intuitive access
to distributed Grid resources. In this paper we present the recent evolution
from project results to production Grids. At the beginning UNICORE was
developed as a prototype software in two projects funded by the German research
ministry (BMBF). Over the following years, in various European-funded projects,
UNICORE evolved to a full-grown and well-tested Grid middleware system, which
today is used in daily production at many supercomputing centers worldwide.
Beyond this production usage, the UNICORE technology serves as a solid basis in
many European and International research projects, which use existing UNICORE
components to implement advanced features, high level services, and support for
applications from a growing range of domains. In order to foster these ongoing
developments, UNICORE is available as open source under BSD licence at
SourceForge, where new releases are published on a regular basis. This paper is
a review of the UNICORE achievements so far and gives a glimpse on the UNICORE
roadmap.
</summary>
    <author>
      <name>A. Streit</name>
    </author>
    <author>
      <name>D. Erwin</name>
    </author>
    <author>
      <name>Th. Lippert</name>
    </author>
    <author>
      <name>D. Mallmann</name>
    </author>
    <author>
      <name>R. Menday</name>
    </author>
    <author>
      <name>M. Rambadt</name>
    </author>
    <author>
      <name>M. Riedel</name>
    </author>
    <author>
      <name>M. Romberg</name>
    </author>
    <author>
      <name>B. Schuller</name>
    </author>
    <author>
      <name>Ph. Wieder</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">21 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0502090v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0502090v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0503074v1</id>
    <updated>2005-03-28T15:32:43Z</updated>
    <published>2005-03-28T15:32:43Z</published>
    <title>A File System Abstraction for Sense and Respond Systems</title>
    <summary>  The heterogeneity and resource constraints of sense-and-respond systems pose
significant challenges to system and application development. In this paper, we
present a flexible, intuitive file system abstraction for organizing and
managing sense-and-respond systems based on the Plan 9 design principles. A key
feature of this abstraction is the ability to support multiple views of the
system via filesystem namespaces. Constructed logical views present an
application-specific representation of the network, thus enabling high-level
programming of the network. Concurrently, structural views of the network
enable resource-efficient planning and execution of tasks. We present and
motivate the design using several examples, outline research challenges and our
research plan to address them, and describe the current state of
implementation.
</summary>
    <author>
      <name>Sameer Tilak</name>
    </author>
    <author>
      <name>Bhanu Pisupati</name>
    </author>
    <author>
      <name>Kenneth Chiu</name>
    </author>
    <author>
      <name>Geoffrey Brown</name>
    </author>
    <author>
      <name>Nael Abu-Ghazaleh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 3 figures Workshop on End-to-End, Sense-and-Respond Systems,
  Applications, and Services In conjunction with MobiSys '05</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0503074v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0503074v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.4.3 Distributed file systems; C.2.1 Wireless communication" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0508130v1</id>
    <updated>2005-08-31T01:44:35Z</updated>
    <published>2005-08-31T01:44:35Z</published>
    <title>A Fresh Look at the Reliability of Long-term Digital Storage</title>
    <summary>  Many emerging Web services, such as email, photo sharing, and web site
archives, need to preserve large amounts of quickly-accessible data
indefinitely into the future. In this paper, we make the case that these
applications' demands on large scale storage systems over long time horizons
require us to re-evaluate traditional storage system designs. We examine
threats to long-lived data from an end-to-end perspective, taking into account
not just hardware and software faults but also faults due to humans and
organizations. We present a simple model of long-term storage failures that
helps us reason about the various strategies for addressing these threats in a
cost-effective manner. Using this model we show that the most important
strategies for increasing the reliability of long-term storage are detecting
latent faults quickly, automating fault repair to make it faster and cheaper,
and increasing the independence of data replicas.
</summary>
    <author>
      <name>Mary Baker</name>
    </author>
    <author>
      <name>Mehul Shah</name>
    </author>
    <author>
      <name>David S. H. Rosenthal</name>
    </author>
    <author>
      <name>Mema Roussopoulos</name>
    </author>
    <author>
      <name>Petros Maniatis</name>
    </author>
    <author>
      <name>TJ Giuli</name>
    </author>
    <author>
      <name>Prashanth Bungale</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0508130v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0508130v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0603021v1</id>
    <updated>2006-03-06T00:46:09Z</updated>
    <published>2006-03-06T00:46:09Z</published>
    <title>Language Support for Optional Functionality</title>
    <summary>  We recommend a programming construct - availability check - for programs that
need to automatically adjust to presence or absence of segments of code. The
idea is to check the existence of a valid definition before a function call is
invoked. The syntax is that of a simple 'if' statement. The vision is to enable
customization of application functionality through addition or removal of
optional components, but without requiring complete re-building. Focus is on
C-like compiled procedural languages and UNIX-based systems. Essentially, our
approach attempts to combine the flexibility of dynamic libraries with the
usability of utility (dependency) libraries. We outline the benefits over
prevalent strategies mainly in terms of development complexity, crudely
measured as lesser lines of code. We also allude to performance and flexibility
facets. A Preliminary implementation and figures from early experimental
evaluation are presented.
</summary>
    <author>
      <name>Joy Mukherjee</name>
    </author>
    <author>
      <name>Srinidhi Varadarajan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 8 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0603021v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0603021v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0603075v1</id>
    <updated>2006-03-18T17:11:04Z</updated>
    <published>2006-03-18T17:11:04Z</published>
    <title>Unmanaged Internet Protocol: Taming the Edge Network Management Crisis</title>
    <summary>  Though appropriate for core Internet infrastructure, the Internet Protocol is
unsuited to routing within and between emerging ad-hoc edge networks due to its
dependence on hierarchical, administratively assigned addresses. Existing
ad-hoc routing protocols address the management problem but do not scale to
Internet-wide networks. The promise of ubiquitous network computing cannot be
fulfilled until we develop an Unmanaged Internet Protocol (UIP), a scalable
routing protocol that manages itself automatically. UIP must route within and
between constantly changing edge networks potentially containing millions or
billions of nodes, and must still function within edge networks disconnected
from the main Internet, all without imposing the administrative burden of
hierarchical address assignment. Such a protocol appears challenging but
feasible. We propose an architecture based on self-certifying, cryptographic
node identities and a routing algorithm adapted from distributed hash tables.
</summary>
    <author>
      <name>Bryan Ford</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 3 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Second Workshop on Hot Topics in Networks (HotNets-II), November
  2003, Cambridge, MA</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0603075v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0603075v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="C.2.1; C.2.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0607049v2</id>
    <updated>2006-08-01T07:04:20Z</updated>
    <published>2006-07-11T18:54:21Z</published>
    <title>Secure Component Deployment in the OSGi(tm) Release 4 Platform</title>
    <summary>  Last years have seen a dramatic increase in the use of component platforms,
not only in classical application servers, but also more and more in the domain
of Embedded Systems. The OSGi(tm) platform is one of these platforms dedicated
to lightweight execution environments, and one of the most prominent. However,
new platforms also imply new security flaws, and a lack of both knowledge and
tools for protecting the exposed systems. This technical report aims at
fostering the understanding of security mechanisms in component deployment. It
focuses on securing the deployment of components. It presents the cryptographic
mechanisms necessary for signing OSGi(tm) bundles, as well as the detailed
process of bundle signature and validation. We also present the SFelix
platform, which is a secure extension to Felix OSGi(tm) framework
implementation. It includes our implementation of the bundle signature process,
as specified by OSGi(tm) Release 4 Security Layer. Moreover, a tool for signing
and publishing bundles, SFelix JarSigner, has been developed to conveniently
integrate bundle signature in the bundle deployment process.
</summary>
    <author>
      <name>Pierre Parrend</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rhône-Alpes</arxiv:affiliation>
    </author>
    <author>
      <name>Stéphane Frénot</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rhône-Alpes</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/cs/0607049v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0607049v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0611117v1</id>
    <updated>2006-11-22T19:28:31Z</updated>
    <published>2006-11-22T19:28:31Z</published>
    <title>2FACE: Bi-Directional Face Traversal for Efficient Geometric Routing</title>
    <summary>  We propose bi-directional face traversal algorithm $2FACE$ to shorten the
path the message takes to reach the destination in geometric routing. Our
algorithm combines the practicality of the best single-direction traversal
algorithms with the worst case message complexity of $O(|E|)$, where $E$ is the
number of network edges. We apply $2FACE$ to a variety of geometric routing
algorithms. Our simulation results indicate that bi-directional face traversal
decreases the latency of message delivery two to three times compared to single
direction face traversal. The thus selected path approaches the shortest
possible route. This gain in speed comes with a similar message overhead
increase. We describe an algorithm which compensates for this message overhead
by recording the preferable face traversal direction. Thus, if a source has
several messages to send to the destination, the subsequent messages follow the
shortest route. Our simulation results show that with most geometric routing
algorithms the message overhead of finding the short route by bi-directional
face traversal is compensated within two to four repeat messages.
</summary>
    <author>
      <name>Mark Miyashita</name>
    </author>
    <author>
      <name>Mikhail Nesterenko</name>
    </author>
    <link href="http://arxiv.org/abs/cs/0611117v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0611117v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0706.3812v3</id>
    <updated>2007-07-27T13:50:46Z</updated>
    <published>2007-06-26T12:36:37Z</published>
    <title>Java Components Vulnerabilities - An Experimental Classification
  Targeted at the OSGi Platform</title>
    <summary>  The OSGi Platform finds a growing interest in two different applications
domains: embedded systems, and applications servers. However, the security
properties of this platform are hardly studied, which is likely to hinder its
use in production systems. This is all the more important that the dynamic
aspect of OSGi-based applications, that can be extended at runtime, make them
vulnerable to malicious code injection. We therefore perform a systematic audit
of the OSGi platform so as to build a vulnerability catalog that intends to
reference OSGi Vulnerabilities originating in the Core Specification, and in
behaviors related to the use of the Java language. Standard Services are not
considered. To support this audit, a Semi-formal Vulnerability Pattern is
defined, that enables to uniquely characterize fundamental properties for each
vulnerability, to include verbose description in the pattern, to reference
known security protections, and to track the implementation status of the
proof-of-concept OSGi Bundles that exploit the vulnerability. Based on the
analysis of the catalog, a robust OSGi Platform is built, and recommendations
are made to enhance the OSGi Specifications.
</summary>
    <author>
      <name>Pierre Parrend</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rhône-Alpes</arxiv:affiliation>
    </author>
    <author>
      <name>Stéphane Frénot</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Rhône-Alpes</arxiv:affiliation>
    </author>
    <link href="http://arxiv.org/abs/0706.3812v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0706.3812v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0803.3338v1</id>
    <updated>2008-03-23T19:10:00Z</updated>
    <published>2008-03-23T19:10:00Z</published>
    <title>Performance Evaluation of Multiple TCP connections in iSCSI</title>
    <summary>  Scaling data storage is a significant concern in enterprise systems and
Storage Area Networks (SANs) are deployed as a means to scale enterprise
storage. SANs based on Fibre Channel have been used extensively in the last
decade while iSCSI is fast becoming a serious contender due to its reduced
costs and unified infrastructure. This work examines the performance of iSCSI
with multiple TCP connections. Multiple TCP connections are often used to
realize higher bandwidth but there may be no fairness in how bandwidth is
distributed. We propose a mechanism to share congestion information across
multiple flows in ``Fair-TCP'' for improved performance. Our results show that
Fair-TCP significantly improves the performance for I/O intensive workloads.
</summary>
    <author>
      <name>Bhargava Kumar K</name>
    </author>
    <author>
      <name>Ganesh M. Narayan</name>
    </author>
    <author>
      <name>K. Gopinath</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10pt, 11 pages, two column, 15 figures</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 24th IEEE Conference on Mass Storage Systems
  and Technologies, 2007 - MSST '07</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/0803.3338v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0803.3338v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="B.3.2; D.4.2; H.3.4; C.2.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0907.4622v1</id>
    <updated>2009-07-26T02:19:42Z</updated>
    <published>2009-07-26T02:19:42Z</published>
    <title>Aneka: A Software Platform for .NET-based Cloud Computing</title>
    <summary>  Aneka is a platform for deploying Clouds developing applications on top of
it. It provides a runtime environment and a set of APIs that allow developers
to build .NET applications that leverage their computation on either public or
private clouds. One of the key features of Aneka is the ability of supporting
multiple programming models that are ways of expressing the execution logic of
applications by using specific abstractions. This is accomplished by creating a
customizable and extensible service oriented runtime environment represented by
a collection of software containers connected together. By leveraging on these
architecture advanced services including resource reservation, persistence,
storage management, security, and performance monitoring have been implemented.
On top of this infrastructure different programming models can be plugged to
provide support for different scenarios as demonstrated by the engineering,
life science, and industry applications.
</summary>
    <author>
      <name>Christian Vecchiola</name>
    </author>
    <author>
      <name>Xingchen Chu</name>
    </author>
    <author>
      <name>Rajkumar Buyya</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">30 pages, 10 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0907.4622v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0907.4622v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="C.1.4; C.2.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0912.3852v1</id>
    <updated>2009-12-19T01:18:05Z</updated>
    <published>2009-12-19T01:18:05Z</published>
    <title>Sharp utilization thresholds for some real-time scheduling problems</title>
    <summary>  Scheduling policies for real-time systems exhibit threshold behavior that is
related to the utilization of the task set they schedule, and in some cases
this threshold is sharp. For the rate monotonic scheduling policy, we show that
periodic workload with utilization less than a threshold $U_{RM}^{*}$ can be
scheduled almost surely and that all workload with utilization greater than
$U_{RM}^{*}$ is almost surely not schedulable. We study such sharp threshold
behavior in the context of processor scheduling using static task priorities,
not only for periodic real-time tasks but for aperiodic real-time tasks as
well. The notion of a utilization threshold provides a simple schedulability
test for most real-time applications. These results improve our understanding
of scheduling policies and provide an interesting characterization of the
typical behavior of policies. The threshold is sharp (small deviations around
the threshold cause schedulability, as a property, to appear or disappear) for
most policies; this is a happy consequence that can be used to address the
limitations of existing utilization-based tests for schedulability. We
demonstrate the use of such an approach for balancing power consumption with
the need to meet deadlines in web servers.
</summary>
    <author>
      <name>Sathish Gopalakrishnan</name>
    </author>
    <link href="http://arxiv.org/abs/0912.3852v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0912.3852v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1005.5045v1</id>
    <updated>2010-05-27T12:28:51Z</updated>
    <published>2010-05-27T12:28:51Z</published>
    <title>File Managing and Program Execution in Web Operating Systems</title>
    <summary>  Web Operating Systems can be seen as an extension of traditional Operating
Systems where the addresses used to manage files and execute programs (via the
basic load/execution mechanism) are extended from local filesystem path-names
to URLs. A first consequence is that, similarly as in traditional web
technologies, executing a program at a given URL, can be done in two
modalities: either the execution is performed client-side at the invoking
machine (and relative URL addressing in the executed program set to refer to
the invoked URL) or it is performed server-side at the machine addressed by the
invoked URL (as, e.g., for a web service). Moreover in this context, user
identification for access to programs and files and workflow-based composition
of service programs is naturally based on token/session-like mechanisms. We
propose a middleware based on client-server protocols and on a set primitives,
for managing files/resources and executing programs (in the form of
client-side/server-side components/services) in Web Operating Systems. We
formally define the semantics of such middleware via a process algebraic
approach.
</summary>
    <author>
      <name>Mario Bravetti</name>
    </author>
    <link href="http://arxiv.org/abs/1005.5045v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1005.5045v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1005.5241v1</id>
    <updated>2010-05-28T08:55:12Z</updated>
    <published>2010-05-28T08:55:12Z</published>
    <title>Simulation de traces réelles d'E/S disque de PC</title>
    <summary>  Under Windows operating system, existing I/O benchmarking tools does not
allow a developer to efficiently define a file access strategy according to the
applications' constraints. This is essentially due to the fact that the
existing tools do allow only a restricted set of I/O workloads that does not
generally correspond to the target applications. To cope with this problem, we
designed and implemented a precise I/O simulator allowing to simulate whatever
real I/O trace on a given defined architecture, and in which most of file and
disk cache strategies, their interactions and the detailed storage system
architecture are implemented. Simulation results on different workloads and
architectures show a very high degree of precision. In fact, the mean error
rate as compared to real measures is of about 6% with a maximum of 10% on
global throughput.
</summary>
    <author>
      <name>Jalil Boukhobza</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LESTER</arxiv:affiliation>
    </author>
    <author>
      <name>Timsit Claude</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">PRISM</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">RenPar'17 / SympA'2006 / CFSE'5 / JC'2006, Canet en Roussillon :
  France (2006)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1005.5241v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1005.5241v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1008.1571v1</id>
    <updated>2010-08-09T19:23:10Z</updated>
    <published>2010-08-09T19:23:10Z</published>
    <title>Scaling Turbo Boost to a 1000 cores</title>
    <summary>  The Intel Core i7 processor code named Nehalem provides a feature named Turbo
Boost which opportunistically varies the frequencies of the processor's cores.
The frequency of a core is determined by core temperature, the number of active
cores, the estimated power consumption, the estimated current consumption, and
operating system frequency scaling requests. For a chip multi-processor(CMP)
that has a small number of physical cores and a small set of performance
states, deciding the Turbo Boost frequency to use on a given core might not be
difficult. However, we do not know the complexity of this decision making
process in the context of a large number of cores, scaling to the 100s, as
predicted by researchers in the field.
</summary>
    <author>
      <name>Ananth Narayan S</name>
    </author>
    <author>
      <name>Somsubhra Sharangi</name>
    </author>
    <author>
      <name>Alexandra Fedorova</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, short paper</arxiv:comment>
    <link href="http://arxiv.org/abs/1008.1571v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1008.1571v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1009.3088v2</id>
    <updated>2010-09-26T01:40:36Z</updated>
    <published>2010-09-16T04:43:46Z</published>
    <title>CloneCloud: Boosting Mobile Device Applications Through Cloud Clone
  Execution</title>
    <summary>  Mobile applications are becoming increasingly ubiquitous and provide ever
richer functionality on mobile devices. At the same time, such devices often
enjoy strong connectivity with more powerful machines ranging from laptops and
desktops to commercial clouds. This paper presents the design and
implementation of CloneCloud, a system that automatically transforms mobile
applications to benefit from the cloud. The system is a flexible application
partitioner and execution runtime that enables unmodified mobile applications
running in an application-level virtual machine to seamlessly off-load part of
their execution from mobile devices onto device clones operating in a
computational cloud. CloneCloud uses a combination of static analysis and
dynamic profiling to optimally and automatically partition an application so
that it migrates, executes in the cloud, and re-integrates computation in a
fine-grained manner that makes efficient use of resources. Our evaluation shows
that CloneCloud can achieve up to 21.2x speedup of smartphone applications we
tested and it allows different partitioning for different inputs and networks.
</summary>
    <author>
      <name>Byung-Gon Chun</name>
    </author>
    <author>
      <name>Sunghwan Ihm</name>
    </author>
    <author>
      <name>Petros Maniatis</name>
    </author>
    <author>
      <name>Mayur Naik</name>
    </author>
    <link href="http://arxiv.org/abs/1009.3088v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1009.3088v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="C.2.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1010.5571v1</id>
    <updated>2010-10-27T05:04:38Z</updated>
    <published>2010-10-27T05:04:38Z</published>
    <title>An Introduction to Time-Constrained Automata</title>
    <summary>  We present time-constrained automata (TCA), a model for hard real-time
computation in which agents behaviors are modeled by automata and constrained
by time intervals.
  TCA actions can have multiple start time and deadlines, can be aperiodic, and
are selected dynamically following a graph, the time-constrained automaton.
This allows expressing much more precise time constraints than classical
periodic or sporadic model, while preserving the ease of scheduling and
analysis.
  We provide some properties of this model as well as their scheduling
semantics. We show that TCA can be automatically derived from source-code, and
optimally scheduled on single processors using a variant of EDF. We explain how
time constraints can be used to guarantee communication determinism by
construction, and to study when possible agent interactions happen.
</summary>
    <author>
      <name>Matthieu Lemerre</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CEA LIST</arxiv:affiliation>
    </author>
    <author>
      <name>Vincent David</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CEA LIST</arxiv:affiliation>
    </author>
    <author>
      <name>Christophe Aussaguès</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">CEA LIST</arxiv:affiliation>
    </author>
    <author>
      <name>Guy Vidal-Naquet</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">SUPELEC</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.38.9</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.38.9" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings ICE 2010, arXiv:1010.5308</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 38, 2010, pp. 83-98</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1010.5571v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1010.5571v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1011.3087v1</id>
    <updated>2010-11-13T02:17:29Z</updated>
    <published>2010-11-13T02:17:29Z</published>
    <title>Leakage-Aware Reallocation for Periodic Real-Time Tasks on Multicore
  Processors</title>
    <summary>  It is an increasingly important issue to reduce the energy consumption of
computing systems. In this paper, we consider partition based energy-aware
scheduling of periodic real-time tasks on multicore processors. The scheduling
exploits dynamic voltage scaling (DVS) and core sleep scheduling to reduce both
dynamic and leakage energy consumption. If the overhead of core state switching
is non-negligible, however, the performance of this scheduling strategy in
terms of energy efficiency might degrade. To achieve further energy saving, we
extend the static task scheduling with run-time task reallocation. The basic
idea is to aggregate idle time among cores so that as many cores as possible
could be put into sleep in a way that the overall energy consumption is
reduced. Simulation results show that the proposed approach results in up to
20% energy saving over traditional leakage-aware DVS.
</summary>
    <author>
      <name>Hongtao Huang</name>
    </author>
    <author>
      <name>Feng Xia</name>
    </author>
    <author>
      <name>Jijie Wang</name>
    </author>
    <author>
      <name>Siyu Lei</name>
    </author>
    <author>
      <name>Guowei Wu</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/FCST.2010.105</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/FCST.2010.105" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">The 5th International Conference on Frontier of Computer Science and
  Technology (FCST), IEEE, Changchun, China, August 2010</arxiv:comment>
    <link href="http://arxiv.org/abs/1011.3087v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1011.3087v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68M20" scheme="http://arxiv.org/schemas/atom"/>
    <category term="C.3; D.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.1930v1</id>
    <updated>2011-11-08T15:03:26Z</updated>
    <published>2011-11-08T15:03:26Z</published>
    <title>The UWB Solution for Multimedia Traffic in Wireless Sensor Networks</title>
    <summary>  Several researches are focused on the QoS (Quality of Service) and Energy
consumption in wireless Multimedia Sensor Networks. Those research projects
invest in theory and practice in order to extend the spectrum of use of norms,
standards and technologies which are emerged in wireless communications. The
performance of these technologies is strongly related to domains of use and
limitations of their characteristics. In this paper, we give a comparison of
ZigBee technology, most widely used in sensor networks, and UWB (Ultra Wide
Band) which presents itself as competitor that present in these work better
results for audiovisual applications with medium-range and high throughput.
</summary>
    <author>
      <name>A. A. Boudhir</name>
    </author>
    <author>
      <name>M. Bouhorma</name>
    </author>
    <author>
      <name>M. Ben Ahmed</name>
    </author>
    <author>
      <name>Elbrak Said</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5121/ijwmn</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5121/ijwmn" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages, 11 figures, IJWMN Journal</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Wireless &amp; Mobile Networks October Issue
  2011</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1111.1930v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.1930v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.MM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="J.2.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1111.5880v1</id>
    <updated>2011-11-25T02:10:11Z</updated>
    <published>2011-11-25T02:10:11Z</published>
    <title>Robustness Analysis for Battery Supported Cyber-Physical Systems</title>
    <summary>  This paper establishes a novel analytical approach to quantify robustness of
scheduling and battery management for battery supported cyber-physical systems.
A dynamic schedulability test is introduced to determine whether tasks are
schedulable within a finite time window. The test is used to measure robustness
of a real-time scheduling algorithm by evaluating the strength of computing
time perturbations that break schedulability at runtime. Robustness of battery
management is quantified analytically by an adaptive threshold on the state of
charge. The adaptive threshold significantly reduces the false alarm rate for
battery management algorithms to decide when a battery needs to be replaced.
</summary>
    <author>
      <name>Fumin Zhang</name>
    </author>
    <author>
      <name>Zhenwu Shi</name>
    </author>
    <author>
      <name>Shayok Mukhopadhyay</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper has been accepted by ACM Transactions in Embedded
  Computing Systems (TECS) in October, 2011</arxiv:comment>
    <link href="http://arxiv.org/abs/1111.5880v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1111.5880v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.ET" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.ET" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="C.3; D.4.1; G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1202.5282v2</id>
    <updated>2012-06-02T15:56:26Z</updated>
    <published>2012-02-23T20:12:00Z</published>
    <title>How to Bypass Verified Boot Security in Chromium OS</title>
    <summary>  Verified boot is an interesting feature of Chromium OS that supposedly can
detect any modification in the root file system (rootfs) by a dedicated
adversary. However, by exploiting a design flaw in verified boot, we show that
an adversary can replace the original rootfs by a malicious rootfs containing
exploits such as a spyware or keylogger and still pass the verified boot
process. The exploit is based on the fact that a dedicated adversary can
replace the rootfs and the corresponding verification information in the
bootloader. We experimentally demonstrate an attack using both the base and
developer version of Chromium OS in which the adversary installs a spyware in
the target system to send cached user data to the attacker machine in plain
text which are otherwise encrypted, and thus inaccessible. We also demonstrate
techniques to mitigate this vulnerability.
</summary>
    <author>
      <name>Mohammad Iftekhar Husain</name>
    </author>
    <author>
      <name>Lokesh Mandvekar</name>
    </author>
    <author>
      <name>Chunming Qiao</name>
    </author>
    <author>
      <name>Ramalingam Sridhar</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Update information about Chromium OS. Added new and advanced
  exploits. Added mitigation techniques and evaluation</arxiv:comment>
    <link href="http://arxiv.org/abs/1202.5282v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1202.5282v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1210.2882v1</id>
    <updated>2012-10-10T12:13:30Z</updated>
    <published>2012-10-10T12:13:30Z</published>
    <title>Online Adaptive Fault Tolerant based Feedback Control Scheduling
  Algorithm for Multiprocessor Embedded Systems</title>
    <summary>  Since some years ago, use of Feedback Control Scheduling Algorithm (FCSA) in
the control scheduling co-design of multiprocessor embedded system has
increased. FCSA provides Quality of Service (QoS) in terms of overall system
performance and resource allocation in open and unpredictable environment. FCSA
uses quality control feedback loop to keep CPU utilization under desired
unitization bound by avoiding overloading and deadline miss ratio. Integrated
Fault tolerance (FT) based FCSA design methodology guarantees that the Safety
Critical (SC) tasks will meet their deadlines in the presence of faults.
However, current FCSA design model does not provide the optimal solution with
dynamic load fluctuation. This paper presented a novel methodology of designing
an online adaptive fault tolerant based feedback control algorithm for
multiprocessor embedded systems. This procedure is important for control
scheduling co-design for multiprocessor embedded systems.
</summary>
    <author>
      <name>Oumair Naseer</name>
    </author>
    <author>
      <name>Rana Atif Ali Khan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1210.2882v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1210.2882v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.6187v1</id>
    <updated>2012-11-27T02:36:24Z</updated>
    <published>2012-11-27T02:36:24Z</published>
    <title>A Formal Model of a Virtual Filesystem Switch</title>
    <summary>  This work presents a formal model that is part of our effort to construct a
verified file system for Flash memory. To modularize the verification we factor
out generic aspects into a common component that is inspired by the Linux
Virtual Filesystem Switch (VFS) and provides POSIX compatible operations. It
relies on an abstract specification of its internal interface to concrete file
system implementations (AFS). We proved that preconditions of AFS are respected
and that the state is kept consistent. The model can be made executable and
mounted into the Linux directory tree using FUSE.
</summary>
    <author>
      <name>Gidon Ernst</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Augsburg</arxiv:affiliation>
    </author>
    <author>
      <name>Gerhard Schellhorn</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Augsburg</arxiv:affiliation>
    </author>
    <author>
      <name>Dominik Haneberg</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Augsburg</arxiv:affiliation>
    </author>
    <author>
      <name>Jörg Pfähler</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Augsburg</arxiv:affiliation>
    </author>
    <author>
      <name>Wolfgang Reif</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Augsburg</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.102.5</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.102.5" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings SSV 2012, arXiv:1211.5873</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 102, 2012, pp. 33-45</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1211.6187v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.6187v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.6190v1</id>
    <updated>2012-11-27T02:36:45Z</updated>
    <published>2012-11-27T02:36:45Z</published>
    <title>On the Use of Underspecified Data-Type Semantics for Type Safety in
  Low-Level Code</title>
    <summary>  In recent projects on operating-system verification, C and C++ data types are
often formalized using a semantics that does not fully specify the precise byte
encoding of objects. It is well-known that such an underspecified data-type
semantics can be used to detect certain kinds of type errors. In general,
however, underspecified data-type semantics are unsound: they assign
well-defined meaning to programs that have undefined behavior according to the
C and C++ language standards.
  A precise characterization of the type-correctness properties that can be
enforced with underspecified data-type semantics is still missing. In this
paper, we identify strengths and weaknesses of underspecified data-type
semantics for ensuring type safety of low-level systems code. We prove
sufficient conditions to detect certain classes of type errors and, finally,
identify a trade-off between the complexity of underspecified data-type
semantics and their type-checking capabilities.
</summary>
    <author>
      <name>Hendrik Tews</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">TU Dresden</arxiv:affiliation>
    </author>
    <author>
      <name>Marcus Völp</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">TU Dresden</arxiv:affiliation>
    </author>
    <author>
      <name>Tjark Weber</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Uppsala University</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.102.8</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.102.8" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings SSV 2012, arXiv:1211.5873</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 102, 2012, pp. 73-87</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1211.6190v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.6190v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1302.0621v3</id>
    <updated>2013-06-27T06:04:17Z</updated>
    <published>2013-02-04T09:09:38Z</published>
    <title>RevDedup: A Reverse Deduplication Storage System Optimized for Reads to
  Latest Backups</title>
    <summary>  Scaling up the backup storage for an ever-increasing volume of virtual
machine (VM) images is a critical issue in virtualization environments. While
deduplication is known to effectively eliminate duplicates for VM image
storage, it also introduces fragmentation that will degrade read performance.
We propose RevDedup, a deduplication system that optimizes reads to latest VM
image backups using an idea called reverse deduplication. In contrast with
conventional deduplication that removes duplicates from new data, RevDedup
removes duplicates from old data, thereby shifting fragmentation to old data
while keeping the layout of new data as sequential as possible. We evaluate our
RevDedup prototype using microbenchmark and real-world workloads. For a 12-week
span of real-world VM images from 160 users, RevDedup achieves high
deduplication efficiency with around 97% of saving, and high backup and read
throughput on the order of 1GB/s. RevDedup also incurs small metadata overhead
in backup/read operations.
</summary>
    <author>
      <name>Chun-Ho Ng</name>
    </author>
    <author>
      <name>Patrick P. C. Lee</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">A 7-page version appeared in APSys'13</arxiv:comment>
    <link href="http://arxiv.org/abs/1302.0621v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1302.0621v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1302.5521v1</id>
    <updated>2013-02-22T09:01:24Z</updated>
    <published>2013-02-22T09:01:24Z</published>
    <title>Towards Python-based Domain-specific Languages for Self-reconfigurable
  Modular Robotics Research</title>
    <summary>  This paper explores the role of operating system and high-level languages in
the development of software and domain-specific languages (DSLs) for
self-reconfigurable robotics. We review some of the current trends in
self-reconfigurable robotics and describe the development of a software system
for ATRON II which utilizes Linux and Python to significantly improve software
abstraction and portability while providing some basic features which could
prove useful when using Python, either stand-alone or via a DSL, on a
self-reconfigurable robot system. These features include transparent socket
communication, module identification, easy software transfer and reliable
module-to-module communication. The end result is a software platform for
modular robots that where appropriate builds on existing work in operating
systems, virtual machines, middleware and high-level languages.
</summary>
    <author>
      <name>Mikael Moghadam</name>
    </author>
    <author>
      <name>David Johan Christensen</name>
    </author>
    <author>
      <name>David Brandt</name>
    </author>
    <author>
      <name>Ulrik Pagh Schultz</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented at DSLRob 2011 (arXiv:1212.3308)</arxiv:comment>
    <link href="http://arxiv.org/abs/1302.5521v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1302.5521v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1308.0698v1</id>
    <updated>2013-08-03T14:09:23Z</updated>
    <published>2013-08-03T14:09:23Z</published>
    <title>An Improving Method for Loop Unrolling</title>
    <summary>  In this paper we review main ideas mentioned in several other papers which
talk about optimization techniques used by compilers. Here we focus on loop
unrolling technique and its effect on power consumption, energy usage and also
its impact on program speed up by achieving ILP (Instruction-level
parallelism). Concentrating on superscalar processors, we discuss the idea of
generalized loop unrolling presented by J.C. Hang and T. Leng and then we
present a new method to traverse a linked list to get a better result of loop
unrolling in that case. After that we mention the results of some experiments
carried out on a Pentium 4 processor (as an instance of super scalar
architecture). Furthermore, the results of some other experiments on
supercomputer (the Alliat FX/2800 System) containing superscalar node
processors would be mentioned. These experiments show that loop unrolling has a
slight measurable effect on energy usage as well as power consumption. But it
could be an effective way for program speed up.
</summary>
    <author>
      <name>Meisam Booshehri</name>
    </author>
    <author>
      <name>Abbas Malekpour</name>
    </author>
    <author>
      <name>Peter Luksch</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, International Journal of Computer Science and Information
  Security</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">International Journal of Computer Science and Information
  Security, Vol. 11, No. 5, pp. 73-76 , 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1308.0698v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1308.0698v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68Nxx" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.3.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1312.5892v1</id>
    <updated>2013-12-20T11:11:54Z</updated>
    <published>2013-12-20T11:11:54Z</published>
    <title>Support for Error Tolerance in the Real-Time Transport Protocol</title>
    <summary>  Streaming applications often tolerate bit errors in their received data well.
This is contrasted by the enforcement of correctness of the packet headers and
payload by network protocols. We investigate a solution for the Real-time
Transport Protocol (RTP) that is tolerant to errors by accepting erroneous
data. It passes potentially corrupted stream data payloads to the codecs. If
errors occur in the header, our solution recovers from these by leveraging the
known state and expected header values for each stream. The solution is fully
receiver-based and incrementally deployable, and as such requires neither
support from the sender nor changes to the RTP specification. Evaluations show
that our header error recovery scheme can recover from almost all errors, with
virtually no erroneous recoveries, up to bit error rates of about 10%.
</summary>
    <author>
      <name>Florian Schmidt</name>
    </author>
    <author>
      <name>David Orlea</name>
    </author>
    <author>
      <name>Klaus Wehrle</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, 9 figures, published as technical report of the Department
  of Computer Science of RWTH Aachen University</arxiv:comment>
    <link href="http://arxiv.org/abs/1312.5892v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1312.5892v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="C.2.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1401.6726v1</id>
    <updated>2014-01-27T03:01:33Z</updated>
    <published>2014-01-27T03:01:33Z</published>
    <title>Anception: Application Virtualization For Android</title>
    <summary>  The problem of malware has become significant on Android devices. Library
operating systems and application virtualization are both possible solutions
for confining malware. Unfortunately, such solutions do not exist for Android.
Designing mechanisms for application virtualization is a significant chal-
lenge for several reasons: (1) graphics performance is important due to
popularity of games and (2) applications with the same UID can share state.
This paper presents Anception, the first flexible application virtualization
framework for Android. It is imple- mented as a modification to the Android
kernel and supports application virtualization that addresses the above
requirements. Anception is able to confine many types of malware while
supporting unmodified Android applications. Our Anception- based system
exhibits up to 3.9% overhead on various 2D/3D benchmarks, and 1.8% overhead on
the SunSpider benchmark.
</summary>
    <author>
      <name>Earlence Fernandes</name>
    </author>
    <author>
      <name>Alexander Crowell</name>
    </author>
    <author>
      <name>Ajit Aluri</name>
    </author>
    <author>
      <name>Atul Prakash</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">University of Michigan, Technical Report CSE-TR-583-13</arxiv:comment>
    <link href="http://arxiv.org/abs/1401.6726v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1401.6726v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1403.1165v1</id>
    <updated>2014-03-05T15:43:57Z</updated>
    <published>2014-03-05T15:43:57Z</published>
    <title>A Taxonomy for Attack Patterns on Information Flows in Component-Based
  Operating Systems</title>
    <summary>  We present a taxonomy and an algebra for attack patterns on component-based
operating systems. In a multilevel security scenario, where isolation of
partitions containing data at different security classifications is the primary
security goal and security breaches are mainly defined as undesired disclosure
or modification of classified data, strict control of information flows is the
ultimate goal. In order to prevent undesired information flows, we provide a
classification of information flow types in a component-based operating system
and, by this, possible patterns to attack the system. The systematic
consideration of informations flows reveals a specific type of operating system
covert channel, the covert physical channel, which connects two former isolated
partitions by emitting physical signals into the computer's environment and
receiving them at another interface.
</summary>
    <author>
      <name>Michael Hanspach</name>
    </author>
    <author>
      <name>Jörg Keller</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings of the 7th Layered Assurance Workshop, New Orleans,
  LA, USA, December 2013</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1403.1165v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1403.1165v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.7754v1</id>
    <updated>2014-10-28T19:23:26Z</updated>
    <published>2014-10-28T19:23:26Z</published>
    <title>A First Look at Firefox OS Security</title>
    <summary>  With Firefox OS, Mozilla is making a serious push for an HTML5-based mobile
platform. In order to assuage security concerns over providing hardware access
to web applications, Mozilla has introduced a number of mechanisms that make
the security landscape of Firefox OS distinct from both the desktop web and
other mobile operating systems. From an application security perspective, the
two most significant of these mechanisms are the the introduction of a default
Content Security Policy and code review in the market. This paper describes how
lightweight static analysis can augment these mechanisms to find
vulnerabilities which have otherwise been missed. We provide examples of
privileged applications in the market that contain vulnerabilities that can be
automatically detected.
  In addition to these findings, we show some of the challenges that occur when
desktop software is repurposed for a mobile operating system. In particular, we
argue that the caching of certificate overrides across applications--a known
problem in Firefox OS--generates a counter-intuitive user experience that
detracts from the security of the system.
</summary>
    <author>
      <name>Daniel Defreez</name>
    </author>
    <author>
      <name>Bhargava Shastry</name>
    </author>
    <author>
      <name>Hao Chen</name>
    </author>
    <author>
      <name>Jean-Pierre Seifert</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings of the Third Workshop on Mobile Security Technologies
  (MoST) 2014 (http://arxiv.org/abs/1410.6674)</arxiv:comment>
    <link href="http://arxiv.org/abs/1410.7754v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.7754v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.06836v1</id>
    <updated>2015-04-26T14:57:05Z</updated>
    <published>2015-04-26T14:57:05Z</published>
    <title>Monitoring Extreme-scale Lustre Toolkit</title>
    <summary>  We discuss the design and ongoing development of the Monitoring Extreme-scale
Lustre Toolkit (MELT), a unified Lustre performance monitoring and analysis
infrastructure that provides continuous, low-overhead summary information on
the health and performance of Lustre, as well as on-demand, in- depth problem
diagnosis and root-cause analysis. The MELT infrastructure leverages a
distributed overlay network to enable monitoring of center-wide Lustre
filesystems where clients are located across many network domains. We preview
interactive command-line utilities that help administrators and users to
observe Lustre performance at various levels of resolution, from individual
servers or clients to whole filesystems, including job-level reporting.
Finally, we discuss our future plans for automating the root-cause analysis of
common Lustre performance problems.
</summary>
    <author>
      <name>Michael J. Brim</name>
    </author>
    <author>
      <name>Joshua K. Lothian</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">International Workshop on the Lustre Ecosystem: Challenges and
  Opportunities, March 2015, Annapolis MD</arxiv:comment>
    <link href="http://arxiv.org/abs/1504.06836v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.06836v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.01448v1</id>
    <updated>2015-05-06T18:14:56Z</updated>
    <published>2015-05-06T18:14:56Z</published>
    <title>Taking back control of HPC file systems with Robinhood Policy Engine</title>
    <summary>  Today, the largest Lustre file systems store billions of entries. On such
systems, classic tools based on namespace scanning become unusable. Operations
such as managing file lifetime, scheduling data copies, and generating overall
filesystem statistics become painful as they require collecting, sorting and
aggregating information for billions of records. Robinhood Policy Engine is an
open source software developed to address these challenges. It makes it
possible to schedule automatic actions on huge numbers of filesystem entries.
It also gives a synthetic understanding of file systems contents by providing
overall statistics about data ownership, age and size profiles. Even if it can
be used with any POSIX filesystem, Robinhood supports Lustre specific features
like OSTs, pools, HSM, ChangeLogs, and DNE. It implements specific support for
these features, and takes advantage of them to manage Lustre file systems
efficiently.
</summary>
    <author>
      <name>Thomas Leibovici</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">International Workshop on the Lustre Ecosystem: Challenges and
  Opportunities, March 2015, Annapolis MD</arxiv:comment>
    <link href="http://arxiv.org/abs/1505.01448v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.01448v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.01765v1</id>
    <updated>2015-05-07T16:31:21Z</updated>
    <published>2015-05-07T16:31:21Z</published>
    <title>Development of a Burst Buffer System for Data-Intensive Applications</title>
    <summary>  Modern parallel filesystems such as Lustre are designed to provide high,
scalable I/O bandwidth in response to growing I/O requirements; however, the
bursty I/O characteristics of many data-intensive scientific applications make
it difficult for back-end parallel filesystems to efficiently handle I/O
requests. A burst buffer system, through which data can be temporarily buffered
via high-performance storage mediums, allows for gradual flushing of data to
back-end filesystems. In this paper, we explore issues surrounding the
development of a burst buffer system for data-intensive scientific
applications. Our initial results demonstrate that utilizing a burst buffer
system on top of the Lustre filesystem shows promise for dealing with the
intense I/O traffic generated by application checkpointing.
</summary>
    <author>
      <name>Teng Wang</name>
    </author>
    <author>
      <name>Sarp Oral</name>
    </author>
    <author>
      <name>Michael Pritchard</name>
    </author>
    <author>
      <name>Kevin Vasko</name>
    </author>
    <author>
      <name>Weikuan Yu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">International Workshop on the Lustre Ecosystem: Challenges and
  Opportunities, March 2015, Annapolis MD</arxiv:comment>
    <link href="http://arxiv.org/abs/1505.01765v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.01765v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1506.02822v2</id>
    <updated>2015-07-26T18:50:32Z</updated>
    <published>2015-06-09T08:30:23Z</published>
    <title>Reproducible and User-Controlled Software Environments in HPC with Guix</title>
    <summary>  Support teams of high-performance computing (HPC) systems often find
themselves between a rock and a hard place: on one hand, they understandably
administrate these large systems in a conservative way, but on the other hand,
they try to satisfy their users by deploying up-to-date tool chains as well as
libraries and scientific software. HPC system users often have no guarantee
that they will be able to reproduce results at a later point in time, even on
the same system-software may have been upgraded, removed, or recompiled under
their feet, and they have little hope of being able to reproduce the same
software environment elsewhere. We present GNU Guix and the functional package
management paradigm and show how it can improve reproducibility and sharing
among researchers with representative use cases.
</summary>
    <author>
      <name>Ludovic Courtès</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Bordeaux - Sud-Ouest</arxiv:affiliation>
    </author>
    <author>
      <name>Ricardo Wurmus</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2nd International Workshop on Reproducibility in Parallel Computing
  (RepPar), Aug 2015, Vienne, Austria. http://reppar.org/</arxiv:comment>
    <link href="http://arxiv.org/abs/1506.02822v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1506.02822v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.04753v1</id>
    <updated>2015-08-18T19:50:17Z</updated>
    <published>2015-08-18T19:50:17Z</published>
    <title>Cold Object Identification in the Java Virtual Machine</title>
    <summary>  Many Java applications instantiate objects within the Java heap that are
persistent but seldom if ever referenced by the application. Examples include
strings, such as error messages, and collections of value objects that are
preloaded for fast access but they may include objects that are seldom
referenced. This paper describes a stack-based framework for detecting these
"cold" objects at runtime, with a view to marshaling and sequestering them in
designated regions of the heap where they may be preferentially paged out to a
backing store, thereby freeing physical memory pages for occupation by more
active objects. Furthermore, we evaluate the correctness and efficiency of
stack-based approach with an Access Barrier. The experimental results from a
series of SPECjvm2008 benchmarks are presented.
</summary>
    <author>
      <name>Kim T. Briggs</name>
    </author>
    <author>
      <name>Baoguo Zhou</name>
    </author>
    <author>
      <name>Gerhard W. Dueck</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">For submission to `Software: Practice and Experience'</arxiv:comment>
    <link href="http://arxiv.org/abs/1508.04753v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.04753v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.05228v1</id>
    <updated>2015-08-21T09:59:27Z</updated>
    <published>2015-08-21T09:59:27Z</published>
    <title>A Case Study on Covert Channel Establishment via Software Caches in
  High-Assurance Computing Systems</title>
    <summary>  Covert channels can be utilized to secretly deliver information from high
privileged processes to low privileged processes in the context of a
high-assurance computing system. In this case study, we investigate the
possibility of covert channel establishment via software caches in the context
of a framework for component-based operating systems. While component-based
operating systems offer security through the encapsulation of system service
processes, complete isolation of these processes is not reasonably feasible.
This limitation is practically demonstrated with our concept of a specific
covert timing channel based on file system caching. The stability of the covert
channel is evaluated and a methodology to disrupt the covert channel
transmission is presented. While these kinds of attacks are not limited to
high-assurance computing systems, our study practically demonstrates that even
security-focused computing systems with a minimal trusted computing base are
vulnerable for such kinds of attacks and careful design decisions are necessary
for secure operating system architectures.
</summary>
    <author>
      <name>Wolfgang Schmidt</name>
    </author>
    <author>
      <name>Michael Hanspach</name>
    </author>
    <author>
      <name>Jörg Keller</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, based upon the master's thesis of Schmidt</arxiv:comment>
    <link href="http://arxiv.org/abs/1508.05228v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.05228v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1508.07127v1</id>
    <updated>2015-08-28T08:45:35Z</updated>
    <published>2015-08-28T08:45:35Z</published>
    <title>Virtualization Architecture for NoC-based Reconfigurable Systems</title>
    <summary>  We propose a virtualization architecture for NoC-based reconfigurable
systems. The motivation of this work is to develop a service-oriented
architecture that includes Partial Reconfigurable Region as a Service (PRRaaS)
and Processing Element as a Service (PEaaS) for software applications.
According to the requirements of software applications, new PEs can be created
on-demand by (re)configuring the logic resource of the PRRs in the FPGA, while
the configured PEs can also be virtualized to support multiple application
tasks at the same time. As a result, such a two-level virtualization mechanism,
including the gate-level virtualization and the PE-level virtualization,
enables an SoC to be dynamically adapted to changing application requirements.
Therefore, more software applications can be performed, and system performance
can be further enhanced.
</summary>
    <author>
      <name>Chun-Hsian Huang</name>
    </author>
    <author>
      <name>Kwuan-Wei Tseng</name>
    </author>
    <author>
      <name>Chih-Cheng Lin</name>
    </author>
    <author>
      <name>Fang-Yu Lin</name>
    </author>
    <author>
      <name>Pao-Ann Hsiung</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented at Second International Workshop on FPGAs for Software
  Programmers (FSP 2015) (arXiv:1508.06320)</arxiv:comment>
    <link href="http://arxiv.org/abs/1508.07127v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1508.07127v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.02528v1</id>
    <updated>2015-11-08T21:12:17Z</updated>
    <published>2015-11-08T21:12:17Z</published>
    <title>Proceedings Workshop on Models for Formal Analysis of Real Systems</title>
    <summary>  This volume contains the proceedings of MARS 2015, the first workshop on
Models for Formal Analysis of Real Systems, held on November 23, 2015 in Suva,
Fiji, as an affiliated workshop of LPAR 2015, the 20th International Conference
on Logic for Programming, Artificial Intelligence and Reasoning.
  The workshop emphasises modelling over verification. It aims at discussing
the lessons learned from making formal methods for the verification and
analysis of realistic systems. Examples are:
  (1) Which formalism is chosen, and why?
  (2) Which abstractions have to be made and why?
  (3) How are important characteristics of the system modelled?
  (4) Were there any complications while modelling the system?
  (5) Which measures were taken to guarantee the accuracy of the model?
  We invited papers that present full models of real systems, which may lay the
basis for future comparison and analysis. An aim of the workshop is to present
different modelling approaches and discuss pros and cons for each of them.
Alternative formal descriptions of the systems presented at this workshop are
encouraged, which should foster the development of improved specification
formalisms.
</summary>
    <author>
      <name>Rob van Glabbeek</name>
    </author>
    <author>
      <name>Jan Friso Groote</name>
    </author>
    <author>
      <name>Peter Höfner</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.196</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.196" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 196, 2015</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1511.02528v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.02528v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1601.03027v1</id>
    <updated>2016-01-12T20:46:07Z</updated>
    <published>2016-01-12T20:46:07Z</published>
    <title>Open Mobile API: Accessing the UICC on Android Devices</title>
    <summary>  This report gives an overview of secure element integration into Android
devices. It focuses on the Open Mobile API as an open interface to access
secure elements from Android applications. The overall architecture of the Open
Mobile API is described and current Android devices are analyzed with regard to
the availability of this API. Moreover, this report summarizes our efforts of
reverse engineering the stock ROM of a Samsung Galaxy S3 in order to analyze
the integration of the Open Mobile API and the interface that is used to
perform APDU-based communication with the UICC (Universal Integrated Circuit
Card). It further provides a detailed explanation on how to integrate this
functionality into CyanogenMod (an after-market firmware for Android devices).
</summary>
    <author>
      <name>Michael Roland</name>
    </author>
    <author>
      <name>Michael Hölzl</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">University of Applied Sciences Upper Austria, JR-Center u'smile,
  Technical report, 76 pages, 12 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1601.03027v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.03027v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="C.2.0; C.3; C.5.3; D.2.7; D.4.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.07371v1</id>
    <updated>2016-04-25T19:20:18Z</updated>
    <published>2016-04-25T19:20:18Z</published>
    <title>Do the Hard Stuff First: Scheduling Dependent Computations in
  Data-Analytics Clusters</title>
    <summary>  We present a scheduler that improves cluster utilization and job completion
times by packing tasks having multi-resource requirements and
inter-dependencies. While the problem is algorithmically very hard, we achieve
near-optimality on the job DAGs that appear in production clusters at a large
enterprise and in benchmarks such as TPC-DS. A key insight is that carefully
handling the long-running tasks and those with tough-to-pack resource needs
will produce good-enough schedules. However, which subset of tasks to treat
carefully is not clear (and intractable to discover). Hence, we offer a search
procedure that evaluates various possibilities and outputs a preferred schedule
order over tasks. An online component enforces the schedule orders desired by
the various jobs running on the cluster. In addition, it packs tasks, overbooks
the fungible resources and guarantees bounded unfairness for a variety of
desirable fairness schemes. Relative to the state-of-the art schedulers, we
speed up 50% of the jobs by over 30% each.
</summary>
    <author>
      <name>Robert Grandl</name>
    </author>
    <author>
      <name>Srikanth Kandula</name>
    </author>
    <author>
      <name>Sriram Rao</name>
    </author>
    <author>
      <name>Aditya Akella</name>
    </author>
    <author>
      <name>Janardhan Kulkarni</name>
    </author>
    <link href="http://arxiv.org/abs/1604.07371v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.07371v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.04386v1</id>
    <updated>2016-06-14T14:22:25Z</updated>
    <published>2016-06-14T14:22:25Z</published>
    <title>A Note on the Period Enforcer Algorithm for Self-Suspending Tasks</title>
    <summary>  The period enforcer algorithm for self-suspending real-time tasks is a
technique for suppressing the "back-to-back" scheduling penalty associated with
deferred execution. Originally proposed in 1991, the algorithm has attracted
renewed interest in recent years. This note revisits the algorithm in the light
of recent developments in the analysis of self-suspending tasks, carefully
re-examines and explains its underlying assumptions and limitations, and points
out three observations that have not been made in the literature to date: (i)
period enforcement is not strictly superior (compared to the base case without
enforcement) as it can cause deadline misses in self-suspending task sets that
are schedulable without enforcement; (ii) to match the assumptions underlying
the analysis of the period enforcer, a schedulability analysis of
self-suspending tasks subject to period enforcement requires a task set
transformation for which no solution is known in the general case, and which is
subject to exponential time complexity (with current techniques) in the limited
case of a single self-suspending task; and (iii) the period enforcer algorithm
is incompatible with all existing analyses of suspension-based locking
protocols, and can in fact cause ever-increasing suspension times until a
deadline is missed.
</summary>
    <author>
      <name>Jian-Jia Chen</name>
    </author>
    <author>
      <name>Björn B. Brandenburg</name>
    </author>
    <link href="http://arxiv.org/abs/1606.04386v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.04386v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="C.3; D.4.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.00571v1</id>
    <updated>2016-08-01T15:33:14Z</updated>
    <published>2016-08-01T15:33:14Z</published>
    <title>TREES: A CPU/GPU Task-Parallel Runtime with Explicit Epoch
  Synchronization</title>
    <summary>  We have developed a task-parallel runtime system, called TREES, that is
designed for high performance on CPU/GPU platforms. On platforms with multiple
CPUs, Cilk's "work-first" principle underlies how task-parallel applications
can achieve performance, but work-first is a poor fit for GPUs. We build upon
work-first to create the "work-together" principle that addresses the specific
strengths and weaknesses of GPUs. The work-together principle extends
work-first by stating that (a) the overhead on the critical path should be paid
by the entire system at once and (b) work overheads should be paid
co-operatively. We have implemented the TREES runtime in OpenCL, and we
experimentally evaluate TREES applications on a CPU/GPU platform.
</summary>
    <author>
      <name>Blake A. Hechtman</name>
    </author>
    <author>
      <name>Andrew D. Hilton</name>
    </author>
    <author>
      <name>Daniel J. Sorin</name>
    </author>
    <link href="http://arxiv.org/abs/1608.00571v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.00571v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1608.04303v1</id>
    <updated>2016-08-15T15:26:22Z</updated>
    <published>2016-08-15T15:26:22Z</published>
    <title>SandBlaster: Reversing the Apple Sandbox</title>
    <summary>  In order to limit the damage of malware on Mac OS X and iOS, Apple uses
sandboxing, a kernel-level security layer that provides tight constraints for
system calls. Particularly used for Apple iOS, sandboxing prevents apps from
executing potentially dangerous actions, by defining rules in a sandbox
profile. Investigating Apple's built-in sandbox profiles is difficult as they
are compiled and stored in binary format. We present SandBlaster, a software
bundle that is able to reverse/decompile Apple binary sandbox profiles to their
original human readable SBPL (SandBox Profile Language) format. We use
SandBlaster to reverse all built-in Apple iOS binary sandbox profiles for iOS
7, 8 and 9. Our tool is, to the best of our knowledge, the first to provide a
full reversing of the Apple sandbox, shedding light into the inner workings of
Apple sandbox profiles and providing essential support for security researchers
and professionals interested in Apple security mechanisms.
</summary>
    <author>
      <name>Răzvan Deaconescu</name>
    </author>
    <author>
      <name>Luke Deshotels</name>
    </author>
    <author>
      <name>Mihai Bucicoiu</name>
    </author>
    <author>
      <name>William Enck</name>
    </author>
    <author>
      <name>Lucas Davi</name>
    </author>
    <author>
      <name>Ahmad-Reza Sadeghi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">25 pages, 9 figures, 14 listings This report is an auxiliary document
  to the paper "SandScout: Automatic Detection of Flaws in iOS Sandbox
  Profiles", to be presented at the ACM Conference on Computer and
  Communications Security (CCS) 2016</arxiv:comment>
    <link href="http://arxiv.org/abs/1608.04303v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1608.04303v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.4.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.00100v2</id>
    <updated>2016-09-03T22:40:31Z</updated>
    <published>2016-09-01T03:45:39Z</published>
    <title>Suspicious-Taint-Based Access Control for Protecting OS from Network
  Attacks</title>
    <summary>  Today, security threats to operating systems largely come from network.
Traditional discretionary access control mechanism alone can hardly defeat
them. Although traditional mandatory access control models can effectively
protect the security of OS, they have problems of being incompatible with
application software and complex in administration. In this paper, we propose a
new model, Suspicious-Taint-Based Access Control (STBAC) model, for defeating
network attacks while being compatible, simple and maintaining good system
performance. STBAC regards the processes using Non-Trustable-Communications as
the starting points of suspicious taint, traces the activities of the
suspiciously tainted processes by taint rules, and forbids the suspiciously
tainted processes to illegally access vital resources by protection rules. Even
in the cases when some privileged processes are subverted, STBAC can still
protect vital resources from being compromised by the intruder. We implemented
the model in the Linux kernel and evaluated it through experiments. The
evaluation showed that STBAC could protect vital resources effectively without
significant impact on compatibility and performance.
</summary>
    <author>
      <name>Zhiyong Shan</name>
    </author>
    <link href="http://arxiv.org/abs/1609.00100v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.00100v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1701.03709v1</id>
    <updated>2017-01-13T16:15:53Z</updated>
    <published>2017-01-13T16:15:53Z</published>
    <title>Power and Execution Time Measurement Methodology for SDF Applications on
  FPGA-based MPSoCs</title>
    <summary>  Timing and power consumption play an important role in the design of embedded
systems. Furthermore, both properties are directly related to the safety
requirements of many embedded systems. With regard to availability
requirements, power considerations are of uttermost importance for battery
operated systems. Validation of timing and power requires observability of
these properties. In many cases this is difficult, because the observability is
either not possible or requires big extra effort in the system validation
process. In this paper, we present a measurement-based approach for the joint
timing and power analysis of Synchronous Dataflow (SDF) applications running on
a shared memory multiprocessor systems-on-chip (MPSoC) architecture. As a
proof-of-concept, we implement an MPSoC system with configurable power and
timing measurement interfaces inside a Field Programmable Gate Array (FPGA).
Our experiments demonstrate the viability of our approach being able of
accurately analyzing different mappings of image processing applications (Sobel
filter and JPEG encoder) on an FPGA-based MPSoC implementation.
</summary>
    <author>
      <name>Christof Schlaak</name>
    </author>
    <author>
      <name>Maher Fakih</name>
    </author>
    <author>
      <name>Ralf Stemmer</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Presented at HIP3ES, 2017 7 pages, 6 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1701.03709v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1701.03709v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68M20" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.02925v1</id>
    <updated>2017-03-08T17:26:02Z</updated>
    <published>2017-03-08T17:26:02Z</published>
    <title>Assessing Code Authorship: The Case of the Linux Kernel</title>
    <summary>  Code authorship is a key information in large-scale open source systems.
Among others, it allows maintainers to assess division of work and identify key
collaborators. Interestingly, open-source communities lack guidelines on how to
manage authorship. This could be mitigated by setting to build an empirical
body of knowledge on how authorship-related measures evolve in successful
open-source communities. Towards that direction, we perform a case study on the
Linux kernel. Our results show that: (a) only a small portion of developers (26
%) makes significant contributions to the code base; (b) the distribution of
the number of files per author is highly skewed --- a small group of top
authors (3 %) is responsible for hundreds of files, while most authors (75 %)
are responsible for at most 11 files; (c) most authors (62 %) have a specialist
profile; (d) authors with a high number of co-authorship connections tend to
collaborate with others with less connections.
</summary>
    <author>
      <name>Guilherme Avelino</name>
    </author>
    <author>
      <name>Leonardo Passos</name>
    </author>
    <author>
      <name>Andre Hora</name>
    </author>
    <author>
      <name>Marco Tulio Valente</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted at 13th International Conference on Open Source Systems
  (OSS). 12 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1703.02925v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.02925v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1703.08469v1</id>
    <updated>2017-03-24T15:38:17Z</updated>
    <published>2017-03-24T15:38:17Z</published>
    <title>Virtualization technology for distributed time sensitive domains</title>
    <summary>  This paper reports on the state of the art of virtualization technology for
both general purpose domains as well as real-time domains. There exits no
entirely instantaneous data transmission/transfer. There always exist a delay
while transmitting data, either in the processing or in the medium itself.
However most systems are designed to function appropriately with a delay
tolerance. This delay, inevitably, is affected when operating with an extra
layer, the virtualization. For real time systems it is crucial to know the
temporal limits in order not to surpass them. Introducing virtualization in the
real-time domain therefore requires deeper analysis by making use of techniques
that will offer results with deterministic execution times. The study of time
in systems and its behaviour under various possible circumstances is hence a
key for properly assessing this technology applied to both domains, especially
the real-time domain.
</summary>
    <author>
      <name>Carlos Antonio Perea-Gómez</name>
    </author>
    <link href="http://arxiv.org/abs/1703.08469v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1703.08469v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.02561v1</id>
    <updated>2017-05-07T04:07:10Z</updated>
    <published>2017-05-07T04:07:10Z</published>
    <title>A Reconnaissance Attack Mechanism for Fixed-Priority Real-Time Systems</title>
    <summary>  In real-time embedded systems (RTS), failures due to security breaches can
cause serious damage to the system, the environment and/or injury to humans.
Therefore, it is very important to understand the potential threats and attacks
against these systems. In this paper we present a novel reconnaissance attack
that extracts the exact schedule of real-time systems designed using fixed
priority scheduling algorithms. The attack is demonstrated on both a real
hardware platform and a simulator, with a high success rate. Our evaluation
results show that the algorithm is robust even in the presence of execution
time variation.
</summary>
    <author>
      <name>Chien-Ying Chen</name>
    </author>
    <author>
      <name>AmirEmad Ghassami</name>
    </author>
    <author>
      <name>Sibin Mohan</name>
    </author>
    <author>
      <name>Negar Kiyavash</name>
    </author>
    <author>
      <name>Rakesh B. Bobba</name>
    </author>
    <author>
      <name>Rodolfo Pellizzoni</name>
    </author>
    <author>
      <name>Man-Ki Yoon</name>
    </author>
    <link href="http://arxiv.org/abs/1705.02561v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.02561v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.07400v1</id>
    <updated>2017-05-21T05:51:21Z</updated>
    <published>2017-05-21T05:51:21Z</published>
    <title>MITHRIL: Mining Sporadic Associations for Cache Prefetching</title>
    <summary>  The growing pressure on cloud application scalability has accentuated storage
performance as a critical bottle- neck. Although cache replacement algorithms
have been extensively studied, cache prefetching - reducing latency by
retrieving items before they are actually requested remains an underexplored
area. Existing approaches to history-based prefetching, in particular, provide
too few benefits for real systems for the resources they cost. We propose
MITHRIL, a prefetching layer that efficiently exploits historical patterns in
cache request associations. MITHRIL is inspired by sporadic association rule
mining and only relies on the timestamps of requests. Through evaluation of 135
block-storage traces, we show that MITHRIL is effective, giving an average of a
55% hit ratio increase over LRU and PROBABILITY GRAPH, a 36% hit ratio gain
over AMP at reasonable cost. We further show that MITHRIL can supplement any
cache replacement algorithm and be readily integrated into existing systems.
Furthermore, we demonstrate the improvement comes from MITHRIL being able to
capture mid-frequency blocks.
</summary>
    <author>
      <name>Juncheng Yang</name>
    </author>
    <author>
      <name>Reza Karimi</name>
    </author>
    <author>
      <name>Trausti Sæmundsson</name>
    </author>
    <author>
      <name>Avani Wildani</name>
    </author>
    <author>
      <name>Ymir Vigfusson</name>
    </author>
    <link href="http://arxiv.org/abs/1705.07400v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.07400v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.05082v2</id>
    <updated>2017-07-18T05:17:14Z</updated>
    <published>2017-07-17T10:38:13Z</published>
    <title>Downgrade Attack on TrustZone</title>
    <summary>  Security-critical tasks require proper isolation from untrusted software.
Chip manufacturers design and include trusted execution environments (TEEs) in
their processors to secure these tasks. The integrity and security of the
software in the trusted environment depend on the verification process of the
system.
  We find a form of attack that can be performed on the current implementations
of the widely deployed ARM TrustZone technology. The attack exploits the fact
that the trustlet (TA) or TrustZone OS loading verification procedure may use
the same verification key and may lack proper rollback prevention across
versions. If an exploit works on an out-of-date version, but the vulnerability
is patched on the latest version, an attacker can still use the same exploit to
compromise the latest system by downgrading the software to an older and
exploitable version.
  We did experiments on popular devices on the market including those from
Google, Samsung and Huawei, and found that all of them have the risk of being
attacked. Also, we show a real-world example to exploit Qualcomm's QSEE.
  In addition, in order to find out which device images share the same
verification key, pattern matching schemes for different vendors are analyzed
and summarized.
</summary>
    <author>
      <name>Yue Chen</name>
    </author>
    <author>
      <name>Yulong Zhang</name>
    </author>
    <author>
      <name>Zhi Wang</name>
    </author>
    <author>
      <name>Tao Wei</name>
    </author>
    <link href="http://arxiv.org/abs/1707.05082v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.05082v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.4.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/9908002v1</id>
    <updated>1999-08-03T14:50:09Z</updated>
    <published>1999-08-03T14:50:09Z</published>
    <title>After Compilers and Operating Systems : The Third Advance in Application
  Support</title>
    <summary>  After compilers and operating systems, TSIAs are the third advance in
application support. A compiler supports a high level application definition in
a programming language. An operating system supports a high level interface to
the resources used by an application execution. A Task System and Item
Architecture (TSIA) provides an application with a transparent reliable,
distributed, heterogeneous, adaptive, dynamic, real-time, interactive,
parallel, secure or other execution. In addition to supporting the application
execution, a TSIA also supports the application definition. This run-time
support for the definition is complementary to the compile-time support of a
compiler. For example, this allows a language similar to Fortran or C to
deliver features promised by functional computing. While many TSIAs exist, they
previously have not been recognized as such and have served only a particular
type of application. Existing TSIAs and other projects demonstrate that TSIAs
are feasible for most applications. As the next paradigm for application
support, the TSIA simplifies and unifies existing computing practice and
research. By solving many outstanding problems, the TSIA opens many, many new
opportunities for computing.
</summary>
    <author>
      <name>Burkhard D. Burow</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages including 13 figures of diagrams and code examples. Based on
  invited seminars held in May-July 1999 at IBM, Caltech and elsewhere. For
  further information see http://www.tsia.org</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/9908002v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/9908002v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="A.1;D.1.1;D.1.3;D.1.4;D.2.11;D.3.2;D.3.3;D.3.4;D.4.5;D.4.7;E.1;F.1.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0006014v1</id>
    <updated>2000-06-08T16:50:24Z</updated>
    <published>2000-06-08T16:50:24Z</published>
    <title>Solaris System Resource Manager: All I Ever Wanted Was My Unfair
  Advantage (And Why You Can't Have It!)</title>
    <summary>  Traditional UNIX time-share schedulers attempt to be fair to all users by
employing a round-robin style algorithm for allocating CPU time. Unfortunately,
a loophole exists whereby the scheduler can be biased in favor of a greedy user
running many short CPU-time processes. This loophole is not a defect but an
intrinsic property of the round-robin scheduler that ensures responsiveness to
the short CPU demands associated with multiple interactive users. A new
generation of UNIX system resource management software constrains the scheduler
to be equitable to all users regardless of the number of processes each may be
running. This "fair-share" scheduling draws on the concept of pro rating
resource "shares" across users and groups and then dynamically adjusting CPU
usage to meet those share proportions. The simple notion of statically
allocating these shares, however, belies the potential consequences for
performance as measured by user response time and service level targets. We
demonstrate this point by modeling several simple share allocation scenarios
and analyzing the corresponding performance effects. A brief comparison of
commercial system resource management implementations from HP, IBM, and SUN is
also given.
</summary>
    <author>
      <name>Neil J. Gunther</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages, Updated since the 25th Computer Measurement Group
  Conference, Reno NV, Dec.5-10, 1999</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. CMG'99 Conf. p.194-205</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0006014v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0006014v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="C.4;D.4.1;D.4.8" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0210031v1</id>
    <updated>2002-10-31T01:51:00Z</updated>
    <published>2002-10-31T01:51:00Z</published>
    <title>The Weaves Reconfigurable Programming Framework</title>
    <summary>  This research proposes a language independent intra-process framework for
object based composition of unmodified code modules. Intuitively, the two major
programming models, threads and processes, can be considered as extremes along
a sharing axis. Multiple threads through a process share all global state,
whereas instances of a process (or independent processes) share no global
state. Weaves provide the generalized framework that allows arbitrary
(selective) sharing of state between multiple control flows through a process.
The Weaves framework supports multiple independent components in a single
process, with flexible state sharing and scheduling, all of which is achieved
without requiring any modification to existing code bases. Furthermore, the
framework allows dynamic instantiation of code modules and control flows
through them. In effect, weaves create intra-process modules (similar to
objects in OOP) from code written in any language. The Weaves paradigm allows
objects to be arbitrarily shared, it is a true superset of both processes as
well as threads, with code sharing and fast context switching time similar to
threads. Weaves does not require any special support from either the language
or application code, practically any code can be weaved. Weaves also include
support for fast automatic checkpointing and recovery with no application
support. This paper presents the elements of the Weaves framework and results
from our implementation that works by reverse-analyzing source-code independent
ELF object files. The current implementation has been validated over Sweep3D, a
benchmark for 3D discrete ordinates neutron transport [Koch et al., 1992], and
a user-level port of the Linux 2.4 family kernel TCP/IP protocol stack.
</summary>
    <author>
      <name>Srinidhi Varadarajan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">To be submitted to ACM TOCS</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0210031v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0210031v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.2.11 D.2.12 D.1.3 D.3.2 D.3.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0603076v1</id>
    <updated>2006-03-18T17:27:22Z</updated>
    <published>2006-03-18T17:27:22Z</published>
    <title>User-Relative Names for Globally Connected Personal Devices</title>
    <summary>  Nontechnical users who own increasingly ubiquitous network-enabled personal
devices such as laptops, digital cameras, and smart phones need a simple,
intuitive, and secure way to share information and services between their
devices. User Information Architecture, or UIA, is a novel naming and
peer-to-peer connectivity architecture addressing this need. Users assign UIA
names by "introducing" devices to each other on a common local-area network,
but these names remain securely bound to their target as devices migrate.
Multiple devices owned by the same user, once introduced, automatically merge
their namespaces to form a distributed "personal cluster" that the owner can
access or modify from any of his devices. Instead of requiring users to
allocate globally unique names from a central authority, UIA enables users to
assign their own "user-relative" names both to their own devices and to other
users. With UIA, for example, Alice can always access her iPod from any of her
own personal devices at any location via the name "ipod", and her friend Bob
can access her iPod via a relative name like "ipod.Alice".
</summary>
    <author>
      <name>Bryan Ford</name>
    </author>
    <author>
      <name>Jacob Strauss</name>
    </author>
    <author>
      <name>Chris Lesniewski-Laas</name>
    </author>
    <author>
      <name>Sean Rhea</name>
    </author>
    <author>
      <name>Frans Kaashoek</name>
    </author>
    <author>
      <name>Robert Morris</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, 1 figure, 1 table</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">5th International Workshop on Peer-to-Peer Systems, February 2006
  (IPTPS 2006), Santa Barbara, CA</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0603076v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0603076v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="C.2.1; C.2.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0611116v1</id>
    <updated>2006-11-22T18:25:43Z</updated>
    <published>2006-11-22T18:25:43Z</published>
    <title>Discovering Network Topology in the Presence of Byzantine Faults</title>
    <summary>  We study the problem of Byzantine-robust topology discovery in an arbitrary
asynchronous network. We formally state the weak and strong versions of the
problem. The weak version requires that either each node discovers the topology
of the network or at least one node detects the presence of a faulty node. The
strong version requires that each node discovers the topology regardless of
faults. We focus on non-cryptographic solutions to these problems. We explore
their bounds. We prove that the weak topology discovery problem is solvable
only if the connectivity of the network exceeds the number of faults in the
system. Similarly, we show that the strong version of the problem is solvable
only if the network connectivity is more than twice the number of faults. We
present solutions to both versions of the problem. The presented algorithms
match the established graph connectivity bounds. The algorithms do not require
the individual nodes to know either the diameter or the size of the network.
The message complexity of both programs is low polynomial with respect to the
network size. We describe how our solutions can be extended to add the property
of termination, handle topology changes and perform neighborhood discovery.
</summary>
    <author>
      <name>Mikhail Nesterenko</name>
    </author>
    <author>
      <name>Sébastien Tixeuil</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/11780823_17</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/11780823_17" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">13th Colloquium on Structural Information and Communication
  Complexity (SIROCCO), LNCS Volume 4056 pp. 212-226, Chester, UK, July 2006</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/cs/0611116v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0611116v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0903.2525v1</id>
    <updated>2009-03-14T04:28:55Z</updated>
    <published>2009-03-14T04:28:55Z</published>
    <title>CloudSim: A Novel Framework for Modeling and Simulation of Cloud
  Computing Infrastructures and Services</title>
    <summary>  Cloud computing focuses on delivery of reliable, secure, fault-tolerant,
sustainable, and scalable infrastructures for hosting Internet-based
application services. These applications have different composition,
configuration, and deployment requirements. Quantifying the performance of
scheduling and allocation policy on a Cloud infrastructure (hardware, software,
services) for different application and service models under varying load,
energy performance (power consumption, heat dissipation), and system size is an
extremely challenging problem to tackle. To simplify this process, in this
paper we propose CloudSim: a new generalized and extensible simulation
framework that enables seamless modelling, simulation, and experimentation of
emerging Cloud computing infrastructures and management services. The
simulation framework has the following novel features: (i) support for
modelling and instantiation of large scale Cloud computing infrastructure,
including data centers on a single physical computing node and java virtual
machine; (ii) a self-contained platform for modelling data centers, service
brokers, scheduling, and allocations policies; (iii) availability of
virtualization engine, which aids in creation and management of multiple,
independent, and co-hosted virtualized services on a data center node; and (iv)
flexibility to switch between space-shared and time-shared allocation of
processing cores to virtualized services.
</summary>
    <author>
      <name>Rodrigo N. Calheiros</name>
    </author>
    <author>
      <name>Rajiv Ranjan</name>
    </author>
    <author>
      <name>Cesar A. F. De Rose</name>
    </author>
    <author>
      <name>Rajkumar Buyya</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 9 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0903.2525v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0903.2525v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="C.2.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/0910.4052v1</id>
    <updated>2009-10-21T11:31:14Z</updated>
    <published>2009-10-21T11:31:14Z</published>
    <title>Virtual-Threading: Advanced General Purpose Processors Architecture</title>
    <summary>  The paper describes the new computers architecture, the main features of
which has been claimed in the Russian Federation patent 2312388 and in the US
patent application 11/991331. This architecture is intended to effective
support of the General Purpose Parallel Computing (GPPC), the essence of which
is extremely frequent switching of threads between states of activity and
states of viewed in the paper the algorithmic latency. To emphasize the same
impact of the architectural latency and the algorithmic latency upon GPPC, is
introduced the new notion of the generalized latency and is defined its
quantitative measure - the Generalized Latency Tolerance (GLT). It is shown
that a well suited for GPPC implementation architecture should have high level
of GLT and is described such architecture, which is called the Virtual-Threaded
Machine. This architecture originates a processor virtualization in the
direction of activities virtualization, which is orthogonal to the well-known
direction of memory virtualization. The key elements of the architecture are 1)
the distributed fine grain representation of the architectural register file,
which elements are hardware swapped through levels of a microarchitectural
memory, 2) the prioritized fine grain direct hardware multiprogramming, 3) the
access controlled virtual addressing and 4) the hardware driven semaphores. The
composition of these features lets to introduce new styles of operating system
(OS) programming, which is free of interruptions, and of applied programming
with a very rare using the OS services.
</summary>
    <author>
      <name>Andrei I. Yafimau</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">56 pages, 5 PNG figures</arxiv:comment>
    <link href="http://arxiv.org/abs/0910.4052v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0910.4052v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="C.1.2; D.4.1; D.4.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1002.0298v1</id>
    <updated>2010-02-01T18:31:06Z</updated>
    <published>2010-02-01T18:31:06Z</published>
    <title>A Data Capsule Framework For Web Services: Providing Flexible Data
  Access Control To Users</title>
    <summary>  This paper introduces the notion of a secure data capsule, which refers to an
encapsulation of sensitive user information (such as a credit card number)
along with code that implements an interface suitable for the use of such
information (such as charging for purchases) by a service (such as an online
merchant). In our capsule framework, users provide their data in the form of
such capsules to web services rather than raw data. Capsules can be deployed in
a variety of ways, either on a trusted third party or the user's own computer
or at the service itself, through the use of a variety of hardware or software
modules, such as a virtual machine monitor or trusted platform module: the only
requirement is that the deployment mechanism must ensure that the user's data
is only accessed via the interface sanctioned by the user. The framework
further allows an user to specify policies regarding which services or machines
may host her capsule, what parties are allowed to access the interface, and
with what parameters. The combination of interface restrictions and policy
control lets us bound the impact of an attacker who compromises the service to
gain access to the user's capsule or a malicious insider at the service itself.
</summary>
    <author>
      <name>Jayanthkumar Kannan</name>
    </author>
    <author>
      <name>Petros Maniatis</name>
    </author>
    <author>
      <name>Byung-Gon Chun</name>
    </author>
    <link href="http://arxiv.org/abs/1002.0298v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1002.0298v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.4.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1012.3071v1</id>
    <updated>2010-12-14T16:10:08Z</updated>
    <published>2010-12-14T16:10:08Z</published>
    <title>Seamless Flow Migration on Smartphones without Network Support</title>
    <summary>  This paper addresses the following question: Is it possible to migrate TCP/IP
flows between different networks on modern mobile devices, without
infrastructure support or protocol changes? To answer this question, we make
three research contributions. (i) We report a comprehensive characterization of
IP traffic on smartphones using traces collected from 27 iPhone 3GS users for
three months. (ii) Driven by the findings from the characterization, we devise
two novel system mechanisms for mobile devices to sup-port seamless flow
migration without network support, and extensively evaluate their effectiveness
using our field collected traces of real-life usage. Wait-n-Migrate leverages
the fact that most flows are short lived. It establishes new flows on newly
available networks but allows pre-existing flows on the old network to
terminate naturally, effectively decreasing, or even eliminating, connectivity
gaps during network switches. Resumption Agent takes advantage of the
functionality integrated into many modern protocols to securely resume flows
without application intervention. When combined, Wait-n-Migrate and Resumption
Agent provide an unprecedented opportunity to immediately deploy performance
and efficiency-enhancing policies that leverage multiple networks to improve
the performance, efficiency, and connectivity of mobile devices. (iii) Finally,
we report an iPhone 3GS based implementation of these two system mechanisms and
show that their overhead is negligible. Furthermore, we employ an example
network switching policy, called AutoSwitch, to demonstrate their performance.
AutoSwitch improves the Wi-Fi user experience by intelligently migrating TCP
flows between Wi-Fi and cellular networks. Through traces and field
measurements, we show that AutoSwitch reduces the number of user disruptions by
an order of magnitude.
</summary>
    <author>
      <name>Ahmad Rahmati</name>
    </author>
    <author>
      <name>Clay Shepard</name>
    </author>
    <author>
      <name>Chad Tossell</name>
    </author>
    <author>
      <name>Angela Nicoara</name>
    </author>
    <author>
      <name>Lin Zhong</name>
    </author>
    <author>
      <name>Phil Kortum</name>
    </author>
    <author>
      <name>Jatinder Singh</name>
    </author>
    <link href="http://arxiv.org/abs/1012.3071v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1012.3071v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1105.3232v1</id>
    <updated>2011-05-16T21:45:54Z</updated>
    <published>2011-05-16T21:45:54Z</published>
    <title>Unleashing the Power of Mobile Cloud Computing using ThinkAir</title>
    <summary>  Smartphones have exploded in popularity in recent years, becoming ever more
sophisticated and capable. As a result, developers worldwide are building
increasingly complex applications that require ever increasing amounts of
computational power and energy. In this paper we propose ThinkAir, a framework
that makes it simple for developers to migrate their smartphone applications to
the cloud. ThinkAir exploits the concept of smartphone virtualization in the
cloud and provides method level computation offloading. Advancing on previous
works, it focuses on the elasticity and scalability of the server side and
enhances the power of mobile cloud computing by parallelizing method execution
using multiple Virtual Machine (VM) images. We evaluate the system using a
range of benchmarks starting from simple micro-benchmarks to more complex
applications. First, we show that the execution time and energy consumption
decrease two orders of magnitude for the N-queens puzzle and one order of
magnitude for a face detection and a virus scan application, using cloud
offloading. We then show that if a task is parallelizable, the user can request
more than one VM to execute it, and these VMs will be provided dynamically. In
fact, by exploiting parallelization, we achieve a greater reduction on the
execution time and energy consumption for the previous applications. Finally,
we use a memory-hungry image combiner tool to demonstrate that applications can
dynamically request VMs with more computational power in order to meet their
computational requirements.
</summary>
    <author>
      <name>Sokol Kosta</name>
    </author>
    <author>
      <name>Andrius Aucinas</name>
    </author>
    <author>
      <name>Pan Hui</name>
    </author>
    <author>
      <name>Richard Mortier</name>
    </author>
    <author>
      <name>Xinwen Zhang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1105.3232v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1105.3232v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1107.2003v2</id>
    <updated>2011-07-12T08:46:58Z</updated>
    <published>2011-07-11T11:51:06Z</published>
    <title>Efficient Deterministic Replay Using Complete Race Detection</title>
    <summary>  Data races can significantly affect the executions of multi-threaded
programs. Hence, one has to recur the results of data races to
deterministically replay a multi-threaded program. However, data races are
concealed in enormous number of memory operations in a program. Due to the
difficulty of accurately identifying data races, previous multi-threaded
deterministic record/replay schemes for commodity multi-processor system give
up to record data races directly. Consequently, they either record all shared
memory operations, which brings remarkable slowdown to the production run, or
record the synchronization only, which introduces significant efforts to
replay.
  Inspired by the advances in data race detection, we propose an efficient
software-only deterministic replay scheme for commodity multi-processor
systems, which is named RacX. The key insight of RacX is as follows: although
it is NP-hard to accurately identify the existence of data races between a pair
of memory operations, we can find out all potential data races in a
multi-threaded program, in which the false positives can be reduced to a small
amount with our automatic false positive reduction techniques. As a result,
RacX can efficiently monitor all potential data races to deterministically
replay a multi-threaded program.
  To evaluate RacX, we have carried out experiments over a number of well-known
multi-threaded programs from SPLASH-2 benchmark suite and large-scale
commercial programs. RacX can precisely recur production runs of these programs
with value determinism. Averagely, RacX causes only about 1.21%, 1.89%, 2.20%,
and 8.41% slowdown to the original run during recording (for 2-, 4-, 8- and
16-thread programs, respectively). The soundness, efficiency, scalability, and
portability of RacX well demonstrate its superiority.
</summary>
    <author>
      <name>Qi Guo</name>
    </author>
    <author>
      <name>Yunji Chen</name>
    </author>
    <author>
      <name>Tianshi chen</name>
    </author>
    <author>
      <name>Ling Li</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1107.2003v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1107.2003v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1206.6213v1</id>
    <updated>2012-06-27T09:33:06Z</updated>
    <published>2012-06-27T09:33:06Z</published>
    <title>The Necessity for Hardware QoS Support for Server Consolidation and
  Cloud Computing</title>
    <summary>  Chip multiprocessors (CMPs) are ubiquitous in most of today's computing
fields. Although they provide noticeable benefits in terms of performance, cost
and power efficiency, they also introduce some new issues. In this paper we
analyze how the interference from Virtual Private Servers running in other
cores is a significant component of performance unpredictability and can
threaten the attainment of cloud computing. Even if virtualization is used, the
sharing of the on-chip section of the memory hierarchy by different cores makes
performance isolation strongly dependent on what is running elsewhere in the
system. We will show in three actual computing systems, based on Sun UltraSparc
T1, Sun UltraSparc T2 and Intel Xeon processors, how state-of-the-art
virtualization techniques are unable to guarantee performance isolation in a
representative workload such as SPECweb2005. In an especially conceived near
worst-case scenario, it is possible to reduce the performance achieved by a
Solaris Zones consolidated server for this suite of benchmarks in a Sun Fire
T1000 and a Sun Enterprise T5120 by up to 80%. The performance drop observed by
a Xen consolidated server running in a HP Proliant DL160 G5 is almost 45%. For
all systems under study, off-chip bandwidth is shown to be the most critical
resource.
</summary>
    <author>
      <name>Javier Merino</name>
    </author>
    <author>
      <name>Valentin Puente</name>
    </author>
    <author>
      <name>José Ángel Gregorio</name>
    </author>
    <link href="http://arxiv.org/abs/1206.6213v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1206.6213v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1209.0687v1</id>
    <updated>2012-09-04T16:16:20Z</updated>
    <published>2012-09-04T16:16:20Z</published>
    <title>Security Issues in the Android Cross-Layer Architecture</title>
    <summary>  The security of Android has been recently challenged by the discovery of a
number of vulnerabilities involving different layers of the Android stack. We
argue that such vulnerabilities are largely related to the interplay among
layers composing the Android stack. Thus, we also argue that such interplay has
been underestimated from a security point-of-view and a systematic analysis of
the Android interplay has not been carried out yet. To this aim, in this paper
we provide a simple model of the Android cross-layer interactions based on the
concept of flow, as a basis for analyzing the Android interplay. In particular,
our model allows us to reason about the security implications associated with
the cross-layer interactions in Android, including a recently discovered
vulnerability that allows a malicious application to make Android devices
totally unresponsive. We used the proposed model to carry out an empirical
assessment of some flows within the Android cross-layered architecture. Our
experiments indicate that little control is exercised by the Android Security
Framework (ASF) over cross-layer interactions in Android. In particular, we
observed that the ASF lacks in discriminating the originator of a flow and
sensitive security issues arise between the Android stack and the Linux kernel,
thereby indicating that the attack surface of the Android platform is wider
than expected.
</summary>
    <author>
      <name>Alessandro Armando</name>
    </author>
    <author>
      <name>Alessio Merlo</name>
    </author>
    <author>
      <name>Luca Verderame</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">7 pages, double column, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1209.0687v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1209.0687v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.4.2; C.1.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1211.6196v1</id>
    <updated>2012-11-27T02:37:28Z</updated>
    <published>2012-11-27T02:37:28Z</published>
    <title>Chiefly Symmetric: Results on the Scalability of Probabilistic Model
  Checking for Operating-System Code</title>
    <summary>  Reliability in terms of functional properties from the safety-liveness
spectrum is an indispensable requirement of low-level operating-system (OS)
code. However, with evermore complex and thus less predictable hardware,
quantitative and probabilistic guarantees become more and more important.
Probabilistic model checking is one technique to automatically obtain these
guarantees. First experiences with the automated quantitative analysis of
low-level operating-system code confirm the expectation that the naive
probabilistic model checking approach rapidly reaches its limits when
increasing the numbers of processes. This paper reports on our work-in-progress
to tackle the state explosion problem for low-level OS-code caused by the
exponential blow-up of the model size when the number of processes grows. We
studied the symmetry reduction approach and carried out our experiments with a
simple test-and-test-and-set lock case study as a representative example for a
wide range of protocols with natural inter-process dependencies and long-run
properties. We quickly see a state-space explosion for scenarios where
inter-process dependencies are insignificant. However, once inter-process
dependencies dominate the picture models with hundred and more processes can be
constructed and analysed.
</summary>
    <author>
      <name>Christel Baier</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">TU Dresden</arxiv:affiliation>
    </author>
    <author>
      <name>Marcus Daum</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">TU Dresden</arxiv:affiliation>
    </author>
    <author>
      <name>Benjamin Engel</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">TU Dresden</arxiv:affiliation>
    </author>
    <author>
      <name>Hermann Härtig</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">TU Dresden</arxiv:affiliation>
    </author>
    <author>
      <name>Joachim Klein</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">TU Dresden</arxiv:affiliation>
    </author>
    <author>
      <name>Sascha Klüppelholz</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">TU Dresden</arxiv:affiliation>
    </author>
    <author>
      <name>Steffen Märcker</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">TU Dresden</arxiv:affiliation>
    </author>
    <author>
      <name>Hendrik Tews</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">TU Dresden</arxiv:affiliation>
    </author>
    <author>
      <name>Marcus Völp</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">TU Dresden</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.102.14</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.102.14" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings SSV 2012, arXiv:1211.5873</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 102, 2012, pp. 156-166</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1211.6196v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1211.6196v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.2778v1</id>
    <updated>2012-12-12T11:37:48Z</updated>
    <published>2012-12-12T11:37:48Z</published>
    <title>Feasibility Tests for Recurrent Real-Time Tasks in the Sporadic DAG
  Model</title>
    <summary>  A model has been proposed in [Baruah et al., in Proceedings of the IEEE
Real-Time Systems Symposium 2012] for representing recurrent
precedence-constrained tasks to be executed on multiprocessor platforms, where
each recurrent task is modeled by a directed acyclic graph (DAG), a period, and
a relative deadline. Each vertex of the DAG represents a sequential job, while
the edges of the DAG represent precedence constraints between these jobs. All
the jobs of the DAG are released simultaneously and have to be completed within
some specified relative deadline. The task may release jobs in this manner an
unbounded number of times, with successive releases occurring at least the
specified period apart. The feasibility problem is to determine whether such a
recurrent task can be scheduled to always meet all deadlines on a specified
number of dedicated processors.
  The case of a single task has been considered in [Baruah et al., 2012]. The
main contribution of this paper is to consider the case of multiple tasks. We
show that EDF has a speedup bound of 2-1/m, where m is the number of
processors. Moreover, we present polynomial and pseudopolynomial schedulability
tests, of differing effectiveness, for determining whether a set of sporadic
DAG tasks can be scheduled by EDF to meet all deadlines on a specified number
of processors.
</summary>
    <author>
      <name>Vincenzo Bonifaci</name>
    </author>
    <author>
      <name>Alberto Marchetti-Spaccamela</name>
    </author>
    <author>
      <name>Sebastian Stiller</name>
    </author>
    <author>
      <name>Andreas Wiese</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/ECRTS.2013.32</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/ECRTS.2013.32" rel="related"/>
    <link href="http://arxiv.org/abs/1212.2778v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.2778v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.4.1; F.2.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1302.1306v1</id>
    <updated>2013-02-06T10:06:39Z</updated>
    <published>2013-02-06T10:06:39Z</published>
    <title>Parametric Schedulability Analysis of Fixed Priority Real-Time
  Distributed Systems</title>
    <summary>  Parametric analysis is a powerful tool for designing modern embedded systems,
because it permits to explore the space of design parameters, and to check the
robustness of the system with respect to variations of some uncontrollable
variable. In this paper, we address the problem of parametric schedulability
analysis of distributed real-time systems scheduled by fixed priority. In
particular, we propose two different approaches to parametric analysis: the
first one is a novel technique based on classical schedulability analysis,
whereas the second approach is based on model checking of Parametric Timed
Automata (PTA).
  The proposed analytic method extends existing sensitivity analysis for single
processors to the case of a distributed system, supporting preemptive and
non-preemptive scheduling, jitters and unconstrained deadlines. Parametric
Timed Automata are used to model all possible behaviours of a distributed
system, and therefore it is a necessary and sufficient analysis. Both
techniques have been implemented in two software tools, and they have been
compared with classical holistic analysis on two meaningful test cases. The
results show that the analytic method provides results similar to classical
holistic analysis in a very efficient way, whereas the PTA approach is slower
but covers the entire space of solutions.
</summary>
    <author>
      <name>Youcheng Sun</name>
    </author>
    <author>
      <name>Romain Soulat</name>
    </author>
    <author>
      <name>Giuseppe Lipari</name>
    </author>
    <author>
      <name>Étienne André</name>
    </author>
    <author>
      <name>Laurent Fribourg</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to ECRTS 2013 (http://ecrts.eit.uni-kl.de/ecrts13)</arxiv:comment>
    <link href="http://arxiv.org/abs/1302.1306v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1302.1306v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.6007v1</id>
    <updated>2013-04-22T16:23:24Z</updated>
    <published>2013-04-22T16:23:24Z</published>
    <title>Paging with dynamic memory capacity</title>
    <summary>  We study a generalization of the classic paging problem that allows the
amount of available memory to vary over time - capturing a fundamental property
of many modern computing realities, from cloud computing to multi-core and
energy-optimized processors. It turns out that good performance in the
"classic" case provides no performance guarantees when memory capacity
fluctuates: roughly speaking, moving from static to dynamic capacity can mean
the difference between optimality within a factor 2 in space and time, and
suboptimality by an arbitrarily large factor. More precisely, adopting the
competitive analysis framework, we show that some online paging algorithms,
despite having an optimal (h,k)-competitive ratio when capacity remains
constant, are not (3,k)-competitive for any arbitrarily large k in the presence
of minimal capacity fluctuations. In this light it is surprising that several
classic paging algorithms perform remarkably well even if memory capacity
changes adversarially - even without taking those changes into explicit
account! In particular, we prove that LFD still achieves the minimum number of
faults, and that several classic online algorithms such as LRU have a "dynamic"
(h,k)-competitive ratio that is the best one can achieve without knowledge of
future page requests, even if one had perfect knowledge of future capacity
fluctuations (an exact characterization of this ratio shows it is almost,
albeit not quite, equal to the "classic" ratio k/(k-h+1)). In other words, with
careful management, knowing/predicting future memory resources appears far less
crucial to performance than knowing/predicting future data accesses.
</summary>
    <author>
      <name>Enoch Peserico</name>
    </author>
    <link href="http://arxiv.org/abs/1304.6007v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1304.6007v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1306.0846v1</id>
    <updated>2013-06-04T16:27:30Z</updated>
    <published>2013-06-04T16:27:30Z</published>
    <title>V-BOINC: The Virtualization of BOINC</title>
    <summary>  The Berkeley Open Infrastructure for Network Computing (BOINC) is an open
source client-server middleware system created to allow projects with large
computational requirements, usually set in the scientific domain, to utilize a
technically unlimited number of volunteer machines distributed over large
physical distances. However various problems exist deploying applications over
these heterogeneous machines using BOINC: applications must be ported to each
machine architecture type, the project server must be trusted to supply
authentic applications, applications that do not regularly checkpoint may lose
execution progress upon volunteer machine termination and applications that
have dependencies may find it difficult to run under BOINC.
  To solve such problems we introduce virtual BOINC, or V-BOINC, where virtual
machines are used to run computations on volunteer machines. Application
developers can then compile their applications on a single architecture,
checkpointing issues are solved through virtualization API's and many security
concerns are addressed via the virtual machine's sandbox environment. In this
paper we focus on outlining a unique approach on how virtualization can be
introduced into BOINC and demonstrate that V-BOINC offers acceptable
computational performance when compared to regular BOINC. Finally we show that
applications with dependencies can easily run under V-BOINC in turn increasing
the computational potential volunteer computing offers to the general public
and project developers.
</summary>
    <author>
      <name>Gary A. McGilvary</name>
    </author>
    <author>
      <name>Adam Barker</name>
    </author>
    <author>
      <name>Ashley Lloyd</name>
    </author>
    <author>
      <name>Malcolm Atkinson</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/CCGrid.2013.14</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/CCGrid.2013.14" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, Proceedings of the 13th IEEE/ACM International Symposium on
  Cluster, Cloud and Grid Computing (CCGrid 2013)</arxiv:comment>
    <link href="http://arxiv.org/abs/1306.0846v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1306.0846v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.0901v1</id>
    <updated>2013-10-03T05:51:48Z</updated>
    <published>2013-10-03T05:51:48Z</published>
    <title>Cudagrind: A Valgrind Extension for CUDA</title>
    <summary>  Valgrind, and specifically the included tool Memcheck, offers an easy and
reliable way for checking the correctness of memory operations in programs.
This works in an unintrusive way where Valgrind translates the program into
intermediate code and executes it on an emulated CPU. The heavy weight tool
Memcheck uses this to keep a full shadow copy of the memory used by a program
and tracking accesses to it. This allows the detection of memory leaks and
checking the validity of accesses.
  Though suited for a wide variety of programs, this approach still fails when
accelerator based programming models are involved. The code running on these
devices is separate from the code running on the host. Access to memory on the
device and starting of kernels is being handled by an API provided by the
driver being used. Hence Valgrind is unable to understand and instrument
operations being run on the device.
  To circumvent this limitation a new set of wrapper functions have been
introduced. These wrap a subset of the CUDA Driver API function that is
responsible for (de-)allocation memory regions on the device and the respective
memory copy operations. This allows to check whether memory is fully allocated
during a transfer and, through the functionality provided by Valgrind, whether
the memory transfered to the device from the host is defined and addressable.
Through this technique it is possible to detect a number of common programming
mistakes, which are very difficult to debug by other means. The combination of
these wrappers together with the Valgrind tool Memcheck is being called
Cudagrind.
</summary>
    <author>
      <name>Thomas M. Baumann</name>
    </author>
    <author>
      <name>Jose Gracia</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 2 figures, accepted for publication in ParCo 2013</arxiv:comment>
    <link href="http://arxiv.org/abs/1310.0901v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.0901v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1310.2148v1</id>
    <updated>2013-10-03T22:49:06Z</updated>
    <published>2013-10-03T22:49:06Z</published>
    <title>C2MS: Dynamic Monitoring and Management of Cloud Infrastructures</title>
    <summary>  Server clustering is a common design principle employed by many organisations
who require high availability, scalability and easier management of their
infrastructure. Servers are typically clustered according to the service they
provide whether it be the application(s) installed, the role of the server or
server accessibility for example. In order to optimize performance, manage load
and maintain availability, servers may migrate from one cluster group to
another making it difficult for server monitoring tools to continuously monitor
these dynamically changing groups. Server monitoring tools are usually
statically configured and with any change of group membership requires manual
reconfiguration; an unreasonable task to undertake on large-scale cloud
infrastructures.
  In this paper we present the Cloudlet Control and Management System (C2MS); a
system for monitoring and controlling dynamic groups of physical or virtual
servers within cloud infrastructures. The C2MS extends Ganglia - an open source
scalable system performance monitoring tool - by allowing system administrators
to define, monitor and modify server groups without the need for server
reconfiguration. In turn administrators can easily monitor group and individual
server metrics on large-scale dynamic cloud infrastructures where roles of
servers may change frequently. Furthermore, we complement group monitoring with
a control element allowing administrator-specified actions to be performed over
servers within service groups as well as introduce further customized
monitoring metrics. This paper outlines the design, implementation and
evaluation of the C2MS.
</summary>
    <author>
      <name>Gary A. McGilvary</name>
    </author>
    <author>
      <name>Josep Rius</name>
    </author>
    <author>
      <name>Íñigo Goiri</name>
    </author>
    <author>
      <name>Francesc Solsona</name>
    </author>
    <author>
      <name>Adam Barker</name>
    </author>
    <author>
      <name>Malcolm Atkinson</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/CloudCom.2013.45</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/CloudCom.2013.45" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the The 5th IEEE International Conference on Cloud
  Computing Technology and Science (CloudCom 2013), 8 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1310.2148v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1310.2148v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1311.2362v1</id>
    <updated>2013-11-11T06:21:29Z</updated>
    <published>2013-11-11T06:21:29Z</published>
    <title>Efficient Runtime Monitoring with Metric Temporal Logic: A Case Study in
  the Android Operating System</title>
    <summary>  We present a design and an implementation of a security policy specification
language based on metric linear-time temporal logic (MTL). MTL features
temporal operators that are indexed by time intervals, allowing one to specify
timing-dependent security policies. The design of the language is driven by the
problem of runtime monitoring of applications in mobile devices. A main case
the study is the privilege escalation attack in the Android operating system,
where an app gains access to certain resource or functionalities that are not
explicitly granted to it by the user, through indirect control flow. To capture
these attacks, we extend MTL with recursive definitions, that are used to
express call chains betwen apps. We then show how the metric operators of MTL,
in combination with recursive definitions, can be used to specify policies to
detect privilege escalation, under various fine grained constraints. We present
a new algorithm, extending that of linear time temporal logic, for monitoring
safety policies written in our specification language. The monitor does not
need to store the entire history of events generated by the apps, something
that is crucial for practical implementations. We modified the Android OS
kernel to allow us to insert our generated monitors modularly. We have tested
the modified OS on an actual device, and show that it is effective in detecting
policy violations.
</summary>
    <author>
      <name>Hendra Gunadi</name>
    </author>
    <author>
      <name>Alwen Tiu</name>
    </author>
    <link href="http://arxiv.org/abs/1311.2362v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1311.2362v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.3.1; D.4.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1401.6100v1</id>
    <updated>2014-01-09T00:04:41Z</updated>
    <published>2014-01-09T00:04:41Z</published>
    <title>Performance Impact of Lock-Free Algorithms on Multicore Communication
  APIs</title>
    <summary>  Data race conditions in multi-tasking software applications are prevented by
serializing access to shared memory resources, ensuring data consistency and
deterministic behavior. Traditionally tasks acquire and release locks to
synchronize operations on shared memory. Unfortunately, lock management can add
significant processing overhead especially for multicore deployments where
tasks on different cores convoy in queues waiting to acquire a lock.
Implementing more than one lock introduces the risk of deadlock and using
spinlocks constrains which cores a task can run on. The better alternative is
to eliminate locks and validate that real-time properties are met, which is not
directly considered in many embedded applications. Removing the locks is
non-trivial and packaging lock-free algorithms for developers reduces the
possibility of concurrency defects. This paper details how a multicore
communication API implementation is enhanced to support lock-free messaging and
the impact this has on data exchange latency between tasks. Throughput and
latency are compared on Windows and Linux between lock-based and lock-free
implementations for data exchange of messages, packets, and scalars. A model of
the lock-free exchange predicts performance at the system architecture level
and provides a stop criterion for the refactoring. The results show that
migration from single to multicore hardware architectures degrades lock-based
performance, and increases lock-free performance.
</summary>
    <author>
      <name>K. Eric Harper</name>
    </author>
    <author>
      <name>Thijmen de Gooijer</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages, 8 figures, 36 references, Embedded World Conference 2013</arxiv:comment>
    <link href="http://arxiv.org/abs/1401.6100v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1401.6100v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1406.5569v1</id>
    <updated>2014-06-21T02:04:56Z</updated>
    <published>2014-06-21T02:04:56Z</published>
    <title>On the Reverse Engineering of the Citadel Botnet</title>
    <summary>  Citadel is an advanced information-stealing malware which targets financial
information. This malware poses a real threat against the confidentiality and
integrity of personal and business data. A joint operation was recently
conducted by the FBI and the Microsoft Digital Crimes Unit in order to take
down Citadel command-and-control servers. The operation caused some disruption
in the botnet but has not stopped it completely. Due to the complex structure
and advanced anti-reverse engineering techniques, the Citadel malware analysis
process is both challenging and time-consuming. This allows cyber criminals to
carry on with their attacks while the analysis is still in progress. In this
paper, we present the results of the Citadel reverse engineering and provide
additional insight into the functionality, inner workings, and open source
components of the malware. In order to accelerate the reverse engineering
process, we propose a clone-based analysis methodology. Citadel is an offspring
of a previously analyzed malware called Zeus; thus, using the former as a
reference, we can measure and quantify the similarities and differences of the
new variant. Two types of code analysis techniques are provided in the
methodology, namely assembly to source code matching and binary clone
detection. The methodology can help reduce the number of functions requiring
manual analysis. The analysis results prove that the approach is promising in
Citadel malware analysis. Furthermore, the same approach is applicable to
similar malware analysis scenarios.
</summary>
    <author>
      <name>Ashkan Rahimian</name>
    </author>
    <author>
      <name>Raha Ziarati</name>
    </author>
    <author>
      <name>Stere Preda</name>
    </author>
    <author>
      <name>Mourad Debbabi</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-319-05302-8_25</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-319-05302-8_25" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 17 figures. This is an updated / edited version of a paper
  appeared in FPS 2013</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">LNCS 8352, 2014, pp 408-425</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1406.5569v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1406.5569v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.4.6; K.6.5; E.3; D.2.7" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1407.4346v1</id>
    <updated>2014-07-16T15:35:47Z</updated>
    <published>2014-07-16T15:35:47Z</published>
    <title>Faults in Linux 2.6</title>
    <summary>  In August 2011, Linux entered its third decade. Ten years before, Chou et al.
published a study of faults found by applying a static analyzer to Linux
versions 1.0 through 2.4.1. A major result of their work was that the drivers
directory contained up to 7 times more of certain kinds of faults than other
directories. This result inspired numerous efforts on improving the reliability
of driver code. Today, Linux is used in a wider range of environments, provides
a wider range of services, and has adopted a new development and release model.
What has been the impact of these changes on code quality? To answer this
question, we have transported Chou et al.'s experiments to all versions of
Linux 2.6; released between 2003 and 2011. We find that Linux has more than
doubled in size during this period, but the number of faults per line of code
has been decreasing. Moreover, the fault rate of drivers is now below that of
other directories, such as arch. These results can guide further development
and research efforts for the decade to come. To allow updating these results as
Linux evolves, we define our experimental protocol and make our checkers
available.
</summary>
    <author>
      <name>Nicolas Palix</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Grenoble 1 UJF, LIG</arxiv:affiliation>
    </author>
    <author>
      <name>Gaël Thomas</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIP6, INRIA Paris-Rocquencourt</arxiv:affiliation>
    </author>
    <author>
      <name>Suman Saha</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIP6, INRIA Paris-Rocquencourt</arxiv:affiliation>
    </author>
    <author>
      <name>Christophe Calvès</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIP6, INRIA Paris-Rocquencourt</arxiv:affiliation>
    </author>
    <author>
      <name>Gilles Muller</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIP6, INRIA Paris-Rocquencourt</arxiv:affiliation>
    </author>
    <author>
      <name>Julia L. Lawall</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIP6, INRIA Paris-Rocquencourt</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/2619090</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/2619090" rel="related"/>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">ACM Transactions on Computer Systems 32, 2 (2014) 1--40</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1407.4346v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1407.4346v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1409.5567v1</id>
    <updated>2014-09-19T09:30:49Z</updated>
    <published>2014-09-19T09:30:49Z</published>
    <title>Rank-Aware Dynamic Migrations and Adaptive Demotions for DRAM Power
  Management</title>
    <summary>  Modern DRAM architectures allow a number of low-power states on individual
memory ranks for advanced power management. Many previous studies have taken
advantage of demotions on low-power states for energy saving. However, most of
the demotion schemes are statically performed on a limited number of
pre-selected low-power states, and are suboptimal for different workloads and
memory architectures. Even worse, the idle periods are often too short for
effective power state transitions, especially for memory intensive
applications. Wrong decisions on power state transition incur significant
energy and delay penalties. In this paper, we propose a novel memory system
design named RAMZzz with rank-aware energy saving optimizations including
dynamic page migrations and adaptive demotions. Specifically, we group the
pages with similar access locality into the same rank with dynamic page
migrations. Ranks have their hotness: hot ranks are kept busy for high
utilization and cold ranks can have more lengthy idle periods for power state
transitions. We further develop adaptive state demotions by considering all
low-power states for each rank and a prediction model to estimate the
power-down timeout among states. We experimentally compare our algorithm with
other energy saving policies with cycle-accurate simulation. Experiments with
benchmark workloads show that RAMZzz achieves significant improvement on
energy-delay2 and energy consumption over other energy saving techniques.
</summary>
    <author>
      <name>Yanchao Lu</name>
    </author>
    <author>
      <name>Donghong Wu</name>
    </author>
    <author>
      <name>Bingsheng He</name>
    </author>
    <author>
      <name>Xueyan Tang</name>
    </author>
    <author>
      <name>Jianliang Xu</name>
    </author>
    <author>
      <name>Minyi Guo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1409.5567v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1409.5567v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="B.3.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1410.7747v1</id>
    <updated>2014-10-28T19:20:34Z</updated>
    <published>2014-10-28T19:20:34Z</published>
    <title>Sprobes: Enforcing Kernel Code Integrity on the TrustZone Architecture</title>
    <summary>  Many smartphones now deploy conventional operating systems, so the rootkit
attacks so prevalent on desktop and server systems are now a threat to
smartphones. While researchers have advocated using virtualization to detect
and prevent attacks on operating systems (e.g., VM introspection and trusted
virtual domains), virtualization is not practical on smartphone systems due to
the lack of virtualization support and/or the expense of virtualization.
Current smartphone processors do have hardware support for running a protected
environment, such as the ARM TrustZone extensions, but such hardware does not
control the operating system operations sufficiently to enable VM
introspection. In particular, a conventional operating system running with
TrustZone still retains full control of memory management, which a rootkit can
use to prevent traps on sensitive instructions or memory accesses necessary for
effective introspection. In this paper, we present SPROBES, a novel primitive
that enables introspection of operating systems running on ARM TrustZone
hardware. Using SPROBES, an introspection mechanism protected by TrustZone can
instrument individual operating system instructions of its choice, receiving an
unforgeable trap whenever any SPROBE is executed. The key challenge in
designing SPROBES is preventing the rootkit from removing them, but we identify
a set of five invariants whose enforcement is sufficient to restrict rootkits
to execute only approved, SPROBE-injected kernel code. We implemented a
proof-of-concept version of SPROBES for the ARM Fast Models emulator,
demonstrating that in Linux kernel 2.6.38, only 12 SPROBES are sufficient to
enforce all five of these invariants. With SPROBES we show that it is possible
to leverage the limited TrustZone extensions to limit conventional kernel
execution to approved code comprehensively.
</summary>
    <author>
      <name>Xinyang Ge</name>
    </author>
    <author>
      <name>Hayawardh Vijayakumar</name>
    </author>
    <author>
      <name>Trent Jaeger</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings of the Third Workshop on Mobile Security Technologies
  (MoST) 2014 (http://arxiv.org/abs/1410.6674)</arxiv:comment>
    <link href="http://arxiv.org/abs/1410.7747v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1410.7747v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.01666v1</id>
    <updated>2015-04-07T16:58:31Z</updated>
    <published>2015-04-07T16:58:31Z</published>
    <title>Garbage Collection Techniques for Flash-Resident Page-Mapping FTLs</title>
    <summary>  Storage devices based on flash memory have replaced hard disk drives (HDDs)
due to their superior performance, increasing density, and lower power
consumption. Unfortunately, flash memory is subject to challenging
idiosyncrasies like erase-before-write and limited block lifetime. These
constraints are handled by a flash translation layer (FTL), which performs
out-of-place updates, wear-leveling and garbage-collection behind the scene,
while offering the application a virtualization of the physical address space.
  A class of relevant FTLs employ a flash-resident page-associative mapping
table from logical to physical addresses, with a smaller RAM-resident cache for
frequently mapped entries. In this paper, we address the problem of performing
garbage-collection under such FTLs. We observe two problems. Firstly,
maintaining the metadata needed to perform garbage-collection under these
schemes is problematic, because at write-time we do not necessarily know the
physical address of the before-image. Secondly, the size of this metadata must
remain small, because it makes RAM unavailable for caching frequently accessed
entries. We propose two complementary techniques, called Lazy Gecko and
Logarithmic Gecko, which address these issues. Lazy Gecko works well when RAM
is plentiful enough to store the GC metadata. Logarithmic Gecko works well when
RAM isn't plentiful and efficiently stores the GC metadata in flash. Thus,
these techniques are applicable to a wide range of flash devices with varying
amounts of embedded RAM.
</summary>
    <author>
      <name>Niv Dayan</name>
    </author>
    <author>
      <name>Philippe Bonnet</name>
    </author>
    <link href="http://arxiv.org/abs/1504.01666v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.01666v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1504.03875v1</id>
    <updated>2015-04-15T12:05:59Z</updated>
    <published>2015-04-15T12:05:59Z</published>
    <title>RIOT OS Paves the Way for Implementation of High-Performance MAC
  Protocols</title>
    <summary>  Implementing new, high-performance MAC protocols requires real-time features,
to be able to synchronize correctly between different unrelated devices. Such
features are highly desirable for operating wireless sensor networks (WSN) that
are designed to be part of the Internet of Things (IoT). Unfortunately, the
operating systems commonly used in this domain cannot provide such features. On
the other hand, "bare-metal" development sacrifices portability, as well as the
mul-titasking abilities needed to develop the rich applications that are useful
in the domain of the Internet of Things. We describe in this paper how we
helped solving these issues by contributing to the development of a port of
RIOT OS on the MSP430 microcontroller, an architecture widely used in
IoT-enabled motes. RIOT OS offers rich and advanced real-time features,
especially the simultaneous use of as many hardware timers as the underlying
platform (microcontroller) can offer. We then demonstrate the effectiveness of
these features by presenting a new implementation, on RIOT OS, of S-CoSenS, an
efficient MAC protocol that uses very low processing power and energy.
</summary>
    <author>
      <name>Kévin Roussel</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Nancy - Grand Est / LORIA</arxiv:affiliation>
    </author>
    <author>
      <name>Ye-Qiong Song</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Nancy - Grand Est / LORIA</arxiv:affiliation>
    </author>
    <author>
      <name>Olivier Zendra</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">INRIA Nancy - Grand Est / LORIA</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.5220/0005237600050014</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.5220/0005237600050014" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">SCITEPRESS. SENSORNETS 2015, Feb 2015, Angers, France.
  http://www.scitepress.org</arxiv:comment>
    <link href="http://arxiv.org/abs/1504.03875v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1504.03875v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1505.02155v3</id>
    <updated>2016-09-23T07:13:59Z</updated>
    <published>2015-05-08T19:52:46Z</published>
    <title>Evaluate and Compare Two Utilization-Based Schedulability-Test
  Frameworks for Real-Time Systems</title>
    <summary>  This report summarizes two general frameworks, namely k2Q and k2U, that have
been recently developed by us. The purpose of this report is to provide
detailed evaluations and comparisons of these two frameworks. These two
frameworks share some similar characteristics, but they are useful for
different application cases. These two frameworks together provide
comprehensive means for the users to automatically convert the pseudo
polynomial-time tests (or even exponential-time tests) into polynomial-time
tests with closed mathematical forms. With the quadratic and hyperbolic forms,
k2Q and k2U frameworks can be used to provide many quantitive features to be
measured and evaluated, like the total utilization bounds, speed-up factors,
etc., not only for uniprocessor scheduling but also for multiprocessor
scheduling. These frameworks can be viewed as "blackbox" interfaces for
providing polynomial-time schedulability tests and response time analysis for
real-time applications. We have already presented their advantages for being
applied in some models in the previous papers. However, it was not possible to
present a more comprehensive comparison between these two frameworks. We hope
this report can help the readers and users clearly understand the difference of
these two frameworks, their unique characteristics, and their advantages. We
demonstrate their differences and properties by using the traditional sporadic
realtime task models in uniprocessor scheduling and multiprocessor global
scheduling.
</summary>
    <author>
      <name>Jian-Jia Chen</name>
    </author>
    <author>
      <name>Wen-Hung Huang</name>
    </author>
    <author>
      <name>Cong Liu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: text overlap with arXiv:1501.07084</arxiv:comment>
    <link href="http://arxiv.org/abs/1505.02155v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1505.02155v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.04170v1</id>
    <updated>2015-11-13T06:27:48Z</updated>
    <published>2015-11-13T06:27:48Z</published>
    <title>Controlled Owicki-Gries Concurrency: Reasoning about the Preemptible
  eChronos Embedded Operating System</title>
    <summary>  We introduce a controlled concurrency framework, derived from the
Owicki-Gries method, for describing a hardware interface in detail sufficient
to support the modelling and verification of small, embedded operating systems
(OS's) whose run-time responsiveness is paramount. Such real-time systems run
with interrupts mostly enabled, including during scheduling. That differs from
many other successfully modelled and verified OS's that typically reduce the
complexity of concurrency by running on uniprocessor platforms and by switching
interrupts off as much as possible. Our framework builds on the traditional
Owicki-Gries method, for its fine-grained concurrency is needed for
high-performance system code. We adapt it to support explicit concurrency
control, by providing a simple, faithful representation of the hardware
interface that allows software to control the degree of interleaving between
user code, OS code, interrupt handlers and a scheduler that controls context
switching. We then apply this framework to model the interleaving behavior of
the eChronos OS, a preemptible real-time OS for embedded micro-controllers. We
discuss the accuracy and usability of our approach when instantiated to model
the eChronos OS. Both our framework and the eChronos model are formalised in
the Isabelle/HOL theorem prover, taking advantage of the high level of
automation in modern reasoning tools.
</summary>
    <author>
      <name>June Andronick</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">NICTA and UNSW</arxiv:affiliation>
    </author>
    <author>
      <name>Corey Lewis</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">NICTA</arxiv:affiliation>
    </author>
    <author>
      <name>Carroll Morgan</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">NICTA and UNSW</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.196.2</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.196.2" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings MARS 2015, arXiv:1511.02528</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 196, 2015, pp. 10-24</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1511.04170v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1511.04170v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1604.00320v1</id>
    <updated>2016-04-01T16:32:47Z</updated>
    <published>2016-04-01T16:32:47Z</published>
    <title>AuDroid: Preventing Attacks on Audio Channels in Mobile Devices</title>
    <summary>  Voice control is a popular way to operate mobile devices, enabling users to
communicate requests to their devices. However, adversaries can leverage voice
control to trick mobile devices into executing commands to leak secrets or to
modify critical information. Contemporary mobile operating systems fail to
prevent such attacks because they do not control access to the speaker at all
and fail to control when untrusted apps may use the microphone, enabling
authorized apps to create exploitable communication channels. In this paper, we
propose a security mechanism that tracks the creation of audio communication
channels explicitly and controls the information flows over these channels to
prevent several types of attacks.We design and implement AuDroid, an extension
to the SELinux reference monitor integrated into the Android operating system
for enforcing lattice security policies over the dynamically changing use of
system audio resources. To enhance flexibility, when information flow errors
are detected, the device owner, system apps and services are given the
opportunity to resolve information flow errors using known methods, enabling
AuDroid to run many configurations safely. We evaluate our approach on 17
widely-used apps that make extensive use of the microphone and speaker, finding
that AuDroid prevents six types of attack scenarios on audio channels while
permitting all 17 apps to run effectively. AuDroid shows that it is possible to
prevent attacks using audio channels without compromising functionality or
introducing significant performance overhead.
</summary>
    <author>
      <name>Giuseppe Petracca</name>
    </author>
    <author>
      <name>Yuqiong Sun</name>
    </author>
    <author>
      <name>Ahmad Atamli</name>
    </author>
    <author>
      <name>Trent Jaeger</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2015 Annual Computer Security Applications Conference</arxiv:comment>
    <link href="http://arxiv.org/abs/1604.00320v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1604.00320v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1606.05794v1</id>
    <updated>2016-06-18T18:55:42Z</updated>
    <published>2016-06-18T18:55:42Z</published>
    <title>Scalability of VM Provisioning Systems</title>
    <summary>  Virtual machines and virtualized hardware have been around for over half a
century. The commoditization of the x86 platform and its rapidly growing
hardware capabilities have led to recent exponential growth in the use of
virtualization both in the enterprise and high performance computing (HPC). The
startup time of a virtualized environment is a key performance metric for high
performance computing in which the runtime of any individual task is typically
much shorter than the lifetime of a virtualized service in an enterprise
context. In this paper, a methodology for accurately measuring the startup
performance on an HPC system is described. The startup performance overhead of
three of the most mature, widely deployed cloud management frameworks
(OpenStack, OpenNebula, and Eucalyptus) is measured to determine their
suitability for workloads typically seen in an HPC environment. A 10x
performance difference is observed between the fastest (Eucalyptus) and the
slowest (OpenNebula) framework. This time difference is primarily due to delays
in waiting on networking in the cloud-init portion of the startup. The
methodology and measurements presented should facilitate the optimization of
startup across a variety of virtualization environments.
</summary>
    <author>
      <name>Mike Jones</name>
    </author>
    <author>
      <name>Bill Arcand</name>
    </author>
    <author>
      <name>Bill Bergeron</name>
    </author>
    <author>
      <name>David Bestor</name>
    </author>
    <author>
      <name>Chansup Byun</name>
    </author>
    <author>
      <name>Lauren Milechin</name>
    </author>
    <author>
      <name>Vijay Gadepally</name>
    </author>
    <author>
      <name>Matt Hubbell</name>
    </author>
    <author>
      <name>Jeremy Kepner</name>
    </author>
    <author>
      <name>Pete Michaleas</name>
    </author>
    <author>
      <name>Julie Mullen</name>
    </author>
    <author>
      <name>Andy Prout</name>
    </author>
    <author>
      <name>Tony Rosa</name>
    </author>
    <author>
      <name>Siddharth Samsi</name>
    </author>
    <author>
      <name>Charles Yee</name>
    </author>
    <author>
      <name>Albert Reuther</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/HPEC.2016.7761629</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/HPEC.2016.7761629" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages; 6 figures; accepted to the IEEE High Performance Extreme
  Computing (HPEC) conference 2016</arxiv:comment>
    <link href="http://arxiv.org/abs/1606.05794v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1606.05794v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.07763v1</id>
    <updated>2016-07-15T14:52:57Z</updated>
    <published>2016-07-15T14:52:57Z</published>
    <title>Energy-Efficient Real-Time Scheduling for Two-Type Heterogeneous
  Multiprocessors</title>
    <summary>  We propose three novel mathematical optimization formulations that solve the
same two-type heterogeneous multiprocessor scheduling problem for a real-time
taskset with hard constraints. Our formulations are based on a global
scheduling scheme and a fluid model. The first formulation is a mixed-integer
nonlinear program, since the scheduling problem is intuitively considered as an
assignment problem. However, by changing the scheduling problem to first
determine a task workload partition and then to find the execution order of all
tasks, the computation time can be significantly reduced. Specifically, the
workload partitioning problem can be formulated as a continuous nonlinear
program for a system with continuous operating frequency, and as a continuous
linear program for a practical system with a discrete speed level set. The task
ordering problem can be solved by an algorithm with a complexity that is linear
in the total number of tasks. The work is evaluated against existing global
energy/feasibility optimal workload allocation formulations. The results
illustrate that our algorithms are both feasibility optimal and energy optimal
for both implicit and constrained deadline tasksets. Specifically, our
algorithm can achieve up to 40% energy saving for some simulated tasksets with
constrained deadlines. The benefit of our formulation compared with existing
work is that our algorithms can solve a more general class of scheduling
problems due to incorporating a scheduling dynamic model in the formulations
and allowing for a time-varying speed profile. Moreover, our algorithms can be
applied to both online and offline scheduling schemes.
</summary>
    <author>
      <name>Mason Thammawichai</name>
    </author>
    <author>
      <name>Eric C. Kerrigan</name>
    </author>
    <link href="http://arxiv.org/abs/1607.07763v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.07763v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1607.07995v2</id>
    <updated>2016-09-24T01:49:03Z</updated>
    <published>2016-07-27T07:46:13Z</published>
    <title>System-level Scalable Checkpoint-Restart for Petascale Computing</title>
    <summary>  Fault tolerance for the upcoming exascale generation has long been an area of
active research. One of the components of a fault tolerance strategy is
checkpointing. Petascale-level checkpointing is demonstrated through a new
mechanism for virtualization of the InfiniBand UD (unreliable datagram) mode,
and for updating the remote address on each UD-based send, due to lack of a
fixed peer. Note that InfiniBand UD is required to support modern MPI
implementations. An extrapolation from the current results to future SSD-based
storage systems provides evidence that the current approach will remain
practical in the exascale generation. This transparent checkpointing approach
is evaluated using a framework of the DMTCP checkpointing package. Results are
shown for HPCG (linear algebra), NAMD (molecular dynamics), and the NAS NPB
benchmarks. In tests up to 32,752 MPI processes on 32,752 CPU cores,
checkpointing of a computation with a 38 TB memory footprint in 11 minutes is
demonstrated. Runtime overhead is reduced to less than 1%. The approach is also
evaluated across three widely used MPI implementations.
</summary>
    <author>
      <name>Jiajun Cao</name>
    </author>
    <author>
      <name>Kapil Arya</name>
    </author>
    <author>
      <name>Rohan Garg</name>
    </author>
    <author>
      <name>Shawn Matott</name>
    </author>
    <author>
      <name>Dhabaleswar K. Panda</name>
    </author>
    <author>
      <name>Hari Subramoni</name>
    </author>
    <author>
      <name>Jérôme Vienne</name>
    </author>
    <author>
      <name>Gene Cooperman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, 5 figures, to be published in ICPADS 2016</arxiv:comment>
    <link href="http://arxiv.org/abs/1607.07995v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.07995v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="C.4; D.1.3; D.2.11" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1609.02067v1</id>
    <updated>2016-09-07T16:53:40Z</updated>
    <published>2016-09-07T16:53:40Z</published>
    <title>Practical Data Compression for Modern Memory Hierarchies</title>
    <summary>  In this thesis, we describe a new, practical approach to integrating
hardware-based data compression within the memory hierarchy, including on-chip
caches, main memory, and both on-chip and off-chip interconnects. This new
approach is fast, simple, and effective in saving storage space. A key insight
in our approach is that access time (including decompression latency) is
critical in modern memory hierarchies. By combining inexpensive hardware
support with modest OS support, our holistic approach to compression achieves
substantial improvements in performance and energy efficiency across the memory
hierarchy. Using this new approach, we make several major contributions in this
thesis. First, we propose a new compression algorithm, Base-Delta-Immediate
Compression (BDI), that achieves high compression ratio with very low
compression/decompression latency. BDI exploits the existing low dynamic range
of values present in many cache lines to compress them to smaller sizes using
Base+Delta encoding. Second, we observe that the compressed size of a cache
block can be indicative of its reuse. We use this observation to develop a new
cache insertion policy for compressed caches, the Size-based Insertion Policy
(SIP), which uses the size of a compressed block as one of the metrics to
predict its potential future reuse. Third, we propose a new main memory
compression framework, Linearly Compressed Pages (LCP), that significantly
reduces the complexity and power cost of supporting main memory compression. We
demonstrate that any compression algorithm can be adapted to fit the
requirements of LCP, and that LCP can be efficiently integrated with the
existing cache compression designs, avoiding extra compression/decompression.
</summary>
    <author>
      <name>Gennady Pekhimenko</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">PhD Thesis</arxiv:comment>
    <link href="http://arxiv.org/abs/1609.02067v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1609.02067v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1610.03052v1</id>
    <updated>2016-10-10T19:59:32Z</updated>
    <published>2016-10-10T19:59:32Z</published>
    <title>Verification of the Tree-Based Hierarchical Read-Copy Update in the
  Linux Kernel</title>
    <summary>  Read-Copy Update (RCU) is a scalable, high-performance Linux-kernel
synchronization mechanism that runs low-overhead readers concurrently with
updaters. Production-quality RCU implementations for multi-core systems are
decidedly non-trivial. Giving the ubiquity of Linux, a rare "million-year" bug
can occur several times per day across the installed base. Stringent validation
of RCU's complex behaviors is thus critically important. Exhaustive testing is
infeasible due to the exponential number of possible executions, which suggests
use of formal verification.
  Previous verification efforts on RCU either focus on simple implementations
or use modeling languages, the latter requiring error-prone manual translation
that must be repeated frequently due to regular changes in the Linux kernel's
RCU implementation. In this paper, we first describe the implementation of Tree
RCU in the Linux kernel. We then discuss how to construct a model directly from
Tree RCU's source code in C, and use the CBMC model checker to verify its
safety and liveness properties. To our best knowledge, this is the first
verification of a significant part of RCU's source code, and is an important
step towards integration of formal verification into the Linux kernel's
regression test suite.
</summary>
    <author>
      <name>Lihao Liang</name>
    </author>
    <author>
      <name>Paul E. McKenney</name>
    </author>
    <author>
      <name>Daniel Kroening</name>
    </author>
    <author>
      <name>Tom Melham</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 11 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1610.03052v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1610.03052v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.2.4; D.1.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1612.00445v2</id>
    <updated>2017-08-21T20:09:02Z</updated>
    <published>2016-12-01T17:45:18Z</published>
    <title>Near-Memory Address Translation</title>
    <summary>  Memory and logic integration on the same chip is becoming increasingly cost
effective, creating the opportunity to offload data-intensive functionality to
processing units placed inside memory chips. The introduction of memory-side
processing units (MPUs) into conventional systems faces virtual memory as the
first big showstopper: without efficient hardware support for address
translation MPUs have highly limited applicability. Unfortunately, conventional
translation mechanisms fall short of providing fast translations as
contemporary memories exceed the reach of TLBs, making expensive page walks
common.
  In this paper, we are the first to show that the historically important
flexibility to map any virtual page to any page frame is unnecessary in today's
servers. We find that while limiting the associativity of the
virtual-to-physical mapping incurs no penalty, it can break the
translate-then-fetch serialization if combined with careful data placement in
the MPU's memory, allowing for translation and data fetch to proceed
independently and in parallel. We propose the Distributed Inverted Page Table
(DIPTA), a near-memory structure in which the smallest memory partition keeps
the translation information for its data share, ensuring that the translation
completes together with the data fetch. DIPTA completely eliminates the
performance overhead of translation, achieving speedups of up to 3.81x and
2.13x over conventional translation using 4KB and 1GB pages respectively.
</summary>
    <author>
      <name>Javier Picorel</name>
    </author>
    <author>
      <name>Djordje Jevdjic</name>
    </author>
    <author>
      <name>Babak Falsafi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, 9 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1612.00445v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1612.00445v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1704.00999v1</id>
    <updated>2017-04-04T13:26:31Z</updated>
    <published>2017-04-04T13:26:31Z</published>
    <title>A Backward Algorithm for the Multiprocessor Online Feasibility of
  Sporadic Tasks</title>
    <summary>  The online feasibility problem (for a set of sporadic tasks) asks whether
there is a scheduler that always prevents deadline misses (if any), whatever
the sequence of job releases, which is a priori} unknown to the scheduler. In
the multiprocessor setting, this problem is notoriously difficult. The only
exact test for this problem has been proposed by Bonifaci and
Marchetti-Spaccamela: it consists in modelling all the possible behaviours of
the scheduler and of the tasks as a graph; and to interpret this graph as a
game between the tasks and the scheduler, which are seen as antagonistic
players. Then, computing a correct scheduler is equivalent to finding a winning
strategy for the `scheduler player', whose objective in the game is to avoid
deadline misses. In practice, however this approach is limited by the
intractable size of the graph. In this work, we consider the classical
attractor algorithm to solve such games, and introduce antichain techniques to
optimise its performance in practice and overcome the huge size of the game
graph. These techniques are inspired from results from the formal methods
community, and exploit the specific structure of the feasibility problem. We
demonstrate empirically that our approach allows to dramatically improve the
performance of the game solving algorithm.
</summary>
    <author>
      <name>Gilles Geeraerts</name>
    </author>
    <author>
      <name>Joël Goossens</name>
    </author>
    <author>
      <name>Thi-Van-Anh Nguyen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Long version of a conference paper accepted to ACSD 2017</arxiv:comment>
    <link href="http://arxiv.org/abs/1704.00999v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1704.00999v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.GT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1704.05600v2</id>
    <updated>2017-06-23T02:43:41Z</updated>
    <published>2017-04-19T03:30:09Z</published>
    <title>TrustShadow: Secure Execution of Unmodified Applications with ARM
  TrustZone</title>
    <summary>  The rapid evolution of Internet-of-Things (IoT) technologies has led to an
emerging need to make it smarter. A variety of applications now run
simultaneously on an ARM-based processor. For example, devices on the edge of
the Internet are provided with higher horsepower to be entrusted with storing,
processing and analyzing data collected from IoT devices. This significantly
improves efficiency and reduces the amount of data that needs to be transported
to the cloud for data processing, analysis and storage. However, commodity OSes
are prone to compromise. Once they are exploited, attackers can access the data
on these devices. Since the data stored and processed on the devices can be
sensitive, left untackled, this is particularly disconcerting.
  In this paper, we propose a new system, TrustShadow that shields legacy
applications from untrusted OSes. TrustShadow takes advantage of ARM TrustZone
technology and partitions resources into the secure and normal worlds. In the
secure world, TrustShadow constructs a trusted execution environment for
security-critical applications. This trusted environment is maintained by a
lightweight runtime system that coordinates the communication between
applications and the ordinary OS running in the normal world. The runtime
system does not provide system services itself. Rather, it forwards requests
for system services to the ordinary OS, and verifies the correctness of the
responses. To demonstrate the efficiency of this design, we prototyped
TrustShadow on a real chip board with ARM TrustZone support, and evaluated its
performance using both microbenchmarks and real-world applications. We showed
TrustShadow introduces only negligible overhead to real-world applications.
</summary>
    <author>
      <name>Le Guan</name>
    </author>
    <author>
      <name>Peng Liu</name>
    </author>
    <author>
      <name>Xinyu Xing</name>
    </author>
    <author>
      <name>Xinyang Ge</name>
    </author>
    <author>
      <name>Shengzhi Zhang</name>
    </author>
    <author>
      <name>Meng Yu</name>
    </author>
    <author>
      <name>Trent Jaeger</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3081333.3081349</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3081333.3081349" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">MobiSys 2017</arxiv:comment>
    <link href="http://arxiv.org/abs/1704.05600v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1704.05600v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.00138v3</id>
    <updated>2017-05-23T19:00:17Z</updated>
    <published>2017-04-29T06:22:32Z</published>
    <title>Contego: An Adaptive Framework for Integrating Security Tasks in
  Real-Time Systems</title>
    <summary>  Embedded real-time systems (RTS) are pervasive. Many modern RTS are exposed
to unknown security flaws, and threats to RTS are growing in both number and
sophistication. However, until recently, cyber-security considerations were an
afterthought in the design of such systems. Any security mechanisms integrated
into RTS must (a) co-exist with the real- time tasks in the system and (b)
operate without impacting the timing and safety constraints of the control
logic. We introduce Contego, an approach to integrating security tasks into RTS
without affecting temporal requirements. Contego is specifically designed for
legacy systems, viz., the real-time control systems in which major alterations
of the system parameters for constituent tasks is not always feasible. Contego
combines the concept of opportunistic execution with hierarchical scheduling to
maintain compatibility with legacy systems while still providing flexibility by
allowing security tasks to operate in different modes. We also define a metric
to measure the effectiveness of such integration. We evaluate Contego using
synthetic workloads as well as with an implementation on a realistic embedded
platform (an open- source ARM CPU running real-time Linux).
</summary>
    <author>
      <name>Monowar Hasan</name>
    </author>
    <author>
      <name>Sibin Mohan</name>
    </author>
    <author>
      <name>Rodolfo Pellizzoni</name>
    </author>
    <author>
      <name>Rakesh B. Bobba</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted for publication, 29th Euromicro Conference on Real-Time
  Systems (ECRTS17)</arxiv:comment>
    <link href="http://arxiv.org/abs/1705.00138v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.00138v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1705.03623v1</id>
    <updated>2017-05-10T06:47:40Z</updated>
    <published>2017-05-10T06:47:40Z</published>
    <title>Improving the Performance and Endurance of Persistent Memory with
  Loose-Ordering Consistency</title>
    <summary>  Persistent memory provides high-performance data persistence at main memory.
Memory writes need to be performed in strict order to satisfy storage
consistency requirements and enable correct recovery from system crashes.
Unfortunately, adhering to such a strict order significantly degrades system
performance and persistent memory endurance. This paper introduces a new
mechanism, Loose-Ordering Consistency (LOC), that satisfies the ordering
requirements at significantly lower performance and endurance loss. LOC
consists of two key techniques. First, Eager Commit eliminates the need to
perform a persistent commit record write within a transaction. We do so by
ensuring that we can determine the status of all committed transactions during
recovery by storing necessary metadata information statically with blocks of
data written to memory. Second, Speculative Persistence relaxes the write
ordering between transactions by allowing writes to be speculatively written to
persistent memory. A speculative write is made visible to software only after
its associated transaction commits. To enable this, our mechanism supports the
tracking of committed transaction ID and multi-versioning in the CPU cache. Our
evaluations show that LOC reduces the average performance overhead of memory
persistence from 66.9% to 34.9% and the memory write traffic overhead from
17.1% to 3.4% on a variety of workloads.
</summary>
    <author>
      <name>Youyou Lu</name>
    </author>
    <author>
      <name>Jiwu Shu</name>
    </author>
    <author>
      <name>Long Sun</name>
    </author>
    <author>
      <name>Onur Mutlu</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/TPDS.2017.2701364</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/TPDS.2017.2701364" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This paper has been accepted by IEEE Transactions on Parallel and
  Distributed Systems</arxiv:comment>
    <link href="http://arxiv.org/abs/1705.03623v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1705.03623v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1707.05260v1</id>
    <updated>2017-07-17T16:12:15Z</updated>
    <published>2017-07-17T16:12:15Z</published>
    <title>Deterministic Memory Abstraction and Supporting Cache Architecture for
  Real-Time Systems</title>
    <summary>  Achieving strong real-time guarantees in multi-core platforms is challenging
due to the extensive hardware resource sharing in the memory hierarchy. Modern
platforms and OS's, however, provide no means to appropriately handle memory
regions that are crucial for real-time performance. In this paper, we propose a
new OS-level abstraction, namely Deterministic Memory, to define memory regions
that are specially handled by the OS and the hardware to exhibit strong
real-time guarantees.
  We show that the deterministic memory abstraction can be introduced in the OS
at the granularity of single memory pages by exploiting existing hardware
support. When deterministic memory pages are accessed, the attribute is
propagated through all the levels of the memory hierarchy. Clearly, the
hardware needs to be designed to ensure real-time handling of deterministic
memory requests. To illustrate the potentialities of the new abstraction, we
also propose a novel design for a shared cache controller that takes advantage
of deterministic memory. Minimum cache space is guaranteed for deterministic
memory, while unused cache space is left available to non-real-time
applications.
  We implemented OS support for deterministic memory in the Linux kernel; and
we evaluated the proposed hardware modifications in a cycle-accurate
full-system simulator. We study the effectiveness of our approach on a set of
synthetic and real benchmarks. Results show that it is possible to achieve (i)
temporal determinism as strong as with traditional way-based cache
partitioning; and (ii) giving 50% of the private partition space, on average,
to the non-real-time applications.
</summary>
    <author>
      <name>Farzad Farshchi</name>
    </author>
    <author>
      <name>Prathap Kumar Valsan</name>
    </author>
    <author>
      <name>Renato Mancuso</name>
    </author>
    <author>
      <name>Heechul Yun</name>
    </author>
    <link href="http://arxiv.org/abs/1707.05260v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1707.05260v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/cs/0701037v3</id>
    <updated>2009-02-24T18:13:25Z</updated>
    <published>2007-01-06T11:36:50Z</published>
    <title>DMTCP: Transparent Checkpointing for Cluster Computations and the
  Desktop</title>
    <summary>  DMTCP (Distributed MultiThreaded CheckPointing) is a transparent user-level
checkpointing package for distributed applications. Checkpointing and restart
is demonstrated for a wide range of over 20 well known applications, including
MATLAB, Python, TightVNC, MPICH2, OpenMPI, and runCMS. RunCMS runs as a 680 MB
image in memory that includes 540 dynamic libraries, and is used for the CMS
experiment of the Large Hadron Collider at CERN. DMTCP transparently
checkpoints general cluster computations consisting of many nodes, processes,
and threads; as well as typical desktop applications. On 128 distributed cores
(32 nodes), checkpoint and restart times are typically 2 seconds, with
negligible run-time overhead. Typical checkpoint times are reduced to 0.2
seconds when using forked checkpointing. Experimental results show that
checkpoint time remains nearly constant as the number of nodes increases on a
medium-size cluster.
  DMTCP automatically accounts for fork, exec, ssh, mutexes/semaphores, TCP/IP
sockets, UNIX domain sockets, pipes, ptys (pseudo-terminals), terminal modes,
ownership of controlling terminals, signal handlers, open file descriptors,
shared open file descriptors, I/O (including the readline library), shared
memory (via mmap), parent-child process relationships, pid virtualization, and
other operating system artifacts. By emphasizing an unprivileged, user-space
approach, compatibility is maintained across Linux kernels from 2.6.9 through
the current 2.6.28. Since DMTCP is unprivileged and does not require special
kernel modules or kernel patches, DMTCP can be incorporated and distributed as
a checkpoint-restart module within some larger package.
</summary>
    <author>
      <name>Jason Ansel</name>
    </author>
    <author>
      <name>Kapil Arya</name>
    </author>
    <author>
      <name>Gene Cooperman</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages; 2 figures, 8 plots, and 2 tables; description of DMTCP;
  Version 3: describing checkpointing both for distributed multi-threaded
  applications (including MPI), and interactive shell-like languages on
  desktop; Revised to reflect version published in IPDPS-09; Software at:
  http://dmtcp.sourceforge.net/</arxiv:comment>
    <link href="http://arxiv.org/abs/cs/0701037v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/cs/0701037v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.4.5" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.6354v1</id>
    <updated>2012-12-27T11:55:43Z</updated>
    <published>2012-12-27T11:55:43Z</published>
    <title>LNOS - Live Network Operating System</title>
    <summary>  Operating Systems exists since existence of computers, and have been evolving
continuously from time to time. In this paper we have reviewed a relatively new
or unexplored topic of Live OS. From networking perspective, Live OS is used
for establishing Clusters, Firewalls and as Network security assessment tool
etc. Our proposed concept is that a Live OS can be established or configured
for an organizations specific network requirements with respect to their
servers. An important server failure due to hardware or software could take
time for remedy of the problem, so for that situation a preconfigured server in
the form of Live OS on CD/DVD/USB can be used as an immediate solution. In a
network of ten nodes, we stopped the server machine and with necessary
adjustments, Live OS replaced the server in less than five minutes. Live OS in
a network environment is a quick replacement of the services that are failed
due to server failure (hardware or software). It is a cost effective solution
for low budget networks. The life of Live OS starts when we boot it from
CD/DVD/USB and remains in action for that session. As soon as the machine is
rebooted, any work done for that session is gone, (in case we do not store any
information on permanent storage media). Live CD/DVD/USB is normally used on
systems where we do not have Operating Systems installed. A Live OS can also be
used on systems where we already have an installed OS. On the basis of
functionality a Live OS can be used for many purposes and has some typical
advantages that are not available on other operating systems. Vendors are
releasing different distributions of Live OS and is becoming their sole
identity in a particular domain like Networks, Security, Education or
Entertainment etc. There can be many aspects of Live OS, but Linux based Live
OS and their use in the field of networks is the main focus of this paper.
</summary>
    <author>
      <name>Sajjad Haider</name>
    </author>
    <author>
      <name>Mehboob Yasin</name>
    </author>
    <author>
      <name>Naveed Hussain</name>
    </author>
    <author>
      <name>Muhammad Imran</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6th CIIT Workshop on Research in Computing (CWRC, 2007)</arxiv:comment>
    <link href="http://arxiv.org/abs/1212.6354v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1212.6354v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1305.1459v1</id>
    <updated>2013-05-07T10:22:31Z</updated>
    <published>2013-05-07T10:22:31Z</published>
    <title>EURETILE 2010-2012 summary: first three years of activity of the
  European Reference Tiled Experiment</title>
    <summary>  This is the summary of first three years of activity of the EURETILE FP7
project 247846. EURETILE investigates and implements brain-inspired and
fault-tolerant foundational innovations to the system architecture of massively
parallel tiled computer architectures and the corresponding programming
paradigm. The execution targets are a many-tile HW platform, and a many-tile
simulator. A set of SW process - HW tile mapping candidates is generated by the
holistic SW tool-chain using a combination of analytic and bio-inspired
methods. The Hardware dependent Software is then generated, providing OS
services with maximum efficiency/minimal overhead. The many-tile simulator
collects profiling data, closing the loop of the SW tool chain. Fine-grain
parallelism inside processes is exploited by optimized intra-tile compilation
techniques, but the project focus is above the level of the elementary tile.
The elementary HW tile is a multi-processor, which includes a fault tolerant
Distributed Network Processor (for inter-tile communication) and ASIP
accelerators. Furthermore, EURETILE investigates and implements the innovations
for equipping the elementary HW tile with high-bandwidth, low-latency
brain-like inter-tile communication emulating 3 levels of connection hierarchy,
namely neural columns, cortical areas and cortex, and develops a dedicated
cortical simulation benchmark: DPSNN-STDP (Distributed Polychronous Spiking
Neural Net with synaptic Spiking Time Dependent Plasticity). EURETILE leverages
on the multi-tile HW paradigm and SW tool-chain developed by the FET-ACA SHAPES
Integrated Project (2006-2009).
</summary>
    <author>
      <name>Pier Stanislao Paolucci</name>
    </author>
    <author>
      <name>Iuliana Bacivarov</name>
    </author>
    <author>
      <name>Gert Goossens</name>
    </author>
    <author>
      <name>Rainer Leupers</name>
    </author>
    <author>
      <name>Frédéric Rousseau</name>
    </author>
    <author>
      <name>Christoph Schumacher</name>
    </author>
    <author>
      <name>Lothar Thiele</name>
    </author>
    <author>
      <name>Piero Vicini</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.12837/2013T01</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.12837/2013T01" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">56 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1305.1459v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1305.1459v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="C.1.4; C.3; B.7.2; F.2.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1406.6037v1</id>
    <updated>2014-06-23T19:44:03Z</updated>
    <published>2014-06-23T19:44:03Z</published>
    <title>Preemptive Thread Block Scheduling with Online Structural Runtime
  Prediction for Concurrent GPGPU Kernels</title>
    <summary>  Recent NVIDIA Graphics Processing Units (GPUs) can execute multiple kernels
concurrently. On these GPUs, the thread block scheduler (TBS) uses the FIFO
policy to schedule their thread blocks. We show that FIFO leaves performance to
chance, resulting in significant loss of performance and fairness. To improve
performance and fairness, we propose use of the preemptive Shortest Remaining
Time First (SRTF) policy instead. Although SRTF requires an estimate of runtime
of GPU kernels, we show that such an estimate of the runtime can be easily
obtained using online profiling and exploiting a simple observation on GPU
kernels' grid structure. Specifically, we propose a novel Structural Runtime
Predictor. Using a simple Staircase model of GPU kernel execution, we show that
the runtime of a kernel can be predicted by profiling only the first few thread
blocks. We evaluate an online predictor based on this model on benchmarks from
ERCBench, and find that it can estimate the actual runtime reasonably well
after the execution of only a single thread block. Next, we design a thread
block scheduler that is both concurrent kernel-aware and uses this predictor.
We implement the SRTF policy and evaluate it on two-program workloads from
ERCBench. SRTF improves STP by 1.18x and ANTT by 2.25x over FIFO. When compared
to MPMax, a state-of-the-art resource allocation policy for concurrent kernels,
SRTF improves STP by 1.16x and ANTT by 1.3x. To improve fairness, we also
propose SRTF/Adaptive which controls resource usage of concurrently executing
kernels to maximize fairness. SRTF/Adaptive improves STP by 1.12x, ANTT by
2.23x and Fairness by 2.95x compared to FIFO. Overall, our implementation of
SRTF achieves system throughput to within 12.64% of Shortest Job First (SJF, an
oracle optimal scheduling policy), bridging 49% of the gap between FIFO and
SJF.
</summary>
    <author>
      <name>Sreepathi Pai</name>
    </author>
    <author>
      <name>R. Govindarajan</name>
    </author>
    <author>
      <name>Matthew J. Thazhuthaveetil</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, full pre-review version of PACT 2014 poster</arxiv:comment>
    <link href="http://arxiv.org/abs/1406.6037v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1406.6037v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.3.3; C.1.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1708.00544v1</id>
    <updated>2017-08-01T22:48:06Z</updated>
    <published>2017-08-01T22:48:06Z</published>
    <title>Performance Measurements of Supercomputing and Cloud Storage Solutions</title>
    <summary>  Increasing amounts of data from varied sources, particularly in the fields of
machine learning and graph analytics, are causing storage requirements to grow
rapidly. A variety of technologies exist for storing and sharing these data,
ranging from parallel file systems used by supercomputers to distributed block
storage systems found in clouds. Relatively few comparative measurements exist
to inform decisions about which storage systems are best suited for particular
tasks. This work provides these measurements for two of the most popular
storage technologies: Lustre and Amazon S3. Lustre is an open-source, high
performance, parallel file system used by many of the largest supercomputers in
the world. Amazon's Simple Storage Service, or S3, is part of the Amazon Web
Services offering, and offers a scalable, distributed option to store and
retrieve data from anywhere on the Internet. Parallel processing is essential
for achieving high performance on modern storage systems. The performance tests
used span the gamut of parallel I/O scenarios, ranging from single-client,
single-node Amazon S3 and Lustre performance to a large-scale, multi-client
test designed to demonstrate the capabilities of a modern storage appliance
under heavy load. These results show that, when parallel I/O is used correctly
(i.e., many simultaneous read or write processes), full network bandwidth
performance is achievable and ranged from 10 gigabits/s over a 10 GigE S3
connection to 0.35 terabits/s using Lustre on a 1200 port 10 GigE switch. These
results demonstrate that S3 is well-suited to sharing vast quantities of data
over the Internet, while Lustre is well-suited to processing large quantities
of data locally.
</summary>
    <author>
      <name>Michael Jones</name>
    </author>
    <author>
      <name>Jeremy Kepner</name>
    </author>
    <author>
      <name>William Arcand</name>
    </author>
    <author>
      <name>David Bestor</name>
    </author>
    <author>
      <name>Bill Bergeron</name>
    </author>
    <author>
      <name>Vijay Gadepally</name>
    </author>
    <author>
      <name>Michael Houle</name>
    </author>
    <author>
      <name>Matthew Hubbell</name>
    </author>
    <author>
      <name>Peter Michaleas</name>
    </author>
    <author>
      <name>Andrew Prout</name>
    </author>
    <author>
      <name>Albert Reuther</name>
    </author>
    <author>
      <name>Siddharth Samsi</name>
    </author>
    <author>
      <name>Paul Monticiollo</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages, 4 figures, to appear in IEEE HPEC 2017</arxiv:comment>
    <link href="http://arxiv.org/abs/1708.00544v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1708.00544v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.IM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.OS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
